+ RUN=2
+ export CUDA_VISIBLE_DEVICES=2
+ CUDA_VISIBLE_DEVICES=2
+ LAYERS='300_300_300_1 500_500_500_500_1'
+ case $RUN in
+ PSI='0 1'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output61
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output75
+ for fn in f1 f2
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0
+ date
Mon Nov  9 00:59:20 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_1000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_1000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_1000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_4000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_4000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_4000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_8000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_8000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_8000/300_300_300_1
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.4
+ date
Mon Nov  9 00:59:20 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.4/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_1000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_1000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_1000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_4000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_4000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_4000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_8000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_8000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_8000/300_300_300_1
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.4/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.8
+ date
Mon Nov  9 00:59:20 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.8/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_1000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_1000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_1000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_4000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_4000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_4000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_8000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_8000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_8000/300_300_300_1
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.8/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.2
+ date
Mon Nov  9 00:59:20 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.2/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_1000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_1000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_1000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_4000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_4000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_4000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_8000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_8000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_8000/300_300_300_1
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.2/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.6
+ date
Mon Nov  9 00:59:20 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.6/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_1000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_1000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_1000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_4000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_4000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_4000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_8000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_8000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_8000/300_300_300_1
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.6/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2
+ date
Mon Nov  9 00:59:20 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_1000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_1000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_1000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_4000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_4000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_4000/300_300_300_1
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_8000/300_300_300_1 ']'
+ echo 'Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_8000/300_300_300_1'
Already computed model for /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_8000/300_300_300_1
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4
+ date
Mon Nov  9 00:59:20 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_1000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_1000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59ec117ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59ec16d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59ec180d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59ec180378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59ec0c0bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59ec0c0b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59e3a6e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59ec060400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f595f5ae048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f595f564a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f595f596bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f595f594268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f595f4d9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f595f4e7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f595f4a8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f595f4c79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f593842b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f595f4a8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59383e5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59383e5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59383ab400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5938352488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5938352ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f593832c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f593832c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59382d28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f593833dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5938241048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5938241620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59382641e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f593825f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5938222840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f593822d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f593822db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5938191a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59381a9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6.91570749e-05
Iter: 2 loss: 0.00526476605
Iter: 3 loss: 5.02729454e-05
Iter: 4 loss: 4.05023675e-05
Iter: 5 loss: 3.47048554e-05
Iter: 6 loss: 3.06581933e-05
Iter: 7 loss: 2.17638208e-05
Iter: 8 loss: 8.31459474e-05
Iter: 9 loss: 2.09188074e-05
Iter: 10 loss: 1.86849211e-05
Iter: 11 loss: 1.79052204e-05
Iter: 12 loss: 1.66423488e-05
Iter: 13 loss: 1.35310474e-05
Iter: 14 loss: 1.92916523e-05
Iter: 15 loss: 1.21955018e-05
Iter: 16 loss: 1.0773696e-05
Iter: 17 loss: 1.34363672e-05
Iter: 18 loss: 1.01693277e-05
Iter: 19 loss: 8.96199163e-06
Iter: 20 loss: 1.16026804e-05
Iter: 21 loss: 8.49727621e-06
Iter: 22 loss: 7.85000066e-06
Iter: 23 loss: 8.65767561e-06
Iter: 24 loss: 7.51459265e-06
Iter: 25 loss: 7.06311903e-06
Iter: 26 loss: 6.28561338e-06
Iter: 27 loss: 6.28426415e-06
Iter: 28 loss: 5.70963539e-06
Iter: 29 loss: 1.03089124e-05
Iter: 30 loss: 5.67233747e-06
Iter: 31 loss: 5.34806532e-06
Iter: 32 loss: 6.61514468e-06
Iter: 33 loss: 5.27318207e-06
Iter: 34 loss: 5.02537569e-06
Iter: 35 loss: 5.76650564e-06
Iter: 36 loss: 4.94994811e-06
Iter: 37 loss: 4.73576347e-06
Iter: 38 loss: 4.81039797e-06
Iter: 39 loss: 4.58483828e-06
Iter: 40 loss: 4.34900039e-06
Iter: 41 loss: 4.75931438e-06
Iter: 42 loss: 4.24497057e-06
Iter: 43 loss: 4.32465231e-06
Iter: 44 loss: 4.13742237e-06
Iter: 45 loss: 4.09135464e-06
Iter: 46 loss: 4.00129738e-06
Iter: 47 loss: 5.8153928e-06
Iter: 48 loss: 4.00029603e-06
Iter: 49 loss: 3.8993112e-06
Iter: 50 loss: 5.37464848e-06
Iter: 51 loss: 3.89951219e-06
Iter: 52 loss: 3.84684199e-06
Iter: 53 loss: 3.80192205e-06
Iter: 54 loss: 3.78701316e-06
Iter: 55 loss: 3.73704893e-06
Iter: 56 loss: 4.21138748e-06
Iter: 57 loss: 3.73494572e-06
Iter: 58 loss: 3.66716063e-06
Iter: 59 loss: 3.57131466e-06
Iter: 60 loss: 3.56717419e-06
Iter: 61 loss: 3.4967502e-06
Iter: 62 loss: 3.7808511e-06
Iter: 63 loss: 3.48051231e-06
Iter: 64 loss: 3.42443627e-06
Iter: 65 loss: 3.39626854e-06
Iter: 66 loss: 3.36958396e-06
Iter: 67 loss: 3.28194938e-06
Iter: 68 loss: 3.75041714e-06
Iter: 69 loss: 3.26845384e-06
Iter: 70 loss: 3.19980245e-06
Iter: 71 loss: 3.40834231e-06
Iter: 72 loss: 3.17922604e-06
Iter: 73 loss: 3.1152872e-06
Iter: 74 loss: 3.39907911e-06
Iter: 75 loss: 3.10275482e-06
Iter: 76 loss: 3.05823914e-06
Iter: 77 loss: 3.22306119e-06
Iter: 78 loss: 3.04756918e-06
Iter: 79 loss: 3.01240129e-06
Iter: 80 loss: 3.01237628e-06
Iter: 81 loss: 2.99480848e-06
Iter: 82 loss: 2.97333372e-06
Iter: 83 loss: 2.97091401e-06
Iter: 84 loss: 2.92317827e-06
Iter: 85 loss: 3.00092552e-06
Iter: 86 loss: 2.90196431e-06
Iter: 87 loss: 2.87572925e-06
Iter: 88 loss: 2.82367137e-06
Iter: 89 loss: 3.83490351e-06
Iter: 90 loss: 2.82312567e-06
Iter: 91 loss: 2.85483111e-06
Iter: 92 loss: 2.80038012e-06
Iter: 93 loss: 2.78940843e-06
Iter: 94 loss: 2.76239643e-06
Iter: 95 loss: 3.0035585e-06
Iter: 96 loss: 2.75804268e-06
Iter: 97 loss: 2.7223582e-06
Iter: 98 loss: 2.80485347e-06
Iter: 99 loss: 2.70951227e-06
Iter: 100 loss: 2.67308951e-06
Iter: 101 loss: 2.84686485e-06
Iter: 102 loss: 2.66645293e-06
Iter: 103 loss: 2.6331611e-06
Iter: 104 loss: 2.66259872e-06
Iter: 105 loss: 2.61330024e-06
Iter: 106 loss: 2.58646014e-06
Iter: 107 loss: 2.58622413e-06
Iter: 108 loss: 2.57110287e-06
Iter: 109 loss: 2.58189425e-06
Iter: 110 loss: 2.56145245e-06
Iter: 111 loss: 2.54664178e-06
Iter: 112 loss: 2.54654151e-06
Iter: 113 loss: 2.5353022e-06
Iter: 114 loss: 2.52038876e-06
Iter: 115 loss: 2.51956385e-06
Iter: 116 loss: 2.50443122e-06
Iter: 117 loss: 2.72123134e-06
Iter: 118 loss: 2.50468634e-06
Iter: 119 loss: 2.49551044e-06
Iter: 120 loss: 2.46935861e-06
Iter: 121 loss: 2.58662976e-06
Iter: 122 loss: 2.45986757e-06
Iter: 123 loss: 2.45468937e-06
Iter: 124 loss: 2.44217654e-06
Iter: 125 loss: 2.43177942e-06
Iter: 126 loss: 2.42167243e-06
Iter: 127 loss: 2.41947782e-06
Iter: 128 loss: 2.39898418e-06
Iter: 129 loss: 2.38388543e-06
Iter: 130 loss: 2.37660356e-06
Iter: 131 loss: 2.34839194e-06
Iter: 132 loss: 2.52630866e-06
Iter: 133 loss: 2.34548793e-06
Iter: 134 loss: 2.32904267e-06
Iter: 135 loss: 2.4501087e-06
Iter: 136 loss: 2.3278003e-06
Iter: 137 loss: 2.31720674e-06
Iter: 138 loss: 2.2993313e-06
Iter: 139 loss: 2.29945408e-06
Iter: 140 loss: 2.28038e-06
Iter: 141 loss: 2.451721e-06
Iter: 142 loss: 2.2793788e-06
Iter: 143 loss: 2.26713337e-06
Iter: 144 loss: 2.2686595e-06
Iter: 145 loss: 2.25772374e-06
Iter: 146 loss: 2.24848327e-06
Iter: 147 loss: 2.24773066e-06
Iter: 148 loss: 2.24154155e-06
Iter: 149 loss: 2.23981442e-06
Iter: 150 loss: 2.235804e-06
Iter: 151 loss: 2.22218955e-06
Iter: 152 loss: 2.21654273e-06
Iter: 153 loss: 2.20888569e-06
Iter: 154 loss: 2.19918843e-06
Iter: 155 loss: 2.24860696e-06
Iter: 156 loss: 2.19722983e-06
Iter: 157 loss: 2.1866108e-06
Iter: 158 loss: 2.26982706e-06
Iter: 159 loss: 2.18569949e-06
Iter: 160 loss: 2.17775414e-06
Iter: 161 loss: 2.1577082e-06
Iter: 162 loss: 2.37944732e-06
Iter: 163 loss: 2.15577097e-06
Iter: 164 loss: 2.13822341e-06
Iter: 165 loss: 2.24090832e-06
Iter: 166 loss: 2.13582553e-06
Iter: 167 loss: 2.12194664e-06
Iter: 168 loss: 2.14706688e-06
Iter: 169 loss: 2.11611678e-06
Iter: 170 loss: 2.1047756e-06
Iter: 171 loss: 2.15167165e-06
Iter: 172 loss: 2.10228677e-06
Iter: 173 loss: 2.09004043e-06
Iter: 174 loss: 2.16605122e-06
Iter: 175 loss: 2.08853294e-06
Iter: 176 loss: 2.0809739e-06
Iter: 177 loss: 2.10345593e-06
Iter: 178 loss: 2.0785219e-06
Iter: 179 loss: 2.0712896e-06
Iter: 180 loss: 2.06772665e-06
Iter: 181 loss: 2.06400955e-06
Iter: 182 loss: 2.05259926e-06
Iter: 183 loss: 2.19683466e-06
Iter: 184 loss: 2.05252354e-06
Iter: 185 loss: 2.04547814e-06
Iter: 186 loss: 2.05585366e-06
Iter: 187 loss: 2.0419734e-06
Iter: 188 loss: 2.0341256e-06
Iter: 189 loss: 2.06151981e-06
Iter: 190 loss: 2.03199079e-06
Iter: 191 loss: 2.02655247e-06
Iter: 192 loss: 2.03088348e-06
Iter: 193 loss: 2.02336355e-06
Iter: 194 loss: 2.01341072e-06
Iter: 195 loss: 2.02919387e-06
Iter: 196 loss: 2.00859245e-06
Iter: 197 loss: 2.00148224e-06
Iter: 198 loss: 1.98753355e-06
Iter: 199 loss: 2.27534e-06
Iter: 200 loss: 1.98736097e-06
Iter: 201 loss: 1.97469512e-06
Iter: 202 loss: 1.97478221e-06
Iter: 203 loss: 1.96769406e-06
Iter: 204 loss: 1.96564315e-06
Iter: 205 loss: 1.9615627e-06
Iter: 206 loss: 1.95124539e-06
Iter: 207 loss: 2.0022369e-06
Iter: 208 loss: 1.9495551e-06
Iter: 209 loss: 1.94054974e-06
Iter: 210 loss: 1.94042036e-06
Iter: 211 loss: 1.93606706e-06
Iter: 212 loss: 1.93037704e-06
Iter: 213 loss: 1.93007145e-06
Iter: 214 loss: 1.92341167e-06
Iter: 215 loss: 1.99803026e-06
Iter: 216 loss: 1.92345988e-06
Iter: 217 loss: 1.91617528e-06
Iter: 218 loss: 1.92127163e-06
Iter: 219 loss: 1.91183403e-06
Iter: 220 loss: 1.90577566e-06
Iter: 221 loss: 1.96254018e-06
Iter: 222 loss: 1.90565049e-06
Iter: 223 loss: 1.90138053e-06
Iter: 224 loss: 1.89878142e-06
Iter: 225 loss: 1.89693742e-06
Iter: 226 loss: 1.89194236e-06
Iter: 227 loss: 1.89166212e-06
Iter: 228 loss: 1.88854676e-06
Iter: 229 loss: 1.88108777e-06
Iter: 230 loss: 2.00128761e-06
Iter: 231 loss: 1.88101865e-06
Iter: 232 loss: 1.87550665e-06
Iter: 233 loss: 1.87800072e-06
Iter: 234 loss: 1.87155058e-06
Iter: 235 loss: 1.86664033e-06
Iter: 236 loss: 1.8665578e-06
Iter: 237 loss: 1.8625027e-06
Iter: 238 loss: 1.8572523e-06
Iter: 239 loss: 1.85691863e-06
Iter: 240 loss: 1.85261592e-06
Iter: 241 loss: 1.85252861e-06
Iter: 242 loss: 1.84853491e-06
Iter: 243 loss: 1.86391537e-06
Iter: 244 loss: 1.84762939e-06
Iter: 245 loss: 1.84429268e-06
Iter: 246 loss: 1.84517023e-06
Iter: 247 loss: 1.84187093e-06
Iter: 248 loss: 1.83789166e-06
Iter: 249 loss: 1.88235504e-06
Iter: 250 loss: 1.83756038e-06
Iter: 251 loss: 1.834621e-06
Iter: 252 loss: 1.83143311e-06
Iter: 253 loss: 1.83083603e-06
Iter: 254 loss: 1.82533529e-06
Iter: 255 loss: 1.86291845e-06
Iter: 256 loss: 1.82486656e-06
Iter: 257 loss: 1.82137899e-06
Iter: 258 loss: 1.83335248e-06
Iter: 259 loss: 1.82035444e-06
Iter: 260 loss: 1.81619282e-06
Iter: 261 loss: 1.8186538e-06
Iter: 262 loss: 1.81326823e-06
Iter: 263 loss: 1.80889469e-06
Iter: 264 loss: 1.79838207e-06
Iter: 265 loss: 1.9261347e-06
Iter: 266 loss: 1.79738413e-06
Iter: 267 loss: 1.78884329e-06
Iter: 268 loss: 1.83181623e-06
Iter: 269 loss: 1.78750656e-06
Iter: 270 loss: 1.78239134e-06
Iter: 271 loss: 1.82711926e-06
Iter: 272 loss: 1.78210553e-06
Iter: 273 loss: 1.7767079e-06
Iter: 274 loss: 1.7841337e-06
Iter: 275 loss: 1.7741387e-06
Iter: 276 loss: 1.76933895e-06
Iter: 277 loss: 1.79005326e-06
Iter: 278 loss: 1.76851972e-06
Iter: 279 loss: 1.76406547e-06
Iter: 280 loss: 1.82464248e-06
Iter: 281 loss: 1.76422964e-06
Iter: 282 loss: 1.76242452e-06
Iter: 283 loss: 1.76544086e-06
Iter: 284 loss: 1.76138246e-06
Iter: 285 loss: 1.75862135e-06
Iter: 286 loss: 1.75561365e-06
Iter: 287 loss: 1.75508e-06
Iter: 288 loss: 1.75099274e-06
Iter: 289 loss: 1.80479242e-06
Iter: 290 loss: 1.75085972e-06
Iter: 291 loss: 1.74864613e-06
Iter: 292 loss: 1.75176751e-06
Iter: 293 loss: 1.74754109e-06
Iter: 294 loss: 1.74456022e-06
Iter: 295 loss: 1.76143692e-06
Iter: 296 loss: 1.74412241e-06
Iter: 297 loss: 1.74214347e-06
Iter: 298 loss: 1.73693661e-06
Iter: 299 loss: 1.78633979e-06
Iter: 300 loss: 1.7363775e-06
Iter: 301 loss: 1.73133435e-06
Iter: 302 loss: 1.75061132e-06
Iter: 303 loss: 1.73046624e-06
Iter: 304 loss: 1.72625596e-06
Iter: 305 loss: 1.73913054e-06
Iter: 306 loss: 1.72491673e-06
Iter: 307 loss: 1.72104865e-06
Iter: 308 loss: 1.72696059e-06
Iter: 309 loss: 1.71878503e-06
Iter: 310 loss: 1.71560623e-06
Iter: 311 loss: 1.73589478e-06
Iter: 312 loss: 1.71513182e-06
Iter: 313 loss: 1.71290412e-06
Iter: 314 loss: 1.72776231e-06
Iter: 315 loss: 1.71264696e-06
Iter: 316 loss: 1.71018746e-06
Iter: 317 loss: 1.71381112e-06
Iter: 318 loss: 1.70864269e-06
Iter: 319 loss: 1.70573139e-06
Iter: 320 loss: 1.72094826e-06
Iter: 321 loss: 1.70555086e-06
Iter: 322 loss: 1.70329713e-06
Iter: 323 loss: 1.70461249e-06
Iter: 324 loss: 1.70177827e-06
Iter: 325 loss: 1.69878899e-06
Iter: 326 loss: 1.71310353e-06
Iter: 327 loss: 1.69840519e-06
Iter: 328 loss: 1.69639611e-06
Iter: 329 loss: 1.70651106e-06
Iter: 330 loss: 1.69621103e-06
Iter: 331 loss: 1.69417535e-06
Iter: 332 loss: 1.68865006e-06
Iter: 333 loss: 1.73731223e-06
Iter: 334 loss: 1.68797828e-06
Iter: 335 loss: 1.68367671e-06
Iter: 336 loss: 1.69808197e-06
Iter: 337 loss: 1.68257509e-06
Iter: 338 loss: 1.67926555e-06
Iter: 339 loss: 1.7007942e-06
Iter: 340 loss: 1.67887674e-06
Iter: 341 loss: 1.67619305e-06
Iter: 342 loss: 1.68405109e-06
Iter: 343 loss: 1.67532403e-06
Iter: 344 loss: 1.67237204e-06
Iter: 345 loss: 1.67831513e-06
Iter: 346 loss: 1.67133e-06
Iter: 347 loss: 1.6687552e-06
Iter: 348 loss: 1.67860856e-06
Iter: 349 loss: 1.66816221e-06
Iter: 350 loss: 1.66585096e-06
Iter: 351 loss: 1.69662701e-06
Iter: 352 loss: 1.66578866e-06
Iter: 353 loss: 1.6640488e-06
Iter: 354 loss: 1.66409654e-06
Iter: 355 loss: 1.66280176e-06
Iter: 356 loss: 1.65984693e-06
Iter: 357 loss: 1.66188806e-06
Iter: 358 loss: 1.65798144e-06
Iter: 359 loss: 1.65511881e-06
Iter: 360 loss: 1.69630778e-06
Iter: 361 loss: 1.65523852e-06
Iter: 362 loss: 1.65381311e-06
Iter: 363 loss: 1.65631491e-06
Iter: 364 loss: 1.65316033e-06
Iter: 365 loss: 1.65103916e-06
Iter: 366 loss: 1.64962603e-06
Iter: 367 loss: 1.64870789e-06
Iter: 368 loss: 1.64620542e-06
Iter: 369 loss: 1.64366702e-06
Iter: 370 loss: 1.64283097e-06
Iter: 371 loss: 1.63965206e-06
Iter: 372 loss: 1.65460142e-06
Iter: 373 loss: 1.6390627e-06
Iter: 374 loss: 1.6353157e-06
Iter: 375 loss: 1.65187112e-06
Iter: 376 loss: 1.63458833e-06
Iter: 377 loss: 1.63169352e-06
Iter: 378 loss: 1.64694279e-06
Iter: 379 loss: 1.63138429e-06
Iter: 380 loss: 1.62889273e-06
Iter: 381 loss: 1.63897573e-06
Iter: 382 loss: 1.62812614e-06
Iter: 383 loss: 1.62655442e-06
Iter: 384 loss: 1.64396943e-06
Iter: 385 loss: 1.6267569e-06
Iter: 386 loss: 1.62506251e-06
Iter: 387 loss: 1.62544723e-06
Iter: 388 loss: 1.62402921e-06
Iter: 389 loss: 1.62171352e-06
Iter: 390 loss: 1.62450351e-06
Iter: 391 loss: 1.62058109e-06
Iter: 392 loss: 1.61876267e-06
Iter: 393 loss: 1.63771756e-06
Iter: 394 loss: 1.6188477e-06
Iter: 395 loss: 1.61730327e-06
Iter: 396 loss: 1.61887056e-06
Iter: 397 loss: 1.61645801e-06
Iter: 398 loss: 1.61468449e-06
Iter: 399 loss: 1.61778985e-06
Iter: 400 loss: 1.61373509e-06
Iter: 401 loss: 1.61219828e-06
Iter: 402 loss: 1.61045864e-06
Iter: 403 loss: 1.61040145e-06
Iter: 404 loss: 1.6074323e-06
Iter: 405 loss: 1.60684e-06
Iter: 406 loss: 1.60505169e-06
Iter: 407 loss: 1.60173306e-06
Iter: 408 loss: 1.60208731e-06
Iter: 409 loss: 1.59973581e-06
Iter: 410 loss: 1.609072e-06
Iter: 411 loss: 1.59940396e-06
Iter: 412 loss: 1.5975894e-06
Iter: 413 loss: 1.60178581e-06
Iter: 414 loss: 1.59678166e-06
Iter: 415 loss: 1.59485285e-06
Iter: 416 loss: 1.61021103e-06
Iter: 417 loss: 1.59483943e-06
Iter: 418 loss: 1.59334456e-06
Iter: 419 loss: 1.59514366e-06
Iter: 420 loss: 1.59258263e-06
Iter: 421 loss: 1.59094395e-06
Iter: 422 loss: 1.59455988e-06
Iter: 423 loss: 1.59053184e-06
Iter: 424 loss: 1.58902299e-06
Iter: 425 loss: 1.5944554e-06
Iter: 426 loss: 1.5888312e-06
Iter: 427 loss: 1.58689102e-06
Iter: 428 loss: 1.58860689e-06
Iter: 429 loss: 1.58609214e-06
Iter: 430 loss: 1.5844048e-06
Iter: 431 loss: 1.59527e-06
Iter: 432 loss: 1.58434148e-06
Iter: 433 loss: 1.58302691e-06
Iter: 434 loss: 1.58080252e-06
Iter: 435 loss: 1.61864978e-06
Iter: 436 loss: 1.58086914e-06
Iter: 437 loss: 1.57802185e-06
Iter: 438 loss: 1.57961722e-06
Iter: 439 loss: 1.57618274e-06
Iter: 440 loss: 1.57331465e-06
Iter: 441 loss: 1.61387311e-06
Iter: 442 loss: 1.57338286e-06
Iter: 443 loss: 1.57108934e-06
Iter: 444 loss: 1.58172975e-06
Iter: 445 loss: 1.57102534e-06
Iter: 446 loss: 1.56947021e-06
Iter: 447 loss: 1.57857721e-06
Iter: 448 loss: 1.56934652e-06
Iter: 449 loss: 1.56793794e-06
Iter: 450 loss: 1.57328918e-06
Iter: 451 loss: 1.56766612e-06
Iter: 452 loss: 1.56632814e-06
Iter: 453 loss: 1.56906958e-06
Iter: 454 loss: 1.56579642e-06
Iter: 455 loss: 1.56470651e-06
Iter: 456 loss: 1.56675492e-06
Iter: 457 loss: 1.56407873e-06
Iter: 458 loss: 1.56274973e-06
Iter: 459 loss: 1.56589408e-06
Iter: 460 loss: 1.56233864e-06
Iter: 461 loss: 1.56084025e-06
Iter: 462 loss: 1.56672809e-06
Iter: 463 loss: 1.56051203e-06
Iter: 464 loss: 1.55924556e-06
Iter: 465 loss: 1.56511715e-06
Iter: 466 loss: 1.55916e-06
Iter: 467 loss: 1.55825808e-06
Iter: 468 loss: 1.5560729e-06
Iter: 469 loss: 1.58224771e-06
Iter: 470 loss: 1.55580267e-06
Iter: 471 loss: 1.55369707e-06
Iter: 472 loss: 1.55597286e-06
Iter: 473 loss: 1.55217e-06
Iter: 474 loss: 1.54992381e-06
Iter: 475 loss: 1.56087037e-06
Iter: 476 loss: 1.54971292e-06
Iter: 477 loss: 1.54743657e-06
Iter: 478 loss: 1.56297278e-06
Iter: 479 loss: 1.54749273e-06
Iter: 480 loss: 1.54592919e-06
Iter: 481 loss: 1.54786107e-06
Iter: 482 loss: 1.54506756e-06
Iter: 483 loss: 1.54376687e-06
Iter: 484 loss: 1.55605358e-06
Iter: 485 loss: 1.54351847e-06
Iter: 486 loss: 1.54248755e-06
Iter: 487 loss: 1.54663053e-06
Iter: 488 loss: 1.54221789e-06
Iter: 489 loss: 1.54098404e-06
Iter: 490 loss: 1.54180282e-06
Iter: 491 loss: 1.54041822e-06
Iter: 492 loss: 1.53863732e-06
Iter: 493 loss: 1.54279314e-06
Iter: 494 loss: 1.53843575e-06
Iter: 495 loss: 1.53690871e-06
Iter: 496 loss: 1.54828058e-06
Iter: 497 loss: 1.53678502e-06
Iter: 498 loss: 1.53588962e-06
Iter: 499 loss: 1.5375789e-06
Iter: 500 loss: 1.53547376e-06
Iter: 501 loss: 1.5341717e-06
Iter: 502 loss: 1.53197948e-06
Iter: 503 loss: 1.53200085e-06
Iter: 504 loss: 1.52979771e-06
Iter: 505 loss: 1.5327654e-06
Iter: 506 loss: 1.52862799e-06
Iter: 507 loss: 1.52672214e-06
Iter: 508 loss: 1.53219821e-06
Iter: 509 loss: 1.52604662e-06
Iter: 510 loss: 1.52433711e-06
Iter: 511 loss: 1.54180032e-06
Iter: 512 loss: 1.52429789e-06
Iter: 513 loss: 1.52289124e-06
Iter: 514 loss: 1.52648852e-06
Iter: 515 loss: 1.52236873e-06
Iter: 516 loss: 1.52108396e-06
Iter: 517 loss: 1.52679945e-06
Iter: 518 loss: 1.5205926e-06
Iter: 519 loss: 1.51891402e-06
Iter: 520 loss: 1.52293558e-06
Iter: 521 loss: 1.5185484e-06
Iter: 522 loss: 1.51702625e-06
Iter: 523 loss: 1.5195119e-06
Iter: 524 loss: 1.51637278e-06
Iter: 525 loss: 1.51487188e-06
Iter: 526 loss: 1.51873269e-06
Iter: 527 loss: 1.51445852e-06
Iter: 528 loss: 1.51310132e-06
Iter: 529 loss: 1.52266011e-06
Iter: 530 loss: 1.51280756e-06
Iter: 531 loss: 1.51176891e-06
Iter: 532 loss: 1.51131621e-06
Iter: 533 loss: 1.51064182e-06
Iter: 534 loss: 1.50844505e-06
Iter: 535 loss: 1.51388008e-06
Iter: 536 loss: 1.50789811e-06
Iter: 537 loss: 1.50657604e-06
Iter: 538 loss: 1.5054593e-06
Iter: 539 loss: 1.50530354e-06
Iter: 540 loss: 1.50317908e-06
Iter: 541 loss: 1.50782557e-06
Iter: 542 loss: 1.50246649e-06
Iter: 543 loss: 1.500346e-06
Iter: 544 loss: 1.51086158e-06
Iter: 545 loss: 1.49998687e-06
Iter: 546 loss: 1.49814366e-06
Iter: 547 loss: 1.51182007e-06
Iter: 548 loss: 1.4979646e-06
Iter: 549 loss: 1.49677885e-06
Iter: 550 loss: 1.50151186e-06
Iter: 551 loss: 1.49646144e-06
Iter: 552 loss: 1.49527909e-06
Iter: 553 loss: 1.49886705e-06
Iter: 554 loss: 1.4949253e-06
Iter: 555 loss: 1.49418304e-06
Iter: 556 loss: 1.4957991e-06
Iter: 557 loss: 1.49374955e-06
Iter: 558 loss: 1.49280561e-06
Iter: 559 loss: 1.49442644e-06
Iter: 560 loss: 1.49218363e-06
Iter: 561 loss: 1.4911617e-06
Iter: 562 loss: 1.49304833e-06
Iter: 563 loss: 1.49084326e-06
Iter: 564 loss: 1.48914989e-06
Iter: 565 loss: 1.49470532e-06
Iter: 566 loss: 1.48886443e-06
Iter: 567 loss: 1.48763047e-06
Iter: 568 loss: 1.49395123e-06
Iter: 569 loss: 1.48731169e-06
Iter: 570 loss: 1.48664651e-06
Iter: 571 loss: 1.48494155e-06
Iter: 572 loss: 1.50865742e-06
Iter: 573 loss: 1.48498475e-06
Iter: 574 loss: 1.48336369e-06
Iter: 575 loss: 1.48615345e-06
Iter: 576 loss: 1.48281629e-06
Iter: 577 loss: 1.48094796e-06
Iter: 578 loss: 1.48688287e-06
Iter: 579 loss: 1.48066067e-06
Iter: 580 loss: 1.47934099e-06
Iter: 581 loss: 1.49577227e-06
Iter: 582 loss: 1.47929393e-06
Iter: 583 loss: 1.47847868e-06
Iter: 584 loss: 1.47969956e-06
Iter: 585 loss: 1.47818355e-06
Iter: 586 loss: 1.47721744e-06
Iter: 587 loss: 1.48492222e-06
Iter: 588 loss: 1.47720505e-06
Iter: 589 loss: 1.47646267e-06
Iter: 590 loss: 1.47680589e-06
Iter: 591 loss: 1.47585286e-06
Iter: 592 loss: 1.47501373e-06
Iter: 593 loss: 1.47748915e-06
Iter: 594 loss: 1.4747252e-06
Iter: 595 loss: 1.47371259e-06
Iter: 596 loss: 1.47438925e-06
Iter: 597 loss: 1.47299534e-06
Iter: 598 loss: 1.4720315e-06
Iter: 599 loss: 1.47645653e-06
Iter: 600 loss: 1.4715298e-06
Iter: 601 loss: 1.47065521e-06
Iter: 602 loss: 1.47541368e-06
Iter: 603 loss: 1.47043943e-06
Iter: 604 loss: 1.4698079e-06
Iter: 605 loss: 1.46877869e-06
Iter: 606 loss: 1.4686575e-06
Iter: 607 loss: 1.46764137e-06
Iter: 608 loss: 1.46810908e-06
Iter: 609 loss: 1.46710136e-06
Iter: 610 loss: 1.4657785e-06
Iter: 611 loss: 1.4688859e-06
Iter: 612 loss: 1.46534614e-06
Iter: 613 loss: 1.46434058e-06
Iter: 614 loss: 1.47500339e-06
Iter: 615 loss: 1.46426521e-06
Iter: 616 loss: 1.46351738e-06
Iter: 617 loss: 1.46583602e-06
Iter: 618 loss: 1.46324271e-06
Iter: 619 loss: 1.46262596e-06
Iter: 620 loss: 1.46593493e-06
Iter: 621 loss: 1.46234993e-06
Iter: 622 loss: 1.4615066e-06
Iter: 623 loss: 1.46337834e-06
Iter: 624 loss: 1.46122966e-06
Iter: 625 loss: 1.46069578e-06
Iter: 626 loss: 1.46276011e-06
Iter: 627 loss: 1.46023888e-06
Iter: 628 loss: 1.45972467e-06
Iter: 629 loss: 1.4604534e-06
Iter: 630 loss: 1.45927788e-06
Iter: 631 loss: 1.4587373e-06
Iter: 632 loss: 1.46537263e-06
Iter: 633 loss: 1.45881336e-06
Iter: 634 loss: 1.45833872e-06
Iter: 635 loss: 1.4581e-06
Iter: 636 loss: 1.45788113e-06
Iter: 637 loss: 1.4570461e-06
Iter: 638 loss: 1.4569514e-06
Iter: 639 loss: 1.45632384e-06
Iter: 640 loss: 1.45512627e-06
Iter: 641 loss: 1.45550359e-06
Iter: 642 loss: 1.45440754e-06
Iter: 643 loss: 1.45332922e-06
Iter: 644 loss: 1.45699869e-06
Iter: 645 loss: 1.45309718e-06
Iter: 646 loss: 1.45185925e-06
Iter: 647 loss: 1.4536862e-06
Iter: 648 loss: 1.45129377e-06
Iter: 649 loss: 1.45069976e-06
Iter: 650 loss: 1.45044464e-06
Iter: 651 loss: 1.45000922e-06
Iter: 652 loss: 1.45097192e-06
Iter: 653 loss: 1.44970977e-06
Iter: 654 loss: 1.44925764e-06
Iter: 655 loss: 1.44955789e-06
Iter: 656 loss: 1.44874025e-06
Iter: 657 loss: 1.44802414e-06
Iter: 658 loss: 1.45047318e-06
Iter: 659 loss: 1.44782973e-06
Iter: 660 loss: 1.44737032e-06
Iter: 661 loss: 1.45084027e-06
Iter: 662 loss: 1.44713863e-06
Iter: 663 loss: 1.44669207e-06
Iter: 664 loss: 1.44730518e-06
Iter: 665 loss: 1.44659543e-06
Iter: 666 loss: 1.44599437e-06
Iter: 667 loss: 1.44606645e-06
Iter: 668 loss: 1.44548108e-06
Iter: 669 loss: 1.44475177e-06
Iter: 670 loss: 1.44913247e-06
Iter: 671 loss: 1.44468731e-06
Iter: 672 loss: 1.4439596e-06
Iter: 673 loss: 1.44344222e-06
Iter: 674 loss: 1.4433175e-06
Iter: 675 loss: 1.44231649e-06
Iter: 676 loss: 1.44402793e-06
Iter: 677 loss: 1.44197327e-06
Iter: 678 loss: 1.44089188e-06
Iter: 679 loss: 1.44250873e-06
Iter: 680 loss: 1.44036301e-06
Iter: 681 loss: 1.43906209e-06
Iter: 682 loss: 1.44792887e-06
Iter: 683 loss: 1.43893772e-06
Iter: 684 loss: 1.43820716e-06
Iter: 685 loss: 1.43821455e-06
Iter: 686 loss: 1.43754164e-06
Iter: 687 loss: 1.43689056e-06
Iter: 688 loss: 1.43680666e-06
Iter: 689 loss: 1.43571174e-06
Iter: 690 loss: 1.43843477e-06
Iter: 691 loss: 1.43522755e-06
Iter: 692 loss: 1.43442503e-06
Iter: 693 loss: 1.43665204e-06
Iter: 694 loss: 1.43390423e-06
Iter: 695 loss: 1.43327941e-06
Iter: 696 loss: 1.43950183e-06
Iter: 697 loss: 1.43307011e-06
Iter: 698 loss: 1.43261821e-06
Iter: 699 loss: 1.43211378e-06
Iter: 700 loss: 1.43202317e-06
Iter: 701 loss: 1.43095258e-06
Iter: 702 loss: 1.4354265e-06
Iter: 703 loss: 1.43056718e-06
Iter: 704 loss: 1.42986562e-06
Iter: 705 loss: 1.43181956e-06
Iter: 706 loss: 1.42962347e-06
Iter: 707 loss: 1.4287067e-06
Iter: 708 loss: 1.42789247e-06
Iter: 709 loss: 1.42775366e-06
Iter: 710 loss: 1.42629574e-06
Iter: 711 loss: 1.42843237e-06
Iter: 712 loss: 1.42582383e-06
Iter: 713 loss: 1.42443844e-06
Iter: 714 loss: 1.42997203e-06
Iter: 715 loss: 1.42398699e-06
Iter: 716 loss: 1.42276849e-06
Iter: 717 loss: 1.43823013e-06
Iter: 718 loss: 1.42278668e-06
Iter: 719 loss: 1.42192948e-06
Iter: 720 loss: 1.42957015e-06
Iter: 721 loss: 1.42166664e-06
Iter: 722 loss: 1.421251e-06
Iter: 723 loss: 1.42049407e-06
Iter: 724 loss: 1.42044382e-06
Iter: 725 loss: 1.41911437e-06
Iter: 726 loss: 1.42524345e-06
Iter: 727 loss: 1.41888358e-06
Iter: 728 loss: 1.41783494e-06
Iter: 729 loss: 1.42212934e-06
Iter: 730 loss: 1.41764474e-06
Iter: 731 loss: 1.41663384e-06
Iter: 732 loss: 1.42032479e-06
Iter: 733 loss: 1.41638679e-06
Iter: 734 loss: 1.41596558e-06
Iter: 735 loss: 1.41529392e-06
Iter: 736 loss: 1.41512362e-06
Iter: 737 loss: 1.41384078e-06
Iter: 738 loss: 1.41719079e-06
Iter: 739 loss: 1.41345868e-06
Iter: 740 loss: 1.41230691e-06
Iter: 741 loss: 1.41585133e-06
Iter: 742 loss: 1.41179623e-06
Iter: 743 loss: 1.41085127e-06
Iter: 744 loss: 1.4096986e-06
Iter: 745 loss: 1.40959457e-06
Iter: 746 loss: 1.40788893e-06
Iter: 747 loss: 1.41081841e-06
Iter: 748 loss: 1.40732618e-06
Iter: 749 loss: 1.406004e-06
Iter: 750 loss: 1.41274506e-06
Iter: 751 loss: 1.40578959e-06
Iter: 752 loss: 1.40505654e-06
Iter: 753 loss: 1.40501584e-06
Iter: 754 loss: 1.40410179e-06
Iter: 755 loss: 1.40505358e-06
Iter: 756 loss: 1.40366842e-06
Iter: 757 loss: 1.40308623e-06
Iter: 758 loss: 1.40240741e-06
Iter: 759 loss: 1.40214081e-06
Iter: 760 loss: 1.40113934e-06
Iter: 761 loss: 1.40112957e-06
Iter: 762 loss: 1.40059115e-06
Iter: 763 loss: 1.40110956e-06
Iter: 764 loss: 1.40004727e-06
Iter: 765 loss: 1.39918575e-06
Iter: 766 loss: 1.40589304e-06
Iter: 767 loss: 1.39904751e-06
Iter: 768 loss: 1.39819e-06
Iter: 769 loss: 1.39916051e-06
Iter: 770 loss: 1.39786084e-06
Iter: 771 loss: 1.39681913e-06
Iter: 772 loss: 1.39795543e-06
Iter: 773 loss: 1.39627707e-06
Iter: 774 loss: 1.3952307e-06
Iter: 775 loss: 1.3959135e-06
Iter: 776 loss: 1.39464203e-06
Iter: 777 loss: 1.39360543e-06
Iter: 778 loss: 1.39457688e-06
Iter: 779 loss: 1.39281758e-06
Iter: 780 loss: 1.39145334e-06
Iter: 781 loss: 1.39139649e-06
Iter: 782 loss: 1.39032954e-06
Iter: 783 loss: 1.38858093e-06
Iter: 784 loss: 1.39618612e-06
Iter: 785 loss: 1.38813289e-06
Iter: 786 loss: 1.38801852e-06
Iter: 787 loss: 1.38744167e-06
Iter: 788 loss: 1.38702876e-06
Iter: 789 loss: 1.38606367e-06
Iter: 790 loss: 1.3918293e-06
Iter: 791 loss: 1.38586574e-06
Iter: 792 loss: 1.38486325e-06
Iter: 793 loss: 1.39078838e-06
Iter: 794 loss: 1.38481926e-06
Iter: 795 loss: 1.38390783e-06
Iter: 796 loss: 1.38817404e-06
Iter: 797 loss: 1.38397047e-06
Iter: 798 loss: 1.3830977e-06
Iter: 799 loss: 1.38353676e-06
Iter: 800 loss: 1.38256837e-06
Iter: 801 loss: 1.38164421e-06
Iter: 802 loss: 1.38917073e-06
Iter: 803 loss: 1.3818626e-06
Iter: 804 loss: 1.38121163e-06
Iter: 805 loss: 1.38123471e-06
Iter: 806 loss: 1.38073028e-06
Iter: 807 loss: 1.3801548e-06
Iter: 808 loss: 1.38226596e-06
Iter: 809 loss: 1.37995221e-06
Iter: 810 loss: 1.37936286e-06
Iter: 811 loss: 1.37794916e-06
Iter: 812 loss: 1.39648421e-06
Iter: 813 loss: 1.37790892e-06
Iter: 814 loss: 1.37635027e-06
Iter: 815 loss: 1.3953852e-06
Iter: 816 loss: 1.37637358e-06
Iter: 817 loss: 1.37556674e-06
Iter: 818 loss: 1.37802408e-06
Iter: 819 loss: 1.37516827e-06
Iter: 820 loss: 1.3745057e-06
Iter: 821 loss: 1.38161863e-06
Iter: 822 loss: 1.37451991e-06
Iter: 823 loss: 1.37402685e-06
Iter: 824 loss: 1.37299662e-06
Iter: 825 loss: 1.3857217e-06
Iter: 826 loss: 1.3729649e-06
Iter: 827 loss: 1.37182155e-06
Iter: 828 loss: 1.37468248e-06
Iter: 829 loss: 1.37139261e-06
Iter: 830 loss: 1.37062807e-06
Iter: 831 loss: 1.37186373e-06
Iter: 832 loss: 1.3702363e-06
Iter: 833 loss: 1.36962501e-06
Iter: 834 loss: 1.36899541e-06
Iter: 835 loss: 1.36882829e-06
Iter: 836 loss: 1.36790845e-06
Iter: 837 loss: 1.36701942e-06
Iter: 838 loss: 1.3665574e-06
Iter: 839 loss: 1.36569497e-06
Iter: 840 loss: 1.37564518e-06
Iter: 841 loss: 1.36560811e-06
Iter: 842 loss: 1.36511278e-06
Iter: 843 loss: 1.36571703e-06
Iter: 844 loss: 1.36486324e-06
Iter: 845 loss: 1.36386836e-06
Iter: 846 loss: 1.365402e-06
Iter: 847 loss: 1.36340145e-06
Iter: 848 loss: 1.3624242e-06
Iter: 849 loss: 1.36332926e-06
Iter: 850 loss: 1.36189465e-06
Iter: 851 loss: 1.36068093e-06
Iter: 852 loss: 1.36240419e-06
Iter: 853 loss: 1.36026529e-06
Iter: 854 loss: 1.35937091e-06
Iter: 855 loss: 1.36577523e-06
Iter: 856 loss: 1.35932669e-06
Iter: 857 loss: 1.35827622e-06
Iter: 858 loss: 1.367599e-06
Iter: 859 loss: 1.35825292e-06
Iter: 860 loss: 1.35804692e-06
Iter: 861 loss: 1.35729692e-06
Iter: 862 loss: 1.37203176e-06
Iter: 863 loss: 1.35725588e-06
Iter: 864 loss: 1.35670359e-06
Iter: 865 loss: 1.36286815e-06
Iter: 866 loss: 1.35671598e-06
Iter: 867 loss: 1.35608491e-06
Iter: 868 loss: 1.35651169e-06
Iter: 869 loss: 1.35565176e-06
Iter: 870 loss: 1.35515836e-06
Iter: 871 loss: 1.35676669e-06
Iter: 872 loss: 1.35504433e-06
Iter: 873 loss: 1.35452387e-06
Iter: 874 loss: 1.35556866e-06
Iter: 875 loss: 1.35444236e-06
Iter: 876 loss: 1.35389314e-06
Iter: 877 loss: 1.35386335e-06
Iter: 878 loss: 1.35352275e-06
Iter: 879 loss: 1.35308073e-06
Iter: 880 loss: 1.35527137e-06
Iter: 881 loss: 1.35298569e-06
Iter: 882 loss: 1.35235632e-06
Iter: 883 loss: 1.35324876e-06
Iter: 884 loss: 1.35194887e-06
Iter: 885 loss: 1.3512722e-06
Iter: 886 loss: 1.35301298e-06
Iter: 887 loss: 1.35107416e-06
Iter: 888 loss: 1.35034816e-06
Iter: 889 loss: 1.35139533e-06
Iter: 890 loss: 1.35015659e-06
Iter: 891 loss: 1.35015705e-06
Iter: 892 loss: 1.34997936e-06
Iter: 893 loss: 1.34979632e-06
Iter: 894 loss: 1.34941934e-06
Iter: 895 loss: 1.34943741e-06
Iter: 896 loss: 1.34907168e-06
Iter: 897 loss: 1.34828e-06
Iter: 898 loss: 1.3483176e-06
Iter: 899 loss: 1.34782476e-06
Iter: 900 loss: 1.34778861e-06
Iter: 901 loss: 1.3473126e-06
Iter: 902 loss: 1.34853678e-06
Iter: 903 loss: 1.34716265e-06
Iter: 904 loss: 1.34676191e-06
Iter: 905 loss: 1.34883533e-06
Iter: 906 loss: 1.34671836e-06
Iter: 907 loss: 1.34621803e-06
Iter: 908 loss: 1.3469579e-06
Iter: 909 loss: 1.34607353e-06
Iter: 910 loss: 1.34578227e-06
Iter: 911 loss: 1.34717e-06
Iter: 912 loss: 1.34568211e-06
Iter: 913 loss: 1.34539391e-06
Iter: 914 loss: 1.34584559e-06
Iter: 915 loss: 1.34534844e-06
Iter: 916 loss: 1.34482116e-06
Iter: 917 loss: 1.34518734e-06
Iter: 918 loss: 1.34465165e-06
Iter: 919 loss: 1.34400454e-06
Iter: 920 loss: 1.34573804e-06
Iter: 921 loss: 1.34378013e-06
Iter: 922 loss: 1.34354377e-06
Iter: 923 loss: 1.34461106e-06
Iter: 924 loss: 1.34343054e-06
Iter: 925 loss: 1.34292736e-06
Iter: 926 loss: 1.34587594e-06
Iter: 927 loss: 1.34286961e-06
Iter: 928 loss: 1.3427657e-06
Iter: 929 loss: 1.34202128e-06
Iter: 930 loss: 1.34701406e-06
Iter: 931 loss: 1.34188917e-06
Iter: 932 loss: 1.341553e-06
Iter: 933 loss: 1.34712968e-06
Iter: 934 loss: 1.34154266e-06
Iter: 935 loss: 1.34113975e-06
Iter: 936 loss: 1.34175571e-06
Iter: 937 loss: 1.34107847e-06
Iter: 938 loss: 1.3408536e-06
Iter: 939 loss: 1.3423105e-06
Iter: 940 loss: 1.34078994e-06
Iter: 941 loss: 1.34062554e-06
Iter: 942 loss: 1.34104403e-06
Iter: 943 loss: 1.34046422e-06
Iter: 944 loss: 1.34025208e-06
Iter: 945 loss: 1.34037373e-06
Iter: 946 loss: 1.3400221e-06
Iter: 947 loss: 1.33983576e-06
Iter: 948 loss: 1.3423745e-06
Iter: 949 loss: 1.33960748e-06
Iter: 950 loss: 1.33946082e-06
Iter: 951 loss: 1.3398236e-06
Iter: 952 loss: 1.33933918e-06
Iter: 953 loss: 1.33905473e-06
Iter: 954 loss: 1.33934111e-06
Iter: 955 loss: 1.33887397e-06
Iter: 956 loss: 1.33854132e-06
Iter: 957 loss: 1.34026391e-06
Iter: 958 loss: 1.33840501e-06
Iter: 959 loss: 1.3381532e-06
Iter: 960 loss: 1.34059167e-06
Iter: 961 loss: 1.33825517e-06
Iter: 962 loss: 1.33797016e-06
Iter: 963 loss: 1.33757624e-06
Iter: 964 loss: 1.34278957e-06
Iter: 965 loss: 1.3376897e-06
Iter: 966 loss: 1.33721619e-06
Iter: 967 loss: 1.33839774e-06
Iter: 968 loss: 1.33704759e-06
Iter: 969 loss: 1.33673916e-06
Iter: 970 loss: 1.33973697e-06
Iter: 971 loss: 1.33669187e-06
Iter: 972 loss: 1.33641288e-06
Iter: 973 loss: 1.33703486e-06
Iter: 974 loss: 1.3363217e-06
Iter: 975 loss: 1.33605681e-06
Iter: 976 loss: 1.33655112e-06
Iter: 977 loss: 1.33582728e-06
Iter: 978 loss: 1.33546428e-06
Iter: 979 loss: 1.33532933e-06
Iter: 980 loss: 1.33520632e-06
Iter: 981 loss: 1.33485753e-06
Iter: 982 loss: 1.33822925e-06
Iter: 983 loss: 1.3347767e-06
Iter: 984 loss: 1.33441949e-06
Iter: 985 loss: 1.33551885e-06
Iter: 986 loss: 1.33420258e-06
Iter: 987 loss: 1.33406752e-06
Iter: 988 loss: 1.33445621e-06
Iter: 989 loss: 1.33380661e-06
Iter: 990 loss: 1.33361345e-06
Iter: 991 loss: 1.33500407e-06
Iter: 992 loss: 1.33362289e-06
Iter: 993 loss: 1.33342496e-06
Iter: 994 loss: 1.33356286e-06
Iter: 995 loss: 1.33331287e-06
Iter: 996 loss: 1.33304059e-06
Iter: 997 loss: 1.3394598e-06
Iter: 998 loss: 1.33294941e-06
Iter: 999 loss: 1.3328505e-06
Iter: 1000 loss: 1.33291906e-06
Iter: 1001 loss: 1.3326586e-06
Iter: 1002 loss: 1.33234562e-06
Iter: 1003 loss: 1.33230355e-06
Iter: 1004 loss: 1.33206686e-06
Iter: 1005 loss: 1.33237063e-06
Iter: 1006 loss: 1.3320174e-06
Iter: 1007 loss: 1.33174569e-06
Iter: 1008 loss: 1.33170397e-06
Iter: 1009 loss: 1.33160427e-06
Iter: 1010 loss: 1.33149058e-06
Iter: 1011 loss: 1.33135563e-06
Iter: 1012 loss: 1.33114133e-06
Iter: 1013 loss: 1.33115236e-06
Iter: 1014 loss: 1.33103617e-06
Iter: 1015 loss: 1.33072956e-06
Iter: 1016 loss: 1.33107073e-06
Iter: 1017 loss: 1.33071103e-06
Iter: 1018 loss: 1.33054118e-06
Iter: 1019 loss: 1.33054255e-06
Iter: 1020 loss: 1.33026424e-06
Iter: 1021 loss: 1.32998389e-06
Iter: 1022 loss: 1.32994069e-06
Iter: 1023 loss: 1.32987975e-06
Iter: 1024 loss: 1.32964215e-06
Iter: 1025 loss: 1.33019944e-06
Iter: 1026 loss: 1.32957314e-06
Iter: 1027 loss: 1.32931098e-06
Iter: 1028 loss: 1.32928403e-06
Iter: 1029 loss: 1.32901368e-06
Iter: 1030 loss: 1.32883588e-06
Iter: 1031 loss: 1.32845594e-06
Iter: 1032 loss: 1.3283601e-06
Iter: 1033 loss: 1.32787693e-06
Iter: 1034 loss: 1.33094659e-06
Iter: 1035 loss: 1.32772232e-06
Iter: 1036 loss: 1.32744458e-06
Iter: 1037 loss: 1.32898208e-06
Iter: 1038 loss: 1.32730304e-06
Iter: 1039 loss: 1.32692412e-06
Iter: 1040 loss: 1.32893615e-06
Iter: 1041 loss: 1.32687535e-06
Iter: 1042 loss: 1.32666537e-06
Iter: 1043 loss: 1.3261149e-06
Iter: 1044 loss: 1.3259679e-06
Iter: 1045 loss: 1.32578884e-06
Iter: 1046 loss: 1.32582409e-06
Iter: 1047 loss: 1.32546029e-06
Iter: 1048 loss: 1.32786113e-06
Iter: 1049 loss: 1.32540231e-06
Iter: 1050 loss: 1.32522723e-06
Iter: 1051 loss: 1.32481023e-06
Iter: 1052 loss: 1.33252706e-06
Iter: 1053 loss: 1.32473372e-06
Iter: 1054 loss: 1.32434195e-06
Iter: 1055 loss: 1.32844889e-06
Iter: 1056 loss: 1.32434081e-06
Iter: 1057 loss: 1.32408343e-06
Iter: 1058 loss: 1.32586547e-06
Iter: 1059 loss: 1.32419268e-06
Iter: 1060 loss: 1.32377545e-06
Iter: 1061 loss: 1.32371702e-06
Iter: 1062 loss: 1.32352534e-06
Iter: 1063 loss: 1.32322168e-06
Iter: 1064 loss: 1.32278353e-06
Iter: 1065 loss: 1.32282162e-06
Iter: 1066 loss: 1.32240621e-06
Iter: 1067 loss: 1.32378216e-06
Iter: 1068 loss: 1.32232685e-06
Iter: 1069 loss: 1.32197181e-06
Iter: 1070 loss: 1.32257503e-06
Iter: 1071 loss: 1.32182151e-06
Iter: 1072 loss: 1.32139883e-06
Iter: 1073 loss: 1.32431535e-06
Iter: 1074 loss: 1.32141338e-06
Iter: 1075 loss: 1.32103298e-06
Iter: 1076 loss: 1.32153423e-06
Iter: 1077 loss: 1.32088326e-06
Iter: 1078 loss: 1.32055e-06
Iter: 1079 loss: 1.32057346e-06
Iter: 1080 loss: 1.32029322e-06
Iter: 1081 loss: 1.32004084e-06
Iter: 1082 loss: 1.31997047e-06
Iter: 1083 loss: 1.31982586e-06
Iter: 1084 loss: 1.31953288e-06
Iter: 1085 loss: 1.32267303e-06
Iter: 1086 loss: 1.31938407e-06
Iter: 1087 loss: 1.31908666e-06
Iter: 1088 loss: 1.31969068e-06
Iter: 1089 loss: 1.31878983e-06
Iter: 1090 loss: 1.31826494e-06
Iter: 1091 loss: 1.31927038e-06
Iter: 1092 loss: 1.3181384e-06
Iter: 1093 loss: 1.31783804e-06
Iter: 1094 loss: 1.31777279e-06
Iter: 1095 loss: 1.31755246e-06
Iter: 1096 loss: 1.31762818e-06
Iter: 1097 loss: 1.31747572e-06
Iter: 1098 loss: 1.31701177e-06
Iter: 1099 loss: 1.31640229e-06
Iter: 1100 loss: 1.31644083e-06
Iter: 1101 loss: 1.31571244e-06
Iter: 1102 loss: 1.31971262e-06
Iter: 1103 loss: 1.31573461e-06
Iter: 1104 loss: 1.3153367e-06
Iter: 1105 loss: 1.3198827e-06
Iter: 1106 loss: 1.31529964e-06
Iter: 1107 loss: 1.31508045e-06
Iter: 1108 loss: 1.31552315e-06
Iter: 1109 loss: 1.31482147e-06
Iter: 1110 loss: 1.31445688e-06
Iter: 1111 loss: 1.31632839e-06
Iter: 1112 loss: 1.31439117e-06
Iter: 1113 loss: 1.31419529e-06
Iter: 1114 loss: 1.31589741e-06
Iter: 1115 loss: 1.31409968e-06
Iter: 1116 loss: 1.3136621e-06
Iter: 1117 loss: 1.31383513e-06
Iter: 1118 loss: 1.31351135e-06
Iter: 1119 loss: 1.3131787e-06
Iter: 1120 loss: 1.31300214e-06
Iter: 1121 loss: 1.31289505e-06
Iter: 1122 loss: 1.31225238e-06
Iter: 1123 loss: 1.31414345e-06
Iter: 1124 loss: 1.31201557e-06
Iter: 1125 loss: 1.31170441e-06
Iter: 1126 loss: 1.31154661e-06
Iter: 1127 loss: 1.31121067e-06
Iter: 1128 loss: 1.31113643e-06
Iter: 1129 loss: 1.31086392e-06
Iter: 1130 loss: 1.31035972e-06
Iter: 1131 loss: 1.31051991e-06
Iter: 1132 loss: 1.30988508e-06
Iter: 1133 loss: 1.30943658e-06
Iter: 1134 loss: 1.30926867e-06
Iter: 1135 loss: 1.30888736e-06
Iter: 1136 loss: 1.30833553e-06
Iter: 1137 loss: 1.30837952e-06
Iter: 1138 loss: 1.30801254e-06
Iter: 1139 loss: 1.30874446e-06
Iter: 1140 loss: 1.3079175e-06
Iter: 1141 loss: 1.30728461e-06
Iter: 1142 loss: 1.30862645e-06
Iter: 1143 loss: 1.30721696e-06
Iter: 1144 loss: 1.30687022e-06
Iter: 1145 loss: 1.30994238e-06
Iter: 1146 loss: 1.30672072e-06
Iter: 1147 loss: 1.30648505e-06
Iter: 1148 loss: 1.30666729e-06
Iter: 1149 loss: 1.30624028e-06
Iter: 1150 loss: 1.30595413e-06
Iter: 1151 loss: 1.30516298e-06
Iter: 1152 loss: 1.31749732e-06
Iter: 1153 loss: 1.30504588e-06
Iter: 1154 loss: 1.30454032e-06
Iter: 1155 loss: 1.31300385e-06
Iter: 1156 loss: 1.30462456e-06
Iter: 1157 loss: 1.30421836e-06
Iter: 1158 loss: 1.30557851e-06
Iter: 1159 loss: 1.30412275e-06
Iter: 1160 loss: 1.30361639e-06
Iter: 1161 loss: 1.30692479e-06
Iter: 1162 loss: 1.30361354e-06
Iter: 1163 loss: 1.30329181e-06
Iter: 1164 loss: 1.30334774e-06
Iter: 1165 loss: 1.30302669e-06
Iter: 1166 loss: 1.30260639e-06
Iter: 1167 loss: 1.30235912e-06
Iter: 1168 loss: 1.30219939e-06
Iter: 1169 loss: 1.30176807e-06
Iter: 1170 loss: 1.30592468e-06
Iter: 1171 loss: 1.30175488e-06
Iter: 1172 loss: 1.30126e-06
Iter: 1173 loss: 1.3038208e-06
Iter: 1174 loss: 1.30109254e-06
Iter: 1175 loss: 1.30066917e-06
Iter: 1176 loss: 1.30269814e-06
Iter: 1177 loss: 1.30073727e-06
Iter: 1178 loss: 1.30034391e-06
Iter: 1179 loss: 1.30066678e-06
Iter: 1180 loss: 1.30001672e-06
Iter: 1181 loss: 1.29968248e-06
Iter: 1182 loss: 1.30044646e-06
Iter: 1183 loss: 1.29927469e-06
Iter: 1184 loss: 1.29897137e-06
Iter: 1185 loss: 1.29841487e-06
Iter: 1186 loss: 1.298283e-06
Iter: 1187 loss: 1.29782075e-06
Iter: 1188 loss: 1.30014905e-06
Iter: 1189 loss: 1.29756211e-06
Iter: 1190 loss: 1.29690648e-06
Iter: 1191 loss: 1.30054059e-06
Iter: 1192 loss: 1.29679188e-06
Iter: 1193 loss: 1.29628336e-06
Iter: 1194 loss: 1.30033834e-06
Iter: 1195 loss: 1.29619787e-06
Iter: 1196 loss: 1.2957247e-06
Iter: 1197 loss: 1.29472812e-06
Iter: 1198 loss: 1.31427691e-06
Iter: 1199 loss: 1.29473688e-06
Iter: 1200 loss: 1.29380669e-06
Iter: 1201 loss: 1.30123033e-06
Iter: 1202 loss: 1.29376099e-06
Iter: 1203 loss: 1.2933366e-06
Iter: 1204 loss: 1.29259331e-06
Iter: 1205 loss: 1.29257114e-06
Iter: 1206 loss: 1.2919852e-06
Iter: 1207 loss: 1.29200532e-06
Iter: 1208 loss: 1.29152681e-06
Iter: 1209 loss: 1.2916388e-06
Iter: 1210 loss: 1.29098225e-06
Iter: 1211 loss: 1.29037812e-06
Iter: 1212 loss: 1.29454941e-06
Iter: 1213 loss: 1.2903954e-06
Iter: 1214 loss: 1.28999841e-06
Iter: 1215 loss: 1.28960289e-06
Iter: 1216 loss: 1.28959437e-06
Iter: 1217 loss: 1.28894192e-06
Iter: 1218 loss: 1.29313298e-06
Iter: 1219 loss: 1.28877298e-06
Iter: 1220 loss: 1.28776605e-06
Iter: 1221 loss: 1.28994191e-06
Iter: 1222 loss: 1.28741317e-06
Iter: 1223 loss: 1.2868677e-06
Iter: 1224 loss: 1.28944941e-06
Iter: 1225 loss: 1.28683189e-06
Iter: 1226 loss: 1.28651845e-06
Iter: 1227 loss: 1.28622048e-06
Iter: 1228 loss: 1.28605814e-06
Iter: 1229 loss: 1.28592285e-06
Iter: 1230 loss: 1.28581189e-06
Iter: 1231 loss: 1.28513307e-06
Iter: 1232 loss: 1.28545901e-06
Iter: 1233 loss: 1.28477e-06
Iter: 1234 loss: 1.28396766e-06
Iter: 1235 loss: 1.28551369e-06
Iter: 1236 loss: 1.28381248e-06
Iter: 1237 loss: 1.28272927e-06
Iter: 1238 loss: 1.28330066e-06
Iter: 1239 loss: 1.28211377e-06
Iter: 1240 loss: 1.28159479e-06
Iter: 1241 loss: 1.28170416e-06
Iter: 1242 loss: 1.28088459e-06
Iter: 1243 loss: 1.2808963e-06
Iter: 1244 loss: 1.28044189e-06
Iter: 1245 loss: 1.2802642e-06
Iter: 1246 loss: 1.28001375e-06
Iter: 1247 loss: 1.27980275e-06
Iter: 1248 loss: 1.27949613e-06
Iter: 1249 loss: 1.27947555e-06
Iter: 1250 loss: 1.27914063e-06
Iter: 1251 loss: 1.2792533e-06
Iter: 1252 loss: 1.27883447e-06
Iter: 1253 loss: 1.27859846e-06
Iter: 1254 loss: 1.27765736e-06
Iter: 1255 loss: 1.28837814e-06
Iter: 1256 loss: 1.2775921e-06
Iter: 1257 loss: 1.27673866e-06
Iter: 1258 loss: 1.27681983e-06
Iter: 1259 loss: 1.27586884e-06
Iter: 1260 loss: 1.27501733e-06
Iter: 1261 loss: 1.27488045e-06
Iter: 1262 loss: 1.27452267e-06
Iter: 1263 loss: 1.27381463e-06
Iter: 1264 loss: 1.27368219e-06
Iter: 1265 loss: 1.2731997e-06
Iter: 1266 loss: 1.27451585e-06
Iter: 1267 loss: 1.27317367e-06
Iter: 1268 loss: 1.27248177e-06
Iter: 1269 loss: 1.27273108e-06
Iter: 1270 loss: 1.27211808e-06
Iter: 1271 loss: 1.27137162e-06
Iter: 1272 loss: 1.27517126e-06
Iter: 1273 loss: 1.27139913e-06
Iter: 1274 loss: 1.27070211e-06
Iter: 1275 loss: 1.27328417e-06
Iter: 1276 loss: 1.27047531e-06
Iter: 1277 loss: 1.26990437e-06
Iter: 1278 loss: 1.27201201e-06
Iter: 1279 loss: 1.26970599e-06
Iter: 1280 loss: 1.26926295e-06
Iter: 1281 loss: 1.27154613e-06
Iter: 1282 loss: 1.2692492e-06
Iter: 1283 loss: 1.26884493e-06
Iter: 1284 loss: 1.26856867e-06
Iter: 1285 loss: 1.26840553e-06
Iter: 1286 loss: 1.26785517e-06
Iter: 1287 loss: 1.267671e-06
Iter: 1288 loss: 1.26727309e-06
Iter: 1289 loss: 1.26632403e-06
Iter: 1290 loss: 1.26592522e-06
Iter: 1291 loss: 1.26547252e-06
Iter: 1292 loss: 1.26458087e-06
Iter: 1293 loss: 1.27815701e-06
Iter: 1294 loss: 1.26448913e-06
Iter: 1295 loss: 1.26385294e-06
Iter: 1296 loss: 1.26632642e-06
Iter: 1297 loss: 1.26348152e-06
Iter: 1298 loss: 1.26287591e-06
Iter: 1299 loss: 1.26514533e-06
Iter: 1300 loss: 1.26272744e-06
Iter: 1301 loss: 1.26197699e-06
Iter: 1302 loss: 1.26348823e-06
Iter: 1303 loss: 1.26170153e-06
Iter: 1304 loss: 1.26098496e-06
Iter: 1305 loss: 1.26374698e-06
Iter: 1306 loss: 1.26075906e-06
Iter: 1307 loss: 1.26028283e-06
Iter: 1308 loss: 1.26327859e-06
Iter: 1309 loss: 1.26016641e-06
Iter: 1310 loss: 1.25964073e-06
Iter: 1311 loss: 1.26194993e-06
Iter: 1312 loss: 1.25958093e-06
Iter: 1313 loss: 1.2591895e-06
Iter: 1314 loss: 1.26133909e-06
Iter: 1315 loss: 1.25910151e-06
Iter: 1316 loss: 1.25856911e-06
Iter: 1317 loss: 1.25823669e-06
Iter: 1318 loss: 1.25819838e-06
Iter: 1319 loss: 1.25746897e-06
Iter: 1320 loss: 1.2599279e-06
Iter: 1321 loss: 1.25729673e-06
Iter: 1322 loss: 1.25677525e-06
Iter: 1323 loss: 1.25677627e-06
Iter: 1324 loss: 1.25632255e-06
Iter: 1325 loss: 1.25570455e-06
Iter: 1326 loss: 1.2596355e-06
Iter: 1327 loss: 1.25570932e-06
Iter: 1328 loss: 1.25502174e-06
Iter: 1329 loss: 1.25533177e-06
Iter: 1330 loss: 1.25459428e-06
Iter: 1331 loss: 1.25389181e-06
Iter: 1332 loss: 1.25616418e-06
Iter: 1333 loss: 1.25364932e-06
Iter: 1334 loss: 1.25289796e-06
Iter: 1335 loss: 1.2525586e-06
Iter: 1336 loss: 1.25222095e-06
Iter: 1337 loss: 1.25153235e-06
Iter: 1338 loss: 1.26189491e-06
Iter: 1339 loss: 1.25143981e-06
Iter: 1340 loss: 1.25106158e-06
Iter: 1341 loss: 1.25129543e-06
Iter: 1342 loss: 1.25060592e-06
Iter: 1343 loss: 1.24978703e-06
Iter: 1344 loss: 1.2533842e-06
Iter: 1345 loss: 1.24975895e-06
Iter: 1346 loss: 1.24897201e-06
Iter: 1347 loss: 1.25646955e-06
Iter: 1348 loss: 1.2489279e-06
Iter: 1349 loss: 1.24854466e-06
Iter: 1350 loss: 1.24877442e-06
Iter: 1351 loss: 1.24838687e-06
Iter: 1352 loss: 1.24774533e-06
Iter: 1353 loss: 1.24794269e-06
Iter: 1354 loss: 1.24731901e-06
Iter: 1355 loss: 1.24676717e-06
Iter: 1356 loss: 1.24649955e-06
Iter: 1357 loss: 1.24602639e-06
Iter: 1358 loss: 1.24509575e-06
Iter: 1359 loss: 1.25051224e-06
Iter: 1360 loss: 1.24504777e-06
Iter: 1361 loss: 1.24413543e-06
Iter: 1362 loss: 1.2471055e-06
Iter: 1363 loss: 1.24384383e-06
Iter: 1364 loss: 1.24303813e-06
Iter: 1365 loss: 1.24655287e-06
Iter: 1366 loss: 1.24277585e-06
Iter: 1367 loss: 1.24224459e-06
Iter: 1368 loss: 1.24168196e-06
Iter: 1369 loss: 1.24147493e-06
Iter: 1370 loss: 1.24086216e-06
Iter: 1371 loss: 1.25204656e-06
Iter: 1372 loss: 1.24075564e-06
Iter: 1373 loss: 1.2402013e-06
Iter: 1374 loss: 1.24029509e-06
Iter: 1375 loss: 1.23981647e-06
Iter: 1376 loss: 1.23920199e-06
Iter: 1377 loss: 1.23922632e-06
Iter: 1378 loss: 1.23892301e-06
Iter: 1379 loss: 1.23967015e-06
Iter: 1380 loss: 1.23865834e-06
Iter: 1381 loss: 1.23846871e-06
Iter: 1382 loss: 1.23784389e-06
Iter: 1383 loss: 1.23793529e-06
Iter: 1384 loss: 1.23730501e-06
Iter: 1385 loss: 1.23776056e-06
Iter: 1386 loss: 1.2368597e-06
Iter: 1387 loss: 1.23644736e-06
Iter: 1388 loss: 1.2396456e-06
Iter: 1389 loss: 1.23647237e-06
Iter: 1390 loss: 1.23600444e-06
Iter: 1391 loss: 1.23603286e-06
Iter: 1392 loss: 1.23556094e-06
Iter: 1393 loss: 1.23510165e-06
Iter: 1394 loss: 1.23537e-06
Iter: 1395 loss: 1.23481891e-06
Iter: 1396 loss: 1.23436917e-06
Iter: 1397 loss: 1.23428242e-06
Iter: 1398 loss: 1.23413042e-06
Iter: 1399 loss: 1.23411974e-06
Iter: 1400 loss: 1.23395193e-06
Iter: 1401 loss: 1.23365112e-06
Iter: 1402 loss: 1.23464679e-06
Iter: 1403 loss: 1.23349537e-06
Iter: 1404 loss: 1.23315272e-06
Iter: 1405 loss: 1.23324446e-06
Iter: 1406 loss: 1.23299333e-06
Iter: 1407 loss: 1.23274481e-06
Iter: 1408 loss: 1.23277073e-06
Iter: 1409 loss: 1.23247924e-06
Iter: 1410 loss: 1.23249117e-06
Iter: 1411 loss: 1.23239499e-06
Iter: 1412 loss: 1.23204779e-06
Iter: 1413 loss: 1.2356868e-06
Iter: 1414 loss: 1.23189227e-06
Iter: 1415 loss: 1.23142399e-06
Iter: 1416 loss: 1.23588109e-06
Iter: 1417 loss: 1.23131588e-06
Iter: 1418 loss: 1.23120356e-06
Iter: 1419 loss: 1.23367329e-06
Iter: 1420 loss: 1.23101483e-06
Iter: 1421 loss: 1.23086386e-06
Iter: 1422 loss: 1.23017958e-06
Iter: 1423 loss: 1.23464838e-06
Iter: 1424 loss: 1.22991173e-06
Iter: 1425 loss: 1.22923382e-06
Iter: 1426 loss: 1.23387383e-06
Iter: 1427 loss: 1.22913661e-06
Iter: 1428 loss: 1.22855556e-06
Iter: 1429 loss: 1.23036693e-06
Iter: 1430 loss: 1.22835456e-06
Iter: 1431 loss: 1.22770291e-06
Iter: 1432 loss: 1.23120572e-06
Iter: 1433 loss: 1.22759786e-06
Iter: 1434 loss: 1.22727795e-06
Iter: 1435 loss: 1.2294031e-06
Iter: 1436 loss: 1.22706865e-06
Iter: 1437 loss: 1.22679171e-06
Iter: 1438 loss: 1.22650874e-06
Iter: 1439 loss: 1.22628308e-06
Iter: 1440 loss: 1.22566075e-06
Iter: 1441 loss: 1.22990457e-06
Iter: 1442 loss: 1.2257052e-06
Iter: 1443 loss: 1.22504412e-06
Iter: 1444 loss: 1.22514382e-06
Iter: 1445 loss: 1.22462745e-06
Iter: 1446 loss: 1.22494907e-06
Iter: 1447 loss: 1.22434801e-06
Iter: 1448 loss: 1.22415918e-06
Iter: 1449 loss: 1.22390293e-06
Iter: 1450 loss: 1.22450865e-06
Iter: 1451 loss: 1.22358938e-06
Iter: 1452 loss: 1.2232033e-06
Iter: 1453 loss: 1.22293363e-06
Iter: 1454 loss: 1.22271626e-06
Iter: 1455 loss: 1.22401082e-06
Iter: 1456 loss: 1.22252629e-06
Iter: 1457 loss: 1.22210122e-06
Iter: 1458 loss: 1.22164079e-06
Iter: 1459 loss: 1.22157473e-06
Iter: 1460 loss: 1.22086158e-06
Iter: 1461 loss: 1.22574784e-06
Iter: 1462 loss: 1.22087317e-06
Iter: 1463 loss: 1.22038193e-06
Iter: 1464 loss: 1.22309029e-06
Iter: 1465 loss: 1.22018525e-06
Iter: 1466 loss: 1.21970652e-06
Iter: 1467 loss: 1.22017605e-06
Iter: 1468 loss: 1.21938194e-06
Iter: 1469 loss: 1.21880475e-06
Iter: 1470 loss: 1.22343261e-06
Iter: 1471 loss: 1.21873609e-06
Iter: 1472 loss: 1.21811786e-06
Iter: 1473 loss: 1.2190194e-06
Iter: 1474 loss: 1.21774713e-06
Iter: 1475 loss: 1.21735809e-06
Iter: 1476 loss: 1.21962887e-06
Iter: 1477 loss: 1.21720439e-06
Iter: 1478 loss: 1.21695405e-06
Iter: 1479 loss: 1.22193342e-06
Iter: 1480 loss: 1.21698099e-06
Iter: 1481 loss: 1.21654978e-06
Iter: 1482 loss: 1.21613357e-06
Iter: 1483 loss: 1.21617904e-06
Iter: 1484 loss: 1.21574089e-06
Iter: 1485 loss: 1.2154992e-06
Iter: 1486 loss: 1.21524499e-06
Iter: 1487 loss: 1.21442315e-06
Iter: 1488 loss: 1.21925791e-06
Iter: 1489 loss: 1.21430071e-06
Iter: 1490 loss: 1.213872e-06
Iter: 1491 loss: 1.21357402e-06
Iter: 1492 loss: 1.21341259e-06
Iter: 1493 loss: 1.21247353e-06
Iter: 1494 loss: 1.21440826e-06
Iter: 1495 loss: 1.21214202e-06
Iter: 1496 loss: 1.21141409e-06
Iter: 1497 loss: 1.21899859e-06
Iter: 1498 loss: 1.21146184e-06
Iter: 1499 loss: 1.21079415e-06
Iter: 1500 loss: 1.21159678e-06
Iter: 1501 loss: 1.21058486e-06
Iter: 1502 loss: 1.21005974e-06
Iter: 1503 loss: 1.21375297e-06
Iter: 1504 loss: 1.20997993e-06
Iter: 1505 loss: 1.20949926e-06
Iter: 1506 loss: 1.21041865e-06
Iter: 1507 loss: 1.20942809e-06
Iter: 1508 loss: 1.20907453e-06
Iter: 1509 loss: 1.21161565e-06
Iter: 1510 loss: 1.2089389e-06
Iter: 1511 loss: 1.20873551e-06
Iter: 1512 loss: 1.21104142e-06
Iter: 1513 loss: 1.20877314e-06
Iter: 1514 loss: 1.20843913e-06
Iter: 1515 loss: 1.20858795e-06
Iter: 1516 loss: 1.208394e-06
Iter: 1517 loss: 1.20798313e-06
Iter: 1518 loss: 1.20774553e-06
Iter: 1519 loss: 1.20761888e-06
Iter: 1520 loss: 1.20727077e-06
Iter: 1521 loss: 1.21117182e-06
Iter: 1522 loss: 1.20718107e-06
Iter: 1523 loss: 1.20697439e-06
Iter: 1524 loss: 1.20708762e-06
Iter: 1525 loss: 1.20681227e-06
Iter: 1526 loss: 1.20631933e-06
Iter: 1527 loss: 1.2056031e-06
Iter: 1528 loss: 1.20560105e-06
Iter: 1529 loss: 1.20500863e-06
Iter: 1530 loss: 1.20718585e-06
Iter: 1531 loss: 1.20484594e-06
Iter: 1532 loss: 1.20415837e-06
Iter: 1533 loss: 1.20545815e-06
Iter: 1534 loss: 1.20386017e-06
Iter: 1535 loss: 1.20318987e-06
Iter: 1536 loss: 1.20329423e-06
Iter: 1537 loss: 1.2027848e-06
Iter: 1538 loss: 1.20214531e-06
Iter: 1539 loss: 1.21510686e-06
Iter: 1540 loss: 1.20218169e-06
Iter: 1541 loss: 1.20139225e-06
Iter: 1542 loss: 1.20593165e-06
Iter: 1543 loss: 1.20118921e-06
Iter: 1544 loss: 1.20092136e-06
Iter: 1545 loss: 1.20501704e-06
Iter: 1546 loss: 1.20088509e-06
Iter: 1547 loss: 1.20046639e-06
Iter: 1548 loss: 1.20417e-06
Iter: 1549 loss: 1.20041352e-06
Iter: 1550 loss: 1.20011441e-06
Iter: 1551 loss: 1.19975618e-06
Iter: 1552 loss: 1.19980439e-06
Iter: 1553 loss: 1.19943581e-06
Iter: 1554 loss: 1.19923391e-06
Iter: 1555 loss: 1.19888136e-06
Iter: 1556 loss: 1.19829087e-06
Iter: 1557 loss: 1.20559048e-06
Iter: 1558 loss: 1.1982213e-06
Iter: 1559 loss: 1.19784124e-06
Iter: 1560 loss: 1.19798915e-06
Iter: 1561 loss: 1.19755248e-06
Iter: 1562 loss: 1.19706738e-06
Iter: 1563 loss: 1.19829156e-06
Iter: 1564 loss: 1.19700462e-06
Iter: 1565 loss: 1.19636684e-06
Iter: 1566 loss: 1.19719425e-06
Iter: 1567 loss: 1.19607239e-06
Iter: 1568 loss: 1.19578465e-06
Iter: 1569 loss: 1.19897823e-06
Iter: 1570 loss: 1.1956879e-06
Iter: 1571 loss: 1.19542597e-06
Iter: 1572 loss: 1.19539743e-06
Iter: 1573 loss: 1.19506183e-06
Iter: 1574 loss: 1.19466949e-06
Iter: 1575 loss: 1.19470394e-06
Iter: 1576 loss: 1.19422509e-06
Iter: 1577 loss: 1.19398e-06
Iter: 1578 loss: 1.19452761e-06
Iter: 1579 loss: 1.19387073e-06
Iter: 1580 loss: 1.19354138e-06
Iter: 1581 loss: 1.19634808e-06
Iter: 1582 loss: 1.19354013e-06
Iter: 1583 loss: 1.19317713e-06
Iter: 1584 loss: 1.19325216e-06
Iter: 1585 loss: 1.19300228e-06
Iter: 1586 loss: 1.19274034e-06
Iter: 1587 loss: 1.19218362e-06
Iter: 1588 loss: 1.19689639e-06
Iter: 1589 loss: 1.19222454e-06
Iter: 1590 loss: 1.19185893e-06
Iter: 1591 loss: 1.19183107e-06
Iter: 1592 loss: 1.19157062e-06
Iter: 1593 loss: 1.19178799e-06
Iter: 1594 loss: 1.1914675e-06
Iter: 1595 loss: 1.19113508e-06
Iter: 1596 loss: 1.19075071e-06
Iter: 1597 loss: 1.19078516e-06
Iter: 1598 loss: 1.19036872e-06
Iter: 1599 loss: 1.19283686e-06
Iter: 1600 loss: 1.19032495e-06
Iter: 1601 loss: 1.18990079e-06
Iter: 1602 loss: 1.19111041e-06
Iter: 1603 loss: 1.18974538e-06
Iter: 1604 loss: 1.18940568e-06
Iter: 1605 loss: 1.19056654e-06
Iter: 1606 loss: 1.18930325e-06
Iter: 1607 loss: 1.1889141e-06
Iter: 1608 loss: 1.18840421e-06
Iter: 1609 loss: 1.18854132e-06
Iter: 1610 loss: 1.18823323e-06
Iter: 1611 loss: 1.18940375e-06
Iter: 1612 loss: 1.1881001e-06
Iter: 1613 loss: 1.18790729e-06
Iter: 1614 loss: 1.18772107e-06
Iter: 1615 loss: 1.18762773e-06
Iter: 1616 loss: 1.18747073e-06
Iter: 1617 loss: 1.18940238e-06
Iter: 1618 loss: 1.18747948e-06
Iter: 1619 loss: 1.18727883e-06
Iter: 1620 loss: 1.1872844e-06
Iter: 1621 loss: 1.18710091e-06
Iter: 1622 loss: 1.18684648e-06
Iter: 1623 loss: 1.18756168e-06
Iter: 1624 loss: 1.18682954e-06
Iter: 1625 loss: 1.18644016e-06
Iter: 1626 loss: 1.18804496e-06
Iter: 1627 loss: 1.18637513e-06
Iter: 1628 loss: 1.18624848e-06
Iter: 1629 loss: 1.18625292e-06
Iter: 1630 loss: 1.18614867e-06
Iter: 1631 loss: 1.18578669e-06
Iter: 1632 loss: 1.18666787e-06
Iter: 1633 loss: 1.18573678e-06
Iter: 1634 loss: 1.18543801e-06
Iter: 1635 loss: 1.18541539e-06
Iter: 1636 loss: 1.18519188e-06
Iter: 1637 loss: 1.18497871e-06
Iter: 1638 loss: 1.18538151e-06
Iter: 1639 loss: 1.18462162e-06
Iter: 1640 loss: 1.18447372e-06
Iter: 1641 loss: 1.18445791e-06
Iter: 1642 loss: 1.18429534e-06
Iter: 1643 loss: 1.18387027e-06
Iter: 1644 loss: 1.19279798e-06
Iter: 1645 loss: 1.18385583e-06
Iter: 1646 loss: 1.18377307e-06
Iter: 1647 loss: 1.18365097e-06
Iter: 1648 loss: 1.18357025e-06
Iter: 1649 loss: 1.18376386e-06
Iter: 1650 loss: 1.18349374e-06
Iter: 1651 loss: 1.18330308e-06
Iter: 1652 loss: 1.18288449e-06
Iter: 1653 loss: 1.18792775e-06
Iter: 1654 loss: 1.18278103e-06
Iter: 1655 loss: 1.18242042e-06
Iter: 1656 loss: 1.18562036e-06
Iter: 1657 loss: 1.18231e-06
Iter: 1658 loss: 1.1822159e-06
Iter: 1659 loss: 1.18205207e-06
Iter: 1660 loss: 1.18197488e-06
Iter: 1661 loss: 1.1816735e-06
Iter: 1662 loss: 1.1851979e-06
Iter: 1663 loss: 1.18169612e-06
Iter: 1664 loss: 1.18129026e-06
Iter: 1665 loss: 1.18435776e-06
Iter: 1666 loss: 1.18137086e-06
Iter: 1667 loss: 1.18098046e-06
Iter: 1668 loss: 1.18100161e-06
Iter: 1669 loss: 1.18082198e-06
Iter: 1670 loss: 1.18060893e-06
Iter: 1671 loss: 1.18076889e-06
Iter: 1672 loss: 1.18051662e-06
Iter: 1673 loss: 1.18024491e-06
Iter: 1674 loss: 1.17971786e-06
Iter: 1675 loss: 1.18634034e-06
Iter: 1676 loss: 1.17979391e-06
Iter: 1677 loss: 1.17930335e-06
Iter: 1678 loss: 1.18353978e-06
Iter: 1679 loss: 1.17935883e-06
Iter: 1680 loss: 1.17913794e-06
Iter: 1681 loss: 1.17914306e-06
Iter: 1682 loss: 1.17887703e-06
Iter: 1683 loss: 1.17913783e-06
Iter: 1684 loss: 1.17881882e-06
Iter: 1685 loss: 1.1785587e-06
Iter: 1686 loss: 1.17911679e-06
Iter: 1687 loss: 1.17844297e-06
Iter: 1688 loss: 1.17832064e-06
Iter: 1689 loss: 1.17808531e-06
Iter: 1690 loss: 1.18081823e-06
Iter: 1691 loss: 1.17797083e-06
Iter: 1692 loss: 1.17772026e-06
Iter: 1693 loss: 1.1807914e-06
Iter: 1694 loss: 1.17768718e-06
Iter: 1695 loss: 1.17752143e-06
Iter: 1696 loss: 1.17888067e-06
Iter: 1697 loss: 1.17737909e-06
Iter: 1698 loss: 1.17723675e-06
Iter: 1699 loss: 1.17860577e-06
Iter: 1700 loss: 1.17724278e-06
Iter: 1701 loss: 1.17717923e-06
Iter: 1702 loss: 1.17714944e-06
Iter: 1703 loss: 1.17702848e-06
Iter: 1704 loss: 1.17694253e-06
Iter: 1705 loss: 1.1768858e-06
Iter: 1706 loss: 1.17676132e-06
Iter: 1707 loss: 1.17647699e-06
Iter: 1708 loss: 1.17936111e-06
Iter: 1709 loss: 1.17653303e-06
Iter: 1710 loss: 1.17642946e-06
Iter: 1711 loss: 1.17621721e-06
Iter: 1712 loss: 1.17786044e-06
Iter: 1713 loss: 1.17599825e-06
Iter: 1714 loss: 1.17582636e-06
Iter: 1715 loss: 1.1758051e-06
Iter: 1716 loss: 1.17549394e-06
Iter: 1717 loss: 1.17828642e-06
Iter: 1718 loss: 1.1755385e-06
Iter: 1719 loss: 1.1754471e-06
Iter: 1720 loss: 1.17632067e-06
Iter: 1721 loss: 1.17550474e-06
Iter: 1722 loss: 1.17543266e-06
Iter: 1723 loss: 1.1751531e-06
Iter: 1724 loss: 1.17818092e-06
Iter: 1725 loss: 1.17507864e-06
Iter: 1726 loss: 1.17486309e-06
Iter: 1727 loss: 1.17472348e-06
Iter: 1728 loss: 1.17459979e-06
Iter: 1729 loss: 1.1745077e-06
Iter: 1730 loss: 1.17578179e-06
Iter: 1731 loss: 1.17432387e-06
Iter: 1732 loss: 1.17428385e-06
Iter: 1733 loss: 1.174217e-06
Iter: 1734 loss: 1.17410173e-06
Iter: 1735 loss: 1.17392869e-06
Iter: 1736 loss: 1.17474167e-06
Iter: 1737 loss: 1.17395496e-06
Iter: 1738 loss: 1.17375691e-06
Iter: 1739 loss: 1.17416539e-06
Iter: 1740 loss: 1.17375976e-06
Iter: 1741 loss: 1.17367188e-06
Iter: 1742 loss: 1.17337777e-06
Iter: 1743 loss: 1.17343916e-06
Iter: 1744 loss: 1.17322043e-06
Iter: 1745 loss: 1.17332138e-06
Iter: 1746 loss: 1.17312504e-06
Iter: 1747 loss: 1.17289699e-06
Iter: 1748 loss: 1.17318359e-06
Iter: 1749 loss: 1.1728871e-06
Iter: 1750 loss: 1.17284719e-06
Iter: 1751 loss: 1.17338845e-06
Iter: 1752 loss: 1.17265085e-06
Iter: 1753 loss: 1.17250386e-06
Iter: 1754 loss: 1.17309787e-06
Iter: 1755 loss: 1.17246316e-06
Iter: 1756 loss: 1.1724253e-06
Iter: 1757 loss: 1.17294962e-06
Iter: 1758 loss: 1.17232184e-06
Iter: 1759 loss: 1.17215336e-06
Iter: 1760 loss: 1.17180434e-06
Iter: 1761 loss: 1.17803063e-06
Iter: 1762 loss: 1.17182219e-06
Iter: 1763 loss: 1.17152399e-06
Iter: 1764 loss: 1.17521006e-06
Iter: 1765 loss: 1.17155821e-06
Iter: 1766 loss: 1.17133914e-06
Iter: 1767 loss: 1.1715606e-06
Iter: 1768 loss: 1.17130583e-06
Iter: 1769 loss: 1.17101808e-06
Iter: 1770 loss: 1.17084062e-06
Iter: 1771 loss: 1.17074501e-06
Iter: 1772 loss: 1.17056948e-06
Iter: 1773 loss: 1.17233594e-06
Iter: 1774 loss: 1.17056641e-06
Iter: 1775 loss: 1.17044499e-06
Iter: 1776 loss: 1.17021591e-06
Iter: 1777 loss: 1.17036211e-06
Iter: 1778 loss: 1.17013781e-06
Iter: 1779 loss: 1.17000798e-06
Iter: 1780 loss: 1.1698346e-06
Iter: 1781 loss: 1.17015099e-06
Iter: 1782 loss: 1.16987746e-06
Iter: 1783 loss: 1.16970796e-06
Iter: 1784 loss: 1.16946819e-06
Iter: 1785 loss: 1.1694716e-06
Iter: 1786 loss: 1.16928334e-06
Iter: 1787 loss: 1.16920148e-06
Iter: 1788 loss: 1.1691194e-06
Iter: 1789 loss: 1.1688719e-06
Iter: 1790 loss: 1.17131424e-06
Iter: 1791 loss: 1.16880324e-06
Iter: 1792 loss: 1.16853414e-06
Iter: 1793 loss: 1.16883291e-06
Iter: 1794 loss: 1.16841682e-06
Iter: 1795 loss: 1.16810918e-06
Iter: 1796 loss: 1.16924025e-06
Iter: 1797 loss: 1.16803915e-06
Iter: 1798 loss: 1.16785827e-06
Iter: 1799 loss: 1.16879801e-06
Iter: 1800 loss: 1.16771332e-06
Iter: 1801 loss: 1.16738443e-06
Iter: 1802 loss: 1.16865112e-06
Iter: 1803 loss: 1.16746116e-06
Iter: 1804 loss: 1.16731906e-06
Iter: 1805 loss: 1.16843535e-06
Iter: 1806 loss: 1.16730962e-06
Iter: 1807 loss: 1.1671342e-06
Iter: 1808 loss: 1.16724618e-06
Iter: 1809 loss: 1.16696094e-06
Iter: 1810 loss: 1.1668767e-06
Iter: 1811 loss: 1.16648323e-06
Iter: 1812 loss: 1.17072011e-06
Iter: 1813 loss: 1.16655269e-06
Iter: 1814 loss: 1.16650881e-06
Iter: 1815 loss: 1.16638921e-06
Iter: 1816 loss: 1.16617957e-06
Iter: 1817 loss: 1.16676517e-06
Iter: 1818 loss: 1.1660585e-06
Iter: 1819 loss: 1.16590456e-06
Iter: 1820 loss: 1.16618719e-06
Iter: 1821 loss: 1.16589854e-06
Iter: 1822 loss: 1.16574415e-06
Iter: 1823 loss: 1.16589217e-06
Iter: 1824 loss: 1.16566366e-06
Iter: 1825 loss: 1.16540377e-06
Iter: 1826 loss: 1.16631634e-06
Iter: 1827 loss: 1.16522779e-06
Iter: 1828 loss: 1.16508761e-06
Iter: 1829 loss: 1.1662512e-06
Iter: 1830 loss: 1.16495073e-06
Iter: 1831 loss: 1.16487229e-06
Iter: 1832 loss: 1.16517458e-06
Iter: 1833 loss: 1.1647935e-06
Iter: 1834 loss: 1.16456306e-06
Iter: 1835 loss: 1.16500485e-06
Iter: 1836 loss: 1.16440913e-06
Iter: 1837 loss: 1.16422689e-06
Iter: 1838 loss: 1.16406534e-06
Iter: 1839 loss: 1.16409365e-06
Iter: 1840 loss: 1.16369642e-06
Iter: 1841 loss: 1.16365186e-06
Iter: 1842 loss: 1.16348178e-06
Iter: 1843 loss: 1.16378169e-06
Iter: 1844 loss: 1.16350293e-06
Iter: 1845 loss: 1.16334172e-06
Iter: 1846 loss: 1.16302908e-06
Iter: 1847 loss: 1.16713295e-06
Iter: 1848 loss: 1.16301089e-06
Iter: 1849 loss: 1.16282695e-06
Iter: 1850 loss: 1.1628124e-06
Iter: 1851 loss: 1.16256297e-06
Iter: 1852 loss: 1.16273168e-06
Iter: 1853 loss: 1.16246576e-06
Iter: 1854 loss: 1.1622808e-06
Iter: 1855 loss: 1.16329659e-06
Iter: 1856 loss: 1.16228898e-06
Iter: 1857 loss: 1.16212766e-06
Iter: 1858 loss: 1.1622642e-06
Iter: 1859 loss: 1.16204433e-06
Iter: 1860 loss: 1.16167894e-06
Iter: 1861 loss: 1.16187573e-06
Iter: 1862 loss: 1.1615723e-06
Iter: 1863 loss: 1.16125318e-06
Iter: 1864 loss: 1.16333263e-06
Iter: 1865 loss: 1.16121021e-06
Iter: 1866 loss: 1.16093008e-06
Iter: 1867 loss: 1.16128604e-06
Iter: 1868 loss: 1.1607533e-06
Iter: 1869 loss: 1.160696e-06
Iter: 1870 loss: 1.16064939e-06
Iter: 1871 loss: 1.16044066e-06
Iter: 1872 loss: 1.16022147e-06
Iter: 1873 loss: 1.16040405e-06
Iter: 1874 loss: 1.16001888e-06
Iter: 1875 loss: 1.16000672e-06
Iter: 1876 loss: 1.16001866e-06
Iter: 1877 loss: 1.15977252e-06
Iter: 1878 loss: 1.15953094e-06
Iter: 1879 loss: 1.15950843e-06
Iter: 1880 loss: 1.1591801e-06
Iter: 1881 loss: 1.15879686e-06
Iter: 1882 loss: 1.1587548e-06
Iter: 1883 loss: 1.15821763e-06
Iter: 1884 loss: 1.15820501e-06
Iter: 1885 loss: 1.15784417e-06
Iter: 1886 loss: 1.16292495e-06
Iter: 1887 loss: 1.15795206e-06
Iter: 1888 loss: 1.15768989e-06
Iter: 1889 loss: 1.15795024e-06
Iter: 1890 loss: 1.15753096e-06
Iter: 1891 loss: 1.15728176e-06
Iter: 1892 loss: 1.1574391e-06
Iter: 1893 loss: 1.15699549e-06
Iter: 1894 loss: 1.15679745e-06
Iter: 1895 loss: 1.15744672e-06
Iter: 1896 loss: 1.15669673e-06
Iter: 1897 loss: 1.15655973e-06
Iter: 1898 loss: 1.15994021e-06
Iter: 1899 loss: 1.15653984e-06
Iter: 1900 loss: 1.15638522e-06
Iter: 1901 loss: 1.156351e-06
Iter: 1902 loss: 1.15620048e-06
Iter: 1903 loss: 1.15608304e-06
Iter: 1904 loss: 1.15656962e-06
Iter: 1905 loss: 1.15605053e-06
Iter: 1906 loss: 1.15585499e-06
Iter: 1907 loss: 1.15640853e-06
Iter: 1908 loss: 1.15578473e-06
Iter: 1909 loss: 1.1556308e-06
Iter: 1910 loss: 1.15562818e-06
Iter: 1911 loss: 1.15551427e-06
Iter: 1912 loss: 1.15524108e-06
Iter: 1913 loss: 1.15935813e-06
Iter: 1914 loss: 1.15529576e-06
Iter: 1915 loss: 1.15508215e-06
Iter: 1916 loss: 1.15464491e-06
Iter: 1917 loss: 1.15457374e-06
Iter: 1918 loss: 1.15398382e-06
Iter: 1919 loss: 1.15433966e-06
Iter: 1920 loss: 1.15372677e-06
Iter: 1921 loss: 1.15334615e-06
Iter: 1922 loss: 1.15323621e-06
Iter: 1923 loss: 1.15309808e-06
Iter: 1924 loss: 1.15587341e-06
Iter: 1925 loss: 1.15299304e-06
Iter: 1926 loss: 1.15288617e-06
Iter: 1927 loss: 1.15254204e-06
Iter: 1928 loss: 1.15261287e-06
Iter: 1929 loss: 1.15215107e-06
Iter: 1930 loss: 1.15437399e-06
Iter: 1931 loss: 1.15210923e-06
Iter: 1932 loss: 1.15183298e-06
Iter: 1933 loss: 1.15234639e-06
Iter: 1934 loss: 1.15170531e-06
Iter: 1935 loss: 1.15139301e-06
Iter: 1936 loss: 1.15461739e-06
Iter: 1937 loss: 1.15145451e-06
Iter: 1938 loss: 1.15122327e-06
Iter: 1939 loss: 1.15092075e-06
Iter: 1940 loss: 1.15093189e-06
Iter: 1941 loss: 1.15070145e-06
Iter: 1942 loss: 1.15072066e-06
Iter: 1943 loss: 1.15047771e-06
Iter: 1944 loss: 1.1506786e-06
Iter: 1945 loss: 1.15041087e-06
Iter: 1946 loss: 1.15008879e-06
Iter: 1947 loss: 1.15039597e-06
Iter: 1948 loss: 1.1498787e-06
Iter: 1949 loss: 1.14955321e-06
Iter: 1950 loss: 1.15043008e-06
Iter: 1951 loss: 1.14944316e-06
Iter: 1952 loss: 1.1490007e-06
Iter: 1953 loss: 1.15035721e-06
Iter: 1954 loss: 1.1490099e-06
Iter: 1955 loss: 1.1487366e-06
Iter: 1956 loss: 1.15136345e-06
Iter: 1957 loss: 1.14872569e-06
Iter: 1958 loss: 1.14852014e-06
Iter: 1959 loss: 1.14835234e-06
Iter: 1960 loss: 1.14813452e-06
Iter: 1961 loss: 1.14796842e-06
Iter: 1962 loss: 1.14796376e-06
Iter: 1963 loss: 1.14778641e-06
Iter: 1964 loss: 1.14748275e-06
Iter: 1965 loss: 1.15027319e-06
Iter: 1966 loss: 1.14746103e-06
Iter: 1967 loss: 1.14718159e-06
Iter: 1968 loss: 1.1470903e-06
Iter: 1969 loss: 1.14694842e-06
Iter: 1970 loss: 1.14672e-06
Iter: 1971 loss: 1.14677016e-06
Iter: 1972 loss: 1.14658815e-06
Iter: 1973 loss: 1.14643638e-06
Iter: 1974 loss: 1.14647185e-06
Iter: 1975 loss: 1.14617546e-06
Iter: 1976 loss: 1.14621821e-06
Iter: 1977 loss: 1.14611623e-06
Iter: 1978 loss: 1.14613692e-06
Iter: 1979 loss: 1.1459374e-06
Iter: 1980 loss: 1.14565535e-06
Iter: 1981 loss: 1.14605837e-06
Iter: 1982 loss: 1.14544287e-06
Iter: 1983 loss: 1.14516604e-06
Iter: 1984 loss: 1.14485817e-06
Iter: 1985 loss: 1.14487193e-06
Iter: 1986 loss: 1.14435056e-06
Iter: 1987 loss: 1.14444845e-06
Iter: 1988 loss: 1.14416775e-06
Iter: 1989 loss: 1.14863531e-06
Iter: 1990 loss: 1.14409943e-06
Iter: 1991 loss: 1.14386205e-06
Iter: 1992 loss: 1.14395493e-06
Iter: 1993 loss: 1.14370528e-06
Iter: 1994 loss: 1.1435111e-06
Iter: 1995 loss: 1.14346108e-06
Iter: 1996 loss: 1.14333125e-06
Iter: 1997 loss: 1.14293255e-06
Iter: 1998 loss: 1.14701118e-06
Iter: 1999 loss: 1.14298189e-06
Iter: 2000 loss: 1.14266663e-06
Iter: 2001 loss: 1.14450881e-06
Iter: 2002 loss: 1.14267334e-06
Iter: 2003 loss: 1.14251179e-06
Iter: 2004 loss: 1.14221803e-06
Iter: 2005 loss: 1.14966122e-06
Iter: 2006 loss: 1.1422369e-06
Iter: 2007 loss: 1.14202862e-06
Iter: 2008 loss: 1.14197667e-06
Iter: 2009 loss: 1.14178954e-06
Iter: 2010 loss: 1.14203976e-06
Iter: 2011 loss: 1.14165937e-06
Iter: 2012 loss: 1.14145689e-06
Iter: 2013 loss: 1.14153409e-06
Iter: 2014 loss: 1.14117051e-06
Iter: 2015 loss: 1.14088755e-06
Iter: 2016 loss: 1.14276111e-06
Iter: 2017 loss: 1.14076852e-06
Iter: 2018 loss: 1.1405042e-06
Iter: 2019 loss: 1.14153568e-06
Iter: 2020 loss: 1.14049158e-06
Iter: 2021 loss: 1.14014244e-06
Iter: 2022 loss: 1.14087015e-06
Iter: 2023 loss: 1.14006571e-06
Iter: 2024 loss: 1.13986221e-06
Iter: 2025 loss: 1.14219665e-06
Iter: 2026 loss: 1.13982549e-06
Iter: 2027 loss: 1.13965621e-06
Iter: 2028 loss: 1.1396246e-06
Iter: 2029 loss: 1.13951739e-06
Iter: 2030 loss: 1.13932128e-06
Iter: 2031 loss: 1.13959152e-06
Iter: 2032 loss: 1.13916758e-06
Iter: 2033 loss: 1.13879173e-06
Iter: 2034 loss: 1.14291652e-06
Iter: 2035 loss: 1.13891815e-06
Iter: 2036 loss: 1.13856333e-06
Iter: 2037 loss: 1.1389543e-06
Iter: 2038 loss: 1.13841668e-06
Iter: 2039 loss: 1.13817589e-06
Iter: 2040 loss: 1.13930309e-06
Iter: 2041 loss: 1.13816191e-06
Iter: 2042 loss: 1.13789906e-06
Iter: 2043 loss: 1.13791464e-06
Iter: 2044 loss: 1.13778765e-06
Iter: 2045 loss: 1.13766771e-06
Iter: 2046 loss: 1.13761894e-06
Iter: 2047 loss: 1.13745193e-06
Iter: 2048 loss: 1.13737838e-06
Iter: 2049 loss: 1.13728083e-06
Iter: 2050 loss: 1.13687099e-06
Iter: 2051 loss: 1.13709916e-06
Iter: 2052 loss: 1.13674719e-06
Iter: 2053 loss: 1.13647206e-06
Iter: 2054 loss: 1.13909994e-06
Iter: 2055 loss: 1.13643682e-06
Iter: 2056 loss: 1.13610099e-06
Iter: 2057 loss: 1.13881208e-06
Iter: 2058 loss: 1.1361542e-06
Iter: 2059 loss: 1.13585463e-06
Iter: 2060 loss: 1.13583485e-06
Iter: 2061 loss: 1.13573105e-06
Iter: 2062 loss: 1.1353618e-06
Iter: 2063 loss: 1.13505314e-06
Iter: 2064 loss: 1.13501221e-06
Iter: 2065 loss: 1.13446686e-06
Iter: 2066 loss: 1.13550186e-06
Iter: 2067 loss: 1.13429815e-06
Iter: 2068 loss: 1.13386795e-06
Iter: 2069 loss: 1.13515114e-06
Iter: 2070 loss: 1.1336025e-06
Iter: 2071 loss: 1.13334727e-06
Iter: 2072 loss: 1.13617307e-06
Iter: 2073 loss: 1.1332927e-06
Iter: 2074 loss: 1.13311546e-06
Iter: 2075 loss: 1.13357783e-06
Iter: 2076 loss: 1.13298074e-06
Iter: 2077 loss: 1.13273518e-06
Iter: 2078 loss: 1.13383214e-06
Iter: 2079 loss: 1.13266094e-06
Iter: 2080 loss: 1.13254009e-06
Iter: 2081 loss: 1.13308283e-06
Iter: 2082 loss: 1.13253702e-06
Iter: 2083 loss: 1.13244721e-06
Iter: 2084 loss: 1.13195347e-06
Iter: 2085 loss: 1.1370181e-06
Iter: 2086 loss: 1.13189151e-06
Iter: 2087 loss: 1.13138753e-06
Iter: 2088 loss: 1.13242913e-06
Iter: 2089 loss: 1.1310799e-06
Iter: 2090 loss: 1.13064698e-06
Iter: 2091 loss: 1.13366889e-06
Iter: 2092 loss: 1.13057149e-06
Iter: 2093 loss: 1.13011492e-06
Iter: 2094 loss: 1.13593683e-06
Iter: 2095 loss: 1.13006706e-06
Iter: 2096 loss: 1.12996486e-06
Iter: 2097 loss: 1.12983162e-06
Iter: 2098 loss: 1.12969531e-06
Iter: 2099 loss: 1.12934322e-06
Iter: 2100 loss: 1.12938335e-06
Iter: 2101 loss: 1.12907139e-06
Iter: 2102 loss: 1.12873772e-06
Iter: 2103 loss: 1.12892894e-06
Iter: 2104 loss: 1.12837199e-06
Iter: 2105 loss: 1.12783255e-06
Iter: 2106 loss: 1.1331183e-06
Iter: 2107 loss: 1.12779867e-06
Iter: 2108 loss: 1.1274019e-06
Iter: 2109 loss: 1.12741589e-06
Iter: 2110 loss: 1.12708585e-06
Iter: 2111 loss: 1.12695955e-06
Iter: 2112 loss: 1.126911e-06
Iter: 2113 loss: 1.12670523e-06
Iter: 2114 loss: 1.12668749e-06
Iter: 2115 loss: 1.12665828e-06
Iter: 2116 loss: 1.12653026e-06
Iter: 2117 loss: 1.13057763e-06
Iter: 2118 loss: 1.12630903e-06
Iter: 2119 loss: 1.12606847e-06
Iter: 2120 loss: 1.12637417e-06
Iter: 2121 loss: 1.1257863e-06
Iter: 2122 loss: 1.12564942e-06
Iter: 2123 loss: 1.12547457e-06
Iter: 2124 loss: 1.12541375e-06
Iter: 2125 loss: 1.12506211e-06
Iter: 2126 loss: 1.1287475e-06
Iter: 2127 loss: 1.12495172e-06
Iter: 2128 loss: 1.12457678e-06
Iter: 2129 loss: 1.12495013e-06
Iter: 2130 loss: 1.12433327e-06
Iter: 2131 loss: 1.12397629e-06
Iter: 2132 loss: 1.12602993e-06
Iter: 2133 loss: 1.12397072e-06
Iter: 2134 loss: 1.12349812e-06
Iter: 2135 loss: 1.12384578e-06
Iter: 2136 loss: 1.12337216e-06
Iter: 2137 loss: 1.12293935e-06
Iter: 2138 loss: 1.1285706e-06
Iter: 2139 loss: 1.12286602e-06
Iter: 2140 loss: 1.12246528e-06
Iter: 2141 loss: 1.12227735e-06
Iter: 2142 loss: 1.12209466e-06
Iter: 2143 loss: 1.12159148e-06
Iter: 2144 loss: 1.12474402e-06
Iter: 2145 loss: 1.12155158e-06
Iter: 2146 loss: 1.12114481e-06
Iter: 2147 loss: 1.12691123e-06
Iter: 2148 loss: 1.12111798e-06
Iter: 2149 loss: 1.12088208e-06
Iter: 2150 loss: 1.12137695e-06
Iter: 2151 loss: 1.12064413e-06
Iter: 2152 loss: 1.12040993e-06
Iter: 2153 loss: 1.1202078e-06
Iter: 2154 loss: 1.12033592e-06
Iter: 2155 loss: 1.1199445e-06
Iter: 2156 loss: 1.11970826e-06
Iter: 2157 loss: 1.11947452e-06
Iter: 2158 loss: 1.11917666e-06
Iter: 2159 loss: 1.119128e-06
Iter: 2160 loss: 1.11878796e-06
Iter: 2161 loss: 1.11991187e-06
Iter: 2162 loss: 1.11870929e-06
Iter: 2163 loss: 1.11843565e-06
Iter: 2164 loss: 1.11817758e-06
Iter: 2165 loss: 1.11813279e-06
Iter: 2166 loss: 1.11756162e-06
Iter: 2167 loss: 1.1187384e-06
Iter: 2168 loss: 1.11757447e-06
Iter: 2169 loss: 1.11715383e-06
Iter: 2170 loss: 1.12056318e-06
Iter: 2171 loss: 1.11712541e-06
Iter: 2172 loss: 1.11695022e-06
Iter: 2173 loss: 1.11896691e-06
Iter: 2174 loss: 1.11689974e-06
Iter: 2175 loss: 1.11663871e-06
Iter: 2176 loss: 1.11637178e-06
Iter: 2177 loss: 1.11634881e-06
Iter: 2178 loss: 1.11610393e-06
Iter: 2179 loss: 1.1183372e-06
Iter: 2180 loss: 1.11606175e-06
Iter: 2181 loss: 1.11587462e-06
Iter: 2182 loss: 1.1175548e-06
Iter: 2183 loss: 1.11594636e-06
Iter: 2184 loss: 1.11568488e-06
Iter: 2185 loss: 1.1160264e-06
Iter: 2186 loss: 1.11551321e-06
Iter: 2187 loss: 1.11528823e-06
Iter: 2188 loss: 1.11507632e-06
Iter: 2189 loss: 1.12199359e-06
Iter: 2190 loss: 1.11504653e-06
Iter: 2191 loss: 1.1146758e-06
Iter: 2192 loss: 1.11797215e-06
Iter: 2193 loss: 1.11462168e-06
Iter: 2194 loss: 1.11431382e-06
Iter: 2195 loss: 1.11490465e-06
Iter: 2196 loss: 1.11412567e-06
Iter: 2197 loss: 1.11375721e-06
Iter: 2198 loss: 1.1151734e-06
Iter: 2199 loss: 1.11355871e-06
Iter: 2200 loss: 1.11336533e-06
Iter: 2201 loss: 1.11296549e-06
Iter: 2202 loss: 1.11293525e-06
Iter: 2203 loss: 1.1121308e-06
Iter: 2204 loss: 1.11704037e-06
Iter: 2205 loss: 1.11210124e-06
Iter: 2206 loss: 1.11193367e-06
Iter: 2207 loss: 1.11176735e-06
Iter: 2208 loss: 1.11155214e-06
Iter: 2209 loss: 1.11129282e-06
Iter: 2210 loss: 1.11134182e-06
Iter: 2211 loss: 1.11103282e-06
Iter: 2212 loss: 1.11131874e-06
Iter: 2213 loss: 1.11084501e-06
Iter: 2214 loss: 1.11049201e-06
Iter: 2215 loss: 1.11075599e-06
Iter: 2216 loss: 1.11034933e-06
Iter: 2217 loss: 1.11029613e-06
Iter: 2218 loss: 1.11011786e-06
Iter: 2219 loss: 1.10999758e-06
Iter: 2220 loss: 1.11024735e-06
Iter: 2221 loss: 1.10999429e-06
Iter: 2222 loss: 1.10974838e-06
Iter: 2223 loss: 1.10936446e-06
Iter: 2224 loss: 1.11527356e-06
Iter: 2225 loss: 1.10934161e-06
Iter: 2226 loss: 1.10894507e-06
Iter: 2227 loss: 1.11104032e-06
Iter: 2228 loss: 1.1089237e-06
Iter: 2229 loss: 1.10852898e-06
Iter: 2230 loss: 1.10990652e-06
Iter: 2231 loss: 1.10839983e-06
Iter: 2232 loss: 1.10804933e-06
Iter: 2233 loss: 1.10855046e-06
Iter: 2234 loss: 1.1081022e-06
Iter: 2235 loss: 1.10760482e-06
Iter: 2236 loss: 1.10732299e-06
Iter: 2237 loss: 1.10718213e-06
Iter: 2238 loss: 1.1067217e-06
Iter: 2239 loss: 1.10955557e-06
Iter: 2240 loss: 1.10667645e-06
Iter: 2241 loss: 1.10633084e-06
Iter: 2242 loss: 1.10630162e-06
Iter: 2243 loss: 1.10615827e-06
Iter: 2244 loss: 1.10615508e-06
Iter: 2245 loss: 1.10596943e-06
Iter: 2246 loss: 1.10555436e-06
Iter: 2247 loss: 1.10563e-06
Iter: 2248 loss: 1.10539e-06
Iter: 2249 loss: 1.10525752e-06
Iter: 2250 loss: 1.10520853e-06
Iter: 2251 loss: 1.10507654e-06
Iter: 2252 loss: 1.10547319e-06
Iter: 2253 loss: 1.10497706e-06
Iter: 2254 loss: 1.1048113e-06
Iter: 2255 loss: 1.10468204e-06
Iter: 2256 loss: 1.10468352e-06
Iter: 2257 loss: 1.10448309e-06
Iter: 2258 loss: 1.10411725e-06
Iter: 2259 loss: 1.10421047e-06
Iter: 2260 loss: 1.10386395e-06
Iter: 2261 loss: 1.10381507e-06
Iter: 2262 loss: 1.10364942e-06
Iter: 2263 loss: 1.10341057e-06
Iter: 2264 loss: 1.10335748e-06
Iter: 2265 loss: 1.10305371e-06
Iter: 2266 loss: 1.10334349e-06
Iter: 2267 loss: 1.10282849e-06
Iter: 2268 loss: 1.1025968e-06
Iter: 2269 loss: 1.1026367e-06
Iter: 2270 loss: 1.10232065e-06
Iter: 2271 loss: 1.10193946e-06
Iter: 2272 loss: 1.102954e-06
Iter: 2273 loss: 1.10185852e-06
Iter: 2274 loss: 1.10159033e-06
Iter: 2275 loss: 1.10158771e-06
Iter: 2276 loss: 1.1013326e-06
Iter: 2277 loss: 1.10129213e-06
Iter: 2278 loss: 1.1011e-06
Iter: 2279 loss: 1.10081476e-06
Iter: 2280 loss: 1.10247174e-06
Iter: 2281 loss: 1.10087535e-06
Iter: 2282 loss: 1.10062513e-06
Iter: 2283 loss: 1.10068481e-06
Iter: 2284 loss: 1.100443e-06
Iter: 2285 loss: 1.10011615e-06
Iter: 2286 loss: 1.10358496e-06
Iter: 2287 loss: 1.10015162e-06
Iter: 2288 loss: 1.0997752e-06
Iter: 2289 loss: 1.09969653e-06
Iter: 2290 loss: 1.09959785e-06
Iter: 2291 loss: 1.09935718e-06
Iter: 2292 loss: 1.10200142e-06
Iter: 2293 loss: 1.09917551e-06
Iter: 2294 loss: 1.09917403e-06
Iter: 2295 loss: 1.09946416e-06
Iter: 2296 loss: 1.09901816e-06
Iter: 2297 loss: 1.09885082e-06
Iter: 2298 loss: 1.09975122e-06
Iter: 2299 loss: 1.09878533e-06
Iter: 2300 loss: 1.09865903e-06
Iter: 2301 loss: 1.09883797e-06
Iter: 2302 loss: 1.09854557e-06
Iter: 2303 loss: 1.09828113e-06
Iter: 2304 loss: 1.09932603e-06
Iter: 2305 loss: 1.0982011e-06
Iter: 2306 loss: 1.09795769e-06
Iter: 2307 loss: 1.09946109e-06
Iter: 2308 loss: 1.09790381e-06
Iter: 2309 loss: 1.09771156e-06
Iter: 2310 loss: 1.09814675e-06
Iter: 2311 loss: 1.0976039e-06
Iter: 2312 loss: 1.09753671e-06
Iter: 2313 loss: 1.09715472e-06
Iter: 2314 loss: 1.09707958e-06
Iter: 2315 loss: 1.09735163e-06
Iter: 2316 loss: 1.09693326e-06
Iter: 2317 loss: 1.09676023e-06
Iter: 2318 loss: 1.09681037e-06
Iter: 2319 loss: 1.09672476e-06
Iter: 2320 loss: 1.09656935e-06
Iter: 2321 loss: 1.09636233e-06
Iter: 2322 loss: 1.09628718e-06
Iter: 2323 loss: 1.09597488e-06
Iter: 2324 loss: 1.09598341e-06
Iter: 2325 loss: 1.09580867e-06
Iter: 2326 loss: 1.09554821e-06
Iter: 2327 loss: 1.09925736e-06
Iter: 2328 loss: 1.09555253e-06
Iter: 2329 loss: 1.09533084e-06
Iter: 2330 loss: 1.09554571e-06
Iter: 2331 loss: 1.09532152e-06
Iter: 2332 loss: 1.09482949e-06
Iter: 2333 loss: 1.09454868e-06
Iter: 2334 loss: 1.09450525e-06
Iter: 2335 loss: 1.09412156e-06
Iter: 2336 loss: 1.09525627e-06
Iter: 2337 loss: 1.09402026e-06
Iter: 2338 loss: 1.09371626e-06
Iter: 2339 loss: 1.09394318e-06
Iter: 2340 loss: 1.09350037e-06
Iter: 2341 loss: 1.09316329e-06
Iter: 2342 loss: 1.09401572e-06
Iter: 2343 loss: 1.09301891e-06
Iter: 2344 loss: 1.09272139e-06
Iter: 2345 loss: 1.09274583e-06
Iter: 2346 loss: 1.09238749e-06
Iter: 2347 loss: 1.09211032e-06
Iter: 2348 loss: 1.09502503e-06
Iter: 2349 loss: 1.0920869e-06
Iter: 2350 loss: 1.09196571e-06
Iter: 2351 loss: 1.09302414e-06
Iter: 2352 loss: 1.09181838e-06
Iter: 2353 loss: 1.0917588e-06
Iter: 2354 loss: 1.09124608e-06
Iter: 2355 loss: 1.09910491e-06
Iter: 2356 loss: 1.09131258e-06
Iter: 2357 loss: 1.09118184e-06
Iter: 2358 loss: 1.09150346e-06
Iter: 2359 loss: 1.09092582e-06
Iter: 2360 loss: 1.09065468e-06
Iter: 2361 loss: 1.09222538e-06
Iter: 2362 loss: 1.09047858e-06
Iter: 2363 loss: 1.09031464e-06
Iter: 2364 loss: 1.0925404e-06
Iter: 2365 loss: 1.09027246e-06
Iter: 2366 loss: 1.09001678e-06
Iter: 2367 loss: 1.09071482e-06
Iter: 2368 loss: 1.0899364e-06
Iter: 2369 loss: 1.08973359e-06
Iter: 2370 loss: 1.0895759e-06
Iter: 2371 loss: 1.08950758e-06
Iter: 2372 loss: 1.08909558e-06
Iter: 2373 loss: 1.08919062e-06
Iter: 2374 loss: 1.08893096e-06
Iter: 2375 loss: 1.08881954e-06
Iter: 2376 loss: 1.08877884e-06
Iter: 2377 loss: 1.08859888e-06
Iter: 2378 loss: 1.08865072e-06
Iter: 2379 loss: 1.08850304e-06
Iter: 2380 loss: 1.0881339e-06
Iter: 2381 loss: 1.08820529e-06
Iter: 2382 loss: 1.08797735e-06
Iter: 2383 loss: 1.08780705e-06
Iter: 2384 loss: 1.08784411e-06
Iter: 2385 loss: 1.08779739e-06
Iter: 2386 loss: 1.08755455e-06
Iter: 2387 loss: 1.09008829e-06
Iter: 2388 loss: 1.0875176e-06
Iter: 2389 loss: 1.08722736e-06
Iter: 2390 loss: 1.08712482e-06
Iter: 2391 loss: 1.08705979e-06
Iter: 2392 loss: 1.08674442e-06
Iter: 2393 loss: 1.08671645e-06
Iter: 2394 loss: 1.08646259e-06
Iter: 2395 loss: 1.08591655e-06
Iter: 2396 loss: 1.0901307e-06
Iter: 2397 loss: 1.08595839e-06
Iter: 2398 loss: 1.0857093e-06
Iter: 2399 loss: 1.0873157e-06
Iter: 2400 loss: 1.08562881e-06
Iter: 2401 loss: 1.08532276e-06
Iter: 2402 loss: 1.086157e-06
Iter: 2403 loss: 1.0853206e-06
Iter: 2404 loss: 1.08505412e-06
Iter: 2405 loss: 1.08635402e-06
Iter: 2406 loss: 1.08509232e-06
Iter: 2407 loss: 1.0848147e-06
Iter: 2408 loss: 1.08462348e-06
Iter: 2409 loss: 1.08465338e-06
Iter: 2410 loss: 1.08427628e-06
Iter: 2411 loss: 1.088418e-06
Iter: 2412 loss: 1.08424092e-06
Iter: 2413 loss: 1.08411916e-06
Iter: 2414 loss: 1.08403196e-06
Iter: 2415 loss: 1.08385461e-06
Iter: 2416 loss: 1.08369682e-06
Iter: 2417 loss: 1.08525217e-06
Iter: 2418 loss: 1.08370034e-06
Iter: 2419 loss: 1.08359257e-06
Iter: 2420 loss: 1.08417851e-06
Iter: 2421 loss: 1.08350832e-06
Iter: 2422 loss: 1.08328436e-06
Iter: 2423 loss: 1.0830654e-06
Iter: 2424 loss: 1.08314009e-06
Iter: 2425 loss: 1.08279642e-06
Iter: 2426 loss: 1.08267875e-06
Iter: 2427 loss: 1.08252095e-06
Iter: 2428 loss: 1.08213487e-06
Iter: 2429 loss: 1.08356426e-06
Iter: 2430 loss: 1.08200584e-06
Iter: 2431 loss: 1.08168877e-06
Iter: 2432 loss: 1.0849958e-06
Iter: 2433 loss: 1.0815636e-06
Iter: 2434 loss: 1.08135168e-06
Iter: 2435 loss: 1.08429185e-06
Iter: 2436 loss: 1.08132463e-06
Iter: 2437 loss: 1.0811417e-06
Iter: 2438 loss: 1.08134805e-06
Iter: 2439 loss: 1.08095867e-06
Iter: 2440 loss: 1.0807114e-06
Iter: 2441 loss: 1.08147606e-06
Iter: 2442 loss: 1.08058282e-06
Iter: 2443 loss: 1.08049483e-06
Iter: 2444 loss: 1.08050369e-06
Iter: 2445 loss: 1.08034169e-06
Iter: 2446 loss: 1.08008135e-06
Iter: 2447 loss: 1.08393522e-06
Iter: 2448 loss: 1.08018742e-06
Iter: 2449 loss: 1.07982885e-06
Iter: 2450 loss: 1.07976211e-06
Iter: 2451 loss: 1.07956566e-06
Iter: 2452 loss: 1.07941059e-06
Iter: 2453 loss: 1.08117308e-06
Iter: 2454 loss: 1.07938399e-06
Iter: 2455 loss: 1.07918993e-06
Iter: 2456 loss: 1.07936876e-06
Iter: 2457 loss: 1.07909318e-06
Iter: 2458 loss: 1.0788965e-06
Iter: 2459 loss: 1.0792287e-06
Iter: 2460 loss: 1.07879964e-06
Iter: 2461 loss: 1.0785966e-06
Iter: 2462 loss: 1.07847484e-06
Iter: 2463 loss: 1.07842743e-06
Iter: 2464 loss: 1.07801975e-06
Iter: 2465 loss: 1.07848155e-06
Iter: 2466 loss: 1.07771632e-06
Iter: 2467 loss: 1.07752533e-06
Iter: 2468 loss: 1.07983544e-06
Iter: 2469 loss: 1.07748792e-06
Iter: 2470 loss: 1.07718256e-06
Iter: 2471 loss: 1.08071686e-06
Iter: 2472 loss: 1.07724372e-06
Iter: 2473 loss: 1.07697736e-06
Iter: 2474 loss: 1.07686947e-06
Iter: 2475 loss: 1.07681035e-06
Iter: 2476 loss: 1.07642632e-06
Iter: 2477 loss: 1.07813662e-06
Iter: 2478 loss: 1.07637152e-06
Iter: 2479 loss: 1.07618837e-06
Iter: 2480 loss: 1.07677579e-06
Iter: 2481 loss: 1.07612425e-06
Iter: 2482 loss: 1.07589926e-06
Iter: 2483 loss: 1.07588858e-06
Iter: 2484 loss: 1.07568985e-06
Iter: 2485 loss: 1.07584924e-06
Iter: 2486 loss: 1.0757243e-06
Iter: 2487 loss: 1.07556457e-06
Iter: 2488 loss: 1.07632093e-06
Iter: 2489 loss: 1.07555854e-06
Iter: 2490 loss: 1.07530127e-06
Iter: 2491 loss: 1.07584287e-06
Iter: 2492 loss: 1.07521362e-06
Iter: 2493 loss: 1.07510209e-06
Iter: 2494 loss: 1.07491041e-06
Iter: 2495 loss: 1.07496976e-06
Iter: 2496 loss: 1.0747649e-06
Iter: 2497 loss: 1.07563676e-06
Iter: 2498 loss: 1.07474125e-06
Iter: 2499 loss: 1.07464962e-06
Iter: 2500 loss: 1.07443111e-06
Iter: 2501 loss: 1.07442895e-06
Iter: 2502 loss: 1.07426104e-06
Iter: 2503 loss: 1.07664096e-06
Iter: 2504 loss: 1.07429094e-06
Iter: 2505 loss: 1.0741212e-06
Iter: 2506 loss: 1.07398387e-06
Iter: 2507 loss: 1.073872e-06
Iter: 2508 loss: 1.07363303e-06
Iter: 2509 loss: 1.07393544e-06
Iter: 2510 loss: 1.07352992e-06
Iter: 2511 loss: 1.07348308e-06
Iter: 2512 loss: 1.0731876e-06
Iter: 2513 loss: 1.07625215e-06
Iter: 2514 loss: 1.07318306e-06
Iter: 2515 loss: 1.07280493e-06
Iter: 2516 loss: 1.07561914e-06
Iter: 2517 loss: 1.07267056e-06
Iter: 2518 loss: 1.07249798e-06
Iter: 2519 loss: 1.07372352e-06
Iter: 2520 loss: 1.07245125e-06
Iter: 2521 loss: 1.07231074e-06
Iter: 2522 loss: 1.07211349e-06
Iter: 2523 loss: 1.07202436e-06
Iter: 2524 loss: 1.07177038e-06
Iter: 2525 loss: 1.07384835e-06
Iter: 2526 loss: 1.07180779e-06
Iter: 2527 loss: 1.07157575e-06
Iter: 2528 loss: 1.07296489e-06
Iter: 2529 loss: 1.07168194e-06
Iter: 2530 loss: 1.07166079e-06
Iter: 2531 loss: 1.0712414e-06
Iter: 2532 loss: 1.07347546e-06
Iter: 2533 loss: 1.07125447e-06
Iter: 2534 loss: 1.07100539e-06
Iter: 2535 loss: 1.07476694e-06
Iter: 2536 loss: 1.07103881e-06
Iter: 2537 loss: 1.07084941e-06
Iter: 2538 loss: 1.0711467e-06
Iter: 2539 loss: 1.07079495e-06
Iter: 2540 loss: 1.0705437e-06
Iter: 2541 loss: 1.07102267e-06
Iter: 2542 loss: 1.07053086e-06
Iter: 2543 loss: 1.07035873e-06
Iter: 2544 loss: 1.07089022e-06
Iter: 2545 loss: 1.07020776e-06
Iter: 2546 loss: 1.07005451e-06
Iter: 2547 loss: 1.07025289e-06
Iter: 2548 loss: 1.06994923e-06
Iter: 2549 loss: 1.06975608e-06
Iter: 2550 loss: 1.07080507e-06
Iter: 2551 loss: 1.06972857e-06
Iter: 2552 loss: 1.06973596e-06
Iter: 2553 loss: 1.06974585e-06
Iter: 2554 loss: 1.06971879e-06
Iter: 2555 loss: 1.06975267e-06
Iter: 2556 loss: 1.06976074e-06
Iter: 2557 loss: 1.06975324e-06
Iter: 2558 loss: 1.06968719e-06
Iter: 2559 loss: 1.06975699e-06
Iter: 2560 loss: 1.06964376e-06
Iter: 2561 loss: 1.06969321e-06
Iter: 2562 loss: 1.06972743e-06
Iter: 2563 loss: 1.06973403e-06
Iter: 2564 loss: 1.06970856e-06
Iter: 2565 loss: 1.06970026e-06
Iter: 2566 loss: 1.06968093e-06
Iter: 2567 loss: 1.06968207e-06
Iter: 2568 loss: 1.0697197e-06
Iter: 2569 loss: 1.06974085e-06
Iter: 2570 loss: 1.06972345e-06
Iter: 2571 loss: 1.06973323e-06
Iter: 2572 loss: 1.0697272e-06
Iter: 2573 loss: 1.06973459e-06
Iter: 2574 loss: 1.069728e-06
Iter: 2575 loss: 1.06972971e-06
Iter: 2576 loss: 1.069728e-06
Iter: 2577 loss: 1.06972971e-06
Iter: 2578 loss: 1.069728e-06
Iter: 2579 loss: 1.06935624e-06
Iter: 2580 loss: 1.07411825e-06
Iter: 2581 loss: 1.06928269e-06
Iter: 2582 loss: 1.06910602e-06
Iter: 2583 loss: 1.06912785e-06
Iter: 2584 loss: 1.06896277e-06
Iter: 2585 loss: 1.06940763e-06
Iter: 2586 loss: 1.0689912e-06
Iter: 2587 loss: 1.068904e-06
Iter: 2588 loss: 1.06893731e-06
Iter: 2589 loss: 1.0687e-06
Iter: 2590 loss: 1.06866946e-06
Iter: 2591 loss: 1.06864923e-06
Iter: 2592 loss: 1.06857487e-06
Iter: 2593 loss: 1.06835319e-06
Iter: 2594 loss: 1.0689821e-06
Iter: 2595 loss: 1.0682985e-06
Iter: 2596 loss: 1.06813991e-06
Iter: 2597 loss: 1.06825598e-06
Iter: 2598 loss: 1.06800519e-06
Iter: 2599 loss: 1.0678358e-06
Iter: 2600 loss: 1.06777543e-06
Iter: 2601 loss: 1.06769744e-06
Iter: 2602 loss: 1.06749906e-06
Iter: 2603 loss: 1.06756886e-06
Iter: 2604 loss: 1.06739276e-06
Iter: 2605 loss: 1.0671439e-06
Iter: 2606 loss: 1.07085646e-06
Iter: 2607 loss: 1.06710968e-06
Iter: 2608 loss: 1.06688196e-06
Iter: 2609 loss: 1.06693437e-06
Iter: 2610 loss: 1.06682751e-06
Iter: 2611 loss: 1.06697951e-06
Iter: 2612 loss: 1.06686502e-06
Iter: 2613 loss: 1.066648e-06
Iter: 2614 loss: 1.06654e-06
Iter: 2615 loss: 1.06643392e-06
Iter: 2616 loss: 1.06624714e-06
Iter: 2617 loss: 1.0678981e-06
Iter: 2618 loss: 1.0662676e-06
Iter: 2619 loss: 1.06621178e-06
Iter: 2620 loss: 1.06604762e-06
Iter: 2621 loss: 1.06597759e-06
Iter: 2622 loss: 1.06574487e-06
Iter: 2623 loss: 1.06802634e-06
Iter: 2624 loss: 1.06579512e-06
Iter: 2625 loss: 1.06559833e-06
Iter: 2626 loss: 1.06557275e-06
Iter: 2627 loss: 1.06984612e-06
Iter: 2628 loss: 1.06543644e-06
Iter: 2629 loss: 1.06512755e-06
Iter: 2630 loss: 1.06554046e-06
Iter: 2631 loss: 1.06502853e-06
Iter: 2632 loss: 1.0647658e-06
Iter: 2633 loss: 1.0656164e-06
Iter: 2634 loss: 1.06472771e-06
Iter: 2635 loss: 1.06440984e-06
Iter: 2636 loss: 1.06565312e-06
Iter: 2637 loss: 1.0644751e-06
Iter: 2638 loss: 1.06423863e-06
Iter: 2639 loss: 1.06417497e-06
Iter: 2640 loss: 1.06403888e-06
Iter: 2641 loss: 1.06378468e-06
Iter: 2642 loss: 1.06543541e-06
Iter: 2643 loss: 1.0639003e-06
Iter: 2644 loss: 1.06364746e-06
Iter: 2645 loss: 1.06528978e-06
Iter: 2646 loss: 1.0636021e-06
Iter: 2647 loss: 1.06343896e-06
Iter: 2648 loss: 1.06336131e-06
Iter: 2649 loss: 1.06329617e-06
Iter: 2650 loss: 1.06313837e-06
Iter: 2651 loss: 1.06459231e-06
Iter: 2652 loss: 1.063132e-06
Iter: 2653 loss: 1.06306777e-06
Iter: 2654 loss: 1.06311404e-06
Iter: 2655 loss: 1.06295386e-06
Iter: 2656 loss: 1.06275832e-06
Iter: 2657 loss: 1.06444827e-06
Iter: 2658 loss: 1.06281141e-06
Iter: 2659 loss: 1.06277935e-06
Iter: 2660 loss: 1.06272148e-06
Iter: 2661 loss: 1.06267885e-06
Iter: 2662 loss: 1.06243363e-06
Iter: 2663 loss: 1.06250684e-06
Iter: 2664 loss: 1.06240441e-06
Iter: 2665 loss: 1.06228117e-06
Iter: 2666 loss: 1.06265622e-06
Iter: 2667 loss: 1.06230505e-06
Iter: 2668 loss: 1.06210211e-06
Iter: 2669 loss: 1.06218954e-06
Iter: 2670 loss: 1.06198888e-06
Iter: 2671 loss: 1.06186451e-06
Iter: 2672 loss: 1.0618453e-06
Iter: 2673 loss: 1.06181801e-06
Iter: 2674 loss: 1.06168466e-06
Iter: 2675 loss: 1.06248638e-06
Iter: 2676 loss: 1.06169534e-06
Iter: 2677 loss: 1.06153198e-06
Iter: 2678 loss: 1.06155028e-06
Iter: 2679 loss: 1.061479e-06
Iter: 2680 loss: 1.06142602e-06
Iter: 2681 loss: 1.06128937e-06
Iter: 2682 loss: 1.06125776e-06
Iter: 2683 loss: 1.06107041e-06
Iter: 2684 loss: 1.06312336e-06
Iter: 2685 loss: 1.06107848e-06
Iter: 2686 loss: 1.06089487e-06
Iter: 2687 loss: 1.0612149e-06
Iter: 2688 loss: 1.06098446e-06
Iter: 2689 loss: 1.06091306e-06
Iter: 2690 loss: 1.06071582e-06
Iter: 2691 loss: 1.06068046e-06
Iter: 2692 loss: 1.06057234e-06
Iter: 2693 loss: 1.06039158e-06
Iter: 2694 loss: 1.06032235e-06
Iter: 2695 loss: 1.06024902e-06
Iter: 2696 loss: 1.06025027e-06
Iter: 2697 loss: 1.06012453e-06
Iter: 2698 loss: 1.06001414e-06
Iter: 2699 loss: 1.0599789e-06
Iter: 2700 loss: 1.05970639e-06
Iter: 2701 loss: 1.0602771e-06
Iter: 2702 loss: 1.05969366e-06
Iter: 2703 loss: 1.05951904e-06
Iter: 2704 loss: 1.06072446e-06
Iter: 2705 loss: 1.05951699e-06
Iter: 2706 loss: 1.05940808e-06
Iter: 2707 loss: 1.05916081e-06
Iter: 2708 loss: 1.05912977e-06
Iter: 2709 loss: 1.05896981e-06
Iter: 2710 loss: 1.05942445e-06
Iter: 2711 loss: 1.05893139e-06
Iter: 2712 loss: 1.0587097e-06
Iter: 2713 loss: 1.05903746e-06
Iter: 2714 loss: 1.05858499e-06
Iter: 2715 loss: 1.05849756e-06
Iter: 2716 loss: 1.0595171e-06
Iter: 2717 loss: 1.05854213e-06
Iter: 2718 loss: 1.05831259e-06
Iter: 2719 loss: 1.05865593e-06
Iter: 2720 loss: 1.05832669e-06
Iter: 2721 loss: 1.05813263e-06
Iter: 2722 loss: 1.0586009e-06
Iter: 2723 loss: 1.0581515e-06
Iter: 2724 loss: 1.05790309e-06
Iter: 2725 loss: 1.05775325e-06
Iter: 2726 loss: 1.05777087e-06
Iter: 2727 loss: 1.05744743e-06
Iter: 2728 loss: 1.05865433e-06
Iter: 2729 loss: 1.05749359e-06
Iter: 2730 loss: 1.05714457e-06
Iter: 2731 loss: 1.05831896e-06
Iter: 2732 loss: 1.05704612e-06
Iter: 2733 loss: 1.05687695e-06
Iter: 2734 loss: 1.05734443e-06
Iter: 2735 loss: 1.05678475e-06
Iter: 2736 loss: 1.05668903e-06
Iter: 2737 loss: 1.05637014e-06
Iter: 2738 loss: 1.05645597e-06
Iter: 2739 loss: 1.05609786e-06
Iter: 2740 loss: 1.0573782e-06
Iter: 2741 loss: 1.05614367e-06
Iter: 2742 loss: 1.05585093e-06
Iter: 2743 loss: 1.05771278e-06
Iter: 2744 loss: 1.05581194e-06
Iter: 2745 loss: 1.0557236e-06
Iter: 2746 loss: 1.05563845e-06
Iter: 2747 loss: 1.05554307e-06
Iter: 2748 loss: 1.05518529e-06
Iter: 2749 loss: 1.0561339e-06
Iter: 2750 loss: 1.0552626e-06
Iter: 2751 loss: 1.05488107e-06
Iter: 2752 loss: 1.05487129e-06
Iter: 2753 loss: 1.05460947e-06
Iter: 2754 loss: 1.05437141e-06
Iter: 2755 loss: 1.05676543e-06
Iter: 2756 loss: 1.0545067e-06
Iter: 2757 loss: 1.05417303e-06
Iter: 2758 loss: 1.05552715e-06
Iter: 2759 loss: 1.05412948e-06
Iter: 2760 loss: 1.05394406e-06
Iter: 2761 loss: 1.05369838e-06
Iter: 2762 loss: 1.05348499e-06
Iter: 2763 loss: 1.05323488e-06
Iter: 2764 loss: 1.05346544e-06
Iter: 2765 loss: 1.05308732e-06
Iter: 2766 loss: 1.05294498e-06
Iter: 2767 loss: 1.05292179e-06
Iter: 2768 loss: 1.05282083e-06
Iter: 2769 loss: 1.05267827e-06
Iter: 2770 loss: 1.0550566e-06
Iter: 2771 loss: 1.05270317e-06
Iter: 2772 loss: 1.05241702e-06
Iter: 2773 loss: 1.05239269e-06
Iter: 2774 loss: 1.05226377e-06
Iter: 2775 loss: 1.05198706e-06
Iter: 2776 loss: 1.05292577e-06
Iter: 2777 loss: 1.05201707e-06
Iter: 2778 loss: 1.05172103e-06
Iter: 2779 loss: 1.05188326e-06
Iter: 2780 loss: 1.05147626e-06
Iter: 2781 loss: 1.05133893e-06
Iter: 2782 loss: 1.05165577e-06
Iter: 2783 loss: 1.05128038e-06
Iter: 2784 loss: 1.05115078e-06
Iter: 2785 loss: 1.05113304e-06
Iter: 2786 loss: 1.05093977e-06
Iter: 2787 loss: 1.05066056e-06
Iter: 2788 loss: 1.05031177e-06
Iter: 2789 loss: 1.05029414e-06
Iter: 2790 loss: 1.04974436e-06
Iter: 2791 loss: 1.05277809e-06
Iter: 2792 loss: 1.04971912e-06
Iter: 2793 loss: 1.04926812e-06
Iter: 2794 loss: 1.05046445e-06
Iter: 2795 loss: 1.04919013e-06
Iter: 2796 loss: 1.04866285e-06
Iter: 2797 loss: 1.05021309e-06
Iter: 2798 loss: 1.04859873e-06
Iter: 2799 loss: 1.04826256e-06
Iter: 2800 loss: 1.0482471e-06
Iter: 2801 loss: 1.04801381e-06
Iter: 2802 loss: 1.0488892e-06
Iter: 2803 loss: 1.04792241e-06
Iter: 2804 loss: 1.04772573e-06
Iter: 2805 loss: 1.04740798e-06
Iter: 2806 loss: 1.04735568e-06
Iter: 2807 loss: 1.04694061e-06
Iter: 2808 loss: 1.0475452e-06
Iter: 2809 loss: 1.04652793e-06
Iter: 2810 loss: 1.04607852e-06
Iter: 2811 loss: 1.04706226e-06
Iter: 2812 loss: 1.04589037e-06
Iter: 2813 loss: 1.04610785e-06
Iter: 2814 loss: 1.0458e-06
Iter: 2815 loss: 1.04567221e-06
Iter: 2816 loss: 1.04547814e-06
Iter: 2817 loss: 1.0454653e-06
Iter: 2818 loss: 1.0453997e-06
Iter: 2819 loss: 1.04514584e-06
Iter: 2820 loss: 1.04514515e-06
Iter: 2821 loss: 1.0448714e-06
Iter: 2822 loss: 1.04488709e-06
Iter: 2823 loss: 1.04469802e-06
Iter: 2824 loss: 1.04441915e-06
Iter: 2825 loss: 1.04459059e-06
Iter: 2826 loss: 1.04433354e-06
Iter: 2827 loss: 1.04388801e-06
Iter: 2828 loss: 1.04406433e-06
Iter: 2829 loss: 1.04369099e-06
Iter: 2830 loss: 1.04334606e-06
Iter: 2831 loss: 1.04777246e-06
Iter: 2832 loss: 1.04338267e-06
Iter: 2833 loss: 1.04317257e-06
Iter: 2834 loss: 1.04324454e-06
Iter: 2835 loss: 1.04296635e-06
Iter: 2836 loss: 1.04268076e-06
Iter: 2837 loss: 1.0431346e-06
Iter: 2838 loss: 1.04263518e-06
Iter: 2839 loss: 1.04244634e-06
Iter: 2840 loss: 1.04564322e-06
Iter: 2841 loss: 1.04241872e-06
Iter: 2842 loss: 1.04221886e-06
Iter: 2843 loss: 1.0420647e-06
Iter: 2844 loss: 1.04202411e-06
Iter: 2845 loss: 1.04179719e-06
Iter: 2846 loss: 1.04355684e-06
Iter: 2847 loss: 1.04183198e-06
Iter: 2848 loss: 1.041583e-06
Iter: 2849 loss: 1.0427018e-06
Iter: 2850 loss: 1.04160654e-06
Iter: 2851 loss: 1.04147625e-06
Iter: 2852 loss: 1.04164167e-06
Iter: 2853 loss: 1.04137723e-06
Iter: 2854 loss: 1.0412806e-06
Iter: 2855 loss: 1.04124297e-06
Iter: 2856 loss: 1.04121375e-06
Iter: 2857 loss: 1.04093965e-06
Iter: 2858 loss: 1.04150683e-06
Iter: 2859 loss: 1.0409733e-06
Iter: 2860 loss: 1.04074218e-06
Iter: 2861 loss: 1.04030767e-06
Iter: 2862 loss: 1.04621131e-06
Iter: 2863 loss: 1.04026924e-06
Iter: 2864 loss: 1.04017147e-06
Iter: 2865 loss: 1.04012474e-06
Iter: 2866 loss: 1.03989476e-06
Iter: 2867 loss: 1.04015817e-06
Iter: 2868 loss: 1.03978346e-06
Iter: 2869 loss: 1.03964044e-06
Iter: 2870 loss: 1.03955654e-06
Iter: 2871 loss: 1.03937612e-06
Iter: 2872 loss: 1.03920831e-06
Iter: 2873 loss: 1.04135529e-06
Iter: 2874 loss: 1.03917148e-06
Iter: 2875 loss: 1.03889363e-06
Iter: 2876 loss: 1.04066692e-06
Iter: 2877 loss: 1.03880359e-06
Iter: 2878 loss: 1.03870775e-06
Iter: 2879 loss: 1.03901607e-06
Iter: 2880 loss: 1.03859259e-06
Iter: 2881 loss: 1.03840443e-06
Iter: 2882 loss: 1.03845696e-06
Iter: 2883 loss: 1.03834452e-06
Iter: 2884 loss: 1.03807793e-06
Iter: 2885 loss: 1.04030516e-06
Iter: 2886 loss: 1.03800994e-06
Iter: 2887 loss: 1.03784316e-06
Iter: 2888 loss: 1.04129492e-06
Iter: 2889 loss: 1.03782884e-06
Iter: 2890 loss: 1.03759817e-06
Iter: 2891 loss: 1.03796731e-06
Iter: 2892 loss: 1.03735113e-06
Iter: 2893 loss: 1.03718503e-06
Iter: 2894 loss: 1.03721288e-06
Iter: 2895 loss: 1.03689183e-06
Iter: 2896 loss: 1.03659659e-06
Iter: 2897 loss: 1.03686898e-06
Iter: 2898 loss: 1.03648313e-06
Iter: 2899 loss: 1.03603873e-06
Iter: 2900 loss: 1.03872208e-06
Iter: 2901 loss: 1.03589377e-06
Iter: 2902 loss: 1.03543846e-06
Iter: 2903 loss: 1.03539492e-06
Iter: 2904 loss: 1.03513082e-06
Iter: 2905 loss: 1.03468881e-06
Iter: 2906 loss: 1.03729053e-06
Iter: 2907 loss: 1.03459081e-06
Iter: 2908 loss: 1.03423235e-06
Iter: 2909 loss: 1.03419791e-06
Iter: 2910 loss: 1.03410684e-06
Iter: 2911 loss: 1.03420189e-06
Iter: 2912 loss: 1.03394621e-06
Iter: 2913 loss: 1.03383377e-06
Iter: 2914 loss: 1.03387413e-06
Iter: 2915 loss: 1.03371394e-06
Iter: 2916 loss: 1.03332275e-06
Iter: 2917 loss: 1.0374639e-06
Iter: 2918 loss: 1.03330831e-06
Iter: 2919 loss: 1.0330449e-06
Iter: 2920 loss: 1.0336214e-06
Iter: 2921 loss: 1.03287664e-06
Iter: 2922 loss: 1.03255809e-06
Iter: 2923 loss: 1.0335317e-06
Iter: 2924 loss: 1.03253171e-06
Iter: 2925 loss: 1.03221601e-06
Iter: 2926 loss: 1.03301454e-06
Iter: 2927 loss: 1.03207833e-06
Iter: 2928 loss: 1.03187608e-06
Iter: 2929 loss: 1.03156276e-06
Iter: 2930 loss: 1.04088701e-06
Iter: 2931 loss: 1.03145351e-06
Iter: 2932 loss: 1.03121931e-06
Iter: 2933 loss: 1.03300101e-06
Iter: 2934 loss: 1.0312184e-06
Iter: 2935 loss: 1.03102707e-06
Iter: 2936 loss: 1.03124898e-06
Iter: 2937 loss: 1.0310298e-06
Iter: 2938 loss: 1.03089394e-06
Iter: 2939 loss: 1.03090861e-06
Iter: 2940 loss: 1.03066179e-06
Iter: 2941 loss: 1.03058278e-06
Iter: 2942 loss: 1.03048842e-06
Iter: 2943 loss: 1.03043806e-06
Iter: 2944 loss: 1.03027264e-06
Iter: 2945 loss: 1.03340642e-06
Iter: 2946 loss: 1.03029879e-06
Iter: 2947 loss: 1.03017317e-06
Iter: 2948 loss: 1.0306079e-06
Iter: 2949 loss: 1.03010257e-06
Iter: 2950 loss: 1.02990316e-06
Iter: 2951 loss: 1.02991874e-06
Iter: 2952 loss: 1.02975844e-06
Iter: 2953 loss: 1.02939953e-06
Iter: 2954 loss: 1.03249317e-06
Iter: 2955 loss: 1.02948104e-06
Iter: 2956 loss: 1.02929857e-06
Iter: 2957 loss: 1.02968522e-06
Iter: 2958 loss: 1.02922331e-06
Iter: 2959 loss: 1.02910349e-06
Iter: 2960 loss: 1.02910622e-06
Iter: 2961 loss: 1.02900594e-06
Iter: 2962 loss: 1.02881415e-06
Iter: 2963 loss: 1.02899673e-06
Iter: 2964 loss: 1.02863135e-06
Iter: 2965 loss: 1.02845354e-06
Iter: 2966 loss: 1.02918159e-06
Iter: 2967 loss: 1.02843069e-06
Iter: 2968 loss: 1.02827175e-06
Iter: 2969 loss: 1.02896229e-06
Iter: 2970 loss: 1.02815977e-06
Iter: 2971 loss: 1.02790102e-06
Iter: 2972 loss: 1.02837691e-06
Iter: 2973 loss: 1.02794945e-06
Iter: 2974 loss: 1.02770991e-06
Iter: 2975 loss: 1.02863919e-06
Iter: 2976 loss: 1.02763545e-06
Iter: 2977 loss: 1.02748515e-06
Iter: 2978 loss: 1.02753779e-06
Iter: 2979 loss: 1.02734361e-06
Iter: 2980 loss: 1.02720821e-06
Iter: 2981 loss: 1.0280836e-06
Iter: 2982 loss: 1.02717968e-06
Iter: 2983 loss: 1.02706349e-06
Iter: 2984 loss: 1.02711215e-06
Iter: 2985 loss: 1.02694128e-06
Iter: 2986 loss: 1.02664751e-06
Iter: 2987 loss: 1.02747322e-06
Iter: 2988 loss: 1.02672516e-06
Iter: 2989 loss: 1.02639478e-06
Iter: 2990 loss: 1.02628292e-06
Iter: 2991 loss: 1.02623358e-06
Iter: 2992 loss: 1.02594993e-06
Iter: 2993 loss: 1.02855472e-06
Iter: 2994 loss: 1.02594481e-06
Iter: 2995 loss: 1.02563627e-06
Iter: 2996 loss: 1.02781564e-06
Iter: 2997 loss: 1.02559852e-06
Iter: 2998 loss: 1.02556101e-06
Iter: 2999 loss: 1.02531976e-06
Iter: 3000 loss: 1.02538456e-06
Iter: 3001 loss: 1.02513809e-06
Iter: 3002 loss: 1.02592037e-06
Iter: 3003 loss: 1.02512843e-06
Iter: 3004 loss: 1.02497268e-06
Iter: 3005 loss: 1.02641957e-06
Iter: 3006 loss: 1.0249671e-06
Iter: 3007 loss: 1.02481908e-06
Iter: 3008 loss: 1.02508966e-06
Iter: 3009 loss: 1.02479942e-06
Iter: 3010 loss: 1.02459353e-06
Iter: 3011 loss: 1.02437082e-06
Iter: 3012 loss: 1.0284665e-06
Iter: 3013 loss: 1.02442459e-06
Iter: 3014 loss: 1.02413969e-06
Iter: 3015 loss: 1.02418949e-06
Iter: 3016 loss: 1.02398928e-06
Iter: 3017 loss: 1.02361116e-06
Iter: 3018 loss: 1.02733839e-06
Iter: 3019 loss: 1.02370154e-06
Iter: 3020 loss: 1.02349929e-06
Iter: 3021 loss: 1.02378579e-06
Iter: 3022 loss: 1.02337185e-06
Iter: 3023 loss: 1.02309332e-06
Iter: 3024 loss: 1.02394324e-06
Iter: 3025 loss: 1.02315778e-06
Iter: 3026 loss: 1.02286253e-06
Iter: 3027 loss: 1.02258366e-06
Iter: 3028 loss: 1.02263186e-06
Iter: 3029 loss: 1.02230297e-06
Iter: 3030 loss: 1.02508625e-06
Iter: 3031 loss: 1.02231752e-06
Iter: 3032 loss: 1.02213767e-06
Iter: 3033 loss: 1.02279773e-06
Iter: 3034 loss: 1.0220175e-06
Iter: 3035 loss: 1.02199681e-06
Iter: 3036 loss: 1.02208321e-06
Iter: 3037 loss: 1.0219801e-06
Iter: 3038 loss: 1.0218173e-06
Iter: 3039 loss: 1.02162676e-06
Iter: 3040 loss: 1.02160141e-06
Iter: 3041 loss: 1.02136084e-06
Iter: 3042 loss: 1.02147214e-06
Iter: 3043 loss: 1.02129275e-06
Iter: 3044 loss: 1.02116439e-06
Iter: 3045 loss: 1.02293313e-06
Iter: 3046 loss: 1.02105423e-06
Iter: 3047 loss: 1.02086369e-06
Iter: 3048 loss: 1.02115121e-06
Iter: 3049 loss: 1.02081879e-06
Iter: 3050 loss: 1.02047136e-06
Iter: 3051 loss: 1.02102047e-06
Iter: 3052 loss: 1.02042918e-06
Iter: 3053 loss: 1.02014724e-06
Iter: 3054 loss: 1.02232127e-06
Iter: 3055 loss: 1.02006084e-06
Iter: 3056 loss: 1.01981414e-06
Iter: 3057 loss: 1.02000706e-06
Iter: 3058 loss: 1.01968385e-06
Iter: 3059 loss: 1.01940782e-06
Iter: 3060 loss: 1.02208116e-06
Iter: 3061 loss: 1.01940043e-06
Iter: 3062 loss: 1.01918295e-06
Iter: 3063 loss: 1.02144315e-06
Iter: 3064 loss: 1.01913861e-06
Iter: 3065 loss: 1.01896183e-06
Iter: 3066 loss: 1.01895466e-06
Iter: 3067 loss: 1.018989e-06
Iter: 3068 loss: 1.01874241e-06
Iter: 3069 loss: 1.01890453e-06
Iter: 3070 loss: 1.01855721e-06
Iter: 3071 loss: 1.01850799e-06
Iter: 3072 loss: 1.01910916e-06
Iter: 3073 loss: 1.01848116e-06
Iter: 3074 loss: 1.01834041e-06
Iter: 3075 loss: 1.01836804e-06
Iter: 3076 loss: 1.0183154e-06
Iter: 3077 loss: 1.01816568e-06
Iter: 3078 loss: 1.01851788e-06
Iter: 3079 loss: 1.01806893e-06
Iter: 3080 loss: 1.01795558e-06
Iter: 3081 loss: 1.01772116e-06
Iter: 3082 loss: 1.01771695e-06
Iter: 3083 loss: 1.01755234e-06
Iter: 3084 loss: 1.02000558e-06
Iter: 3085 loss: 1.01753562e-06
Iter: 3086 loss: 1.01739579e-06
Iter: 3087 loss: 1.01741978e-06
Iter: 3088 loss: 1.01730211e-06
Iter: 3089 loss: 1.01717478e-06
Iter: 3090 loss: 1.01675607e-06
Iter: 3091 loss: 1.01664216e-06
Iter: 3092 loss: 1.01638284e-06
Iter: 3093 loss: 1.01763442e-06
Iter: 3094 loss: 1.01643582e-06
Iter: 3095 loss: 1.01619139e-06
Iter: 3096 loss: 1.0171118e-06
Iter: 3097 loss: 1.0161948e-06
Iter: 3098 loss: 1.01573949e-06
Iter: 3099 loss: 1.01697344e-06
Iter: 3100 loss: 1.0157969e-06
Iter: 3101 loss: 1.01567571e-06
Iter: 3102 loss: 1.01568594e-06
Iter: 3103 loss: 1.01564865e-06
Iter: 3104 loss: 1.01542639e-06
Iter: 3105 loss: 1.01490866e-06
Iter: 3106 loss: 1.01503463e-06
Iter: 3107 loss: 1.01466333e-06
Iter: 3108 loss: 1.01468186e-06
Iter: 3109 loss: 1.01441663e-06
Iter: 3110 loss: 1.01474848e-06
Iter: 3111 loss: 1.01431328e-06
Iter: 3112 loss: 1.01414685e-06
Iter: 3113 loss: 1.01523165e-06
Iter: 3114 loss: 1.01417254e-06
Iter: 3115 loss: 1.01394039e-06
Iter: 3116 loss: 1.01375667e-06
Iter: 3117 loss: 1.01358671e-06
Iter: 3118 loss: 1.01327271e-06
Iter: 3119 loss: 1.01698856e-06
Iter: 3120 loss: 1.01330249e-06
Iter: 3121 loss: 1.01326464e-06
Iter: 3122 loss: 1.0133441e-06
Iter: 3123 loss: 1.01326e-06
Iter: 3124 loss: 1.01299986e-06
Iter: 3125 loss: 1.0126829e-06
Iter: 3126 loss: 1.01274566e-06
Iter: 3127 loss: 1.0124802e-06
Iter: 3128 loss: 1.01372495e-06
Iter: 3129 loss: 1.01242972e-06
Iter: 3130 loss: 1.0122277e-06
Iter: 3131 loss: 1.01419221e-06
Iter: 3132 loss: 1.01228704e-06
Iter: 3133 loss: 1.01219712e-06
Iter: 3134 loss: 1.01381193e-06
Iter: 3135 loss: 1.01222247e-06
Iter: 3136 loss: 1.0120558e-06
Iter: 3137 loss: 1.01178603e-06
Iter: 3138 loss: 1.01741603e-06
Iter: 3139 loss: 1.0117335e-06
Iter: 3140 loss: 1.01148305e-06
Iter: 3141 loss: 1.0117418e-06
Iter: 3142 loss: 1.011481e-06
Iter: 3143 loss: 1.01127364e-06
Iter: 3144 loss: 1.01131e-06
Iter: 3145 loss: 1.01108583e-06
Iter: 3146 loss: 1.0113796e-06
Iter: 3147 loss: 1.01105979e-06
Iter: 3148 loss: 1.01085436e-06
Iter: 3149 loss: 1.01079081e-06
Iter: 3150 loss: 1.01083344e-06
Iter: 3151 loss: 1.01054229e-06
Iter: 3152 loss: 1.01162777e-06
Iter: 3153 loss: 1.01045555e-06
Iter: 3154 loss: 1.01027831e-06
Iter: 3155 loss: 1.01132127e-06
Iter: 3156 loss: 1.0101769e-06
Iter: 3157 loss: 1.01007504e-06
Iter: 3158 loss: 1.01007095e-06
Iter: 3159 loss: 1.00994782e-06
Iter: 3160 loss: 1.00969771e-06
Iter: 3161 loss: 1.00937677e-06
Iter: 3162 loss: 1.00936825e-06
Iter: 3163 loss: 1.00911302e-06
Iter: 3164 loss: 1.01220803e-06
Iter: 3165 loss: 1.00917032e-06
Iter: 3166 loss: 1.00892805e-06
Iter: 3167 loss: 1.00889213e-06
Iter: 3168 loss: 1.00874604e-06
Iter: 3169 loss: 1.00877583e-06
Iter: 3170 loss: 1.00870284e-06
Iter: 3171 loss: 1.00857437e-06
Iter: 3172 loss: 1.00891441e-06
Iter: 3173 loss: 1.0085347e-06
Iter: 3174 loss: 1.00843192e-06
Iter: 3175 loss: 1.00823e-06
Iter: 3176 loss: 1.01150931e-06
Iter: 3177 loss: 1.00824957e-06
Iter: 3178 loss: 1.0080621e-06
Iter: 3179 loss: 1.00860257e-06
Iter: 3180 loss: 1.00808984e-06
Iter: 3181 loss: 1.00785076e-06
Iter: 3182 loss: 1.00917055e-06
Iter: 3183 loss: 1.00783609e-06
Iter: 3184 loss: 1.00771422e-06
Iter: 3185 loss: 1.00768159e-06
Iter: 3186 loss: 1.00754266e-06
Iter: 3187 loss: 1.00735804e-06
Iter: 3188 loss: 1.0077888e-06
Iter: 3189 loss: 1.00730074e-06
Iter: 3190 loss: 1.00716966e-06
Iter: 3191 loss: 1.00761429e-06
Iter: 3192 loss: 1.00707325e-06
Iter: 3193 loss: 1.00702e-06
Iter: 3194 loss: 1.00805096e-06
Iter: 3195 loss: 1.00693376e-06
Iter: 3196 loss: 1.00674163e-06
Iter: 3197 loss: 1.00710633e-06
Iter: 3198 loss: 1.00667683e-06
Iter: 3199 loss: 1.00655916e-06
Iter: 3200 loss: 1.00626198e-06
Iter: 3201 loss: 1.00624766e-06
Iter: 3202 loss: 1.00605519e-06
Iter: 3203 loss: 1.00659884e-06
Iter: 3204 loss: 1.00605951e-06
Iter: 3205 loss: 1.00577347e-06
Iter: 3206 loss: 1.00579939e-06
Iter: 3207 loss: 1.00560828e-06
Iter: 3208 loss: 1.005885e-06
Iter: 3209 loss: 1.00553711e-06
Iter: 3210 loss: 1.00543116e-06
Iter: 3211 loss: 1.00531531e-06
Iter: 3212 loss: 1.00527882e-06
Iter: 3213 loss: 1.00509783e-06
Iter: 3214 loss: 1.00810189e-06
Iter: 3215 loss: 1.00507236e-06
Iter: 3216 loss: 1.00491252e-06
Iter: 3217 loss: 1.00483908e-06
Iter: 3218 loss: 1.0047745e-06
Iter: 3219 loss: 1.00460852e-06
Iter: 3220 loss: 1.00473085e-06
Iter: 3221 loss: 1.00448847e-06
Iter: 3222 loss: 1.00438069e-06
Iter: 3223 loss: 1.00410966e-06
Iter: 3224 loss: 1.01028024e-06
Iter: 3225 loss: 1.00412433e-06
Iter: 3226 loss: 1.00394129e-06
Iter: 3227 loss: 1.00395835e-06
Iter: 3228 loss: 1.00380748e-06
Iter: 3229 loss: 1.00371062e-06
Iter: 3230 loss: 1.00366037e-06
Iter: 3231 loss: 1.00354316e-06
Iter: 3232 loss: 1.0037179e-06
Iter: 3233 loss: 1.00347495e-06
Iter: 3234 loss: 1.00340571e-06
Iter: 3235 loss: 1.00331567e-06
Iter: 3236 loss: 1.00328793e-06
Iter: 3237 loss: 1.00322347e-06
Iter: 3238 loss: 1.00381328e-06
Iter: 3239 loss: 1.00323575e-06
Iter: 3240 loss: 1.00308159e-06
Iter: 3241 loss: 1.00311684e-06
Iter: 3242 loss: 1.00307921e-06
Iter: 3243 loss: 1.00291857e-06
Iter: 3244 loss: 1.00505338e-06
Iter: 3245 loss: 1.00295165e-06
Iter: 3246 loss: 1.0028275e-06
Iter: 3247 loss: 1.00381135e-06
Iter: 3248 loss: 1.00281034e-06
Iter: 3249 loss: 1.00264742e-06
Iter: 3250 loss: 1.0028441e-06
Iter: 3251 loss: 1.00257273e-06
Iter: 3252 loss: 1.00237742e-06
Iter: 3253 loss: 1.00229443e-06
Iter: 3254 loss: 1.00213231e-06
Iter: 3255 loss: 1.00214277e-06
Iter: 3256 loss: 1.00195825e-06
Iter: 3257 loss: 1.0018648e-06
Iter: 3258 loss: 1.00169314e-06
Iter: 3259 loss: 1.00174395e-06
Iter: 3260 loss: 1.00150817e-06
Iter: 3261 loss: 1.00181342e-06
Iter: 3262 loss: 1.00151692e-06
Iter: 3263 loss: 1.00140312e-06
Iter: 3264 loss: 1.00125908e-06
Iter: 3265 loss: 1.00117325e-06
Iter: 3266 loss: 1.00099453e-06
Iter: 3267 loss: 1.00250475e-06
Iter: 3268 loss: 1.00097895e-06
Iter: 3269 loss: 1.00087414e-06
Iter: 3270 loss: 1.00078091e-06
Iter: 3271 loss: 1.00075147e-06
Iter: 3272 loss: 1.00062903e-06
Iter: 3273 loss: 1.0008381e-06
Iter: 3274 loss: 1.00052614e-06
Iter: 3275 loss: 1.00037539e-06
Iter: 3276 loss: 1.00033481e-06
Iter: 3277 loss: 1.00029263e-06
Iter: 3278 loss: 1.00071168e-06
Iter: 3279 loss: 1.0002675e-06
Iter: 3280 loss: 1.000103e-06
Iter: 3281 loss: 1.00006309e-06
Iter: 3282 loss: 1.00002637e-06
Iter: 3283 loss: 9.99832423e-07
Iter: 3284 loss: 1.00117916e-06
Iter: 3285 loss: 9.99772169e-07
Iter: 3286 loss: 9.99633357e-07
Iter: 3287 loss: 9.99713734e-07
Iter: 3288 loss: 9.99628924e-07
Iter: 3289 loss: 9.99460781e-07
Iter: 3290 loss: 9.99481358e-07
Iter: 3291 loss: 9.99356416e-07
Iter: 3292 loss: 9.99544113e-07
Iter: 3293 loss: 9.99366648e-07
Iter: 3294 loss: 9.99244094e-07
Iter: 3295 loss: 9.99201575e-07
Iter: 3296 loss: 9.99107101e-07
Iter: 3297 loss: 9.99030931e-07
Iter: 3298 loss: 9.99621307e-07
Iter: 3299 loss: 9.99061172e-07
Iter: 3300 loss: 9.98908376e-07
Iter: 3301 loss: 9.98895e-07
Iter: 3302 loss: 9.98806e-07
Iter: 3303 loss: 9.98638598e-07
Iter: 3304 loss: 9.98888481e-07
Iter: 3305 loss: 9.98698852e-07
Iter: 3306 loss: 9.98565e-07
Iter: 3307 loss: 9.99335271e-07
Iter: 3308 loss: 9.98570613e-07
Iter: 3309 loss: 9.98403152e-07
Iter: 3310 loss: 9.99607892e-07
Iter: 3311 loss: 9.98387122e-07
Iter: 3312 loss: 9.98322207e-07
Iter: 3313 loss: 9.98127916e-07
Iter: 3314 loss: 1.00033469e-06
Iter: 3315 loss: 9.98218525e-07
Iter: 3316 loss: 9.98061296e-07
Iter: 3317 loss: 9.98505584e-07
Iter: 3318 loss: 9.97956e-07
Iter: 3319 loss: 9.97807774e-07
Iter: 3320 loss: 9.97953066e-07
Iter: 3321 loss: 9.97739562e-07
Iter: 3322 loss: 9.97542884e-07
Iter: 3323 loss: 9.97315851e-07
Iter: 3324 loss: 9.97413e-07
Iter: 3325 loss: 9.97145776e-07
Iter: 3326 loss: 9.98006726e-07
Iter: 3327 loss: 9.97158281e-07
Iter: 3328 loss: 9.96822337e-07
Iter: 3329 loss: 9.99063332e-07
Iter: 3330 loss: 9.96933636e-07
Iter: 3331 loss: 9.96677727e-07
Iter: 3332 loss: 9.97646566e-07
Iter: 3333 loss: 9.96695576e-07
Iter: 3334 loss: 9.96484232e-07
Iter: 3335 loss: 9.96259928e-07
Iter: 3336 loss: 9.96256e-07
Iter: 3337 loss: 9.95975824e-07
Iter: 3338 loss: 9.96445806e-07
Iter: 3339 loss: 9.96014933e-07
Iter: 3340 loss: 9.95747882e-07
Iter: 3341 loss: 9.9657143e-07
Iter: 3342 loss: 9.95652499e-07
Iter: 3343 loss: 9.95528239e-07
Iter: 3344 loss: 9.95428763e-07
Iter: 3345 loss: 9.95321443e-07
Iter: 3346 loss: 9.95329742e-07
Iter: 3347 loss: 9.95169557e-07
Iter: 3348 loss: 9.95136e-07
Iter: 3349 loss: 9.95059e-07
Iter: 3350 loss: 9.94998231e-07
Iter: 3351 loss: 9.94716856e-07
Iter: 3352 loss: 9.94972766e-07
Iter: 3353 loss: 9.94663196e-07
Iter: 3354 loss: 9.94416e-07
Iter: 3355 loss: 9.94477e-07
Iter: 3356 loss: 9.94291668e-07
Iter: 3357 loss: 9.94160928e-07
Iter: 3358 loss: 9.94073616e-07
Iter: 3359 loss: 9.93922185e-07
Iter: 3360 loss: 9.93912749e-07
Iter: 3361 loss: 9.93852382e-07
Iter: 3362 loss: 9.94121137e-07
Iter: 3363 loss: 9.93723916e-07
Iter: 3364 loss: 9.93598519e-07
Iter: 3365 loss: 9.93542358e-07
Iter: 3366 loss: 9.93405138e-07
Iter: 3367 loss: 9.93305775e-07
Iter: 3368 loss: 9.95254709e-07
Iter: 3369 loss: 9.93331582e-07
Iter: 3370 loss: 9.93245408e-07
Iter: 3371 loss: 9.93377398e-07
Iter: 3372 loss: 9.93222557e-07
Iter: 3373 loss: 9.93097615e-07
Iter: 3374 loss: 9.93054414e-07
Iter: 3375 loss: 9.92890591e-07
Iter: 3376 loss: 9.92764e-07
Iter: 3377 loss: 9.94449e-07
Iter: 3378 loss: 9.92735409e-07
Iter: 3379 loss: 9.92578862e-07
Iter: 3380 loss: 9.92998707e-07
Iter: 3381 loss: 9.92580908e-07
Iter: 3382 loss: 9.92340915e-07
Iter: 3383 loss: 9.92191e-07
Iter: 3384 loss: 9.92246e-07
Iter: 3385 loss: 9.91952e-07
Iter: 3386 loss: 9.9320323e-07
Iter: 3387 loss: 9.92022478e-07
Iter: 3388 loss: 9.91820798e-07
Iter: 3389 loss: 9.92351488e-07
Iter: 3390 loss: 9.91776801e-07
Iter: 3391 loss: 9.91753268e-07
Iter: 3392 loss: 9.9195745e-07
Iter: 3393 loss: 9.9158342e-07
Iter: 3394 loss: 9.91500428e-07
Iter: 3395 loss: 9.91541583e-07
Iter: 3396 loss: 9.91634e-07
Iter: 3397 loss: 9.91537377e-07
Iter: 3398 loss: 9.91306592e-07
Iter: 3399 loss: 9.92076707e-07
Iter: 3400 loss: 9.91338084e-07
Iter: 3401 loss: 9.91117076e-07
Iter: 3402 loss: 9.91578077e-07
Iter: 3403 loss: 9.91109e-07
Iter: 3404 loss: 9.90895273e-07
Iter: 3405 loss: 9.91017146e-07
Iter: 3406 loss: 9.90663125e-07
Iter: 3407 loss: 9.90472e-07
Iter: 3408 loss: 9.9111e-07
Iter: 3409 loss: 9.90494755e-07
Iter: 3410 loss: 9.90256e-07
Iter: 3411 loss: 9.90218837e-07
Iter: 3412 loss: 9.90074682e-07
Iter: 3413 loss: 9.89743512e-07
Iter: 3414 loss: 9.93448452e-07
Iter: 3415 loss: 9.89736e-07
Iter: 3416 loss: 9.89614932e-07
Iter: 3417 loss: 9.89549108e-07
Iter: 3418 loss: 9.89522732e-07
Iter: 3419 loss: 9.89300588e-07
Iter: 3420 loss: 9.89554792e-07
Iter: 3421 loss: 9.89102659e-07
Iter: 3422 loss: 9.88919e-07
Iter: 3423 loss: 9.89389264e-07
Iter: 3424 loss: 9.8882424e-07
Iter: 3425 loss: 9.88619263e-07
Iter: 3426 loss: 9.88656666e-07
Iter: 3427 loss: 9.88548095e-07
Iter: 3428 loss: 9.88735223e-07
Iter: 3429 loss: 9.88495458e-07
Iter: 3430 loss: 9.88435431e-07
Iter: 3431 loss: 9.88169631e-07
Iter: 3432 loss: 9.88175e-07
Iter: 3433 loss: 9.87986823e-07
Iter: 3434 loss: 9.87983071e-07
Iter: 3435 loss: 9.8782e-07
Iter: 3436 loss: 9.87613475e-07
Iter: 3437 loss: 9.87573799e-07
Iter: 3438 loss: 9.87578233e-07
Iter: 3439 loss: 9.87572e-07
Iter: 3440 loss: 9.87481599e-07
Iter: 3441 loss: 9.87548674e-07
Iter: 3442 loss: 9.87573458e-07
Iter: 3443 loss: 9.87501721e-07
Iter: 3444 loss: 9.87564363e-07
Iter: 3445 loss: 9.87532076e-07
Iter: 3446 loss: 9.87542e-07
Iter: 3447 loss: 9.87547537e-07
Iter: 3448 loss: 9.87569933e-07
Iter: 3449 loss: 9.87551743e-07
Iter: 3450 loss: 9.87550152e-07
Iter: 3451 loss: 9.87577778e-07
Iter: 3452 loss: 9.87571184e-07
Iter: 3453 loss: 9.87571525e-07
Iter: 3454 loss: 9.87571298e-07
Iter: 3455 loss: 9.87571184e-07
Iter: 3456 loss: 9.87579142e-07
Iter: 3457 loss: 9.87579256e-07
Iter: 3458 loss: 9.87579483e-07
Iter: 3459 loss: 9.87571866e-07
Iter: 3460 loss: 9.87571866e-07
Iter: 3461 loss: 9.87571866e-07
Iter: 3462 loss: 9.87579483e-07
Iter: 3463 loss: 9.87571866e-07
Iter: 3464 loss: 9.87134399e-07
Iter: 3465 loss: 9.9122758e-07
Iter: 3466 loss: 9.87088242e-07
Iter: 3467 loss: 9.87261387e-07
Iter: 3468 loss: 9.86921577e-07
Iter: 3469 loss: 9.86710916e-07
Iter: 3470 loss: 9.86469e-07
Iter: 3471 loss: 9.86445457e-07
Iter: 3472 loss: 9.86198074e-07
Iter: 3473 loss: 9.85970246e-07
Iter: 3474 loss: 9.85805e-07
Iter: 3475 loss: 9.85655e-07
Iter: 3476 loss: 9.86108375e-07
Iter: 3477 loss: 9.85616452e-07
Iter: 3478 loss: 9.85393e-07
Iter: 3479 loss: 9.85629413e-07
Iter: 3480 loss: 9.85355e-07
Iter: 3481 loss: 9.85188763e-07
Iter: 3482 loss: 9.85529709e-07
Iter: 3483 loss: 9.85124416e-07
Iter: 3484 loss: 9.84975e-07
Iter: 3485 loss: 9.84828375e-07
Iter: 3486 loss: 9.84838152e-07
Iter: 3487 loss: 9.84703e-07
Iter: 3488 loss: 9.84573262e-07
Iter: 3489 loss: 9.84604185e-07
Iter: 3490 loss: 9.84541884e-07
Iter: 3491 loss: 9.84602e-07
Iter: 3492 loss: 9.8457383e-07
Iter: 3493 loss: 9.84622716e-07
Iter: 3494 loss: 9.84633e-07
Iter: 3495 loss: 9.84559392e-07
Iter: 3496 loss: 9.84592361e-07
Iter: 3497 loss: 9.84607254e-07
Iter: 3498 loss: 9.84608e-07
Iter: 3499 loss: 9.84606572e-07
Iter: 3500 loss: 9.84622261e-07
Iter: 3501 loss: 9.84576559e-07
Iter: 3502 loss: 9.84583153e-07
Iter: 3503 loss: 9.84551093e-07
Iter: 3504 loss: 9.84565531e-07
Iter: 3505 loss: 9.84584631e-07
Iter: 3506 loss: 9.84565872e-07
Iter: 3507 loss: 9.84562348e-07
Iter: 3508 loss: 9.84569169e-07
Iter: 3509 loss: 9.84576332e-07
Iter: 3510 loss: 9.84575763e-07
Iter: 3511 loss: 9.84575308e-07
Iter: 3512 loss: 9.84575308e-07
Iter: 3513 loss: 9.84569169e-07
Iter: 3514 loss: 9.84575308e-07
Iter: 3515 loss: 9.84392841e-07
Iter: 3516 loss: 9.85628162e-07
Iter: 3517 loss: 9.84318376e-07
Iter: 3518 loss: 9.84174449e-07
Iter: 3519 loss: 9.84322241e-07
Iter: 3520 loss: 9.84127269e-07
Iter: 3521 loss: 9.84005169e-07
Iter: 3522 loss: 9.85494353e-07
Iter: 3523 loss: 9.83975269e-07
Iter: 3524 loss: 9.83857376e-07
Iter: 3525 loss: 9.84573489e-07
Iter: 3526 loss: 9.83901487e-07
Iter: 3527 loss: 9.83768587e-07
Iter: 3528 loss: 9.83782229e-07
Iter: 3529 loss: 9.8372584e-07
Iter: 3530 loss: 9.83610221e-07
Iter: 3531 loss: 9.83872837e-07
Iter: 3532 loss: 9.83508926e-07
Iter: 3533 loss: 9.83370683e-07
Iter: 3534 loss: 9.84867e-07
Iter: 3535 loss: 9.833783e-07
Iter: 3536 loss: 9.83341806e-07
Iter: 3537 loss: 9.8339558e-07
Iter: 3538 loss: 9.83255291e-07
Iter: 3539 loss: 9.83119435e-07
Iter: 3540 loss: 9.8307e-07
Iter: 3541 loss: 9.83070663e-07
Iter: 3542 loss: 9.82973688e-07
Iter: 3543 loss: 9.83605787e-07
Iter: 3544 loss: 9.82999e-07
Iter: 3545 loss: 9.82804e-07
Iter: 3546 loss: 9.82821462e-07
Iter: 3547 loss: 9.82713686e-07
Iter: 3548 loss: 9.82581469e-07
Iter: 3549 loss: 9.82590564e-07
Iter: 3550 loss: 9.82343295e-07
Iter: 3551 loss: 9.82170832e-07
Iter: 3552 loss: 9.83900236e-07
Iter: 3553 loss: 9.8214764e-07
Iter: 3554 loss: 9.81897074e-07
Iter: 3555 loss: 9.81698918e-07
Iter: 3556 loss: 9.81734843e-07
Iter: 3557 loss: 9.81638209e-07
Iter: 3558 loss: 9.81585231e-07
Iter: 3559 loss: 9.81482231e-07
Iter: 3560 loss: 9.81581707e-07
Iter: 3561 loss: 9.81351718e-07
Iter: 3562 loss: 9.81305e-07
Iter: 3563 loss: 9.81095e-07
Iter: 3564 loss: 9.8103294e-07
Iter: 3565 loss: 9.8093426e-07
Iter: 3566 loss: 9.82122287e-07
Iter: 3567 loss: 9.80792493e-07
Iter: 3568 loss: 9.80599907e-07
Iter: 3569 loss: 9.81051926e-07
Iter: 3570 loss: 9.80466325e-07
Iter: 3571 loss: 9.80224058e-07
Iter: 3572 loss: 9.80621394e-07
Iter: 3573 loss: 9.80209734e-07
Iter: 3574 loss: 9.8000794e-07
Iter: 3575 loss: 9.80001687e-07
Iter: 3576 loss: 9.79977472e-07
Iter: 3577 loss: 9.80067512e-07
Iter: 3578 loss: 9.79859578e-07
Iter: 3579 loss: 9.79680749e-07
Iter: 3580 loss: 9.79651077e-07
Iter: 3581 loss: 9.79522156e-07
Iter: 3582 loss: 9.79410515e-07
Iter: 3583 loss: 9.82126e-07
Iter: 3584 loss: 9.79378683e-07
Iter: 3585 loss: 9.7918587e-07
Iter: 3586 loss: 9.7920929e-07
Iter: 3587 loss: 9.7912357e-07
Iter: 3588 loss: 9.78913e-07
Iter: 3589 loss: 9.79873448e-07
Iter: 3590 loss: 9.78993398e-07
Iter: 3591 loss: 9.78812636e-07
Iter: 3592 loss: 9.8024077e-07
Iter: 3593 loss: 9.78835487e-07
Iter: 3594 loss: 9.78764319e-07
Iter: 3595 loss: 9.78861408e-07
Iter: 3596 loss: 9.78731919e-07
Iter: 3597 loss: 9.78668822e-07
Iter: 3598 loss: 9.78947128e-07
Iter: 3599 loss: 9.7865086e-07
Iter: 3600 loss: 9.7851364e-07
Iter: 3601 loss: 9.78450089e-07
Iter: 3602 loss: 9.78504318e-07
Iter: 3603 loss: 9.78298658e-07
Iter: 3604 loss: 9.79111519e-07
Iter: 3605 loss: 9.78270464e-07
Iter: 3606 loss: 9.78192929e-07
Iter: 3607 loss: 9.78258413e-07
Iter: 3608 loss: 9.78115736e-07
Iter: 3609 loss: 9.77954528e-07
Iter: 3610 loss: 9.79851e-07
Iter: 3611 loss: 9.77959189e-07
Iter: 3612 loss: 9.77916898e-07
Iter: 3613 loss: 9.7783311e-07
Iter: 3614 loss: 9.77805712e-07
Iter: 3615 loss: 9.77625291e-07
Iter: 3616 loss: 9.77753643e-07
Iter: 3617 loss: 9.77534e-07
Iter: 3618 loss: 9.77426e-07
Iter: 3619 loss: 9.7737734e-07
Iter: 3620 loss: 9.77288551e-07
Iter: 3621 loss: 9.77125524e-07
Iter: 3622 loss: 9.77082095e-07
Iter: 3623 loss: 9.77013201e-07
Iter: 3624 loss: 9.77746367e-07
Iter: 3625 loss: 9.7696693e-07
Iter: 3626 loss: 9.7691418e-07
Iter: 3627 loss: 9.7702241e-07
Iter: 3628 loss: 9.76831529e-07
Iter: 3629 loss: 9.76736715e-07
Iter: 3630 loss: 9.76783213e-07
Iter: 3631 loss: 9.7675138e-07
Iter: 3632 loss: 9.76421e-07
Iter: 3633 loss: 9.76541742e-07
Iter: 3634 loss: 9.76384399e-07
Iter: 3635 loss: 9.76198294e-07
Iter: 3636 loss: 9.77047648e-07
Iter: 3637 loss: 9.76146225e-07
Iter: 3638 loss: 9.75980356e-07
Iter: 3639 loss: 9.75958073e-07
Iter: 3640 loss: 9.75944e-07
Iter: 3641 loss: 9.75641569e-07
Iter: 3642 loss: 9.7602674e-07
Iter: 3643 loss: 9.75529701e-07
Iter: 3644 loss: 9.753943e-07
Iter: 3645 loss: 9.76021738e-07
Iter: 3646 loss: 9.75311082e-07
Iter: 3647 loss: 9.75157263e-07
Iter: 3648 loss: 9.75471721e-07
Iter: 3649 loss: 9.75120088e-07
Iter: 3650 loss: 9.74804493e-07
Iter: 3651 loss: 9.7514237e-07
Iter: 3652 loss: 9.74824e-07
Iter: 3653 loss: 9.74504e-07
Iter: 3654 loss: 9.76072101e-07
Iter: 3655 loss: 9.74498903e-07
Iter: 3656 loss: 9.74335308e-07
Iter: 3657 loss: 9.74316777e-07
Iter: 3658 loss: 9.74288241e-07
Iter: 3659 loss: 9.74323939e-07
Iter: 3660 loss: 9.74230375e-07
Iter: 3661 loss: 9.74138516e-07
Iter: 3662 loss: 9.74139652e-07
Iter: 3663 loss: 9.73941724e-07
Iter: 3664 loss: 9.74000613e-07
Iter: 3665 loss: 9.73963324e-07
Iter: 3666 loss: 9.73932e-07
Iter: 3667 loss: 9.73859187e-07
Iter: 3668 loss: 9.73911369e-07
Iter: 3669 loss: 9.73927513e-07
Iter: 3670 loss: 9.73937631e-07
Iter: 3671 loss: 9.73941383e-07
Iter: 3672 loss: 9.73949113e-07
Iter: 3673 loss: 9.73983788e-07
Iter: 3674 loss: 9.73988449e-07
Iter: 3675 loss: 9.7398015e-07
Iter: 3676 loss: 9.73933425e-07
Iter: 3677 loss: 9.73904434e-07
Iter: 3678 loss: 9.73954684e-07
Iter: 3679 loss: 9.7394593e-07
Iter: 3680 loss: 9.7392774e-07
Iter: 3681 loss: 9.73956503e-07
Iter: 3682 loss: 9.73946499e-07
Iter: 3683 loss: 9.73939564e-07
Iter: 3684 loss: 9.73946271e-07
Iter: 3685 loss: 9.73941724e-07
Iter: 3686 loss: 9.73943315e-07
Iter: 3687 loss: 9.73941837e-07
Iter: 3688 loss: 9.73942292e-07
Iter: 3689 loss: 9.73942633e-07
Iter: 3690 loss: 9.73943315e-07
Iter: 3691 loss: 9.73632268e-07
Iter: 3692 loss: 9.75440685e-07
Iter: 3693 loss: 9.73665806e-07
Iter: 3694 loss: 9.73533702e-07
Iter: 3695 loss: 9.73400802e-07
Iter: 3696 loss: 9.73343163e-07
Iter: 3697 loss: 9.73130796e-07
Iter: 3698 loss: 9.73569058e-07
Iter: 3699 loss: 9.73055194e-07
Iter: 3700 loss: 9.72898533e-07
Iter: 3701 loss: 9.73611e-07
Iter: 3702 loss: 9.72869316e-07
Iter: 3703 loss: 9.72787575e-07
Iter: 3704 loss: 9.73008696e-07
Iter: 3705 loss: 9.72639555e-07
Iter: 3706 loss: 9.72435e-07
Iter: 3707 loss: 9.72618636e-07
Iter: 3708 loss: 9.72419457e-07
Iter: 3709 loss: 9.72156e-07
Iter: 3710 loss: 9.74933414e-07
Iter: 3711 loss: 9.72279508e-07
Iter: 3712 loss: 9.72282351e-07
Iter: 3713 loss: 9.72179805e-07
Iter: 3714 loss: 9.72192424e-07
Iter: 3715 loss: 9.72182193e-07
Iter: 3716 loss: 9.72194e-07
Iter: 3717 loss: 9.72266776e-07
Iter: 3718 loss: 9.72215503e-07
Iter: 3719 loss: 9.72211637e-07
Iter: 3720 loss: 9.72202429e-07
Iter: 3721 loss: 9.72205157e-07
Iter: 3722 loss: 9.72216299e-07
Iter: 3723 loss: 9.72209932e-07
Iter: 3724 loss: 9.72188e-07
Iter: 3725 loss: 9.72156272e-07
Iter: 3726 loss: 9.72172302e-07
Iter: 3727 loss: 9.72192424e-07
Iter: 3728 loss: 9.72170596e-07
Iter: 3729 loss: 9.72174121e-07
Iter: 3730 loss: 9.72179691e-07
Iter: 3731 loss: 9.72183e-07
Iter: 3732 loss: 9.72181624e-07
Iter: 3733 loss: 9.72183e-07
Iter: 3734 loss: 9.72181283e-07
Iter: 3735 loss: 9.72179919e-07
Iter: 3736 loss: 9.72181e-07
Iter: 3737 loss: 9.7218e-07
Iter: 3738 loss: 9.72181169e-07
Iter: 3739 loss: 9.72181e-07
Iter: 3740 loss: 9.72181e-07
Iter: 3741 loss: 9.7218e-07
Iter: 3742 loss: 9.72181e-07
Iter: 3743 loss: 9.7218e-07
Iter: 3744 loss: 9.72181e-07
Iter: 3745 loss: 9.72181e-07
Iter: 3746 loss: 9.7218e-07
Iter: 3747 loss: 9.7218e-07
Iter: 3748 loss: 9.7218e-07
Iter: 3749 loss: 9.72181e-07
Iter: 3750 loss: 9.74508339e-07
Iter: 3751 loss: 9.72196744e-07
Iter: 3752 loss: 9.72152179e-07
Iter: 3753 loss: 9.72101134e-07
Iter: 3754 loss: 9.72412408e-07
Iter: 3755 loss: 9.72084308e-07
Iter: 3756 loss: 9.71999e-07
Iter: 3757 loss: 9.72220164e-07
Iter: 3758 loss: 9.71895361e-07
Iter: 3759 loss: 9.71810891e-07
Iter: 3760 loss: 9.71957e-07
Iter: 3761 loss: 9.71766667e-07
Iter: 3762 loss: 9.71664122e-07
Iter: 3763 loss: 9.71759505e-07
Iter: 3764 loss: 9.71471763e-07
Iter: 3765 loss: 9.71554869e-07
Iter: 3766 loss: 9.71561576e-07
Iter: 3767 loss: 9.71533382e-07
Iter: 3768 loss: 9.71535542e-07
Iter: 3769 loss: 9.71477675e-07
Iter: 3770 loss: 9.71515306e-07
Iter: 3771 loss: 9.71576e-07
Iter: 3772 loss: 9.71504e-07
Iter: 3773 loss: 9.71562258e-07
Iter: 3774 loss: 9.71534291e-07
Iter: 3775 loss: 9.71574309e-07
Iter: 3776 loss: 9.71529403e-07
Iter: 3777 loss: 9.71500754e-07
Iter: 3778 loss: 9.71498935e-07
Iter: 3779 loss: 9.71482e-07
Iter: 3780 loss: 9.71480858e-07
Iter: 3781 loss: 9.71469262e-07
Iter: 3782 loss: 9.71466079e-07
Iter: 3783 loss: 9.71471e-07
Iter: 3784 loss: 9.71476197e-07
Iter: 3785 loss: 9.71474719e-07
Iter: 3786 loss: 9.71473582e-07
Iter: 3787 loss: 9.71470399e-07
Iter: 3788 loss: 9.71474e-07
Iter: 3789 loss: 9.71474492e-07
Iter: 3790 loss: 9.71470399e-07
Iter: 3791 loss: 9.71474492e-07
Iter: 3792 loss: 9.71470399e-07
Iter: 3793 loss: 9.71474492e-07
Iter: 3794 loss: 9.71470399e-07
Iter: 3795 loss: 9.71470399e-07
Iter: 3796 loss: 9.71474492e-07
Iter: 3797 loss: 9.71474492e-07
Iter: 3798 loss: 9.71470399e-07
Iter: 3799 loss: 9.71474492e-07
Iter: 3800 loss: 9.71474492e-07
Iter: 3801 loss: 9.71470399e-07
Iter: 3802 loss: 9.71474492e-07
Iter: 3803 loss: 9.71474492e-07
Iter: 3804 loss: 9.71470399e-07
Iter: 3805 loss: 9.71474492e-07
Iter: 3806 loss: 1.16737806e-06
Iter: 3807 loss: 9.71578e-07
Iter: 3808 loss: 9.71562258e-07
Iter: 3809 loss: 9.71488589e-07
Iter: 3810 loss: 9.71569307e-07
Iter: 3811 loss: 9.71537816e-07
Iter: 3812 loss: 9.71557256e-07
Iter: 3813 loss: 9.71529175e-07
Iter: 3814 loss: 9.71512463e-07
Iter: 3815 loss: 9.71516e-07
Iter: 3816 loss: 9.71475629e-07
Iter: 3817 loss: 9.71501322e-07
Iter: 3818 loss: 9.7148029e-07
Iter: 3819 loss: 9.71459372e-07
Iter: 3820 loss: 9.71476766e-07
Iter: 3821 loss: 9.71467216e-07
Iter: 3822 loss: 9.71476766e-07
Iter: 3823 loss: 9.71477675e-07
Iter: 3824 loss: 9.71466761e-07
Iter: 3825 loss: 9.71468e-07
Iter: 3826 loss: 9.71469376e-07
Iter: 3827 loss: 9.71477675e-07
Iter: 3828 loss: 9.71477675e-07
Iter: 3829 loss: 9.71477675e-07
Iter: 3830 loss: 9.71477789e-07
Iter: 3831 loss: 9.71478e-07
Iter: 3832 loss: 9.71477789e-07
Iter: 3833 loss: 9.71477789e-07
Iter: 3834 loss: 9.71477789e-07
Iter: 3835 loss: 9.71469376e-07
Iter: 3836 loss: 9.71477789e-07
Iter: 3837 loss: 9.71469376e-07
Iter: 3838 loss: 9.71477789e-07
Iter: 3839 loss: 9.71477789e-07
Iter: 3840 loss: 9.71469376e-07
Iter: 3841 loss: 9.71469376e-07
Iter: 3842 loss: 9.71469376e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_4000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_4000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaec065378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaec0c0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaec0a9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaec1686a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaec168510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaec168730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaec168620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa21b78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa21b72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa21561e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa2103950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa212b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa212b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa20ce2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa2156ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa2156bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa20a77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7c115f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7c11ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbaa20a7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7c0da488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7c0f72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7c0806a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7c0aaf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7c045598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7427ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7c06c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7427f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba741e81e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba741ef0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba741d9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba741b31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba741c26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba741639d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba7412a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fba74123f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.70745833e-05
Iter: 2 loss: 0.000443084136
Iter: 3 loss: 4.31433509e-05
Iter: 4 loss: 3.14891804e-05
Iter: 5 loss: 5.13615742e-05
Iter: 6 loss: 2.63260354e-05
Iter: 7 loss: 2.05494325e-05
Iter: 8 loss: 3.93659357e-05
Iter: 9 loss: 1.89410566e-05
Iter: 10 loss: 1.55448051e-05
Iter: 11 loss: 2.81980829e-05
Iter: 12 loss: 1.47188775e-05
Iter: 13 loss: 1.19160104e-05
Iter: 14 loss: 2.12063533e-05
Iter: 15 loss: 1.11385461e-05
Iter: 16 loss: 1.01171809e-05
Iter: 17 loss: 1.13882179e-05
Iter: 18 loss: 9.58801684e-06
Iter: 19 loss: 8.4186e-06
Iter: 20 loss: 9.91850902e-06
Iter: 21 loss: 7.81993276e-06
Iter: 22 loss: 7.03773958e-06
Iter: 23 loss: 1.28341744e-05
Iter: 24 loss: 6.97359701e-06
Iter: 25 loss: 6.50745142e-06
Iter: 26 loss: 1.04327901e-05
Iter: 27 loss: 6.48092555e-06
Iter: 28 loss: 6.11659e-06
Iter: 29 loss: 5.81479935e-06
Iter: 30 loss: 5.7098855e-06
Iter: 31 loss: 5.47340369e-06
Iter: 32 loss: 5.47211584e-06
Iter: 33 loss: 5.29525414e-06
Iter: 34 loss: 5.22109576e-06
Iter: 35 loss: 5.1284178e-06
Iter: 36 loss: 5.81164204e-06
Iter: 37 loss: 5.0777262e-06
Iter: 38 loss: 5.05177559e-06
Iter: 39 loss: 4.99397447e-06
Iter: 40 loss: 5.81699351e-06
Iter: 41 loss: 4.99097268e-06
Iter: 42 loss: 4.89752711e-06
Iter: 43 loss: 4.85891724e-06
Iter: 44 loss: 4.8094239e-06
Iter: 45 loss: 4.69889846e-06
Iter: 46 loss: 4.6988589e-06
Iter: 47 loss: 4.61412856e-06
Iter: 48 loss: 4.61394666e-06
Iter: 49 loss: 4.54616338e-06
Iter: 50 loss: 4.43732642e-06
Iter: 51 loss: 4.59186276e-06
Iter: 52 loss: 4.38425195e-06
Iter: 53 loss: 4.26592942e-06
Iter: 54 loss: 4.74305125e-06
Iter: 55 loss: 4.23980782e-06
Iter: 56 loss: 4.15450313e-06
Iter: 57 loss: 4.18463969e-06
Iter: 58 loss: 4.09442964e-06
Iter: 59 loss: 3.99308601e-06
Iter: 60 loss: 4.16667262e-06
Iter: 61 loss: 3.94756125e-06
Iter: 62 loss: 3.85411522e-06
Iter: 63 loss: 4.55792315e-06
Iter: 64 loss: 3.84659279e-06
Iter: 65 loss: 3.76780372e-06
Iter: 66 loss: 4.26858696e-06
Iter: 67 loss: 3.75888385e-06
Iter: 68 loss: 3.70171847e-06
Iter: 69 loss: 3.73173748e-06
Iter: 70 loss: 3.6638894e-06
Iter: 71 loss: 3.72788236e-06
Iter: 72 loss: 3.64821108e-06
Iter: 73 loss: 3.63247773e-06
Iter: 74 loss: 3.59226988e-06
Iter: 75 loss: 3.93695882e-06
Iter: 76 loss: 3.58567581e-06
Iter: 77 loss: 3.54120039e-06
Iter: 78 loss: 3.5388e-06
Iter: 79 loss: 3.50494156e-06
Iter: 80 loss: 3.45007265e-06
Iter: 81 loss: 3.45010949e-06
Iter: 82 loss: 3.42479734e-06
Iter: 83 loss: 3.43716965e-06
Iter: 84 loss: 3.40773022e-06
Iter: 85 loss: 3.37958318e-06
Iter: 86 loss: 3.43016109e-06
Iter: 87 loss: 3.36742278e-06
Iter: 88 loss: 3.33636e-06
Iter: 89 loss: 3.35842174e-06
Iter: 90 loss: 3.31733099e-06
Iter: 91 loss: 3.28405395e-06
Iter: 92 loss: 3.40246606e-06
Iter: 93 loss: 3.27558791e-06
Iter: 94 loss: 3.24490702e-06
Iter: 95 loss: 3.26523605e-06
Iter: 96 loss: 3.22547953e-06
Iter: 97 loss: 3.18619254e-06
Iter: 98 loss: 3.40048518e-06
Iter: 99 loss: 3.18046841e-06
Iter: 100 loss: 3.15313491e-06
Iter: 101 loss: 3.17523518e-06
Iter: 102 loss: 3.13672717e-06
Iter: 103 loss: 3.09736765e-06
Iter: 104 loss: 3.41430609e-06
Iter: 105 loss: 3.09512711e-06
Iter: 106 loss: 3.09669304e-06
Iter: 107 loss: 3.08307062e-06
Iter: 108 loss: 3.0753481e-06
Iter: 109 loss: 3.05426056e-06
Iter: 110 loss: 3.16502337e-06
Iter: 111 loss: 3.0475212e-06
Iter: 112 loss: 3.02788294e-06
Iter: 113 loss: 3.02594435e-06
Iter: 114 loss: 3.01156774e-06
Iter: 115 loss: 2.98978193e-06
Iter: 116 loss: 2.98878422e-06
Iter: 117 loss: 2.98063765e-06
Iter: 118 loss: 2.97269344e-06
Iter: 119 loss: 2.97114457e-06
Iter: 120 loss: 2.95177324e-06
Iter: 121 loss: 2.95786276e-06
Iter: 122 loss: 2.93842231e-06
Iter: 123 loss: 2.91953893e-06
Iter: 124 loss: 2.97376801e-06
Iter: 125 loss: 2.91370952e-06
Iter: 126 loss: 2.89800255e-06
Iter: 127 loss: 2.92914615e-06
Iter: 128 loss: 2.89198761e-06
Iter: 129 loss: 2.86804334e-06
Iter: 130 loss: 2.87368357e-06
Iter: 131 loss: 2.8507377e-06
Iter: 132 loss: 2.82680458e-06
Iter: 133 loss: 2.93640278e-06
Iter: 134 loss: 2.82205383e-06
Iter: 135 loss: 2.80013296e-06
Iter: 136 loss: 2.84713724e-06
Iter: 137 loss: 2.79150208e-06
Iter: 138 loss: 2.77822392e-06
Iter: 139 loss: 2.77805748e-06
Iter: 140 loss: 2.77008144e-06
Iter: 141 loss: 2.76967239e-06
Iter: 142 loss: 2.76644528e-06
Iter: 143 loss: 2.75714797e-06
Iter: 144 loss: 2.81144253e-06
Iter: 145 loss: 2.7547926e-06
Iter: 146 loss: 2.74433887e-06
Iter: 147 loss: 2.7933047e-06
Iter: 148 loss: 2.74260947e-06
Iter: 149 loss: 2.73440287e-06
Iter: 150 loss: 2.74825584e-06
Iter: 151 loss: 2.73055e-06
Iter: 152 loss: 2.72306443e-06
Iter: 153 loss: 2.82393898e-06
Iter: 154 loss: 2.72288571e-06
Iter: 155 loss: 2.71667136e-06
Iter: 156 loss: 2.71596969e-06
Iter: 157 loss: 2.71100043e-06
Iter: 158 loss: 2.70321107e-06
Iter: 159 loss: 2.75234061e-06
Iter: 160 loss: 2.70223222e-06
Iter: 161 loss: 2.69592897e-06
Iter: 162 loss: 2.68423582e-06
Iter: 163 loss: 2.95479481e-06
Iter: 164 loss: 2.68438134e-06
Iter: 165 loss: 2.67024416e-06
Iter: 166 loss: 2.70400824e-06
Iter: 167 loss: 2.66516236e-06
Iter: 168 loss: 2.65496033e-06
Iter: 169 loss: 2.71765134e-06
Iter: 170 loss: 2.65347489e-06
Iter: 171 loss: 2.64096752e-06
Iter: 172 loss: 2.65627682e-06
Iter: 173 loss: 2.63435231e-06
Iter: 174 loss: 2.62400067e-06
Iter: 175 loss: 2.68408303e-06
Iter: 176 loss: 2.62251024e-06
Iter: 177 loss: 2.62735693e-06
Iter: 178 loss: 2.61909554e-06
Iter: 179 loss: 2.61724904e-06
Iter: 180 loss: 2.61111745e-06
Iter: 181 loss: 2.61203832e-06
Iter: 182 loss: 2.60508887e-06
Iter: 183 loss: 2.59350736e-06
Iter: 184 loss: 2.65176686e-06
Iter: 185 loss: 2.59151216e-06
Iter: 186 loss: 2.58361115e-06
Iter: 187 loss: 2.62311687e-06
Iter: 188 loss: 2.58231557e-06
Iter: 189 loss: 2.57518059e-06
Iter: 190 loss: 2.59862304e-06
Iter: 191 loss: 2.57313673e-06
Iter: 192 loss: 2.5638285e-06
Iter: 193 loss: 2.58087721e-06
Iter: 194 loss: 2.55996292e-06
Iter: 195 loss: 2.55411669e-06
Iter: 196 loss: 2.58012096e-06
Iter: 197 loss: 2.55291661e-06
Iter: 198 loss: 2.54636598e-06
Iter: 199 loss: 2.53861117e-06
Iter: 200 loss: 2.53787266e-06
Iter: 201 loss: 2.5246743e-06
Iter: 202 loss: 2.53125199e-06
Iter: 203 loss: 2.51588085e-06
Iter: 204 loss: 2.50475296e-06
Iter: 205 loss: 2.55021928e-06
Iter: 206 loss: 2.50229868e-06
Iter: 207 loss: 2.49134564e-06
Iter: 208 loss: 2.53872622e-06
Iter: 209 loss: 2.48894935e-06
Iter: 210 loss: 2.48336414e-06
Iter: 211 loss: 2.48342485e-06
Iter: 212 loss: 2.47933531e-06
Iter: 213 loss: 2.47941125e-06
Iter: 214 loss: 2.47796834e-06
Iter: 215 loss: 2.47332764e-06
Iter: 216 loss: 2.47372873e-06
Iter: 217 loss: 2.46867785e-06
Iter: 218 loss: 2.46063087e-06
Iter: 219 loss: 2.50692574e-06
Iter: 220 loss: 2.45934689e-06
Iter: 221 loss: 2.45292472e-06
Iter: 222 loss: 2.50725816e-06
Iter: 223 loss: 2.45252636e-06
Iter: 224 loss: 2.44870125e-06
Iter: 225 loss: 2.47336538e-06
Iter: 226 loss: 2.44820694e-06
Iter: 227 loss: 2.44353328e-06
Iter: 228 loss: 2.44142097e-06
Iter: 229 loss: 2.43905106e-06
Iter: 230 loss: 2.43350223e-06
Iter: 231 loss: 2.45467163e-06
Iter: 232 loss: 2.43225259e-06
Iter: 233 loss: 2.42691567e-06
Iter: 234 loss: 2.44035186e-06
Iter: 235 loss: 2.42492797e-06
Iter: 236 loss: 2.41955581e-06
Iter: 237 loss: 2.42029319e-06
Iter: 238 loss: 2.41559837e-06
Iter: 239 loss: 2.40862596e-06
Iter: 240 loss: 2.41865678e-06
Iter: 241 loss: 2.40524741e-06
Iter: 242 loss: 2.39782e-06
Iter: 243 loss: 2.39473184e-06
Iter: 244 loss: 2.39106453e-06
Iter: 245 loss: 2.39843098e-06
Iter: 246 loss: 2.38769871e-06
Iter: 247 loss: 2.3839325e-06
Iter: 248 loss: 2.38590792e-06
Iter: 249 loss: 2.38157259e-06
Iter: 250 loss: 2.37896302e-06
Iter: 251 loss: 2.37399581e-06
Iter: 252 loss: 2.47930484e-06
Iter: 253 loss: 2.3740763e-06
Iter: 254 loss: 2.36885512e-06
Iter: 255 loss: 2.38077746e-06
Iter: 256 loss: 2.36680853e-06
Iter: 257 loss: 2.36216374e-06
Iter: 258 loss: 2.42943474e-06
Iter: 259 loss: 2.36235246e-06
Iter: 260 loss: 2.35963216e-06
Iter: 261 loss: 2.37234258e-06
Iter: 262 loss: 2.35899961e-06
Iter: 263 loss: 2.35537254e-06
Iter: 264 loss: 2.35178118e-06
Iter: 265 loss: 2.35118955e-06
Iter: 266 loss: 2.34605886e-06
Iter: 267 loss: 2.36869892e-06
Iter: 268 loss: 2.34498702e-06
Iter: 269 loss: 2.34013601e-06
Iter: 270 loss: 2.35268772e-06
Iter: 271 loss: 2.33860419e-06
Iter: 272 loss: 2.33360288e-06
Iter: 273 loss: 2.33515766e-06
Iter: 274 loss: 2.33001174e-06
Iter: 275 loss: 2.32524985e-06
Iter: 276 loss: 2.35178572e-06
Iter: 277 loss: 2.32463321e-06
Iter: 278 loss: 2.32118555e-06
Iter: 279 loss: 2.32091793e-06
Iter: 280 loss: 2.3184225e-06
Iter: 281 loss: 2.32194679e-06
Iter: 282 loss: 2.31703848e-06
Iter: 283 loss: 2.31529066e-06
Iter: 284 loss: 2.31153354e-06
Iter: 285 loss: 2.3656421e-06
Iter: 286 loss: 2.31131935e-06
Iter: 287 loss: 2.30914793e-06
Iter: 288 loss: 2.30706951e-06
Iter: 289 loss: 2.30663682e-06
Iter: 290 loss: 2.30236628e-06
Iter: 291 loss: 2.30677188e-06
Iter: 292 loss: 2.30016167e-06
Iter: 293 loss: 2.29523516e-06
Iter: 294 loss: 2.34320578e-06
Iter: 295 loss: 2.29524608e-06
Iter: 296 loss: 2.29244984e-06
Iter: 297 loss: 2.32997149e-06
Iter: 298 loss: 2.29263082e-06
Iter: 299 loss: 2.29100556e-06
Iter: 300 loss: 2.28929093e-06
Iter: 301 loss: 2.28903332e-06
Iter: 302 loss: 2.28558861e-06
Iter: 303 loss: 2.28326508e-06
Iter: 304 loss: 2.28176077e-06
Iter: 305 loss: 2.27769601e-06
Iter: 306 loss: 2.29074431e-06
Iter: 307 loss: 2.27688452e-06
Iter: 308 loss: 2.27168198e-06
Iter: 309 loss: 2.27766805e-06
Iter: 310 loss: 2.2688796e-06
Iter: 311 loss: 2.26299858e-06
Iter: 312 loss: 2.27258397e-06
Iter: 313 loss: 2.26016937e-06
Iter: 314 loss: 2.2569302e-06
Iter: 315 loss: 2.29851321e-06
Iter: 316 loss: 2.25687336e-06
Iter: 317 loss: 2.2534141e-06
Iter: 318 loss: 2.28461545e-06
Iter: 319 loss: 2.25308895e-06
Iter: 320 loss: 2.25145209e-06
Iter: 321 loss: 2.24656515e-06
Iter: 322 loss: 2.27555461e-06
Iter: 323 loss: 2.24519886e-06
Iter: 324 loss: 2.24087921e-06
Iter: 325 loss: 2.26790212e-06
Iter: 326 loss: 2.24028213e-06
Iter: 327 loss: 2.23662983e-06
Iter: 328 loss: 2.26187626e-06
Iter: 329 loss: 2.23655479e-06
Iter: 330 loss: 2.23348934e-06
Iter: 331 loss: 2.25051349e-06
Iter: 332 loss: 2.23315283e-06
Iter: 333 loss: 2.23024722e-06
Iter: 334 loss: 2.24174619e-06
Iter: 335 loss: 2.2296731e-06
Iter: 336 loss: 2.22767835e-06
Iter: 337 loss: 2.22619406e-06
Iter: 338 loss: 2.22549488e-06
Iter: 339 loss: 2.22155086e-06
Iter: 340 loss: 2.2338279e-06
Iter: 341 loss: 2.2203717e-06
Iter: 342 loss: 2.21799201e-06
Iter: 343 loss: 2.22584845e-06
Iter: 344 loss: 2.21755613e-06
Iter: 345 loss: 2.21499681e-06
Iter: 346 loss: 2.21767232e-06
Iter: 347 loss: 2.21360119e-06
Iter: 348 loss: 2.21027494e-06
Iter: 349 loss: 2.2127947e-06
Iter: 350 loss: 2.20822903e-06
Iter: 351 loss: 2.20559241e-06
Iter: 352 loss: 2.2168424e-06
Iter: 353 loss: 2.20509173e-06
Iter: 354 loss: 2.20624224e-06
Iter: 355 loss: 2.20415268e-06
Iter: 356 loss: 2.20355423e-06
Iter: 357 loss: 2.20162951e-06
Iter: 358 loss: 2.19870299e-06
Iter: 359 loss: 2.19836875e-06
Iter: 360 loss: 2.19563526e-06
Iter: 361 loss: 2.19542812e-06
Iter: 362 loss: 2.19336266e-06
Iter: 363 loss: 2.2119093e-06
Iter: 364 loss: 2.19324443e-06
Iter: 365 loss: 2.19175172e-06
Iter: 366 loss: 2.20709649e-06
Iter: 367 loss: 2.19159415e-06
Iter: 368 loss: 2.19019785e-06
Iter: 369 loss: 2.18767786e-06
Iter: 370 loss: 2.18762489e-06
Iter: 371 loss: 2.18527907e-06
Iter: 372 loss: 2.20438392e-06
Iter: 373 loss: 2.18514037e-06
Iter: 374 loss: 2.18246873e-06
Iter: 375 loss: 2.18608238e-06
Iter: 376 loss: 2.18134778e-06
Iter: 377 loss: 2.17876459e-06
Iter: 378 loss: 2.18427726e-06
Iter: 379 loss: 2.17771276e-06
Iter: 380 loss: 2.17513889e-06
Iter: 381 loss: 2.17678894e-06
Iter: 382 loss: 2.17343791e-06
Iter: 383 loss: 2.16994113e-06
Iter: 384 loss: 2.17326124e-06
Iter: 385 loss: 2.16814055e-06
Iter: 386 loss: 2.1686e-06
Iter: 387 loss: 2.16705484e-06
Iter: 388 loss: 2.16587182e-06
Iter: 389 loss: 2.1628116e-06
Iter: 390 loss: 2.17832485e-06
Iter: 391 loss: 2.16182525e-06
Iter: 392 loss: 2.1588603e-06
Iter: 393 loss: 2.15852469e-06
Iter: 394 loss: 2.1564033e-06
Iter: 395 loss: 2.1531846e-06
Iter: 396 loss: 2.18926925e-06
Iter: 397 loss: 2.1532037e-06
Iter: 398 loss: 2.15093132e-06
Iter: 399 loss: 2.16226567e-06
Iter: 400 loss: 2.15047612e-06
Iter: 401 loss: 2.14798888e-06
Iter: 402 loss: 2.16095964e-06
Iter: 403 loss: 2.14757915e-06
Iter: 404 loss: 2.14591591e-06
Iter: 405 loss: 2.1472556e-06
Iter: 406 loss: 2.14489864e-06
Iter: 407 loss: 2.14312604e-06
Iter: 408 loss: 2.14480588e-06
Iter: 409 loss: 2.1421622e-06
Iter: 410 loss: 2.13988096e-06
Iter: 411 loss: 2.15214141e-06
Iter: 412 loss: 2.13958879e-06
Iter: 413 loss: 2.13749649e-06
Iter: 414 loss: 2.1357489e-06
Iter: 415 loss: 2.13519365e-06
Iter: 416 loss: 2.13323915e-06
Iter: 417 loss: 2.15708656e-06
Iter: 418 loss: 2.13324915e-06
Iter: 419 loss: 2.13282033e-06
Iter: 420 loss: 2.13226122e-06
Iter: 421 loss: 2.13152134e-06
Iter: 422 loss: 2.12953501e-06
Iter: 423 loss: 2.15824684e-06
Iter: 424 loss: 2.1295275e-06
Iter: 425 loss: 2.12823625e-06
Iter: 426 loss: 2.12794384e-06
Iter: 427 loss: 2.12718714e-06
Iter: 428 loss: 2.12511804e-06
Iter: 429 loss: 2.1286146e-06
Iter: 430 loss: 2.12426198e-06
Iter: 431 loss: 2.12149325e-06
Iter: 432 loss: 2.12097234e-06
Iter: 433 loss: 2.11924498e-06
Iter: 434 loss: 2.1164019e-06
Iter: 435 loss: 2.14236979e-06
Iter: 436 loss: 2.11637939e-06
Iter: 437 loss: 2.11394604e-06
Iter: 438 loss: 2.13215571e-06
Iter: 439 loss: 2.11387533e-06
Iter: 440 loss: 2.11193674e-06
Iter: 441 loss: 2.11608449e-06
Iter: 442 loss: 2.11118777e-06
Iter: 443 loss: 2.10889402e-06
Iter: 444 loss: 2.11170686e-06
Iter: 445 loss: 2.10789176e-06
Iter: 446 loss: 2.1059268e-06
Iter: 447 loss: 2.10628718e-06
Iter: 448 loss: 2.10463872e-06
Iter: 449 loss: 2.10205758e-06
Iter: 450 loss: 2.11486076e-06
Iter: 451 loss: 2.10165149e-06
Iter: 452 loss: 2.09933296e-06
Iter: 453 loss: 2.11250472e-06
Iter: 454 loss: 2.09902169e-06
Iter: 455 loss: 2.09927498e-06
Iter: 456 loss: 2.09857171e-06
Iter: 457 loss: 2.09805739e-06
Iter: 458 loss: 2.09644509e-06
Iter: 459 loss: 2.09555378e-06
Iter: 460 loss: 2.09461086e-06
Iter: 461 loss: 2.09077871e-06
Iter: 462 loss: 2.10868097e-06
Iter: 463 loss: 2.09022801e-06
Iter: 464 loss: 2.08739834e-06
Iter: 465 loss: 2.11863471e-06
Iter: 466 loss: 2.08733491e-06
Iter: 467 loss: 2.08530446e-06
Iter: 468 loss: 2.08255688e-06
Iter: 469 loss: 2.08243614e-06
Iter: 470 loss: 2.07958e-06
Iter: 471 loss: 2.09010955e-06
Iter: 472 loss: 2.07882022e-06
Iter: 473 loss: 2.07674566e-06
Iter: 474 loss: 2.10587859e-06
Iter: 475 loss: 2.07675203e-06
Iter: 476 loss: 2.07501262e-06
Iter: 477 loss: 2.08522511e-06
Iter: 478 loss: 2.07481435e-06
Iter: 479 loss: 2.07381572e-06
Iter: 480 loss: 2.07182893e-06
Iter: 481 loss: 2.11360407e-06
Iter: 482 loss: 2.07177163e-06
Iter: 483 loss: 2.06957361e-06
Iter: 484 loss: 2.07859193e-06
Iter: 485 loss: 2.06913683e-06
Iter: 486 loss: 2.0671207e-06
Iter: 487 loss: 2.06820755e-06
Iter: 488 loss: 2.06600112e-06
Iter: 489 loss: 2.06562549e-06
Iter: 490 loss: 2.0651637e-06
Iter: 491 loss: 2.06422237e-06
Iter: 492 loss: 2.06235973e-06
Iter: 493 loss: 2.10350345e-06
Iter: 494 loss: 2.06237746e-06
Iter: 495 loss: 2.06017e-06
Iter: 496 loss: 2.0640914e-06
Iter: 497 loss: 2.0593809e-06
Iter: 498 loss: 2.05780384e-06
Iter: 499 loss: 2.05731203e-06
Iter: 500 loss: 2.05651668e-06
Iter: 501 loss: 2.05403376e-06
Iter: 502 loss: 2.05572633e-06
Iter: 503 loss: 2.05253627e-06
Iter: 504 loss: 2.04993785e-06
Iter: 505 loss: 2.06554819e-06
Iter: 506 loss: 2.04969547e-06
Iter: 507 loss: 2.0471648e-06
Iter: 508 loss: 2.05715264e-06
Iter: 509 loss: 2.04671528e-06
Iter: 510 loss: 2.0457137e-06
Iter: 511 loss: 2.04536309e-06
Iter: 512 loss: 2.04438e-06
Iter: 513 loss: 2.04357139e-06
Iter: 514 loss: 2.04329035e-06
Iter: 515 loss: 2.04173466e-06
Iter: 516 loss: 2.04387084e-06
Iter: 517 loss: 2.04106072e-06
Iter: 518 loss: 2.03948275e-06
Iter: 519 loss: 2.04480466e-06
Iter: 520 loss: 2.03910736e-06
Iter: 521 loss: 2.03778245e-06
Iter: 522 loss: 2.04139724e-06
Iter: 523 loss: 2.03739501e-06
Iter: 524 loss: 2.03728587e-06
Iter: 525 loss: 2.03673153e-06
Iter: 526 loss: 2.03606783e-06
Iter: 527 loss: 2.03432342e-06
Iter: 528 loss: 2.04059188e-06
Iter: 529 loss: 2.03358559e-06
Iter: 530 loss: 2.03217405e-06
Iter: 531 loss: 2.03100058e-06
Iter: 532 loss: 2.03071295e-06
Iter: 533 loss: 2.02832462e-06
Iter: 534 loss: 2.04015419e-06
Iter: 535 loss: 2.02801129e-06
Iter: 536 loss: 2.02663477e-06
Iter: 537 loss: 2.04855314e-06
Iter: 538 loss: 2.02663114e-06
Iter: 539 loss: 2.02541514e-06
Iter: 540 loss: 2.02592537e-06
Iter: 541 loss: 2.02452316e-06
Iter: 542 loss: 2.02313049e-06
Iter: 543 loss: 2.02460569e-06
Iter: 544 loss: 2.02225465e-06
Iter: 545 loss: 2.02190404e-06
Iter: 546 loss: 2.02143269e-06
Iter: 547 loss: 2.02093293e-06
Iter: 548 loss: 2.01950616e-06
Iter: 549 loss: 2.03873697e-06
Iter: 550 loss: 2.01944113e-06
Iter: 551 loss: 2.01808416e-06
Iter: 552 loss: 2.01987791e-06
Iter: 553 loss: 2.01724765e-06
Iter: 554 loss: 2.01604053e-06
Iter: 555 loss: 2.02132037e-06
Iter: 556 loss: 2.01577041e-06
Iter: 557 loss: 2.01499643e-06
Iter: 558 loss: 2.02409183e-06
Iter: 559 loss: 2.01501916e-06
Iter: 560 loss: 2.01416606e-06
Iter: 561 loss: 2.01592138e-06
Iter: 562 loss: 2.0137104e-06
Iter: 563 loss: 2.01307307e-06
Iter: 564 loss: 2.01190073e-06
Iter: 565 loss: 2.0296859e-06
Iter: 566 loss: 2.01188527e-06
Iter: 567 loss: 2.01051103e-06
Iter: 568 loss: 2.01277635e-06
Iter: 569 loss: 2.00989803e-06
Iter: 570 loss: 2.00848172e-06
Iter: 571 loss: 2.01812418e-06
Iter: 572 loss: 2.00832619e-06
Iter: 573 loss: 2.00725185e-06
Iter: 574 loss: 2.01482385e-06
Iter: 575 loss: 2.00730028e-06
Iter: 576 loss: 2.00632712e-06
Iter: 577 loss: 2.00691306e-06
Iter: 578 loss: 2.00575823e-06
Iter: 579 loss: 2.00432623e-06
Iter: 580 loss: 2.0049747e-06
Iter: 581 loss: 2.00333648e-06
Iter: 582 loss: 2.00241948e-06
Iter: 583 loss: 2.00240447e-06
Iter: 584 loss: 2.00138402e-06
Iter: 585 loss: 2.00142949e-06
Iter: 586 loss: 2.00065301e-06
Iter: 587 loss: 1.99959436e-06
Iter: 588 loss: 1.99968099e-06
Iter: 589 loss: 1.9986237e-06
Iter: 590 loss: 1.99847273e-06
Iter: 591 loss: 1.99818055e-06
Iter: 592 loss: 1.99780584e-06
Iter: 593 loss: 1.99921396e-06
Iter: 594 loss: 1.9975364e-06
Iter: 595 loss: 1.99701458e-06
Iter: 596 loss: 1.99589545e-06
Iter: 597 loss: 2.00338809e-06
Iter: 598 loss: 1.99568308e-06
Iter: 599 loss: 1.99417445e-06
Iter: 600 loss: 1.99706892e-06
Iter: 601 loss: 1.99350507e-06
Iter: 602 loss: 1.99205033e-06
Iter: 603 loss: 2.00887212e-06
Iter: 604 loss: 1.99202395e-06
Iter: 605 loss: 1.99110718e-06
Iter: 606 loss: 1.99037913e-06
Iter: 607 loss: 1.98997964e-06
Iter: 608 loss: 1.9883521e-06
Iter: 609 loss: 1.99378928e-06
Iter: 610 loss: 1.9879576e-06
Iter: 611 loss: 1.98650105e-06
Iter: 612 loss: 2.00019849e-06
Iter: 613 loss: 1.98654766e-06
Iter: 614 loss: 1.9854765e-06
Iter: 615 loss: 1.98647e-06
Iter: 616 loss: 1.98483758e-06
Iter: 617 loss: 1.9836325e-06
Iter: 618 loss: 1.99223905e-06
Iter: 619 loss: 1.98359749e-06
Iter: 620 loss: 1.98274302e-06
Iter: 621 loss: 1.98514681e-06
Iter: 622 loss: 1.98229213e-06
Iter: 623 loss: 1.9816855e-06
Iter: 624 loss: 1.9801987e-06
Iter: 625 loss: 2.00624027e-06
Iter: 626 loss: 1.98008411e-06
Iter: 627 loss: 1.97934446e-06
Iter: 628 loss: 1.97916825e-06
Iter: 629 loss: 1.97808822e-06
Iter: 630 loss: 1.98185535e-06
Iter: 631 loss: 1.97761483e-06
Iter: 632 loss: 1.97737063e-06
Iter: 633 loss: 1.97647432e-06
Iter: 634 loss: 1.98525345e-06
Iter: 635 loss: 1.97623e-06
Iter: 636 loss: 1.9748411e-06
Iter: 637 loss: 1.97493296e-06
Iter: 638 loss: 1.97383497e-06
Iter: 639 loss: 1.97244162e-06
Iter: 640 loss: 1.98596331e-06
Iter: 641 loss: 1.97244549e-06
Iter: 642 loss: 1.97128088e-06
Iter: 643 loss: 1.97308373e-06
Iter: 644 loss: 1.9706672e-06
Iter: 645 loss: 1.96901965e-06
Iter: 646 loss: 1.97154122e-06
Iter: 647 loss: 1.96836436e-06
Iter: 648 loss: 1.96719611e-06
Iter: 649 loss: 1.97583563e-06
Iter: 650 loss: 1.96716428e-06
Iter: 651 loss: 1.96606629e-06
Iter: 652 loss: 1.96808469e-06
Iter: 653 loss: 1.96571227e-06
Iter: 654 loss: 1.96480551e-06
Iter: 655 loss: 1.97133136e-06
Iter: 656 loss: 1.9645945e-06
Iter: 657 loss: 1.96365363e-06
Iter: 658 loss: 1.96631549e-06
Iter: 659 loss: 1.96339215e-06
Iter: 660 loss: 1.96270298e-06
Iter: 661 loss: 1.96218866e-06
Iter: 662 loss: 1.96185897e-06
Iter: 663 loss: 1.96115661e-06
Iter: 664 loss: 1.96114e-06
Iter: 665 loss: 1.96028441e-06
Iter: 666 loss: 1.95978487e-06
Iter: 667 loss: 1.959364e-06
Iter: 668 loss: 1.95869598e-06
Iter: 669 loss: 1.9571587e-06
Iter: 670 loss: 1.96729616e-06
Iter: 671 loss: 1.95692223e-06
Iter: 672 loss: 1.95477651e-06
Iter: 673 loss: 1.96670499e-06
Iter: 674 loss: 1.95452321e-06
Iter: 675 loss: 1.95281791e-06
Iter: 676 loss: 1.96571e-06
Iter: 677 loss: 1.95280131e-06
Iter: 678 loss: 1.95179791e-06
Iter: 679 loss: 1.9536028e-06
Iter: 680 loss: 1.95128678e-06
Iter: 681 loss: 1.94985091e-06
Iter: 682 loss: 1.95260532e-06
Iter: 683 loss: 1.94933182e-06
Iter: 684 loss: 1.9481638e-06
Iter: 685 loss: 1.94909353e-06
Iter: 686 loss: 1.94750305e-06
Iter: 687 loss: 1.94601535e-06
Iter: 688 loss: 1.96287237e-06
Iter: 689 loss: 1.94592099e-06
Iter: 690 loss: 1.94520476e-06
Iter: 691 loss: 1.94977633e-06
Iter: 692 loss: 1.94510358e-06
Iter: 693 loss: 1.94427912e-06
Iter: 694 loss: 1.94518384e-06
Iter: 695 loss: 1.94391237e-06
Iter: 696 loss: 1.94301629e-06
Iter: 697 loss: 1.94261065e-06
Iter: 698 loss: 1.94223639e-06
Iter: 699 loss: 1.94096174e-06
Iter: 700 loss: 1.94665108e-06
Iter: 701 loss: 1.94084532e-06
Iter: 702 loss: 1.94188715e-06
Iter: 703 loss: 1.94058748e-06
Iter: 704 loss: 1.9403949e-06
Iter: 705 loss: 1.93983806e-06
Iter: 706 loss: 1.93963979e-06
Iter: 707 loss: 1.93902e-06
Iter: 708 loss: 1.93817505e-06
Iter: 709 loss: 1.93934466e-06
Iter: 710 loss: 1.93771962e-06
Iter: 711 loss: 1.93674759e-06
Iter: 712 loss: 1.93720234e-06
Iter: 713 loss: 1.93600249e-06
Iter: 714 loss: 1.93413848e-06
Iter: 715 loss: 1.93659298e-06
Iter: 716 loss: 1.93332244e-06
Iter: 717 loss: 1.93222331e-06
Iter: 718 loss: 1.94684594e-06
Iter: 719 loss: 1.93209689e-06
Iter: 720 loss: 1.93111759e-06
Iter: 721 loss: 1.93161713e-06
Iter: 722 loss: 1.93049323e-06
Iter: 723 loss: 1.92926973e-06
Iter: 724 loss: 1.93635879e-06
Iter: 725 loss: 1.92907828e-06
Iter: 726 loss: 1.92824609e-06
Iter: 727 loss: 1.93626533e-06
Iter: 728 loss: 1.92817538e-06
Iter: 729 loss: 1.92751304e-06
Iter: 730 loss: 1.92827383e-06
Iter: 731 loss: 1.92723951e-06
Iter: 732 loss: 1.92639186e-06
Iter: 733 loss: 1.92497578e-06
Iter: 734 loss: 1.95697748e-06
Iter: 735 loss: 1.92502193e-06
Iter: 736 loss: 1.92379366e-06
Iter: 737 loss: 1.94243694e-06
Iter: 738 loss: 1.92373227e-06
Iter: 739 loss: 1.92353059e-06
Iter: 740 loss: 1.92331186e-06
Iter: 741 loss: 1.92311677e-06
Iter: 742 loss: 1.92224434e-06
Iter: 743 loss: 1.92283665e-06
Iter: 744 loss: 1.9217523e-06
Iter: 745 loss: 1.92003563e-06
Iter: 746 loss: 1.91977597e-06
Iter: 747 loss: 1.91860227e-06
Iter: 748 loss: 1.91689355e-06
Iter: 749 loss: 1.93244341e-06
Iter: 750 loss: 1.91679942e-06
Iter: 751 loss: 1.91548634e-06
Iter: 752 loss: 1.92443349e-06
Iter: 753 loss: 1.91533718e-06
Iter: 754 loss: 1.91428853e-06
Iter: 755 loss: 1.91694016e-06
Iter: 756 loss: 1.91401546e-06
Iter: 757 loss: 1.91316667e-06
Iter: 758 loss: 1.91557274e-06
Iter: 759 loss: 1.91286358e-06
Iter: 760 loss: 1.91205663e-06
Iter: 761 loss: 1.91865138e-06
Iter: 762 loss: 1.91202685e-06
Iter: 763 loss: 1.91107574e-06
Iter: 764 loss: 1.91255299e-06
Iter: 765 loss: 1.91083541e-06
Iter: 766 loss: 1.91011986e-06
Iter: 767 loss: 1.91124082e-06
Iter: 768 loss: 1.90973424e-06
Iter: 769 loss: 1.90891501e-06
Iter: 770 loss: 1.90826472e-06
Iter: 771 loss: 1.90814399e-06
Iter: 772 loss: 1.90896981e-06
Iter: 773 loss: 1.90780247e-06
Iter: 774 loss: 1.90738706e-06
Iter: 775 loss: 1.9064621e-06
Iter: 776 loss: 1.91467507e-06
Iter: 777 loss: 1.90637763e-06
Iter: 778 loss: 1.90550054e-06
Iter: 779 loss: 1.9053698e-06
Iter: 780 loss: 1.90476089e-06
Iter: 781 loss: 1.90331832e-06
Iter: 782 loss: 1.90509445e-06
Iter: 783 loss: 1.90280446e-06
Iter: 784 loss: 1.90150536e-06
Iter: 785 loss: 1.90835885e-06
Iter: 786 loss: 1.9012723e-06
Iter: 787 loss: 1.89985724e-06
Iter: 788 loss: 1.90209153e-06
Iter: 789 loss: 1.89925049e-06
Iter: 790 loss: 1.89792979e-06
Iter: 791 loss: 1.90319656e-06
Iter: 792 loss: 1.89754383e-06
Iter: 793 loss: 1.89641059e-06
Iter: 794 loss: 1.90176456e-06
Iter: 795 loss: 1.89637672e-06
Iter: 796 loss: 1.89510524e-06
Iter: 797 loss: 1.89825687e-06
Iter: 798 loss: 1.89476327e-06
Iter: 799 loss: 1.89357957e-06
Iter: 800 loss: 1.89785396e-06
Iter: 801 loss: 1.89328853e-06
Iter: 802 loss: 1.892417e-06
Iter: 803 loss: 1.89413117e-06
Iter: 804 loss: 1.89205161e-06
Iter: 805 loss: 1.89120237e-06
Iter: 806 loss: 1.89007289e-06
Iter: 807 loss: 1.88985257e-06
Iter: 808 loss: 1.89169191e-06
Iter: 809 loss: 1.88944477e-06
Iter: 810 loss: 1.88899605e-06
Iter: 811 loss: 1.88774493e-06
Iter: 812 loss: 1.89475986e-06
Iter: 813 loss: 1.8873e-06
Iter: 814 loss: 1.88624097e-06
Iter: 815 loss: 1.88855074e-06
Iter: 816 loss: 1.88594561e-06
Iter: 817 loss: 1.88479748e-06
Iter: 818 loss: 1.88648755e-06
Iter: 819 loss: 1.88413765e-06
Iter: 820 loss: 1.88305808e-06
Iter: 821 loss: 1.8868019e-06
Iter: 822 loss: 1.88288e-06
Iter: 823 loss: 1.88201716e-06
Iter: 824 loss: 1.88399758e-06
Iter: 825 loss: 1.88182867e-06
Iter: 826 loss: 1.88080071e-06
Iter: 827 loss: 1.88610966e-06
Iter: 828 loss: 1.8807707e-06
Iter: 829 loss: 1.88012689e-06
Iter: 830 loss: 1.8806187e-06
Iter: 831 loss: 1.87971068e-06
Iter: 832 loss: 1.87895466e-06
Iter: 833 loss: 1.88443676e-06
Iter: 834 loss: 1.87883211e-06
Iter: 835 loss: 1.87811611e-06
Iter: 836 loss: 1.87852197e-06
Iter: 837 loss: 1.87772036e-06
Iter: 838 loss: 1.87653677e-06
Iter: 839 loss: 1.87731348e-06
Iter: 840 loss: 1.87596413e-06
Iter: 841 loss: 1.87512774e-06
Iter: 842 loss: 1.87838191e-06
Iter: 843 loss: 1.87480225e-06
Iter: 844 loss: 1.87400826e-06
Iter: 845 loss: 1.87405533e-06
Iter: 846 loss: 1.87364651e-06
Iter: 847 loss: 1.87263606e-06
Iter: 848 loss: 1.87402338e-06
Iter: 849 loss: 1.87172373e-06
Iter: 850 loss: 1.87045498e-06
Iter: 851 loss: 1.87280125e-06
Iter: 852 loss: 1.86990269e-06
Iter: 853 loss: 1.86870727e-06
Iter: 854 loss: 1.86957777e-06
Iter: 855 loss: 1.86789521e-06
Iter: 856 loss: 1.86655257e-06
Iter: 857 loss: 1.88556601e-06
Iter: 858 loss: 1.86656075e-06
Iter: 859 loss: 1.86580178e-06
Iter: 860 loss: 1.86473176e-06
Iter: 861 loss: 1.86469197e-06
Iter: 862 loss: 1.86342709e-06
Iter: 863 loss: 1.86340935e-06
Iter: 864 loss: 1.86263685e-06
Iter: 865 loss: 1.86413308e-06
Iter: 866 loss: 1.86236321e-06
Iter: 867 loss: 1.86155808e-06
Iter: 868 loss: 1.8654107e-06
Iter: 869 loss: 1.86138618e-06
Iter: 870 loss: 1.86039938e-06
Iter: 871 loss: 1.86117e-06
Iter: 872 loss: 1.85987574e-06
Iter: 873 loss: 1.85908198e-06
Iter: 874 loss: 1.86609645e-06
Iter: 875 loss: 1.85902149e-06
Iter: 876 loss: 1.85877479e-06
Iter: 877 loss: 1.85876638e-06
Iter: 878 loss: 1.8583894e-06
Iter: 879 loss: 1.85802719e-06
Iter: 880 loss: 1.85794909e-06
Iter: 881 loss: 1.85751651e-06
Iter: 882 loss: 1.85661338e-06
Iter: 883 loss: 1.87344097e-06
Iter: 884 loss: 1.85630813e-06
Iter: 885 loss: 1.85562499e-06
Iter: 886 loss: 1.8583479e-06
Iter: 887 loss: 1.85538283e-06
Iter: 888 loss: 1.8544722e-06
Iter: 889 loss: 1.85629142e-06
Iter: 890 loss: 1.85401461e-06
Iter: 891 loss: 1.85313581e-06
Iter: 892 loss: 1.85822762e-06
Iter: 893 loss: 1.85310466e-06
Iter: 894 loss: 1.85219665e-06
Iter: 895 loss: 1.85273677e-06
Iter: 896 loss: 1.85171575e-06
Iter: 897 loss: 1.85073748e-06
Iter: 898 loss: 1.85813656e-06
Iter: 899 loss: 1.85072918e-06
Iter: 900 loss: 1.84993223e-06
Iter: 901 loss: 1.85012925e-06
Iter: 902 loss: 1.84930946e-06
Iter: 903 loss: 1.84857925e-06
Iter: 904 loss: 1.85903059e-06
Iter: 905 loss: 1.84856913e-06
Iter: 906 loss: 1.84789849e-06
Iter: 907 loss: 1.8500341e-06
Iter: 908 loss: 1.84773739e-06
Iter: 909 loss: 1.84720511e-06
Iter: 910 loss: 1.84859402e-06
Iter: 911 loss: 1.84711769e-06
Iter: 912 loss: 1.84691874e-06
Iter: 913 loss: 1.84682199e-06
Iter: 914 loss: 1.84650617e-06
Iter: 915 loss: 1.84574219e-06
Iter: 916 loss: 1.86073078e-06
Iter: 917 loss: 1.84570877e-06
Iter: 918 loss: 1.84525243e-06
Iter: 919 loss: 1.84522082e-06
Iter: 920 loss: 1.84485611e-06
Iter: 921 loss: 1.84410203e-06
Iter: 922 loss: 1.84420014e-06
Iter: 923 loss: 1.84363034e-06
Iter: 924 loss: 1.8425485e-06
Iter: 925 loss: 1.85058e-06
Iter: 926 loss: 1.84247347e-06
Iter: 927 loss: 1.84158012e-06
Iter: 928 loss: 1.84419468e-06
Iter: 929 loss: 1.84133114e-06
Iter: 930 loss: 1.84046314e-06
Iter: 931 loss: 1.83980274e-06
Iter: 932 loss: 1.8397111e-06
Iter: 933 loss: 1.83870418e-06
Iter: 934 loss: 1.84640624e-06
Iter: 935 loss: 1.83847737e-06
Iter: 936 loss: 1.83794157e-06
Iter: 937 loss: 1.83799966e-06
Iter: 938 loss: 1.83737222e-06
Iter: 939 loss: 1.83682448e-06
Iter: 940 loss: 1.83681732e-06
Iter: 941 loss: 1.83628549e-06
Iter: 942 loss: 1.83690076e-06
Iter: 943 loss: 1.83600355e-06
Iter: 944 loss: 1.83556961e-06
Iter: 945 loss: 1.83551231e-06
Iter: 946 loss: 1.83507973e-06
Iter: 947 loss: 1.83449106e-06
Iter: 948 loss: 1.84103919e-06
Iter: 949 loss: 1.83453722e-06
Iter: 950 loss: 1.83383338e-06
Iter: 951 loss: 1.8362781e-06
Iter: 952 loss: 1.83370878e-06
Iter: 953 loss: 1.833532e-06
Iter: 954 loss: 1.83300165e-06
Iter: 955 loss: 1.84413773e-06
Iter: 956 loss: 1.83293992e-06
Iter: 957 loss: 1.83211932e-06
Iter: 958 loss: 1.83191707e-06
Iter: 959 loss: 1.83149518e-06
Iter: 960 loss: 1.83048894e-06
Iter: 961 loss: 1.8373114e-06
Iter: 962 loss: 1.83034501e-06
Iter: 963 loss: 1.82982649e-06
Iter: 964 loss: 1.83419229e-06
Iter: 965 loss: 1.82988276e-06
Iter: 966 loss: 1.82925123e-06
Iter: 967 loss: 1.82934821e-06
Iter: 968 loss: 1.82892029e-06
Iter: 969 loss: 1.82809742e-06
Iter: 970 loss: 1.82895133e-06
Iter: 971 loss: 1.82769577e-06
Iter: 972 loss: 1.82703343e-06
Iter: 973 loss: 1.82822919e-06
Iter: 974 loss: 1.82663587e-06
Iter: 975 loss: 1.82588383e-06
Iter: 976 loss: 1.8259459e-06
Iter: 977 loss: 1.82516146e-06
Iter: 978 loss: 1.82719714e-06
Iter: 979 loss: 1.82504812e-06
Iter: 980 loss: 1.82469159e-06
Iter: 981 loss: 1.82390306e-06
Iter: 982 loss: 1.83856741e-06
Iter: 983 loss: 1.82390011e-06
Iter: 984 loss: 1.82285157e-06
Iter: 985 loss: 1.82701694e-06
Iter: 986 loss: 1.82262488e-06
Iter: 987 loss: 1.82188501e-06
Iter: 988 loss: 1.83046154e-06
Iter: 989 loss: 1.8218584e-06
Iter: 990 loss: 1.82187682e-06
Iter: 991 loss: 1.82175302e-06
Iter: 992 loss: 1.82158192e-06
Iter: 993 loss: 1.82117856e-06
Iter: 994 loss: 1.82319741e-06
Iter: 995 loss: 1.82095732e-06
Iter: 996 loss: 1.82039685e-06
Iter: 997 loss: 1.82079941e-06
Iter: 998 loss: 1.8199969e-06
Iter: 999 loss: 1.81936593e-06
Iter: 1000 loss: 1.82269082e-06
Iter: 1001 loss: 1.81932728e-06
Iter: 1002 loss: 1.81880341e-06
Iter: 1003 loss: 1.81976202e-06
Iter: 1004 loss: 1.81849009e-06
Iter: 1005 loss: 1.81770315e-06
Iter: 1006 loss: 1.81827409e-06
Iter: 1007 loss: 1.81721452e-06
Iter: 1008 loss: 1.81650842e-06
Iter: 1009 loss: 1.81767587e-06
Iter: 1010 loss: 1.81621488e-06
Iter: 1011 loss: 1.81528094e-06
Iter: 1012 loss: 1.81719474e-06
Iter: 1013 loss: 1.81507016e-06
Iter: 1014 loss: 1.81409337e-06
Iter: 1015 loss: 1.81409609e-06
Iter: 1016 loss: 1.81376652e-06
Iter: 1017 loss: 1.81323503e-06
Iter: 1018 loss: 1.81326482e-06
Iter: 1019 loss: 1.81263158e-06
Iter: 1020 loss: 1.81159294e-06
Iter: 1021 loss: 1.81153746e-06
Iter: 1022 loss: 1.81222492e-06
Iter: 1023 loss: 1.81136693e-06
Iter: 1024 loss: 1.81102803e-06
Iter: 1025 loss: 1.81074824e-06
Iter: 1026 loss: 1.81071e-06
Iter: 1027 loss: 1.81043254e-06
Iter: 1028 loss: 1.81004407e-06
Iter: 1029 loss: 1.80989537e-06
Iter: 1030 loss: 1.80932579e-06
Iter: 1031 loss: 1.80928566e-06
Iter: 1032 loss: 1.80875043e-06
Iter: 1033 loss: 1.80828727e-06
Iter: 1034 loss: 1.80918892e-06
Iter: 1035 loss: 1.80796758e-06
Iter: 1036 loss: 1.80728034e-06
Iter: 1037 loss: 1.80935785e-06
Iter: 1038 loss: 1.80715278e-06
Iter: 1039 loss: 1.80658935e-06
Iter: 1040 loss: 1.80680706e-06
Iter: 1041 loss: 1.80614654e-06
Iter: 1042 loss: 1.80557333e-06
Iter: 1043 loss: 1.8058189e-06
Iter: 1044 loss: 1.80504139e-06
Iter: 1045 loss: 1.80450445e-06
Iter: 1046 loss: 1.80678808e-06
Iter: 1047 loss: 1.80427594e-06
Iter: 1048 loss: 1.80377288e-06
Iter: 1049 loss: 1.80577342e-06
Iter: 1050 loss: 1.80363793e-06
Iter: 1051 loss: 1.8032481e-06
Iter: 1052 loss: 1.80279994e-06
Iter: 1053 loss: 1.80275958e-06
Iter: 1054 loss: 1.80207167e-06
Iter: 1055 loss: 1.80730603e-06
Iter: 1056 loss: 1.80195161e-06
Iter: 1057 loss: 1.80182269e-06
Iter: 1058 loss: 1.80183156e-06
Iter: 1059 loss: 1.80150914e-06
Iter: 1060 loss: 1.80115308e-06
Iter: 1061 loss: 1.80112124e-06
Iter: 1062 loss: 1.80074369e-06
Iter: 1063 loss: 1.80032e-06
Iter: 1064 loss: 1.80027803e-06
Iter: 1065 loss: 1.7996731e-06
Iter: 1066 loss: 1.80160043e-06
Iter: 1067 loss: 1.7995086e-06
Iter: 1068 loss: 1.79897745e-06
Iter: 1069 loss: 1.80025609e-06
Iter: 1070 loss: 1.79850736e-06
Iter: 1071 loss: 1.79798076e-06
Iter: 1072 loss: 1.80394841e-06
Iter: 1073 loss: 1.79798792e-06
Iter: 1074 loss: 1.79763231e-06
Iter: 1075 loss: 1.79703011e-06
Iter: 1076 loss: 1.79701601e-06
Iter: 1077 loss: 1.79638346e-06
Iter: 1078 loss: 1.79692574e-06
Iter: 1079 loss: 1.79607309e-06
Iter: 1080 loss: 1.79590654e-06
Iter: 1081 loss: 1.79563972e-06
Iter: 1082 loss: 1.79535039e-06
Iter: 1083 loss: 1.79543895e-06
Iter: 1084 loss: 1.79515132e-06
Iter: 1085 loss: 1.79472249e-06
Iter: 1086 loss: 1.79419271e-06
Iter: 1087 loss: 1.79413337e-06
Iter: 1088 loss: 1.79349968e-06
Iter: 1089 loss: 1.79484698e-06
Iter: 1090 loss: 1.79336939e-06
Iter: 1091 loss: 1.79321137e-06
Iter: 1092 loss: 1.79313884e-06
Iter: 1093 loss: 1.79282165e-06
Iter: 1094 loss: 1.7921717e-06
Iter: 1095 loss: 1.80495613e-06
Iter: 1096 loss: 1.7921343e-06
Iter: 1097 loss: 1.79182007e-06
Iter: 1098 loss: 1.79182825e-06
Iter: 1099 loss: 1.79162237e-06
Iter: 1100 loss: 1.79108304e-06
Iter: 1101 loss: 1.79227925e-06
Iter: 1102 loss: 1.79090421e-06
Iter: 1103 loss: 1.79030553e-06
Iter: 1104 loss: 1.79022618e-06
Iter: 1105 loss: 1.78978382e-06
Iter: 1106 loss: 1.78926018e-06
Iter: 1107 loss: 1.78923096e-06
Iter: 1108 loss: 1.7889854e-06
Iter: 1109 loss: 1.78864275e-06
Iter: 1110 loss: 1.78851e-06
Iter: 1111 loss: 1.78803168e-06
Iter: 1112 loss: 1.78775372e-06
Iter: 1113 loss: 1.78770244e-06
Iter: 1114 loss: 1.78712048e-06
Iter: 1115 loss: 1.79169479e-06
Iter: 1116 loss: 1.78715436e-06
Iter: 1117 loss: 1.78686639e-06
Iter: 1118 loss: 1.78652726e-06
Iter: 1119 loss: 1.78647383e-06
Iter: 1120 loss: 1.78602602e-06
Iter: 1121 loss: 1.78572077e-06
Iter: 1122 loss: 1.78565506e-06
Iter: 1123 loss: 1.7852376e-06
Iter: 1124 loss: 1.78836899e-06
Iter: 1125 loss: 1.7852376e-06
Iter: 1126 loss: 1.78503058e-06
Iter: 1127 loss: 1.78483128e-06
Iter: 1128 loss: 1.78484959e-06
Iter: 1129 loss: 1.78445657e-06
Iter: 1130 loss: 1.78405185e-06
Iter: 1131 loss: 1.7839925e-06
Iter: 1132 loss: 1.78350797e-06
Iter: 1133 loss: 1.78814696e-06
Iter: 1134 loss: 1.78337791e-06
Iter: 1135 loss: 1.78299797e-06
Iter: 1136 loss: 1.7838812e-06
Iter: 1137 loss: 1.78292248e-06
Iter: 1138 loss: 1.78239543e-06
Iter: 1139 loss: 1.7829434e-06
Iter: 1140 loss: 1.7822332e-06
Iter: 1141 loss: 1.781675e-06
Iter: 1142 loss: 1.78498681e-06
Iter: 1143 loss: 1.78146024e-06
Iter: 1144 loss: 1.78127993e-06
Iter: 1145 loss: 1.7831959e-06
Iter: 1146 loss: 1.78120774e-06
Iter: 1147 loss: 1.78087635e-06
Iter: 1148 loss: 1.78172888e-06
Iter: 1149 loss: 1.78086532e-06
Iter: 1150 loss: 1.78040159e-06
Iter: 1151 loss: 1.78038454e-06
Iter: 1152 loss: 1.7801367e-06
Iter: 1153 loss: 1.77977529e-06
Iter: 1154 loss: 1.78072514e-06
Iter: 1155 loss: 1.77963921e-06
Iter: 1156 loss: 1.7795544e-06
Iter: 1157 loss: 1.77954234e-06
Iter: 1158 loss: 1.77934908e-06
Iter: 1159 loss: 1.77904212e-06
Iter: 1160 loss: 1.78100061e-06
Iter: 1161 loss: 1.77901507e-06
Iter: 1162 loss: 1.77845334e-06
Iter: 1163 loss: 1.77840025e-06
Iter: 1164 loss: 1.77807487e-06
Iter: 1165 loss: 1.77747734e-06
Iter: 1166 loss: 1.78152686e-06
Iter: 1167 loss: 1.77754043e-06
Iter: 1168 loss: 1.77706488e-06
Iter: 1169 loss: 1.77678942e-06
Iter: 1170 loss: 1.77665629e-06
Iter: 1171 loss: 1.77606785e-06
Iter: 1172 loss: 1.77821084e-06
Iter: 1173 loss: 1.77578477e-06
Iter: 1174 loss: 1.77538516e-06
Iter: 1175 loss: 1.77887387e-06
Iter: 1176 loss: 1.77529807e-06
Iter: 1177 loss: 1.77494371e-06
Iter: 1178 loss: 1.77501818e-06
Iter: 1179 loss: 1.7746944e-06
Iter: 1180 loss: 1.77422737e-06
Iter: 1181 loss: 1.77824495e-06
Iter: 1182 loss: 1.77416268e-06
Iter: 1183 loss: 1.77382901e-06
Iter: 1184 loss: 1.77569791e-06
Iter: 1185 loss: 1.77377831e-06
Iter: 1186 loss: 1.77336335e-06
Iter: 1187 loss: 1.77314223e-06
Iter: 1188 loss: 1.77300626e-06
Iter: 1189 loss: 1.77257368e-06
Iter: 1190 loss: 1.77806976e-06
Iter: 1191 loss: 1.77253582e-06
Iter: 1192 loss: 1.77197523e-06
Iter: 1193 loss: 1.77438039e-06
Iter: 1194 loss: 1.77190884e-06
Iter: 1195 loss: 1.77179618e-06
Iter: 1196 loss: 1.77135337e-06
Iter: 1197 loss: 1.77906963e-06
Iter: 1198 loss: 1.77137588e-06
Iter: 1199 loss: 1.77067818e-06
Iter: 1200 loss: 1.7718155e-06
Iter: 1201 loss: 1.77050856e-06
Iter: 1202 loss: 1.77005916e-06
Iter: 1203 loss: 1.77175116e-06
Iter: 1204 loss: 1.76991352e-06
Iter: 1205 loss: 1.76941751e-06
Iter: 1206 loss: 1.77201935e-06
Iter: 1207 loss: 1.76931644e-06
Iter: 1208 loss: 1.76883304e-06
Iter: 1209 loss: 1.76930371e-06
Iter: 1210 loss: 1.76864876e-06
Iter: 1211 loss: 1.76832907e-06
Iter: 1212 loss: 1.77214804e-06
Iter: 1213 loss: 1.7683094e-06
Iter: 1214 loss: 1.76801268e-06
Iter: 1215 loss: 1.76780077e-06
Iter: 1216 loss: 1.76777178e-06
Iter: 1217 loss: 1.76730737e-06
Iter: 1218 loss: 1.76946389e-06
Iter: 1219 loss: 1.76721221e-06
Iter: 1220 loss: 1.76701474e-06
Iter: 1221 loss: 1.76700394e-06
Iter: 1222 loss: 1.76674098e-06
Iter: 1223 loss: 1.76669744e-06
Iter: 1224 loss: 1.76661661e-06
Iter: 1225 loss: 1.76633193e-06
Iter: 1226 loss: 1.76644903e-06
Iter: 1227 loss: 1.76630294e-06
Iter: 1228 loss: 1.76575941e-06
Iter: 1229 loss: 1.77013976e-06
Iter: 1230 loss: 1.76578078e-06
Iter: 1231 loss: 1.76552851e-06
Iter: 1232 loss: 1.76672506e-06
Iter: 1233 loss: 1.76546155e-06
Iter: 1234 loss: 1.76507649e-06
Iter: 1235 loss: 1.76528647e-06
Iter: 1236 loss: 1.76494927e-06
Iter: 1237 loss: 1.76453193e-06
Iter: 1238 loss: 1.76465039e-06
Iter: 1239 loss: 1.76421031e-06
Iter: 1240 loss: 1.76365211e-06
Iter: 1241 loss: 1.76726894e-06
Iter: 1242 loss: 1.76353933e-06
Iter: 1243 loss: 1.7632874e-06
Iter: 1244 loss: 1.76429398e-06
Iter: 1245 loss: 1.76308208e-06
Iter: 1246 loss: 1.76276649e-06
Iter: 1247 loss: 1.76320202e-06
Iter: 1248 loss: 1.7625398e-06
Iter: 1249 loss: 1.76210722e-06
Iter: 1250 loss: 1.76369156e-06
Iter: 1251 loss: 1.76195408e-06
Iter: 1252 loss: 1.76160347e-06
Iter: 1253 loss: 1.76096614e-06
Iter: 1254 loss: 1.76107903e-06
Iter: 1255 loss: 1.76073718e-06
Iter: 1256 loss: 1.76063349e-06
Iter: 1257 loss: 1.76030017e-06
Iter: 1258 loss: 1.76126014e-06
Iter: 1259 loss: 1.76031426e-06
Iter: 1260 loss: 1.76006529e-06
Iter: 1261 loss: 1.76308345e-06
Iter: 1262 loss: 1.76005699e-06
Iter: 1263 loss: 1.75999298e-06
Iter: 1264 loss: 1.7596418e-06
Iter: 1265 loss: 1.76372851e-06
Iter: 1266 loss: 1.75974446e-06
Iter: 1267 loss: 1.75933314e-06
Iter: 1268 loss: 1.75908713e-06
Iter: 1269 loss: 1.75886476e-06
Iter: 1270 loss: 1.75846606e-06
Iter: 1271 loss: 1.76270203e-06
Iter: 1272 loss: 1.75848368e-06
Iter: 1273 loss: 1.75815023e-06
Iter: 1274 loss: 1.75782941e-06
Iter: 1275 loss: 1.75774016e-06
Iter: 1276 loss: 1.75716571e-06
Iter: 1277 loss: 1.75848277e-06
Iter: 1278 loss: 1.75686671e-06
Iter: 1279 loss: 1.75646687e-06
Iter: 1280 loss: 1.75758032e-06
Iter: 1281 loss: 1.75630305e-06
Iter: 1282 loss: 1.75590117e-06
Iter: 1283 loss: 1.75689127e-06
Iter: 1284 loss: 1.75576429e-06
Iter: 1285 loss: 1.75535592e-06
Iter: 1286 loss: 1.75632681e-06
Iter: 1287 loss: 1.75514072e-06
Iter: 1288 loss: 1.75474361e-06
Iter: 1289 loss: 1.7568093e-06
Iter: 1290 loss: 1.75462696e-06
Iter: 1291 loss: 1.75421701e-06
Iter: 1292 loss: 1.75426828e-06
Iter: 1293 loss: 1.75408195e-06
Iter: 1294 loss: 1.75551077e-06
Iter: 1295 loss: 1.75403409e-06
Iter: 1296 loss: 1.75384616e-06
Iter: 1297 loss: 1.7538166e-06
Iter: 1298 loss: 1.75374009e-06
Iter: 1299 loss: 1.75346497e-06
Iter: 1300 loss: 1.7530848e-06
Iter: 1301 loss: 1.75312789e-06
Iter: 1302 loss: 1.75259879e-06
Iter: 1303 loss: 1.75288392e-06
Iter: 1304 loss: 1.75219361e-06
Iter: 1305 loss: 1.75151047e-06
Iter: 1306 loss: 1.75538082e-06
Iter: 1307 loss: 1.75136631e-06
Iter: 1308 loss: 1.75101889e-06
Iter: 1309 loss: 1.75230457e-06
Iter: 1310 loss: 1.75099194e-06
Iter: 1311 loss: 1.75044818e-06
Iter: 1312 loss: 1.75112314e-06
Iter: 1313 loss: 1.7503005e-06
Iter: 1314 loss: 1.74984746e-06
Iter: 1315 loss: 1.75504067e-06
Iter: 1316 loss: 1.74987088e-06
Iter: 1317 loss: 1.74957017e-06
Iter: 1318 loss: 1.74951174e-06
Iter: 1319 loss: 1.74924344e-06
Iter: 1320 loss: 1.74888521e-06
Iter: 1321 loss: 1.74961667e-06
Iter: 1322 loss: 1.7486683e-06
Iter: 1323 loss: 1.74847446e-06
Iter: 1324 loss: 1.74843922e-06
Iter: 1325 loss: 1.7482289e-06
Iter: 1326 loss: 1.74933e-06
Iter: 1327 loss: 1.74814602e-06
Iter: 1328 loss: 1.74793695e-06
Iter: 1329 loss: 1.74800152e-06
Iter: 1330 loss: 1.74783077e-06
Iter: 1331 loss: 1.74735419e-06
Iter: 1332 loss: 1.74687295e-06
Iter: 1333 loss: 1.74694219e-06
Iter: 1334 loss: 1.74637e-06
Iter: 1335 loss: 1.74816023e-06
Iter: 1336 loss: 1.7461407e-06
Iter: 1337 loss: 1.7456814e-06
Iter: 1338 loss: 1.7480013e-06
Iter: 1339 loss: 1.74568845e-06
Iter: 1340 loss: 1.74525189e-06
Iter: 1341 loss: 1.74513298e-06
Iter: 1342 loss: 1.74482807e-06
Iter: 1343 loss: 1.74429454e-06
Iter: 1344 loss: 1.74849629e-06
Iter: 1345 loss: 1.74426941e-06
Iter: 1346 loss: 1.74393961e-06
Iter: 1347 loss: 1.74577985e-06
Iter: 1348 loss: 1.74375828e-06
Iter: 1349 loss: 1.74346269e-06
Iter: 1350 loss: 1.74413572e-06
Iter: 1351 loss: 1.74329136e-06
Iter: 1352 loss: 1.74285969e-06
Iter: 1353 loss: 1.74350316e-06
Iter: 1354 loss: 1.74268803e-06
Iter: 1355 loss: 1.74229308e-06
Iter: 1356 loss: 1.74235402e-06
Iter: 1357 loss: 1.74212369e-06
Iter: 1358 loss: 1.74306592e-06
Iter: 1359 loss: 1.74200443e-06
Iter: 1360 loss: 1.74189574e-06
Iter: 1361 loss: 1.74191086e-06
Iter: 1362 loss: 1.74163733e-06
Iter: 1363 loss: 1.74122988e-06
Iter: 1364 loss: 1.74110687e-06
Iter: 1365 loss: 1.74087575e-06
Iter: 1366 loss: 1.74059483e-06
Iter: 1367 loss: 1.74075717e-06
Iter: 1368 loss: 1.74038246e-06
Iter: 1369 loss: 1.73972398e-06
Iter: 1370 loss: 1.7405464e-06
Iter: 1371 loss: 1.73957176e-06
Iter: 1372 loss: 1.73900287e-06
Iter: 1373 loss: 1.74282263e-06
Iter: 1374 loss: 1.73885019e-06
Iter: 1375 loss: 1.73841295e-06
Iter: 1376 loss: 1.73853834e-06
Iter: 1377 loss: 1.73813578e-06
Iter: 1378 loss: 1.73764852e-06
Iter: 1379 loss: 1.74030492e-06
Iter: 1380 loss: 1.73744695e-06
Iter: 1381 loss: 1.73698254e-06
Iter: 1382 loss: 1.74153e-06
Iter: 1383 loss: 1.73700755e-06
Iter: 1384 loss: 1.73665876e-06
Iter: 1385 loss: 1.73662272e-06
Iter: 1386 loss: 1.73641729e-06
Iter: 1387 loss: 1.73615717e-06
Iter: 1388 loss: 1.74145282e-06
Iter: 1389 loss: 1.73615661e-06
Iter: 1390 loss: 1.73576e-06
Iter: 1391 loss: 1.7377148e-06
Iter: 1392 loss: 1.73577234e-06
Iter: 1393 loss: 1.73556e-06
Iter: 1394 loss: 1.73641092e-06
Iter: 1395 loss: 1.73541753e-06
Iter: 1396 loss: 1.73514684e-06
Iter: 1397 loss: 1.73491935e-06
Iter: 1398 loss: 1.73487888e-06
Iter: 1399 loss: 1.7344388e-06
Iter: 1400 loss: 1.73378851e-06
Iter: 1401 loss: 1.73386479e-06
Iter: 1402 loss: 1.73309661e-06
Iter: 1403 loss: 1.73735714e-06
Iter: 1404 loss: 1.73296621e-06
Iter: 1405 loss: 1.73243768e-06
Iter: 1406 loss: 1.7345609e-06
Iter: 1407 loss: 1.73231717e-06
Iter: 1408 loss: 1.73176613e-06
Iter: 1409 loss: 1.73178432e-06
Iter: 1410 loss: 1.73128865e-06
Iter: 1411 loss: 1.73082185e-06
Iter: 1412 loss: 1.73764749e-06
Iter: 1413 loss: 1.73074932e-06
Iter: 1414 loss: 1.73040905e-06
Iter: 1415 loss: 1.73181411e-06
Iter: 1416 loss: 1.73039757e-06
Iter: 1417 loss: 1.72994214e-06
Iter: 1418 loss: 1.73034402e-06
Iter: 1419 loss: 1.72966475e-06
Iter: 1420 loss: 1.72935711e-06
Iter: 1421 loss: 1.7323041e-06
Iter: 1422 loss: 1.72931425e-06
Iter: 1423 loss: 1.72910586e-06
Iter: 1424 loss: 1.7323556e-06
Iter: 1425 loss: 1.72900059e-06
Iter: 1426 loss: 1.72891009e-06
Iter: 1427 loss: 1.72949808e-06
Iter: 1428 loss: 1.7287507e-06
Iter: 1429 loss: 1.72849e-06
Iter: 1430 loss: 1.72811667e-06
Iter: 1431 loss: 1.73726676e-06
Iter: 1432 loss: 1.72819557e-06
Iter: 1433 loss: 1.72748787e-06
Iter: 1434 loss: 1.72806654e-06
Iter: 1435 loss: 1.72718353e-06
Iter: 1436 loss: 1.72669536e-06
Iter: 1437 loss: 1.72870205e-06
Iter: 1438 loss: 1.72652506e-06
Iter: 1439 loss: 1.72606769e-06
Iter: 1440 loss: 1.72719047e-06
Iter: 1441 loss: 1.72603347e-06
Iter: 1442 loss: 1.72548141e-06
Iter: 1443 loss: 1.72727118e-06
Iter: 1444 loss: 1.72536784e-06
Iter: 1445 loss: 1.72501132e-06
Iter: 1446 loss: 1.72669934e-06
Iter: 1447 loss: 1.72491082e-06
Iter: 1448 loss: 1.7246972e-06
Iter: 1449 loss: 1.72507805e-06
Iter: 1450 loss: 1.72449097e-06
Iter: 1451 loss: 1.72413922e-06
Iter: 1452 loss: 1.72518526e-06
Iter: 1453 loss: 1.72400564e-06
Iter: 1454 loss: 1.72388479e-06
Iter: 1455 loss: 1.725228e-06
Iter: 1456 loss: 1.72384603e-06
Iter: 1457 loss: 1.72353509e-06
Iter: 1458 loss: 1.72355203e-06
Iter: 1459 loss: 1.72339446e-06
Iter: 1460 loss: 1.72363229e-06
Iter: 1461 loss: 1.72336865e-06
Iter: 1462 loss: 1.72314049e-06
Iter: 1463 loss: 1.72286013e-06
Iter: 1464 loss: 1.72283524e-06
Iter: 1465 loss: 1.72252044e-06
Iter: 1466 loss: 1.72344869e-06
Iter: 1467 loss: 1.722457e-06
Iter: 1468 loss: 1.72231171e-06
Iter: 1469 loss: 1.72220052e-06
Iter: 1470 loss: 1.72214072e-06
Iter: 1471 loss: 1.72172463e-06
Iter: 1472 loss: 1.72263128e-06
Iter: 1473 loss: 1.7216297e-06
Iter: 1474 loss: 1.72126227e-06
Iter: 1475 loss: 1.7230484e-06
Iter: 1476 loss: 1.72131183e-06
Iter: 1477 loss: 1.72087402e-06
Iter: 1478 loss: 1.72130626e-06
Iter: 1479 loss: 1.72077705e-06
Iter: 1480 loss: 1.72024579e-06
Iter: 1481 loss: 1.72292448e-06
Iter: 1482 loss: 1.72022237e-06
Iter: 1483 loss: 1.71992963e-06
Iter: 1484 loss: 1.72099237e-06
Iter: 1485 loss: 1.71966531e-06
Iter: 1486 loss: 1.71942042e-06
Iter: 1487 loss: 1.71955071e-06
Iter: 1488 loss: 1.71911756e-06
Iter: 1489 loss: 1.71873342e-06
Iter: 1490 loss: 1.71869419e-06
Iter: 1491 loss: 1.71841452e-06
Iter: 1492 loss: 1.71912063e-06
Iter: 1493 loss: 1.71840065e-06
Iter: 1494 loss: 1.71813826e-06
Iter: 1495 loss: 1.71803856e-06
Iter: 1496 loss: 1.71790271e-06
Iter: 1497 loss: 1.71765532e-06
Iter: 1498 loss: 1.71771865e-06
Iter: 1499 loss: 1.71750185e-06
Iter: 1500 loss: 1.71710747e-06
Iter: 1501 loss: 1.71679721e-06
Iter: 1502 loss: 1.71669103e-06
Iter: 1503 loss: 1.7160736e-06
Iter: 1504 loss: 1.71958561e-06
Iter: 1505 loss: 1.71594945e-06
Iter: 1506 loss: 1.71555041e-06
Iter: 1507 loss: 1.71698684e-06
Iter: 1508 loss: 1.71537613e-06
Iter: 1509 loss: 1.71480053e-06
Iter: 1510 loss: 1.71553938e-06
Iter: 1511 loss: 1.71465e-06
Iter: 1512 loss: 1.71415047e-06
Iter: 1513 loss: 1.71985857e-06
Iter: 1514 loss: 1.71411591e-06
Iter: 1515 loss: 1.71389263e-06
Iter: 1516 loss: 1.71414899e-06
Iter: 1517 loss: 1.7136847e-06
Iter: 1518 loss: 1.71332545e-06
Iter: 1519 loss: 1.71414331e-06
Iter: 1520 loss: 1.71319766e-06
Iter: 1521 loss: 1.71299178e-06
Iter: 1522 loss: 1.71303816e-06
Iter: 1523 loss: 1.71282159e-06
Iter: 1524 loss: 1.71323245e-06
Iter: 1525 loss: 1.71284591e-06
Iter: 1526 loss: 1.7126124e-06
Iter: 1527 loss: 1.71264128e-06
Iter: 1528 loss: 1.71241459e-06
Iter: 1529 loss: 1.71234785e-06
Iter: 1530 loss: 1.712021e-06
Iter: 1531 loss: 1.71204874e-06
Iter: 1532 loss: 1.71164231e-06
Iter: 1533 loss: 1.71285137e-06
Iter: 1534 loss: 1.71159877e-06
Iter: 1535 loss: 1.71126544e-06
Iter: 1536 loss: 1.71153022e-06
Iter: 1537 loss: 1.71111924e-06
Iter: 1538 loss: 1.71070644e-06
Iter: 1539 loss: 1.71121292e-06
Iter: 1540 loss: 1.71042097e-06
Iter: 1541 loss: 1.71010686e-06
Iter: 1542 loss: 1.71289821e-06
Iter: 1543 loss: 1.70993269e-06
Iter: 1544 loss: 1.70970475e-06
Iter: 1545 loss: 1.71051772e-06
Iter: 1546 loss: 1.70967155e-06
Iter: 1547 loss: 1.7093339e-06
Iter: 1548 loss: 1.70980184e-06
Iter: 1549 loss: 1.7092126e-06
Iter: 1550 loss: 1.70882959e-06
Iter: 1551 loss: 1.70957151e-06
Iter: 1552 loss: 1.70874773e-06
Iter: 1553 loss: 1.70854582e-06
Iter: 1554 loss: 1.7085016e-06
Iter: 1555 loss: 1.70829185e-06
Iter: 1556 loss: 1.70855287e-06
Iter: 1557 loss: 1.70820601e-06
Iter: 1558 loss: 1.70788212e-06
Iter: 1559 loss: 1.70849239e-06
Iter: 1560 loss: 1.70789508e-06
Iter: 1561 loss: 1.70769306e-06
Iter: 1562 loss: 1.70736712e-06
Iter: 1563 loss: 1.71463603e-06
Iter: 1564 loss: 1.70734245e-06
Iter: 1565 loss: 1.70695284e-06
Iter: 1566 loss: 1.70926864e-06
Iter: 1567 loss: 1.70683097e-06
Iter: 1568 loss: 1.70652584e-06
Iter: 1569 loss: 1.70622468e-06
Iter: 1570 loss: 1.70620024e-06
Iter: 1571 loss: 1.7056625e-06
Iter: 1572 loss: 1.70821284e-06
Iter: 1573 loss: 1.70565022e-06
Iter: 1574 loss: 1.70537601e-06
Iter: 1575 loss: 1.7064408e-06
Iter: 1576 loss: 1.70530234e-06
Iter: 1577 loss: 1.7048352e-06
Iter: 1578 loss: 1.70509111e-06
Iter: 1579 loss: 1.70461863e-06
Iter: 1580 loss: 1.70416035e-06
Iter: 1581 loss: 1.70615101e-06
Iter: 1582 loss: 1.70405497e-06
Iter: 1583 loss: 1.70381622e-06
Iter: 1584 loss: 1.70493138e-06
Iter: 1585 loss: 1.70366297e-06
Iter: 1586 loss: 1.70360613e-06
Iter: 1587 loss: 1.7035884e-06
Iter: 1588 loss: 1.70336307e-06
Iter: 1589 loss: 1.70367059e-06
Iter: 1590 loss: 1.70335511e-06
Iter: 1591 loss: 1.70301348e-06
Iter: 1592 loss: 1.70394333e-06
Iter: 1593 loss: 1.7030136e-06
Iter: 1594 loss: 1.70298608e-06
Iter: 1595 loss: 1.702605e-06
Iter: 1596 loss: 1.7082931e-06
Iter: 1597 loss: 1.70257795e-06
Iter: 1598 loss: 1.7022212e-06
Iter: 1599 loss: 1.70272415e-06
Iter: 1600 loss: 1.70208352e-06
Iter: 1601 loss: 1.70153726e-06
Iter: 1602 loss: 1.70249825e-06
Iter: 1603 loss: 1.70136514e-06
Iter: 1604 loss: 1.70117221e-06
Iter: 1605 loss: 1.7025302e-06
Iter: 1606 loss: 1.70115072e-06
Iter: 1607 loss: 1.7008058e-06
Iter: 1608 loss: 1.7007967e-06
Iter: 1609 loss: 1.70056137e-06
Iter: 1610 loss: 1.70022054e-06
Iter: 1611 loss: 1.7037155e-06
Iter: 1612 loss: 1.70026897e-06
Iter: 1613 loss: 1.69995292e-06
Iter: 1614 loss: 1.70053056e-06
Iter: 1615 loss: 1.69991051e-06
Iter: 1616 loss: 1.69956934e-06
Iter: 1617 loss: 1.69978489e-06
Iter: 1618 loss: 1.69941143e-06
Iter: 1619 loss: 1.69917735e-06
Iter: 1620 loss: 1.70095018e-06
Iter: 1621 loss: 1.69911391e-06
Iter: 1622 loss: 1.69887221e-06
Iter: 1623 loss: 1.70252656e-06
Iter: 1624 loss: 1.69894815e-06
Iter: 1625 loss: 1.69885e-06
Iter: 1626 loss: 1.6988356e-06
Iter: 1627 loss: 1.69868451e-06
Iter: 1628 loss: 1.69844e-06
Iter: 1629 loss: 1.69811733e-06
Iter: 1630 loss: 1.69811312e-06
Iter: 1631 loss: 1.69770419e-06
Iter: 1632 loss: 1.69779071e-06
Iter: 1633 loss: 1.697519e-06
Iter: 1634 loss: 1.69722091e-06
Iter: 1635 loss: 1.70017529e-06
Iter: 1636 loss: 1.69724899e-06
Iter: 1637 loss: 1.69699206e-06
Iter: 1638 loss: 1.69664429e-06
Iter: 1639 loss: 1.69655777e-06
Iter: 1640 loss: 1.69632801e-06
Iter: 1641 loss: 1.7014188e-06
Iter: 1642 loss: 1.69628379e-06
Iter: 1643 loss: 1.69601367e-06
Iter: 1644 loss: 1.69635223e-06
Iter: 1645 loss: 1.69596819e-06
Iter: 1646 loss: 1.69560451e-06
Iter: 1647 loss: 1.69672649e-06
Iter: 1648 loss: 1.69562702e-06
Iter: 1649 loss: 1.69525731e-06
Iter: 1650 loss: 1.69592931e-06
Iter: 1651 loss: 1.69524492e-06
Iter: 1652 loss: 1.69503551e-06
Iter: 1653 loss: 1.69653799e-06
Iter: 1654 loss: 1.69498639e-06
Iter: 1655 loss: 1.69492978e-06
Iter: 1656 loss: 1.69493921e-06
Iter: 1657 loss: 1.69486862e-06
Iter: 1658 loss: 1.69478199e-06
Iter: 1659 loss: 1.69472128e-06
Iter: 1660 loss: 1.69459008e-06
Iter: 1661 loss: 1.69446878e-06
Iter: 1662 loss: 1.69447685e-06
Iter: 1663 loss: 1.69415785e-06
Iter: 1664 loss: 1.69398936e-06
Iter: 1665 loss: 1.69395105e-06
Iter: 1666 loss: 1.69351654e-06
Iter: 1667 loss: 1.69461555e-06
Iter: 1668 loss: 1.6934132e-06
Iter: 1669 loss: 1.69297391e-06
Iter: 1670 loss: 1.69377711e-06
Iter: 1671 loss: 1.69273255e-06
Iter: 1672 loss: 1.69241e-06
Iter: 1673 loss: 1.69397208e-06
Iter: 1674 loss: 1.69228485e-06
Iter: 1675 loss: 1.69193709e-06
Iter: 1676 loss: 1.69155612e-06
Iter: 1677 loss: 1.69151849e-06
Iter: 1678 loss: 1.69102964e-06
Iter: 1679 loss: 1.69110342e-06
Iter: 1680 loss: 1.69082909e-06
Iter: 1681 loss: 1.69080351e-06
Iter: 1682 loss: 1.69069449e-06
Iter: 1683 loss: 1.69031364e-06
Iter: 1684 loss: 1.69008183e-06
Iter: 1685 loss: 1.68998906e-06
Iter: 1686 loss: 1.69023201e-06
Iter: 1687 loss: 1.68982115e-06
Iter: 1688 loss: 1.68966324e-06
Iter: 1689 loss: 1.68952442e-06
Iter: 1690 loss: 1.68942961e-06
Iter: 1691 loss: 1.68913618e-06
Iter: 1692 loss: 1.68983718e-06
Iter: 1693 loss: 1.68900647e-06
Iter: 1694 loss: 1.68868894e-06
Iter: 1695 loss: 1.68840791e-06
Iter: 1696 loss: 1.6883306e-06
Iter: 1697 loss: 1.68797021e-06
Iter: 1698 loss: 1.69079578e-06
Iter: 1699 loss: 1.68797305e-06
Iter: 1700 loss: 1.68767644e-06
Iter: 1701 loss: 1.68792428e-06
Iter: 1702 loss: 1.6873995e-06
Iter: 1703 loss: 1.68706106e-06
Iter: 1704 loss: 1.68766189e-06
Iter: 1705 loss: 1.68686324e-06
Iter: 1706 loss: 1.68663837e-06
Iter: 1707 loss: 1.68830798e-06
Iter: 1708 loss: 1.68654219e-06
Iter: 1709 loss: 1.6861818e-06
Iter: 1710 loss: 1.6866245e-06
Iter: 1711 loss: 1.68594806e-06
Iter: 1712 loss: 1.68568715e-06
Iter: 1713 loss: 1.68687336e-06
Iter: 1714 loss: 1.68563577e-06
Iter: 1715 loss: 1.6853852e-06
Iter: 1716 loss: 1.68776808e-06
Iter: 1717 loss: 1.68537053e-06
Iter: 1718 loss: 1.68510837e-06
Iter: 1719 loss: 1.68514441e-06
Iter: 1720 loss: 1.68497843e-06
Iter: 1721 loss: 1.68473207e-06
Iter: 1722 loss: 1.68467443e-06
Iter: 1723 loss: 1.68456427e-06
Iter: 1724 loss: 1.68434826e-06
Iter: 1725 loss: 1.68439146e-06
Iter: 1726 loss: 1.68415841e-06
Iter: 1727 loss: 1.68476208e-06
Iter: 1728 loss: 1.68402585e-06
Iter: 1729 loss: 1.68379438e-06
Iter: 1730 loss: 1.68351278e-06
Iter: 1731 loss: 1.69119699e-06
Iter: 1732 loss: 1.68354779e-06
Iter: 1733 loss: 1.68310066e-06
Iter: 1734 loss: 1.68377699e-06
Iter: 1735 loss: 1.68280553e-06
Iter: 1736 loss: 1.68240297e-06
Iter: 1737 loss: 1.68724193e-06
Iter: 1738 loss: 1.68237909e-06
Iter: 1739 loss: 1.68185113e-06
Iter: 1740 loss: 1.68150336e-06
Iter: 1741 loss: 1.68143413e-06
Iter: 1742 loss: 1.68100314e-06
Iter: 1743 loss: 1.68780434e-06
Iter: 1744 loss: 1.68090401e-06
Iter: 1745 loss: 1.68061524e-06
Iter: 1746 loss: 1.68199699e-06
Iter: 1747 loss: 1.68044153e-06
Iter: 1748 loss: 1.68015094e-06
Iter: 1749 loss: 1.68007023e-06
Iter: 1750 loss: 1.67981705e-06
Iter: 1751 loss: 1.67948792e-06
Iter: 1752 loss: 1.6794661e-06
Iter: 1753 loss: 1.67933956e-06
Iter: 1754 loss: 1.68103293e-06
Iter: 1755 loss: 1.67938299e-06
Iter: 1756 loss: 1.67916812e-06
Iter: 1757 loss: 1.67912162e-06
Iter: 1758 loss: 1.67902226e-06
Iter: 1759 loss: 1.67880103e-06
Iter: 1760 loss: 1.67958422e-06
Iter: 1761 loss: 1.67864459e-06
Iter: 1762 loss: 1.67839357e-06
Iter: 1763 loss: 1.67884627e-06
Iter: 1764 loss: 1.67828955e-06
Iter: 1765 loss: 1.67804637e-06
Iter: 1766 loss: 1.67811413e-06
Iter: 1767 loss: 1.67794167e-06
Iter: 1768 loss: 1.67763119e-06
Iter: 1769 loss: 1.67761118e-06
Iter: 1770 loss: 1.67727967e-06
Iter: 1771 loss: 1.67696589e-06
Iter: 1772 loss: 1.68222095e-06
Iter: 1773 loss: 1.67683106e-06
Iter: 1774 loss: 1.6766403e-06
Iter: 1775 loss: 1.67687676e-06
Iter: 1776 loss: 1.67650137e-06
Iter: 1777 loss: 1.67620738e-06
Iter: 1778 loss: 1.67903931e-06
Iter: 1779 loss: 1.67623602e-06
Iter: 1780 loss: 1.67594612e-06
Iter: 1781 loss: 1.67596284e-06
Iter: 1782 loss: 1.67582016e-06
Iter: 1783 loss: 1.67542044e-06
Iter: 1784 loss: 1.67532585e-06
Iter: 1785 loss: 1.67503254e-06
Iter: 1786 loss: 1.67530038e-06
Iter: 1787 loss: 1.67508153e-06
Iter: 1788 loss: 1.67500968e-06
Iter: 1789 loss: 1.67501e-06
Iter: 1790 loss: 1.67500752e-06
Iter: 1791 loss: 1.67497387e-06
Iter: 1792 loss: 1.67499343e-06
Iter: 1793 loss: 1.675004e-06
Iter: 1794 loss: 1.67504413e-06
Iter: 1795 loss: 1.67504027e-06
Iter: 1796 loss: 1.67502799e-06
Iter: 1797 loss: 1.67501639e-06
Iter: 1798 loss: 1.67500662e-06
Iter: 1799 loss: 1.67502481e-06
Iter: 1800 loss: 1.67506903e-06
Iter: 1801 loss: 1.67505596e-06
Iter: 1802 loss: 1.67501594e-06
Iter: 1803 loss: 1.67505175e-06
Iter: 1804 loss: 1.67501901e-06
Iter: 1805 loss: 1.67502174e-06
Iter: 1806 loss: 1.67503833e-06
Iter: 1807 loss: 1.67503367e-06
Iter: 1808 loss: 1.67503981e-06
Iter: 1809 loss: 1.67504015e-06
Iter: 1810 loss: 1.67503401e-06
Iter: 1811 loss: 1.67503401e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_8000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215b48bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215b457b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215ab8bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215afc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215a43f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215a43598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22159c5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f221597e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f221597e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f221597e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f221595d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f221591bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22159069d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22158b52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215906ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22158e3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22158a0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22158669d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215815ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22157d3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22157c0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215796598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2215723158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22156fcd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22156fc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22156fc6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f21c3251f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22156fc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f21c320e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f21c31fc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f21c31cb598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f21c3193268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f21c31a7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f21c3187a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f21c316a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f219c22ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.93823463e-05
Iter: 2 loss: 0.00061587675
Iter: 3 loss: 4.02751612e-05
Iter: 4 loss: 3.25685141e-05
Iter: 5 loss: 3.34048236e-05
Iter: 6 loss: 2.66608567e-05
Iter: 7 loss: 2.17579254e-05
Iter: 8 loss: 4.60227711e-05
Iter: 9 loss: 2.09282753e-05
Iter: 10 loss: 1.79557574e-05
Iter: 11 loss: 4.16492039e-05
Iter: 12 loss: 1.77531219e-05
Iter: 13 loss: 1.56404058e-05
Iter: 14 loss: 1.48527761e-05
Iter: 15 loss: 1.368625e-05
Iter: 16 loss: 1.15828161e-05
Iter: 17 loss: 2.46530653e-05
Iter: 18 loss: 1.13363849e-05
Iter: 19 loss: 1.04940182e-05
Iter: 20 loss: 1.02415952e-05
Iter: 21 loss: 9.73748593e-06
Iter: 22 loss: 8.66180471e-06
Iter: 23 loss: 1.17032141e-05
Iter: 24 loss: 8.31921534e-06
Iter: 25 loss: 7.69828239e-06
Iter: 26 loss: 1.35191995e-05
Iter: 27 loss: 7.67301481e-06
Iter: 28 loss: 7.37103073e-06
Iter: 29 loss: 7.41160511e-06
Iter: 30 loss: 7.14123416e-06
Iter: 31 loss: 6.78591186e-06
Iter: 32 loss: 6.48416471e-06
Iter: 33 loss: 6.38572737e-06
Iter: 34 loss: 6.14008e-06
Iter: 35 loss: 8.56796214e-06
Iter: 36 loss: 6.13165867e-06
Iter: 37 loss: 5.97276903e-06
Iter: 38 loss: 5.95823622e-06
Iter: 39 loss: 5.90673108e-06
Iter: 40 loss: 5.79952e-06
Iter: 41 loss: 7.65093318e-06
Iter: 42 loss: 5.79744e-06
Iter: 43 loss: 5.69846543e-06
Iter: 44 loss: 7.01834688e-06
Iter: 45 loss: 5.69776284e-06
Iter: 46 loss: 5.63201729e-06
Iter: 47 loss: 5.74319392e-06
Iter: 48 loss: 5.60224225e-06
Iter: 49 loss: 5.52882102e-06
Iter: 50 loss: 5.47417221e-06
Iter: 51 loss: 5.4498e-06
Iter: 52 loss: 5.31652086e-06
Iter: 53 loss: 5.62293098e-06
Iter: 54 loss: 5.2669393e-06
Iter: 55 loss: 5.18485558e-06
Iter: 56 loss: 5.40944075e-06
Iter: 57 loss: 5.15802458e-06
Iter: 58 loss: 5.05860862e-06
Iter: 59 loss: 5.24934467e-06
Iter: 60 loss: 5.01691102e-06
Iter: 61 loss: 4.91188393e-06
Iter: 62 loss: 5.08769108e-06
Iter: 63 loss: 4.8639813e-06
Iter: 64 loss: 4.78538777e-06
Iter: 65 loss: 5.82187931e-06
Iter: 66 loss: 4.78498714e-06
Iter: 67 loss: 4.7308431e-06
Iter: 68 loss: 4.71004387e-06
Iter: 69 loss: 4.6805726e-06
Iter: 70 loss: 4.71832755e-06
Iter: 71 loss: 4.65060566e-06
Iter: 72 loss: 4.63307606e-06
Iter: 73 loss: 4.57831402e-06
Iter: 74 loss: 4.69138922e-06
Iter: 75 loss: 4.54451674e-06
Iter: 76 loss: 4.51585265e-06
Iter: 77 loss: 4.50375774e-06
Iter: 78 loss: 4.47492039e-06
Iter: 79 loss: 4.47826187e-06
Iter: 80 loss: 4.45267369e-06
Iter: 81 loss: 4.39830728e-06
Iter: 82 loss: 4.36277605e-06
Iter: 83 loss: 4.34189224e-06
Iter: 84 loss: 4.28593376e-06
Iter: 85 loss: 4.93744938e-06
Iter: 86 loss: 4.28528438e-06
Iter: 87 loss: 4.24803875e-06
Iter: 88 loss: 4.20586912e-06
Iter: 89 loss: 4.20049582e-06
Iter: 90 loss: 4.14022816e-06
Iter: 91 loss: 4.68678809e-06
Iter: 92 loss: 4.1374692e-06
Iter: 93 loss: 4.0956993e-06
Iter: 94 loss: 4.16958346e-06
Iter: 95 loss: 4.07731841e-06
Iter: 96 loss: 4.04067441e-06
Iter: 97 loss: 4.17446699e-06
Iter: 98 loss: 4.03122431e-06
Iter: 99 loss: 3.99446708e-06
Iter: 100 loss: 4.14159194e-06
Iter: 101 loss: 3.98591419e-06
Iter: 102 loss: 3.98567818e-06
Iter: 103 loss: 3.97472377e-06
Iter: 104 loss: 3.96453243e-06
Iter: 105 loss: 3.93695291e-06
Iter: 106 loss: 4.1277226e-06
Iter: 107 loss: 3.93049595e-06
Iter: 108 loss: 3.91031972e-06
Iter: 109 loss: 4.11341671e-06
Iter: 110 loss: 3.90975583e-06
Iter: 111 loss: 3.8866151e-06
Iter: 112 loss: 3.95602592e-06
Iter: 113 loss: 3.87963792e-06
Iter: 114 loss: 3.85938574e-06
Iter: 115 loss: 3.89377828e-06
Iter: 116 loss: 3.85027352e-06
Iter: 117 loss: 3.83619226e-06
Iter: 118 loss: 3.83448605e-06
Iter: 119 loss: 3.82448934e-06
Iter: 120 loss: 3.79413837e-06
Iter: 121 loss: 3.76266303e-06
Iter: 122 loss: 3.75695345e-06
Iter: 123 loss: 3.71858914e-06
Iter: 124 loss: 4.08982123e-06
Iter: 125 loss: 3.71698616e-06
Iter: 126 loss: 3.68320048e-06
Iter: 127 loss: 3.73311696e-06
Iter: 128 loss: 3.66676613e-06
Iter: 129 loss: 3.63167305e-06
Iter: 130 loss: 3.69770396e-06
Iter: 131 loss: 3.61668208e-06
Iter: 132 loss: 3.58019088e-06
Iter: 133 loss: 3.897037e-06
Iter: 134 loss: 3.57841918e-06
Iter: 135 loss: 3.57299518e-06
Iter: 136 loss: 3.56958799e-06
Iter: 137 loss: 3.56034252e-06
Iter: 138 loss: 3.54011308e-06
Iter: 139 loss: 3.82856433e-06
Iter: 140 loss: 3.53902851e-06
Iter: 141 loss: 3.52207439e-06
Iter: 142 loss: 3.52850543e-06
Iter: 143 loss: 3.50993787e-06
Iter: 144 loss: 3.4841355e-06
Iter: 145 loss: 3.73772946e-06
Iter: 146 loss: 3.48303752e-06
Iter: 147 loss: 3.46733918e-06
Iter: 148 loss: 3.50637674e-06
Iter: 149 loss: 3.46181878e-06
Iter: 150 loss: 3.44993759e-06
Iter: 151 loss: 3.43171268e-06
Iter: 152 loss: 3.43146166e-06
Iter: 153 loss: 3.40171391e-06
Iter: 154 loss: 3.50358505e-06
Iter: 155 loss: 3.39379221e-06
Iter: 156 loss: 3.37344795e-06
Iter: 157 loss: 3.40072302e-06
Iter: 158 loss: 3.36315316e-06
Iter: 159 loss: 3.3380943e-06
Iter: 160 loss: 3.46030151e-06
Iter: 161 loss: 3.33364756e-06
Iter: 162 loss: 3.31046385e-06
Iter: 163 loss: 3.31386218e-06
Iter: 164 loss: 3.29289219e-06
Iter: 165 loss: 3.27603766e-06
Iter: 166 loss: 3.27529597e-06
Iter: 167 loss: 3.26751092e-06
Iter: 168 loss: 3.38589734e-06
Iter: 169 loss: 3.26743475e-06
Iter: 170 loss: 3.25830524e-06
Iter: 171 loss: 3.24170492e-06
Iter: 172 loss: 3.2417729e-06
Iter: 173 loss: 3.22675578e-06
Iter: 174 loss: 3.21754032e-06
Iter: 175 loss: 3.21128141e-06
Iter: 176 loss: 3.20117329e-06
Iter: 177 loss: 3.19789115e-06
Iter: 178 loss: 3.19097376e-06
Iter: 179 loss: 3.19268702e-06
Iter: 180 loss: 3.18574098e-06
Iter: 181 loss: 3.17544209e-06
Iter: 182 loss: 3.15911188e-06
Iter: 183 loss: 3.15886382e-06
Iter: 184 loss: 3.14097224e-06
Iter: 185 loss: 3.32439572e-06
Iter: 186 loss: 3.14042381e-06
Iter: 187 loss: 3.12927909e-06
Iter: 188 loss: 3.11788472e-06
Iter: 189 loss: 3.11578151e-06
Iter: 190 loss: 3.09665757e-06
Iter: 191 loss: 3.25942619e-06
Iter: 192 loss: 3.09557095e-06
Iter: 193 loss: 3.07906475e-06
Iter: 194 loss: 3.09733514e-06
Iter: 195 loss: 3.07016398e-06
Iter: 196 loss: 3.05778985e-06
Iter: 197 loss: 3.16718979e-06
Iter: 198 loss: 3.05733465e-06
Iter: 199 loss: 3.05091226e-06
Iter: 200 loss: 3.05061076e-06
Iter: 201 loss: 3.04395462e-06
Iter: 202 loss: 3.03388788e-06
Iter: 203 loss: 3.03354136e-06
Iter: 204 loss: 3.02433523e-06
Iter: 205 loss: 3.02718877e-06
Iter: 206 loss: 3.01752289e-06
Iter: 207 loss: 3.01378486e-06
Iter: 208 loss: 3.01213709e-06
Iter: 209 loss: 3.00807415e-06
Iter: 210 loss: 3.00228885e-06
Iter: 211 loss: 3.0018939e-06
Iter: 212 loss: 2.99141334e-06
Iter: 213 loss: 2.98090526e-06
Iter: 214 loss: 2.97856695e-06
Iter: 215 loss: 2.96374492e-06
Iter: 216 loss: 3.06089487e-06
Iter: 217 loss: 2.96222788e-06
Iter: 218 loss: 2.94881147e-06
Iter: 219 loss: 2.95294035e-06
Iter: 220 loss: 2.9393766e-06
Iter: 221 loss: 2.92371624e-06
Iter: 222 loss: 2.97282622e-06
Iter: 223 loss: 2.91907395e-06
Iter: 224 loss: 2.90311732e-06
Iter: 225 loss: 2.99281123e-06
Iter: 226 loss: 2.90085177e-06
Iter: 227 loss: 2.89133322e-06
Iter: 228 loss: 2.91095785e-06
Iter: 229 loss: 2.88753881e-06
Iter: 230 loss: 2.88098636e-06
Iter: 231 loss: 2.88056435e-06
Iter: 232 loss: 2.87350349e-06
Iter: 233 loss: 2.87420062e-06
Iter: 234 loss: 2.86813497e-06
Iter: 235 loss: 2.86281556e-06
Iter: 236 loss: 2.85473538e-06
Iter: 237 loss: 2.85454166e-06
Iter: 238 loss: 2.8483496e-06
Iter: 239 loss: 2.848127e-06
Iter: 240 loss: 2.84124917e-06
Iter: 241 loss: 2.83544296e-06
Iter: 242 loss: 2.83352801e-06
Iter: 243 loss: 2.82186784e-06
Iter: 244 loss: 2.8528757e-06
Iter: 245 loss: 2.81796883e-06
Iter: 246 loss: 2.81008556e-06
Iter: 247 loss: 2.82653582e-06
Iter: 248 loss: 2.80691e-06
Iter: 249 loss: 2.7967842e-06
Iter: 250 loss: 2.79335768e-06
Iter: 251 loss: 2.78766129e-06
Iter: 252 loss: 2.77400454e-06
Iter: 253 loss: 2.8436209e-06
Iter: 254 loss: 2.77151889e-06
Iter: 255 loss: 2.76253786e-06
Iter: 256 loss: 2.8513773e-06
Iter: 257 loss: 2.76235e-06
Iter: 258 loss: 2.75504635e-06
Iter: 259 loss: 2.74174454e-06
Iter: 260 loss: 3.06118682e-06
Iter: 261 loss: 2.74181639e-06
Iter: 262 loss: 2.75270509e-06
Iter: 263 loss: 2.73644036e-06
Iter: 264 loss: 2.73241085e-06
Iter: 265 loss: 2.73698561e-06
Iter: 266 loss: 2.73029582e-06
Iter: 267 loss: 2.72699253e-06
Iter: 268 loss: 2.71980753e-06
Iter: 269 loss: 2.81438406e-06
Iter: 270 loss: 2.71917543e-06
Iter: 271 loss: 2.71253248e-06
Iter: 272 loss: 2.7921742e-06
Iter: 273 loss: 2.71250701e-06
Iter: 274 loss: 2.70530563e-06
Iter: 275 loss: 2.71822637e-06
Iter: 276 loss: 2.70228747e-06
Iter: 277 loss: 2.6970115e-06
Iter: 278 loss: 2.7147521e-06
Iter: 279 loss: 2.6957855e-06
Iter: 280 loss: 2.6919779e-06
Iter: 281 loss: 2.69056613e-06
Iter: 282 loss: 2.68844724e-06
Iter: 283 loss: 2.68232725e-06
Iter: 284 loss: 2.69940483e-06
Iter: 285 loss: 2.68033227e-06
Iter: 286 loss: 2.67400401e-06
Iter: 287 loss: 2.68508416e-06
Iter: 288 loss: 2.67133191e-06
Iter: 289 loss: 2.66644042e-06
Iter: 290 loss: 2.70830401e-06
Iter: 291 loss: 2.66604911e-06
Iter: 292 loss: 2.66204302e-06
Iter: 293 loss: 2.66118604e-06
Iter: 294 loss: 2.65831591e-06
Iter: 295 loss: 2.65636868e-06
Iter: 296 loss: 2.65555627e-06
Iter: 297 loss: 2.65253698e-06
Iter: 298 loss: 2.65824156e-06
Iter: 299 loss: 2.65112112e-06
Iter: 300 loss: 2.64822165e-06
Iter: 301 loss: 2.64024879e-06
Iter: 302 loss: 2.69294878e-06
Iter: 303 loss: 2.63819697e-06
Iter: 304 loss: 2.63231823e-06
Iter: 305 loss: 2.63224501e-06
Iter: 306 loss: 2.62686081e-06
Iter: 307 loss: 2.64668734e-06
Iter: 308 loss: 2.62542881e-06
Iter: 309 loss: 2.62157232e-06
Iter: 310 loss: 2.62927961e-06
Iter: 311 loss: 2.61981882e-06
Iter: 312 loss: 2.61547825e-06
Iter: 313 loss: 2.60913521e-06
Iter: 314 loss: 2.60886645e-06
Iter: 315 loss: 2.59918761e-06
Iter: 316 loss: 2.63713582e-06
Iter: 317 loss: 2.59686749e-06
Iter: 318 loss: 2.58944033e-06
Iter: 319 loss: 2.6215439e-06
Iter: 320 loss: 2.58802424e-06
Iter: 321 loss: 2.58240561e-06
Iter: 322 loss: 2.58724867e-06
Iter: 323 loss: 2.57904549e-06
Iter: 324 loss: 2.57051033e-06
Iter: 325 loss: 2.58803516e-06
Iter: 326 loss: 2.56705198e-06
Iter: 327 loss: 2.56487715e-06
Iter: 328 loss: 2.5635245e-06
Iter: 329 loss: 2.56088856e-06
Iter: 330 loss: 2.5734314e-06
Iter: 331 loss: 2.56029148e-06
Iter: 332 loss: 2.55829741e-06
Iter: 333 loss: 2.5529007e-06
Iter: 334 loss: 2.58794626e-06
Iter: 335 loss: 2.55160262e-06
Iter: 336 loss: 2.54564588e-06
Iter: 337 loss: 2.58009e-06
Iter: 338 loss: 2.5448619e-06
Iter: 339 loss: 2.54093766e-06
Iter: 340 loss: 2.54067686e-06
Iter: 341 loss: 2.53919848e-06
Iter: 342 loss: 2.53759254e-06
Iter: 343 loss: 2.53733e-06
Iter: 344 loss: 2.53387316e-06
Iter: 345 loss: 2.53075768e-06
Iter: 346 loss: 2.52984341e-06
Iter: 347 loss: 2.52491668e-06
Iter: 348 loss: 2.56097042e-06
Iter: 349 loss: 2.52457357e-06
Iter: 350 loss: 2.52037853e-06
Iter: 351 loss: 2.51964957e-06
Iter: 352 loss: 2.51701113e-06
Iter: 353 loss: 2.50992775e-06
Iter: 354 loss: 2.52154814e-06
Iter: 355 loss: 2.50677613e-06
Iter: 356 loss: 2.49924915e-06
Iter: 357 loss: 2.56018893e-06
Iter: 358 loss: 2.49880168e-06
Iter: 359 loss: 2.4940166e-06
Iter: 360 loss: 2.495231e-06
Iter: 361 loss: 2.49069126e-06
Iter: 362 loss: 2.48781043e-06
Iter: 363 loss: 2.48645301e-06
Iter: 364 loss: 2.48421952e-06
Iter: 365 loss: 2.47860453e-06
Iter: 366 loss: 2.5299089e-06
Iter: 367 loss: 2.47771095e-06
Iter: 368 loss: 2.47329262e-06
Iter: 369 loss: 2.48988044e-06
Iter: 370 loss: 2.47210482e-06
Iter: 371 loss: 2.47030016e-06
Iter: 372 loss: 2.46987042e-06
Iter: 373 loss: 2.46770605e-06
Iter: 374 loss: 2.46413492e-06
Iter: 375 loss: 2.46412378e-06
Iter: 376 loss: 2.45966885e-06
Iter: 377 loss: 2.47614844e-06
Iter: 378 loss: 2.4585911e-06
Iter: 379 loss: 2.45554747e-06
Iter: 380 loss: 2.45761157e-06
Iter: 381 loss: 2.45380943e-06
Iter: 382 loss: 2.44975126e-06
Iter: 383 loss: 2.45413435e-06
Iter: 384 loss: 2.44758371e-06
Iter: 385 loss: 2.44245985e-06
Iter: 386 loss: 2.44264629e-06
Iter: 387 loss: 2.43831937e-06
Iter: 388 loss: 2.43434761e-06
Iter: 389 loss: 2.47991716e-06
Iter: 390 loss: 2.43416571e-06
Iter: 391 loss: 2.43066711e-06
Iter: 392 loss: 2.42773626e-06
Iter: 393 loss: 2.42669921e-06
Iter: 394 loss: 2.42453052e-06
Iter: 395 loss: 2.42404394e-06
Iter: 396 loss: 2.42102169e-06
Iter: 397 loss: 2.42616352e-06
Iter: 398 loss: 2.41979569e-06
Iter: 399 loss: 2.41799194e-06
Iter: 400 loss: 2.41485031e-06
Iter: 401 loss: 2.41492057e-06
Iter: 402 loss: 2.41128964e-06
Iter: 403 loss: 2.42342185e-06
Iter: 404 loss: 2.41037242e-06
Iter: 405 loss: 2.40632448e-06
Iter: 406 loss: 2.45213505e-06
Iter: 407 loss: 2.40630902e-06
Iter: 408 loss: 2.40451936e-06
Iter: 409 loss: 2.40419172e-06
Iter: 410 loss: 2.40293e-06
Iter: 411 loss: 2.40035388e-06
Iter: 412 loss: 2.40182e-06
Iter: 413 loss: 2.39855308e-06
Iter: 414 loss: 2.3953296e-06
Iter: 415 loss: 2.40160693e-06
Iter: 416 loss: 2.39408564e-06
Iter: 417 loss: 2.39007204e-06
Iter: 418 loss: 2.39649262e-06
Iter: 419 loss: 2.38821326e-06
Iter: 420 loss: 2.38493794e-06
Iter: 421 loss: 2.38814073e-06
Iter: 422 loss: 2.38318307e-06
Iter: 423 loss: 2.38004964e-06
Iter: 424 loss: 2.42628539e-06
Iter: 425 loss: 2.38002531e-06
Iter: 426 loss: 2.37797803e-06
Iter: 427 loss: 2.38060306e-06
Iter: 428 loss: 2.37717313e-06
Iter: 429 loss: 2.37771565e-06
Iter: 430 loss: 2.37613131e-06
Iter: 431 loss: 2.37566246e-06
Iter: 432 loss: 2.37402196e-06
Iter: 433 loss: 2.36995083e-06
Iter: 434 loss: 2.46242371e-06
Iter: 435 loss: 2.37000813e-06
Iter: 436 loss: 2.36491246e-06
Iter: 437 loss: 2.38386042e-06
Iter: 438 loss: 2.36367532e-06
Iter: 439 loss: 2.36180904e-06
Iter: 440 loss: 2.36070127e-06
Iter: 441 loss: 2.35845619e-06
Iter: 442 loss: 2.3626967e-06
Iter: 443 loss: 2.35742641e-06
Iter: 444 loss: 2.35561015e-06
Iter: 445 loss: 2.35674474e-06
Iter: 446 loss: 2.35446032e-06
Iter: 447 loss: 2.35264042e-06
Iter: 448 loss: 2.36205551e-06
Iter: 449 loss: 2.35250491e-06
Iter: 450 loss: 2.35070934e-06
Iter: 451 loss: 2.34646268e-06
Iter: 452 loss: 2.38854955e-06
Iter: 453 loss: 2.34586014e-06
Iter: 454 loss: 2.34104937e-06
Iter: 455 loss: 2.38778057e-06
Iter: 456 loss: 2.34080358e-06
Iter: 457 loss: 2.33809965e-06
Iter: 458 loss: 2.35720881e-06
Iter: 459 loss: 2.33771834e-06
Iter: 460 loss: 2.33499736e-06
Iter: 461 loss: 2.32916727e-06
Iter: 462 loss: 2.43525437e-06
Iter: 463 loss: 2.32908178e-06
Iter: 464 loss: 2.33971969e-06
Iter: 465 loss: 2.32767206e-06
Iter: 466 loss: 2.3262287e-06
Iter: 467 loss: 2.32368484e-06
Iter: 468 loss: 2.37408062e-06
Iter: 469 loss: 2.3235666e-06
Iter: 470 loss: 2.32119464e-06
Iter: 471 loss: 2.31578861e-06
Iter: 472 loss: 2.39197334e-06
Iter: 473 loss: 2.31556919e-06
Iter: 474 loss: 2.31472086e-06
Iter: 475 loss: 2.31315653e-06
Iter: 476 loss: 2.31103149e-06
Iter: 477 loss: 2.33057699e-06
Iter: 478 loss: 2.31102263e-06
Iter: 479 loss: 2.31001309e-06
Iter: 480 loss: 2.30902606e-06
Iter: 481 loss: 2.30887099e-06
Iter: 482 loss: 2.3069465e-06
Iter: 483 loss: 2.30314754e-06
Iter: 484 loss: 2.3897046e-06
Iter: 485 loss: 2.30307069e-06
Iter: 486 loss: 2.29969055e-06
Iter: 487 loss: 2.31048898e-06
Iter: 488 loss: 2.29870193e-06
Iter: 489 loss: 2.29550687e-06
Iter: 490 loss: 2.32242292e-06
Iter: 491 loss: 2.29541729e-06
Iter: 492 loss: 2.29188868e-06
Iter: 493 loss: 2.28996055e-06
Iter: 494 loss: 2.28847057e-06
Iter: 495 loss: 2.28537465e-06
Iter: 496 loss: 2.32398e-06
Iter: 497 loss: 2.28537056e-06
Iter: 498 loss: 2.28286058e-06
Iter: 499 loss: 2.28241538e-06
Iter: 500 loss: 2.2806621e-06
Iter: 501 loss: 2.27885494e-06
Iter: 502 loss: 2.27809505e-06
Iter: 503 loss: 2.27700866e-06
Iter: 504 loss: 2.27480587e-06
Iter: 505 loss: 2.30450678e-06
Iter: 506 loss: 2.27460896e-06
Iter: 507 loss: 2.27237115e-06
Iter: 508 loss: 2.27370174e-06
Iter: 509 loss: 2.27101054e-06
Iter: 510 loss: 2.26922e-06
Iter: 511 loss: 2.2691529e-06
Iter: 512 loss: 2.26754901e-06
Iter: 513 loss: 2.27373926e-06
Iter: 514 loss: 2.26701559e-06
Iter: 515 loss: 2.26605061e-06
Iter: 516 loss: 2.26450402e-06
Iter: 517 loss: 2.26443785e-06
Iter: 518 loss: 2.26219208e-06
Iter: 519 loss: 2.26416751e-06
Iter: 520 loss: 2.26071961e-06
Iter: 521 loss: 2.25798294e-06
Iter: 522 loss: 2.26218708e-06
Iter: 523 loss: 2.25658323e-06
Iter: 524 loss: 2.25370809e-06
Iter: 525 loss: 2.25268514e-06
Iter: 526 loss: 2.2508907e-06
Iter: 527 loss: 2.24945893e-06
Iter: 528 loss: 2.24853784e-06
Iter: 529 loss: 2.24748692e-06
Iter: 530 loss: 2.24522182e-06
Iter: 531 loss: 2.28875524e-06
Iter: 532 loss: 2.2451477e-06
Iter: 533 loss: 2.24331825e-06
Iter: 534 loss: 2.24318319e-06
Iter: 535 loss: 2.24082942e-06
Iter: 536 loss: 2.24715677e-06
Iter: 537 loss: 2.23993629e-06
Iter: 538 loss: 2.23886582e-06
Iter: 539 loss: 2.23729467e-06
Iter: 540 loss: 2.27947476e-06
Iter: 541 loss: 2.23729239e-06
Iter: 542 loss: 2.23508687e-06
Iter: 543 loss: 2.25330859e-06
Iter: 544 loss: 2.23493589e-06
Iter: 545 loss: 2.23330721e-06
Iter: 546 loss: 2.2456295e-06
Iter: 547 loss: 2.2332174e-06
Iter: 548 loss: 2.23215602e-06
Iter: 549 loss: 2.23188272e-06
Iter: 550 loss: 2.23130951e-06
Iter: 551 loss: 2.22986864e-06
Iter: 552 loss: 2.22793938e-06
Iter: 553 loss: 2.22801282e-06
Iter: 554 loss: 2.22498556e-06
Iter: 555 loss: 2.24345899e-06
Iter: 556 loss: 2.22466429e-06
Iter: 557 loss: 2.22326162e-06
Iter: 558 loss: 2.22284507e-06
Iter: 559 loss: 2.22185236e-06
Iter: 560 loss: 2.21955702e-06
Iter: 561 loss: 2.23634561e-06
Iter: 562 loss: 2.21927485e-06
Iter: 563 loss: 2.21730943e-06
Iter: 564 loss: 2.22633798e-06
Iter: 565 loss: 2.21689106e-06
Iter: 566 loss: 2.215221e-06
Iter: 567 loss: 2.21205119e-06
Iter: 568 loss: 2.27852388e-06
Iter: 569 loss: 2.2119093e-06
Iter: 570 loss: 2.21836717e-06
Iter: 571 loss: 2.21080768e-06
Iter: 572 loss: 2.21029359e-06
Iter: 573 loss: 2.2089348e-06
Iter: 574 loss: 2.21473829e-06
Iter: 575 loss: 2.2083625e-06
Iter: 576 loss: 2.20595257e-06
Iter: 577 loss: 2.20647712e-06
Iter: 578 loss: 2.2040831e-06
Iter: 579 loss: 2.20224092e-06
Iter: 580 loss: 2.22765198e-06
Iter: 581 loss: 2.20225047e-06
Iter: 582 loss: 2.20010179e-06
Iter: 583 loss: 2.20471406e-06
Iter: 584 loss: 2.19923982e-06
Iter: 585 loss: 2.19801768e-06
Iter: 586 loss: 2.19692083e-06
Iter: 587 loss: 2.19665844e-06
Iter: 588 loss: 2.19414892e-06
Iter: 589 loss: 2.1959479e-06
Iter: 590 loss: 2.19284175e-06
Iter: 591 loss: 2.19097774e-06
Iter: 592 loss: 2.21799314e-06
Iter: 593 loss: 2.1910771e-06
Iter: 594 loss: 2.18991e-06
Iter: 595 loss: 2.18758578e-06
Iter: 596 loss: 2.22972676e-06
Iter: 597 loss: 2.18744071e-06
Iter: 598 loss: 2.18478181e-06
Iter: 599 loss: 2.21569144e-06
Iter: 600 loss: 2.18475043e-06
Iter: 601 loss: 2.18264222e-06
Iter: 602 loss: 2.18776495e-06
Iter: 603 loss: 2.18206105e-06
Iter: 604 loss: 2.18053447e-06
Iter: 605 loss: 2.17941124e-06
Iter: 606 loss: 2.17882234e-06
Iter: 607 loss: 2.1786625e-06
Iter: 608 loss: 2.17733668e-06
Iter: 609 loss: 2.17678917e-06
Iter: 610 loss: 2.17507272e-06
Iter: 611 loss: 2.17656589e-06
Iter: 612 loss: 2.17362253e-06
Iter: 613 loss: 2.17098136e-06
Iter: 614 loss: 2.17005027e-06
Iter: 615 loss: 2.16864464e-06
Iter: 616 loss: 2.16691387e-06
Iter: 617 loss: 2.16631588e-06
Iter: 618 loss: 2.16441413e-06
Iter: 619 loss: 2.17639672e-06
Iter: 620 loss: 2.16410672e-06
Iter: 621 loss: 2.16268472e-06
Iter: 622 loss: 2.16175317e-06
Iter: 623 loss: 2.16126773e-06
Iter: 624 loss: 2.15933e-06
Iter: 625 loss: 2.16276567e-06
Iter: 626 loss: 2.15833848e-06
Iter: 627 loss: 2.15652517e-06
Iter: 628 loss: 2.16108629e-06
Iter: 629 loss: 2.15586283e-06
Iter: 630 loss: 2.15430964e-06
Iter: 631 loss: 2.16244143e-06
Iter: 632 loss: 2.15404384e-06
Iter: 633 loss: 2.15240516e-06
Iter: 634 loss: 2.15118666e-06
Iter: 635 loss: 2.15082014e-06
Iter: 636 loss: 2.14859392e-06
Iter: 637 loss: 2.16803528e-06
Iter: 638 loss: 2.14840657e-06
Iter: 639 loss: 2.14868396e-06
Iter: 640 loss: 2.14788e-06
Iter: 641 loss: 2.14718102e-06
Iter: 642 loss: 2.14550528e-06
Iter: 643 loss: 2.15754653e-06
Iter: 644 loss: 2.14519491e-06
Iter: 645 loss: 2.14359989e-06
Iter: 646 loss: 2.14376e-06
Iter: 647 loss: 2.14238912e-06
Iter: 648 loss: 2.13972817e-06
Iter: 649 loss: 2.13598287e-06
Iter: 650 loss: 2.13591466e-06
Iter: 651 loss: 2.13318822e-06
Iter: 652 loss: 2.13308454e-06
Iter: 653 loss: 2.13152521e-06
Iter: 654 loss: 2.13144358e-06
Iter: 655 loss: 2.13068529e-06
Iter: 656 loss: 2.12952068e-06
Iter: 657 loss: 2.12942973e-06
Iter: 658 loss: 2.1277333e-06
Iter: 659 loss: 2.13253816e-06
Iter: 660 loss: 2.12715395e-06
Iter: 661 loss: 2.1255064e-06
Iter: 662 loss: 2.1289361e-06
Iter: 663 loss: 2.12480154e-06
Iter: 664 loss: 2.12302234e-06
Iter: 665 loss: 2.12482132e-06
Iter: 666 loss: 2.12207738e-06
Iter: 667 loss: 2.11988549e-06
Iter: 668 loss: 2.12555642e-06
Iter: 669 loss: 2.11911652e-06
Iter: 670 loss: 2.1170722e-06
Iter: 671 loss: 2.13653e-06
Iter: 672 loss: 2.1170631e-06
Iter: 673 loss: 2.11628799e-06
Iter: 674 loss: 2.11613269e-06
Iter: 675 loss: 2.11561792e-06
Iter: 676 loss: 2.11421e-06
Iter: 677 loss: 2.11848601e-06
Iter: 678 loss: 2.11340739e-06
Iter: 679 loss: 2.11102088e-06
Iter: 680 loss: 2.11036e-06
Iter: 681 loss: 2.10900089e-06
Iter: 682 loss: 2.10609846e-06
Iter: 683 loss: 2.13567068e-06
Iter: 684 loss: 2.10610733e-06
Iter: 685 loss: 2.10478902e-06
Iter: 686 loss: 2.1070291e-06
Iter: 687 loss: 2.10416897e-06
Iter: 688 loss: 2.10193139e-06
Iter: 689 loss: 2.1135329e-06
Iter: 690 loss: 2.10152439e-06
Iter: 691 loss: 2.10070857e-06
Iter: 692 loss: 2.09860855e-06
Iter: 693 loss: 2.13862e-06
Iter: 694 loss: 2.09869654e-06
Iter: 695 loss: 2.09677046e-06
Iter: 696 loss: 2.10860776e-06
Iter: 697 loss: 2.0964676e-06
Iter: 698 loss: 2.09503423e-06
Iter: 699 loss: 2.0947557e-06
Iter: 700 loss: 2.09364316e-06
Iter: 701 loss: 2.09216614e-06
Iter: 702 loss: 2.09440987e-06
Iter: 703 loss: 2.09137784e-06
Iter: 704 loss: 2.09022915e-06
Iter: 705 loss: 2.08900542e-06
Iter: 706 loss: 2.08888559e-06
Iter: 707 loss: 2.09439804e-06
Iter: 708 loss: 2.08820074e-06
Iter: 709 loss: 2.08766505e-06
Iter: 710 loss: 2.087e-06
Iter: 711 loss: 2.08692541e-06
Iter: 712 loss: 2.08503388e-06
Iter: 713 loss: 2.09468362e-06
Iter: 714 loss: 2.08474694e-06
Iter: 715 loss: 2.08354277e-06
Iter: 716 loss: 2.09508471e-06
Iter: 717 loss: 2.08350184e-06
Iter: 718 loss: 2.08215488e-06
Iter: 719 loss: 2.0812879e-06
Iter: 720 loss: 2.08070787e-06
Iter: 721 loss: 2.08114716e-06
Iter: 722 loss: 2.07996095e-06
Iter: 723 loss: 2.07942844e-06
Iter: 724 loss: 2.07817288e-06
Iter: 725 loss: 2.09539212e-06
Iter: 726 loss: 2.07805283e-06
Iter: 727 loss: 2.07674861e-06
Iter: 728 loss: 2.07638277e-06
Iter: 729 loss: 2.07569019e-06
Iter: 730 loss: 2.07466633e-06
Iter: 731 loss: 2.07627886e-06
Iter: 732 loss: 2.07409767e-06
Iter: 733 loss: 2.07313815e-06
Iter: 734 loss: 2.07503786e-06
Iter: 735 loss: 2.07281209e-06
Iter: 736 loss: 2.07156972e-06
Iter: 737 loss: 2.07250855e-06
Iter: 738 loss: 2.07084236e-06
Iter: 739 loss: 2.06926302e-06
Iter: 740 loss: 2.09317659e-06
Iter: 741 loss: 2.06930144e-06
Iter: 742 loss: 2.06802406e-06
Iter: 743 loss: 2.06983032e-06
Iter: 744 loss: 2.06727577e-06
Iter: 745 loss: 2.06555342e-06
Iter: 746 loss: 2.07166227e-06
Iter: 747 loss: 2.06513459e-06
Iter: 748 loss: 2.06407844e-06
Iter: 749 loss: 2.06600657e-06
Iter: 750 loss: 2.0635739e-06
Iter: 751 loss: 2.06237337e-06
Iter: 752 loss: 2.06697905e-06
Iter: 753 loss: 2.06205414e-06
Iter: 754 loss: 2.06116033e-06
Iter: 755 loss: 2.06022196e-06
Iter: 756 loss: 2.05989045e-06
Iter: 757 loss: 2.05839979e-06
Iter: 758 loss: 2.05834885e-06
Iter: 759 loss: 2.05735682e-06
Iter: 760 loss: 2.05737206e-06
Iter: 761 loss: 2.05673746e-06
Iter: 762 loss: 2.05584251e-06
Iter: 763 loss: 2.05581728e-06
Iter: 764 loss: 2.05436436e-06
Iter: 765 loss: 2.05722836e-06
Iter: 766 loss: 2.05373863e-06
Iter: 767 loss: 2.0524958e-06
Iter: 768 loss: 2.07140965e-06
Iter: 769 loss: 2.05246488e-06
Iter: 770 loss: 2.05164088e-06
Iter: 771 loss: 2.05118477e-06
Iter: 772 loss: 2.05079687e-06
Iter: 773 loss: 2.05015567e-06
Iter: 774 loss: 2.05591823e-06
Iter: 775 loss: 2.04998082e-06
Iter: 776 loss: 2.04935441e-06
Iter: 777 loss: 2.0477255e-06
Iter: 778 loss: 2.07149969e-06
Iter: 779 loss: 2.04765774e-06
Iter: 780 loss: 2.0464222e-06
Iter: 781 loss: 2.04638582e-06
Iter: 782 loss: 2.04523849e-06
Iter: 783 loss: 2.04782e-06
Iter: 784 loss: 2.04475327e-06
Iter: 785 loss: 2.04360117e-06
Iter: 786 loss: 2.04420121e-06
Iter: 787 loss: 2.04286061e-06
Iter: 788 loss: 2.04128514e-06
Iter: 789 loss: 2.04099183e-06
Iter: 790 loss: 2.03996842e-06
Iter: 791 loss: 2.03944569e-06
Iter: 792 loss: 2.0391376e-06
Iter: 793 loss: 2.03853051e-06
Iter: 794 loss: 2.03719719e-06
Iter: 795 loss: 2.03717536e-06
Iter: 796 loss: 2.03567129e-06
Iter: 797 loss: 2.05231709e-06
Iter: 798 loss: 2.0357611e-06
Iter: 799 loss: 2.03488344e-06
Iter: 800 loss: 2.0353034e-06
Iter: 801 loss: 2.03437594e-06
Iter: 802 loss: 2.03321633e-06
Iter: 803 loss: 2.04849584e-06
Iter: 804 loss: 2.03311947e-06
Iter: 805 loss: 2.03265904e-06
Iter: 806 loss: 2.03352965e-06
Iter: 807 loss: 2.03233549e-06
Iter: 808 loss: 2.03129571e-06
Iter: 809 loss: 2.03012928e-06
Iter: 810 loss: 2.02991532e-06
Iter: 811 loss: 2.02856245e-06
Iter: 812 loss: 2.03061563e-06
Iter: 813 loss: 2.02791807e-06
Iter: 814 loss: 2.0268908e-06
Iter: 815 loss: 2.0269224e-06
Iter: 816 loss: 2.02615229e-06
Iter: 817 loss: 2.02608885e-06
Iter: 818 loss: 2.02562569e-06
Iter: 819 loss: 2.02440742e-06
Iter: 820 loss: 2.02446427e-06
Iter: 821 loss: 2.02346018e-06
Iter: 822 loss: 2.02228898e-06
Iter: 823 loss: 2.03385775e-06
Iter: 824 loss: 2.02224169e-06
Iter: 825 loss: 2.02124352e-06
Iter: 826 loss: 2.03070113e-06
Iter: 827 loss: 2.02125511e-06
Iter: 828 loss: 2.0206935e-06
Iter: 829 loss: 2.02069759e-06
Iter: 830 loss: 2.02011165e-06
Iter: 831 loss: 2.01953162e-06
Iter: 832 loss: 2.02678166e-06
Iter: 833 loss: 2.01946432e-06
Iter: 834 loss: 2.01908665e-06
Iter: 835 loss: 2.02075807e-06
Iter: 836 loss: 2.01891635e-06
Iter: 837 loss: 2.01842136e-06
Iter: 838 loss: 2.01805278e-06
Iter: 839 loss: 2.01786361e-06
Iter: 840 loss: 2.017e-06
Iter: 841 loss: 2.01996295e-06
Iter: 842 loss: 2.01666944e-06
Iter: 843 loss: 2.01605235e-06
Iter: 844 loss: 2.01468379e-06
Iter: 845 loss: 2.03647414e-06
Iter: 846 loss: 2.01461626e-06
Iter: 847 loss: 2.01260173e-06
Iter: 848 loss: 2.01473858e-06
Iter: 849 loss: 2.01143916e-06
Iter: 850 loss: 2.01064131e-06
Iter: 851 loss: 2.01011585e-06
Iter: 852 loss: 2.00930276e-06
Iter: 853 loss: 2.00791055e-06
Iter: 854 loss: 2.0374473e-06
Iter: 855 loss: 2.0078387e-06
Iter: 856 loss: 2.00604472e-06
Iter: 857 loss: 2.02050524e-06
Iter: 858 loss: 2.0059565e-06
Iter: 859 loss: 2.00504678e-06
Iter: 860 loss: 2.01529883e-06
Iter: 861 loss: 2.00502382e-06
Iter: 862 loss: 2.00451814e-06
Iter: 863 loss: 2.00568184e-06
Iter: 864 loss: 2.00425097e-06
Iter: 865 loss: 2.00374348e-06
Iter: 866 loss: 2.00468185e-06
Iter: 867 loss: 2.00337968e-06
Iter: 868 loss: 2.00260183e-06
Iter: 869 loss: 2.00470458e-06
Iter: 870 loss: 2.00236263e-06
Iter: 871 loss: 2.00141767e-06
Iter: 872 loss: 2.00499971e-06
Iter: 873 loss: 2.00126442e-06
Iter: 874 loss: 2.00066415e-06
Iter: 875 loss: 2.00240379e-06
Iter: 876 loss: 2.00050476e-06
Iter: 877 loss: 2.00001796e-06
Iter: 878 loss: 1.99903775e-06
Iter: 879 loss: 2.01464536e-06
Iter: 880 loss: 1.99901251e-06
Iter: 881 loss: 1.99765509e-06
Iter: 882 loss: 1.99939427e-06
Iter: 883 loss: 1.99693795e-06
Iter: 884 loss: 1.99647616e-06
Iter: 885 loss: 1.99636656e-06
Iter: 886 loss: 1.99564602e-06
Iter: 887 loss: 1.99430133e-06
Iter: 888 loss: 1.99438227e-06
Iter: 889 loss: 1.99291981e-06
Iter: 890 loss: 1.99709984e-06
Iter: 891 loss: 1.99241549e-06
Iter: 892 loss: 1.99149235e-06
Iter: 893 loss: 1.99136434e-06
Iter: 894 loss: 1.99092574e-06
Iter: 895 loss: 1.99583656e-06
Iter: 896 loss: 1.99085298e-06
Iter: 897 loss: 1.99034366e-06
Iter: 898 loss: 1.98943735e-06
Iter: 899 loss: 2.00983641e-06
Iter: 900 loss: 1.98949874e-06
Iter: 901 loss: 1.98872863e-06
Iter: 902 loss: 1.98865564e-06
Iter: 903 loss: 1.98828798e-06
Iter: 904 loss: 1.98881139e-06
Iter: 905 loss: 1.98824614e-06
Iter: 906 loss: 1.98790872e-06
Iter: 907 loss: 1.98771659e-06
Iter: 908 loss: 1.98748967e-06
Iter: 909 loss: 1.98684916e-06
Iter: 910 loss: 1.98680209e-06
Iter: 911 loss: 1.98619364e-06
Iter: 912 loss: 1.98524413e-06
Iter: 913 loss: 1.98461294e-06
Iter: 914 loss: 1.98428779e-06
Iter: 915 loss: 1.98301723e-06
Iter: 916 loss: 1.98354405e-06
Iter: 917 loss: 1.98226371e-06
Iter: 918 loss: 1.98112275e-06
Iter: 919 loss: 1.9810409e-06
Iter: 920 loss: 1.98011048e-06
Iter: 921 loss: 1.97950749e-06
Iter: 922 loss: 1.97917484e-06
Iter: 923 loss: 1.97811778e-06
Iter: 924 loss: 1.9935062e-06
Iter: 925 loss: 1.97809095e-06
Iter: 926 loss: 1.97733971e-06
Iter: 927 loss: 1.97589975e-06
Iter: 928 loss: 1.97596455e-06
Iter: 929 loss: 1.97543932e-06
Iter: 930 loss: 1.97475265e-06
Iter: 931 loss: 1.9743236e-06
Iter: 932 loss: 1.97359259e-06
Iter: 933 loss: 1.97354711e-06
Iter: 934 loss: 1.97276586e-06
Iter: 935 loss: 1.98203634e-06
Iter: 936 loss: 1.9728634e-06
Iter: 937 loss: 1.97207737e-06
Iter: 938 loss: 1.97988857e-06
Iter: 939 loss: 1.97198642e-06
Iter: 940 loss: 1.97173313e-06
Iter: 941 loss: 1.97089457e-06
Iter: 942 loss: 1.97404734e-06
Iter: 943 loss: 1.97047143e-06
Iter: 944 loss: 1.96939527e-06
Iter: 945 loss: 1.9696522e-06
Iter: 946 loss: 1.9686413e-06
Iter: 947 loss: 1.96800738e-06
Iter: 948 loss: 1.96789733e-06
Iter: 949 loss: 1.9674485e-06
Iter: 950 loss: 1.9686463e-06
Iter: 951 loss: 1.96733299e-06
Iter: 952 loss: 1.96662018e-06
Iter: 953 loss: 1.96632595e-06
Iter: 954 loss: 1.96607789e-06
Iter: 955 loss: 1.96506471e-06
Iter: 956 loss: 1.96424207e-06
Iter: 957 loss: 1.96399719e-06
Iter: 958 loss: 1.96388737e-06
Iter: 959 loss: 1.96344263e-06
Iter: 960 loss: 1.96305245e-06
Iter: 961 loss: 1.96209749e-06
Iter: 962 loss: 1.97597433e-06
Iter: 963 loss: 1.96205497e-06
Iter: 964 loss: 1.96156e-06
Iter: 965 loss: 1.97066447e-06
Iter: 966 loss: 1.96152541e-06
Iter: 967 loss: 1.96087626e-06
Iter: 968 loss: 1.96292785e-06
Iter: 969 loss: 1.96064502e-06
Iter: 970 loss: 1.96013207e-06
Iter: 971 loss: 1.96468909e-06
Iter: 972 loss: 1.96010569e-06
Iter: 973 loss: 1.9597278e-06
Iter: 974 loss: 1.95927169e-06
Iter: 975 loss: 1.95916618e-06
Iter: 976 loss: 1.95831444e-06
Iter: 977 loss: 1.9574295e-06
Iter: 978 loss: 1.95739267e-06
Iter: 979 loss: 1.95641906e-06
Iter: 980 loss: 1.95837265e-06
Iter: 981 loss: 1.95620805e-06
Iter: 982 loss: 1.95518464e-06
Iter: 983 loss: 1.95887583e-06
Iter: 984 loss: 1.95499865e-06
Iter: 985 loss: 1.95383927e-06
Iter: 986 loss: 1.96243673e-06
Iter: 987 loss: 1.9537415e-06
Iter: 988 loss: 1.95318353e-06
Iter: 989 loss: 1.95344273e-06
Iter: 990 loss: 1.95267512e-06
Iter: 991 loss: 1.95188773e-06
Iter: 992 loss: 1.95167604e-06
Iter: 993 loss: 1.95122607e-06
Iter: 994 loss: 1.95066423e-06
Iter: 995 loss: 1.95059056e-06
Iter: 996 loss: 1.95003531e-06
Iter: 997 loss: 1.94996551e-06
Iter: 998 loss: 1.94954237e-06
Iter: 999 loss: 1.94892164e-06
Iter: 1000 loss: 1.95660709e-06
Iter: 1001 loss: 1.94889481e-06
Iter: 1002 loss: 1.94860127e-06
Iter: 1003 loss: 1.94940321e-06
Iter: 1004 loss: 1.94837503e-06
Iter: 1005 loss: 1.94785457e-06
Iter: 1006 loss: 1.94753784e-06
Iter: 1007 loss: 1.94739687e-06
Iter: 1008 loss: 1.94653239e-06
Iter: 1009 loss: 1.94804602e-06
Iter: 1010 loss: 1.94615222e-06
Iter: 1011 loss: 1.94567042e-06
Iter: 1012 loss: 1.94496715e-06
Iter: 1013 loss: 1.94490349e-06
Iter: 1014 loss: 1.9441527e-06
Iter: 1015 loss: 1.94731865e-06
Iter: 1016 loss: 1.94385802e-06
Iter: 1017 loss: 1.94359291e-06
Iter: 1018 loss: 1.9435588e-06
Iter: 1019 loss: 1.94317454e-06
Iter: 1020 loss: 1.94211657e-06
Iter: 1021 loss: 1.95500525e-06
Iter: 1022 loss: 1.94217159e-06
Iter: 1023 loss: 1.94070208e-06
Iter: 1024 loss: 1.94337372e-06
Iter: 1025 loss: 1.94026143e-06
Iter: 1026 loss: 1.93938649e-06
Iter: 1027 loss: 1.94700488e-06
Iter: 1028 loss: 1.93940014e-06
Iter: 1029 loss: 1.93871415e-06
Iter: 1030 loss: 1.9440804e-06
Iter: 1031 loss: 1.93868141e-06
Iter: 1032 loss: 1.93813503e-06
Iter: 1033 loss: 1.93837514e-06
Iter: 1034 loss: 1.93776441e-06
Iter: 1035 loss: 1.9369154e-06
Iter: 1036 loss: 1.93937717e-06
Iter: 1037 loss: 1.9366164e-06
Iter: 1038 loss: 1.93606138e-06
Iter: 1039 loss: 1.94474046e-06
Iter: 1040 loss: 1.9358481e-06
Iter: 1041 loss: 1.93566029e-06
Iter: 1042 loss: 1.93499272e-06
Iter: 1043 loss: 1.93496498e-06
Iter: 1044 loss: 1.93414326e-06
Iter: 1045 loss: 1.93360302e-06
Iter: 1046 loss: 1.93328287e-06
Iter: 1047 loss: 1.93237429e-06
Iter: 1048 loss: 1.93309461e-06
Iter: 1049 loss: 1.93171854e-06
Iter: 1050 loss: 1.93087499e-06
Iter: 1051 loss: 1.94352219e-06
Iter: 1052 loss: 1.93092592e-06
Iter: 1053 loss: 1.93016399e-06
Iter: 1054 loss: 1.93188225e-06
Iter: 1055 loss: 1.92976017e-06
Iter: 1056 loss: 1.92917037e-06
Iter: 1057 loss: 1.92909783e-06
Iter: 1058 loss: 1.92855055e-06
Iter: 1059 loss: 1.92768266e-06
Iter: 1060 loss: 1.92920834e-06
Iter: 1061 loss: 1.92729067e-06
Iter: 1062 loss: 1.9265965e-06
Iter: 1063 loss: 1.92655261e-06
Iter: 1064 loss: 1.92594325e-06
Iter: 1065 loss: 1.92574566e-06
Iter: 1066 loss: 1.92537073e-06
Iter: 1067 loss: 1.92495781e-06
Iter: 1068 loss: 1.92485641e-06
Iter: 1069 loss: 1.9246e-06
Iter: 1070 loss: 1.92516654e-06
Iter: 1071 loss: 1.92440393e-06
Iter: 1072 loss: 1.92383141e-06
Iter: 1073 loss: 1.92272682e-06
Iter: 1074 loss: 1.93946835e-06
Iter: 1075 loss: 1.92274911e-06
Iter: 1076 loss: 1.92191033e-06
Iter: 1077 loss: 1.92187235e-06
Iter: 1078 loss: 1.92151833e-06
Iter: 1079 loss: 1.92050538e-06
Iter: 1080 loss: 1.9336635e-06
Iter: 1081 loss: 1.92044649e-06
Iter: 1082 loss: 1.91921708e-06
Iter: 1083 loss: 1.92722473e-06
Iter: 1084 loss: 1.91919412e-06
Iter: 1085 loss: 1.91831487e-06
Iter: 1086 loss: 1.93095775e-06
Iter: 1087 loss: 1.91841082e-06
Iter: 1088 loss: 1.91786648e-06
Iter: 1089 loss: 1.91736854e-06
Iter: 1090 loss: 1.9174272e-06
Iter: 1091 loss: 1.91673462e-06
Iter: 1092 loss: 1.91924937e-06
Iter: 1093 loss: 1.91649247e-06
Iter: 1094 loss: 1.91602294e-06
Iter: 1095 loss: 1.92087782e-06
Iter: 1096 loss: 1.91601748e-06
Iter: 1097 loss: 1.91557638e-06
Iter: 1098 loss: 1.91765548e-06
Iter: 1099 loss: 1.91551362e-06
Iter: 1100 loss: 1.91526215e-06
Iter: 1101 loss: 1.91554227e-06
Iter: 1102 loss: 1.9149893e-06
Iter: 1103 loss: 1.91452364e-06
Iter: 1104 loss: 1.91644131e-06
Iter: 1105 loss: 1.91442768e-06
Iter: 1106 loss: 1.913912e-06
Iter: 1107 loss: 1.91497702e-06
Iter: 1108 loss: 1.91372396e-06
Iter: 1109 loss: 1.9134809e-06
Iter: 1110 loss: 1.91304662e-06
Iter: 1111 loss: 1.91301206e-06
Iter: 1112 loss: 1.91214144e-06
Iter: 1113 loss: 1.91263e-06
Iter: 1114 loss: 1.91170329e-06
Iter: 1115 loss: 1.91091885e-06
Iter: 1116 loss: 1.91238e-06
Iter: 1117 loss: 1.9105853e-06
Iter: 1118 loss: 1.9100919e-06
Iter: 1119 loss: 1.91006302e-06
Iter: 1120 loss: 1.90949095e-06
Iter: 1121 loss: 1.90849e-06
Iter: 1122 loss: 1.90848641e-06
Iter: 1123 loss: 1.90757055e-06
Iter: 1124 loss: 1.91209392e-06
Iter: 1125 loss: 1.90744458e-06
Iter: 1126 loss: 1.90668641e-06
Iter: 1127 loss: 1.91025e-06
Iter: 1128 loss: 1.90650292e-06
Iter: 1129 loss: 1.90600872e-06
Iter: 1130 loss: 1.9060069e-06
Iter: 1131 loss: 1.90560013e-06
Iter: 1132 loss: 1.90462401e-06
Iter: 1133 loss: 1.9207605e-06
Iter: 1134 loss: 1.90460412e-06
Iter: 1135 loss: 1.90455648e-06
Iter: 1136 loss: 1.90432866e-06
Iter: 1137 loss: 1.90399658e-06
Iter: 1138 loss: 1.90427784e-06
Iter: 1139 loss: 1.90381934e-06
Iter: 1140 loss: 1.90334197e-06
Iter: 1141 loss: 1.9037011e-06
Iter: 1142 loss: 1.90307105e-06
Iter: 1143 loss: 1.902657e-06
Iter: 1144 loss: 1.90225876e-06
Iter: 1145 loss: 1.90205378e-06
Iter: 1146 loss: 1.90146761e-06
Iter: 1147 loss: 1.90551168e-06
Iter: 1148 loss: 1.90127912e-06
Iter: 1149 loss: 1.90072842e-06
Iter: 1150 loss: 1.90050423e-06
Iter: 1151 loss: 1.90025526e-06
Iter: 1152 loss: 1.89946752e-06
Iter: 1153 loss: 1.90540118e-06
Iter: 1154 loss: 1.89938226e-06
Iter: 1155 loss: 1.89888169e-06
Iter: 1156 loss: 1.89795685e-06
Iter: 1157 loss: 1.897978e-06
Iter: 1158 loss: 1.89723517e-06
Iter: 1159 loss: 1.89859884e-06
Iter: 1160 loss: 1.89678121e-06
Iter: 1161 loss: 1.8961307e-06
Iter: 1162 loss: 1.90004948e-06
Iter: 1163 loss: 1.89611683e-06
Iter: 1164 loss: 1.89582647e-06
Iter: 1165 loss: 1.89726006e-06
Iter: 1166 loss: 1.89573348e-06
Iter: 1167 loss: 1.89529305e-06
Iter: 1168 loss: 1.8950002e-06
Iter: 1169 loss: 1.89496109e-06
Iter: 1170 loss: 1.89469222e-06
Iter: 1171 loss: 1.8946896e-06
Iter: 1172 loss: 1.8943515e-06
Iter: 1173 loss: 1.89526565e-06
Iter: 1174 loss: 1.89428977e-06
Iter: 1175 loss: 1.89399339e-06
Iter: 1176 loss: 1.89414732e-06
Iter: 1177 loss: 1.89378693e-06
Iter: 1178 loss: 1.89341222e-06
Iter: 1179 loss: 1.89290552e-06
Iter: 1180 loss: 1.89281934e-06
Iter: 1181 loss: 1.89213063e-06
Iter: 1182 loss: 1.89779246e-06
Iter: 1183 loss: 1.89215029e-06
Iter: 1184 loss: 1.89156322e-06
Iter: 1185 loss: 1.89144055e-06
Iter: 1186 loss: 1.89117054e-06
Iter: 1187 loss: 1.89050093e-06
Iter: 1188 loss: 1.89053401e-06
Iter: 1189 loss: 1.89003185e-06
Iter: 1190 loss: 1.88954755e-06
Iter: 1191 loss: 1.88960075e-06
Iter: 1192 loss: 1.88904119e-06
Iter: 1193 loss: 1.8888029e-06
Iter: 1194 loss: 1.88851436e-06
Iter: 1195 loss: 1.88816989e-06
Iter: 1196 loss: 1.88797719e-06
Iter: 1197 loss: 1.88747958e-06
Iter: 1198 loss: 1.88764068e-06
Iter: 1199 loss: 1.88714716e-06
Iter: 1200 loss: 1.88666138e-06
Iter: 1201 loss: 1.88593026e-06
Iter: 1202 loss: 1.88593231e-06
Iter: 1203 loss: 1.88539855e-06
Iter: 1204 loss: 1.88539275e-06
Iter: 1205 loss: 1.88491617e-06
Iter: 1206 loss: 1.88417266e-06
Iter: 1207 loss: 1.89623063e-06
Iter: 1208 loss: 1.88416402e-06
Iter: 1209 loss: 1.88346326e-06
Iter: 1210 loss: 1.88348e-06
Iter: 1211 loss: 1.88294234e-06
Iter: 1212 loss: 1.88406682e-06
Iter: 1213 loss: 1.88264744e-06
Iter: 1214 loss: 1.88210595e-06
Iter: 1215 loss: 1.88195634e-06
Iter: 1216 loss: 1.8815432e-06
Iter: 1217 loss: 1.88101239e-06
Iter: 1218 loss: 1.88847935e-06
Iter: 1219 loss: 1.8809734e-06
Iter: 1220 loss: 1.88019817e-06
Iter: 1221 loss: 1.87989463e-06
Iter: 1222 loss: 1.87961973e-06
Iter: 1223 loss: 1.87892545e-06
Iter: 1224 loss: 1.87946694e-06
Iter: 1225 loss: 1.8785388e-06
Iter: 1226 loss: 1.87797639e-06
Iter: 1227 loss: 1.87984563e-06
Iter: 1228 loss: 1.8779424e-06
Iter: 1229 loss: 1.87742296e-06
Iter: 1230 loss: 1.88518823e-06
Iter: 1231 loss: 1.87744399e-06
Iter: 1232 loss: 1.87697606e-06
Iter: 1233 loss: 1.87759861e-06
Iter: 1234 loss: 1.87676233e-06
Iter: 1235 loss: 1.87643866e-06
Iter: 1236 loss: 1.87906494e-06
Iter: 1237 loss: 1.87636181e-06
Iter: 1238 loss: 1.8760752e-06
Iter: 1239 loss: 1.87545811e-06
Iter: 1240 loss: 1.8753293e-06
Iter: 1241 loss: 1.87492719e-06
Iter: 1242 loss: 1.87610112e-06
Iter: 1243 loss: 1.87469197e-06
Iter: 1244 loss: 1.87416958e-06
Iter: 1245 loss: 1.87805108e-06
Iter: 1246 loss: 1.87400565e-06
Iter: 1247 loss: 1.87371279e-06
Iter: 1248 loss: 1.87526325e-06
Iter: 1249 loss: 1.87357341e-06
Iter: 1250 loss: 1.87328396e-06
Iter: 1251 loss: 1.87301646e-06
Iter: 1252 loss: 1.87287287e-06
Iter: 1253 loss: 1.87253988e-06
Iter: 1254 loss: 1.87919659e-06
Iter: 1255 loss: 1.87246746e-06
Iter: 1256 loss: 1.87202693e-06
Iter: 1257 loss: 1.87109424e-06
Iter: 1258 loss: 1.88068611e-06
Iter: 1259 loss: 1.87101773e-06
Iter: 1260 loss: 1.87010869e-06
Iter: 1261 loss: 1.87404225e-06
Iter: 1262 loss: 1.87006322e-06
Iter: 1263 loss: 1.86941111e-06
Iter: 1264 loss: 1.8764033e-06
Iter: 1265 loss: 1.86938144e-06
Iter: 1266 loss: 1.86875252e-06
Iter: 1267 loss: 1.87026762e-06
Iter: 1268 loss: 1.86854982e-06
Iter: 1269 loss: 1.86817795e-06
Iter: 1270 loss: 1.87043429e-06
Iter: 1271 loss: 1.86804198e-06
Iter: 1272 loss: 1.8677124e-06
Iter: 1273 loss: 1.86797547e-06
Iter: 1274 loss: 1.86734815e-06
Iter: 1275 loss: 1.86695331e-06
Iter: 1276 loss: 1.86599107e-06
Iter: 1277 loss: 1.87758985e-06
Iter: 1278 loss: 1.8659008e-06
Iter: 1279 loss: 1.86583134e-06
Iter: 1280 loss: 1.86551301e-06
Iter: 1281 loss: 1.86523846e-06
Iter: 1282 loss: 1.86506213e-06
Iter: 1283 loss: 1.86500574e-06
Iter: 1284 loss: 1.86460215e-06
Iter: 1285 loss: 1.86596151e-06
Iter: 1286 loss: 1.86436853e-06
Iter: 1287 loss: 1.86392072e-06
Iter: 1288 loss: 1.86384113e-06
Iter: 1289 loss: 1.86353009e-06
Iter: 1290 loss: 1.86304351e-06
Iter: 1291 loss: 1.86333932e-06
Iter: 1292 loss: 1.86258262e-06
Iter: 1293 loss: 1.86220916e-06
Iter: 1294 loss: 1.86171803e-06
Iter: 1295 loss: 1.86158206e-06
Iter: 1296 loss: 1.86131979e-06
Iter: 1297 loss: 1.86119405e-06
Iter: 1298 loss: 1.86097509e-06
Iter: 1299 loss: 1.86116267e-06
Iter: 1300 loss: 1.86070577e-06
Iter: 1301 loss: 1.86041234e-06
Iter: 1302 loss: 1.86099703e-06
Iter: 1303 loss: 1.86030047e-06
Iter: 1304 loss: 1.85986585e-06
Iter: 1305 loss: 1.86236025e-06
Iter: 1306 loss: 1.85980389e-06
Iter: 1307 loss: 1.85939211e-06
Iter: 1308 loss: 1.85871363e-06
Iter: 1309 loss: 1.85862314e-06
Iter: 1310 loss: 1.85823365e-06
Iter: 1311 loss: 1.85911335e-06
Iter: 1312 loss: 1.85807903e-06
Iter: 1313 loss: 1.85772672e-06
Iter: 1314 loss: 1.85877434e-06
Iter: 1315 loss: 1.85747831e-06
Iter: 1316 loss: 1.85711428e-06
Iter: 1317 loss: 1.86220109e-06
Iter: 1318 loss: 1.85714953e-06
Iter: 1319 loss: 1.85673071e-06
Iter: 1320 loss: 1.85655404e-06
Iter: 1321 loss: 1.85639965e-06
Iter: 1322 loss: 1.85600743e-06
Iter: 1323 loss: 1.8555138e-06
Iter: 1324 loss: 1.85532758e-06
Iter: 1325 loss: 1.85445197e-06
Iter: 1326 loss: 1.86683246e-06
Iter: 1327 loss: 1.85448391e-06
Iter: 1328 loss: 1.85407839e-06
Iter: 1329 loss: 1.85574117e-06
Iter: 1330 loss: 1.85395766e-06
Iter: 1331 loss: 1.85369754e-06
Iter: 1332 loss: 1.85775934e-06
Iter: 1333 loss: 1.85369129e-06
Iter: 1334 loss: 1.85345743e-06
Iter: 1335 loss: 1.85300792e-06
Iter: 1336 loss: 1.85910721e-06
Iter: 1337 loss: 1.85301894e-06
Iter: 1338 loss: 1.85250792e-06
Iter: 1339 loss: 1.85895669e-06
Iter: 1340 loss: 1.8525443e-06
Iter: 1341 loss: 1.85214776e-06
Iter: 1342 loss: 1.85326212e-06
Iter: 1343 loss: 1.85203851e-06
Iter: 1344 loss: 1.85179897e-06
Iter: 1345 loss: 1.85125145e-06
Iter: 1346 loss: 1.86221359e-06
Iter: 1347 loss: 1.85126066e-06
Iter: 1348 loss: 1.85063641e-06
Iter: 1349 loss: 1.85042347e-06
Iter: 1350 loss: 1.85009515e-06
Iter: 1351 loss: 1.84961596e-06
Iter: 1352 loss: 1.84957105e-06
Iter: 1353 loss: 1.84915541e-06
Iter: 1354 loss: 1.84973737e-06
Iter: 1355 loss: 1.8489834e-06
Iter: 1356 loss: 1.84851228e-06
Iter: 1357 loss: 1.84808061e-06
Iter: 1358 loss: 1.84796045e-06
Iter: 1359 loss: 1.84721807e-06
Iter: 1360 loss: 1.84874466e-06
Iter: 1361 loss: 1.84685064e-06
Iter: 1362 loss: 1.84648934e-06
Iter: 1363 loss: 1.84639907e-06
Iter: 1364 loss: 1.84620558e-06
Iter: 1365 loss: 1.84910812e-06
Iter: 1366 loss: 1.84624173e-06
Iter: 1367 loss: 1.8459408e-06
Iter: 1368 loss: 1.8454823e-06
Iter: 1369 loss: 1.85238127e-06
Iter: 1370 loss: 1.84562873e-06
Iter: 1371 loss: 1.84526732e-06
Iter: 1372 loss: 1.84523947e-06
Iter: 1373 loss: 1.84486703e-06
Iter: 1374 loss: 1.84523753e-06
Iter: 1375 loss: 1.84485975e-06
Iter: 1376 loss: 1.84453506e-06
Iter: 1377 loss: 1.84426085e-06
Iter: 1378 loss: 1.84414193e-06
Iter: 1379 loss: 1.84366695e-06
Iter: 1380 loss: 1.84327655e-06
Iter: 1381 loss: 1.8431474e-06
Iter: 1382 loss: 1.8429597e-06
Iter: 1383 loss: 1.84293413e-06
Iter: 1384 loss: 1.84264081e-06
Iter: 1385 loss: 1.84298688e-06
Iter: 1386 loss: 1.84260307e-06
Iter: 1387 loss: 1.84223904e-06
Iter: 1388 loss: 1.84203691e-06
Iter: 1389 loss: 1.84196278e-06
Iter: 1390 loss: 1.84148621e-06
Iter: 1391 loss: 1.84197211e-06
Iter: 1392 loss: 1.84123701e-06
Iter: 1393 loss: 1.84069108e-06
Iter: 1394 loss: 1.84530063e-06
Iter: 1395 loss: 1.8407618e-06
Iter: 1396 loss: 1.84029318e-06
Iter: 1397 loss: 1.84331361e-06
Iter: 1398 loss: 1.8403216e-06
Iter: 1399 loss: 1.83990255e-06
Iter: 1400 loss: 1.84014846e-06
Iter: 1401 loss: 1.83953159e-06
Iter: 1402 loss: 1.83936061e-06
Iter: 1403 loss: 1.84134683e-06
Iter: 1404 loss: 1.83937425e-06
Iter: 1405 loss: 1.83905252e-06
Iter: 1406 loss: 1.83912846e-06
Iter: 1407 loss: 1.83883617e-06
Iter: 1408 loss: 1.83849215e-06
Iter: 1409 loss: 1.83819031e-06
Iter: 1410 loss: 1.83788882e-06
Iter: 1411 loss: 1.83727798e-06
Iter: 1412 loss: 1.83728582e-06
Iter: 1413 loss: 1.83690611e-06
Iter: 1414 loss: 1.83633915e-06
Iter: 1415 loss: 1.8390142e-06
Iter: 1416 loss: 1.8362648e-06
Iter: 1417 loss: 1.83571092e-06
Iter: 1418 loss: 1.83975635e-06
Iter: 1419 loss: 1.83564669e-06
Iter: 1420 loss: 1.83529357e-06
Iter: 1421 loss: 1.83507427e-06
Iter: 1422 loss: 1.8349233e-06
Iter: 1423 loss: 1.83446184e-06
Iter: 1424 loss: 1.83553584e-06
Iter: 1425 loss: 1.83421957e-06
Iter: 1426 loss: 1.83376574e-06
Iter: 1427 loss: 1.83474435e-06
Iter: 1428 loss: 1.83360305e-06
Iter: 1429 loss: 1.83309328e-06
Iter: 1430 loss: 1.83957025e-06
Iter: 1431 loss: 1.83324687e-06
Iter: 1432 loss: 1.8327803e-06
Iter: 1433 loss: 1.83518978e-06
Iter: 1434 loss: 1.83270231e-06
Iter: 1435 loss: 1.83255884e-06
Iter: 1436 loss: 1.83220163e-06
Iter: 1437 loss: 1.83213365e-06
Iter: 1438 loss: 1.83170312e-06
Iter: 1439 loss: 1.83536554e-06
Iter: 1440 loss: 1.83173813e-06
Iter: 1441 loss: 1.83153861e-06
Iter: 1442 loss: 1.83152906e-06
Iter: 1443 loss: 1.83125178e-06
Iter: 1444 loss: 1.83086831e-06
Iter: 1445 loss: 1.83090128e-06
Iter: 1446 loss: 1.83064481e-06
Iter: 1447 loss: 1.83030943e-06
Iter: 1448 loss: 1.83034683e-06
Iter: 1449 loss: 1.82989641e-06
Iter: 1450 loss: 1.82972667e-06
Iter: 1451 loss: 1.82964777e-06
Iter: 1452 loss: 1.82945837e-06
Iter: 1453 loss: 1.8296098e-06
Iter: 1454 loss: 1.82934753e-06
Iter: 1455 loss: 1.82902113e-06
Iter: 1456 loss: 1.8291114e-06
Iter: 1457 loss: 1.82888095e-06
Iter: 1458 loss: 1.82840859e-06
Iter: 1459 loss: 1.82831911e-06
Iter: 1460 loss: 1.82809799e-06
Iter: 1461 loss: 1.82782367e-06
Iter: 1462 loss: 1.82779877e-06
Iter: 1463 loss: 1.8274867e-06
Iter: 1464 loss: 1.8287019e-06
Iter: 1465 loss: 1.82748067e-06
Iter: 1466 loss: 1.82727717e-06
Iter: 1467 loss: 1.82703559e-06
Iter: 1468 loss: 1.82700455e-06
Iter: 1469 loss: 1.8267516e-06
Iter: 1470 loss: 1.82672215e-06
Iter: 1471 loss: 1.82648455e-06
Iter: 1472 loss: 1.82605334e-06
Iter: 1473 loss: 1.82609642e-06
Iter: 1474 loss: 1.82574388e-06
Iter: 1475 loss: 1.82778138e-06
Iter: 1476 loss: 1.82567669e-06
Iter: 1477 loss: 1.82538622e-06
Iter: 1478 loss: 1.82493432e-06
Iter: 1479 loss: 1.82504516e-06
Iter: 1480 loss: 1.82445615e-06
Iter: 1481 loss: 1.82663712e-06
Iter: 1482 loss: 1.82422241e-06
Iter: 1483 loss: 1.82383565e-06
Iter: 1484 loss: 1.82386304e-06
Iter: 1485 loss: 1.82360031e-06
Iter: 1486 loss: 1.8231475e-06
Iter: 1487 loss: 1.8311564e-06
Iter: 1488 loss: 1.82303313e-06
Iter: 1489 loss: 1.82260976e-06
Iter: 1490 loss: 1.82730037e-06
Iter: 1491 loss: 1.82253598e-06
Iter: 1492 loss: 1.82221925e-06
Iter: 1493 loss: 1.822135e-06
Iter: 1494 loss: 1.82198835e-06
Iter: 1495 loss: 1.82199494e-06
Iter: 1496 loss: 1.82176143e-06
Iter: 1497 loss: 1.8215685e-06
Iter: 1498 loss: 1.82150256e-06
Iter: 1499 loss: 1.82147187e-06
Iter: 1500 loss: 1.82109261e-06
Iter: 1501 loss: 1.82177018e-06
Iter: 1502 loss: 1.82103645e-06
Iter: 1503 loss: 1.82077383e-06
Iter: 1504 loss: 1.82259714e-06
Iter: 1505 loss: 1.82071949e-06
Iter: 1506 loss: 1.82045858e-06
Iter: 1507 loss: 1.82000167e-06
Iter: 1508 loss: 1.82753934e-06
Iter: 1509 loss: 1.81999724e-06
Iter: 1510 loss: 1.81951066e-06
Iter: 1511 loss: 1.8238436e-06
Iter: 1512 loss: 1.81943801e-06
Iter: 1513 loss: 1.81918563e-06
Iter: 1514 loss: 1.81876158e-06
Iter: 1515 loss: 1.8187161e-06
Iter: 1516 loss: 1.81827522e-06
Iter: 1517 loss: 1.81957842e-06
Iter: 1518 loss: 1.81811095e-06
Iter: 1519 loss: 1.81801852e-06
Iter: 1520 loss: 1.81792893e-06
Iter: 1521 loss: 1.81785219e-06
Iter: 1522 loss: 1.81721464e-06
Iter: 1523 loss: 1.81664268e-06
Iter: 1524 loss: 1.81632504e-06
Iter: 1525 loss: 1.81569305e-06
Iter: 1526 loss: 1.81568544e-06
Iter: 1527 loss: 1.81546102e-06
Iter: 1528 loss: 1.81543328e-06
Iter: 1529 loss: 1.81501764e-06
Iter: 1530 loss: 1.81627695e-06
Iter: 1531 loss: 1.81499695e-06
Iter: 1532 loss: 1.81484324e-06
Iter: 1533 loss: 1.81477253e-06
Iter: 1534 loss: 1.81457722e-06
Iter: 1535 loss: 1.81421103e-06
Iter: 1536 loss: 1.81704445e-06
Iter: 1537 loss: 1.81430664e-06
Iter: 1538 loss: 1.81408313e-06
Iter: 1539 loss: 1.81366522e-06
Iter: 1540 loss: 1.81368557e-06
Iter: 1541 loss: 1.81320479e-06
Iter: 1542 loss: 1.81554969e-06
Iter: 1543 loss: 1.8131251e-06
Iter: 1544 loss: 1.81275414e-06
Iter: 1545 loss: 1.81226164e-06
Iter: 1546 loss: 1.81219207e-06
Iter: 1547 loss: 1.81157429e-06
Iter: 1548 loss: 1.81800192e-06
Iter: 1549 loss: 1.81151552e-06
Iter: 1550 loss: 1.81116866e-06
Iter: 1551 loss: 1.81095891e-06
Iter: 1552 loss: 1.81063638e-06
Iter: 1553 loss: 1.81040582e-06
Iter: 1554 loss: 1.8104688e-06
Iter: 1555 loss: 1.81009e-06
Iter: 1556 loss: 1.80969721e-06
Iter: 1557 loss: 1.80958477e-06
Iter: 1558 loss: 1.80937946e-06
Iter: 1559 loss: 1.81087069e-06
Iter: 1560 loss: 1.80932784e-06
Iter: 1561 loss: 1.80921961e-06
Iter: 1562 loss: 1.80885627e-06
Iter: 1563 loss: 1.8123975e-06
Iter: 1564 loss: 1.80886025e-06
Iter: 1565 loss: 1.8083781e-06
Iter: 1566 loss: 1.80854431e-06
Iter: 1567 loss: 1.80799611e-06
Iter: 1568 loss: 1.80823679e-06
Iter: 1569 loss: 1.80766926e-06
Iter: 1570 loss: 1.80756615e-06
Iter: 1571 loss: 1.80756945e-06
Iter: 1572 loss: 1.80734469e-06
Iter: 1573 loss: 1.80719348e-06
Iter: 1574 loss: 1.80726215e-06
Iter: 1575 loss: 1.80702818e-06
Iter: 1576 loss: 1.80678808e-06
Iter: 1577 loss: 1.80619031e-06
Iter: 1578 loss: 1.81266864e-06
Iter: 1579 loss: 1.80613984e-06
Iter: 1580 loss: 1.80570669e-06
Iter: 1581 loss: 1.80566235e-06
Iter: 1582 loss: 1.80523341e-06
Iter: 1583 loss: 1.80859161e-06
Iter: 1584 loss: 1.80532481e-06
Iter: 1585 loss: 1.80486222e-06
Iter: 1586 loss: 1.80425809e-06
Iter: 1587 loss: 1.81909684e-06
Iter: 1588 loss: 1.80422717e-06
Iter: 1589 loss: 1.80392419e-06
Iter: 1590 loss: 1.80391112e-06
Iter: 1591 loss: 1.80375105e-06
Iter: 1592 loss: 1.80543395e-06
Iter: 1593 loss: 1.80361735e-06
Iter: 1594 loss: 1.80344239e-06
Iter: 1595 loss: 1.8035123e-06
Iter: 1596 loss: 1.80321945e-06
Iter: 1597 loss: 1.80305733e-06
Iter: 1598 loss: 1.80307882e-06
Iter: 1599 loss: 1.80285724e-06
Iter: 1600 loss: 1.80259235e-06
Iter: 1601 loss: 1.80232951e-06
Iter: 1602 loss: 1.80232018e-06
Iter: 1603 loss: 1.80225345e-06
Iter: 1604 loss: 1.80203938e-06
Iter: 1605 loss: 1.80181542e-06
Iter: 1606 loss: 1.80132724e-06
Iter: 1607 loss: 1.80337565e-06
Iter: 1608 loss: 1.80100892e-06
Iter: 1609 loss: 1.8004115e-06
Iter: 1610 loss: 1.80657912e-06
Iter: 1611 loss: 1.80039706e-06
Iter: 1612 loss: 1.79997664e-06
Iter: 1613 loss: 1.79928065e-06
Iter: 1614 loss: 1.79928611e-06
Iter: 1615 loss: 1.7987893e-06
Iter: 1616 loss: 1.79876542e-06
Iter: 1617 loss: 1.79837934e-06
Iter: 1618 loss: 1.79834456e-06
Iter: 1619 loss: 1.79811411e-06
Iter: 1620 loss: 1.79770223e-06
Iter: 1621 loss: 1.80269217e-06
Iter: 1622 loss: 1.79770836e-06
Iter: 1623 loss: 1.79749554e-06
Iter: 1624 loss: 1.79734616e-06
Iter: 1625 loss: 1.79717767e-06
Iter: 1626 loss: 1.80006e-06
Iter: 1627 loss: 1.79717813e-06
Iter: 1628 loss: 1.79712902e-06
Iter: 1629 loss: 1.79683639e-06
Iter: 1630 loss: 1.79960966e-06
Iter: 1631 loss: 1.79671486e-06
Iter: 1632 loss: 1.79620929e-06
Iter: 1633 loss: 1.79722724e-06
Iter: 1634 loss: 1.79607218e-06
Iter: 1635 loss: 1.79569463e-06
Iter: 1636 loss: 1.79822428e-06
Iter: 1637 loss: 1.79567382e-06
Iter: 1638 loss: 1.79512449e-06
Iter: 1639 loss: 1.79659901e-06
Iter: 1640 loss: 1.79504491e-06
Iter: 1641 loss: 1.79470032e-06
Iter: 1642 loss: 1.79383449e-06
Iter: 1643 loss: 1.79968822e-06
Iter: 1644 loss: 1.79364565e-06
Iter: 1645 loss: 1.79285576e-06
Iter: 1646 loss: 1.7928661e-06
Iter: 1647 loss: 1.79231915e-06
Iter: 1648 loss: 1.79200833e-06
Iter: 1649 loss: 1.79172707e-06
Iter: 1650 loss: 1.79116728e-06
Iter: 1651 loss: 1.79594747e-06
Iter: 1652 loss: 1.79104381e-06
Iter: 1653 loss: 1.79056235e-06
Iter: 1654 loss: 1.79047595e-06
Iter: 1655 loss: 1.79030621e-06
Iter: 1656 loss: 1.78969435e-06
Iter: 1657 loss: 1.7914208e-06
Iter: 1658 loss: 1.78963739e-06
Iter: 1659 loss: 1.78913592e-06
Iter: 1660 loss: 1.79044105e-06
Iter: 1661 loss: 1.78910477e-06
Iter: 1662 loss: 1.78873006e-06
Iter: 1663 loss: 1.78975449e-06
Iter: 1664 loss: 1.7885061e-06
Iter: 1665 loss: 1.78816663e-06
Iter: 1666 loss: 1.78795449e-06
Iter: 1667 loss: 1.78782443e-06
Iter: 1668 loss: 1.78725418e-06
Iter: 1669 loss: 1.78838059e-06
Iter: 1670 loss: 1.78709843e-06
Iter: 1671 loss: 1.78640221e-06
Iter: 1672 loss: 1.78557525e-06
Iter: 1673 loss: 1.78548589e-06
Iter: 1674 loss: 1.7874338e-06
Iter: 1675 loss: 1.78524374e-06
Iter: 1676 loss: 1.78511914e-06
Iter: 1677 loss: 1.78477046e-06
Iter: 1678 loss: 1.78466121e-06
Iter: 1679 loss: 1.78388837e-06
Iter: 1680 loss: 1.7885643e-06
Iter: 1681 loss: 1.7837649e-06
Iter: 1682 loss: 1.78350012e-06
Iter: 1683 loss: 1.78343987e-06
Iter: 1684 loss: 1.78301809e-06
Iter: 1685 loss: 1.78364189e-06
Iter: 1686 loss: 1.78295136e-06
Iter: 1687 loss: 1.78261564e-06
Iter: 1688 loss: 1.78226924e-06
Iter: 1689 loss: 1.78223104e-06
Iter: 1690 loss: 1.78174446e-06
Iter: 1691 loss: 1.78254459e-06
Iter: 1692 loss: 1.78147013e-06
Iter: 1693 loss: 1.78143796e-06
Iter: 1694 loss: 1.7812722e-06
Iter: 1695 loss: 1.78099435e-06
Iter: 1696 loss: 1.78065181e-06
Iter: 1697 loss: 1.78063067e-06
Iter: 1698 loss: 1.78025107e-06
Iter: 1699 loss: 1.78013806e-06
Iter: 1700 loss: 1.77992138e-06
Iter: 1701 loss: 1.77935078e-06
Iter: 1702 loss: 1.77974448e-06
Iter: 1703 loss: 1.77901609e-06
Iter: 1704 loss: 1.7784389e-06
Iter: 1705 loss: 1.78021207e-06
Iter: 1706 loss: 1.77828679e-06
Iter: 1707 loss: 1.77801257e-06
Iter: 1708 loss: 1.78309438e-06
Iter: 1709 loss: 1.77805225e-06
Iter: 1710 loss: 1.77761194e-06
Iter: 1711 loss: 1.7784165e-06
Iter: 1712 loss: 1.7775717e-06
Iter: 1713 loss: 1.77702759e-06
Iter: 1714 loss: 1.77675292e-06
Iter: 1715 loss: 1.77671814e-06
Iter: 1716 loss: 1.7762095e-06
Iter: 1717 loss: 1.77541392e-06
Iter: 1718 loss: 1.77539641e-06
Iter: 1719 loss: 1.77615425e-06
Iter: 1720 loss: 1.77508116e-06
Iter: 1721 loss: 1.77487482e-06
Iter: 1722 loss: 1.77457355e-06
Iter: 1723 loss: 1.77462516e-06
Iter: 1724 loss: 1.77412301e-06
Iter: 1725 loss: 1.77501397e-06
Iter: 1726 loss: 1.77409697e-06
Iter: 1727 loss: 1.77373022e-06
Iter: 1728 loss: 1.77348147e-06
Iter: 1729 loss: 1.77328707e-06
Iter: 1730 loss: 1.77279389e-06
Iter: 1731 loss: 1.77385436e-06
Iter: 1732 loss: 1.77257414e-06
Iter: 1733 loss: 1.77221045e-06
Iter: 1734 loss: 1.77351194e-06
Iter: 1735 loss: 1.77210222e-06
Iter: 1736 loss: 1.7717814e-06
Iter: 1737 loss: 1.7722366e-06
Iter: 1738 loss: 1.77158142e-06
Iter: 1739 loss: 1.77119534e-06
Iter: 1740 loss: 1.77160439e-06
Iter: 1741 loss: 1.77100446e-06
Iter: 1742 loss: 1.77067739e-06
Iter: 1743 loss: 1.77036907e-06
Iter: 1744 loss: 1.77021047e-06
Iter: 1745 loss: 1.76964295e-06
Iter: 1746 loss: 1.7693385e-06
Iter: 1747 loss: 1.76905837e-06
Iter: 1748 loss: 1.76855804e-06
Iter: 1749 loss: 1.76852518e-06
Iter: 1750 loss: 1.76834715e-06
Iter: 1751 loss: 1.76846254e-06
Iter: 1752 loss: 1.76823062e-06
Iter: 1753 loss: 1.76779668e-06
Iter: 1754 loss: 1.76834669e-06
Iter: 1755 loss: 1.76764956e-06
Iter: 1756 loss: 1.76724586e-06
Iter: 1757 loss: 1.76895014e-06
Iter: 1758 loss: 1.76723393e-06
Iter: 1759 loss: 1.76685148e-06
Iter: 1760 loss: 1.76711637e-06
Iter: 1761 loss: 1.76665458e-06
Iter: 1762 loss: 1.76611081e-06
Iter: 1763 loss: 1.76613457e-06
Iter: 1764 loss: 1.76565618e-06
Iter: 1765 loss: 1.76516642e-06
Iter: 1766 loss: 1.76784522e-06
Iter: 1767 loss: 1.76504727e-06
Iter: 1768 loss: 1.76441563e-06
Iter: 1769 loss: 1.76413778e-06
Iter: 1770 loss: 1.76388767e-06
Iter: 1771 loss: 1.76319304e-06
Iter: 1772 loss: 1.76348124e-06
Iter: 1773 loss: 1.76273807e-06
Iter: 1774 loss: 1.76231492e-06
Iter: 1775 loss: 1.76221272e-06
Iter: 1776 loss: 1.7618155e-06
Iter: 1777 loss: 1.7611485e-06
Iter: 1778 loss: 1.76112144e-06
Iter: 1779 loss: 1.76053732e-06
Iter: 1780 loss: 1.76321964e-06
Iter: 1781 loss: 1.76036724e-06
Iter: 1782 loss: 1.76017147e-06
Iter: 1783 loss: 1.76008211e-06
Iter: 1784 loss: 1.75988498e-06
Iter: 1785 loss: 1.75967284e-06
Iter: 1786 loss: 1.76777735e-06
Iter: 1787 loss: 1.7596202e-06
Iter: 1788 loss: 1.75942796e-06
Iter: 1789 loss: 1.75941148e-06
Iter: 1790 loss: 1.75927516e-06
Iter: 1791 loss: 1.75886407e-06
Iter: 1792 loss: 1.76142407e-06
Iter: 1793 loss: 1.7587322e-06
Iter: 1794 loss: 1.7580951e-06
Iter: 1795 loss: 1.76577328e-06
Iter: 1796 loss: 1.75810317e-06
Iter: 1797 loss: 1.75790342e-06
Iter: 1798 loss: 1.75965647e-06
Iter: 1799 loss: 1.75774949e-06
Iter: 1800 loss: 1.75751029e-06
Iter: 1801 loss: 1.75777791e-06
Iter: 1802 loss: 1.75731407e-06
Iter: 1803 loss: 1.75673313e-06
Iter: 1804 loss: 1.75734021e-06
Iter: 1805 loss: 1.75646619e-06
Iter: 1806 loss: 1.75610444e-06
Iter: 1807 loss: 1.76084598e-06
Iter: 1808 loss: 1.75609216e-06
Iter: 1809 loss: 1.75589776e-06
Iter: 1810 loss: 1.75584944e-06
Iter: 1811 loss: 1.75558262e-06
Iter: 1812 loss: 1.75512776e-06
Iter: 1813 loss: 1.75542641e-06
Iter: 1814 loss: 1.75474383e-06
Iter: 1815 loss: 1.75429113e-06
Iter: 1816 loss: 1.75646198e-06
Iter: 1817 loss: 1.75427488e-06
Iter: 1818 loss: 1.75377318e-06
Iter: 1819 loss: 1.75721834e-06
Iter: 1820 loss: 1.75377522e-06
Iter: 1821 loss: 1.75350101e-06
Iter: 1822 loss: 1.75420121e-06
Iter: 1823 loss: 1.75344394e-06
Iter: 1824 loss: 1.75307309e-06
Iter: 1825 loss: 1.75253263e-06
Iter: 1826 loss: 1.75254604e-06
Iter: 1827 loss: 1.75221453e-06
Iter: 1828 loss: 1.75408661e-06
Iter: 1829 loss: 1.75214007e-06
Iter: 1830 loss: 1.7518264e-06
Iter: 1831 loss: 1.75317689e-06
Iter: 1832 loss: 1.75176149e-06
Iter: 1833 loss: 1.75159926e-06
Iter: 1834 loss: 1.75139644e-06
Iter: 1835 loss: 1.75124228e-06
Iter: 1836 loss: 1.7508537e-06
Iter: 1837 loss: 1.75199216e-06
Iter: 1838 loss: 1.75071125e-06
Iter: 1839 loss: 1.75035325e-06
Iter: 1840 loss: 1.75060018e-06
Iter: 1841 loss: 1.75005857e-06
Iter: 1842 loss: 1.74964816e-06
Iter: 1843 loss: 1.75258606e-06
Iter: 1844 loss: 1.74953198e-06
Iter: 1845 loss: 1.74920899e-06
Iter: 1846 loss: 1.75137211e-06
Iter: 1847 loss: 1.74915499e-06
Iter: 1848 loss: 1.74863203e-06
Iter: 1849 loss: 1.74882734e-06
Iter: 1850 loss: 1.74843785e-06
Iter: 1851 loss: 1.74806632e-06
Iter: 1852 loss: 1.74874651e-06
Iter: 1853 loss: 1.74790284e-06
Iter: 1854 loss: 1.74761226e-06
Iter: 1855 loss: 1.75315813e-06
Iter: 1856 loss: 1.74752768e-06
Iter: 1857 loss: 1.74728768e-06
Iter: 1858 loss: 1.74837203e-06
Iter: 1859 loss: 1.74722481e-06
Iter: 1860 loss: 1.74706224e-06
Iter: 1861 loss: 1.74672698e-06
Iter: 1862 loss: 1.75173022e-06
Iter: 1863 loss: 1.74668594e-06
Iter: 1864 loss: 1.74631612e-06
Iter: 1865 loss: 1.7463276e-06
Iter: 1866 loss: 1.74603679e-06
Iter: 1867 loss: 1.74575302e-06
Iter: 1868 loss: 1.74564934e-06
Iter: 1869 loss: 1.74520653e-06
Iter: 1870 loss: 1.74752677e-06
Iter: 1871 loss: 1.74516356e-06
Iter: 1872 loss: 1.74483876e-06
Iter: 1873 loss: 1.74571221e-06
Iter: 1874 loss: 1.74470563e-06
Iter: 1875 loss: 1.74416607e-06
Iter: 1876 loss: 1.74469596e-06
Iter: 1877 loss: 1.74410593e-06
Iter: 1878 loss: 1.74368188e-06
Iter: 1879 loss: 1.74825254e-06
Iter: 1880 loss: 1.74367551e-06
Iter: 1881 loss: 1.74339232e-06
Iter: 1882 loss: 1.74376009e-06
Iter: 1883 loss: 1.74331797e-06
Iter: 1884 loss: 1.74301545e-06
Iter: 1885 loss: 1.74267291e-06
Iter: 1886 loss: 1.74269621e-06
Iter: 1887 loss: 1.74247293e-06
Iter: 1888 loss: 1.74237903e-06
Iter: 1889 loss: 1.74242587e-06
Iter: 1890 loss: 1.74226011e-06
Iter: 1891 loss: 1.74221918e-06
Iter: 1892 loss: 1.74208469e-06
Iter: 1893 loss: 1.74293791e-06
Iter: 1894 loss: 1.74207685e-06
Iter: 1895 loss: 1.74163893e-06
Iter: 1896 loss: 1.74152456e-06
Iter: 1897 loss: 1.74135255e-06
Iter: 1898 loss: 1.740892e-06
Iter: 1899 loss: 1.74412946e-06
Iter: 1900 loss: 1.74095544e-06
Iter: 1901 loss: 1.74060403e-06
Iter: 1902 loss: 1.74416914e-06
Iter: 1903 loss: 1.74053275e-06
Iter: 1904 loss: 1.74052593e-06
Iter: 1905 loss: 1.74113211e-06
Iter: 1906 loss: 1.74044408e-06
Iter: 1907 loss: 1.74017066e-06
Iter: 1908 loss: 1.73970511e-06
Iter: 1909 loss: 1.74630713e-06
Iter: 1910 loss: 1.7396751e-06
Iter: 1911 loss: 1.73924127e-06
Iter: 1912 loss: 1.74307365e-06
Iter: 1913 loss: 1.7392282e-06
Iter: 1914 loss: 1.73895569e-06
Iter: 1915 loss: 1.73949354e-06
Iter: 1916 loss: 1.73870944e-06
Iter: 1917 loss: 1.73827573e-06
Iter: 1918 loss: 1.73809576e-06
Iter: 1919 loss: 1.73776073e-06
Iter: 1920 loss: 1.73732928e-06
Iter: 1921 loss: 1.73910507e-06
Iter: 1922 loss: 1.73724732e-06
Iter: 1923 loss: 1.73681713e-06
Iter: 1924 loss: 1.73854642e-06
Iter: 1925 loss: 1.73659339e-06
Iter: 1926 loss: 1.73645037e-06
Iter: 1927 loss: 1.73640819e-06
Iter: 1928 loss: 1.7361466e-06
Iter: 1929 loss: 1.7355369e-06
Iter: 1930 loss: 1.73762248e-06
Iter: 1931 loss: 1.73522835e-06
Iter: 1932 loss: 1.73466958e-06
Iter: 1933 loss: 1.73635954e-06
Iter: 1934 loss: 1.73446438e-06
Iter: 1935 loss: 1.73375327e-06
Iter: 1936 loss: 1.73810918e-06
Iter: 1937 loss: 1.7337436e-06
Iter: 1938 loss: 1.73336866e-06
Iter: 1939 loss: 1.73517515e-06
Iter: 1940 loss: 1.733266e-06
Iter: 1941 loss: 1.73293006e-06
Iter: 1942 loss: 1.73639296e-06
Iter: 1943 loss: 1.73288754e-06
Iter: 1944 loss: 1.73265266e-06
Iter: 1945 loss: 1.73266949e-06
Iter: 1946 loss: 1.73255262e-06
Iter: 1947 loss: 1.73236992e-06
Iter: 1948 loss: 1.732182e-06
Iter: 1949 loss: 1.73204955e-06
Iter: 1950 loss: 1.73149078e-06
Iter: 1951 loss: 1.73498302e-06
Iter: 1952 loss: 1.73151534e-06
Iter: 1953 loss: 1.73120861e-06
Iter: 1954 loss: 1.73141916e-06
Iter: 1955 loss: 1.73101444e-06
Iter: 1956 loss: 1.73064427e-06
Iter: 1957 loss: 1.73471835e-06
Iter: 1958 loss: 1.73063199e-06
Iter: 1959 loss: 1.73060221e-06
Iter: 1960 loss: 1.73048807e-06
Iter: 1961 loss: 1.73038757e-06
Iter: 1962 loss: 1.73001285e-06
Iter: 1963 loss: 1.73144122e-06
Iter: 1964 loss: 1.72984085e-06
Iter: 1965 loss: 1.72942737e-06
Iter: 1966 loss: 1.73168394e-06
Iter: 1967 loss: 1.72939531e-06
Iter: 1968 loss: 1.7291635e-06
Iter: 1969 loss: 1.72867703e-06
Iter: 1970 loss: 1.728705e-06
Iter: 1971 loss: 1.72806153e-06
Iter: 1972 loss: 1.73198669e-06
Iter: 1973 loss: 1.7279242e-06
Iter: 1974 loss: 1.72777618e-06
Iter: 1975 loss: 1.72751777e-06
Iter: 1976 loss: 1.72736293e-06
Iter: 1977 loss: 1.72704904e-06
Iter: 1978 loss: 1.73419733e-06
Iter: 1979 loss: 1.72700106e-06
Iter: 1980 loss: 1.72641671e-06
Iter: 1981 loss: 1.72862701e-06
Iter: 1982 loss: 1.72636646e-06
Iter: 1983 loss: 1.72622345e-06
Iter: 1984 loss: 1.7278669e-06
Iter: 1985 loss: 1.72614978e-06
Iter: 1986 loss: 1.72594571e-06
Iter: 1987 loss: 1.72560215e-06
Iter: 1988 loss: 1.72557043e-06
Iter: 1989 loss: 1.7250984e-06
Iter: 1990 loss: 1.7254672e-06
Iter: 1991 loss: 1.72481555e-06
Iter: 1992 loss: 1.72499665e-06
Iter: 1993 loss: 1.72470368e-06
Iter: 1994 loss: 1.72457089e-06
Iter: 1995 loss: 1.72442196e-06
Iter: 1996 loss: 1.72435716e-06
Iter: 1997 loss: 1.72414877e-06
Iter: 1998 loss: 1.72371381e-06
Iter: 1999 loss: 1.73026251e-06
Iter: 2000 loss: 1.72375769e-06
Iter: 2001 loss: 1.72319028e-06
Iter: 2002 loss: 1.72710634e-06
Iter: 2003 loss: 1.72316868e-06
Iter: 2004 loss: 1.72265982e-06
Iter: 2005 loss: 1.72272917e-06
Iter: 2006 loss: 1.72241016e-06
Iter: 2007 loss: 1.72212049e-06
Iter: 2008 loss: 1.72207695e-06
Iter: 2009 loss: 1.721731e-06
Iter: 2010 loss: 1.72215846e-06
Iter: 2011 loss: 1.72154682e-06
Iter: 2012 loss: 1.72125488e-06
Iter: 2013 loss: 1.72098362e-06
Iter: 2014 loss: 1.72091359e-06
Iter: 2015 loss: 1.72042382e-06
Iter: 2016 loss: 1.71981276e-06
Iter: 2017 loss: 1.7198596e-06
Iter: 2018 loss: 1.71926479e-06
Iter: 2019 loss: 1.71926513e-06
Iter: 2020 loss: 1.71886973e-06
Iter: 2021 loss: 1.72063824e-06
Iter: 2022 loss: 1.71879651e-06
Iter: 2023 loss: 1.71849763e-06
Iter: 2024 loss: 1.7193064e-06
Iter: 2025 loss: 1.71819738e-06
Iter: 2026 loss: 1.71805482e-06
Iter: 2027 loss: 1.71793261e-06
Iter: 2028 loss: 1.71781926e-06
Iter: 2029 loss: 1.71738816e-06
Iter: 2030 loss: 1.71733666e-06
Iter: 2031 loss: 1.71695388e-06
Iter: 2032 loss: 1.71619081e-06
Iter: 2033 loss: 1.72200885e-06
Iter: 2034 loss: 1.71619831e-06
Iter: 2035 loss: 1.71561146e-06
Iter: 2036 loss: 1.72278919e-06
Iter: 2037 loss: 1.71560714e-06
Iter: 2038 loss: 1.71523561e-06
Iter: 2039 loss: 1.71485067e-06
Iter: 2040 loss: 1.71476086e-06
Iter: 2041 loss: 1.71464626e-06
Iter: 2042 loss: 1.71444344e-06
Iter: 2043 loss: 1.71421698e-06
Iter: 2044 loss: 1.71472152e-06
Iter: 2045 loss: 1.71404099e-06
Iter: 2046 loss: 1.71383863e-06
Iter: 2047 loss: 1.71380896e-06
Iter: 2048 loss: 1.71360239e-06
Iter: 2049 loss: 1.71319584e-06
Iter: 2050 loss: 1.7125642e-06
Iter: 2051 loss: 1.7125094e-06
Iter: 2052 loss: 1.7120052e-06
Iter: 2053 loss: 1.71561237e-06
Iter: 2054 loss: 1.71182114e-06
Iter: 2055 loss: 1.71142494e-06
Iter: 2056 loss: 1.71136014e-06
Iter: 2057 loss: 1.71115482e-06
Iter: 2058 loss: 1.71116653e-06
Iter: 2059 loss: 1.7109943e-06
Iter: 2060 loss: 1.71050817e-06
Iter: 2061 loss: 1.71460715e-06
Iter: 2062 loss: 1.71053489e-06
Iter: 2063 loss: 1.71006195e-06
Iter: 2064 loss: 1.70893952e-06
Iter: 2065 loss: 1.72071964e-06
Iter: 2066 loss: 1.70886074e-06
Iter: 2067 loss: 1.70807357e-06
Iter: 2068 loss: 1.7186195e-06
Iter: 2069 loss: 1.70808198e-06
Iter: 2070 loss: 1.70764338e-06
Iter: 2071 loss: 1.70991507e-06
Iter: 2072 loss: 1.70762974e-06
Iter: 2073 loss: 1.70728993e-06
Iter: 2074 loss: 1.70753538e-06
Iter: 2075 loss: 1.70713906e-06
Iter: 2076 loss: 1.70683279e-06
Iter: 2077 loss: 1.70683143e-06
Iter: 2078 loss: 1.70659223e-06
Iter: 2079 loss: 1.70656904e-06
Iter: 2080 loss: 1.7064001e-06
Iter: 2081 loss: 1.7061077e-06
Iter: 2082 loss: 1.70586645e-06
Iter: 2083 loss: 1.70568569e-06
Iter: 2084 loss: 1.70528699e-06
Iter: 2085 loss: 1.7053776e-06
Iter: 2086 loss: 1.70502494e-06
Iter: 2087 loss: 1.70438295e-06
Iter: 2088 loss: 1.70950261e-06
Iter: 2089 loss: 1.70444969e-06
Iter: 2090 loss: 1.70408271e-06
Iter: 2091 loss: 1.70410681e-06
Iter: 2092 loss: 1.70381827e-06
Iter: 2093 loss: 1.70380758e-06
Iter: 2094 loss: 1.7035743e-06
Iter: 2095 loss: 1.70345675e-06
Iter: 2096 loss: 1.70312535e-06
Iter: 2097 loss: 1.70310818e-06
Iter: 2098 loss: 1.7026498e-06
Iter: 2099 loss: 1.70236297e-06
Iter: 2100 loss: 1.70220096e-06
Iter: 2101 loss: 1.70174496e-06
Iter: 2102 loss: 1.70811131e-06
Iter: 2103 loss: 1.70175269e-06
Iter: 2104 loss: 1.7014022e-06
Iter: 2105 loss: 1.70216379e-06
Iter: 2106 loss: 1.70125804e-06
Iter: 2107 loss: 1.70086992e-06
Iter: 2108 loss: 1.70175542e-06
Iter: 2109 loss: 1.70071507e-06
Iter: 2110 loss: 1.70032956e-06
Iter: 2111 loss: 1.70443593e-06
Iter: 2112 loss: 1.70028829e-06
Iter: 2113 loss: 1.70007797e-06
Iter: 2114 loss: 1.70269743e-06
Iter: 2115 loss: 1.70009559e-06
Iter: 2116 loss: 1.69997429e-06
Iter: 2117 loss: 1.69999612e-06
Iter: 2118 loss: 1.69977841e-06
Iter: 2119 loss: 1.69957093e-06
Iter: 2120 loss: 1.69926579e-06
Iter: 2121 loss: 1.70778139e-06
Iter: 2122 loss: 1.69926409e-06
Iter: 2123 loss: 1.69895452e-06
Iter: 2124 loss: 1.70313456e-06
Iter: 2125 loss: 1.69890927e-06
Iter: 2126 loss: 1.69878911e-06
Iter: 2127 loss: 1.69873942e-06
Iter: 2128 loss: 1.69859641e-06
Iter: 2129 loss: 1.69837131e-06
Iter: 2130 loss: 1.6983588e-06
Iter: 2131 loss: 1.69819623e-06
Iter: 2132 loss: 1.69762416e-06
Iter: 2133 loss: 1.7037205e-06
Iter: 2134 loss: 1.69768612e-06
Iter: 2135 loss: 1.69719453e-06
Iter: 2136 loss: 1.69927841e-06
Iter: 2137 loss: 1.69710881e-06
Iter: 2138 loss: 1.69667373e-06
Iter: 2139 loss: 1.69900784e-06
Iter: 2140 loss: 1.69655561e-06
Iter: 2141 loss: 1.6962781e-06
Iter: 2142 loss: 1.6958968e-06
Iter: 2143 loss: 1.69595683e-06
Iter: 2144 loss: 1.69546024e-06
Iter: 2145 loss: 1.69542773e-06
Iter: 2146 loss: 1.69519365e-06
Iter: 2147 loss: 1.69517182e-06
Iter: 2148 loss: 1.69496082e-06
Iter: 2149 loss: 1.69520411e-06
Iter: 2150 loss: 1.69493819e-06
Iter: 2151 loss: 1.69461953e-06
Iter: 2152 loss: 1.69424175e-06
Iter: 2153 loss: 1.70291969e-06
Iter: 2154 loss: 1.69424527e-06
Iter: 2155 loss: 1.69392501e-06
Iter: 2156 loss: 1.69537009e-06
Iter: 2157 loss: 1.69381315e-06
Iter: 2158 loss: 1.69360533e-06
Iter: 2159 loss: 1.69472401e-06
Iter: 2160 loss: 1.69347447e-06
Iter: 2161 loss: 1.69324596e-06
Iter: 2162 loss: 1.69329428e-06
Iter: 2163 loss: 1.69312966e-06
Iter: 2164 loss: 1.69279281e-06
Iter: 2165 loss: 1.69460657e-06
Iter: 2166 loss: 1.69256339e-06
Iter: 2167 loss: 1.69209102e-06
Iter: 2168 loss: 1.69599195e-06
Iter: 2169 loss: 1.69209954e-06
Iter: 2170 loss: 1.69182e-06
Iter: 2171 loss: 1.69226337e-06
Iter: 2172 loss: 1.69156419e-06
Iter: 2173 loss: 1.69108216e-06
Iter: 2174 loss: 1.69063344e-06
Iter: 2175 loss: 1.69054886e-06
Iter: 2176 loss: 1.69001157e-06
Iter: 2177 loss: 1.69198961e-06
Iter: 2178 loss: 1.68986298e-06
Iter: 2179 loss: 1.68941051e-06
Iter: 2180 loss: 1.68987981e-06
Iter: 2181 loss: 1.68925885e-06
Iter: 2182 loss: 1.68906024e-06
Iter: 2183 loss: 1.68902636e-06
Iter: 2184 loss: 1.68881866e-06
Iter: 2185 loss: 1.68899214e-06
Iter: 2186 loss: 1.68863278e-06
Iter: 2187 loss: 1.68827103e-06
Iter: 2188 loss: 1.68927386e-06
Iter: 2189 loss: 1.68823385e-06
Iter: 2190 loss: 1.68805661e-06
Iter: 2191 loss: 1.68902443e-06
Iter: 2192 loss: 1.68796305e-06
Iter: 2193 loss: 1.68769429e-06
Iter: 2194 loss: 1.68905842e-06
Iter: 2195 loss: 1.68764973e-06
Iter: 2196 loss: 1.68731231e-06
Iter: 2197 loss: 1.68851489e-06
Iter: 2198 loss: 1.68726569e-06
Iter: 2199 loss: 1.68712154e-06
Iter: 2200 loss: 1.68687518e-06
Iter: 2201 loss: 1.69223347e-06
Iter: 2202 loss: 1.68677491e-06
Iter: 2203 loss: 1.68645124e-06
Iter: 2204 loss: 1.68962947e-06
Iter: 2205 loss: 1.68641941e-06
Iter: 2206 loss: 1.6860738e-06
Iter: 2207 loss: 1.68660802e-06
Iter: 2208 loss: 1.68603492e-06
Iter: 2209 loss: 1.68557563e-06
Iter: 2210 loss: 1.68700819e-06
Iter: 2211 loss: 1.68553925e-06
Iter: 2212 loss: 1.68526026e-06
Iter: 2213 loss: 1.68495239e-06
Iter: 2214 loss: 1.68488498e-06
Iter: 2215 loss: 1.68460974e-06
Iter: 2216 loss: 1.68459133e-06
Iter: 2217 loss: 1.68436293e-06
Iter: 2218 loss: 1.68415625e-06
Iter: 2219 loss: 1.68411e-06
Iter: 2220 loss: 1.68392603e-06
Iter: 2221 loss: 1.68391239e-06
Iter: 2222 loss: 1.68370559e-06
Iter: 2223 loss: 1.6838311e-06
Iter: 2224 loss: 1.68361885e-06
Iter: 2225 loss: 1.68344923e-06
Iter: 2226 loss: 1.68511974e-06
Iter: 2227 loss: 1.68346673e-06
Iter: 2228 loss: 1.68328586e-06
Iter: 2229 loss: 1.68306701e-06
Iter: 2230 loss: 1.68302654e-06
Iter: 2231 loss: 1.68265183e-06
Iter: 2232 loss: 1.68293514e-06
Iter: 2233 loss: 1.68268684e-06
Iter: 2234 loss: 1.68241547e-06
Iter: 2235 loss: 1.68246675e-06
Iter: 2236 loss: 1.68221811e-06
Iter: 2237 loss: 1.68198358e-06
Iter: 2238 loss: 1.68475276e-06
Iter: 2239 loss: 1.68205838e-06
Iter: 2240 loss: 1.68181214e-06
Iter: 2241 loss: 1.68209863e-06
Iter: 2242 loss: 1.68172892e-06
Iter: 2243 loss: 1.68154486e-06
Iter: 2244 loss: 1.68161614e-06
Iter: 2245 loss: 1.68138024e-06
Iter: 2246 loss: 1.68102952e-06
Iter: 2247 loss: 1.68260271e-06
Iter: 2248 loss: 1.6810759e-06
Iter: 2249 loss: 1.68081056e-06
Iter: 2250 loss: 1.6810036e-06
Iter: 2251 loss: 1.68076986e-06
Iter: 2252 loss: 1.68047222e-06
Iter: 2253 loss: 1.68041402e-06
Iter: 2254 loss: 1.68017903e-06
Iter: 2255 loss: 1.67989265e-06
Iter: 2256 loss: 1.67988901e-06
Iter: 2257 loss: 1.67975259e-06
Iter: 2258 loss: 1.67977441e-06
Iter: 2259 loss: 1.67959388e-06
Iter: 2260 loss: 1.6795293e-06
Iter: 2261 loss: 1.67954158e-06
Iter: 2262 loss: 1.67945404e-06
Iter: 2263 loss: 1.67915732e-06
Iter: 2264 loss: 1.68299766e-06
Iter: 2265 loss: 1.67923929e-06
Iter: 2266 loss: 1.67901294e-06
Iter: 2267 loss: 1.67871735e-06
Iter: 2268 loss: 1.67870417e-06
Iter: 2269 loss: 1.67828682e-06
Iter: 2270 loss: 1.68037889e-06
Iter: 2271 loss: 1.67824373e-06
Iter: 2272 loss: 1.67797248e-06
Iter: 2273 loss: 1.67869052e-06
Iter: 2274 loss: 1.6779295e-06
Iter: 2275 loss: 1.67751773e-06
Iter: 2276 loss: 1.67739063e-06
Iter: 2277 loss: 1.67724e-06
Iter: 2278 loss: 1.67684391e-06
Iter: 2279 loss: 1.67964561e-06
Iter: 2280 loss: 1.67688324e-06
Iter: 2281 loss: 1.67657242e-06
Iter: 2282 loss: 1.67723238e-06
Iter: 2283 loss: 1.6764775e-06
Iter: 2284 loss: 1.67620146e-06
Iter: 2285 loss: 1.676902e-06
Iter: 2286 loss: 1.67613553e-06
Iter: 2287 loss: 1.67592043e-06
Iter: 2288 loss: 1.67677138e-06
Iter: 2289 loss: 1.67577559e-06
Iter: 2290 loss: 1.67575286e-06
Iter: 2291 loss: 1.67569669e-06
Iter: 2292 loss: 1.67563348e-06
Iter: 2293 loss: 1.67562416e-06
Iter: 2294 loss: 1.67558198e-06
Iter: 2295 loss: 1.67533892e-06
Iter: 2296 loss: 1.67562939e-06
Iter: 2297 loss: 1.67528538e-06
Iter: 2298 loss: 1.67504504e-06
Iter: 2299 loss: 1.67481107e-06
Iter: 2300 loss: 1.67477856e-06
Iter: 2301 loss: 1.67467601e-06
Iter: 2302 loss: 1.67465737e-06
Iter: 2303 loss: 1.67451299e-06
Iter: 2304 loss: 1.67417852e-06
Iter: 2305 loss: 1.67428118e-06
Iter: 2306 loss: 1.67398809e-06
Iter: 2307 loss: 1.67380676e-06
Iter: 2308 loss: 1.67380028e-06
Iter: 2309 loss: 1.67361407e-06
Iter: 2310 loss: 1.67342478e-06
Iter: 2311 loss: 1.67334269e-06
Iter: 2312 loss: 1.67310282e-06
Iter: 2313 loss: 1.67363669e-06
Iter: 2314 loss: 1.67298663e-06
Iter: 2315 loss: 1.67267467e-06
Iter: 2316 loss: 1.67274925e-06
Iter: 2317 loss: 1.67260237e-06
Iter: 2318 loss: 1.67242501e-06
Iter: 2319 loss: 1.67236078e-06
Iter: 2320 loss: 1.67216626e-06
Iter: 2321 loss: 1.67394467e-06
Iter: 2322 loss: 1.67208441e-06
Iter: 2323 loss: 1.67195503e-06
Iter: 2324 loss: 1.67194059e-06
Iter: 2325 loss: 1.67186136e-06
Iter: 2326 loss: 1.67252313e-06
Iter: 2327 loss: 1.67184066e-06
Iter: 2328 loss: 1.67188841e-06
Iter: 2329 loss: 1.67182839e-06
Iter: 2330 loss: 1.67191592e-06
Iter: 2331 loss: 1.67186431e-06
Iter: 2332 loss: 1.6718252e-06
Iter: 2333 loss: 1.67182293e-06
Iter: 2334 loss: 1.67186022e-06
Iter: 2335 loss: 1.67188966e-06
Iter: 2336 loss: 1.67182247e-06
Iter: 2337 loss: 1.67185067e-06
Iter: 2338 loss: 1.67187295e-06
Iter: 2339 loss: 1.67187841e-06
Iter: 2340 loss: 1.67184794e-06
Iter: 2341 loss: 1.67184976e-06
Iter: 2342 loss: 1.67182679e-06
Iter: 2343 loss: 1.67183521e-06
Iter: 2344 loss: 1.67183384e-06
Iter: 2345 loss: 1.67184453e-06
Iter: 2346 loss: 1.67183509e-06
Iter: 2347 loss: 1.67183828e-06
Iter: 2348 loss: 1.6718468e-06
Iter: 2349 loss: 1.67184589e-06
Iter: 2350 loss: 1.67183839e-06
Iter: 2351 loss: 1.67183839e-06
Iter: 2352 loss: 1.67184407e-06
Iter: 2353 loss: 1.67183839e-06
Iter: 2354 loss: 1.67132612e-06
Iter: 2355 loss: 1.67510166e-06
Iter: 2356 loss: 1.67134021e-06
Iter: 2357 loss: 1.67117287e-06
Iter: 2358 loss: 1.67143264e-06
Iter: 2359 loss: 1.67105486e-06
Iter: 2360 loss: 1.6708907e-06
Iter: 2361 loss: 1.67115513e-06
Iter: 2362 loss: 1.67086296e-06
Iter: 2363 loss: 1.67066764e-06
Iter: 2364 loss: 1.67071505e-06
Iter: 2365 loss: 1.67053304e-06
Iter: 2366 loss: 1.67034295e-06
Iter: 2367 loss: 1.67134635e-06
Iter: 2368 loss: 1.67035887e-06
Iter: 2369 loss: 1.67021335e-06
Iter: 2370 loss: 1.67012024e-06
Iter: 2371 loss: 1.67000826e-06
Iter: 2372 loss: 1.66974962e-06
Iter: 2373 loss: 1.66969994e-06
Iter: 2374 loss: 1.66945642e-06
Iter: 2375 loss: 1.6693059e-06
Iter: 2376 loss: 1.67075132e-06
Iter: 2377 loss: 1.6692552e-06
Iter: 2378 loss: 1.66906921e-06
Iter: 2379 loss: 1.66977452e-06
Iter: 2380 loss: 1.66901873e-06
Iter: 2381 loss: 1.66893096e-06
Iter: 2382 loss: 1.66930363e-06
Iter: 2383 loss: 1.66882569e-06
Iter: 2384 loss: 1.66869836e-06
Iter: 2385 loss: 1.66875918e-06
Iter: 2386 loss: 1.66853852e-06
Iter: 2387 loss: 1.66837435e-06
Iter: 2388 loss: 1.66816108e-06
Iter: 2389 loss: 1.66812424e-06
Iter: 2390 loss: 1.66790801e-06
Iter: 2391 loss: 1.66868131e-06
Iter: 2392 loss: 1.66777704e-06
Iter: 2393 loss: 1.66756558e-06
Iter: 2394 loss: 1.66736186e-06
Iter: 2395 loss: 1.66727455e-06
Iter: 2396 loss: 1.6667866e-06
Iter: 2397 loss: 1.67056817e-06
Iter: 2398 loss: 1.66683515e-06
Iter: 2399 loss: 1.66656616e-06
Iter: 2400 loss: 1.66816562e-06
Iter: 2401 loss: 1.66662653e-06
Iter: 2402 loss: 1.66642451e-06
Iter: 2403 loss: 1.66646976e-06
Iter: 2404 loss: 1.66628081e-06
Iter: 2405 loss: 1.66602877e-06
Iter: 2406 loss: 1.66664267e-06
Iter: 2407 loss: 1.66591326e-06
Iter: 2408 loss: 1.66577183e-06
Iter: 2409 loss: 1.6682767e-06
Iter: 2410 loss: 1.66571704e-06
Iter: 2411 loss: 1.66561233e-06
Iter: 2412 loss: 1.66647385e-06
Iter: 2413 loss: 1.66561335e-06
Iter: 2414 loss: 1.66553752e-06
Iter: 2415 loss: 1.66532254e-06
Iter: 2416 loss: 1.66958739e-06
Iter: 2417 loss: 1.66535392e-06
Iter: 2418 loss: 1.66506015e-06
Iter: 2419 loss: 1.66548443e-06
Iter: 2420 loss: 1.66505356e-06
Iter: 2421 loss: 1.66495124e-06
Iter: 2422 loss: 1.66484529e-06
Iter: 2423 loss: 1.66483062e-06
Iter: 2424 loss: 1.66465418e-06
Iter: 2425 loss: 1.66465486e-06
Iter: 2426 loss: 1.66453879e-06
Iter: 2427 loss: 1.66441077e-06
Iter: 2428 loss: 1.66432085e-06
Iter: 2429 loss: 1.66411712e-06
Iter: 2430 loss: 1.66518407e-06
Iter: 2431 loss: 1.66411382e-06
Iter: 2432 loss: 1.66400446e-06
Iter: 2433 loss: 1.66428583e-06
Iter: 2434 loss: 1.66396944e-06
Iter: 2435 loss: 1.66377436e-06
Iter: 2436 loss: 1.66402856e-06
Iter: 2437 loss: 1.66372e-06
Iter: 2438 loss: 1.66353607e-06
Iter: 2439 loss: 1.66481141e-06
Iter: 2440 loss: 1.66347479e-06
Iter: 2441 loss: 1.66339805e-06
Iter: 2442 loss: 1.66397149e-06
Iter: 2443 loss: 1.66336122e-06
Iter: 2444 loss: 1.66325299e-06
Iter: 2445 loss: 1.66324139e-06
Iter: 2446 loss: 1.66320501e-06
Iter: 2447 loss: 1.66305199e-06
Iter: 2448 loss: 1.66610243e-06
Iter: 2449 loss: 1.66300515e-06
Iter: 2450 loss: 1.66295922e-06
Iter: 2451 loss: 1.66343295e-06
Iter: 2452 loss: 1.6628826e-06
Iter: 2453 loss: 1.66274958e-06
Iter: 2454 loss: 1.66381233e-06
Iter: 2455 loss: 1.6627514e-06
Iter: 2456 loss: 1.66271684e-06
Iter: 2457 loss: 1.66354698e-06
Iter: 2458 loss: 1.66268285e-06
Iter: 2459 loss: 1.66264022e-06
Iter: 2460 loss: 1.66247059e-06
Iter: 2461 loss: 1.66469499e-06
Iter: 2462 loss: 1.66249583e-06
Iter: 2463 loss: 1.66231257e-06
Iter: 2464 loss: 1.66293717e-06
Iter: 2465 loss: 1.66232326e-06
Iter: 2466 loss: 1.66221173e-06
Iter: 2467 loss: 1.6623377e-06
Iter: 2468 loss: 1.66215875e-06
Iter: 2469 loss: 1.66201949e-06
Iter: 2470 loss: 1.66231052e-06
Iter: 2471 loss: 1.66190694e-06
Iter: 2472 loss: 1.66179962e-06
Iter: 2473 loss: 1.66262464e-06
Iter: 2474 loss: 1.66177665e-06
Iter: 2475 loss: 1.66169116e-06
Iter: 2476 loss: 1.66145719e-06
Iter: 2477 loss: 1.66147561e-06
Iter: 2478 loss: 1.66155314e-06
Iter: 2479 loss: 1.66142081e-06
Iter: 2480 loss: 1.66137079e-06
Iter: 2481 loss: 1.66127074e-06
Iter: 2482 loss: 1.66128189e-06
Iter: 2483 loss: 1.66118502e-06
Iter: 2484 loss: 1.66101177e-06
Iter: 2485 loss: 1.66377799e-06
Iter: 2486 loss: 1.66102359e-06
Iter: 2487 loss: 1.66091331e-06
Iter: 2488 loss: 1.66088535e-06
Iter: 2489 loss: 1.66068116e-06
Iter: 2490 loss: 1.66044174e-06
Iter: 2491 loss: 1.66164739e-06
Iter: 2492 loss: 1.66047471e-06
Iter: 2493 loss: 1.6603318e-06
Iter: 2494 loss: 1.6604173e-06
Iter: 2495 loss: 1.66027496e-06
Iter: 2496 loss: 1.6600784e-06
Iter: 2497 loss: 1.66080531e-06
Iter: 2498 loss: 1.66003474e-06
Iter: 2499 loss: 1.6598915e-06
Iter: 2500 loss: 1.66007e-06
Iter: 2501 loss: 1.65974029e-06
Iter: 2502 loss: 1.65964036e-06
Iter: 2503 loss: 1.65939355e-06
Iter: 2504 loss: 1.65944061e-06
Iter: 2505 loss: 1.659296e-06
Iter: 2506 loss: 1.65916458e-06
Iter: 2507 loss: 1.65905817e-06
Iter: 2508 loss: 1.658884e-06
Iter: 2509 loss: 1.6592503e-06
Iter: 2510 loss: 1.65887764e-06
Iter: 2511 loss: 1.65878248e-06
Iter: 2512 loss: 1.65895722e-06
Iter: 2513 loss: 1.65863082e-06
Iter: 2514 loss: 1.6586431e-06
Iter: 2515 loss: 1.65852623e-06
Iter: 2516 loss: 1.65847496e-06
Iter: 2517 loss: 1.65837923e-06
Iter: 2518 loss: 1.66092104e-06
Iter: 2519 loss: 1.65841152e-06
Iter: 2520 loss: 1.65837616e-06
Iter: 2521 loss: 1.6588898e-06
Iter: 2522 loss: 1.65834092e-06
Iter: 2523 loss: 1.65824667e-06
Iter: 2524 loss: 1.65835206e-06
Iter: 2525 loss: 1.65816914e-06
Iter: 2526 loss: 1.65811934e-06
Iter: 2527 loss: 1.65802976e-06
Iter: 2528 loss: 1.66060499e-06
Iter: 2529 loss: 1.6579894e-06
Iter: 2530 loss: 1.65787844e-06
Iter: 2531 loss: 1.65824099e-06
Iter: 2532 loss: 1.6577801e-06
Iter: 2533 loss: 1.65763765e-06
Iter: 2534 loss: 1.65860138e-06
Iter: 2535 loss: 1.65762754e-06
Iter: 2536 loss: 1.65749543e-06
Iter: 2537 loss: 1.65781228e-06
Iter: 2538 loss: 1.65744927e-06
Iter: 2539 loss: 1.65727181e-06
Iter: 2540 loss: 1.65750828e-06
Iter: 2541 loss: 1.65720462e-06
Iter: 2542 loss: 1.65717506e-06
Iter: 2543 loss: 1.65745496e-06
Iter: 2544 loss: 1.65703057e-06
Iter: 2545 loss: 1.6569461e-06
Iter: 2546 loss: 1.65707229e-06
Iter: 2547 loss: 1.65680785e-06
Iter: 2548 loss: 1.65674601e-06
Iter: 2549 loss: 1.65689016e-06
Iter: 2550 loss: 1.65659651e-06
Iter: 2551 loss: 1.65646816e-06
Iter: 2552 loss: 1.65758479e-06
Iter: 2553 loss: 1.65650351e-06
Iter: 2554 loss: 1.65640517e-06
Iter: 2555 loss: 1.6564145e-06
Iter: 2556 loss: 1.65627932e-06
Iter: 2557 loss: 1.65622373e-06
Iter: 2558 loss: 1.65622657e-06
Iter: 2559 loss: 1.65608549e-06
Iter: 2560 loss: 1.65624556e-06
Iter: 2561 loss: 1.65611868e-06
Iter: 2562 loss: 1.65593156e-06
Iter: 2563 loss: 1.65632014e-06
Iter: 2564 loss: 1.65592371e-06
Iter: 2565 loss: 1.65577899e-06
Iter: 2566 loss: 1.65591518e-06
Iter: 2567 loss: 1.65569281e-06
Iter: 2568 loss: 1.65557981e-06
Iter: 2569 loss: 1.65690449e-06
Iter: 2570 loss: 1.65557458e-06
Iter: 2571 loss: 1.65548624e-06
Iter: 2572 loss: 1.65537813e-06
Iter: 2573 loss: 1.65534152e-06
Iter: 2574 loss: 1.65530287e-06
Iter: 2575 loss: 1.65537813e-06
Iter: 2576 loss: 1.65518952e-06
Iter: 2577 loss: 1.65500614e-06
Iter: 2578 loss: 1.65664665e-06
Iter: 2579 loss: 1.6550232e-06
Iter: 2580 loss: 1.65489882e-06
Iter: 2581 loss: 1.65485903e-06
Iter: 2582 loss: 1.65474694e-06
Iter: 2583 loss: 1.65467395e-06
Iter: 2584 loss: 1.65541132e-06
Iter: 2585 loss: 1.65460756e-06
Iter: 2586 loss: 1.65452809e-06
Iter: 2587 loss: 1.65452298e-06
Iter: 2588 loss: 1.6544775e-06
Iter: 2589 loss: 1.65432e-06
Iter: 2590 loss: 1.65432789e-06
Iter: 2591 loss: 1.65421693e-06
Iter: 2592 loss: 1.65451308e-06
Iter: 2593 loss: 1.65419874e-06
Iter: 2594 loss: 1.6541685e-06
Iter: 2595 loss: 1.65446863e-06
Iter: 2596 loss: 1.65407596e-06
Iter: 2597 loss: 1.65399592e-06
Iter: 2598 loss: 1.65401138e-06
Iter: 2599 loss: 1.65388224e-06
Iter: 2600 loss: 1.65380618e-06
Iter: 2601 loss: 1.65547203e-06
Iter: 2602 loss: 1.65379913e-06
Iter: 2603 loss: 1.65365429e-06
Iter: 2604 loss: 1.65355982e-06
Iter: 2605 loss: 1.65356744e-06
Iter: 2606 loss: 1.65336769e-06
Iter: 2607 loss: 1.65374774e-06
Iter: 2608 loss: 1.6533304e-06
Iter: 2609 loss: 1.65324548e-06
Iter: 2610 loss: 1.65462166e-06
Iter: 2611 loss: 1.65312872e-06
Iter: 2612 loss: 1.65310348e-06
Iter: 2613 loss: 1.65298138e-06
Iter: 2614 loss: 1.65299241e-06
Iter: 2615 loss: 1.65288714e-06
Iter: 2616 loss: 1.65299343e-06
Iter: 2617 loss: 1.65283041e-06
Iter: 2618 loss: 1.65273e-06
Iter: 2619 loss: 1.65415042e-06
Iter: 2620 loss: 1.65276845e-06
Iter: 2621 loss: 1.65262929e-06
Iter: 2622 loss: 1.65264578e-06
Iter: 2623 loss: 1.65257688e-06
Iter: 2624 loss: 1.65240908e-06
Iter: 2625 loss: 1.65295069e-06
Iter: 2626 loss: 1.65242318e-06
Iter: 2627 loss: 1.65233655e-06
Iter: 2628 loss: 1.65250469e-06
Iter: 2629 loss: 1.65222616e-06
Iter: 2630 loss: 1.65223946e-06
Iter: 2631 loss: 1.65219137e-06
Iter: 2632 loss: 1.6521667e-06
Iter: 2633 loss: 1.65225401e-06
Iter: 2634 loss: 1.6521692e-06
Iter: 2635 loss: 1.65213771e-06
Iter: 2636 loss: 1.65217727e-06
Iter: 2637 loss: 1.65223275e-06
Iter: 2638 loss: 1.65223457e-06
Iter: 2639 loss: 1.6522124e-06
Iter: 2640 loss: 1.65224014e-06
Iter: 2641 loss: 1.652214e-06
Iter: 2642 loss: 1.65224094e-06
Iter: 2643 loss: 1.652234e-06
Iter: 2644 loss: 1.65223139e-06
Iter: 2645 loss: 1.65222809e-06
Iter: 2646 loss: 1.65222571e-06
Iter: 2647 loss: 1.65223423e-06
Iter: 2648 loss: 1.65223366e-06
Iter: 2649 loss: 1.65223207e-06
Iter: 2650 loss: 1.65222741e-06
Iter: 2651 loss: 1.65223173e-06
Iter: 2652 loss: 1.65222718e-06
Iter: 2653 loss: 1.65222968e-06
Iter: 2654 loss: 1.65222866e-06
Iter: 2655 loss: 1.65222718e-06
Iter: 2656 loss: 1.65194149e-06
Iter: 2657 loss: 1.65549375e-06
Iter: 2658 loss: 1.65189749e-06
Iter: 2659 loss: 1.65172435e-06
Iter: 2660 loss: 1.65170184e-06
Iter: 2661 loss: 1.65149356e-06
Iter: 2662 loss: 1.65150129e-06
Iter: 2663 loss: 1.65142069e-06
Iter: 2664 loss: 1.65135043e-06
Iter: 2665 loss: 1.65132519e-06
Iter: 2666 loss: 1.6512281e-06
Iter: 2667 loss: 1.65103597e-06
Iter: 2668 loss: 1.65159622e-06
Iter: 2669 loss: 1.65106894e-06
Iter: 2670 loss: 1.65085089e-06
Iter: 2671 loss: 1.65091751e-06
Iter: 2672 loss: 1.65085112e-06
Iter: 2673 loss: 1.6509257e-06
Iter: 2674 loss: 1.65085328e-06
Iter: 2675 loss: 1.65065205e-06
Iter: 2676 loss: 1.65093866e-06
Iter: 2677 loss: 1.65063727e-06
Iter: 2678 loss: 1.65051938e-06
Iter: 2679 loss: 1.65061738e-06
Iter: 2680 loss: 1.65042866e-06
Iter: 2681 loss: 1.65036101e-06
Iter: 2682 loss: 1.65066922e-06
Iter: 2683 loss: 1.65034157e-06
Iter: 2684 loss: 1.65012693e-06
Iter: 2685 loss: 1.64979474e-06
Iter: 2686 loss: 1.651871e-06
Iter: 2687 loss: 1.64967423e-06
Iter: 2688 loss: 1.64918356e-06
Iter: 2689 loss: 1.65312315e-06
Iter: 2690 loss: 1.64917719e-06
Iter: 2691 loss: 1.64882567e-06
Iter: 2692 loss: 1.64967651e-06
Iter: 2693 loss: 1.64879384e-06
Iter: 2694 loss: 1.64867674e-06
Iter: 2695 loss: 1.64873109e-06
Iter: 2696 loss: 1.6485028e-06
Iter: 2697 loss: 1.64838843e-06
Iter: 2698 loss: 1.648374e-06
Iter: 2699 loss: 1.64815106e-06
Iter: 2700 loss: 1.64859762e-06
Iter: 2701 loss: 1.64818493e-06
Iter: 2702 loss: 1.64812718e-06
Iter: 2703 loss: 1.64949392e-06
Iter: 2704 loss: 1.64811195e-06
Iter: 2705 loss: 1.64785843e-06
Iter: 2706 loss: 1.64851622e-06
Iter: 2707 loss: 1.64791402e-06
Iter: 2708 loss: 1.64779988e-06
Iter: 2709 loss: 1.64763401e-06
Iter: 2710 loss: 1.64760036e-06
Iter: 2711 loss: 1.6474512e-06
Iter: 2712 loss: 1.6479853e-06
Iter: 2713 loss: 1.64746621e-06
Iter: 2714 loss: 1.64726464e-06
Iter: 2715 loss: 1.64763969e-06
Iter: 2716 loss: 1.64719677e-06
Iter: 2717 loss: 1.64693824e-06
Iter: 2718 loss: 1.64672019e-06
Iter: 2719 loss: 1.64671394e-06
Iter: 2720 loss: 1.64643711e-06
Iter: 2721 loss: 1.6465043e-06
Iter: 2722 loss: 1.64636378e-06
Iter: 2723 loss: 1.64608787e-06
Iter: 2724 loss: 1.65125721e-06
Iter: 2725 loss: 1.64608741e-06
Iter: 2726 loss: 1.64570724e-06
Iter: 2727 loss: 1.6470342e-06
Iter: 2728 loss: 1.64560151e-06
Iter: 2729 loss: 1.64574817e-06
Iter: 2730 loss: 1.64559049e-06
Iter: 2731 loss: 1.6455183e-06
Iter: 2732 loss: 1.64530877e-06
Iter: 2733 loss: 1.64651624e-06
Iter: 2734 loss: 1.64516018e-06
Iter: 2735 loss: 1.64512426e-06
Iter: 2736 loss: 1.64490905e-06
Iter: 2737 loss: 1.64487619e-06
Iter: 2738 loss: 1.64488597e-06
Iter: 2739 loss: 1.6448007e-06
Iter: 2740 loss: 1.64472533e-06
Iter: 2741 loss: 1.64478831e-06
Iter: 2742 loss: 1.64474523e-06
Iter: 2743 loss: 1.64459675e-06
Iter: 2744 loss: 1.64454423e-06
Iter: 2745 loss: 1.6445033e-06
Iter: 2746 loss: 1.6446819e-06
Iter: 2747 loss: 1.64436551e-06
Iter: 2748 loss: 1.64425546e-06
Iter: 2749 loss: 1.64459379e-06
Iter: 2750 loss: 1.64419646e-06
Iter: 2751 loss: 1.64413518e-06
Iter: 2752 loss: 1.6454519e-06
Iter: 2753 loss: 1.6440913e-06
Iter: 2754 loss: 1.64394294e-06
Iter: 2755 loss: 1.64367623e-06
Iter: 2756 loss: 1.6470708e-06
Iter: 2757 loss: 1.64376581e-06
Iter: 2758 loss: 1.6435896e-06
Iter: 2759 loss: 1.64565301e-06
Iter: 2760 loss: 1.64346761e-06
Iter: 2761 loss: 1.64333846e-06
Iter: 2762 loss: 1.64294602e-06
Iter: 2763 loss: 1.64294306e-06
Iter: 2764 loss: 1.64289474e-06
Iter: 2765 loss: 1.64285348e-06
Iter: 2766 loss: 1.64269977e-06
Iter: 2767 loss: 1.64298535e-06
Iter: 2768 loss: 1.64262599e-06
Iter: 2769 loss: 1.64241851e-06
Iter: 2770 loss: 1.64276469e-06
Iter: 2771 loss: 1.64239373e-06
Iter: 2772 loss: 1.64232301e-06
Iter: 2773 loss: 1.64337928e-06
Iter: 2774 loss: 1.64230471e-06
Iter: 2775 loss: 1.64224207e-06
Iter: 2776 loss: 1.64206381e-06
Iter: 2777 loss: 1.64407402e-06
Iter: 2778 loss: 1.64213475e-06
Iter: 2779 loss: 1.64207154e-06
Iter: 2780 loss: 1.64261701e-06
Iter: 2781 loss: 1.64196945e-06
Iter: 2782 loss: 1.64185678e-06
Iter: 2783 loss: 1.64191465e-06
Iter: 2784 loss: 1.64175799e-06
Iter: 2785 loss: 1.64164339e-06
Iter: 2786 loss: 1.64210724e-06
Iter: 2787 loss: 1.64152175e-06
Iter: 2788 loss: 1.641361e-06
Iter: 2789 loss: 1.64166158e-06
Iter: 2790 loss: 1.64128505e-06
Iter: 2791 loss: 1.6410811e-06
Iter: 2792 loss: 1.64201424e-06
Iter: 2793 loss: 1.64110077e-06
Iter: 2794 loss: 1.64089988e-06
Iter: 2795 loss: 1.64069252e-06
Iter: 2796 loss: 1.64068729e-06
Iter: 2797 loss: 1.64067706e-06
Iter: 2798 loss: 1.64054745e-06
Iter: 2799 loss: 1.64045957e-06
Iter: 2800 loss: 1.6403327e-06
Iter: 2801 loss: 1.64032519e-06
Iter: 2802 loss: 1.64015091e-06
Iter: 2803 loss: 1.64151788e-06
Iter: 2804 loss: 1.64016524e-06
Iter: 2805 loss: 1.6400013e-06
Iter: 2806 loss: 1.64001654e-06
Iter: 2807 loss: 1.63996538e-06
Iter: 2808 loss: 1.63981429e-06
Iter: 2809 loss: 1.64046867e-06
Iter: 2810 loss: 1.63971777e-06
Iter: 2811 loss: 1.63948403e-06
Iter: 2812 loss: 1.64008384e-06
Iter: 2813 loss: 1.63946834e-06
Iter: 2814 loss: 1.63924483e-06
Iter: 2815 loss: 1.63971072e-06
Iter: 2816 loss: 1.63915774e-06
Iter: 2817 loss: 1.63904622e-06
Iter: 2818 loss: 1.64066341e-06
Iter: 2819 loss: 1.63905679e-06
Iter: 2820 loss: 1.63892116e-06
Iter: 2821 loss: 1.63879167e-06
Iter: 2822 loss: 1.63884033e-06
Iter: 2823 loss: 1.6385344e-06
Iter: 2824 loss: 1.6396076e-06
Iter: 2825 loss: 1.6384995e-06
Iter: 2826 loss: 1.63827167e-06
Iter: 2827 loss: 1.63835512e-06
Iter: 2828 loss: 1.63808591e-06
Iter: 2829 loss: 1.63793356e-06
Iter: 2830 loss: 1.63794152e-06
Iter: 2831 loss: 1.63773393e-06
Iter: 2832 loss: 1.63777133e-06
Iter: 2833 loss: 1.63769903e-06
Iter: 2834 loss: 1.63754794e-06
Iter: 2835 loss: 1.6388899e-06
Iter: 2836 loss: 1.63755135e-06
Iter: 2837 loss: 1.63755817e-06
Iter: 2838 loss: 1.63748871e-06
Iter: 2839 loss: 1.6374695e-06
Iter: 2840 loss: 1.63736092e-06
Iter: 2841 loss: 1.6379347e-06
Iter: 2842 loss: 1.63734114e-06
Iter: 2843 loss: 1.63721961e-06
Iter: 2844 loss: 1.63731397e-06
Iter: 2845 loss: 1.63712775e-06
Iter: 2846 loss: 1.6369554e-06
Iter: 2847 loss: 1.63739912e-06
Iter: 2848 loss: 1.63686627e-06
Iter: 2849 loss: 1.63666232e-06
Iter: 2850 loss: 1.63791333e-06
Iter: 2851 loss: 1.63679204e-06
Iter: 2852 loss: 1.63667255e-06
Iter: 2853 loss: 1.63646382e-06
Iter: 2854 loss: 1.64002279e-06
Iter: 2855 loss: 1.63649861e-06
Iter: 2856 loss: 1.63630762e-06
Iter: 2857 loss: 1.63625646e-06
Iter: 2858 loss: 1.63616073e-06
Iter: 2859 loss: 1.63682955e-06
Iter: 2860 loss: 1.63612731e-06
Iter: 2861 loss: 1.63602147e-06
Iter: 2862 loss: 1.63587697e-06
Iter: 2863 loss: 1.63964592e-06
Iter: 2864 loss: 1.63575794e-06
Iter: 2865 loss: 1.63578716e-06
Iter: 2866 loss: 1.63568234e-06
Iter: 2867 loss: 1.63561231e-06
Iter: 2868 loss: 1.63608388e-06
Iter: 2869 loss: 1.63562561e-06
Iter: 2870 loss: 1.63558548e-06
Iter: 2871 loss: 1.63564641e-06
Iter: 2872 loss: 1.63546201e-06
Iter: 2873 loss: 1.635442e-06
Iter: 2874 loss: 1.63532104e-06
Iter: 2875 loss: 1.63527977e-06
Iter: 2876 loss: 1.63521179e-06
Iter: 2877 loss: 1.63512891e-06
Iter: 2878 loss: 1.6350748e-06
Iter: 2879 loss: 1.63494076e-06
Iter: 2880 loss: 1.63508651e-06
Iter: 2881 loss: 1.63476579e-06
Iter: 2882 loss: 1.63448533e-06
Iter: 2883 loss: 1.63522714e-06
Iter: 2884 loss: 1.63456207e-06
Iter: 2885 loss: 1.63442382e-06
Iter: 2886 loss: 1.63593552e-06
Iter: 2887 loss: 1.6344402e-06
Iter: 2888 loss: 1.63437846e-06
Iter: 2889 loss: 1.63435527e-06
Iter: 2890 loss: 1.63419259e-06
Iter: 2891 loss: 1.63403479e-06
Iter: 2892 loss: 1.6345839e-06
Iter: 2893 loss: 1.63400296e-06
Iter: 2894 loss: 1.63379354e-06
Iter: 2895 loss: 1.63414666e-06
Iter: 2896 loss: 1.63370714e-06
Iter: 2897 loss: 1.63356606e-06
Iter: 2898 loss: 1.63410323e-06
Iter: 2899 loss: 1.63345976e-06
Iter: 2900 loss: 1.63332402e-06
Iter: 2901 loss: 1.63417076e-06
Iter: 2902 loss: 1.63330924e-06
Iter: 2903 loss: 1.63317611e-06
Iter: 2904 loss: 1.63411e-06
Iter: 2905 loss: 1.63321238e-06
Iter: 2906 loss: 1.63302036e-06
Iter: 2907 loss: 1.63361619e-06
Iter: 2908 loss: 1.63302695e-06
Iter: 2909 loss: 1.63295749e-06
Iter: 2910 loss: 1.6327715e-06
Iter: 2911 loss: 1.63432219e-06
Iter: 2912 loss: 1.63279913e-06
Iter: 2913 loss: 1.63256334e-06
Iter: 2914 loss: 1.63286677e-06
Iter: 2915 loss: 1.63250354e-06
Iter: 2916 loss: 1.63231164e-06
Iter: 2917 loss: 1.63380264e-06
Iter: 2918 loss: 1.63224524e-06
Iter: 2919 loss: 1.63218147e-06
Iter: 2920 loss: 1.63237064e-06
Iter: 2921 loss: 1.6321062e-06
Iter: 2922 loss: 1.63198706e-06
Iter: 2923 loss: 1.63280856e-06
Iter: 2924 loss: 1.63193306e-06
Iter: 2925 loss: 1.63185564e-06
Iter: 2926 loss: 1.63201855e-06
Iter: 2927 loss: 1.63185086e-06
Iter: 2928 loss: 1.63175514e-06
Iter: 2929 loss: 1.63193909e-06
Iter: 2930 loss: 1.63168897e-06
Iter: 2931 loss: 1.63148297e-06
Iter: 2932 loss: 1.63178197e-06
Iter: 2933 loss: 1.63138748e-06
Iter: 2934 loss: 1.63123104e-06
Iter: 2935 loss: 1.63199502e-06
Iter: 2936 loss: 1.63114566e-06
Iter: 2937 loss: 1.63101811e-06
Iter: 2938 loss: 1.63314576e-06
Iter: 2939 loss: 1.6309906e-06
Iter: 2940 loss: 1.63088521e-06
Iter: 2941 loss: 1.631288e-06
Iter: 2942 loss: 1.63090715e-06
Iter: 2943 loss: 1.63076515e-06
Iter: 2944 loss: 1.63052721e-06
Iter: 2945 loss: 1.63206118e-06
Iter: 2946 loss: 1.63040613e-06
Iter: 2947 loss: 1.63018126e-06
Iter: 2948 loss: 1.63132518e-06
Iter: 2949 loss: 1.6300869e-06
Iter: 2950 loss: 1.62987703e-06
Iter: 2951 loss: 1.63095569e-06
Iter: 2952 loss: 1.6298668e-06
Iter: 2953 loss: 1.62970127e-06
Iter: 2954 loss: 1.62960634e-06
Iter: 2955 loss: 1.62955985e-06
Iter: 2956 loss: 1.62938602e-06
Iter: 2957 loss: 1.62934157e-06
Iter: 2958 loss: 1.62916217e-06
Iter: 2959 loss: 1.62954598e-06
Iter: 2960 loss: 1.62913238e-06
Iter: 2961 loss: 1.62903859e-06
Iter: 2962 loss: 1.62901267e-06
Iter: 2963 loss: 1.6289041e-06
Iter: 2964 loss: 1.62871493e-06
Iter: 2965 loss: 1.62915683e-06
Iter: 2966 loss: 1.62870572e-06
Iter: 2967 loss: 1.6284655e-06
Iter: 2968 loss: 1.62947072e-06
Iter: 2969 loss: 1.62850893e-06
Iter: 2970 loss: 1.62839206e-06
Iter: 2971 loss: 1.62986589e-06
Iter: 2972 loss: 1.62837455e-06
Iter: 2973 loss: 1.62831498e-06
Iter: 2974 loss: 1.62835249e-06
Iter: 2975 loss: 1.62826359e-06
Iter: 2976 loss: 1.62821198e-06
Iter: 2977 loss: 1.62798e-06
Iter: 2978 loss: 1.62795266e-06
Iter: 2979 loss: 1.62788433e-06
Iter: 2980 loss: 1.62792549e-06
Iter: 2981 loss: 1.62778588e-06
Iter: 2982 loss: 1.62758602e-06
Iter: 2983 loss: 1.62814092e-06
Iter: 2984 loss: 1.6274962e-06
Iter: 2985 loss: 1.62734102e-06
Iter: 2986 loss: 1.62728384e-06
Iter: 2987 loss: 1.62708989e-06
Iter: 2988 loss: 1.6269255e-06
Iter: 2989 loss: 1.62989159e-06
Iter: 2990 loss: 1.62692822e-06
Iter: 2991 loss: 1.6267295e-06
Iter: 2992 loss: 1.6271174e-06
Iter: 2993 loss: 1.62666947e-06
Iter: 2994 loss: 1.62646052e-06
Iter: 2995 loss: 1.62654203e-06
Iter: 2996 loss: 1.62633751e-06
Iter: 2997 loss: 1.62608876e-06
Iter: 2998 loss: 1.62660012e-06
Iter: 2999 loss: 1.6259628e-06
Iter: 3000 loss: 1.6257145e-06
Iter: 3001 loss: 1.62815559e-06
Iter: 3002 loss: 1.62570495e-06
Iter: 3003 loss: 1.62561093e-06
Iter: 3004 loss: 1.62652384e-06
Iter: 3005 loss: 1.62563924e-06
Iter: 3006 loss: 1.62542278e-06
Iter: 3007 loss: 1.62607182e-06
Iter: 3008 loss: 1.62536526e-06
Iter: 3009 loss: 1.62520564e-06
Iter: 3010 loss: 1.6252659e-06
Iter: 3011 loss: 1.62512345e-06
Iter: 3012 loss: 1.62499646e-06
Iter: 3013 loss: 1.6248357e-06
Iter: 3014 loss: 1.62478591e-06
Iter: 3015 loss: 1.62458889e-06
Iter: 3016 loss: 1.6249968e-06
Iter: 3017 loss: 1.62447304e-06
Iter: 3018 loss: 1.62415256e-06
Iter: 3019 loss: 1.62543017e-06
Iter: 3020 loss: 1.62426034e-06
Iter: 3021 loss: 1.62407491e-06
Iter: 3022 loss: 1.62497918e-06
Iter: 3023 loss: 1.62409322e-06
Iter: 3024 loss: 1.62388233e-06
Iter: 3025 loss: 1.62429671e-06
Iter: 3026 loss: 1.62382878e-06
Iter: 3027 loss: 1.62370236e-06
Iter: 3028 loss: 1.62380184e-06
Iter: 3029 loss: 1.62363278e-06
Iter: 3030 loss: 1.62347112e-06
Iter: 3031 loss: 1.62366246e-06
Iter: 3032 loss: 1.62337301e-06
Iter: 3033 loss: 1.6231885e-06
Iter: 3034 loss: 1.62383594e-06
Iter: 3035 loss: 1.6231204e-06
Iter: 3036 loss: 1.62302604e-06
Iter: 3037 loss: 1.62368201e-06
Iter: 3038 loss: 1.62295908e-06
Iter: 3039 loss: 1.62285198e-06
Iter: 3040 loss: 1.62423908e-06
Iter: 3041 loss: 1.6228804e-06
Iter: 3042 loss: 1.62276092e-06
Iter: 3043 loss: 1.62292304e-06
Iter: 3044 loss: 1.62270101e-06
Iter: 3045 loss: 1.62254992e-06
Iter: 3046 loss: 1.62237654e-06
Iter: 3047 loss: 1.62715935e-06
Iter: 3048 loss: 1.62237393e-06
Iter: 3049 loss: 1.62210245e-06
Iter: 3050 loss: 1.62280753e-06
Iter: 3051 loss: 1.62201218e-06
Iter: 3052 loss: 1.62175593e-06
Iter: 3053 loss: 1.62377637e-06
Iter: 3054 loss: 1.6218072e-06
Iter: 3055 loss: 1.62168431e-06
Iter: 3056 loss: 1.62177696e-06
Iter: 3057 loss: 1.62159176e-06
Iter: 3058 loss: 1.62132847e-06
Iter: 3059 loss: 1.62245055e-06
Iter: 3060 loss: 1.62134779e-06
Iter: 3061 loss: 1.62113633e-06
Iter: 3062 loss: 1.62160495e-06
Iter: 3063 loss: 1.62113929e-06
Iter: 3064 loss: 1.62103152e-06
Iter: 3065 loss: 1.62127265e-06
Iter: 3066 loss: 1.62097217e-06
Iter: 3067 loss: 1.62077e-06
Iter: 3068 loss: 1.62140748e-06
Iter: 3069 loss: 1.62073388e-06
Iter: 3070 loss: 1.62066692e-06
Iter: 3071 loss: 1.62152492e-06
Iter: 3072 loss: 1.62062202e-06
Iter: 3073 loss: 1.62056517e-06
Iter: 3074 loss: 1.62145739e-06
Iter: 3075 loss: 1.62052493e-06
Iter: 3076 loss: 1.62044012e-06
Iter: 3077 loss: 1.62042875e-06
Iter: 3078 loss: 1.62038077e-06
Iter: 3079 loss: 1.62022479e-06
Iter: 3080 loss: 1.62006802e-06
Iter: 3081 loss: 1.62007382e-06
Iter: 3082 loss: 1.61988169e-06
Iter: 3083 loss: 1.61994433e-06
Iter: 3084 loss: 1.61974344e-06
Iter: 3085 loss: 1.61952721e-06
Iter: 3086 loss: 1.62137781e-06
Iter: 3087 loss: 1.61961475e-06
Iter: 3088 loss: 1.6193876e-06
Iter: 3089 loss: 1.61924e-06
Iter: 3090 loss: 1.61918388e-06
Iter: 3091 loss: 1.6189997e-06
Iter: 3092 loss: 1.6189158e-06
Iter: 3093 loss: 1.61881121e-06
Iter: 3094 loss: 1.6192331e-06
Iter: 3095 loss: 1.61881417e-06
Iter: 3096 loss: 1.61868445e-06
Iter: 3097 loss: 1.61887306e-06
Iter: 3098 loss: 1.61860862e-06
Iter: 3099 loss: 1.61842058e-06
Iter: 3100 loss: 1.61877483e-06
Iter: 3101 loss: 1.61839932e-06
Iter: 3102 loss: 1.6182837e-06
Iter: 3103 loss: 1.61870616e-06
Iter: 3104 loss: 1.61824323e-06
Iter: 3105 loss: 1.6181682e-06
Iter: 3106 loss: 1.61815478e-06
Iter: 3107 loss: 1.61810397e-06
Iter: 3108 loss: 1.61814341e-06
Iter: 3109 loss: 1.61807588e-06
Iter: 3110 loss: 1.61788444e-06
Iter: 3111 loss: 1.6178335e-06
Iter: 3112 loss: 1.61791559e-06
Iter: 3113 loss: 1.61768344e-06
Iter: 3114 loss: 1.61761818e-06
Iter: 3115 loss: 1.61762239e-06
Iter: 3116 loss: 1.61728485e-06
Iter: 3117 loss: 1.61865341e-06
Iter: 3118 loss: 1.61730873e-06
Iter: 3119 loss: 1.61702781e-06
Iter: 3120 loss: 1.61746971e-06
Iter: 3121 loss: 1.61705e-06
Iter: 3122 loss: 1.61692833e-06
Iter: 3123 loss: 1.61864023e-06
Iter: 3124 loss: 1.61689059e-06
Iter: 3125 loss: 1.61676144e-06
Iter: 3126 loss: 1.61722437e-06
Iter: 3127 loss: 1.61675928e-06
Iter: 3128 loss: 1.61665434e-06
Iter: 3129 loss: 1.61662967e-06
Iter: 3130 loss: 1.61657317e-06
Iter: 3131 loss: 1.61652656e-06
Iter: 3132 loss: 1.61671051e-06
Iter: 3133 loss: 1.6164056e-06
Iter: 3134 loss: 1.61632454e-06
Iter: 3135 loss: 1.61658659e-06
Iter: 3136 loss: 1.61632624e-06
Iter: 3137 loss: 1.61619846e-06
Iter: 3138 loss: 1.61624644e-06
Iter: 3139 loss: 1.6161132e-06
Iter: 3140 loss: 1.61611456e-06
Iter: 3141 loss: 1.61606226e-06
Iter: 3142 loss: 1.61593778e-06
Iter: 3143 loss: 1.61592811e-06
Iter: 3144 loss: 1.61581931e-06
Iter: 3145 loss: 1.61575497e-06
Iter: 3146 loss: 1.61570017e-06
Iter: 3147 loss: 1.61561513e-06
Iter: 3148 loss: 1.61551361e-06
Iter: 3149 loss: 1.61586388e-06
Iter: 3150 loss: 1.61549303e-06
Iter: 3151 loss: 1.61531739e-06
Iter: 3152 loss: 1.61666924e-06
Iter: 3153 loss: 1.61530556e-06
Iter: 3154 loss: 1.61517e-06
Iter: 3155 loss: 1.61516721e-06
Iter: 3156 loss: 1.61509251e-06
Iter: 3157 loss: 1.61492164e-06
Iter: 3158 loss: 1.6149404e-06
Iter: 3159 loss: 1.61476328e-06
Iter: 3160 loss: 1.61484343e-06
Iter: 3161 loss: 1.61477533e-06
Iter: 3162 loss: 1.61459434e-06
Iter: 3163 loss: 1.61504795e-06
Iter: 3164 loss: 1.61457797e-06
Iter: 3165 loss: 1.61443052e-06
Iter: 3166 loss: 1.61503044e-06
Iter: 3167 loss: 1.61441699e-06
Iter: 3168 loss: 1.61433127e-06
Iter: 3169 loss: 1.61481285e-06
Iter: 3170 loss: 1.61433491e-06
Iter: 3171 loss: 1.61419416e-06
Iter: 3172 loss: 1.61451317e-06
Iter: 3173 loss: 1.61421588e-06
Iter: 3174 loss: 1.61414584e-06
Iter: 3175 loss: 1.61407263e-06
Iter: 3176 loss: 1.6140043e-06
Iter: 3177 loss: 1.61392688e-06
Iter: 3178 loss: 1.61379933e-06
Iter: 3179 loss: 1.61378159e-06
Iter: 3180 loss: 1.61352807e-06
Iter: 3181 loss: 1.61376101e-06
Iter: 3182 loss: 1.61339312e-06
Iter: 3183 loss: 1.61319429e-06
Iter: 3184 loss: 1.61552873e-06
Iter: 3185 loss: 1.61326193e-06
Iter: 3186 loss: 1.61307e-06
Iter: 3187 loss: 1.61312369e-06
Iter: 3188 loss: 1.61302091e-06
Iter: 3189 loss: 1.61284891e-06
Iter: 3190 loss: 1.61430239e-06
Iter: 3191 loss: 1.61283788e-06
Iter: 3192 loss: 1.61262e-06
Iter: 3193 loss: 1.61309e-06
Iter: 3194 loss: 1.61263301e-06
Iter: 3195 loss: 1.61245202e-06
Iter: 3196 loss: 1.61240519e-06
Iter: 3197 loss: 1.61237517e-06
Iter: 3198 loss: 1.61215735e-06
Iter: 3199 loss: 1.61330968e-06
Iter: 3200 loss: 1.61215689e-06
Iter: 3201 loss: 1.61199e-06
Iter: 3202 loss: 1.61234925e-06
Iter: 3203 loss: 1.61195032e-06
Iter: 3204 loss: 1.61193816e-06
Iter: 3205 loss: 1.611877e-06
Iter: 3206 loss: 1.61180981e-06
Iter: 3207 loss: 1.6117524e-06
Iter: 3208 loss: 1.61172022e-06
Iter: 3209 loss: 1.61169214e-06
Iter: 3210 loss: 1.6116237e-06
Iter: 3211 loss: 1.61159471e-06
Iter: 3212 loss: 1.61150138e-06
Iter: 3213 loss: 1.61165781e-06
Iter: 3214 loss: 1.61141293e-06
Iter: 3215 loss: 1.6112939e-06
Iter: 3216 loss: 1.61123262e-06
Iter: 3217 loss: 1.61112598e-06
Iter: 3218 loss: 1.61098194e-06
Iter: 3219 loss: 1.61150433e-06
Iter: 3220 loss: 1.61095295e-06
Iter: 3221 loss: 1.61074263e-06
Iter: 3222 loss: 1.61142304e-06
Iter: 3223 loss: 1.61074513e-06
Iter: 3224 loss: 1.61050377e-06
Iter: 3225 loss: 1.6108803e-06
Iter: 3226 loss: 1.61052253e-06
Iter: 3227 loss: 1.61035223e-06
Iter: 3228 loss: 1.61259231e-06
Iter: 3229 loss: 1.61028072e-06
Iter: 3230 loss: 1.61026276e-06
Iter: 3231 loss: 1.61017226e-06
Iter: 3232 loss: 1.61018613e-06
Iter: 3233 loss: 1.60997661e-06
Iter: 3234 loss: 1.61048115e-06
Iter: 3235 loss: 1.60993545e-06
Iter: 3236 loss: 1.61001321e-06
Iter: 3237 loss: 1.60992522e-06
Iter: 3238 loss: 1.60986951e-06
Iter: 3239 loss: 1.60986133e-06
Iter: 3240 loss: 1.609891e-06
Iter: 3241 loss: 1.60983e-06
Iter: 3242 loss: 1.60972786e-06
Iter: 3243 loss: 1.6096842e-06
Iter: 3244 loss: 1.60967102e-06
Iter: 3245 loss: 1.61011292e-06
Iter: 3246 loss: 1.60961395e-06
Iter: 3247 loss: 1.60953334e-06
Iter: 3248 loss: 1.60996603e-06
Iter: 3249 loss: 1.60953414e-06
Iter: 3250 loss: 1.60950765e-06
Iter: 3251 loss: 1.60932086e-06
Iter: 3252 loss: 1.60935804e-06
Iter: 3253 loss: 1.60922696e-06
Iter: 3254 loss: 1.60939021e-06
Iter: 3255 loss: 1.60904119e-06
Iter: 3256 loss: 1.60892e-06
Iter: 3257 loss: 1.61032904e-06
Iter: 3258 loss: 1.60894024e-06
Iter: 3259 loss: 1.60879324e-06
Iter: 3260 loss: 1.60961054e-06
Iter: 3261 loss: 1.60882485e-06
Iter: 3262 loss: 1.60871855e-06
Iter: 3263 loss: 1.60891545e-06
Iter: 3264 loss: 1.60865454e-06
Iter: 3265 loss: 1.60850152e-06
Iter: 3266 loss: 1.60832246e-06
Iter: 3267 loss: 1.60831905e-06
Iter: 3268 loss: 1.60813363e-06
Iter: 3269 loss: 1.60818786e-06
Iter: 3270 loss: 1.60811794e-06
Iter: 3271 loss: 1.60869854e-06
Iter: 3272 loss: 1.60799016e-06
Iter: 3273 loss: 1.60794389e-06
Iter: 3274 loss: 1.60785476e-06
Iter: 3275 loss: 1.61023218e-06
Iter: 3276 loss: 1.60791933e-06
Iter: 3277 loss: 1.60773504e-06
Iter: 3278 loss: 1.60799163e-06
Iter: 3279 loss: 1.6076483e-06
Iter: 3280 loss: 1.60753211e-06
Iter: 3281 loss: 1.60799323e-06
Iter: 3282 loss: 1.60740501e-06
Iter: 3283 loss: 1.60727757e-06
Iter: 3284 loss: 1.60754075e-06
Iter: 3285 loss: 1.60724358e-06
Iter: 3286 loss: 1.60704781e-06
Iter: 3287 loss: 1.60717366e-06
Iter: 3288 loss: 1.60701404e-06
Iter: 3289 loss: 1.60679429e-06
Iter: 3290 loss: 1.60725835e-06
Iter: 3291 loss: 1.60671789e-06
Iter: 3292 loss: 1.60664285e-06
Iter: 3293 loss: 1.60662012e-06
Iter: 3294 loss: 1.60652257e-06
Iter: 3295 loss: 1.60648756e-06
Iter: 3296 loss: 1.60644754e-06
Iter: 3297 loss: 1.6062728e-06
Iter: 3298 loss: 1.6069821e-06
Iter: 3299 loss: 1.60615014e-06
Iter: 3300 loss: 1.60605578e-06
Iter: 3301 loss: 1.60630884e-06
Iter: 3302 loss: 1.60603918e-06
Iter: 3303 loss: 1.60599075e-06
Iter: 3304 loss: 1.60592379e-06
Iter: 3305 loss: 1.605889e-06
Iter: 3306 loss: 1.60578361e-06
Iter: 3307 loss: 1.60665786e-06
Iter: 3308 loss: 1.60581658e-06
Iter: 3309 loss: 1.60566799e-06
Iter: 3310 loss: 1.6058292e-06
Iter: 3311 loss: 1.60561297e-06
Iter: 3312 loss: 1.60553157e-06
Iter: 3313 loss: 1.60547688e-06
Iter: 3314 loss: 1.60550871e-06
Iter: 3315 loss: 1.60553202e-06
Iter: 3316 loss: 1.60549143e-06
Iter: 3317 loss: 1.6055069e-06
Iter: 3318 loss: 1.60555419e-06
Iter: 3319 loss: 1.60546028e-06
Iter: 3320 loss: 1.60549689e-06
Iter: 3321 loss: 1.60545778e-06
Iter: 3322 loss: 1.60551826e-06
Iter: 3323 loss: 1.6055468e-06
Iter: 3324 loss: 1.60548552e-06
Iter: 3325 loss: 1.60548962e-06
Iter: 3326 loss: 1.60547631e-06
Iter: 3327 loss: 1.60548097e-06
Iter: 3328 loss: 1.60548871e-06
Iter: 3329 loss: 1.6054862e-06
Iter: 3330 loss: 1.60548325e-06
Iter: 3331 loss: 1.60547506e-06
Iter: 3332 loss: 1.60547836e-06
Iter: 3333 loss: 1.6054795e-06
Iter: 3334 loss: 1.60547916e-06
Iter: 3335 loss: 1.6054787e-06
Iter: 3336 loss: 1.6054787e-06
Iter: 3337 loss: 1.60547847e-06
Iter: 3338 loss: 1.6054787e-06
Iter: 3339 loss: 1.60547847e-06
Iter: 3340 loss: 1.6054787e-06
Iter: 3341 loss: 1.6054787e-06
Iter: 3342 loss: 1.60547847e-06
Iter: 3343 loss: 1.6054787e-06
Iter: 3344 loss: 1.60536615e-06
Iter: 3345 loss: 1.60509228e-06
Iter: 3346 loss: 1.60497689e-06
Iter: 3347 loss: 1.60534478e-06
Iter: 3348 loss: 1.60482875e-06
Iter: 3349 loss: 1.60457955e-06
Iter: 3350 loss: 1.60522632e-06
Iter: 3351 loss: 1.60450372e-06
Iter: 3352 loss: 1.60444552e-06
Iter: 3353 loss: 1.60436423e-06
Iter: 3354 loss: 1.60422269e-06
Iter: 3355 loss: 1.60436707e-06
Iter: 3356 loss: 1.60424179e-06
Iter: 3357 loss: 1.60412492e-06
Iter: 3358 loss: 1.60389868e-06
Iter: 3359 loss: 1.60384604e-06
Iter: 3360 loss: 1.60370473e-06
Iter: 3361 loss: 1.60364448e-06
Iter: 3362 loss: 1.60363277e-06
Iter: 3363 loss: 1.60360935e-06
Iter: 3364 loss: 1.60359014e-06
Iter: 3365 loss: 1.60347861e-06
Iter: 3366 loss: 1.60403351e-06
Iter: 3367 loss: 1.6033971e-06
Iter: 3368 loss: 1.6033282e-06
Iter: 3369 loss: 1.60386753e-06
Iter: 3370 loss: 1.60323577e-06
Iter: 3371 loss: 1.6030699e-06
Iter: 3372 loss: 1.60336128e-06
Iter: 3373 loss: 1.60307263e-06
Iter: 3374 loss: 1.60290813e-06
Iter: 3375 loss: 1.60373941e-06
Iter: 3376 loss: 1.60288187e-06
Iter: 3377 loss: 1.60282934e-06
Iter: 3378 loss: 1.60303648e-06
Iter: 3379 loss: 1.60278159e-06
Iter: 3380 loss: 1.60254967e-06
Iter: 3381 loss: 1.60241802e-06
Iter: 3382 loss: 1.60246384e-06
Iter: 3383 loss: 1.60223487e-06
Iter: 3384 loss: 1.60319291e-06
Iter: 3385 loss: 1.60233844e-06
Iter: 3386 loss: 1.6021645e-06
Iter: 3387 loss: 1.6021869e-06
Iter: 3388 loss: 1.6020474e-06
Iter: 3389 loss: 1.60192985e-06
Iter: 3390 loss: 1.60199329e-06
Iter: 3391 loss: 1.60178013e-06
Iter: 3392 loss: 1.60167099e-06
Iter: 3393 loss: 1.60174045e-06
Iter: 3394 loss: 1.6016852e-06
Iter: 3395 loss: 1.60167019e-06
Iter: 3396 loss: 1.60159539e-06
Iter: 3397 loss: 1.60154821e-06
Iter: 3398 loss: 1.60254388e-06
Iter: 3399 loss: 1.60144862e-06
Iter: 3400 loss: 1.60130048e-06
Iter: 3401 loss: 1.60123022e-06
Iter: 3402 loss: 1.60119794e-06
Iter: 3403 loss: 1.6010024e-06
Iter: 3404 loss: 1.60101683e-06
Iter: 3405 loss: 1.60085665e-06
Iter: 3406 loss: 1.60069294e-06
Iter: 3407 loss: 1.6006e-06
Iter: 3408 loss: 1.6004185e-06
Iter: 3409 loss: 1.6004384e-06
Iter: 3410 loss: 1.60024922e-06
Iter: 3411 loss: 1.60075956e-06
Iter: 3412 loss: 1.60022387e-06
Iter: 3413 loss: 1.60006766e-06
Iter: 3414 loss: 1.6005672e-06
Iter: 3415 loss: 1.60014974e-06
Iter: 3416 loss: 1.60001946e-06
Iter: 3417 loss: 1.59970057e-06
Iter: 3418 loss: 1.60393915e-06
Iter: 3419 loss: 1.59970671e-06
Iter: 3420 loss: 1.59969579e-06
Iter: 3421 loss: 1.60191985e-06
Iter: 3422 loss: 1.59969647e-06
Iter: 3423 loss: 1.59951276e-06
Iter: 3424 loss: 1.59946717e-06
Iter: 3425 loss: 1.59946831e-06
Iter: 3426 loss: 1.59930846e-06
Iter: 3427 loss: 1.60087222e-06
Iter: 3428 loss: 1.5993254e-06
Iter: 3429 loss: 1.59915169e-06
Iter: 3430 loss: 1.59986348e-06
Iter: 3431 loss: 1.59906949e-06
Iter: 3432 loss: 1.59894773e-06
Iter: 3433 loss: 1.59891295e-06
Iter: 3434 loss: 1.59883473e-06
Iter: 3435 loss: 1.59878937e-06
Iter: 3436 loss: 1.59979413e-06
Iter: 3437 loss: 1.59884803e-06
Iter: 3438 loss: 1.59874457e-06
Iter: 3439 loss: 1.59876322e-06
Iter: 3440 loss: 1.59873798e-06
Iter: 3441 loss: 1.59880187e-06
Iter: 3442 loss: 1.59879824e-06
Iter: 3443 loss: 1.59877868e-06
Iter: 3444 loss: 1.59882813e-06
Iter: 3445 loss: 1.59878e-06
Iter: 3446 loss: 1.598832e-06
Iter: 3447 loss: 1.59882904e-06
Iter: 3448 loss: 1.59884394e-06
Iter: 3449 loss: 1.59883575e-06
Iter: 3450 loss: 1.59883075e-06
Iter: 3451 loss: 1.59884019e-06
Iter: 3452 loss: 1.59883916e-06
Iter: 3453 loss: 1.59884223e-06
Iter: 3454 loss: 1.59884394e-06
Iter: 3455 loss: 1.59883655e-06
Iter: 3456 loss: 1.59883371e-06
Iter: 3457 loss: 1.59883666e-06
Iter: 3458 loss: 1.59883666e-06
Iter: 3459 loss: 1.59883371e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8
+ date
Mon Nov  9 01:31:26 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_1000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_1000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d5408378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d539fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d5374b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d5374488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d5486378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d53746a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d5351510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d52aa268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d52a4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d525f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d527e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d5241378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d5288400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d51f3d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d51947b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d51c7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d51c7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d5187400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d512fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d50dbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d50f6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d509a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d50c1158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d50c1d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79d5076598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79823bc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7982361b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79823cf158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7982361510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7982361598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7982349d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79823008c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7982310840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79822b6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f795c3612f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f795c310c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.93547895e-06
Iter: 2 loss: 1.73752669e-05
Iter: 3 loss: 6.73830345e-06
Iter: 4 loss: 5.45081957e-06
Iter: 5 loss: 1.00234465e-05
Iter: 6 loss: 5.12401812e-06
Iter: 7 loss: 4.57956867e-06
Iter: 8 loss: 3.90188416e-06
Iter: 9 loss: 3.84544546e-06
Iter: 10 loss: 3.08543645e-06
Iter: 11 loss: 7.20382377e-06
Iter: 12 loss: 2.97244287e-06
Iter: 13 loss: 2.73353e-06
Iter: 14 loss: 5.26063559e-06
Iter: 15 loss: 2.7273345e-06
Iter: 16 loss: 2.57953297e-06
Iter: 17 loss: 2.71927388e-06
Iter: 18 loss: 2.49487266e-06
Iter: 19 loss: 2.34599679e-06
Iter: 20 loss: 3.17618765e-06
Iter: 21 loss: 2.32474099e-06
Iter: 22 loss: 2.21996538e-06
Iter: 23 loss: 2.57932447e-06
Iter: 24 loss: 2.1924493e-06
Iter: 25 loss: 2.10715893e-06
Iter: 26 loss: 2.28821546e-06
Iter: 27 loss: 2.07345965e-06
Iter: 28 loss: 1.99343867e-06
Iter: 29 loss: 2.20779248e-06
Iter: 30 loss: 1.96699557e-06
Iter: 31 loss: 1.91623394e-06
Iter: 32 loss: 1.90824471e-06
Iter: 33 loss: 1.87293597e-06
Iter: 34 loss: 1.79894175e-06
Iter: 35 loss: 2.45044566e-06
Iter: 36 loss: 1.79528763e-06
Iter: 37 loss: 1.79460267e-06
Iter: 38 loss: 1.77887955e-06
Iter: 39 loss: 1.75814159e-06
Iter: 40 loss: 1.70343355e-06
Iter: 41 loss: 2.12329564e-06
Iter: 42 loss: 1.6928002e-06
Iter: 43 loss: 1.6381158e-06
Iter: 44 loss: 1.84371549e-06
Iter: 45 loss: 1.62464846e-06
Iter: 46 loss: 1.57826526e-06
Iter: 47 loss: 1.79307608e-06
Iter: 48 loss: 1.56990723e-06
Iter: 49 loss: 1.54092447e-06
Iter: 50 loss: 1.56262627e-06
Iter: 51 loss: 1.52332234e-06
Iter: 52 loss: 1.48462e-06
Iter: 53 loss: 1.70452392e-06
Iter: 54 loss: 1.47922697e-06
Iter: 55 loss: 1.46196533e-06
Iter: 56 loss: 1.55659131e-06
Iter: 57 loss: 1.45952345e-06
Iter: 58 loss: 1.44185094e-06
Iter: 59 loss: 1.42421447e-06
Iter: 60 loss: 1.4206073e-06
Iter: 61 loss: 1.39262397e-06
Iter: 62 loss: 1.67603048e-06
Iter: 63 loss: 1.39186977e-06
Iter: 64 loss: 1.37764243e-06
Iter: 65 loss: 1.36701044e-06
Iter: 66 loss: 1.3621509e-06
Iter: 67 loss: 1.33911385e-06
Iter: 68 loss: 1.48448362e-06
Iter: 69 loss: 1.33646097e-06
Iter: 70 loss: 1.32148966e-06
Iter: 71 loss: 1.3103205e-06
Iter: 72 loss: 1.30559056e-06
Iter: 73 loss: 1.35289952e-06
Iter: 74 loss: 1.30142303e-06
Iter: 75 loss: 1.29747139e-06
Iter: 76 loss: 1.28711736e-06
Iter: 77 loss: 1.36409858e-06
Iter: 78 loss: 1.28480565e-06
Iter: 79 loss: 1.27302917e-06
Iter: 80 loss: 1.27413045e-06
Iter: 81 loss: 1.26418149e-06
Iter: 82 loss: 1.25113172e-06
Iter: 83 loss: 1.44584067e-06
Iter: 84 loss: 1.25108204e-06
Iter: 85 loss: 1.24348901e-06
Iter: 86 loss: 1.23643861e-06
Iter: 87 loss: 1.23444875e-06
Iter: 88 loss: 1.22093888e-06
Iter: 89 loss: 1.28711247e-06
Iter: 90 loss: 1.21850144e-06
Iter: 91 loss: 1.20807817e-06
Iter: 92 loss: 1.28572765e-06
Iter: 93 loss: 1.20732466e-06
Iter: 94 loss: 1.20168875e-06
Iter: 95 loss: 1.2025414e-06
Iter: 96 loss: 1.1976399e-06
Iter: 97 loss: 1.18736023e-06
Iter: 98 loss: 1.19678771e-06
Iter: 99 loss: 1.18145613e-06
Iter: 100 loss: 1.16877084e-06
Iter: 101 loss: 1.21443395e-06
Iter: 102 loss: 1.16559249e-06
Iter: 103 loss: 1.15718012e-06
Iter: 104 loss: 1.16407909e-06
Iter: 105 loss: 1.1520284e-06
Iter: 106 loss: 1.13975875e-06
Iter: 107 loss: 1.1921029e-06
Iter: 108 loss: 1.13721308e-06
Iter: 109 loss: 1.13871783e-06
Iter: 110 loss: 1.13512647e-06
Iter: 111 loss: 1.13237616e-06
Iter: 112 loss: 1.12478801e-06
Iter: 113 loss: 1.15736873e-06
Iter: 114 loss: 1.12194391e-06
Iter: 115 loss: 1.11481575e-06
Iter: 116 loss: 1.12906639e-06
Iter: 117 loss: 1.11194356e-06
Iter: 118 loss: 1.10523229e-06
Iter: 119 loss: 1.12855184e-06
Iter: 120 loss: 1.10351948e-06
Iter: 121 loss: 1.09573602e-06
Iter: 122 loss: 1.13574083e-06
Iter: 123 loss: 1.09438793e-06
Iter: 124 loss: 1.0902844e-06
Iter: 125 loss: 1.09853113e-06
Iter: 126 loss: 1.08861707e-06
Iter: 127 loss: 1.08405163e-06
Iter: 128 loss: 1.09356279e-06
Iter: 129 loss: 1.08243228e-06
Iter: 130 loss: 1.07643871e-06
Iter: 131 loss: 1.08847428e-06
Iter: 132 loss: 1.07399239e-06
Iter: 133 loss: 1.06944321e-06
Iter: 134 loss: 1.07817436e-06
Iter: 135 loss: 1.06749974e-06
Iter: 136 loss: 1.06062066e-06
Iter: 137 loss: 1.06410118e-06
Iter: 138 loss: 1.05593767e-06
Iter: 139 loss: 1.04937214e-06
Iter: 140 loss: 1.08881841e-06
Iter: 141 loss: 1.04862329e-06
Iter: 142 loss: 1.04317064e-06
Iter: 143 loss: 1.03718173e-06
Iter: 144 loss: 1.03634875e-06
Iter: 145 loss: 1.04863261e-06
Iter: 146 loss: 1.03391028e-06
Iter: 147 loss: 1.03214393e-06
Iter: 148 loss: 1.02990964e-06
Iter: 149 loss: 1.02956824e-06
Iter: 150 loss: 1.02702927e-06
Iter: 151 loss: 1.02051183e-06
Iter: 152 loss: 1.08682457e-06
Iter: 153 loss: 1.01982778e-06
Iter: 154 loss: 1.01418198e-06
Iter: 155 loss: 1.05419952e-06
Iter: 156 loss: 1.01365242e-06
Iter: 157 loss: 1.00775117e-06
Iter: 158 loss: 1.03577679e-06
Iter: 159 loss: 1.00673674e-06
Iter: 160 loss: 1.00264072e-06
Iter: 161 loss: 1.01683486e-06
Iter: 162 loss: 1.00165266e-06
Iter: 163 loss: 9.98650421e-07
Iter: 164 loss: 1.00088585e-06
Iter: 165 loss: 9.96905442e-07
Iter: 166 loss: 9.92815e-07
Iter: 167 loss: 1.01662988e-06
Iter: 168 loss: 9.92316245e-07
Iter: 169 loss: 9.89386422e-07
Iter: 170 loss: 9.94200491e-07
Iter: 171 loss: 9.88037414e-07
Iter: 172 loss: 9.85410907e-07
Iter: 173 loss: 9.94075776e-07
Iter: 174 loss: 9.84680241e-07
Iter: 175 loss: 9.8107239e-07
Iter: 176 loss: 9.80437676e-07
Iter: 177 loss: 9.78173603e-07
Iter: 178 loss: 9.74617e-07
Iter: 179 loss: 1.00325451e-06
Iter: 180 loss: 9.74411e-07
Iter: 181 loss: 9.7398663e-07
Iter: 182 loss: 9.73149326e-07
Iter: 183 loss: 9.72024282e-07
Iter: 184 loss: 9.6838528e-07
Iter: 185 loss: 9.81629228e-07
Iter: 186 loss: 9.67037408e-07
Iter: 187 loss: 9.63830644e-07
Iter: 188 loss: 9.84755843e-07
Iter: 189 loss: 9.63499588e-07
Iter: 190 loss: 9.60559532e-07
Iter: 191 loss: 9.57593556e-07
Iter: 192 loss: 9.5709629e-07
Iter: 193 loss: 9.54964435e-07
Iter: 194 loss: 9.54466e-07
Iter: 195 loss: 9.5263772e-07
Iter: 196 loss: 9.52039045e-07
Iter: 197 loss: 9.51055938e-07
Iter: 198 loss: 9.48331547e-07
Iter: 199 loss: 9.48509125e-07
Iter: 200 loss: 9.46090609e-07
Iter: 201 loss: 9.4373911e-07
Iter: 202 loss: 9.43667942e-07
Iter: 203 loss: 9.42161762e-07
Iter: 204 loss: 9.39306915e-07
Iter: 205 loss: 9.91286e-07
Iter: 206 loss: 9.39198628e-07
Iter: 207 loss: 9.36035747e-07
Iter: 208 loss: 9.78249886e-07
Iter: 209 loss: 9.36129652e-07
Iter: 210 loss: 9.34177e-07
Iter: 211 loss: 9.33979493e-07
Iter: 212 loss: 9.32452622e-07
Iter: 213 loss: 9.29571684e-07
Iter: 214 loss: 9.43987516e-07
Iter: 215 loss: 9.29075156e-07
Iter: 216 loss: 9.26088433e-07
Iter: 217 loss: 9.65498e-07
Iter: 218 loss: 9.26070697e-07
Iter: 219 loss: 9.25093161e-07
Iter: 220 loss: 9.22985919e-07
Iter: 221 loss: 9.52788355e-07
Iter: 222 loss: 9.22889171e-07
Iter: 223 loss: 9.20537957e-07
Iter: 224 loss: 9.1899841e-07
Iter: 225 loss: 9.18051569e-07
Iter: 226 loss: 9.14666714e-07
Iter: 227 loss: 9.52386358e-07
Iter: 228 loss: 9.14563316e-07
Iter: 229 loss: 9.12329881e-07
Iter: 230 loss: 9.17758e-07
Iter: 231 loss: 9.11549932e-07
Iter: 232 loss: 9.08726633e-07
Iter: 233 loss: 9.17631837e-07
Iter: 234 loss: 9.07857157e-07
Iter: 235 loss: 9.06066873e-07
Iter: 236 loss: 9.06958462e-07
Iter: 237 loss: 9.04789772e-07
Iter: 238 loss: 9.02224429e-07
Iter: 239 loss: 9.17876491e-07
Iter: 240 loss: 9.01792419e-07
Iter: 241 loss: 8.99853489e-07
Iter: 242 loss: 9.02196916e-07
Iter: 243 loss: 8.98716166e-07
Iter: 244 loss: 8.96702659e-07
Iter: 245 loss: 9.00592397e-07
Iter: 246 loss: 8.95946243e-07
Iter: 247 loss: 8.93270112e-07
Iter: 248 loss: 9.00048803e-07
Iter: 249 loss: 8.92388869e-07
Iter: 250 loss: 8.90707042e-07
Iter: 251 loss: 9.12679127e-07
Iter: 252 loss: 8.90605747e-07
Iter: 253 loss: 8.89358944e-07
Iter: 254 loss: 9.08300706e-07
Iter: 255 loss: 8.89410501e-07
Iter: 256 loss: 8.88917612e-07
Iter: 257 loss: 8.87324234e-07
Iter: 258 loss: 8.87160297e-07
Iter: 259 loss: 8.85669692e-07
Iter: 260 loss: 8.83055634e-07
Iter: 261 loss: 9.14229418e-07
Iter: 262 loss: 8.82951213e-07
Iter: 263 loss: 8.81344363e-07
Iter: 264 loss: 8.82231575e-07
Iter: 265 loss: 8.80100799e-07
Iter: 266 loss: 8.77323657e-07
Iter: 267 loss: 8.86401608e-07
Iter: 268 loss: 8.76560478e-07
Iter: 269 loss: 8.74528837e-07
Iter: 270 loss: 8.96633765e-07
Iter: 271 loss: 8.74542366e-07
Iter: 272 loss: 8.73384295e-07
Iter: 273 loss: 8.71103e-07
Iter: 274 loss: 9.18572368e-07
Iter: 275 loss: 8.7114114e-07
Iter: 276 loss: 8.68269922e-07
Iter: 277 loss: 8.97514951e-07
Iter: 278 loss: 8.68158793e-07
Iter: 279 loss: 8.66495895e-07
Iter: 280 loss: 8.70630686e-07
Iter: 281 loss: 8.66104756e-07
Iter: 282 loss: 8.64422077e-07
Iter: 283 loss: 8.62808577e-07
Iter: 284 loss: 8.6252993e-07
Iter: 285 loss: 8.60843954e-07
Iter: 286 loss: 8.6091967e-07
Iter: 287 loss: 8.59649901e-07
Iter: 288 loss: 8.63618538e-07
Iter: 289 loss: 8.59369266e-07
Iter: 290 loss: 8.57928171e-07
Iter: 291 loss: 8.69844541e-07
Iter: 292 loss: 8.57794e-07
Iter: 293 loss: 8.57201087e-07
Iter: 294 loss: 8.55232599e-07
Iter: 295 loss: 8.64940944e-07
Iter: 296 loss: 8.54624659e-07
Iter: 297 loss: 8.52542883e-07
Iter: 298 loss: 8.58798558e-07
Iter: 299 loss: 8.51843481e-07
Iter: 300 loss: 8.49872777e-07
Iter: 301 loss: 8.60581167e-07
Iter: 302 loss: 8.49528647e-07
Iter: 303 loss: 8.47869387e-07
Iter: 304 loss: 8.56782322e-07
Iter: 305 loss: 8.47616889e-07
Iter: 306 loss: 8.46126852e-07
Iter: 307 loss: 8.50478784e-07
Iter: 308 loss: 8.45690352e-07
Iter: 309 loss: 8.44132614e-07
Iter: 310 loss: 8.45953195e-07
Iter: 311 loss: 8.43306339e-07
Iter: 312 loss: 8.41855694e-07
Iter: 313 loss: 8.45238674e-07
Iter: 314 loss: 8.41374e-07
Iter: 315 loss: 8.39350378e-07
Iter: 316 loss: 8.43761086e-07
Iter: 317 loss: 8.38651545e-07
Iter: 318 loss: 8.37214088e-07
Iter: 319 loss: 8.41646909e-07
Iter: 320 loss: 8.36749564e-07
Iter: 321 loss: 8.35481046e-07
Iter: 322 loss: 8.39864413e-07
Iter: 323 loss: 8.35149876e-07
Iter: 324 loss: 8.33955085e-07
Iter: 325 loss: 8.34033472e-07
Iter: 326 loss: 8.33031208e-07
Iter: 327 loss: 8.32269393e-07
Iter: 328 loss: 8.31917589e-07
Iter: 329 loss: 8.30952899e-07
Iter: 330 loss: 8.30078761e-07
Iter: 331 loss: 8.29818418e-07
Iter: 332 loss: 8.28191901e-07
Iter: 333 loss: 8.27148483e-07
Iter: 334 loss: 8.26511382e-07
Iter: 335 loss: 8.24854624e-07
Iter: 336 loss: 8.4484293e-07
Iter: 337 loss: 8.24920562e-07
Iter: 338 loss: 8.23363507e-07
Iter: 339 loss: 8.27738859e-07
Iter: 340 loss: 8.22931327e-07
Iter: 341 loss: 8.21425886e-07
Iter: 342 loss: 8.30842168e-07
Iter: 343 loss: 8.21187427e-07
Iter: 344 loss: 8.20336595e-07
Iter: 345 loss: 8.19962395e-07
Iter: 346 loss: 8.19414709e-07
Iter: 347 loss: 8.17640512e-07
Iter: 348 loss: 8.22835773e-07
Iter: 349 loss: 8.17083674e-07
Iter: 350 loss: 8.15809926e-07
Iter: 351 loss: 8.27029851e-07
Iter: 352 loss: 8.1581544e-07
Iter: 353 loss: 8.14785039e-07
Iter: 354 loss: 8.12999474e-07
Iter: 355 loss: 8.54616928e-07
Iter: 356 loss: 8.12849521e-07
Iter: 357 loss: 8.1251028e-07
Iter: 358 loss: 8.11943778e-07
Iter: 359 loss: 8.11008817e-07
Iter: 360 loss: 8.13556824e-07
Iter: 361 loss: 8.10801907e-07
Iter: 362 loss: 8.10230176e-07
Iter: 363 loss: 8.0948e-07
Iter: 364 loss: 8.09446874e-07
Iter: 365 loss: 8.08234859e-07
Iter: 366 loss: 8.07787274e-07
Iter: 367 loss: 8.07228105e-07
Iter: 368 loss: 8.05432649e-07
Iter: 369 loss: 8.08299205e-07
Iter: 370 loss: 8.04573915e-07
Iter: 371 loss: 8.02547959e-07
Iter: 372 loss: 8.05257741e-07
Iter: 373 loss: 8.01463443e-07
Iter: 374 loss: 8.0073653e-07
Iter: 375 loss: 8.00475277e-07
Iter: 376 loss: 7.99561235e-07
Iter: 377 loss: 7.9811673e-07
Iter: 378 loss: 7.98053406e-07
Iter: 379 loss: 7.96668473e-07
Iter: 380 loss: 8.10911615e-07
Iter: 381 loss: 7.96683707e-07
Iter: 382 loss: 7.95567587e-07
Iter: 383 loss: 7.9703841e-07
Iter: 384 loss: 7.94974596e-07
Iter: 385 loss: 7.93507297e-07
Iter: 386 loss: 7.95407686e-07
Iter: 387 loss: 7.92634e-07
Iter: 388 loss: 7.91421598e-07
Iter: 389 loss: 8.02116688e-07
Iter: 390 loss: 7.9138016e-07
Iter: 391 loss: 7.90933029e-07
Iter: 392 loss: 7.9086351e-07
Iter: 393 loss: 7.90510626e-07
Iter: 394 loss: 7.89454e-07
Iter: 395 loss: 7.92251512e-07
Iter: 396 loss: 7.88908324e-07
Iter: 397 loss: 7.87130944e-07
Iter: 398 loss: 7.96580707e-07
Iter: 399 loss: 7.86890951e-07
Iter: 400 loss: 7.85807e-07
Iter: 401 loss: 7.86068085e-07
Iter: 402 loss: 7.84936844e-07
Iter: 403 loss: 7.83239329e-07
Iter: 404 loss: 7.84758072e-07
Iter: 405 loss: 7.82200061e-07
Iter: 406 loss: 7.80838263e-07
Iter: 407 loss: 7.94701748e-07
Iter: 408 loss: 7.80754135e-07
Iter: 409 loss: 7.79703896e-07
Iter: 410 loss: 7.83759447e-07
Iter: 411 loss: 7.79371589e-07
Iter: 412 loss: 7.77985633e-07
Iter: 413 loss: 7.79579864e-07
Iter: 414 loss: 7.77272362e-07
Iter: 415 loss: 7.76354113e-07
Iter: 416 loss: 7.78263086e-07
Iter: 417 loss: 7.75972183e-07
Iter: 418 loss: 7.74627324e-07
Iter: 419 loss: 7.78002e-07
Iter: 420 loss: 7.74037858e-07
Iter: 421 loss: 7.72982276e-07
Iter: 422 loss: 7.77287312e-07
Iter: 423 loss: 7.72857845e-07
Iter: 424 loss: 7.72172257e-07
Iter: 425 loss: 7.79924619e-07
Iter: 426 loss: 7.72178055e-07
Iter: 427 loss: 7.71189832e-07
Iter: 428 loss: 7.71497525e-07
Iter: 429 loss: 7.70593829e-07
Iter: 430 loss: 7.6997253e-07
Iter: 431 loss: 7.69802284e-07
Iter: 432 loss: 7.69303313e-07
Iter: 433 loss: 7.68564689e-07
Iter: 434 loss: 7.6845356e-07
Iter: 435 loss: 7.67942311e-07
Iter: 436 loss: 7.66371841e-07
Iter: 437 loss: 7.70905558e-07
Iter: 438 loss: 7.66030951e-07
Iter: 439 loss: 7.65044263e-07
Iter: 440 loss: 7.6613685e-07
Iter: 441 loss: 7.64434787e-07
Iter: 442 loss: 7.63035416e-07
Iter: 443 loss: 7.63785465e-07
Iter: 444 loss: 7.62016271e-07
Iter: 445 loss: 7.61226147e-07
Iter: 446 loss: 7.61048113e-07
Iter: 447 loss: 7.60237583e-07
Iter: 448 loss: 7.59804607e-07
Iter: 449 loss: 7.5949356e-07
Iter: 450 loss: 7.58308715e-07
Iter: 451 loss: 7.60800333e-07
Iter: 452 loss: 7.57890348e-07
Iter: 453 loss: 7.57139503e-07
Iter: 454 loss: 7.64922902e-07
Iter: 455 loss: 7.57054863e-07
Iter: 456 loss: 7.56225063e-07
Iter: 457 loss: 7.55678457e-07
Iter: 458 loss: 7.55402766e-07
Iter: 459 loss: 7.54742132e-07
Iter: 460 loss: 7.5480807e-07
Iter: 461 loss: 7.54145674e-07
Iter: 462 loss: 7.58018075e-07
Iter: 463 loss: 7.54141581e-07
Iter: 464 loss: 7.53725317e-07
Iter: 465 loss: 7.52823667e-07
Iter: 466 loss: 7.58971339e-07
Iter: 467 loss: 7.5260607e-07
Iter: 468 loss: 7.51367224e-07
Iter: 469 loss: 7.56664804e-07
Iter: 470 loss: 7.51098924e-07
Iter: 471 loss: 7.50254344e-07
Iter: 472 loss: 7.52790129e-07
Iter: 473 loss: 7.50052834e-07
Iter: 474 loss: 7.49002538e-07
Iter: 475 loss: 7.49251853e-07
Iter: 476 loss: 7.48297623e-07
Iter: 477 loss: 7.47205888e-07
Iter: 478 loss: 7.53644656e-07
Iter: 479 loss: 7.47053605e-07
Iter: 480 loss: 7.46197259e-07
Iter: 481 loss: 7.46206183e-07
Iter: 482 loss: 7.45521504e-07
Iter: 483 loss: 7.44025783e-07
Iter: 484 loss: 7.53924269e-07
Iter: 485 loss: 7.4382217e-07
Iter: 486 loss: 7.43187854e-07
Iter: 487 loss: 7.44026863e-07
Iter: 488 loss: 7.42912334e-07
Iter: 489 loss: 7.42125e-07
Iter: 490 loss: 7.41531835e-07
Iter: 491 loss: 7.41300596e-07
Iter: 492 loss: 7.40070675e-07
Iter: 493 loss: 7.53003633e-07
Iter: 494 loss: 7.40060841e-07
Iter: 495 loss: 7.39555105e-07
Iter: 496 loss: 7.39537768e-07
Iter: 497 loss: 7.39175732e-07
Iter: 498 loss: 7.38830408e-07
Iter: 499 loss: 7.38785332e-07
Iter: 500 loss: 7.38339622e-07
Iter: 501 loss: 7.37347477e-07
Iter: 502 loss: 7.45711759e-07
Iter: 503 loss: 7.37244818e-07
Iter: 504 loss: 7.3648846e-07
Iter: 505 loss: 7.40792586e-07
Iter: 506 loss: 7.36279446e-07
Iter: 507 loss: 7.35447486e-07
Iter: 508 loss: 7.35514277e-07
Iter: 509 loss: 7.34924242e-07
Iter: 510 loss: 7.3401884e-07
Iter: 511 loss: 7.383141e-07
Iter: 512 loss: 7.33835293e-07
Iter: 513 loss: 7.33104343e-07
Iter: 514 loss: 7.34362288e-07
Iter: 515 loss: 7.32721787e-07
Iter: 516 loss: 7.32143917e-07
Iter: 517 loss: 7.36038714e-07
Iter: 518 loss: 7.3204842e-07
Iter: 519 loss: 7.31502439e-07
Iter: 520 loss: 7.33869683e-07
Iter: 521 loss: 7.31413479e-07
Iter: 522 loss: 7.30830038e-07
Iter: 523 loss: 7.29811347e-07
Iter: 524 loss: 7.50035895e-07
Iter: 525 loss: 7.29695557e-07
Iter: 526 loss: 7.28583927e-07
Iter: 527 loss: 7.40950895e-07
Iter: 528 loss: 7.28625423e-07
Iter: 529 loss: 7.27833253e-07
Iter: 530 loss: 7.26171947e-07
Iter: 531 loss: 7.51356765e-07
Iter: 532 loss: 7.26150517e-07
Iter: 533 loss: 7.26782844e-07
Iter: 534 loss: 7.2547931e-07
Iter: 535 loss: 7.24825782e-07
Iter: 536 loss: 7.27067118e-07
Iter: 537 loss: 7.24526217e-07
Iter: 538 loss: 7.23943685e-07
Iter: 539 loss: 7.2274679e-07
Iter: 540 loss: 7.35619153e-07
Iter: 541 loss: 7.2261264e-07
Iter: 542 loss: 7.218988e-07
Iter: 543 loss: 7.21883e-07
Iter: 544 loss: 7.2126079e-07
Iter: 545 loss: 7.21011418e-07
Iter: 546 loss: 7.20656e-07
Iter: 547 loss: 7.19695e-07
Iter: 548 loss: 7.21839569e-07
Iter: 549 loss: 7.19274624e-07
Iter: 550 loss: 7.18360639e-07
Iter: 551 loss: 7.21648462e-07
Iter: 552 loss: 7.1821762e-07
Iter: 553 loss: 7.17578246e-07
Iter: 554 loss: 7.20282401e-07
Iter: 555 loss: 7.17341891e-07
Iter: 556 loss: 7.16659429e-07
Iter: 557 loss: 7.19570835e-07
Iter: 558 loss: 7.16363388e-07
Iter: 559 loss: 7.15856345e-07
Iter: 560 loss: 7.16013e-07
Iter: 561 loss: 7.15356634e-07
Iter: 562 loss: 7.14455041e-07
Iter: 563 loss: 7.1687748e-07
Iter: 564 loss: 7.14163605e-07
Iter: 565 loss: 7.13368422e-07
Iter: 566 loss: 7.18223305e-07
Iter: 567 loss: 7.13297254e-07
Iter: 568 loss: 7.1295625e-07
Iter: 569 loss: 7.12988253e-07
Iter: 570 loss: 7.12670385e-07
Iter: 571 loss: 7.11575922e-07
Iter: 572 loss: 7.13881775e-07
Iter: 573 loss: 7.10887e-07
Iter: 574 loss: 7.09820142e-07
Iter: 575 loss: 7.14665e-07
Iter: 576 loss: 7.09649612e-07
Iter: 577 loss: 7.08700668e-07
Iter: 578 loss: 7.10013182e-07
Iter: 579 loss: 7.08244102e-07
Iter: 580 loss: 7.06963306e-07
Iter: 581 loss: 7.14579528e-07
Iter: 582 loss: 7.06702735e-07
Iter: 583 loss: 7.06066828e-07
Iter: 584 loss: 7.07361892e-07
Iter: 585 loss: 7.05803245e-07
Iter: 586 loss: 7.0499334e-07
Iter: 587 loss: 7.04642844e-07
Iter: 588 loss: 7.04278136e-07
Iter: 589 loss: 7.03985563e-07
Iter: 590 loss: 7.03710214e-07
Iter: 591 loss: 7.03338401e-07
Iter: 592 loss: 7.0274541e-07
Iter: 593 loss: 7.02701641e-07
Iter: 594 loss: 7.01920214e-07
Iter: 595 loss: 7.05009143e-07
Iter: 596 loss: 7.01697e-07
Iter: 597 loss: 7.01166698e-07
Iter: 598 loss: 7.06429546e-07
Iter: 599 loss: 7.01094223e-07
Iter: 600 loss: 7.00672558e-07
Iter: 601 loss: 7.01051135e-07
Iter: 602 loss: 7.00476789e-07
Iter: 603 loss: 6.99793418e-07
Iter: 604 loss: 7.05090315e-07
Iter: 605 loss: 6.99827581e-07
Iter: 606 loss: 6.99552743e-07
Iter: 607 loss: 6.99207533e-07
Iter: 608 loss: 6.99151201e-07
Iter: 609 loss: 6.98709073e-07
Iter: 610 loss: 6.97662472e-07
Iter: 611 loss: 7.14178725e-07
Iter: 612 loss: 6.97638598e-07
Iter: 613 loss: 6.96989844e-07
Iter: 614 loss: 6.96968698e-07
Iter: 615 loss: 6.96357e-07
Iter: 616 loss: 6.96654411e-07
Iter: 617 loss: 6.96019242e-07
Iter: 618 loss: 6.95175402e-07
Iter: 619 loss: 6.95962854e-07
Iter: 620 loss: 6.94761411e-07
Iter: 621 loss: 6.94041e-07
Iter: 622 loss: 6.93870788e-07
Iter: 623 loss: 6.93467086e-07
Iter: 624 loss: 6.92369952e-07
Iter: 625 loss: 6.96692268e-07
Iter: 626 loss: 6.92165941e-07
Iter: 627 loss: 6.91673108e-07
Iter: 628 loss: 6.9165975e-07
Iter: 629 loss: 6.91143384e-07
Iter: 630 loss: 6.90844331e-07
Iter: 631 loss: 6.90591435e-07
Iter: 632 loss: 6.89980084e-07
Iter: 633 loss: 6.93439802e-07
Iter: 634 loss: 6.89884928e-07
Iter: 635 loss: 6.89655394e-07
Iter: 636 loss: 6.89584908e-07
Iter: 637 loss: 6.89321155e-07
Iter: 638 loss: 6.8890364e-07
Iter: 639 loss: 6.98774841e-07
Iter: 640 loss: 6.8890887e-07
Iter: 641 loss: 6.88513126e-07
Iter: 642 loss: 6.88239425e-07
Iter: 643 loss: 6.8797e-07
Iter: 644 loss: 6.8737296e-07
Iter: 645 loss: 6.88807233e-07
Iter: 646 loss: 6.8713257e-07
Iter: 647 loss: 6.86471537e-07
Iter: 648 loss: 6.88540354e-07
Iter: 649 loss: 6.86259682e-07
Iter: 650 loss: 6.85783903e-07
Iter: 651 loss: 6.91533558e-07
Iter: 652 loss: 6.85686359e-07
Iter: 653 loss: 6.85289763e-07
Iter: 654 loss: 6.84687734e-07
Iter: 655 loss: 6.84632425e-07
Iter: 656 loss: 6.8363056e-07
Iter: 657 loss: 6.859633e-07
Iter: 658 loss: 6.83270912e-07
Iter: 659 loss: 6.82629434e-07
Iter: 660 loss: 6.84088945e-07
Iter: 661 loss: 6.82426389e-07
Iter: 662 loss: 6.81487222e-07
Iter: 663 loss: 6.82114262e-07
Iter: 664 loss: 6.80892526e-07
Iter: 665 loss: 6.80665266e-07
Iter: 666 loss: 6.80447101e-07
Iter: 667 loss: 6.80143216e-07
Iter: 668 loss: 6.79663e-07
Iter: 669 loss: 6.79646348e-07
Iter: 670 loss: 6.79325808e-07
Iter: 671 loss: 6.79193931e-07
Iter: 672 loss: 6.79036248e-07
Iter: 673 loss: 6.78758056e-07
Iter: 674 loss: 6.85810051e-07
Iter: 675 loss: 6.7868973e-07
Iter: 676 loss: 6.7822873e-07
Iter: 677 loss: 6.78378228e-07
Iter: 678 loss: 6.77962589e-07
Iter: 679 loss: 6.7729934e-07
Iter: 680 loss: 6.78913295e-07
Iter: 681 loss: 6.76955324e-07
Iter: 682 loss: 6.76470904e-07
Iter: 683 loss: 6.81294694e-07
Iter: 684 loss: 6.76437935e-07
Iter: 685 loss: 6.76020477e-07
Iter: 686 loss: 6.77133812e-07
Iter: 687 loss: 6.75894626e-07
Iter: 688 loss: 6.75471426e-07
Iter: 689 loss: 6.75983415e-07
Iter: 690 loss: 6.75342676e-07
Iter: 691 loss: 6.74855471e-07
Iter: 692 loss: 6.74888e-07
Iter: 693 loss: 6.74424712e-07
Iter: 694 loss: 6.73775048e-07
Iter: 695 loss: 6.77936441e-07
Iter: 696 loss: 6.73680518e-07
Iter: 697 loss: 6.73245154e-07
Iter: 698 loss: 6.73441093e-07
Iter: 699 loss: 6.728485e-07
Iter: 700 loss: 6.72186673e-07
Iter: 701 loss: 6.77991e-07
Iter: 702 loss: 6.72112947e-07
Iter: 703 loss: 6.71807697e-07
Iter: 704 loss: 6.75688511e-07
Iter: 705 loss: 6.71737098e-07
Iter: 706 loss: 6.71436e-07
Iter: 707 loss: 6.74085356e-07
Iter: 708 loss: 6.71338569e-07
Iter: 709 loss: 6.71251087e-07
Iter: 710 loss: 6.70835334e-07
Iter: 711 loss: 6.7259208e-07
Iter: 712 loss: 6.70593238e-07
Iter: 713 loss: 6.69925555e-07
Iter: 714 loss: 6.73284205e-07
Iter: 715 loss: 6.69828751e-07
Iter: 716 loss: 6.69379858e-07
Iter: 717 loss: 6.69497808e-07
Iter: 718 loss: 6.69003384e-07
Iter: 719 loss: 6.68332518e-07
Iter: 720 loss: 6.69260203e-07
Iter: 721 loss: 6.67937968e-07
Iter: 722 loss: 6.67344693e-07
Iter: 723 loss: 6.68838766e-07
Iter: 724 loss: 6.67216113e-07
Iter: 725 loss: 6.66507901e-07
Iter: 726 loss: 6.71101418e-07
Iter: 727 loss: 6.66344249e-07
Iter: 728 loss: 6.65881316e-07
Iter: 729 loss: 6.69475924e-07
Iter: 730 loss: 6.65796506e-07
Iter: 731 loss: 6.65450614e-07
Iter: 732 loss: 6.64878428e-07
Iter: 733 loss: 6.76929517e-07
Iter: 734 loss: 6.64943627e-07
Iter: 735 loss: 6.64038566e-07
Iter: 736 loss: 6.67776419e-07
Iter: 737 loss: 6.63884862e-07
Iter: 738 loss: 6.633353e-07
Iter: 739 loss: 6.67015229e-07
Iter: 740 loss: 6.63306309e-07
Iter: 741 loss: 6.62978664e-07
Iter: 742 loss: 6.6678831e-07
Iter: 743 loss: 6.63017317e-07
Iter: 744 loss: 6.62611569e-07
Iter: 745 loss: 6.63681249e-07
Iter: 746 loss: 6.62500781e-07
Iter: 747 loss: 6.62275625e-07
Iter: 748 loss: 6.61966226e-07
Iter: 749 loss: 6.61900231e-07
Iter: 750 loss: 6.61512559e-07
Iter: 751 loss: 6.61297861e-07
Iter: 752 loss: 6.61095669e-07
Iter: 753 loss: 6.60735395e-07
Iter: 754 loss: 6.60708167e-07
Iter: 755 loss: 6.60494834e-07
Iter: 756 loss: 6.60429691e-07
Iter: 757 loss: 6.60220678e-07
Iter: 758 loss: 6.59709713e-07
Iter: 759 loss: 6.6058027e-07
Iter: 760 loss: 6.59367629e-07
Iter: 761 loss: 6.58838474e-07
Iter: 762 loss: 6.59071873e-07
Iter: 763 loss: 6.5853834e-07
Iter: 764 loss: 6.57950068e-07
Iter: 765 loss: 6.57984287e-07
Iter: 766 loss: 6.5751658e-07
Iter: 767 loss: 6.58616045e-07
Iter: 768 loss: 6.57469059e-07
Iter: 769 loss: 6.57112821e-07
Iter: 770 loss: 6.56483053e-07
Iter: 771 loss: 6.72603278e-07
Iter: 772 loss: 6.56507e-07
Iter: 773 loss: 6.56152167e-07
Iter: 774 loss: 6.56079465e-07
Iter: 775 loss: 6.5579809e-07
Iter: 776 loss: 6.59531111e-07
Iter: 777 loss: 6.55873293e-07
Iter: 778 loss: 6.55570204e-07
Iter: 779 loss: 6.55138365e-07
Iter: 780 loss: 6.63733e-07
Iter: 781 loss: 6.55154e-07
Iter: 782 loss: 6.54624273e-07
Iter: 783 loss: 6.54896155e-07
Iter: 784 loss: 6.5434557e-07
Iter: 785 loss: 6.53803113e-07
Iter: 786 loss: 6.55446684e-07
Iter: 787 loss: 6.537677e-07
Iter: 788 loss: 6.53199663e-07
Iter: 789 loss: 6.5370125e-07
Iter: 790 loss: 6.52986614e-07
Iter: 791 loss: 6.52373615e-07
Iter: 792 loss: 6.56453608e-07
Iter: 793 loss: 6.52326321e-07
Iter: 794 loss: 6.51908238e-07
Iter: 795 loss: 6.52075528e-07
Iter: 796 loss: 6.51617825e-07
Iter: 797 loss: 6.51030803e-07
Iter: 798 loss: 6.53466145e-07
Iter: 799 loss: 6.50951392e-07
Iter: 800 loss: 6.50566221e-07
Iter: 801 loss: 6.53720463e-07
Iter: 802 loss: 6.5051853e-07
Iter: 803 loss: 6.50146035e-07
Iter: 804 loss: 6.49848346e-07
Iter: 805 loss: 6.49642232e-07
Iter: 806 loss: 6.49284857e-07
Iter: 807 loss: 6.52053359e-07
Iter: 808 loss: 6.49188166e-07
Iter: 809 loss: 6.48955279e-07
Iter: 810 loss: 6.4893959e-07
Iter: 811 loss: 6.48646676e-07
Iter: 812 loss: 6.48521905e-07
Iter: 813 loss: 6.48347054e-07
Iter: 814 loss: 6.48049195e-07
Iter: 815 loss: 6.48112291e-07
Iter: 816 loss: 6.47754121e-07
Iter: 817 loss: 6.47459842e-07
Iter: 818 loss: 6.47280444e-07
Iter: 819 loss: 6.47107242e-07
Iter: 820 loss: 6.46495437e-07
Iter: 821 loss: 6.4846472e-07
Iter: 822 loss: 6.46357137e-07
Iter: 823 loss: 6.45885279e-07
Iter: 824 loss: 6.47785782e-07
Iter: 825 loss: 6.45725891e-07
Iter: 826 loss: 6.45321791e-07
Iter: 827 loss: 6.4662072e-07
Iter: 828 loss: 6.4506844e-07
Iter: 829 loss: 6.44676902e-07
Iter: 830 loss: 6.45464638e-07
Iter: 831 loss: 6.44502848e-07
Iter: 832 loss: 6.44140528e-07
Iter: 833 loss: 6.45109367e-07
Iter: 834 loss: 6.4401911e-07
Iter: 835 loss: 6.4354731e-07
Iter: 836 loss: 6.46696662e-07
Iter: 837 loss: 6.43525e-07
Iter: 838 loss: 6.43250303e-07
Iter: 839 loss: 6.43441467e-07
Iter: 840 loss: 6.4299536e-07
Iter: 841 loss: 6.42699e-07
Iter: 842 loss: 6.46064393e-07
Iter: 843 loss: 6.42683233e-07
Iter: 844 loss: 6.42368263e-07
Iter: 845 loss: 6.4408971e-07
Iter: 846 loss: 6.42302723e-07
Iter: 847 loss: 6.42120142e-07
Iter: 848 loss: 6.42098087e-07
Iter: 849 loss: 6.42009297e-07
Iter: 850 loss: 6.41698705e-07
Iter: 851 loss: 6.41573592e-07
Iter: 852 loss: 6.41439044e-07
Iter: 853 loss: 6.40989356e-07
Iter: 854 loss: 6.41861959e-07
Iter: 855 loss: 6.40855717e-07
Iter: 856 loss: 6.40424105e-07
Iter: 857 loss: 6.43250132e-07
Iter: 858 loss: 6.40436269e-07
Iter: 859 loss: 6.40070539e-07
Iter: 860 loss: 6.40111693e-07
Iter: 861 loss: 6.3969253e-07
Iter: 862 loss: 6.39381426e-07
Iter: 863 loss: 6.4396454e-07
Iter: 864 loss: 6.39385121e-07
Iter: 865 loss: 6.39089706e-07
Iter: 866 loss: 6.38725e-07
Iter: 867 loss: 6.38661902e-07
Iter: 868 loss: 6.38059646e-07
Iter: 869 loss: 6.43517296e-07
Iter: 870 loss: 6.38091478e-07
Iter: 871 loss: 6.37761e-07
Iter: 872 loss: 6.40702581e-07
Iter: 873 loss: 6.37745586e-07
Iter: 874 loss: 6.37525886e-07
Iter: 875 loss: 6.37387075e-07
Iter: 876 loss: 6.37239793e-07
Iter: 877 loss: 6.37180278e-07
Iter: 878 loss: 6.37024584e-07
Iter: 879 loss: 6.36956429e-07
Iter: 880 loss: 6.36664481e-07
Iter: 881 loss: 6.36672894e-07
Iter: 882 loss: 6.36549885e-07
Iter: 883 loss: 6.36738434e-07
Iter: 884 loss: 6.36352752e-07
Iter: 885 loss: 6.36039317e-07
Iter: 886 loss: 6.36159143e-07
Iter: 887 loss: 6.35911192e-07
Iter: 888 loss: 6.35639083e-07
Iter: 889 loss: 6.35890501e-07
Iter: 890 loss: 6.35397555e-07
Iter: 891 loss: 6.34940591e-07
Iter: 892 loss: 6.36804e-07
Iter: 893 loss: 6.34888636e-07
Iter: 894 loss: 6.34613286e-07
Iter: 895 loss: 6.34595e-07
Iter: 896 loss: 6.34381934e-07
Iter: 897 loss: 6.33970387e-07
Iter: 898 loss: 6.37083417e-07
Iter: 899 loss: 6.33870741e-07
Iter: 900 loss: 6.33497393e-07
Iter: 901 loss: 6.34676724e-07
Iter: 902 loss: 6.33422644e-07
Iter: 903 loss: 6.33122852e-07
Iter: 904 loss: 6.33576633e-07
Iter: 905 loss: 6.32945557e-07
Iter: 906 loss: 6.32543788e-07
Iter: 907 loss: 6.34186904e-07
Iter: 908 loss: 6.32358365e-07
Iter: 909 loss: 6.3215532e-07
Iter: 910 loss: 6.32182264e-07
Iter: 911 loss: 6.31969897e-07
Iter: 912 loss: 6.31941589e-07
Iter: 913 loss: 6.31752528e-07
Iter: 914 loss: 6.31519754e-07
Iter: 915 loss: 6.31414593e-07
Iter: 916 loss: 6.31347575e-07
Iter: 917 loss: 6.3093546e-07
Iter: 918 loss: 6.32212846e-07
Iter: 919 loss: 6.30785905e-07
Iter: 920 loss: 6.3043143e-07
Iter: 921 loss: 6.30622139e-07
Iter: 922 loss: 6.3026971e-07
Iter: 923 loss: 6.29851286e-07
Iter: 924 loss: 6.30698878e-07
Iter: 925 loss: 6.29641136e-07
Iter: 926 loss: 6.29300757e-07
Iter: 927 loss: 6.3133831e-07
Iter: 928 loss: 6.29279214e-07
Iter: 929 loss: 6.28844873e-07
Iter: 930 loss: 6.29160638e-07
Iter: 931 loss: 6.28807356e-07
Iter: 932 loss: 6.28333282e-07
Iter: 933 loss: 6.3084849e-07
Iter: 934 loss: 6.28286273e-07
Iter: 935 loss: 6.28114e-07
Iter: 936 loss: 6.28159967e-07
Iter: 937 loss: 6.27893428e-07
Iter: 938 loss: 6.27543955e-07
Iter: 939 loss: 6.31028229e-07
Iter: 940 loss: 6.27571865e-07
Iter: 941 loss: 6.27412874e-07
Iter: 942 loss: 6.29321448e-07
Iter: 943 loss: 6.27342843e-07
Iter: 944 loss: 6.27222e-07
Iter: 945 loss: 6.27481541e-07
Iter: 946 loss: 6.27128486e-07
Iter: 947 loss: 6.2695409e-07
Iter: 948 loss: 6.26615247e-07
Iter: 949 loss: 6.32974832e-07
Iter: 950 loss: 6.26588132e-07
Iter: 951 loss: 6.26344217e-07
Iter: 952 loss: 6.2944946e-07
Iter: 953 loss: 6.26309088e-07
Iter: 954 loss: 6.26190683e-07
Iter: 955 loss: 6.25943755e-07
Iter: 956 loss: 6.25870655e-07
Iter: 957 loss: 6.25539428e-07
Iter: 958 loss: 6.26612405e-07
Iter: 959 loss: 6.25471671e-07
Iter: 960 loss: 6.25088148e-07
Iter: 961 loss: 6.26280496e-07
Iter: 962 loss: 6.25050859e-07
Iter: 963 loss: 6.2468763e-07
Iter: 964 loss: 6.24595771e-07
Iter: 965 loss: 6.24332188e-07
Iter: 966 loss: 6.24094127e-07
Iter: 967 loss: 6.29535577e-07
Iter: 968 loss: 6.24023301e-07
Iter: 969 loss: 6.23757387e-07
Iter: 970 loss: 6.23796439e-07
Iter: 971 loss: 6.23529672e-07
Iter: 972 loss: 6.23092319e-07
Iter: 973 loss: 6.23198673e-07
Iter: 974 loss: 6.22741e-07
Iter: 975 loss: 6.22513653e-07
Iter: 976 loss: 6.22448965e-07
Iter: 977 loss: 6.22248194e-07
Iter: 978 loss: 6.25100313e-07
Iter: 979 loss: 6.22252969e-07
Iter: 980 loss: 6.22125413e-07
Iter: 981 loss: 6.21751781e-07
Iter: 982 loss: 6.25311827e-07
Iter: 983 loss: 6.21752065e-07
Iter: 984 loss: 6.21301638e-07
Iter: 985 loss: 6.24980089e-07
Iter: 986 loss: 6.21352456e-07
Iter: 987 loss: 6.21109848e-07
Iter: 988 loss: 6.21098252e-07
Iter: 989 loss: 6.20914307e-07
Iter: 990 loss: 6.20586e-07
Iter: 991 loss: 6.21154e-07
Iter: 992 loss: 6.20448e-07
Iter: 993 loss: 6.20104515e-07
Iter: 994 loss: 6.20334788e-07
Iter: 995 loss: 6.19861453e-07
Iter: 996 loss: 6.19450077e-07
Iter: 997 loss: 6.20446485e-07
Iter: 998 loss: 6.19257605e-07
Iter: 999 loss: 6.18750903e-07
Iter: 1000 loss: 6.21351205e-07
Iter: 1001 loss: 6.18744195e-07
Iter: 1002 loss: 6.18383183e-07
Iter: 1003 loss: 6.18826448e-07
Iter: 1004 loss: 6.18226522e-07
Iter: 1005 loss: 6.17776834e-07
Iter: 1006 loss: 6.1876608e-07
Iter: 1007 loss: 6.17654393e-07
Iter: 1008 loss: 6.17195951e-07
Iter: 1009 loss: 6.18692866e-07
Iter: 1010 loss: 6.17148089e-07
Iter: 1011 loss: 6.16747798e-07
Iter: 1012 loss: 6.16752e-07
Iter: 1013 loss: 6.16489672e-07
Iter: 1014 loss: 6.16519173e-07
Iter: 1015 loss: 6.16275599e-07
Iter: 1016 loss: 6.16085e-07
Iter: 1017 loss: 6.16191301e-07
Iter: 1018 loss: 6.16039e-07
Iter: 1019 loss: 6.158524e-07
Iter: 1020 loss: 6.15368492e-07
Iter: 1021 loss: 6.20128731e-07
Iter: 1022 loss: 6.15318413e-07
Iter: 1023 loss: 6.14949329e-07
Iter: 1024 loss: 6.19822856e-07
Iter: 1025 loss: 6.14853e-07
Iter: 1026 loss: 6.14564328e-07
Iter: 1027 loss: 6.15764122e-07
Iter: 1028 loss: 6.1449316e-07
Iter: 1029 loss: 6.14212581e-07
Iter: 1030 loss: 6.13756129e-07
Iter: 1031 loss: 6.13719521e-07
Iter: 1032 loss: 6.13351176e-07
Iter: 1033 loss: 6.18411036e-07
Iter: 1034 loss: 6.13323664e-07
Iter: 1035 loss: 6.1306423e-07
Iter: 1036 loss: 6.12843223e-07
Iter: 1037 loss: 6.12731412e-07
Iter: 1038 loss: 6.12194412e-07
Iter: 1039 loss: 6.13858901e-07
Iter: 1040 loss: 6.12112672e-07
Iter: 1041 loss: 6.11713062e-07
Iter: 1042 loss: 6.14118562e-07
Iter: 1043 loss: 6.11726e-07
Iter: 1044 loss: 6.11373252e-07
Iter: 1045 loss: 6.11153382e-07
Iter: 1046 loss: 6.11067e-07
Iter: 1047 loss: 6.10574034e-07
Iter: 1048 loss: 6.10646225e-07
Iter: 1049 loss: 6.10517418e-07
Iter: 1050 loss: 6.10524353e-07
Iter: 1051 loss: 6.10302209e-07
Iter: 1052 loss: 6.1000344e-07
Iter: 1053 loss: 6.10018219e-07
Iter: 1054 loss: 6.09652716e-07
Iter: 1055 loss: 6.09629353e-07
Iter: 1056 loss: 6.09401241e-07
Iter: 1057 loss: 6.0901516e-07
Iter: 1058 loss: 6.10071254e-07
Iter: 1059 loss: 6.0890477e-07
Iter: 1060 loss: 6.08607877e-07
Iter: 1061 loss: 6.0975168e-07
Iter: 1062 loss: 6.08413757e-07
Iter: 1063 loss: 6.08077e-07
Iter: 1064 loss: 6.0901084e-07
Iter: 1065 loss: 6.07941161e-07
Iter: 1066 loss: 6.07654329e-07
Iter: 1067 loss: 6.08122e-07
Iter: 1068 loss: 6.07486868e-07
Iter: 1069 loss: 6.07121081e-07
Iter: 1070 loss: 6.07038544e-07
Iter: 1071 loss: 6.06845674e-07
Iter: 1072 loss: 6.06421224e-07
Iter: 1073 loss: 6.10945563e-07
Iter: 1074 loss: 6.06371316e-07
Iter: 1075 loss: 6.06147694e-07
Iter: 1076 loss: 6.0652809e-07
Iter: 1077 loss: 6.059729e-07
Iter: 1078 loss: 6.05601144e-07
Iter: 1079 loss: 6.06010929e-07
Iter: 1080 loss: 6.05485297e-07
Iter: 1081 loss: 6.0511627e-07
Iter: 1082 loss: 6.08493224e-07
Iter: 1083 loss: 6.05074e-07
Iter: 1084 loss: 6.04941363e-07
Iter: 1085 loss: 6.06381377e-07
Iter: 1086 loss: 6.04875368e-07
Iter: 1087 loss: 6.04727461e-07
Iter: 1088 loss: 6.04814602e-07
Iter: 1089 loss: 6.04505885e-07
Iter: 1090 loss: 6.04227068e-07
Iter: 1091 loss: 6.04152e-07
Iter: 1092 loss: 6.04061256e-07
Iter: 1093 loss: 6.03804e-07
Iter: 1094 loss: 6.04433239e-07
Iter: 1095 loss: 6.03677108e-07
Iter: 1096 loss: 6.03472415e-07
Iter: 1097 loss: 6.03835133e-07
Iter: 1098 loss: 6.03359922e-07
Iter: 1099 loss: 6.03137835e-07
Iter: 1100 loss: 6.05396224e-07
Iter: 1101 loss: 6.03059448e-07
Iter: 1102 loss: 6.02966963e-07
Iter: 1103 loss: 6.02818545e-07
Iter: 1104 loss: 6.02837417e-07
Iter: 1105 loss: 6.02479759e-07
Iter: 1106 loss: 6.03007038e-07
Iter: 1107 loss: 6.02309683e-07
Iter: 1108 loss: 6.02020577e-07
Iter: 1109 loss: 6.0310856e-07
Iter: 1110 loss: 6.02014381e-07
Iter: 1111 loss: 6.01625e-07
Iter: 1112 loss: 6.01676106e-07
Iter: 1113 loss: 6.0136739e-07
Iter: 1114 loss: 6.00961357e-07
Iter: 1115 loss: 6.03467242e-07
Iter: 1116 loss: 6.00953058e-07
Iter: 1117 loss: 6.00630074e-07
Iter: 1118 loss: 6.01087152e-07
Iter: 1119 loss: 6.00456531e-07
Iter: 1120 loss: 6.00166231e-07
Iter: 1121 loss: 6.04055e-07
Iter: 1122 loss: 6.00182261e-07
Iter: 1123 loss: 5.99958071e-07
Iter: 1124 loss: 6.02024215e-07
Iter: 1125 loss: 5.99925386e-07
Iter: 1126 loss: 5.99845407e-07
Iter: 1127 loss: 5.9964259e-07
Iter: 1128 loss: 6.02548084e-07
Iter: 1129 loss: 5.99621e-07
Iter: 1130 loss: 5.99326768e-07
Iter: 1131 loss: 5.99418854e-07
Iter: 1132 loss: 5.98992926e-07
Iter: 1133 loss: 5.98598774e-07
Iter: 1134 loss: 6.01443048e-07
Iter: 1135 loss: 5.98614747e-07
Iter: 1136 loss: 5.98350482e-07
Iter: 1137 loss: 5.99494797e-07
Iter: 1138 loss: 5.98221561e-07
Iter: 1139 loss: 5.9797236e-07
Iter: 1140 loss: 5.97597307e-07
Iter: 1141 loss: 5.97520398e-07
Iter: 1142 loss: 5.97210715e-07
Iter: 1143 loss: 6.02347313e-07
Iter: 1144 loss: 5.971267e-07
Iter: 1145 loss: 5.96919392e-07
Iter: 1146 loss: 5.96890118e-07
Iter: 1147 loss: 5.96718e-07
Iter: 1148 loss: 5.96280643e-07
Iter: 1149 loss: 5.96988343e-07
Iter: 1150 loss: 5.9618651e-07
Iter: 1151 loss: 5.95843744e-07
Iter: 1152 loss: 5.98735937e-07
Iter: 1153 loss: 5.95769507e-07
Iter: 1154 loss: 5.95528377e-07
Iter: 1155 loss: 5.96077598e-07
Iter: 1156 loss: 5.95383653e-07
Iter: 1157 loss: 5.9510586e-07
Iter: 1158 loss: 5.98969109e-07
Iter: 1159 loss: 5.95121094e-07
Iter: 1160 loss: 5.94866265e-07
Iter: 1161 loss: 5.94747576e-07
Iter: 1162 loss: 5.94643e-07
Iter: 1163 loss: 5.94417372e-07
Iter: 1164 loss: 5.94822154e-07
Iter: 1165 loss: 5.94322614e-07
Iter: 1166 loss: 5.94072731e-07
Iter: 1167 loss: 5.93723655e-07
Iter: 1168 loss: 5.93694836e-07
Iter: 1169 loss: 5.93165737e-07
Iter: 1170 loss: 5.97560472e-07
Iter: 1171 loss: 5.93195409e-07
Iter: 1172 loss: 5.92957e-07
Iter: 1173 loss: 5.95109839e-07
Iter: 1174 loss: 5.92949448e-07
Iter: 1175 loss: 5.92758e-07
Iter: 1176 loss: 5.92303081e-07
Iter: 1177 loss: 6.00592955e-07
Iter: 1178 loss: 5.9225863e-07
Iter: 1179 loss: 5.91944399e-07
Iter: 1180 loss: 5.91977368e-07
Iter: 1181 loss: 5.91701451e-07
Iter: 1182 loss: 5.91497326e-07
Iter: 1183 loss: 5.91465664e-07
Iter: 1184 loss: 5.90941738e-07
Iter: 1185 loss: 5.93531183e-07
Iter: 1186 loss: 5.90955779e-07
Iter: 1187 loss: 5.90726074e-07
Iter: 1188 loss: 5.93677896e-07
Iter: 1189 loss: 5.90723175e-07
Iter: 1190 loss: 5.90583454e-07
Iter: 1191 loss: 5.91955541e-07
Iter: 1192 loss: 5.90609375e-07
Iter: 1193 loss: 5.90422076e-07
Iter: 1194 loss: 5.90301e-07
Iter: 1195 loss: 5.90246827e-07
Iter: 1196 loss: 5.9008903e-07
Iter: 1197 loss: 5.90192144e-07
Iter: 1198 loss: 5.89898207e-07
Iter: 1199 loss: 5.89742626e-07
Iter: 1200 loss: 5.89691126e-07
Iter: 1201 loss: 5.89528099e-07
Iter: 1202 loss: 5.89122465e-07
Iter: 1203 loss: 5.89711931e-07
Iter: 1204 loss: 5.8899775e-07
Iter: 1205 loss: 5.88696935e-07
Iter: 1206 loss: 5.88690284e-07
Iter: 1207 loss: 5.88613602e-07
Iter: 1208 loss: 5.88588875e-07
Iter: 1209 loss: 5.88407772e-07
Iter: 1210 loss: 5.88033402e-07
Iter: 1211 loss: 5.88226953e-07
Iter: 1212 loss: 5.87902036e-07
Iter: 1213 loss: 5.87616682e-07
Iter: 1214 loss: 5.88979731e-07
Iter: 1215 loss: 5.87555803e-07
Iter: 1216 loss: 5.87293471e-07
Iter: 1217 loss: 5.87207751e-07
Iter: 1218 loss: 5.86984072e-07
Iter: 1219 loss: 5.86697752e-07
Iter: 1220 loss: 5.88703188e-07
Iter: 1221 loss: 5.86597821e-07
Iter: 1222 loss: 5.86457816e-07
Iter: 1223 loss: 5.86431156e-07
Iter: 1224 loss: 5.86257158e-07
Iter: 1225 loss: 5.86839292e-07
Iter: 1226 loss: 5.86226463e-07
Iter: 1227 loss: 5.86095155e-07
Iter: 1228 loss: 5.85993064e-07
Iter: 1229 loss: 5.85982605e-07
Iter: 1230 loss: 5.8572806e-07
Iter: 1231 loss: 5.86092085e-07
Iter: 1232 loss: 5.85728458e-07
Iter: 1233 loss: 5.85487101e-07
Iter: 1234 loss: 5.85494e-07
Iter: 1235 loss: 5.85337716e-07
Iter: 1236 loss: 5.85043e-07
Iter: 1237 loss: 5.85961686e-07
Iter: 1238 loss: 5.84929126e-07
Iter: 1239 loss: 5.84633938e-07
Iter: 1240 loss: 5.84624388e-07
Iter: 1241 loss: 5.84401505e-07
Iter: 1242 loss: 5.83932376e-07
Iter: 1243 loss: 5.85200098e-07
Iter: 1244 loss: 5.83810106e-07
Iter: 1245 loss: 5.83486383e-07
Iter: 1246 loss: 5.83499173e-07
Iter: 1247 loss: 5.83344274e-07
Iter: 1248 loss: 5.82890493e-07
Iter: 1249 loss: 5.88421244e-07
Iter: 1250 loss: 5.82828818e-07
Iter: 1251 loss: 5.82421762e-07
Iter: 1252 loss: 5.87805516e-07
Iter: 1253 loss: 5.82420114e-07
Iter: 1254 loss: 5.82137545e-07
Iter: 1255 loss: 5.82074108e-07
Iter: 1256 loss: 5.81841732e-07
Iter: 1257 loss: 5.8150539e-07
Iter: 1258 loss: 5.81441157e-07
Iter: 1259 loss: 5.81158304e-07
Iter: 1260 loss: 5.83627639e-07
Iter: 1261 loss: 5.81128404e-07
Iter: 1262 loss: 5.81034101e-07
Iter: 1263 loss: 5.80731296e-07
Iter: 1264 loss: 5.82163239e-07
Iter: 1265 loss: 5.80659957e-07
Iter: 1266 loss: 5.80257336e-07
Iter: 1267 loss: 5.82946598e-07
Iter: 1268 loss: 5.802126e-07
Iter: 1269 loss: 5.79887342e-07
Iter: 1270 loss: 5.80668484e-07
Iter: 1271 loss: 5.79693733e-07
Iter: 1272 loss: 5.79461641e-07
Iter: 1273 loss: 5.79997e-07
Iter: 1274 loss: 5.79362e-07
Iter: 1275 loss: 5.78963125e-07
Iter: 1276 loss: 5.80910751e-07
Iter: 1277 loss: 5.78935499e-07
Iter: 1278 loss: 5.78742288e-07
Iter: 1279 loss: 5.7983533e-07
Iter: 1280 loss: 5.78682261e-07
Iter: 1281 loss: 5.78478193e-07
Iter: 1282 loss: 5.78436413e-07
Iter: 1283 loss: 5.78334038e-07
Iter: 1284 loss: 5.78032655e-07
Iter: 1285 loss: 5.80632786e-07
Iter: 1286 loss: 5.78003153e-07
Iter: 1287 loss: 5.77791695e-07
Iter: 1288 loss: 5.77832338e-07
Iter: 1289 loss: 5.77623155e-07
Iter: 1290 loss: 5.77441597e-07
Iter: 1291 loss: 5.77376227e-07
Iter: 1292 loss: 5.77236278e-07
Iter: 1293 loss: 5.77084393e-07
Iter: 1294 loss: 5.77050912e-07
Iter: 1295 loss: 5.76988725e-07
Iter: 1296 loss: 5.76802734e-07
Iter: 1297 loss: 5.80543599e-07
Iter: 1298 loss: 5.7676607e-07
Iter: 1299 loss: 5.76617879e-07
Iter: 1300 loss: 5.76359469e-07
Iter: 1301 loss: 5.76302284e-07
Iter: 1302 loss: 5.76008404e-07
Iter: 1303 loss: 5.78202446e-07
Iter: 1304 loss: 5.75994932e-07
Iter: 1305 loss: 5.75798708e-07
Iter: 1306 loss: 5.76205366e-07
Iter: 1307 loss: 5.75650802e-07
Iter: 1308 loss: 5.75414219e-07
Iter: 1309 loss: 5.76009541e-07
Iter: 1310 loss: 5.75254489e-07
Iter: 1311 loss: 5.75034505e-07
Iter: 1312 loss: 5.76973889e-07
Iter: 1313 loss: 5.75046215e-07
Iter: 1314 loss: 5.74837827e-07
Iter: 1315 loss: 5.74741648e-07
Iter: 1316 loss: 5.74678381e-07
Iter: 1317 loss: 5.74394335e-07
Iter: 1318 loss: 5.74759156e-07
Iter: 1319 loss: 5.74196747e-07
Iter: 1320 loss: 5.7399609e-07
Iter: 1321 loss: 5.7630831e-07
Iter: 1322 loss: 5.74019111e-07
Iter: 1323 loss: 5.73774287e-07
Iter: 1324 loss: 5.73443344e-07
Iter: 1325 loss: 5.73423051e-07
Iter: 1326 loss: 5.73657e-07
Iter: 1327 loss: 5.73341197e-07
Iter: 1328 loss: 5.73209604e-07
Iter: 1329 loss: 5.73056695e-07
Iter: 1330 loss: 5.73030661e-07
Iter: 1331 loss: 5.72959607e-07
Iter: 1332 loss: 5.72815452e-07
Iter: 1333 loss: 5.72706085e-07
Iter: 1334 loss: 5.72455804e-07
Iter: 1335 loss: 5.72914814e-07
Iter: 1336 loss: 5.72298688e-07
Iter: 1337 loss: 5.71986504e-07
Iter: 1338 loss: 5.72456543e-07
Iter: 1339 loss: 5.71814041e-07
Iter: 1340 loss: 5.71523799e-07
Iter: 1341 loss: 5.72680165e-07
Iter: 1342 loss: 5.71485884e-07
Iter: 1343 loss: 5.71201156e-07
Iter: 1344 loss: 5.71715191e-07
Iter: 1345 loss: 5.71048645e-07
Iter: 1346 loss: 5.70803763e-07
Iter: 1347 loss: 5.70890165e-07
Iter: 1348 loss: 5.70456109e-07
Iter: 1349 loss: 5.70144039e-07
Iter: 1350 loss: 5.72886393e-07
Iter: 1351 loss: 5.70166549e-07
Iter: 1352 loss: 5.69834413e-07
Iter: 1353 loss: 5.71226167e-07
Iter: 1354 loss: 5.69777853e-07
Iter: 1355 loss: 5.69538315e-07
Iter: 1356 loss: 5.69961742e-07
Iter: 1357 loss: 5.69446286e-07
Iter: 1358 loss: 5.69159113e-07
Iter: 1359 loss: 5.69625342e-07
Iter: 1360 loss: 5.68930545e-07
Iter: 1361 loss: 5.68688165e-07
Iter: 1362 loss: 5.70027e-07
Iter: 1363 loss: 5.68609892e-07
Iter: 1364 loss: 5.68513201e-07
Iter: 1365 loss: 5.68517464e-07
Iter: 1366 loss: 5.68290659e-07
Iter: 1367 loss: 5.68091707e-07
Iter: 1368 loss: 5.68068856e-07
Iter: 1369 loss: 5.67834434e-07
Iter: 1370 loss: 5.68623e-07
Iter: 1371 loss: 5.67786856e-07
Iter: 1372 loss: 5.67586937e-07
Iter: 1373 loss: 5.67199834e-07
Iter: 1374 loss: 5.75777733e-07
Iter: 1375 loss: 5.6720279e-07
Iter: 1376 loss: 5.66801759e-07
Iter: 1377 loss: 5.71181602e-07
Iter: 1378 loss: 5.66816311e-07
Iter: 1379 loss: 5.66460244e-07
Iter: 1380 loss: 5.66822223e-07
Iter: 1381 loss: 5.6636793e-07
Iter: 1382 loss: 5.66041649e-07
Iter: 1383 loss: 5.66087408e-07
Iter: 1384 loss: 5.65750327e-07
Iter: 1385 loss: 5.65463665e-07
Iter: 1386 loss: 5.68832206e-07
Iter: 1387 loss: 5.65396306e-07
Iter: 1388 loss: 5.65163759e-07
Iter: 1389 loss: 5.66034601e-07
Iter: 1390 loss: 5.65026539e-07
Iter: 1391 loss: 5.64739e-07
Iter: 1392 loss: 5.65120899e-07
Iter: 1393 loss: 5.6456156e-07
Iter: 1394 loss: 5.64251195e-07
Iter: 1395 loss: 5.65478899e-07
Iter: 1396 loss: 5.64189406e-07
Iter: 1397 loss: 5.63961862e-07
Iter: 1398 loss: 5.63952142e-07
Iter: 1399 loss: 5.63728236e-07
Iter: 1400 loss: 5.63995968e-07
Iter: 1401 loss: 5.63622848e-07
Iter: 1402 loss: 5.63466813e-07
Iter: 1403 loss: 5.63509559e-07
Iter: 1404 loss: 5.63326239e-07
Iter: 1405 loss: 5.63078743e-07
Iter: 1406 loss: 5.63078572e-07
Iter: 1407 loss: 5.62864727e-07
Iter: 1408 loss: 5.62527816e-07
Iter: 1409 loss: 5.63397748e-07
Iter: 1410 loss: 5.62411515e-07
Iter: 1411 loss: 5.62165667e-07
Iter: 1412 loss: 5.62788841e-07
Iter: 1413 loss: 5.6203e-07
Iter: 1414 loss: 5.61644e-07
Iter: 1415 loss: 5.62109449e-07
Iter: 1416 loss: 5.6144421e-07
Iter: 1417 loss: 5.61181423e-07
Iter: 1418 loss: 5.62220521e-07
Iter: 1419 loss: 5.61026411e-07
Iter: 1420 loss: 5.60756348e-07
Iter: 1421 loss: 5.6142045e-07
Iter: 1422 loss: 5.60645731e-07
Iter: 1423 loss: 5.603722e-07
Iter: 1424 loss: 5.60376805e-07
Iter: 1425 loss: 5.60155797e-07
Iter: 1426 loss: 5.59982084e-07
Iter: 1427 loss: 5.59936e-07
Iter: 1428 loss: 5.59799901e-07
Iter: 1429 loss: 5.59726345e-07
Iter: 1430 loss: 5.59549449e-07
Iter: 1431 loss: 5.59938712e-07
Iter: 1432 loss: 5.59528416e-07
Iter: 1433 loss: 5.59290925e-07
Iter: 1434 loss: 5.59205375e-07
Iter: 1435 loss: 5.59225441e-07
Iter: 1436 loss: 5.589186e-07
Iter: 1437 loss: 5.58697252e-07
Iter: 1438 loss: 5.58682132e-07
Iter: 1439 loss: 5.582109e-07
Iter: 1440 loss: 5.6051465e-07
Iter: 1441 loss: 5.58146496e-07
Iter: 1442 loss: 5.57897636e-07
Iter: 1443 loss: 5.58149452e-07
Iter: 1444 loss: 5.57770477e-07
Iter: 1445 loss: 5.57363137e-07
Iter: 1446 loss: 5.58201577e-07
Iter: 1447 loss: 5.57231488e-07
Iter: 1448 loss: 5.56880138e-07
Iter: 1449 loss: 5.59154898e-07
Iter: 1450 loss: 5.56879e-07
Iter: 1451 loss: 5.56610473e-07
Iter: 1452 loss: 5.56081659e-07
Iter: 1453 loss: 5.68458859e-07
Iter: 1454 loss: 5.56073246e-07
Iter: 1455 loss: 5.55630265e-07
Iter: 1456 loss: 5.55649592e-07
Iter: 1457 loss: 5.5529074e-07
Iter: 1458 loss: 5.56284704e-07
Iter: 1459 loss: 5.5520286e-07
Iter: 1460 loss: 5.54986968e-07
Iter: 1461 loss: 5.5538186e-07
Iter: 1462 loss: 5.548236e-07
Iter: 1463 loss: 5.5456826e-07
Iter: 1464 loss: 5.54554731e-07
Iter: 1465 loss: 5.54407961e-07
Iter: 1466 loss: 5.54262385e-07
Iter: 1467 loss: 5.54210885e-07
Iter: 1468 loss: 5.54027508e-07
Iter: 1469 loss: 5.54302403e-07
Iter: 1470 loss: 5.53918767e-07
Iter: 1471 loss: 5.53620907e-07
Iter: 1472 loss: 5.53664336e-07
Iter: 1473 loss: 5.53463622e-07
Iter: 1474 loss: 5.52984545e-07
Iter: 1475 loss: 5.54819735e-07
Iter: 1476 loss: 5.52915708e-07
Iter: 1477 loss: 5.52564188e-07
Iter: 1478 loss: 5.52684185e-07
Iter: 1479 loss: 5.52366316e-07
Iter: 1480 loss: 5.52075107e-07
Iter: 1481 loss: 5.5536691e-07
Iter: 1482 loss: 5.51973812e-07
Iter: 1483 loss: 5.51722792e-07
Iter: 1484 loss: 5.5204373e-07
Iter: 1485 loss: 5.51560959e-07
Iter: 1486 loss: 5.51214555e-07
Iter: 1487 loss: 5.51457e-07
Iter: 1488 loss: 5.50989853e-07
Iter: 1489 loss: 5.50653624e-07
Iter: 1490 loss: 5.50681875e-07
Iter: 1491 loss: 5.50406e-07
Iter: 1492 loss: 5.50343e-07
Iter: 1493 loss: 5.50175571e-07
Iter: 1494 loss: 5.50063078e-07
Iter: 1495 loss: 5.50036248e-07
Iter: 1496 loss: 5.4987413e-07
Iter: 1497 loss: 5.4978409e-07
Iter: 1498 loss: 5.49736683e-07
Iter: 1499 loss: 5.49548702e-07
Iter: 1500 loss: 5.49494303e-07
Iter: 1501 loss: 5.49394883e-07
Iter: 1502 loss: 5.49069057e-07
Iter: 1503 loss: 5.5042392e-07
Iter: 1504 loss: 5.48981e-07
Iter: 1505 loss: 5.48754144e-07
Iter: 1506 loss: 5.4905945e-07
Iter: 1507 loss: 5.48542289e-07
Iter: 1508 loss: 5.48279e-07
Iter: 1509 loss: 5.4874215e-07
Iter: 1510 loss: 5.48127616e-07
Iter: 1511 loss: 5.47797754e-07
Iter: 1512 loss: 5.48213109e-07
Iter: 1513 loss: 5.47607783e-07
Iter: 1514 loss: 5.4727235e-07
Iter: 1515 loss: 5.49274034e-07
Iter: 1516 loss: 5.47170259e-07
Iter: 1517 loss: 5.46893773e-07
Iter: 1518 loss: 5.47495e-07
Iter: 1519 loss: 5.46801061e-07
Iter: 1520 loss: 5.46436809e-07
Iter: 1521 loss: 5.47285424e-07
Iter: 1522 loss: 5.46404351e-07
Iter: 1523 loss: 5.46139177e-07
Iter: 1524 loss: 5.48786034e-07
Iter: 1525 loss: 5.46226829e-07
Iter: 1526 loss: 5.46072272e-07
Iter: 1527 loss: 5.47081868e-07
Iter: 1528 loss: 5.45977e-07
Iter: 1529 loss: 5.45859223e-07
Iter: 1530 loss: 5.45815908e-07
Iter: 1531 loss: 5.45767534e-07
Iter: 1532 loss: 5.45478315e-07
Iter: 1533 loss: 5.45301418e-07
Iter: 1534 loss: 5.45258786e-07
Iter: 1535 loss: 5.44998841e-07
Iter: 1536 loss: 5.45867522e-07
Iter: 1537 loss: 5.44898398e-07
Iter: 1538 loss: 5.44637601e-07
Iter: 1539 loss: 5.45156126e-07
Iter: 1540 loss: 5.44398517e-07
Iter: 1541 loss: 5.44085e-07
Iter: 1542 loss: 5.45300679e-07
Iter: 1543 loss: 5.4396105e-07
Iter: 1544 loss: 5.43709461e-07
Iter: 1545 loss: 5.44256e-07
Iter: 1546 loss: 5.43621184e-07
Iter: 1547 loss: 5.43302519e-07
Iter: 1548 loss: 5.43222825e-07
Iter: 1549 loss: 5.43051158e-07
Iter: 1550 loss: 5.42613236e-07
Iter: 1551 loss: 5.46736317e-07
Iter: 1552 loss: 5.42621251e-07
Iter: 1553 loss: 5.42330554e-07
Iter: 1554 loss: 5.42238865e-07
Iter: 1555 loss: 5.4206663e-07
Iter: 1556 loss: 5.41745408e-07
Iter: 1557 loss: 5.46004173e-07
Iter: 1558 loss: 5.41696693e-07
Iter: 1559 loss: 5.41421059e-07
Iter: 1560 loss: 5.42086127e-07
Iter: 1561 loss: 5.41367967e-07
Iter: 1562 loss: 5.41145198e-07
Iter: 1563 loss: 5.41130305e-07
Iter: 1564 loss: 5.41026338e-07
Iter: 1565 loss: 5.40760254e-07
Iter: 1566 loss: 5.42882503e-07
Iter: 1567 loss: 5.40710232e-07
Iter: 1568 loss: 5.40429312e-07
Iter: 1569 loss: 5.41315e-07
Iter: 1570 loss: 5.40337965e-07
Iter: 1571 loss: 5.40085e-07
Iter: 1572 loss: 5.40794872e-07
Iter: 1573 loss: 5.40066424e-07
Iter: 1574 loss: 5.39775556e-07
Iter: 1575 loss: 5.39633618e-07
Iter: 1576 loss: 5.39495773e-07
Iter: 1577 loss: 5.39224573e-07
Iter: 1578 loss: 5.41703059e-07
Iter: 1579 loss: 5.39153575e-07
Iter: 1580 loss: 5.38941151e-07
Iter: 1581 loss: 5.38854124e-07
Iter: 1582 loss: 5.38733559e-07
Iter: 1583 loss: 5.38497602e-07
Iter: 1584 loss: 5.38763857e-07
Iter: 1585 loss: 5.38294557e-07
Iter: 1586 loss: 5.37967423e-07
Iter: 1587 loss: 5.39570863e-07
Iter: 1588 loss: 5.38006134e-07
Iter: 1589 loss: 5.37648873e-07
Iter: 1590 loss: 5.38107372e-07
Iter: 1591 loss: 5.3748e-07
Iter: 1592 loss: 5.37202766e-07
Iter: 1593 loss: 5.40506505e-07
Iter: 1594 loss: 5.37237838e-07
Iter: 1595 loss: 5.3713336e-07
Iter: 1596 loss: 5.37129722e-07
Iter: 1597 loss: 5.36973516e-07
Iter: 1598 loss: 5.36632456e-07
Iter: 1599 loss: 5.41713632e-07
Iter: 1600 loss: 5.36637685e-07
Iter: 1601 loss: 5.36446635e-07
Iter: 1602 loss: 5.36808329e-07
Iter: 1603 loss: 5.36337097e-07
Iter: 1604 loss: 5.36129505e-07
Iter: 1605 loss: 5.37002848e-07
Iter: 1606 loss: 5.36048049e-07
Iter: 1607 loss: 5.35759227e-07
Iter: 1608 loss: 5.3525082e-07
Iter: 1609 loss: 5.35263325e-07
Iter: 1610 loss: 5.3490885e-07
Iter: 1611 loss: 5.37321966e-07
Iter: 1612 loss: 5.34842684e-07
Iter: 1613 loss: 5.34507365e-07
Iter: 1614 loss: 5.34846436e-07
Iter: 1615 loss: 5.3426453e-07
Iter: 1616 loss: 5.33874299e-07
Iter: 1617 loss: 5.34860533e-07
Iter: 1618 loss: 5.33794321e-07
Iter: 1619 loss: 5.33470541e-07
Iter: 1620 loss: 5.33600598e-07
Iter: 1621 loss: 5.33281764e-07
Iter: 1622 loss: 5.33001753e-07
Iter: 1623 loss: 5.34812102e-07
Iter: 1624 loss: 5.32907e-07
Iter: 1625 loss: 5.3265552e-07
Iter: 1626 loss: 5.33017328e-07
Iter: 1627 loss: 5.3252927e-07
Iter: 1628 loss: 5.32220611e-07
Iter: 1629 loss: 5.32178944e-07
Iter: 1630 loss: 5.31941964e-07
Iter: 1631 loss: 5.3180969e-07
Iter: 1632 loss: 5.31783428e-07
Iter: 1633 loss: 5.3163825e-07
Iter: 1634 loss: 5.33181094e-07
Iter: 1635 loss: 5.31643934e-07
Iter: 1636 loss: 5.31586238e-07
Iter: 1637 loss: 5.31379726e-07
Iter: 1638 loss: 5.33102479e-07
Iter: 1639 loss: 5.31294518e-07
Iter: 1640 loss: 5.31035425e-07
Iter: 1641 loss: 5.32234878e-07
Iter: 1642 loss: 5.31004957e-07
Iter: 1643 loss: 5.30791851e-07
Iter: 1644 loss: 5.31996932e-07
Iter: 1645 loss: 5.30825787e-07
Iter: 1646 loss: 5.30608304e-07
Iter: 1647 loss: 5.30366947e-07
Iter: 1648 loss: 5.30363e-07
Iter: 1649 loss: 5.3004419e-07
Iter: 1650 loss: 5.32345268e-07
Iter: 1651 loss: 5.30065279e-07
Iter: 1652 loss: 5.29865815e-07
Iter: 1653 loss: 5.30495356e-07
Iter: 1654 loss: 5.2983853e-07
Iter: 1655 loss: 5.29635599e-07
Iter: 1656 loss: 5.29651118e-07
Iter: 1657 loss: 5.29453814e-07
Iter: 1658 loss: 5.29278225e-07
Iter: 1659 loss: 5.30576074e-07
Iter: 1660 loss: 5.29264696e-07
Iter: 1661 loss: 5.29025897e-07
Iter: 1662 loss: 5.29389865e-07
Iter: 1663 loss: 5.28943531e-07
Iter: 1664 loss: 5.28636747e-07
Iter: 1665 loss: 5.299446e-07
Iter: 1666 loss: 5.2860338e-07
Iter: 1667 loss: 5.2852522e-07
Iter: 1668 loss: 5.28527949e-07
Iter: 1669 loss: 5.28394e-07
Iter: 1670 loss: 5.28342412e-07
Iter: 1671 loss: 5.2828193e-07
Iter: 1672 loss: 5.28165117e-07
Iter: 1673 loss: 5.27894258e-07
Iter: 1674 loss: 5.32648357e-07
Iter: 1675 loss: 5.27825478e-07
Iter: 1676 loss: 5.27646762e-07
Iter: 1677 loss: 5.27649661e-07
Iter: 1678 loss: 5.27476857e-07
Iter: 1679 loss: 5.27498344e-07
Iter: 1680 loss: 5.27314853e-07
Iter: 1681 loss: 5.27055477e-07
Iter: 1682 loss: 5.27215093e-07
Iter: 1683 loss: 5.2691297e-07
Iter: 1684 loss: 5.26675763e-07
Iter: 1685 loss: 5.2802767e-07
Iter: 1686 loss: 5.26644271e-07
Iter: 1687 loss: 5.26450492e-07
Iter: 1688 loss: 5.27022053e-07
Iter: 1689 loss: 5.26355791e-07
Iter: 1690 loss: 5.26166957e-07
Iter: 1691 loss: 5.26410645e-07
Iter: 1692 loss: 5.26114434e-07
Iter: 1693 loss: 5.25843348e-07
Iter: 1694 loss: 5.25812652e-07
Iter: 1695 loss: 5.25657924e-07
Iter: 1696 loss: 5.25357791e-07
Iter: 1697 loss: 5.29094564e-07
Iter: 1698 loss: 5.25324651e-07
Iter: 1699 loss: 5.25173277e-07
Iter: 1700 loss: 5.26093231e-07
Iter: 1701 loss: 5.25177654e-07
Iter: 1702 loss: 5.24974212e-07
Iter: 1703 loss: 5.26213455e-07
Iter: 1704 loss: 5.25000132e-07
Iter: 1705 loss: 5.24946756e-07
Iter: 1706 loss: 5.24737686e-07
Iter: 1707 loss: 5.29051647e-07
Iter: 1708 loss: 5.2472376e-07
Iter: 1709 loss: 5.24514292e-07
Iter: 1710 loss: 5.25406051e-07
Iter: 1711 loss: 5.24468135e-07
Iter: 1712 loss: 5.24295672e-07
Iter: 1713 loss: 5.2540463e-07
Iter: 1714 loss: 5.242876e-07
Iter: 1715 loss: 5.24101551e-07
Iter: 1716 loss: 5.23874633e-07
Iter: 1717 loss: 5.31090905e-07
Iter: 1718 loss: 5.23830352e-07
Iter: 1719 loss: 5.23633787e-07
Iter: 1720 loss: 5.25651899e-07
Iter: 1721 loss: 5.23618951e-07
Iter: 1722 loss: 5.23403742e-07
Iter: 1723 loss: 5.23248957e-07
Iter: 1724 loss: 5.23166e-07
Iter: 1725 loss: 5.22959965e-07
Iter: 1726 loss: 5.22964342e-07
Iter: 1727 loss: 5.22854634e-07
Iter: 1728 loss: 5.22678249e-07
Iter: 1729 loss: 5.22690698e-07
Iter: 1730 loss: 5.22463267e-07
Iter: 1731 loss: 5.22545179e-07
Iter: 1732 loss: 5.2234185e-07
Iter: 1733 loss: 5.22212417e-07
Iter: 1734 loss: 5.22049334e-07
Iter: 1735 loss: 5.22035691e-07
Iter: 1736 loss: 5.21871e-07
Iter: 1737 loss: 5.2302795e-07
Iter: 1738 loss: 5.21796153e-07
Iter: 1739 loss: 5.21634e-07
Iter: 1740 loss: 5.21987e-07
Iter: 1741 loss: 5.2161522e-07
Iter: 1742 loss: 5.21430593e-07
Iter: 1743 loss: 5.21460947e-07
Iter: 1744 loss: 5.21299171e-07
Iter: 1745 loss: 5.2112e-07
Iter: 1746 loss: 5.21183097e-07
Iter: 1747 loss: 5.21000914e-07
Iter: 1748 loss: 5.2165592e-07
Iter: 1749 loss: 5.20964079e-07
Iter: 1750 loss: 5.20905132e-07
Iter: 1751 loss: 5.20821686e-07
Iter: 1752 loss: 5.20791559e-07
Iter: 1753 loss: 5.2059346e-07
Iter: 1754 loss: 5.20964647e-07
Iter: 1755 loss: 5.20477556e-07
Iter: 1756 loss: 5.20269282e-07
Iter: 1757 loss: 5.2062336e-07
Iter: 1758 loss: 5.20255639e-07
Iter: 1759 loss: 5.20070671e-07
Iter: 1760 loss: 5.20276e-07
Iter: 1761 loss: 5.19883883e-07
Iter: 1762 loss: 5.19639116e-07
Iter: 1763 loss: 5.21090044e-07
Iter: 1764 loss: 5.19636671e-07
Iter: 1765 loss: 5.19447e-07
Iter: 1766 loss: 5.20199819e-07
Iter: 1767 loss: 5.19404466e-07
Iter: 1768 loss: 5.19274295e-07
Iter: 1769 loss: 5.1976366e-07
Iter: 1770 loss: 5.19272191e-07
Iter: 1771 loss: 5.19129173e-07
Iter: 1772 loss: 5.19209266e-07
Iter: 1773 loss: 5.19009291e-07
Iter: 1774 loss: 5.18844217e-07
Iter: 1775 loss: 5.18957449e-07
Iter: 1776 loss: 5.18691252e-07
Iter: 1777 loss: 5.18510831e-07
Iter: 1778 loss: 5.19977277e-07
Iter: 1779 loss: 5.18433524e-07
Iter: 1780 loss: 5.18339561e-07
Iter: 1781 loss: 5.18373838e-07
Iter: 1782 loss: 5.18255206e-07
Iter: 1783 loss: 5.18109914e-07
Iter: 1784 loss: 5.1812e-07
Iter: 1785 loss: 5.1798412e-07
Iter: 1786 loss: 5.17803699e-07
Iter: 1787 loss: 5.17802675e-07
Iter: 1788 loss: 5.17695412e-07
Iter: 1789 loss: 5.18783565e-07
Iter: 1790 loss: 5.1761657e-07
Iter: 1791 loss: 5.17371063e-07
Iter: 1792 loss: 5.17510557e-07
Iter: 1793 loss: 5.17242256e-07
Iter: 1794 loss: 5.17093667e-07
Iter: 1795 loss: 5.17584795e-07
Iter: 1796 loss: 5.17015394e-07
Iter: 1797 loss: 5.16819398e-07
Iter: 1798 loss: 5.17043702e-07
Iter: 1799 loss: 5.1679973e-07
Iter: 1800 loss: 5.16581906e-07
Iter: 1801 loss: 5.16610612e-07
Iter: 1802 loss: 5.16464809e-07
Iter: 1803 loss: 5.16236526e-07
Iter: 1804 loss: 5.16202135e-07
Iter: 1805 loss: 5.16060538e-07
Iter: 1806 loss: 5.16220553e-07
Iter: 1807 loss: 5.15998238e-07
Iter: 1808 loss: 5.15896431e-07
Iter: 1809 loss: 5.15734882e-07
Iter: 1810 loss: 5.15664453e-07
Iter: 1811 loss: 5.15494264e-07
Iter: 1812 loss: 5.17311207e-07
Iter: 1813 loss: 5.1551865e-07
Iter: 1814 loss: 5.15333227e-07
Iter: 1815 loss: 5.15983402e-07
Iter: 1816 loss: 5.15319073e-07
Iter: 1817 loss: 5.15117222e-07
Iter: 1818 loss: 5.16208843e-07
Iter: 1819 loss: 5.15021213e-07
Iter: 1820 loss: 5.14967553e-07
Iter: 1821 loss: 5.14991711e-07
Iter: 1822 loss: 5.14897067e-07
Iter: 1823 loss: 5.14796056e-07
Iter: 1824 loss: 5.14640305e-07
Iter: 1825 loss: 5.14616318e-07
Iter: 1826 loss: 5.14480348e-07
Iter: 1827 loss: 5.14469377e-07
Iter: 1828 loss: 5.14336648e-07
Iter: 1829 loss: 5.14475914e-07
Iter: 1830 loss: 5.14263604e-07
Iter: 1831 loss: 5.14111434e-07
Iter: 1832 loss: 5.14264741e-07
Iter: 1833 loss: 5.14014062e-07
Iter: 1834 loss: 5.13823636e-07
Iter: 1835 loss: 5.14871033e-07
Iter: 1836 loss: 5.1376918e-07
Iter: 1837 loss: 5.13598138e-07
Iter: 1838 loss: 5.14011333e-07
Iter: 1839 loss: 5.1355812e-07
Iter: 1840 loss: 5.13385487e-07
Iter: 1841 loss: 5.13912426e-07
Iter: 1842 loss: 5.1333825e-07
Iter: 1843 loss: 5.13124917e-07
Iter: 1844 loss: 5.13246903e-07
Iter: 1845 loss: 5.13057e-07
Iter: 1846 loss: 5.12889642e-07
Iter: 1847 loss: 5.13237467e-07
Iter: 1848 loss: 5.12802444e-07
Iter: 1849 loss: 5.12726047e-07
Iter: 1850 loss: 5.12698e-07
Iter: 1851 loss: 5.12568306e-07
Iter: 1852 loss: 5.12373788e-07
Iter: 1853 loss: 5.12351392e-07
Iter: 1854 loss: 5.12170232e-07
Iter: 1855 loss: 5.12702286e-07
Iter: 1856 loss: 5.1214e-07
Iter: 1857 loss: 5.11958433e-07
Iter: 1858 loss: 5.11984126e-07
Iter: 1859 loss: 5.11775625e-07
Iter: 1860 loss: 5.11521762e-07
Iter: 1861 loss: 5.13197847e-07
Iter: 1862 loss: 5.11478277e-07
Iter: 1863 loss: 5.11390738e-07
Iter: 1864 loss: 5.11950589e-07
Iter: 1865 loss: 5.11270116e-07
Iter: 1866 loss: 5.11159271e-07
Iter: 1867 loss: 5.11179564e-07
Iter: 1868 loss: 5.11062865e-07
Iter: 1869 loss: 5.10874372e-07
Iter: 1870 loss: 5.11289556e-07
Iter: 1871 loss: 5.10794e-07
Iter: 1872 loss: 5.10623579e-07
Iter: 1873 loss: 5.12528572e-07
Iter: 1874 loss: 5.10655582e-07
Iter: 1875 loss: 5.1047482e-07
Iter: 1876 loss: 5.10471e-07
Iter: 1877 loss: 5.10389214e-07
Iter: 1878 loss: 5.10198674e-07
Iter: 1879 loss: 5.10284053e-07
Iter: 1880 loss: 5.10025586e-07
Iter: 1881 loss: 5.09916333e-07
Iter: 1882 loss: 5.0990144e-07
Iter: 1883 loss: 5.09766323e-07
Iter: 1884 loss: 5.10011773e-07
Iter: 1885 loss: 5.097545e-07
Iter: 1886 loss: 5.09709309e-07
Iter: 1887 loss: 5.09479605e-07
Iter: 1888 loss: 5.13570967e-07
Iter: 1889 loss: 5.09522238e-07
Iter: 1890 loss: 5.09301e-07
Iter: 1891 loss: 5.10444693e-07
Iter: 1892 loss: 5.09274059e-07
Iter: 1893 loss: 5.09073345e-07
Iter: 1894 loss: 5.0992054e-07
Iter: 1895 loss: 5.0905237e-07
Iter: 1896 loss: 5.08944879e-07
Iter: 1897 loss: 5.08860865e-07
Iter: 1898 loss: 5.08786172e-07
Iter: 1899 loss: 5.08549817e-07
Iter: 1900 loss: 5.10213226e-07
Iter: 1901 loss: 5.0853788e-07
Iter: 1902 loss: 5.08330913e-07
Iter: 1903 loss: 5.08787139e-07
Iter: 1904 loss: 5.08332278e-07
Iter: 1905 loss: 5.0822689e-07
Iter: 1906 loss: 5.08249229e-07
Iter: 1907 loss: 5.08083076e-07
Iter: 1908 loss: 5.07889808e-07
Iter: 1909 loss: 5.0960648e-07
Iter: 1910 loss: 5.07881623e-07
Iter: 1911 loss: 5.07715e-07
Iter: 1912 loss: 5.07861955e-07
Iter: 1913 loss: 5.07656466e-07
Iter: 1914 loss: 5.07542666e-07
Iter: 1915 loss: 5.0835996e-07
Iter: 1916 loss: 5.07535e-07
Iter: 1917 loss: 5.07332231e-07
Iter: 1918 loss: 5.08658559e-07
Iter: 1919 loss: 5.073544e-07
Iter: 1920 loss: 5.07272205e-07
Iter: 1921 loss: 5.07165794e-07
Iter: 1922 loss: 5.07144136e-07
Iter: 1923 loss: 5.06951949e-07
Iter: 1924 loss: 5.07167329e-07
Iter: 1925 loss: 5.06859408e-07
Iter: 1926 loss: 5.06627316e-07
Iter: 1927 loss: 5.08171695e-07
Iter: 1928 loss: 5.06613219e-07
Iter: 1929 loss: 5.06421145e-07
Iter: 1930 loss: 5.06885783e-07
Iter: 1931 loss: 5.06342644e-07
Iter: 1932 loss: 5.06179447e-07
Iter: 1933 loss: 5.06417223e-07
Iter: 1934 loss: 5.06128572e-07
Iter: 1935 loss: 5.05840205e-07
Iter: 1936 loss: 5.06805634e-07
Iter: 1937 loss: 5.05895059e-07
Iter: 1938 loss: 5.05667174e-07
Iter: 1939 loss: 5.06258459e-07
Iter: 1940 loss: 5.05664389e-07
Iter: 1941 loss: 5.05490789e-07
Iter: 1942 loss: 5.05614e-07
Iter: 1943 loss: 5.05420758e-07
Iter: 1944 loss: 5.05286e-07
Iter: 1945 loss: 5.05550361e-07
Iter: 1946 loss: 5.05181902e-07
Iter: 1947 loss: 5.04999093e-07
Iter: 1948 loss: 5.05260743e-07
Iter: 1949 loss: 5.05010519e-07
Iter: 1950 loss: 5.04846071e-07
Iter: 1951 loss: 5.0486824e-07
Iter: 1952 loss: 5.04737557e-07
Iter: 1953 loss: 5.04494778e-07
Iter: 1954 loss: 5.05778644e-07
Iter: 1955 loss: 5.04402919e-07
Iter: 1956 loss: 5.04221873e-07
Iter: 1957 loss: 5.05407627e-07
Iter: 1958 loss: 5.04199306e-07
Iter: 1959 loss: 5.03961132e-07
Iter: 1960 loss: 5.04083516e-07
Iter: 1961 loss: 5.03941919e-07
Iter: 1962 loss: 5.03620242e-07
Iter: 1963 loss: 5.04587035e-07
Iter: 1964 loss: 5.03573233e-07
Iter: 1965 loss: 5.03508e-07
Iter: 1966 loss: 5.0486517e-07
Iter: 1967 loss: 5.0350036e-07
Iter: 1968 loss: 5.03346428e-07
Iter: 1969 loss: 5.03211481e-07
Iter: 1970 loss: 5.03226829e-07
Iter: 1971 loss: 5.03032538e-07
Iter: 1972 loss: 5.03717217e-07
Iter: 1973 loss: 5.02991895e-07
Iter: 1974 loss: 5.02833473e-07
Iter: 1975 loss: 5.0467338e-07
Iter: 1976 loss: 5.02788453e-07
Iter: 1977 loss: 5.02700232e-07
Iter: 1978 loss: 5.02716205e-07
Iter: 1979 loss: 5.02606952e-07
Iter: 1980 loss: 5.02432272e-07
Iter: 1981 loss: 5.02606099e-07
Iter: 1982 loss: 5.02285445e-07
Iter: 1983 loss: 5.02249918e-07
Iter: 1984 loss: 5.02253499e-07
Iter: 1985 loss: 5.02099795e-07
Iter: 1986 loss: 5.02328191e-07
Iter: 1987 loss: 5.02050227e-07
Iter: 1988 loss: 5.02011858e-07
Iter: 1989 loss: 5.0169956e-07
Iter: 1990 loss: 5.03879278e-07
Iter: 1991 loss: 5.01676254e-07
Iter: 1992 loss: 5.01434272e-07
Iter: 1993 loss: 5.01470481e-07
Iter: 1994 loss: 5.01353725e-07
Iter: 1995 loss: 5.01714055e-07
Iter: 1996 loss: 5.01218e-07
Iter: 1997 loss: 5.01044724e-07
Iter: 1998 loss: 5.01257034e-07
Iter: 1999 loss: 5.00948545e-07
Iter: 2000 loss: 5.00824797e-07
Iter: 2001 loss: 5.03055048e-07
Iter: 2002 loss: 5.00849637e-07
Iter: 2003 loss: 5.00746637e-07
Iter: 2004 loss: 5.00714577e-07
Iter: 2005 loss: 5.00646365e-07
Iter: 2006 loss: 5.00433543e-07
Iter: 2007 loss: 5.01062402e-07
Iter: 2008 loss: 5.00416149e-07
Iter: 2009 loss: 5.00295357e-07
Iter: 2010 loss: 5.01029035e-07
Iter: 2011 loss: 5.00238741e-07
Iter: 2012 loss: 5.00139265e-07
Iter: 2013 loss: 5.00252384e-07
Iter: 2014 loss: 5.00067472e-07
Iter: 2015 loss: 4.99987e-07
Iter: 2016 loss: 5.00018416e-07
Iter: 2017 loss: 4.99835721e-07
Iter: 2018 loss: 4.99762962e-07
Iter: 2019 loss: 4.99712314e-07
Iter: 2020 loss: 4.99708676e-07
Iter: 2021 loss: 4.99540704e-07
Iter: 2022 loss: 5.00373858e-07
Iter: 2023 loss: 4.99525299e-07
Iter: 2024 loss: 4.99264218e-07
Iter: 2025 loss: 4.99107159e-07
Iter: 2026 loss: 4.99061287e-07
Iter: 2027 loss: 4.98833458e-07
Iter: 2028 loss: 4.99833391e-07
Iter: 2029 loss: 4.98822487e-07
Iter: 2030 loss: 4.9861012e-07
Iter: 2031 loss: 4.99453051e-07
Iter: 2032 loss: 4.98521104e-07
Iter: 2033 loss: 4.98415659e-07
Iter: 2034 loss: 4.98630357e-07
Iter: 2035 loss: 4.98309078e-07
Iter: 2036 loss: 4.98132408e-07
Iter: 2037 loss: 4.98570103e-07
Iter: 2038 loss: 4.98082159e-07
Iter: 2039 loss: 4.97923e-07
Iter: 2040 loss: 4.9876769e-07
Iter: 2041 loss: 4.97874737e-07
Iter: 2042 loss: 4.97759174e-07
Iter: 2043 loss: 4.98177144e-07
Iter: 2044 loss: 4.97717167e-07
Iter: 2045 loss: 4.97577844e-07
Iter: 2046 loss: 4.97812721e-07
Iter: 2047 loss: 4.97485416e-07
Iter: 2048 loss: 4.97326e-07
Iter: 2049 loss: 4.97723647e-07
Iter: 2050 loss: 4.97230531e-07
Iter: 2051 loss: 4.97079611e-07
Iter: 2052 loss: 4.97067447e-07
Iter: 2053 loss: 4.96968198e-07
Iter: 2054 loss: 4.97241331e-07
Iter: 2055 loss: 4.96977293e-07
Iter: 2056 loss: 4.9684661e-07
Iter: 2057 loss: 4.96666644e-07
Iter: 2058 loss: 4.97980295e-07
Iter: 2059 loss: 4.967e-07
Iter: 2060 loss: 4.9642631e-07
Iter: 2061 loss: 4.98170266e-07
Iter: 2062 loss: 4.96400673e-07
Iter: 2063 loss: 4.9628386e-07
Iter: 2064 loss: 4.96785162e-07
Iter: 2065 loss: 4.96262544e-07
Iter: 2066 loss: 4.96110545e-07
Iter: 2067 loss: 4.9632456e-07
Iter: 2068 loss: 4.96021698e-07
Iter: 2069 loss: 4.95885104e-07
Iter: 2070 loss: 4.96218036e-07
Iter: 2071 loss: 4.95818483e-07
Iter: 2072 loss: 4.95669e-07
Iter: 2073 loss: 4.9542e-07
Iter: 2074 loss: 4.95456561e-07
Iter: 2075 loss: 4.9530729e-07
Iter: 2076 loss: 4.95225322e-07
Iter: 2077 loss: 4.9505411e-07
Iter: 2078 loss: 4.9530513e-07
Iter: 2079 loss: 4.95011932e-07
Iter: 2080 loss: 4.94827816e-07
Iter: 2081 loss: 4.94908647e-07
Iter: 2082 loss: 4.94719643e-07
Iter: 2083 loss: 4.944784e-07
Iter: 2084 loss: 4.95200084e-07
Iter: 2085 loss: 4.94416781e-07
Iter: 2086 loss: 4.94300366e-07
Iter: 2087 loss: 4.94301787e-07
Iter: 2088 loss: 4.94205437e-07
Iter: 2089 loss: 4.94036499e-07
Iter: 2090 loss: 4.9728294e-07
Iter: 2091 loss: 4.94031042e-07
Iter: 2092 loss: 4.93792527e-07
Iter: 2093 loss: 4.93764048e-07
Iter: 2094 loss: 4.9359835e-07
Iter: 2095 loss: 4.93380924e-07
Iter: 2096 loss: 4.96565178e-07
Iter: 2097 loss: 4.9340133e-07
Iter: 2098 loss: 4.93247512e-07
Iter: 2099 loss: 4.93146388e-07
Iter: 2100 loss: 4.93135872e-07
Iter: 2101 loss: 4.92873198e-07
Iter: 2102 loss: 4.94852031e-07
Iter: 2103 loss: 4.92848471e-07
Iter: 2104 loss: 4.92684592e-07
Iter: 2105 loss: 4.93347898e-07
Iter: 2106 loss: 4.92679646e-07
Iter: 2107 loss: 4.92466e-07
Iter: 2108 loss: 4.92273728e-07
Iter: 2109 loss: 4.92241725e-07
Iter: 2110 loss: 4.92039703e-07
Iter: 2111 loss: 4.93221478e-07
Iter: 2112 loss: 4.91963476e-07
Iter: 2113 loss: 4.91808805e-07
Iter: 2114 loss: 4.9201708e-07
Iter: 2115 loss: 4.91626281e-07
Iter: 2116 loss: 4.91653623e-07
Iter: 2117 loss: 4.91540675e-07
Iter: 2118 loss: 4.91426817e-07
Iter: 2119 loss: 4.91575406e-07
Iter: 2120 loss: 4.91444155e-07
Iter: 2121 loss: 4.91340813e-07
Iter: 2122 loss: 4.91305741e-07
Iter: 2123 loss: 4.91303e-07
Iter: 2124 loss: 4.91170113e-07
Iter: 2125 loss: 4.91127594e-07
Iter: 2126 loss: 4.91027379e-07
Iter: 2127 loss: 4.90836669e-07
Iter: 2128 loss: 4.91481444e-07
Iter: 2129 loss: 4.90777268e-07
Iter: 2130 loss: 4.90592e-07
Iter: 2131 loss: 4.90508512e-07
Iter: 2132 loss: 4.90444222e-07
Iter: 2133 loss: 4.9022492e-07
Iter: 2134 loss: 4.91972287e-07
Iter: 2135 loss: 4.90206673e-07
Iter: 2136 loss: 4.89987713e-07
Iter: 2137 loss: 4.90159721e-07
Iter: 2138 loss: 4.8996634e-07
Iter: 2139 loss: 4.8969622e-07
Iter: 2140 loss: 4.92613196e-07
Iter: 2141 loss: 4.89673255e-07
Iter: 2142 loss: 4.89593e-07
Iter: 2143 loss: 4.89561671e-07
Iter: 2144 loss: 4.89551496e-07
Iter: 2145 loss: 4.893501e-07
Iter: 2146 loss: 4.89189574e-07
Iter: 2147 loss: 4.89123522e-07
Iter: 2148 loss: 4.8902757e-07
Iter: 2149 loss: 4.89039792e-07
Iter: 2150 loss: 4.88869489e-07
Iter: 2151 loss: 4.90066441e-07
Iter: 2152 loss: 4.88891942e-07
Iter: 2153 loss: 4.888023e-07
Iter: 2154 loss: 4.88807359e-07
Iter: 2155 loss: 4.88728517e-07
Iter: 2156 loss: 4.88620856e-07
Iter: 2157 loss: 4.88579872e-07
Iter: 2158 loss: 4.88532e-07
Iter: 2159 loss: 4.88403657e-07
Iter: 2160 loss: 4.88595106e-07
Iter: 2161 loss: 4.88345904e-07
Iter: 2162 loss: 4.88176056e-07
Iter: 2163 loss: 4.88360058e-07
Iter: 2164 loss: 4.88051455e-07
Iter: 2165 loss: 4.87858529e-07
Iter: 2166 loss: 4.88383932e-07
Iter: 2167 loss: 4.87784177e-07
Iter: 2168 loss: 4.87647526e-07
Iter: 2169 loss: 4.87574937e-07
Iter: 2170 loss: 4.87478871e-07
Iter: 2171 loss: 4.87243369e-07
Iter: 2172 loss: 4.89923252e-07
Iter: 2173 loss: 4.87246041e-07
Iter: 2174 loss: 4.87063346e-07
Iter: 2175 loss: 4.8822028e-07
Iter: 2176 loss: 4.87073237e-07
Iter: 2177 loss: 4.86917713e-07
Iter: 2178 loss: 4.8684e-07
Iter: 2179 loss: 4.91164769e-07
Iter: 2180 loss: 4.86830686e-07
Iter: 2181 loss: 4.86576255e-07
Iter: 2182 loss: 4.89094e-07
Iter: 2183 loss: 4.8655204e-07
Iter: 2184 loss: 4.86455178e-07
Iter: 2185 loss: 4.86161127e-07
Iter: 2186 loss: 4.86210809e-07
Iter: 2187 loss: 4.86489171e-07
Iter: 2188 loss: 4.86086e-07
Iter: 2189 loss: 4.86031297e-07
Iter: 2190 loss: 4.85970872e-07
Iter: 2191 loss: 4.85966495e-07
Iter: 2192 loss: 4.85824899e-07
Iter: 2193 loss: 4.86021918e-07
Iter: 2194 loss: 4.85735598e-07
Iter: 2195 loss: 4.85604289e-07
Iter: 2196 loss: 4.85853832e-07
Iter: 2197 loss: 4.8551e-07
Iter: 2198 loss: 4.85352189e-07
Iter: 2199 loss: 4.87449597e-07
Iter: 2200 loss: 4.85321607e-07
Iter: 2201 loss: 4.85231794e-07
Iter: 2202 loss: 4.85176031e-07
Iter: 2203 loss: 4.85119301e-07
Iter: 2204 loss: 4.84938369e-07
Iter: 2205 loss: 4.85033468e-07
Iter: 2206 loss: 4.84733903e-07
Iter: 2207 loss: 4.84627719e-07
Iter: 2208 loss: 4.84655345e-07
Iter: 2209 loss: 4.84531427e-07
Iter: 2210 loss: 4.84240047e-07
Iter: 2211 loss: 4.88412e-07
Iter: 2212 loss: 4.84253462e-07
Iter: 2213 loss: 4.84036718e-07
Iter: 2214 loss: 4.86485419e-07
Iter: 2215 loss: 4.84034899e-07
Iter: 2216 loss: 4.83887561e-07
Iter: 2217 loss: 4.8426574e-07
Iter: 2218 loss: 4.83789108e-07
Iter: 2219 loss: 4.83588337e-07
Iter: 2220 loss: 4.83888641e-07
Iter: 2221 loss: 4.83515635e-07
Iter: 2222 loss: 4.83543e-07
Iter: 2223 loss: 4.83392341e-07
Iter: 2224 loss: 4.83349481e-07
Iter: 2225 loss: 4.8318e-07
Iter: 2226 loss: 4.83509666e-07
Iter: 2227 loss: 4.83078622e-07
Iter: 2228 loss: 4.82894e-07
Iter: 2229 loss: 4.83609142e-07
Iter: 2230 loss: 4.82860287e-07
Iter: 2231 loss: 4.8274e-07
Iter: 2232 loss: 4.82510814e-07
Iter: 2233 loss: 4.86823353e-07
Iter: 2234 loss: 4.82548955e-07
Iter: 2235 loss: 4.82279745e-07
Iter: 2236 loss: 4.8318509e-07
Iter: 2237 loss: 4.8228253e-07
Iter: 2238 loss: 4.82122232e-07
Iter: 2239 loss: 4.83254098e-07
Iter: 2240 loss: 4.82080281e-07
Iter: 2241 loss: 4.81957272e-07
Iter: 2242 loss: 4.81826135e-07
Iter: 2243 loss: 4.81760367e-07
Iter: 2244 loss: 4.81624909e-07
Iter: 2245 loss: 4.83364033e-07
Iter: 2246 loss: 4.81614222e-07
Iter: 2247 loss: 4.81488598e-07
Iter: 2248 loss: 4.81426355e-07
Iter: 2249 loss: 4.81381392e-07
Iter: 2250 loss: 4.8117e-07
Iter: 2251 loss: 4.81629797e-07
Iter: 2252 loss: 4.81061875e-07
Iter: 2253 loss: 4.80912945e-07
Iter: 2254 loss: 4.82464884e-07
Iter: 2255 loss: 4.80905101e-07
Iter: 2256 loss: 4.80778567e-07
Iter: 2257 loss: 4.81484449e-07
Iter: 2258 loss: 4.80763e-07
Iter: 2259 loss: 4.80604626e-07
Iter: 2260 loss: 4.80698304e-07
Iter: 2261 loss: 4.80552615e-07
Iter: 2262 loss: 4.80391691e-07
Iter: 2263 loss: 4.80354174e-07
Iter: 2264 loss: 4.80292613e-07
Iter: 2265 loss: 4.80147435e-07
Iter: 2266 loss: 4.80756171e-07
Iter: 2267 loss: 4.80109e-07
Iter: 2268 loss: 4.79929838e-07
Iter: 2269 loss: 4.79957293e-07
Iter: 2270 loss: 4.79775906e-07
Iter: 2271 loss: 4.79702067e-07
Iter: 2272 loss: 4.80813128e-07
Iter: 2273 loss: 4.79622486e-07
Iter: 2274 loss: 4.79536084e-07
Iter: 2275 loss: 4.79474068e-07
Iter: 2276 loss: 4.7940631e-07
Iter: 2277 loss: 4.79189055e-07
Iter: 2278 loss: 4.8000237e-07
Iter: 2279 loss: 4.791886e-07
Iter: 2280 loss: 4.78998857e-07
Iter: 2281 loss: 4.79146195e-07
Iter: 2282 loss: 4.78947754e-07
Iter: 2283 loss: 4.7868366e-07
Iter: 2284 loss: 4.80312508e-07
Iter: 2285 loss: 4.78697132e-07
Iter: 2286 loss: 4.78513357e-07
Iter: 2287 loss: 4.78360676e-07
Iter: 2288 loss: 4.7834709e-07
Iter: 2289 loss: 4.78271204e-07
Iter: 2290 loss: 4.78218e-07
Iter: 2291 loss: 4.78123638e-07
Iter: 2292 loss: 4.78568609e-07
Iter: 2293 loss: 4.78138361e-07
Iter: 2294 loss: 4.78054858e-07
Iter: 2295 loss: 4.77901551e-07
Iter: 2296 loss: 4.80565518e-07
Iter: 2297 loss: 4.7792696e-07
Iter: 2298 loss: 4.77692e-07
Iter: 2299 loss: 4.77674689e-07
Iter: 2300 loss: 4.77562367e-07
Iter: 2301 loss: 4.77388198e-07
Iter: 2302 loss: 4.79116466e-07
Iter: 2303 loss: 4.77423498e-07
Iter: 2304 loss: 4.77255753e-07
Iter: 2305 loss: 4.7772113e-07
Iter: 2306 loss: 4.77210051e-07
Iter: 2307 loss: 4.77012122e-07
Iter: 2308 loss: 4.77699928e-07
Iter: 2309 loss: 4.7699757e-07
Iter: 2310 loss: 4.76857167e-07
Iter: 2311 loss: 4.77182482e-07
Iter: 2312 loss: 4.76824511e-07
Iter: 2313 loss: 4.76682942e-07
Iter: 2314 loss: 4.7649894e-07
Iter: 2315 loss: 4.76475549e-07
Iter: 2316 loss: 4.76266479e-07
Iter: 2317 loss: 4.77102503e-07
Iter: 2318 loss: 4.76260141e-07
Iter: 2319 loss: 4.76045017e-07
Iter: 2320 loss: 4.77715389e-07
Iter: 2321 loss: 4.76002668e-07
Iter: 2322 loss: 4.75866074e-07
Iter: 2323 loss: 4.76315e-07
Iter: 2324 loss: 4.75822617e-07
Iter: 2325 loss: 4.75741842e-07
Iter: 2326 loss: 4.75771856e-07
Iter: 2327 loss: 4.75651916e-07
Iter: 2328 loss: 4.7548707e-07
Iter: 2329 loss: 4.75519784e-07
Iter: 2330 loss: 4.75389612e-07
Iter: 2331 loss: 4.75503782e-07
Iter: 2332 loss: 4.75365056e-07
Iter: 2333 loss: 4.75189552e-07
Iter: 2334 loss: 4.75250232e-07
Iter: 2335 loss: 4.75099057e-07
Iter: 2336 loss: 4.749499e-07
Iter: 2337 loss: 4.75410445e-07
Iter: 2338 loss: 4.74879812e-07
Iter: 2339 loss: 4.74761748e-07
Iter: 2340 loss: 4.75028e-07
Iter: 2341 loss: 4.74646498e-07
Iter: 2342 loss: 4.7447719e-07
Iter: 2343 loss: 4.75236021e-07
Iter: 2344 loss: 4.74406136e-07
Iter: 2345 loss: 4.74321894e-07
Iter: 2346 loss: 4.746542e-07
Iter: 2347 loss: 4.74327976e-07
Iter: 2348 loss: 4.74175692e-07
Iter: 2349 loss: 4.74139824e-07
Iter: 2350 loss: 4.74109584e-07
Iter: 2351 loss: 4.73909324e-07
Iter: 2352 loss: 4.75641116e-07
Iter: 2353 loss: 4.73933824e-07
Iter: 2354 loss: 4.73777106e-07
Iter: 2355 loss: 4.74035801e-07
Iter: 2356 loss: 4.73735781e-07
Iter: 2357 loss: 4.73575824e-07
Iter: 2358 loss: 4.7429802e-07
Iter: 2359 loss: 4.73666688e-07
Iter: 2360 loss: 4.73494623e-07
Iter: 2361 loss: 4.74249418e-07
Iter: 2362 loss: 4.73524608e-07
Iter: 2363 loss: 4.73424166e-07
Iter: 2364 loss: 4.73381249e-07
Iter: 2365 loss: 4.73399837e-07
Iter: 2366 loss: 4.73250253e-07
Iter: 2367 loss: 4.73248605e-07
Iter: 2368 loss: 4.73131649e-07
Iter: 2369 loss: 4.72964899e-07
Iter: 2370 loss: 4.73591484e-07
Iter: 2371 loss: 4.72940826e-07
Iter: 2372 loss: 4.72837343e-07
Iter: 2373 loss: 4.73734531e-07
Iter: 2374 loss: 4.72803094e-07
Iter: 2375 loss: 4.72704443e-07
Iter: 2376 loss: 4.72555968e-07
Iter: 2377 loss: 4.72584532e-07
Iter: 2378 loss: 4.72344823e-07
Iter: 2379 loss: 4.74612875e-07
Iter: 2380 loss: 4.72343515e-07
Iter: 2381 loss: 4.72263594e-07
Iter: 2382 loss: 4.72358607e-07
Iter: 2383 loss: 4.72288491e-07
Iter: 2384 loss: 4.72065778e-07
Iter: 2385 loss: 4.72149765e-07
Iter: 2386 loss: 4.71945384e-07
Iter: 2387 loss: 4.71885585e-07
Iter: 2388 loss: 4.72712344e-07
Iter: 2389 loss: 4.71818737e-07
Iter: 2390 loss: 4.71675e-07
Iter: 2391 loss: 4.71760842e-07
Iter: 2392 loss: 4.71643943e-07
Iter: 2393 loss: 4.71545434e-07
Iter: 2394 loss: 4.71517922e-07
Iter: 2395 loss: 4.71449027e-07
Iter: 2396 loss: 4.71563567e-07
Iter: 2397 loss: 4.71422283e-07
Iter: 2398 loss: 4.71351882e-07
Iter: 2399 loss: 4.71235978e-07
Iter: 2400 loss: 4.73390372e-07
Iter: 2401 loss: 4.71241037e-07
Iter: 2402 loss: 4.71014914e-07
Iter: 2403 loss: 4.71948567e-07
Iter: 2404 loss: 4.71025146e-07
Iter: 2405 loss: 4.7084319e-07
Iter: 2406 loss: 4.71775309e-07
Iter: 2407 loss: 4.70841485e-07
Iter: 2408 loss: 4.70666777e-07
Iter: 2409 loss: 4.7096529e-07
Iter: 2410 loss: 4.70643215e-07
Iter: 2411 loss: 4.70491358e-07
Iter: 2412 loss: 4.70582563e-07
Iter: 2413 loss: 4.70366047e-07
Iter: 2414 loss: 4.702365e-07
Iter: 2415 loss: 4.7187e-07
Iter: 2416 loss: 4.70259351e-07
Iter: 2417 loss: 4.70151207e-07
Iter: 2418 loss: 4.69991818e-07
Iter: 2419 loss: 4.69934349e-07
Iter: 2420 loss: 4.69794514e-07
Iter: 2421 loss: 4.70871953e-07
Iter: 2422 loss: 4.69779877e-07
Iter: 2423 loss: 4.69630834e-07
Iter: 2424 loss: 4.69438362e-07
Iter: 2425 loss: 4.69395218e-07
Iter: 2426 loss: 4.69378278e-07
Iter: 2427 loss: 4.69308787e-07
Iter: 2428 loss: 4.69186773e-07
Iter: 2429 loss: 4.69604316e-07
Iter: 2430 loss: 4.69218946e-07
Iter: 2431 loss: 4.69128338e-07
Iter: 2432 loss: 4.69006352e-07
Iter: 2433 loss: 4.71198064e-07
Iter: 2434 loss: 4.69015163e-07
Iter: 2435 loss: 4.68832553e-07
Iter: 2436 loss: 4.69160454e-07
Iter: 2437 loss: 4.6870673e-07
Iter: 2438 loss: 4.68547682e-07
Iter: 2439 loss: 4.69414829e-07
Iter: 2440 loss: 4.68533244e-07
Iter: 2441 loss: 4.68368228e-07
Iter: 2442 loss: 4.68473701e-07
Iter: 2443 loss: 4.68307235e-07
Iter: 2444 loss: 4.6809123e-07
Iter: 2445 loss: 4.69139252e-07
Iter: 2446 loss: 4.68031487e-07
Iter: 2447 loss: 4.67925247e-07
Iter: 2448 loss: 4.68067981e-07
Iter: 2449 loss: 4.67807e-07
Iter: 2450 loss: 4.6769361e-07
Iter: 2451 loss: 4.67725272e-07
Iter: 2452 loss: 4.67565371e-07
Iter: 2453 loss: 4.67311111e-07
Iter: 2454 loss: 4.68539952e-07
Iter: 2455 loss: 4.67228688e-07
Iter: 2456 loss: 4.67035051e-07
Iter: 2457 loss: 4.67791352e-07
Iter: 2458 loss: 4.670311e-07
Iter: 2459 loss: 4.66857045e-07
Iter: 2460 loss: 4.66781614e-07
Iter: 2461 loss: 4.66749356e-07
Iter: 2462 loss: 4.66545458e-07
Iter: 2463 loss: 4.68039133e-07
Iter: 2464 loss: 4.66547846e-07
Iter: 2465 loss: 4.66417077e-07
Iter: 2466 loss: 4.66438e-07
Iter: 2467 loss: 4.66305977e-07
Iter: 2468 loss: 4.66409972e-07
Iter: 2469 loss: 4.66191e-07
Iter: 2470 loss: 4.66187203e-07
Iter: 2471 loss: 4.66133628e-07
Iter: 2472 loss: 4.66730512e-07
Iter: 2473 loss: 4.661361e-07
Iter: 2474 loss: 4.65943685e-07
Iter: 2475 loss: 4.65832585e-07
Iter: 2476 loss: 4.65792198e-07
Iter: 2477 loss: 4.65655887e-07
Iter: 2478 loss: 4.65655091e-07
Iter: 2479 loss: 4.65609048e-07
Iter: 2480 loss: 4.65466854e-07
Iter: 2481 loss: 4.65447613e-07
Iter: 2482 loss: 4.65259603e-07
Iter: 2483 loss: 4.66169979e-07
Iter: 2484 loss: 4.65277935e-07
Iter: 2485 loss: 4.65086828e-07
Iter: 2486 loss: 4.65832557e-07
Iter: 2487 loss: 4.65106154e-07
Iter: 2488 loss: 4.65010913e-07
Iter: 2489 loss: 4.6492579e-07
Iter: 2490 loss: 4.64861728e-07
Iter: 2491 loss: 4.64695262e-07
Iter: 2492 loss: 4.6526344e-07
Iter: 2493 loss: 4.64656125e-07
Iter: 2494 loss: 4.64509867e-07
Iter: 2495 loss: 4.65618655e-07
Iter: 2496 loss: 4.64485254e-07
Iter: 2497 loss: 4.64386858e-07
Iter: 2498 loss: 4.6446516e-07
Iter: 2499 loss: 4.64352127e-07
Iter: 2500 loss: 4.64299148e-07
Iter: 2501 loss: 4.64334022e-07
Iter: 2502 loss: 4.64230908e-07
Iter: 2503 loss: 4.64202913e-07
Iter: 2504 loss: 4.6413885e-07
Iter: 2505 loss: 4.64061145e-07
Iter: 2506 loss: 4.64077885e-07
Iter: 2507 loss: 4.64054096e-07
Iter: 2508 loss: 4.63942882e-07
Iter: 2509 loss: 4.63935464e-07
Iter: 2510 loss: 4.63952091e-07
Iter: 2511 loss: 4.63748762e-07
Iter: 2512 loss: 4.63762063e-07
Iter: 2513 loss: 4.63663554e-07
Iter: 2514 loss: 4.63534633e-07
Iter: 2515 loss: 4.65103795e-07
Iter: 2516 loss: 4.6356854e-07
Iter: 2517 loss: 4.63425749e-07
Iter: 2518 loss: 4.63938335e-07
Iter: 2519 loss: 4.63360891e-07
Iter: 2520 loss: 4.63324938e-07
Iter: 2521 loss: 4.63305184e-07
Iter: 2522 loss: 4.63216793e-07
Iter: 2523 loss: 4.63138576e-07
Iter: 2524 loss: 4.63206305e-07
Iter: 2525 loss: 4.63056722e-07
Iter: 2526 loss: 4.62998798e-07
Iter: 2527 loss: 4.63400909e-07
Iter: 2528 loss: 4.62913221e-07
Iter: 2529 loss: 4.62798909e-07
Iter: 2530 loss: 4.62937066e-07
Iter: 2531 loss: 4.62795072e-07
Iter: 2532 loss: 4.62641282e-07
Iter: 2533 loss: 4.63674525e-07
Iter: 2534 loss: 4.62674194e-07
Iter: 2535 loss: 4.62618402e-07
Iter: 2536 loss: 4.6258404e-07
Iter: 2537 loss: 4.62517107e-07
Iter: 2538 loss: 4.62506023e-07
Iter: 2539 loss: 4.63362653e-07
Iter: 2540 loss: 4.62522337e-07
Iter: 2541 loss: 4.62390915e-07
Iter: 2542 loss: 4.62558e-07
Iter: 2543 loss: 4.62367865e-07
Iter: 2544 loss: 4.62286749e-07
Iter: 2545 loss: 4.62526287e-07
Iter: 2546 loss: 4.62251961e-07
Iter: 2547 loss: 4.62178775e-07
Iter: 2548 loss: 4.6223829e-07
Iter: 2549 loss: 4.62021603e-07
Iter: 2550 loss: 4.61991306e-07
Iter: 2551 loss: 4.62846515e-07
Iter: 2552 loss: 4.61959445e-07
Iter: 2553 loss: 4.61832343e-07
Iter: 2554 loss: 4.62166156e-07
Iter: 2555 loss: 4.61836805e-07
Iter: 2556 loss: 4.61724085e-07
Iter: 2557 loss: 4.617076e-07
Iter: 2558 loss: 4.61654338e-07
Iter: 2559 loss: 4.61490913e-07
Iter: 2560 loss: 4.61961633e-07
Iter: 2561 loss: 4.61436827e-07
Iter: 2562 loss: 4.61307252e-07
Iter: 2563 loss: 4.61788147e-07
Iter: 2564 loss: 4.6128909e-07
Iter: 2565 loss: 4.61129503e-07
Iter: 2566 loss: 4.61417557e-07
Iter: 2567 loss: 4.61053162e-07
Iter: 2568 loss: 4.61049382e-07
Iter: 2569 loss: 4.61016697e-07
Iter: 2570 loss: 4.60913498e-07
Iter: 2571 loss: 4.60835082e-07
Iter: 2572 loss: 4.62660068e-07
Iter: 2573 loss: 4.60833e-07
Iter: 2574 loss: 4.60780456e-07
Iter: 2575 loss: 4.60778836e-07
Iter: 2576 loss: 4.60706133e-07
Iter: 2577 loss: 4.60600972e-07
Iter: 2578 loss: 4.60993533e-07
Iter: 2579 loss: 4.60480123e-07
Iter: 2580 loss: 4.60408245e-07
Iter: 2581 loss: 4.60327584e-07
Iter: 2582 loss: 4.6032909e-07
Iter: 2583 loss: 4.6019565e-07
Iter: 2584 loss: 4.61052451e-07
Iter: 2585 loss: 4.60060278e-07
Iter: 2586 loss: 4.60051751e-07
Iter: 2587 loss: 4.60462729e-07
Iter: 2588 loss: 4.59995078e-07
Iter: 2589 loss: 4.59900491e-07
Iter: 2590 loss: 4.5999343e-07
Iter: 2591 loss: 4.59809854e-07
Iter: 2592 loss: 4.59665841e-07
Iter: 2593 loss: 4.60379539e-07
Iter: 2594 loss: 4.59658338e-07
Iter: 2595 loss: 4.59578871e-07
Iter: 2596 loss: 4.59453503e-07
Iter: 2597 loss: 4.59419738e-07
Iter: 2598 loss: 4.59271064e-07
Iter: 2599 loss: 4.60185191e-07
Iter: 2600 loss: 4.59197025e-07
Iter: 2601 loss: 4.59020157e-07
Iter: 2602 loss: 4.59906289e-07
Iter: 2603 loss: 4.5906728e-07
Iter: 2604 loss: 4.58957572e-07
Iter: 2605 loss: 4.5894825e-07
Iter: 2606 loss: 4.58914826e-07
Iter: 2607 loss: 4.58708655e-07
Iter: 2608 loss: 4.60506016e-07
Iter: 2609 loss: 4.58706978e-07
Iter: 2610 loss: 4.58598578e-07
Iter: 2611 loss: 4.59052359e-07
Iter: 2612 loss: 4.5856018e-07
Iter: 2613 loss: 4.58461102e-07
Iter: 2614 loss: 4.58562226e-07
Iter: 2615 loss: 4.58371289e-07
Iter: 2616 loss: 4.58213634e-07
Iter: 2617 loss: 4.58385443e-07
Iter: 2618 loss: 4.58115323e-07
Iter: 2619 loss: 4.58028296e-07
Iter: 2620 loss: 4.59250941e-07
Iter: 2621 loss: 4.58025426e-07
Iter: 2622 loss: 4.57890621e-07
Iter: 2623 loss: 4.58270364e-07
Iter: 2624 loss: 4.57891218e-07
Iter: 2625 loss: 4.57791373e-07
Iter: 2626 loss: 4.57764202e-07
Iter: 2627 loss: 4.57694085e-07
Iter: 2628 loss: 4.57546321e-07
Iter: 2629 loss: 4.57719068e-07
Iter: 2630 loss: 4.57505763e-07
Iter: 2631 loss: 4.57355327e-07
Iter: 2632 loss: 4.58235206e-07
Iter: 2633 loss: 4.57349046e-07
Iter: 2634 loss: 4.57273103e-07
Iter: 2635 loss: 4.57354247e-07
Iter: 2636 loss: 4.5719878e-07
Iter: 2637 loss: 4.57094984e-07
Iter: 2638 loss: 4.57705454e-07
Iter: 2639 loss: 4.57084468e-07
Iter: 2640 loss: 4.56953558e-07
Iter: 2641 loss: 4.56964102e-07
Iter: 2642 loss: 4.56903223e-07
Iter: 2643 loss: 4.56858118e-07
Iter: 2644 loss: 4.57827468e-07
Iter: 2645 loss: 4.56875227e-07
Iter: 2646 loss: 4.56756879e-07
Iter: 2647 loss: 4.5663279e-07
Iter: 2648 loss: 4.56613918e-07
Iter: 2649 loss: 4.56432161e-07
Iter: 2650 loss: 4.58079967e-07
Iter: 2651 loss: 4.56448959e-07
Iter: 2652 loss: 4.56342e-07
Iter: 2653 loss: 4.56767339e-07
Iter: 2654 loss: 4.56324585e-07
Iter: 2655 loss: 4.56264729e-07
Iter: 2656 loss: 4.56635632e-07
Iter: 2657 loss: 4.56268253e-07
Iter: 2658 loss: 4.56094085e-07
Iter: 2659 loss: 4.56152691e-07
Iter: 2660 loss: 4.56015243e-07
Iter: 2661 loss: 4.55923725e-07
Iter: 2662 loss: 4.55973094e-07
Iter: 2663 loss: 4.55808674e-07
Iter: 2664 loss: 4.55583034e-07
Iter: 2665 loss: 4.5614172e-07
Iter: 2666 loss: 4.55536451e-07
Iter: 2667 loss: 4.55343127e-07
Iter: 2668 loss: 4.55949504e-07
Iter: 2669 loss: 4.55294099e-07
Iter: 2670 loss: 4.55068516e-07
Iter: 2671 loss: 4.55422594e-07
Iter: 2672 loss: 4.550011e-07
Iter: 2673 loss: 4.54952158e-07
Iter: 2674 loss: 4.54851914e-07
Iter: 2675 loss: 4.54834037e-07
Iter: 2676 loss: 4.54656544e-07
Iter: 2677 loss: 4.57043768e-07
Iter: 2678 loss: 4.54703e-07
Iter: 2679 loss: 4.54534216e-07
Iter: 2680 loss: 4.54398446e-07
Iter: 2681 loss: 4.54404983e-07
Iter: 2682 loss: 4.542282e-07
Iter: 2683 loss: 4.55381979e-07
Iter: 2684 loss: 4.54216888e-07
Iter: 2685 loss: 4.54078304e-07
Iter: 2686 loss: 4.54707e-07
Iter: 2687 loss: 4.54084784e-07
Iter: 2688 loss: 4.53913344e-07
Iter: 2689 loss: 4.54012849e-07
Iter: 2690 loss: 4.53896519e-07
Iter: 2691 loss: 4.53779933e-07
Iter: 2692 loss: 4.54294e-07
Iter: 2693 loss: 4.53789909e-07
Iter: 2694 loss: 4.53684947e-07
Iter: 2695 loss: 4.53569726e-07
Iter: 2696 loss: 4.53514787e-07
Iter: 2697 loss: 4.53402748e-07
Iter: 2698 loss: 4.54326766e-07
Iter: 2699 loss: 4.53410109e-07
Iter: 2700 loss: 4.5325686e-07
Iter: 2701 loss: 4.53507397e-07
Iter: 2702 loss: 4.53221219e-07
Iter: 2703 loss: 4.53096106e-07
Iter: 2704 loss: 4.53261123e-07
Iter: 2705 loss: 4.53029088e-07
Iter: 2706 loss: 4.53074591e-07
Iter: 2707 loss: 4.52980601e-07
Iter: 2708 loss: 4.52954765e-07
Iter: 2709 loss: 4.52844574e-07
Iter: 2710 loss: 4.52846734e-07
Iter: 2711 loss: 4.52774316e-07
Iter: 2712 loss: 4.52704569e-07
Iter: 2713 loss: 4.52678847e-07
Iter: 2714 loss: 4.52570731e-07
Iter: 2715 loss: 4.5318518e-07
Iter: 2716 loss: 4.52523977e-07
Iter: 2717 loss: 4.52453889e-07
Iter: 2718 loss: 4.52853726e-07
Iter: 2719 loss: 4.52467589e-07
Iter: 2720 loss: 4.52344295e-07
Iter: 2721 loss: 4.52856085e-07
Iter: 2722 loss: 4.52335257e-07
Iter: 2723 loss: 4.5224823e-07
Iter: 2724 loss: 4.52401e-07
Iter: 2725 loss: 4.52163391e-07
Iter: 2726 loss: 4.52142103e-07
Iter: 2727 loss: 4.52069401e-07
Iter: 2728 loss: 4.52076904e-07
Iter: 2729 loss: 4.51902594e-07
Iter: 2730 loss: 4.52379112e-07
Iter: 2731 loss: 4.51854845e-07
Iter: 2732 loss: 4.51733229e-07
Iter: 2733 loss: 4.51915753e-07
Iter: 2734 loss: 4.51702476e-07
Iter: 2735 loss: 4.51554854e-07
Iter: 2736 loss: 4.52125363e-07
Iter: 2737 loss: 4.51556275e-07
Iter: 2738 loss: 4.51485022e-07
Iter: 2739 loss: 4.51495396e-07
Iter: 2740 loss: 4.51378412e-07
Iter: 2741 loss: 4.51640858e-07
Iter: 2742 loss: 4.51395238e-07
Iter: 2743 loss: 4.51328333e-07
Iter: 2744 loss: 4.51257335e-07
Iter: 2745 loss: 4.52345176e-07
Iter: 2746 loss: 4.51287605e-07
Iter: 2747 loss: 4.51120457e-07
Iter: 2748 loss: 4.51696906e-07
Iter: 2749 loss: 4.51137879e-07
Iter: 2750 loss: 4.50990342e-07
Iter: 2751 loss: 4.5141752e-07
Iter: 2752 loss: 4.50953536e-07
Iter: 2753 loss: 4.50833454e-07
Iter: 2754 loss: 4.51263872e-07
Iter: 2755 loss: 4.50801565e-07
Iter: 2756 loss: 4.50685036e-07
Iter: 2757 loss: 4.51301759e-07
Iter: 2758 loss: 4.50688077e-07
Iter: 2759 loss: 4.50576636e-07
Iter: 2760 loss: 4.50502739e-07
Iter: 2761 loss: 4.50467525e-07
Iter: 2762 loss: 4.50368361e-07
Iter: 2763 loss: 4.50847267e-07
Iter: 2764 loss: 4.50308733e-07
Iter: 2765 loss: 4.50240634e-07
Iter: 2766 loss: 4.50404684e-07
Iter: 2767 loss: 4.50173559e-07
Iter: 2768 loss: 4.50040346e-07
Iter: 2769 loss: 4.50020707e-07
Iter: 2770 loss: 4.49960055e-07
Iter: 2771 loss: 4.49826388e-07
Iter: 2772 loss: 4.49827382e-07
Iter: 2773 loss: 4.49729953e-07
Iter: 2774 loss: 4.50390587e-07
Iter: 2775 loss: 4.4973e-07
Iter: 2776 loss: 4.49641107e-07
Iter: 2777 loss: 4.49526539e-07
Iter: 2778 loss: 4.4958216e-07
Iter: 2779 loss: 4.49487516e-07
Iter: 2780 loss: 4.4952958e-07
Iter: 2781 loss: 4.49440677e-07
Iter: 2782 loss: 4.49368116e-07
Iter: 2783 loss: 4.49307265e-07
Iter: 2784 loss: 4.49204634e-07
Iter: 2785 loss: 4.49013896e-07
Iter: 2786 loss: 4.5008386e-07
Iter: 2787 loss: 4.48993973e-07
Iter: 2788 loss: 4.48956825e-07
Iter: 2789 loss: 4.49438687e-07
Iter: 2790 loss: 4.48923629e-07
Iter: 2791 loss: 4.48799824e-07
Iter: 2792 loss: 4.48992978e-07
Iter: 2793 loss: 4.48728144e-07
Iter: 2794 loss: 4.48634353e-07
Iter: 2795 loss: 4.49407196e-07
Iter: 2796 loss: 4.48591976e-07
Iter: 2797 loss: 4.48550338e-07
Iter: 2798 loss: 4.4854724e-07
Iter: 2799 loss: 4.48503698e-07
Iter: 2800 loss: 4.48465926e-07
Iter: 2801 loss: 4.48291416e-07
Iter: 2802 loss: 4.48308384e-07
Iter: 2803 loss: 4.48233777e-07
Iter: 2804 loss: 4.49092738e-07
Iter: 2805 loss: 4.4817881e-07
Iter: 2806 loss: 4.48047331e-07
Iter: 2807 loss: 4.48659023e-07
Iter: 2808 loss: 4.48070324e-07
Iter: 2809 loss: 4.47938305e-07
Iter: 2810 loss: 4.48397032e-07
Iter: 2811 loss: 4.47911617e-07
Iter: 2812 loss: 4.47821833e-07
Iter: 2813 loss: 4.47915141e-07
Iter: 2814 loss: 4.47832633e-07
Iter: 2815 loss: 4.47784572e-07
Iter: 2816 loss: 4.47659176e-07
Iter: 2817 loss: 4.48680623e-07
Iter: 2818 loss: 4.47644226e-07
Iter: 2819 loss: 4.47441039e-07
Iter: 2820 loss: 4.48980899e-07
Iter: 2821 loss: 4.47502458e-07
Iter: 2822 loss: 4.47341193e-07
Iter: 2823 loss: 4.47741115e-07
Iter: 2824 loss: 4.47344377e-07
Iter: 2825 loss: 4.47246748e-07
Iter: 2826 loss: 4.47582266e-07
Iter: 2827 loss: 4.4719917e-07
Iter: 2828 loss: 4.47107396e-07
Iter: 2829 loss: 4.47685551e-07
Iter: 2830 loss: 4.47116747e-07
Iter: 2831 loss: 4.46997348e-07
Iter: 2832 loss: 4.47301204e-07
Iter: 2833 loss: 4.47033813e-07
Iter: 2834 loss: 4.46915919e-07
Iter: 2835 loss: 4.46892528e-07
Iter: 2836 loss: 4.46889686e-07
Iter: 2837 loss: 4.46791915e-07
Iter: 2838 loss: 4.46971171e-07
Iter: 2839 loss: 4.46704973e-07
Iter: 2840 loss: 4.46671066e-07
Iter: 2841 loss: 4.46594981e-07
Iter: 2842 loss: 4.46549336e-07
Iter: 2843 loss: 4.46646396e-07
Iter: 2844 loss: 4.46502384e-07
Iter: 2845 loss: 4.46485245e-07
Iter: 2846 loss: 4.46419165e-07
Iter: 2847 loss: 4.46404812e-07
Iter: 2848 loss: 4.46371558e-07
Iter: 2849 loss: 4.46438861e-07
Iter: 2850 loss: 4.46340863e-07
Iter: 2851 loss: 4.46273759e-07
Iter: 2852 loss: 4.46273759e-07
Iter: 2853 loss: 4.46247014e-07
Iter: 2854 loss: 4.46092457e-07
Iter: 2855 loss: 4.46395546e-07
Iter: 2856 loss: 4.46095441e-07
Iter: 2857 loss: 4.46028366e-07
Iter: 2858 loss: 4.46248094e-07
Iter: 2859 loss: 4.45935228e-07
Iter: 2860 loss: 4.45911439e-07
Iter: 2861 loss: 4.46482773e-07
Iter: 2862 loss: 4.45948842e-07
Iter: 2863 loss: 4.45897342e-07
Iter: 2864 loss: 4.45916243e-07
Iter: 2865 loss: 4.45915219e-07
Iter: 2866 loss: 4.45912491e-07
Iter: 2867 loss: 4.45922041e-07
Iter: 2868 loss: 4.45930823e-07
Iter: 2869 loss: 4.45925366e-07
Iter: 2870 loss: 4.45911894e-07
Iter: 2871 loss: 4.45928265e-07
Iter: 2872 loss: 4.45908427e-07
Iter: 2873 loss: 4.45912747e-07
Iter: 2874 loss: 4.45860223e-07
Iter: 2875 loss: 4.45770439e-07
Iter: 2876 loss: 4.45709702e-07
Iter: 2877 loss: 4.45661726e-07
Iter: 2878 loss: 4.46450258e-07
Iter: 2879 loss: 4.45590246e-07
Iter: 2880 loss: 4.45583396e-07
Iter: 2881 loss: 4.45546505e-07
Iter: 2882 loss: 4.45516946e-07
Iter: 2883 loss: 4.45463229e-07
Iter: 2884 loss: 4.45418948e-07
Iter: 2885 loss: 4.45356449e-07
Iter: 2886 loss: 4.46214813e-07
Iter: 2887 loss: 4.4537569e-07
Iter: 2888 loss: 4.45336241e-07
Iter: 2889 loss: 4.45634782e-07
Iter: 2890 loss: 4.4528943e-07
Iter: 2891 loss: 4.45265016e-07
Iter: 2892 loss: 4.45197202e-07
Iter: 2893 loss: 4.458212e-07
Iter: 2894 loss: 4.45179836e-07
Iter: 2895 loss: 4.45075699e-07
Iter: 2896 loss: 4.45728602e-07
Iter: 2897 loss: 4.45060209e-07
Iter: 2898 loss: 4.4496403e-07
Iter: 2899 loss: 4.44990974e-07
Iter: 2900 loss: 4.44939246e-07
Iter: 2901 loss: 4.44835166e-07
Iter: 2902 loss: 4.45094656e-07
Iter: 2903 loss: 4.44737566e-07
Iter: 2904 loss: 4.44651789e-07
Iter: 2905 loss: 4.4513439e-07
Iter: 2906 loss: 4.44669183e-07
Iter: 2907 loss: 4.44532702e-07
Iter: 2908 loss: 4.44733644e-07
Iter: 2909 loss: 4.44523238e-07
Iter: 2910 loss: 4.44439337e-07
Iter: 2911 loss: 4.44694649e-07
Iter: 2912 loss: 4.44411512e-07
Iter: 2913 loss: 4.44342447e-07
Iter: 2914 loss: 4.4448808e-07
Iter: 2915 loss: 4.44325394e-07
Iter: 2916 loss: 4.44224781e-07
Iter: 2917 loss: 4.44572834e-07
Iter: 2918 loss: 4.44200936e-07
Iter: 2919 loss: 4.44173565e-07
Iter: 2920 loss: 4.44424472e-07
Iter: 2921 loss: 4.44105751e-07
Iter: 2922 loss: 4.44087732e-07
Iter: 2923 loss: 4.44111635e-07
Iter: 2924 loss: 4.44085174e-07
Iter: 2925 loss: 4.44105893e-07
Iter: 2926 loss: 4.44070196e-07
Iter: 2927 loss: 4.44122691e-07
Iter: 2928 loss: 4.44127437e-07
Iter: 2929 loss: 4.44126783e-07
Iter: 2930 loss: 4.44102369e-07
Iter: 2931 loss: 4.44087874e-07
Iter: 2932 loss: 4.4411513e-07
Iter: 2933 loss: 4.44107229e-07
Iter: 2934 loss: 4.44116637e-07
Iter: 2935 loss: 4.44097736e-07
Iter: 2936 loss: 4.44111492e-07
Iter: 2937 loss: 4.44107485e-07
Iter: 2938 loss: 4.4410524e-07
Iter: 2939 loss: 4.44111549e-07
Iter: 2940 loss: 4.44108053e-07
Iter: 2941 loss: 4.44105183e-07
Iter: 2942 loss: 4.4410649e-07
Iter: 2943 loss: 4.44107e-07
Iter: 2944 loss: 4.44105666e-07
Iter: 2945 loss: 4.4410595e-07
Iter: 2946 loss: 4.44106e-07
Iter: 2947 loss: 4.44106831e-07
Iter: 2948 loss: 4.44106e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_4000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_4000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa9ffea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa9969d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47faac7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47faa30510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47faa302f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47faa4fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47faa4fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa90c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa90c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa8960d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa8a4268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa887ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa887f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa8be598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa7f3158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa7f31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa7f30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47fa7d20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f4a56268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f49acae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f49bd048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f495d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f497f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f498cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f4929378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f490ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f48e5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f490e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f48611e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f48920d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f488f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f484f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f4843598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47f47da9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47a8345268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f47a8369f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 7.85153e-06
Iter: 2 loss: 1.10200217e-05
Iter: 3 loss: 6.45723503e-06
Iter: 4 loss: 5.54595408e-06
Iter: 5 loss: 7.76566412e-06
Iter: 6 loss: 5.22093251e-06
Iter: 7 loss: 4.6888772e-06
Iter: 8 loss: 3.87811724e-06
Iter: 9 loss: 3.86390093e-06
Iter: 10 loss: 3.26282179e-06
Iter: 11 loss: 7.53630411e-06
Iter: 12 loss: 3.2094058e-06
Iter: 13 loss: 3.0534261e-06
Iter: 14 loss: 5.25573159e-06
Iter: 15 loss: 3.05310823e-06
Iter: 16 loss: 2.92462096e-06
Iter: 17 loss: 2.73977435e-06
Iter: 18 loss: 2.73402293e-06
Iter: 19 loss: 2.59888293e-06
Iter: 20 loss: 2.59873832e-06
Iter: 21 loss: 2.50518633e-06
Iter: 22 loss: 2.46935861e-06
Iter: 23 loss: 2.41830912e-06
Iter: 24 loss: 2.31474382e-06
Iter: 25 loss: 3.665451e-06
Iter: 26 loss: 2.31413833e-06
Iter: 27 loss: 2.25625581e-06
Iter: 28 loss: 2.47139815e-06
Iter: 29 loss: 2.24193855e-06
Iter: 30 loss: 2.17404386e-06
Iter: 31 loss: 2.13150633e-06
Iter: 32 loss: 2.10433063e-06
Iter: 33 loss: 2.03813511e-06
Iter: 34 loss: 2.27422788e-06
Iter: 35 loss: 2.02131332e-06
Iter: 36 loss: 2.00561317e-06
Iter: 37 loss: 1.98457974e-06
Iter: 38 loss: 1.95349321e-06
Iter: 39 loss: 1.88382933e-06
Iter: 40 loss: 2.84158045e-06
Iter: 41 loss: 1.8799808e-06
Iter: 42 loss: 1.84082785e-06
Iter: 43 loss: 2.14096235e-06
Iter: 44 loss: 1.83795123e-06
Iter: 45 loss: 1.8066047e-06
Iter: 46 loss: 1.77081688e-06
Iter: 47 loss: 1.76623234e-06
Iter: 48 loss: 1.73998387e-06
Iter: 49 loss: 1.73873241e-06
Iter: 50 loss: 1.72143962e-06
Iter: 51 loss: 1.72730074e-06
Iter: 52 loss: 1.7092201e-06
Iter: 53 loss: 1.68029567e-06
Iter: 54 loss: 1.69922532e-06
Iter: 55 loss: 1.66184634e-06
Iter: 56 loss: 1.6405678e-06
Iter: 57 loss: 1.72539455e-06
Iter: 58 loss: 1.63581808e-06
Iter: 59 loss: 1.61332014e-06
Iter: 60 loss: 1.68721829e-06
Iter: 61 loss: 1.60713353e-06
Iter: 62 loss: 1.59229558e-06
Iter: 63 loss: 1.73852038e-06
Iter: 64 loss: 1.59171395e-06
Iter: 65 loss: 1.58010641e-06
Iter: 66 loss: 1.58428622e-06
Iter: 67 loss: 1.57195859e-06
Iter: 68 loss: 1.55678129e-06
Iter: 69 loss: 1.62603374e-06
Iter: 70 loss: 1.55384373e-06
Iter: 71 loss: 1.54926204e-06
Iter: 72 loss: 1.54838096e-06
Iter: 73 loss: 1.54113513e-06
Iter: 74 loss: 1.52186476e-06
Iter: 75 loss: 1.66280608e-06
Iter: 76 loss: 1.51772815e-06
Iter: 77 loss: 1.50204232e-06
Iter: 78 loss: 1.56822216e-06
Iter: 79 loss: 1.49868083e-06
Iter: 80 loss: 1.48907213e-06
Iter: 81 loss: 1.47995718e-06
Iter: 82 loss: 1.4776158e-06
Iter: 83 loss: 1.46025434e-06
Iter: 84 loss: 1.68206952e-06
Iter: 85 loss: 1.46014327e-06
Iter: 86 loss: 1.45384888e-06
Iter: 87 loss: 1.4564614e-06
Iter: 88 loss: 1.44967282e-06
Iter: 89 loss: 1.44056776e-06
Iter: 90 loss: 1.47337528e-06
Iter: 91 loss: 1.43830982e-06
Iter: 92 loss: 1.42981844e-06
Iter: 93 loss: 1.45882063e-06
Iter: 94 loss: 1.42751537e-06
Iter: 95 loss: 1.42148372e-06
Iter: 96 loss: 1.41467319e-06
Iter: 97 loss: 1.4138634e-06
Iter: 98 loss: 1.40860755e-06
Iter: 99 loss: 1.40833708e-06
Iter: 100 loss: 1.40245015e-06
Iter: 101 loss: 1.39758481e-06
Iter: 102 loss: 1.39581471e-06
Iter: 103 loss: 1.38951566e-06
Iter: 104 loss: 1.48831452e-06
Iter: 105 loss: 1.38950088e-06
Iter: 106 loss: 1.38729524e-06
Iter: 107 loss: 1.38722578e-06
Iter: 108 loss: 1.38442124e-06
Iter: 109 loss: 1.37706604e-06
Iter: 110 loss: 1.43901241e-06
Iter: 111 loss: 1.37582742e-06
Iter: 112 loss: 1.37056736e-06
Iter: 113 loss: 1.38994608e-06
Iter: 114 loss: 1.36936683e-06
Iter: 115 loss: 1.36503752e-06
Iter: 116 loss: 1.35863411e-06
Iter: 117 loss: 1.35839514e-06
Iter: 118 loss: 1.34954951e-06
Iter: 119 loss: 1.4442935e-06
Iter: 120 loss: 1.34935897e-06
Iter: 121 loss: 1.34490972e-06
Iter: 122 loss: 1.37546226e-06
Iter: 123 loss: 1.34451898e-06
Iter: 124 loss: 1.33974834e-06
Iter: 125 loss: 1.33215144e-06
Iter: 126 loss: 1.33209596e-06
Iter: 127 loss: 1.32892922e-06
Iter: 128 loss: 1.32857895e-06
Iter: 129 loss: 1.32512014e-06
Iter: 130 loss: 1.32012872e-06
Iter: 131 loss: 1.31989452e-06
Iter: 132 loss: 1.31537354e-06
Iter: 133 loss: 1.36799486e-06
Iter: 134 loss: 1.31534557e-06
Iter: 135 loss: 1.31241507e-06
Iter: 136 loss: 1.30961621e-06
Iter: 137 loss: 1.30902731e-06
Iter: 138 loss: 1.30622072e-06
Iter: 139 loss: 1.30577359e-06
Iter: 140 loss: 1.30448348e-06
Iter: 141 loss: 1.3045094e-06
Iter: 142 loss: 1.30292051e-06
Iter: 143 loss: 1.29879732e-06
Iter: 144 loss: 1.33094954e-06
Iter: 145 loss: 1.29803675e-06
Iter: 146 loss: 1.29313776e-06
Iter: 147 loss: 1.29304112e-06
Iter: 148 loss: 1.2891926e-06
Iter: 149 loss: 1.28453826e-06
Iter: 150 loss: 1.31253614e-06
Iter: 151 loss: 1.28396778e-06
Iter: 152 loss: 1.27900739e-06
Iter: 153 loss: 1.28142597e-06
Iter: 154 loss: 1.27579369e-06
Iter: 155 loss: 1.27228532e-06
Iter: 156 loss: 1.30634908e-06
Iter: 157 loss: 1.27216708e-06
Iter: 158 loss: 1.26922032e-06
Iter: 159 loss: 1.27733153e-06
Iter: 160 loss: 1.26825262e-06
Iter: 161 loss: 1.26555574e-06
Iter: 162 loss: 1.28218403e-06
Iter: 163 loss: 1.26514237e-06
Iter: 164 loss: 1.26339864e-06
Iter: 165 loss: 1.26077407e-06
Iter: 166 loss: 1.26072359e-06
Iter: 167 loss: 1.2568878e-06
Iter: 168 loss: 1.28855e-06
Iter: 169 loss: 1.25657664e-06
Iter: 170 loss: 1.25457484e-06
Iter: 171 loss: 1.26538043e-06
Iter: 172 loss: 1.2542165e-06
Iter: 173 loss: 1.25227484e-06
Iter: 174 loss: 1.25330166e-06
Iter: 175 loss: 1.25092356e-06
Iter: 176 loss: 1.25184829e-06
Iter: 177 loss: 1.25001839e-06
Iter: 178 loss: 1.24959e-06
Iter: 179 loss: 1.24842677e-06
Iter: 180 loss: 1.25416545e-06
Iter: 181 loss: 1.24809196e-06
Iter: 182 loss: 1.24593964e-06
Iter: 183 loss: 1.24531584e-06
Iter: 184 loss: 1.24403277e-06
Iter: 185 loss: 1.24149165e-06
Iter: 186 loss: 1.25467204e-06
Iter: 187 loss: 1.24106714e-06
Iter: 188 loss: 1.23901827e-06
Iter: 189 loss: 1.23656059e-06
Iter: 190 loss: 1.23630639e-06
Iter: 191 loss: 1.2337091e-06
Iter: 192 loss: 1.26220061e-06
Iter: 193 loss: 1.23368409e-06
Iter: 194 loss: 1.23136783e-06
Iter: 195 loss: 1.2328062e-06
Iter: 196 loss: 1.22996357e-06
Iter: 197 loss: 1.22741312e-06
Iter: 198 loss: 1.22740914e-06
Iter: 199 loss: 1.22623499e-06
Iter: 200 loss: 1.22385416e-06
Iter: 201 loss: 1.26807697e-06
Iter: 202 loss: 1.22381493e-06
Iter: 203 loss: 1.22118877e-06
Iter: 204 loss: 1.26018415e-06
Iter: 205 loss: 1.22118308e-06
Iter: 206 loss: 1.21986761e-06
Iter: 207 loss: 1.22225674e-06
Iter: 208 loss: 1.21932408e-06
Iter: 209 loss: 1.21796415e-06
Iter: 210 loss: 1.22582617e-06
Iter: 211 loss: 1.21778021e-06
Iter: 212 loss: 1.21626556e-06
Iter: 213 loss: 1.22924064e-06
Iter: 214 loss: 1.21616915e-06
Iter: 215 loss: 1.21558071e-06
Iter: 216 loss: 1.21444157e-06
Iter: 217 loss: 1.24232054e-06
Iter: 218 loss: 1.21439905e-06
Iter: 219 loss: 1.21299649e-06
Iter: 220 loss: 1.21138851e-06
Iter: 221 loss: 1.2111027e-06
Iter: 222 loss: 1.20867571e-06
Iter: 223 loss: 1.23591497e-06
Iter: 224 loss: 1.20866946e-06
Iter: 225 loss: 1.20712275e-06
Iter: 226 loss: 1.20563368e-06
Iter: 227 loss: 1.20535253e-06
Iter: 228 loss: 1.2025987e-06
Iter: 229 loss: 1.21610469e-06
Iter: 230 loss: 1.20209643e-06
Iter: 231 loss: 1.20013942e-06
Iter: 232 loss: 1.19922765e-06
Iter: 233 loss: 1.19824244e-06
Iter: 234 loss: 1.1948116e-06
Iter: 235 loss: 1.21552137e-06
Iter: 236 loss: 1.19435617e-06
Iter: 237 loss: 1.19223955e-06
Iter: 238 loss: 1.20006462e-06
Iter: 239 loss: 1.19168135e-06
Iter: 240 loss: 1.18907167e-06
Iter: 241 loss: 1.20047844e-06
Iter: 242 loss: 1.18856701e-06
Iter: 243 loss: 1.18714468e-06
Iter: 244 loss: 1.18836942e-06
Iter: 245 loss: 1.18623598e-06
Iter: 246 loss: 1.18446394e-06
Iter: 247 loss: 1.18903722e-06
Iter: 248 loss: 1.18382422e-06
Iter: 249 loss: 1.18411742e-06
Iter: 250 loss: 1.18296134e-06
Iter: 251 loss: 1.18251637e-06
Iter: 252 loss: 1.18157243e-06
Iter: 253 loss: 1.19789433e-06
Iter: 254 loss: 1.18166258e-06
Iter: 255 loss: 1.18038429e-06
Iter: 256 loss: 1.17918739e-06
Iter: 257 loss: 1.17902709e-06
Iter: 258 loss: 1.17751597e-06
Iter: 259 loss: 1.18753144e-06
Iter: 260 loss: 1.17731588e-06
Iter: 261 loss: 1.1759771e-06
Iter: 262 loss: 1.17854438e-06
Iter: 263 loss: 1.17542413e-06
Iter: 264 loss: 1.17351965e-06
Iter: 265 loss: 1.1743025e-06
Iter: 266 loss: 1.17224772e-06
Iter: 267 loss: 1.17058687e-06
Iter: 268 loss: 1.17140212e-06
Iter: 269 loss: 1.16968715e-06
Iter: 270 loss: 1.16729757e-06
Iter: 271 loss: 1.18242372e-06
Iter: 272 loss: 1.16704064e-06
Iter: 273 loss: 1.16558533e-06
Iter: 274 loss: 1.1692282e-06
Iter: 275 loss: 1.16512047e-06
Iter: 276 loss: 1.16345552e-06
Iter: 277 loss: 1.16885622e-06
Iter: 278 loss: 1.1629694e-06
Iter: 279 loss: 1.16182707e-06
Iter: 280 loss: 1.17217405e-06
Iter: 281 loss: 1.16182423e-06
Iter: 282 loss: 1.16071567e-06
Iter: 283 loss: 1.1601901e-06
Iter: 284 loss: 1.15978025e-06
Iter: 285 loss: 1.16015121e-06
Iter: 286 loss: 1.15925309e-06
Iter: 287 loss: 1.15881392e-06
Iter: 288 loss: 1.15776231e-06
Iter: 289 loss: 1.17406978e-06
Iter: 290 loss: 1.15765715e-06
Iter: 291 loss: 1.15668922e-06
Iter: 292 loss: 1.15498597e-06
Iter: 293 loss: 1.15500347e-06
Iter: 294 loss: 1.15402349e-06
Iter: 295 loss: 1.15393459e-06
Iter: 296 loss: 1.15302737e-06
Iter: 297 loss: 1.15299292e-06
Iter: 298 loss: 1.15221496e-06
Iter: 299 loss: 1.15087676e-06
Iter: 300 loss: 1.15494106e-06
Iter: 301 loss: 1.15051853e-06
Iter: 302 loss: 1.14939894e-06
Iter: 303 loss: 1.15644298e-06
Iter: 304 loss: 1.14926627e-06
Iter: 305 loss: 1.14835734e-06
Iter: 306 loss: 1.1473611e-06
Iter: 307 loss: 1.14718591e-06
Iter: 308 loss: 1.14579211e-06
Iter: 309 loss: 1.15355272e-06
Iter: 310 loss: 1.14551733e-06
Iter: 311 loss: 1.14411182e-06
Iter: 312 loss: 1.14363445e-06
Iter: 313 loss: 1.14283318e-06
Iter: 314 loss: 1.14132206e-06
Iter: 315 loss: 1.1584674e-06
Iter: 316 loss: 1.14126215e-06
Iter: 317 loss: 1.13986198e-06
Iter: 318 loss: 1.14480531e-06
Iter: 319 loss: 1.13952319e-06
Iter: 320 loss: 1.13845704e-06
Iter: 321 loss: 1.14307863e-06
Iter: 322 loss: 1.13829128e-06
Iter: 323 loss: 1.13827014e-06
Iter: 324 loss: 1.13792271e-06
Iter: 325 loss: 1.13771534e-06
Iter: 326 loss: 1.13687588e-06
Iter: 327 loss: 1.1363943e-06
Iter: 328 loss: 1.13592125e-06
Iter: 329 loss: 1.13484793e-06
Iter: 330 loss: 1.15002899e-06
Iter: 331 loss: 1.13479302e-06
Iter: 332 loss: 1.13401416e-06
Iter: 333 loss: 1.13400142e-06
Iter: 334 loss: 1.13334886e-06
Iter: 335 loss: 1.13246142e-06
Iter: 336 loss: 1.13841838e-06
Iter: 337 loss: 1.13237047e-06
Iter: 338 loss: 1.13160468e-06
Iter: 339 loss: 1.13182887e-06
Iter: 340 loss: 1.13105489e-06
Iter: 341 loss: 1.13022656e-06
Iter: 342 loss: 1.14253294e-06
Iter: 343 loss: 1.13030569e-06
Iter: 344 loss: 1.12964267e-06
Iter: 345 loss: 1.12896839e-06
Iter: 346 loss: 1.12886e-06
Iter: 347 loss: 1.12772227e-06
Iter: 348 loss: 1.13065778e-06
Iter: 349 loss: 1.12742759e-06
Iter: 350 loss: 1.12653242e-06
Iter: 351 loss: 1.13770784e-06
Iter: 352 loss: 1.12645466e-06
Iter: 353 loss: 1.12576265e-06
Iter: 354 loss: 1.12542705e-06
Iter: 355 loss: 1.12508019e-06
Iter: 356 loss: 1.12499868e-06
Iter: 357 loss: 1.12472026e-06
Iter: 358 loss: 1.12428711e-06
Iter: 359 loss: 1.12327973e-06
Iter: 360 loss: 1.13800274e-06
Iter: 361 loss: 1.1231939e-06
Iter: 362 loss: 1.12214457e-06
Iter: 363 loss: 1.12452608e-06
Iter: 364 loss: 1.12170835e-06
Iter: 365 loss: 1.12086423e-06
Iter: 366 loss: 1.12179896e-06
Iter: 367 loss: 1.1203997e-06
Iter: 368 loss: 1.11922759e-06
Iter: 369 loss: 1.11795111e-06
Iter: 370 loss: 1.11770316e-06
Iter: 371 loss: 1.11664463e-06
Iter: 372 loss: 1.11665281e-06
Iter: 373 loss: 1.11567306e-06
Iter: 374 loss: 1.11664986e-06
Iter: 375 loss: 1.11520012e-06
Iter: 376 loss: 1.11424322e-06
Iter: 377 loss: 1.11739269e-06
Iter: 378 loss: 1.11398992e-06
Iter: 379 loss: 1.11296856e-06
Iter: 380 loss: 1.11456006e-06
Iter: 381 loss: 1.11248357e-06
Iter: 382 loss: 1.11165502e-06
Iter: 383 loss: 1.12372607e-06
Iter: 384 loss: 1.11168231e-06
Iter: 385 loss: 1.11113388e-06
Iter: 386 loss: 1.11030101e-06
Iter: 387 loss: 1.11024133e-06
Iter: 388 loss: 1.10925112e-06
Iter: 389 loss: 1.11654276e-06
Iter: 390 loss: 1.10921223e-06
Iter: 391 loss: 1.10863766e-06
Iter: 392 loss: 1.11645988e-06
Iter: 393 loss: 1.10867734e-06
Iter: 394 loss: 1.10799544e-06
Iter: 395 loss: 1.11007444e-06
Iter: 396 loss: 1.10785084e-06
Iter: 397 loss: 1.10741348e-06
Iter: 398 loss: 1.10734334e-06
Iter: 399 loss: 1.10711551e-06
Iter: 400 loss: 1.10671556e-06
Iter: 401 loss: 1.10591304e-06
Iter: 402 loss: 1.10596284e-06
Iter: 403 loss: 1.10518795e-06
Iter: 404 loss: 1.11214331e-06
Iter: 405 loss: 1.10504743e-06
Iter: 406 loss: 1.10452265e-06
Iter: 407 loss: 1.10822532e-06
Iter: 408 loss: 1.10444284e-06
Iter: 409 loss: 1.10389215e-06
Iter: 410 loss: 1.10321628e-06
Iter: 411 loss: 1.10315455e-06
Iter: 412 loss: 1.10230258e-06
Iter: 413 loss: 1.10527594e-06
Iter: 414 loss: 1.10201165e-06
Iter: 415 loss: 1.10098824e-06
Iter: 416 loss: 1.10163433e-06
Iter: 417 loss: 1.10027486e-06
Iter: 418 loss: 1.09937423e-06
Iter: 419 loss: 1.10749806e-06
Iter: 420 loss: 1.09929738e-06
Iter: 421 loss: 1.09837345e-06
Iter: 422 loss: 1.09813027e-06
Iter: 423 loss: 1.09757991e-06
Iter: 424 loss: 1.09699829e-06
Iter: 425 loss: 1.09694611e-06
Iter: 426 loss: 1.09669429e-06
Iter: 427 loss: 1.0966645e-06
Iter: 428 loss: 1.09632128e-06
Iter: 429 loss: 1.09571715e-06
Iter: 430 loss: 1.10842575e-06
Iter: 431 loss: 1.09575467e-06
Iter: 432 loss: 1.09517509e-06
Iter: 433 loss: 1.09562939e-06
Iter: 434 loss: 1.09475081e-06
Iter: 435 loss: 1.09396956e-06
Iter: 436 loss: 1.09487655e-06
Iter: 437 loss: 1.09349776e-06
Iter: 438 loss: 1.09258895e-06
Iter: 439 loss: 1.0967949e-06
Iter: 440 loss: 1.09239488e-06
Iter: 441 loss: 1.09176619e-06
Iter: 442 loss: 1.09172856e-06
Iter: 443 loss: 1.09104826e-06
Iter: 444 loss: 1.09006737e-06
Iter: 445 loss: 1.09688744e-06
Iter: 446 loss: 1.08994743e-06
Iter: 447 loss: 1.08927134e-06
Iter: 448 loss: 1.09288919e-06
Iter: 449 loss: 1.08916947e-06
Iter: 450 loss: 1.08850543e-06
Iter: 451 loss: 1.0875815e-06
Iter: 452 loss: 1.08759502e-06
Iter: 453 loss: 1.08660538e-06
Iter: 454 loss: 1.09431517e-06
Iter: 455 loss: 1.08655479e-06
Iter: 456 loss: 1.08564473e-06
Iter: 457 loss: 1.08644906e-06
Iter: 458 loss: 1.08517327e-06
Iter: 459 loss: 1.08515974e-06
Iter: 460 loss: 1.08480481e-06
Iter: 461 loss: 1.08438553e-06
Iter: 462 loss: 1.08342101e-06
Iter: 463 loss: 1.10023439e-06
Iter: 464 loss: 1.08342942e-06
Iter: 465 loss: 1.08277368e-06
Iter: 466 loss: 1.08579184e-06
Iter: 467 loss: 1.08269796e-06
Iter: 468 loss: 1.08208974e-06
Iter: 469 loss: 1.08174368e-06
Iter: 470 loss: 1.08155314e-06
Iter: 471 loss: 1.08052177e-06
Iter: 472 loss: 1.08508789e-06
Iter: 473 loss: 1.08042616e-06
Iter: 474 loss: 1.07982464e-06
Iter: 475 loss: 1.08156701e-06
Iter: 476 loss: 1.07953269e-06
Iter: 477 loss: 1.07880498e-06
Iter: 478 loss: 1.07964252e-06
Iter: 479 loss: 1.07842754e-06
Iter: 480 loss: 1.07773758e-06
Iter: 481 loss: 1.08485358e-06
Iter: 482 loss: 1.07769893e-06
Iter: 483 loss: 1.07714459e-06
Iter: 484 loss: 1.07629148e-06
Iter: 485 loss: 1.07625806e-06
Iter: 486 loss: 1.07534061e-06
Iter: 487 loss: 1.08798963e-06
Iter: 488 loss: 1.07525614e-06
Iter: 489 loss: 1.07465303e-06
Iter: 490 loss: 1.07597089e-06
Iter: 491 loss: 1.07451638e-06
Iter: 492 loss: 1.0737408e-06
Iter: 493 loss: 1.07390645e-06
Iter: 494 loss: 1.07316214e-06
Iter: 495 loss: 1.07241476e-06
Iter: 496 loss: 1.07385449e-06
Iter: 497 loss: 1.0720953e-06
Iter: 498 loss: 1.07230107e-06
Iter: 499 loss: 1.07162782e-06
Iter: 500 loss: 1.07146843e-06
Iter: 501 loss: 1.07089522e-06
Iter: 502 loss: 1.07577102e-06
Iter: 503 loss: 1.0708136e-06
Iter: 504 loss: 1.0704448e-06
Iter: 505 loss: 1.07138953e-06
Iter: 506 loss: 1.07022186e-06
Iter: 507 loss: 1.06964239e-06
Iter: 508 loss: 1.06983839e-06
Iter: 509 loss: 1.06914081e-06
Iter: 510 loss: 1.06861114e-06
Iter: 511 loss: 1.07185713e-06
Iter: 512 loss: 1.0685194e-06
Iter: 513 loss: 1.06786342e-06
Iter: 514 loss: 1.06784921e-06
Iter: 515 loss: 1.06745267e-06
Iter: 516 loss: 1.0668266e-06
Iter: 517 loss: 1.07532981e-06
Iter: 518 loss: 1.06680341e-06
Iter: 519 loss: 1.06649532e-06
Iter: 520 loss: 1.06581274e-06
Iter: 521 loss: 1.06574066e-06
Iter: 522 loss: 1.06495668e-06
Iter: 523 loss: 1.06948801e-06
Iter: 524 loss: 1.06488756e-06
Iter: 525 loss: 1.0645017e-06
Iter: 526 loss: 1.0665434e-06
Iter: 527 loss: 1.06435778e-06
Iter: 528 loss: 1.06386699e-06
Iter: 529 loss: 1.06408095e-06
Iter: 530 loss: 1.06365292e-06
Iter: 531 loss: 1.06337291e-06
Iter: 532 loss: 1.06328264e-06
Iter: 533 loss: 1.06292305e-06
Iter: 534 loss: 1.06267464e-06
Iter: 535 loss: 1.06256118e-06
Iter: 536 loss: 1.06224195e-06
Iter: 537 loss: 1.06162861e-06
Iter: 538 loss: 1.07478627e-06
Iter: 539 loss: 1.06169557e-06
Iter: 540 loss: 1.06088396e-06
Iter: 541 loss: 1.06505684e-06
Iter: 542 loss: 1.06083075e-06
Iter: 543 loss: 1.06010589e-06
Iter: 544 loss: 1.06259813e-06
Iter: 545 loss: 1.05990057e-06
Iter: 546 loss: 1.05944991e-06
Iter: 547 loss: 1.05981837e-06
Iter: 548 loss: 1.05919582e-06
Iter: 549 loss: 1.05846993e-06
Iter: 550 loss: 1.06019843e-06
Iter: 551 loss: 1.0582055e-06
Iter: 552 loss: 1.05768925e-06
Iter: 553 loss: 1.06275218e-06
Iter: 554 loss: 1.05763593e-06
Iter: 555 loss: 1.05719585e-06
Iter: 556 loss: 1.05671802e-06
Iter: 557 loss: 1.05657773e-06
Iter: 558 loss: 1.05597519e-06
Iter: 559 loss: 1.05979097e-06
Iter: 560 loss: 1.05581955e-06
Iter: 561 loss: 1.05533434e-06
Iter: 562 loss: 1.05577374e-06
Iter: 563 loss: 1.05499794e-06
Iter: 564 loss: 1.05472282e-06
Iter: 565 loss: 1.05466052e-06
Iter: 566 loss: 1.05433514e-06
Iter: 567 loss: 1.05634979e-06
Iter: 568 loss: 1.05437903e-06
Iter: 569 loss: 1.05428262e-06
Iter: 570 loss: 1.05393758e-06
Iter: 571 loss: 1.05668664e-06
Iter: 572 loss: 1.05389381e-06
Iter: 573 loss: 1.05321942e-06
Iter: 574 loss: 1.05321521e-06
Iter: 575 loss: 1.05276217e-06
Iter: 576 loss: 1.05227809e-06
Iter: 577 loss: 1.05488971e-06
Iter: 578 loss: 1.05221318e-06
Iter: 579 loss: 1.05161735e-06
Iter: 580 loss: 1.05186041e-06
Iter: 581 loss: 1.05120489e-06
Iter: 582 loss: 1.05065612e-06
Iter: 583 loss: 1.05443405e-06
Iter: 584 loss: 1.050577e-06
Iter: 585 loss: 1.04997775e-06
Iter: 586 loss: 1.05288927e-06
Iter: 587 loss: 1.04995434e-06
Iter: 588 loss: 1.04953028e-06
Iter: 589 loss: 1.05018523e-06
Iter: 590 loss: 1.04934838e-06
Iter: 591 loss: 1.04883566e-06
Iter: 592 loss: 1.04881087e-06
Iter: 593 loss: 1.04839364e-06
Iter: 594 loss: 1.04784317e-06
Iter: 595 loss: 1.05277991e-06
Iter: 596 loss: 1.04779451e-06
Iter: 597 loss: 1.04740127e-06
Iter: 598 loss: 1.047718e-06
Iter: 599 loss: 1.0472188e-06
Iter: 600 loss: 1.04689275e-06
Iter: 601 loss: 1.04682613e-06
Iter: 602 loss: 1.04660307e-06
Iter: 603 loss: 1.04635149e-06
Iter: 604 loss: 1.04623291e-06
Iter: 605 loss: 1.04594801e-06
Iter: 606 loss: 1.04529659e-06
Iter: 607 loss: 1.05898425e-06
Iter: 608 loss: 1.0452793e-06
Iter: 609 loss: 1.04473406e-06
Iter: 610 loss: 1.05187087e-06
Iter: 611 loss: 1.04475362e-06
Iter: 612 loss: 1.04434355e-06
Iter: 613 loss: 1.04379069e-06
Iter: 614 loss: 1.0437667e-06
Iter: 615 loss: 1.04291007e-06
Iter: 616 loss: 1.05118784e-06
Iter: 617 loss: 1.04295736e-06
Iter: 618 loss: 1.0425922e-06
Iter: 619 loss: 1.04250398e-06
Iter: 620 loss: 1.04215781e-06
Iter: 621 loss: 1.04157346e-06
Iter: 622 loss: 1.04421565e-06
Iter: 623 loss: 1.04142418e-06
Iter: 624 loss: 1.04090759e-06
Iter: 625 loss: 1.04523065e-06
Iter: 626 loss: 1.04093272e-06
Iter: 627 loss: 1.04049536e-06
Iter: 628 loss: 1.04004562e-06
Iter: 629 loss: 1.03996899e-06
Iter: 630 loss: 1.03940863e-06
Iter: 631 loss: 1.04105152e-06
Iter: 632 loss: 1.03916818e-06
Iter: 633 loss: 1.03891307e-06
Iter: 634 loss: 1.03885429e-06
Iter: 635 loss: 1.03844036e-06
Iter: 636 loss: 1.03817069e-06
Iter: 637 loss: 1.0380104e-06
Iter: 638 loss: 1.0376491e-06
Iter: 639 loss: 1.03784282e-06
Iter: 640 loss: 1.03740047e-06
Iter: 641 loss: 1.03695527e-06
Iter: 642 loss: 1.03690581e-06
Iter: 643 loss: 1.0366166e-06
Iter: 644 loss: 1.03602702e-06
Iter: 645 loss: 1.03974514e-06
Iter: 646 loss: 1.03603668e-06
Iter: 647 loss: 1.03557045e-06
Iter: 648 loss: 1.03503817e-06
Iter: 649 loss: 1.03494494e-06
Iter: 650 loss: 1.03424236e-06
Iter: 651 loss: 1.04305707e-06
Iter: 652 loss: 1.03419893e-06
Iter: 653 loss: 1.03380933e-06
Iter: 654 loss: 1.03487548e-06
Iter: 655 loss: 1.03369598e-06
Iter: 656 loss: 1.03307229e-06
Iter: 657 loss: 1.03328023e-06
Iter: 658 loss: 1.03274897e-06
Iter: 659 loss: 1.03224897e-06
Iter: 660 loss: 1.03708976e-06
Iter: 661 loss: 1.03228501e-06
Iter: 662 loss: 1.03193588e-06
Iter: 663 loss: 1.03212665e-06
Iter: 664 loss: 1.03168281e-06
Iter: 665 loss: 1.03115758e-06
Iter: 666 loss: 1.03287562e-06
Iter: 667 loss: 1.03103116e-06
Iter: 668 loss: 1.03098751e-06
Iter: 669 loss: 1.03090929e-06
Iter: 670 loss: 1.03066918e-06
Iter: 671 loss: 1.03018795e-06
Iter: 672 loss: 1.03222283e-06
Iter: 673 loss: 1.02993795e-06
Iter: 674 loss: 1.02951185e-06
Iter: 675 loss: 1.03091679e-06
Iter: 676 loss: 1.02927402e-06
Iter: 677 loss: 1.02878892e-06
Iter: 678 loss: 1.02925719e-06
Iter: 679 loss: 1.02842273e-06
Iter: 680 loss: 1.02796673e-06
Iter: 681 loss: 1.02798674e-06
Iter: 682 loss: 1.02766626e-06
Iter: 683 loss: 1.02696356e-06
Iter: 684 loss: 1.03677269e-06
Iter: 685 loss: 1.02690387e-06
Iter: 686 loss: 1.02636841e-06
Iter: 687 loss: 1.03350817e-06
Iter: 688 loss: 1.02633282e-06
Iter: 689 loss: 1.02586716e-06
Iter: 690 loss: 1.02752529e-06
Iter: 691 loss: 1.02571096e-06
Iter: 692 loss: 1.02530748e-06
Iter: 693 loss: 1.02572039e-06
Iter: 694 loss: 1.02512683e-06
Iter: 695 loss: 1.0247511e-06
Iter: 696 loss: 1.02699471e-06
Iter: 697 loss: 1.02461422e-06
Iter: 698 loss: 1.02419642e-06
Iter: 699 loss: 1.0242295e-06
Iter: 700 loss: 1.02386207e-06
Iter: 701 loss: 1.02357797e-06
Iter: 702 loss: 1.02357239e-06
Iter: 703 loss: 1.02331137e-06
Iter: 704 loss: 1.0238083e-06
Iter: 705 loss: 1.02310275e-06
Iter: 706 loss: 1.02291142e-06
Iter: 707 loss: 1.02234e-06
Iter: 708 loss: 1.03135199e-06
Iter: 709 loss: 1.02230547e-06
Iter: 710 loss: 1.02190552e-06
Iter: 711 loss: 1.02371359e-06
Iter: 712 loss: 1.02181662e-06
Iter: 713 loss: 1.02137187e-06
Iter: 714 loss: 1.02172021e-06
Iter: 715 loss: 1.02111574e-06
Iter: 716 loss: 1.02073409e-06
Iter: 717 loss: 1.02071658e-06
Iter: 718 loss: 1.02039235e-06
Iter: 719 loss: 1.01974979e-06
Iter: 720 loss: 1.03067714e-06
Iter: 721 loss: 1.01971659e-06
Iter: 722 loss: 1.01898036e-06
Iter: 723 loss: 1.0245883e-06
Iter: 724 loss: 1.01888202e-06
Iter: 725 loss: 1.01839044e-06
Iter: 726 loss: 1.01931914e-06
Iter: 727 loss: 1.01816102e-06
Iter: 728 loss: 1.01763601e-06
Iter: 729 loss: 1.02145566e-06
Iter: 730 loss: 1.01757132e-06
Iter: 731 loss: 1.01720764e-06
Iter: 732 loss: 1.01772378e-06
Iter: 733 loss: 1.0169922e-06
Iter: 734 loss: 1.01670457e-06
Iter: 735 loss: 1.01967316e-06
Iter: 736 loss: 1.01674595e-06
Iter: 737 loss: 1.01641695e-06
Iter: 738 loss: 1.01813976e-06
Iter: 739 loss: 1.01643832e-06
Iter: 740 loss: 1.01623596e-06
Iter: 741 loss: 1.01616604e-06
Iter: 742 loss: 1.01604792e-06
Iter: 743 loss: 1.015826e-06
Iter: 744 loss: 1.0153824e-06
Iter: 745 loss: 1.02487911e-06
Iter: 746 loss: 1.01536e-06
Iter: 747 loss: 1.01479213e-06
Iter: 748 loss: 1.01903606e-06
Iter: 749 loss: 1.01478247e-06
Iter: 750 loss: 1.01432113e-06
Iter: 751 loss: 1.01444618e-06
Iter: 752 loss: 1.01404817e-06
Iter: 753 loss: 1.0134479e-06
Iter: 754 loss: 1.01503542e-06
Iter: 755 loss: 1.0132137e-06
Iter: 756 loss: 1.01273054e-06
Iter: 757 loss: 1.012947e-06
Iter: 758 loss: 1.01244029e-06
Iter: 759 loss: 1.01198134e-06
Iter: 760 loss: 1.01201067e-06
Iter: 761 loss: 1.01160106e-06
Iter: 762 loss: 1.01143735e-06
Iter: 763 loss: 1.01138437e-06
Iter: 764 loss: 1.0107151e-06
Iter: 765 loss: 1.01094747e-06
Iter: 766 loss: 1.01026467e-06
Iter: 767 loss: 1.01003661e-06
Iter: 768 loss: 1.00994146e-06
Iter: 769 loss: 1.00963598e-06
Iter: 770 loss: 1.01195178e-06
Iter: 771 loss: 1.00963518e-06
Iter: 772 loss: 1.00934278e-06
Iter: 773 loss: 1.00900547e-06
Iter: 774 loss: 1.00893658e-06
Iter: 775 loss: 1.00846626e-06
Iter: 776 loss: 1.00913735e-06
Iter: 777 loss: 1.00842794e-06
Iter: 778 loss: 1.00792715e-06
Iter: 779 loss: 1.0078237e-06
Iter: 780 loss: 1.00751606e-06
Iter: 781 loss: 1.00699947e-06
Iter: 782 loss: 1.01293858e-06
Iter: 783 loss: 1.00701141e-06
Iter: 784 loss: 1.00666682e-06
Iter: 785 loss: 1.00649436e-06
Iter: 786 loss: 1.00637806e-06
Iter: 787 loss: 1.00578802e-06
Iter: 788 loss: 1.00890975e-06
Iter: 789 loss: 1.00568832e-06
Iter: 790 loss: 1.00538568e-06
Iter: 791 loss: 1.00656337e-06
Iter: 792 loss: 1.00523596e-06
Iter: 793 loss: 1.00475472e-06
Iter: 794 loss: 1.00425245e-06
Iter: 795 loss: 1.00417401e-06
Iter: 796 loss: 1.00363343e-06
Iter: 797 loss: 1.00831812e-06
Iter: 798 loss: 1.0036008e-06
Iter: 799 loss: 1.00311684e-06
Iter: 800 loss: 1.00516945e-06
Iter: 801 loss: 1.00297621e-06
Iter: 802 loss: 1.00260422e-06
Iter: 803 loss: 1.00259899e-06
Iter: 804 loss: 1.00226384e-06
Iter: 805 loss: 1.00392299e-06
Iter: 806 loss: 1.0022361e-06
Iter: 807 loss: 1.00209684e-06
Iter: 808 loss: 1.00171326e-06
Iter: 809 loss: 1.00186037e-06
Iter: 810 loss: 1.00134434e-06
Iter: 811 loss: 1.0007966e-06
Iter: 812 loss: 1.00959687e-06
Iter: 813 loss: 1.00083355e-06
Iter: 814 loss: 1.00047782e-06
Iter: 815 loss: 1.00173293e-06
Iter: 816 loss: 1.00024442e-06
Iter: 817 loss: 9.99805138e-07
Iter: 818 loss: 9.99907456e-07
Iter: 819 loss: 9.99535587e-07
Iter: 820 loss: 9.99110284e-07
Iter: 821 loss: 1.00063221e-06
Iter: 822 loss: 9.98941914e-07
Iter: 823 loss: 9.98471251e-07
Iter: 824 loss: 9.99891768e-07
Iter: 825 loss: 9.98372116e-07
Iter: 826 loss: 9.98001e-07
Iter: 827 loss: 9.99035478e-07
Iter: 828 loss: 9.97883149e-07
Iter: 829 loss: 9.97358484e-07
Iter: 830 loss: 9.97629e-07
Iter: 831 loss: 9.97046527e-07
Iter: 832 loss: 9.96512654e-07
Iter: 833 loss: 1.00208979e-06
Iter: 834 loss: 9.96544486e-07
Iter: 835 loss: 9.96187e-07
Iter: 836 loss: 9.95740265e-07
Iter: 837 loss: 1.00658372e-06
Iter: 838 loss: 9.95751e-07
Iter: 839 loss: 9.95826e-07
Iter: 840 loss: 9.95469236e-07
Iter: 841 loss: 9.95256073e-07
Iter: 842 loss: 9.97132e-07
Iter: 843 loss: 9.95202868e-07
Iter: 844 loss: 9.95165806e-07
Iter: 845 loss: 9.94912625e-07
Iter: 846 loss: 9.95001415e-07
Iter: 847 loss: 9.9464819e-07
Iter: 848 loss: 9.94112e-07
Iter: 849 loss: 9.97396e-07
Iter: 850 loss: 9.94114316e-07
Iter: 851 loss: 9.93808158e-07
Iter: 852 loss: 9.94364427e-07
Iter: 853 loss: 9.93690492e-07
Iter: 854 loss: 9.93193794e-07
Iter: 855 loss: 9.9349063e-07
Iter: 856 loss: 9.92881e-07
Iter: 857 loss: 9.92411174e-07
Iter: 858 loss: 9.95836899e-07
Iter: 859 loss: 9.92387e-07
Iter: 860 loss: 9.92018727e-07
Iter: 861 loss: 9.91393222e-07
Iter: 862 loss: 1.00356056e-06
Iter: 863 loss: 9.91329e-07
Iter: 864 loss: 9.91024422e-07
Iter: 865 loss: 9.90937906e-07
Iter: 866 loss: 9.90674e-07
Iter: 867 loss: 9.90276703e-07
Iter: 868 loss: 9.90223498e-07
Iter: 869 loss: 9.89746923e-07
Iter: 870 loss: 9.93066237e-07
Iter: 871 loss: 9.89690307e-07
Iter: 872 loss: 9.89256e-07
Iter: 873 loss: 9.90252374e-07
Iter: 874 loss: 9.89183491e-07
Iter: 875 loss: 9.88898591e-07
Iter: 876 loss: 9.88886541e-07
Iter: 877 loss: 9.88720444e-07
Iter: 878 loss: 9.88413831e-07
Iter: 879 loss: 9.88380179e-07
Iter: 880 loss: 9.8808539e-07
Iter: 881 loss: 9.88967599e-07
Iter: 882 loss: 9.87927933e-07
Iter: 883 loss: 9.87679527e-07
Iter: 884 loss: 9.87234898e-07
Iter: 885 loss: 9.96668177e-07
Iter: 886 loss: 9.8726e-07
Iter: 887 loss: 9.86804935e-07
Iter: 888 loss: 9.86812779e-07
Iter: 889 loss: 9.86540385e-07
Iter: 890 loss: 9.87167141e-07
Iter: 891 loss: 9.86390432e-07
Iter: 892 loss: 9.85903284e-07
Iter: 893 loss: 9.85477527e-07
Iter: 894 loss: 9.85371e-07
Iter: 895 loss: 9.84858161e-07
Iter: 896 loss: 9.86093141e-07
Iter: 897 loss: 9.84626581e-07
Iter: 898 loss: 9.83956625e-07
Iter: 899 loss: 9.87329827e-07
Iter: 900 loss: 9.83849191e-07
Iter: 901 loss: 9.83626705e-07
Iter: 902 loss: 9.84749e-07
Iter: 903 loss: 9.83521772e-07
Iter: 904 loss: 9.83187647e-07
Iter: 905 loss: 9.83391e-07
Iter: 906 loss: 9.82999723e-07
Iter: 907 loss: 9.82896381e-07
Iter: 908 loss: 9.82845108e-07
Iter: 909 loss: 9.82634447e-07
Iter: 910 loss: 9.82729716e-07
Iter: 911 loss: 9.82511096e-07
Iter: 912 loss: 9.82342385e-07
Iter: 913 loss: 9.82045549e-07
Iter: 914 loss: 9.82045208e-07
Iter: 915 loss: 9.81794642e-07
Iter: 916 loss: 9.84184339e-07
Iter: 917 loss: 9.81719154e-07
Iter: 918 loss: 9.81549078e-07
Iter: 919 loss: 9.81125936e-07
Iter: 920 loss: 9.88684e-07
Iter: 921 loss: 9.81186076e-07
Iter: 922 loss: 9.80719506e-07
Iter: 923 loss: 9.84828603e-07
Iter: 924 loss: 9.80732125e-07
Iter: 925 loss: 9.80416189e-07
Iter: 926 loss: 9.80075583e-07
Iter: 927 loss: 9.79976789e-07
Iter: 928 loss: 9.79469064e-07
Iter: 929 loss: 9.86457e-07
Iter: 930 loss: 9.79462584e-07
Iter: 931 loss: 9.79079459e-07
Iter: 932 loss: 9.80880486e-07
Iter: 933 loss: 9.7904956e-07
Iter: 934 loss: 9.78710204e-07
Iter: 935 loss: 9.78298544e-07
Iter: 936 loss: 9.7828854e-07
Iter: 937 loss: 9.78023309e-07
Iter: 938 loss: 9.77985337e-07
Iter: 939 loss: 9.77803893e-07
Iter: 940 loss: 9.7770544e-07
Iter: 941 loss: 9.77630179e-07
Iter: 942 loss: 9.77603577e-07
Iter: 943 loss: 9.77412355e-07
Iter: 944 loss: 9.77369837e-07
Iter: 945 loss: 9.77143713e-07
Iter: 946 loss: 9.79691208e-07
Iter: 947 loss: 9.77153832e-07
Iter: 948 loss: 9.76845854e-07
Iter: 949 loss: 9.76607794e-07
Iter: 950 loss: 9.76583578e-07
Iter: 951 loss: 9.7623456e-07
Iter: 952 loss: 9.76285e-07
Iter: 953 loss: 9.76069487e-07
Iter: 954 loss: 9.76843694e-07
Iter: 955 loss: 9.7599866e-07
Iter: 956 loss: 9.75796183e-07
Iter: 957 loss: 9.75466833e-07
Iter: 958 loss: 9.75526405e-07
Iter: 959 loss: 9.7520217e-07
Iter: 960 loss: 9.75207058e-07
Iter: 961 loss: 9.74956151e-07
Iter: 962 loss: 9.75089279e-07
Iter: 963 loss: 9.74777e-07
Iter: 964 loss: 9.74316777e-07
Iter: 965 loss: 9.75052217e-07
Iter: 966 loss: 9.74117256e-07
Iter: 967 loss: 9.73765282e-07
Iter: 968 loss: 9.74125214e-07
Iter: 969 loss: 9.73627e-07
Iter: 970 loss: 9.73142505e-07
Iter: 971 loss: 9.73887609e-07
Iter: 972 loss: 9.72952e-07
Iter: 973 loss: 9.73158e-07
Iter: 974 loss: 9.72773364e-07
Iter: 975 loss: 9.7268844e-07
Iter: 976 loss: 9.72404223e-07
Iter: 977 loss: 9.74077693e-07
Iter: 978 loss: 9.72267458e-07
Iter: 979 loss: 9.71886266e-07
Iter: 980 loss: 9.73252213e-07
Iter: 981 loss: 9.71815e-07
Iter: 982 loss: 9.7161228e-07
Iter: 983 loss: 9.72307475e-07
Iter: 984 loss: 9.71533609e-07
Iter: 985 loss: 9.7123575e-07
Iter: 986 loss: 9.70850238e-07
Iter: 987 loss: 9.70922e-07
Iter: 988 loss: 9.70668907e-07
Iter: 989 loss: 9.70667088e-07
Iter: 990 loss: 9.70381848e-07
Iter: 991 loss: 9.70245765e-07
Iter: 992 loss: 9.7016482e-07
Iter: 993 loss: 9.69806706e-07
Iter: 994 loss: 9.71842155e-07
Iter: 995 loss: 9.69765779e-07
Iter: 996 loss: 9.6945223e-07
Iter: 997 loss: 9.70006568e-07
Iter: 998 loss: 9.6934059e-07
Iter: 999 loss: 9.68920745e-07
Iter: 1000 loss: 9.70064775e-07
Iter: 1001 loss: 9.68859e-07
Iter: 1002 loss: 9.68520681e-07
Iter: 1003 loss: 9.69604e-07
Iter: 1004 loss: 9.68442123e-07
Iter: 1005 loss: 9.68032737e-07
Iter: 1006 loss: 9.67657343e-07
Iter: 1007 loss: 9.67617098e-07
Iter: 1008 loss: 9.68217e-07
Iter: 1009 loss: 9.67522283e-07
Iter: 1010 loss: 9.67362e-07
Iter: 1011 loss: 9.6710562e-07
Iter: 1012 loss: 9.7141924e-07
Iter: 1013 loss: 9.67045139e-07
Iter: 1014 loss: 9.66779453e-07
Iter: 1015 loss: 9.66263656e-07
Iter: 1016 loss: 9.78369485e-07
Iter: 1017 loss: 9.66276843e-07
Iter: 1018 loss: 9.65878598e-07
Iter: 1019 loss: 9.65848358e-07
Iter: 1020 loss: 9.65553454e-07
Iter: 1021 loss: 9.66338689e-07
Iter: 1022 loss: 9.6549411e-07
Iter: 1023 loss: 9.65272875e-07
Iter: 1024 loss: 9.65032541e-07
Iter: 1025 loss: 9.64978085e-07
Iter: 1026 loss: 9.64650781e-07
Iter: 1027 loss: 9.647e-07
Iter: 1028 loss: 9.64344736e-07
Iter: 1029 loss: 9.64046876e-07
Iter: 1030 loss: 9.64057904e-07
Iter: 1031 loss: 9.63772436e-07
Iter: 1032 loss: 9.67353799e-07
Iter: 1033 loss: 9.63788352e-07
Iter: 1034 loss: 9.63398293e-07
Iter: 1035 loss: 9.63468892e-07
Iter: 1036 loss: 9.63218554e-07
Iter: 1037 loss: 9.62851232e-07
Iter: 1038 loss: 9.64104856e-07
Iter: 1039 loss: 9.6279291e-07
Iter: 1040 loss: 9.62555532e-07
Iter: 1041 loss: 9.6529493e-07
Iter: 1042 loss: 9.62581225e-07
Iter: 1043 loss: 9.6233407e-07
Iter: 1044 loss: 9.62349759e-07
Iter: 1045 loss: 9.62083277e-07
Iter: 1046 loss: 9.61861247e-07
Iter: 1047 loss: 9.61833166e-07
Iter: 1048 loss: 9.61661158e-07
Iter: 1049 loss: 9.61381375e-07
Iter: 1050 loss: 9.61225282e-07
Iter: 1051 loss: 9.61054e-07
Iter: 1052 loss: 9.60654802e-07
Iter: 1053 loss: 9.63184448e-07
Iter: 1054 loss: 9.60667194e-07
Iter: 1055 loss: 9.6038093e-07
Iter: 1056 loss: 9.6195015e-07
Iter: 1057 loss: 9.60357738e-07
Iter: 1058 loss: 9.60152079e-07
Iter: 1059 loss: 9.59782255e-07
Iter: 1060 loss: 9.59809313e-07
Iter: 1061 loss: 9.59489853e-07
Iter: 1062 loss: 9.6311976e-07
Iter: 1063 loss: 9.59570116e-07
Iter: 1064 loss: 9.59222e-07
Iter: 1065 loss: 9.58896635e-07
Iter: 1066 loss: 9.58894475e-07
Iter: 1067 loss: 9.58577175e-07
Iter: 1068 loss: 9.60992338e-07
Iter: 1069 loss: 9.58465193e-07
Iter: 1070 loss: 9.58189275e-07
Iter: 1071 loss: 9.58624355e-07
Iter: 1072 loss: 9.5801272e-07
Iter: 1073 loss: 9.57673365e-07
Iter: 1074 loss: 9.60368538e-07
Iter: 1075 loss: 9.57647217e-07
Iter: 1076 loss: 9.57461566e-07
Iter: 1077 loss: 9.57416432e-07
Iter: 1078 loss: 9.57364819e-07
Iter: 1079 loss: 9.57135171e-07
Iter: 1080 loss: 9.58405e-07
Iter: 1081 loss: 9.57113571e-07
Iter: 1082 loss: 9.56706458e-07
Iter: 1083 loss: 9.56846e-07
Iter: 1084 loss: 9.56476242e-07
Iter: 1085 loss: 9.5615826e-07
Iter: 1086 loss: 9.59278623e-07
Iter: 1087 loss: 9.56155418e-07
Iter: 1088 loss: 9.55895075e-07
Iter: 1089 loss: 9.55812766e-07
Iter: 1090 loss: 9.55677478e-07
Iter: 1091 loss: 9.55397354e-07
Iter: 1092 loss: 9.58386067e-07
Iter: 1093 loss: 9.55282e-07
Iter: 1094 loss: 9.55026167e-07
Iter: 1095 loss: 9.54848701e-07
Iter: 1096 loss: 9.54846882e-07
Iter: 1097 loss: 9.54573e-07
Iter: 1098 loss: 9.54515258e-07
Iter: 1099 loss: 9.54401457e-07
Iter: 1100 loss: 9.54278e-07
Iter: 1101 loss: 9.54197503e-07
Iter: 1102 loss: 9.53962285e-07
Iter: 1103 loss: 9.54130883e-07
Iter: 1104 loss: 9.53838594e-07
Iter: 1105 loss: 9.53568758e-07
Iter: 1106 loss: 9.53593485e-07
Iter: 1107 loss: 9.53480708e-07
Iter: 1108 loss: 9.54545e-07
Iter: 1109 loss: 9.53470419e-07
Iter: 1110 loss: 9.53263623e-07
Iter: 1111 loss: 9.53036192e-07
Iter: 1112 loss: 9.52986397e-07
Iter: 1113 loss: 9.52671087e-07
Iter: 1114 loss: 9.5292836e-07
Iter: 1115 loss: 9.52592188e-07
Iter: 1116 loss: 9.52318089e-07
Iter: 1117 loss: 9.52033872e-07
Iter: 1118 loss: 9.52037738e-07
Iter: 1119 loss: 9.51830771e-07
Iter: 1120 loss: 9.51776371e-07
Iter: 1121 loss: 9.51698041e-07
Iter: 1122 loss: 9.51723109e-07
Iter: 1123 loss: 9.51575885e-07
Iter: 1124 loss: 9.5134078e-07
Iter: 1125 loss: 9.51458787e-07
Iter: 1126 loss: 9.51194863e-07
Iter: 1127 loss: 9.51021605e-07
Iter: 1128 loss: 9.52432288e-07
Iter: 1129 loss: 9.51023083e-07
Iter: 1130 loss: 9.5082811e-07
Iter: 1131 loss: 9.50808726e-07
Iter: 1132 loss: 9.50649053e-07
Iter: 1133 loss: 9.50321919e-07
Iter: 1134 loss: 9.52420919e-07
Iter: 1135 loss: 9.50278434e-07
Iter: 1136 loss: 9.50153e-07
Iter: 1137 loss: 9.50072604e-07
Iter: 1138 loss: 9.50025765e-07
Iter: 1139 loss: 9.4987854e-07
Iter: 1140 loss: 9.49841819e-07
Iter: 1141 loss: 9.49676235e-07
Iter: 1142 loss: 9.50664628e-07
Iter: 1143 loss: 9.49650143e-07
Iter: 1144 loss: 9.49562661e-07
Iter: 1145 loss: 9.49381956e-07
Iter: 1146 loss: 9.49415e-07
Iter: 1147 loss: 9.4917732e-07
Iter: 1148 loss: 9.48814545e-07
Iter: 1149 loss: 9.57899601e-07
Iter: 1150 loss: 9.48808747e-07
Iter: 1151 loss: 9.4857694e-07
Iter: 1152 loss: 9.51063441e-07
Iter: 1153 loss: 9.48547836e-07
Iter: 1154 loss: 9.48295508e-07
Iter: 1155 loss: 9.48712227e-07
Iter: 1156 loss: 9.48207799e-07
Iter: 1157 loss: 9.4804534e-07
Iter: 1158 loss: 9.49736886e-07
Iter: 1159 loss: 9.47962803e-07
Iter: 1160 loss: 9.47807621e-07
Iter: 1161 loss: 9.47642775e-07
Iter: 1162 loss: 9.47596845e-07
Iter: 1163 loss: 9.47320473e-07
Iter: 1164 loss: 9.50517915e-07
Iter: 1165 loss: 9.4730467e-07
Iter: 1166 loss: 9.47126523e-07
Iter: 1167 loss: 9.47550404e-07
Iter: 1168 loss: 9.47057742e-07
Iter: 1169 loss: 9.46868909e-07
Iter: 1170 loss: 9.46877776e-07
Iter: 1171 loss: 9.46672e-07
Iter: 1172 loss: 9.46517616e-07
Iter: 1173 loss: 9.4856108e-07
Iter: 1174 loss: 9.46401428e-07
Iter: 1175 loss: 9.46382897e-07
Iter: 1176 loss: 9.47185299e-07
Iter: 1177 loss: 9.46360785e-07
Iter: 1178 loss: 9.46184684e-07
Iter: 1179 loss: 9.45985903e-07
Iter: 1180 loss: 9.45961119e-07
Iter: 1181 loss: 9.45865054e-07
Iter: 1182 loss: 9.46074465e-07
Iter: 1183 loss: 9.45706915e-07
Iter: 1184 loss: 9.45537749e-07
Iter: 1185 loss: 9.45465558e-07
Iter: 1186 loss: 9.45358408e-07
Iter: 1187 loss: 9.45029228e-07
Iter: 1188 loss: 9.45400643e-07
Iter: 1189 loss: 9.44863586e-07
Iter: 1190 loss: 9.44659348e-07
Iter: 1191 loss: 9.45104034e-07
Iter: 1192 loss: 9.44538783e-07
Iter: 1193 loss: 9.44241549e-07
Iter: 1194 loss: 9.46939167e-07
Iter: 1195 loss: 9.44247233e-07
Iter: 1196 loss: 9.44100577e-07
Iter: 1197 loss: 9.4457846e-07
Iter: 1198 loss: 9.44025942e-07
Iter: 1199 loss: 9.43828468e-07
Iter: 1200 loss: 9.43667544e-07
Iter: 1201 loss: 9.43620478e-07
Iter: 1202 loss: 9.43450857e-07
Iter: 1203 loss: 9.43445059e-07
Iter: 1204 loss: 9.43257419e-07
Iter: 1205 loss: 9.43011e-07
Iter: 1206 loss: 9.42960128e-07
Iter: 1207 loss: 9.42719566e-07
Iter: 1208 loss: 9.45776435e-07
Iter: 1209 loss: 9.42656243e-07
Iter: 1210 loss: 9.42552276e-07
Iter: 1211 loss: 9.43785949e-07
Iter: 1212 loss: 9.42555857e-07
Iter: 1213 loss: 9.42389704e-07
Iter: 1214 loss: 9.42395843e-07
Iter: 1215 loss: 9.42244696e-07
Iter: 1216 loss: 9.42113616e-07
Iter: 1217 loss: 9.42122256e-07
Iter: 1218 loss: 9.42013742e-07
Iter: 1219 loss: 9.41802909e-07
Iter: 1220 loss: 9.4199828e-07
Iter: 1221 loss: 9.41666e-07
Iter: 1222 loss: 9.41374765e-07
Iter: 1223 loss: 9.41322924e-07
Iter: 1224 loss: 9.4111715e-07
Iter: 1225 loss: 9.40793825e-07
Iter: 1226 loss: 9.43568068e-07
Iter: 1227 loss: 9.40787402e-07
Iter: 1228 loss: 9.40565315e-07
Iter: 1229 loss: 9.40307075e-07
Iter: 1230 loss: 9.4029491e-07
Iter: 1231 loss: 9.40045481e-07
Iter: 1232 loss: 9.40019049e-07
Iter: 1233 loss: 9.39800543e-07
Iter: 1234 loss: 9.39651954e-07
Iter: 1235 loss: 9.39596589e-07
Iter: 1236 loss: 9.39264396e-07
Iter: 1237 loss: 9.41286487e-07
Iter: 1238 loss: 9.39247457e-07
Iter: 1239 loss: 9.39028439e-07
Iter: 1240 loss: 9.39271217e-07
Iter: 1241 loss: 9.39002803e-07
Iter: 1242 loss: 9.38735411e-07
Iter: 1243 loss: 9.3905885e-07
Iter: 1244 loss: 9.38663902e-07
Iter: 1245 loss: 9.38497578e-07
Iter: 1246 loss: 9.38456424e-07
Iter: 1247 loss: 9.38433345e-07
Iter: 1248 loss: 9.38248377e-07
Iter: 1249 loss: 9.40302584e-07
Iter: 1250 loss: 9.38249684e-07
Iter: 1251 loss: 9.38006679e-07
Iter: 1252 loss: 9.37983373e-07
Iter: 1253 loss: 9.37842628e-07
Iter: 1254 loss: 9.375986e-07
Iter: 1255 loss: 9.396922e-07
Iter: 1256 loss: 9.37539482e-07
Iter: 1257 loss: 9.3735207e-07
Iter: 1258 loss: 9.37450295e-07
Iter: 1259 loss: 9.37235313e-07
Iter: 1260 loss: 9.36959339e-07
Iter: 1261 loss: 9.3696724e-07
Iter: 1262 loss: 9.36679612e-07
Iter: 1263 loss: 9.36438937e-07
Iter: 1264 loss: 9.3756654e-07
Iter: 1265 loss: 9.36343383e-07
Iter: 1266 loss: 9.35972082e-07
Iter: 1267 loss: 9.37565346e-07
Iter: 1268 loss: 9.3598004e-07
Iter: 1269 loss: 9.35807577e-07
Iter: 1270 loss: 9.37027153e-07
Iter: 1271 loss: 9.35786943e-07
Iter: 1272 loss: 9.35586854e-07
Iter: 1273 loss: 9.35335038e-07
Iter: 1274 loss: 9.35317757e-07
Iter: 1275 loss: 9.35083733e-07
Iter: 1276 loss: 9.37317736e-07
Iter: 1277 loss: 9.35039395e-07
Iter: 1278 loss: 9.35005176e-07
Iter: 1279 loss: 9.35007336e-07
Iter: 1280 loss: 9.34909394e-07
Iter: 1281 loss: 9.34601076e-07
Iter: 1282 loss: 9.3623828e-07
Iter: 1283 loss: 9.34433501e-07
Iter: 1284 loss: 9.34214768e-07
Iter: 1285 loss: 9.36294384e-07
Iter: 1286 loss: 9.34205e-07
Iter: 1287 loss: 9.34080049e-07
Iter: 1288 loss: 9.34054128e-07
Iter: 1289 loss: 9.33963634e-07
Iter: 1290 loss: 9.33749789e-07
Iter: 1291 loss: 9.34724198e-07
Iter: 1292 loss: 9.33626893e-07
Iter: 1293 loss: 9.33427827e-07
Iter: 1294 loss: 9.33809815e-07
Iter: 1295 loss: 9.33344e-07
Iter: 1296 loss: 9.33164756e-07
Iter: 1297 loss: 9.32955231e-07
Iter: 1298 loss: 9.32905152e-07
Iter: 1299 loss: 9.32632929e-07
Iter: 1300 loss: 9.32607634e-07
Iter: 1301 loss: 9.32495595e-07
Iter: 1302 loss: 9.32516286e-07
Iter: 1303 loss: 9.32402e-07
Iter: 1304 loss: 9.32087687e-07
Iter: 1305 loss: 9.33108481e-07
Iter: 1306 loss: 9.32036187e-07
Iter: 1307 loss: 9.31929435e-07
Iter: 1308 loss: 9.3232245e-07
Iter: 1309 loss: 9.31886575e-07
Iter: 1310 loss: 9.31715476e-07
Iter: 1311 loss: 9.31985539e-07
Iter: 1312 loss: 9.31585419e-07
Iter: 1313 loss: 9.31437683e-07
Iter: 1314 loss: 9.31440582e-07
Iter: 1315 loss: 9.31341731e-07
Iter: 1316 loss: 9.31249531e-07
Iter: 1317 loss: 9.33891e-07
Iter: 1318 loss: 9.31152385e-07
Iter: 1319 loss: 9.30992201e-07
Iter: 1320 loss: 9.30644148e-07
Iter: 1321 loss: 9.37155733e-07
Iter: 1322 loss: 9.30681438e-07
Iter: 1323 loss: 9.30517444e-07
Iter: 1324 loss: 9.30497777e-07
Iter: 1325 loss: 9.30317697e-07
Iter: 1326 loss: 9.30338615e-07
Iter: 1327 loss: 9.30234e-07
Iter: 1328 loss: 9.29997213e-07
Iter: 1329 loss: 9.31382e-07
Iter: 1330 loss: 9.29990733e-07
Iter: 1331 loss: 9.29865e-07
Iter: 1332 loss: 9.29787461e-07
Iter: 1333 loss: 9.29674229e-07
Iter: 1334 loss: 9.29442933e-07
Iter: 1335 loss: 9.29238809e-07
Iter: 1336 loss: 9.29209364e-07
Iter: 1337 loss: 9.28869156e-07
Iter: 1338 loss: 9.30253464e-07
Iter: 1339 loss: 9.28874215e-07
Iter: 1340 loss: 9.28557597e-07
Iter: 1341 loss: 9.29297585e-07
Iter: 1342 loss: 9.28479494e-07
Iter: 1343 loss: 9.28341e-07
Iter: 1344 loss: 9.30193039e-07
Iter: 1345 loss: 9.28289523e-07
Iter: 1346 loss: 9.28190559e-07
Iter: 1347 loss: 9.28155089e-07
Iter: 1348 loss: 9.28088411e-07
Iter: 1349 loss: 9.2791e-07
Iter: 1350 loss: 9.27927658e-07
Iter: 1351 loss: 9.27727115e-07
Iter: 1352 loss: 9.27763779e-07
Iter: 1353 loss: 9.27592339e-07
Iter: 1354 loss: 9.27344e-07
Iter: 1355 loss: 9.27507813e-07
Iter: 1356 loss: 9.27268331e-07
Iter: 1357 loss: 9.26943528e-07
Iter: 1358 loss: 9.2810609e-07
Iter: 1359 loss: 9.26853431e-07
Iter: 1360 loss: 9.26693133e-07
Iter: 1361 loss: 9.27330461e-07
Iter: 1362 loss: 9.2665249e-07
Iter: 1363 loss: 9.26367818e-07
Iter: 1364 loss: 9.26453879e-07
Iter: 1365 loss: 9.26163125e-07
Iter: 1366 loss: 9.2589778e-07
Iter: 1367 loss: 9.27750477e-07
Iter: 1368 loss: 9.25874588e-07
Iter: 1369 loss: 9.25751863e-07
Iter: 1370 loss: 9.25530344e-07
Iter: 1371 loss: 9.25513348e-07
Iter: 1372 loss: 9.2534458e-07
Iter: 1373 loss: 9.2531e-07
Iter: 1374 loss: 9.25174618e-07
Iter: 1375 loss: 9.25300697e-07
Iter: 1376 loss: 9.25147958e-07
Iter: 1377 loss: 9.2501557e-07
Iter: 1378 loss: 9.2551187e-07
Iter: 1379 loss: 9.24880396e-07
Iter: 1380 loss: 9.24745109e-07
Iter: 1381 loss: 9.26492476e-07
Iter: 1382 loss: 9.24773872e-07
Iter: 1383 loss: 9.246844e-07
Iter: 1384 loss: 9.24630285e-07
Iter: 1385 loss: 9.26758105e-07
Iter: 1386 loss: 9.24655808e-07
Iter: 1387 loss: 9.24505116e-07
Iter: 1388 loss: 9.24364599e-07
Iter: 1389 loss: 9.24319636e-07
Iter: 1390 loss: 9.24074e-07
Iter: 1391 loss: 9.24885e-07
Iter: 1392 loss: 9.24036726e-07
Iter: 1393 loss: 9.23773939e-07
Iter: 1394 loss: 9.23778089e-07
Iter: 1395 loss: 9.23677192e-07
Iter: 1396 loss: 9.2329725e-07
Iter: 1397 loss: 9.26410848e-07
Iter: 1398 loss: 9.23311688e-07
Iter: 1399 loss: 9.23230118e-07
Iter: 1400 loss: 9.23518087e-07
Iter: 1401 loss: 9.23203515e-07
Iter: 1402 loss: 9.23017865e-07
Iter: 1403 loss: 9.22817492e-07
Iter: 1404 loss: 9.22768891e-07
Iter: 1405 loss: 9.22519916e-07
Iter: 1406 loss: 9.24029621e-07
Iter: 1407 loss: 9.22503773e-07
Iter: 1408 loss: 9.22353479e-07
Iter: 1409 loss: 9.2286524e-07
Iter: 1410 loss: 9.22274637e-07
Iter: 1411 loss: 9.22094e-07
Iter: 1412 loss: 9.24167864e-07
Iter: 1413 loss: 9.22092113e-07
Iter: 1414 loss: 9.2199042e-07
Iter: 1415 loss: 9.22005427e-07
Iter: 1416 loss: 9.21912033e-07
Iter: 1417 loss: 9.21778849e-07
Iter: 1418 loss: 9.23314133e-07
Iter: 1419 loss: 9.21797607e-07
Iter: 1420 loss: 9.21559263e-07
Iter: 1421 loss: 9.21684546e-07
Iter: 1422 loss: 9.21475589e-07
Iter: 1423 loss: 9.21324272e-07
Iter: 1424 loss: 9.21328e-07
Iter: 1425 loss: 9.21282151e-07
Iter: 1426 loss: 9.20988384e-07
Iter: 1427 loss: 9.23470111e-07
Iter: 1428 loss: 9.20970422e-07
Iter: 1429 loss: 9.20820355e-07
Iter: 1430 loss: 9.20714911e-07
Iter: 1431 loss: 9.20682908e-07
Iter: 1432 loss: 9.20633624e-07
Iter: 1433 loss: 9.20649256e-07
Iter: 1434 loss: 9.20417904e-07
Iter: 1435 loss: 9.20434218e-07
Iter: 1436 loss: 9.20228103e-07
Iter: 1437 loss: 9.20062803e-07
Iter: 1438 loss: 9.22381446e-07
Iter: 1439 loss: 9.20053651e-07
Iter: 1440 loss: 9.19939623e-07
Iter: 1441 loss: 9.19805132e-07
Iter: 1442 loss: 9.19750619e-07
Iter: 1443 loss: 9.19642957e-07
Iter: 1444 loss: 9.19595095e-07
Iter: 1445 loss: 9.1953666e-07
Iter: 1446 loss: 9.20883963e-07
Iter: 1447 loss: 9.19539048e-07
Iter: 1448 loss: 9.19413765e-07
Iter: 1449 loss: 9.19310651e-07
Iter: 1450 loss: 9.21724222e-07
Iter: 1451 loss: 9.19233855e-07
Iter: 1452 loss: 9.19128183e-07
Iter: 1453 loss: 9.1911005e-07
Iter: 1454 loss: 9.18953731e-07
Iter: 1455 loss: 9.18769047e-07
Iter: 1456 loss: 9.20756065e-07
Iter: 1457 loss: 9.18792921e-07
Iter: 1458 loss: 9.186233e-07
Iter: 1459 loss: 9.18368528e-07
Iter: 1460 loss: 9.18341811e-07
Iter: 1461 loss: 9.18112505e-07
Iter: 1462 loss: 9.21385436e-07
Iter: 1463 loss: 9.18073283e-07
Iter: 1464 loss: 9.17960392e-07
Iter: 1465 loss: 9.18116e-07
Iter: 1466 loss: 9.17890759e-07
Iter: 1467 loss: 9.1768834e-07
Iter: 1468 loss: 9.18389333e-07
Iter: 1469 loss: 9.17583918e-07
Iter: 1470 loss: 9.17503314e-07
Iter: 1471 loss: 9.17433113e-07
Iter: 1472 loss: 9.17327839e-07
Iter: 1473 loss: 9.17077841e-07
Iter: 1474 loss: 9.17242744e-07
Iter: 1475 loss: 9.1685e-07
Iter: 1476 loss: 9.16767249e-07
Iter: 1477 loss: 9.16772365e-07
Iter: 1478 loss: 9.16725185e-07
Iter: 1479 loss: 9.16744114e-07
Iter: 1480 loss: 9.16666e-07
Iter: 1481 loss: 9.16496504e-07
Iter: 1482 loss: 9.19136141e-07
Iter: 1483 loss: 9.16494287e-07
Iter: 1484 loss: 9.16346835e-07
Iter: 1485 loss: 9.16691874e-07
Iter: 1486 loss: 9.16267368e-07
Iter: 1487 loss: 9.16218085e-07
Iter: 1488 loss: 9.16131739e-07
Iter: 1489 loss: 9.16073532e-07
Iter: 1490 loss: 9.15850478e-07
Iter: 1491 loss: 9.15888961e-07
Iter: 1492 loss: 9.15684438e-07
Iter: 1493 loss: 9.15507712e-07
Iter: 1494 loss: 9.15501118e-07
Iter: 1495 loss: 9.15420628e-07
Iter: 1496 loss: 9.15155852e-07
Iter: 1497 loss: 9.20797902e-07
Iter: 1498 loss: 9.15168926e-07
Iter: 1499 loss: 9.14901648e-07
Iter: 1500 loss: 9.17331e-07
Iter: 1501 loss: 9.14916598e-07
Iter: 1502 loss: 9.14731515e-07
Iter: 1503 loss: 9.15115265e-07
Iter: 1504 loss: 9.14704e-07
Iter: 1505 loss: 9.14494876e-07
Iter: 1506 loss: 9.15474516e-07
Iter: 1507 loss: 9.14436896e-07
Iter: 1508 loss: 9.1426e-07
Iter: 1509 loss: 9.14209522e-07
Iter: 1510 loss: 9.14161717e-07
Iter: 1511 loss: 9.13991755e-07
Iter: 1512 loss: 9.15876853e-07
Iter: 1513 loss: 9.13980614e-07
Iter: 1514 loss: 9.13920076e-07
Iter: 1515 loss: 9.13898361e-07
Iter: 1516 loss: 9.13874828e-07
Iter: 1517 loss: 9.1377342e-07
Iter: 1518 loss: 9.14054e-07
Iter: 1519 loss: 9.13742269e-07
Iter: 1520 loss: 9.13549798e-07
Iter: 1521 loss: 9.13760687e-07
Iter: 1522 loss: 9.13445206e-07
Iter: 1523 loss: 9.13315773e-07
Iter: 1524 loss: 9.14741577e-07
Iter: 1525 loss: 9.13317194e-07
Iter: 1526 loss: 9.13155077e-07
Iter: 1527 loss: 9.13018823e-07
Iter: 1528 loss: 9.13032068e-07
Iter: 1529 loss: 9.12730457e-07
Iter: 1530 loss: 9.1371669e-07
Iter: 1531 loss: 9.12692485e-07
Iter: 1532 loss: 9.1253952e-07
Iter: 1533 loss: 9.12705445e-07
Iter: 1534 loss: 9.12402186e-07
Iter: 1535 loss: 9.12192036e-07
Iter: 1536 loss: 9.13485337e-07
Iter: 1537 loss: 9.12077098e-07
Iter: 1538 loss: 9.11903157e-07
Iter: 1539 loss: 9.12097903e-07
Iter: 1540 loss: 9.11798e-07
Iter: 1541 loss: 9.11604332e-07
Iter: 1542 loss: 9.11723646e-07
Iter: 1543 loss: 9.11363202e-07
Iter: 1544 loss: 9.11184543e-07
Iter: 1545 loss: 9.11262248e-07
Iter: 1546 loss: 9.11088364e-07
Iter: 1547 loss: 9.1112e-07
Iter: 1548 loss: 9.11006566e-07
Iter: 1549 loss: 9.10934034e-07
Iter: 1550 loss: 9.10852691e-07
Iter: 1551 loss: 9.10815629e-07
Iter: 1552 loss: 9.10763276e-07
Iter: 1553 loss: 9.11939708e-07
Iter: 1554 loss: 9.10725475e-07
Iter: 1555 loss: 9.10573362e-07
Iter: 1556 loss: 9.10444214e-07
Iter: 1557 loss: 9.10506458e-07
Iter: 1558 loss: 9.10312735e-07
Iter: 1559 loss: 9.10326435e-07
Iter: 1560 loss: 9.10150447e-07
Iter: 1561 loss: 9.10128563e-07
Iter: 1562 loss: 9.10047447e-07
Iter: 1563 loss: 9.09948199e-07
Iter: 1564 loss: 9.1021235e-07
Iter: 1565 loss: 9.09817516e-07
Iter: 1566 loss: 9.09692176e-07
Iter: 1567 loss: 9.10757876e-07
Iter: 1568 loss: 9.09663754e-07
Iter: 1569 loss: 9.09535856e-07
Iter: 1570 loss: 9.09377434e-07
Iter: 1571 loss: 9.09351115e-07
Iter: 1572 loss: 9.09215601e-07
Iter: 1573 loss: 9.11231439e-07
Iter: 1574 loss: 9.0919e-07
Iter: 1575 loss: 9.09070422e-07
Iter: 1576 loss: 9.08803713e-07
Iter: 1577 loss: 9.13072085e-07
Iter: 1578 loss: 9.08757841e-07
Iter: 1579 loss: 9.08689913e-07
Iter: 1580 loss: 9.08674622e-07
Iter: 1581 loss: 9.0858066e-07
Iter: 1582 loss: 9.08575828e-07
Iter: 1583 loss: 9.08472657e-07
Iter: 1584 loss: 9.08364143e-07
Iter: 1585 loss: 9.08341235e-07
Iter: 1586 loss: 9.08217942e-07
Iter: 1587 loss: 9.08395e-07
Iter: 1588 loss: 9.08107154e-07
Iter: 1589 loss: 9.0806e-07
Iter: 1590 loss: 9.07822141e-07
Iter: 1591 loss: 9.11478139e-07
Iter: 1592 loss: 9.07776894e-07
Iter: 1593 loss: 9.07574531e-07
Iter: 1594 loss: 9.11357688e-07
Iter: 1595 loss: 9.07536332e-07
Iter: 1596 loss: 9.07300659e-07
Iter: 1597 loss: 9.07111371e-07
Iter: 1598 loss: 9.07048e-07
Iter: 1599 loss: 9.06842047e-07
Iter: 1600 loss: 9.06759908e-07
Iter: 1601 loss: 9.06678224e-07
Iter: 1602 loss: 9.06579828e-07
Iter: 1603 loss: 9.06589321e-07
Iter: 1604 loss: 9.06276512e-07
Iter: 1605 loss: 9.06625e-07
Iter: 1606 loss: 9.06108767e-07
Iter: 1607 loss: 9.0595762e-07
Iter: 1608 loss: 9.06892126e-07
Iter: 1609 loss: 9.05955574e-07
Iter: 1610 loss: 9.05682441e-07
Iter: 1611 loss: 9.05681759e-07
Iter: 1612 loss: 9.05437616e-07
Iter: 1613 loss: 9.05316369e-07
Iter: 1614 loss: 9.05318075e-07
Iter: 1615 loss: 9.05214506e-07
Iter: 1616 loss: 9.05181366e-07
Iter: 1617 loss: 9.05121851e-07
Iter: 1618 loss: 9.04940066e-07
Iter: 1619 loss: 9.06608761e-07
Iter: 1620 loss: 9.04885439e-07
Iter: 1621 loss: 9.04719855e-07
Iter: 1622 loss: 9.06252126e-07
Iter: 1623 loss: 9.04696776e-07
Iter: 1624 loss: 9.0460253e-07
Iter: 1625 loss: 9.04400849e-07
Iter: 1626 loss: 9.0892604e-07
Iter: 1627 loss: 9.04401929e-07
Iter: 1628 loss: 9.04240778e-07
Iter: 1629 loss: 9.0425084e-07
Iter: 1630 loss: 9.04099238e-07
Iter: 1631 loss: 9.03871637e-07
Iter: 1632 loss: 9.09546657e-07
Iter: 1633 loss: 9.03887212e-07
Iter: 1634 loss: 9.03665182e-07
Iter: 1635 loss: 9.06029072e-07
Iter: 1636 loss: 9.03633179e-07
Iter: 1637 loss: 9.03512671e-07
Iter: 1638 loss: 9.04169156e-07
Iter: 1639 loss: 9.03421608e-07
Iter: 1640 loss: 9.03367322e-07
Iter: 1641 loss: 9.03195087e-07
Iter: 1642 loss: 9.03173486e-07
Iter: 1643 loss: 9.02997499e-07
Iter: 1644 loss: 9.0399e-07
Iter: 1645 loss: 9.02948045e-07
Iter: 1646 loss: 9.02768477e-07
Iter: 1647 loss: 9.02772626e-07
Iter: 1648 loss: 9.02636657e-07
Iter: 1649 loss: 9.0281975e-07
Iter: 1650 loss: 9.02572708e-07
Iter: 1651 loss: 9.02509669e-07
Iter: 1652 loss: 9.02434067e-07
Iter: 1653 loss: 9.02411784e-07
Iter: 1654 loss: 9.02305715e-07
Iter: 1655 loss: 9.02135582e-07
Iter: 1656 loss: 9.0613139e-07
Iter: 1657 loss: 9.02118359e-07
Iter: 1658 loss: 9.01969088e-07
Iter: 1659 loss: 9.04420915e-07
Iter: 1660 loss: 9.01937938e-07
Iter: 1661 loss: 9.01874841e-07
Iter: 1662 loss: 9.01815156e-07
Iter: 1663 loss: 9.01745466e-07
Iter: 1664 loss: 9.01537931e-07
Iter: 1665 loss: 9.01826354e-07
Iter: 1666 loss: 9.01447947e-07
Iter: 1667 loss: 9.01393832e-07
Iter: 1668 loss: 9.02111424e-07
Iter: 1669 loss: 9.01268834e-07
Iter: 1670 loss: 9.01169642e-07
Iter: 1671 loss: 9.01055841e-07
Iter: 1672 loss: 9.00994621e-07
Iter: 1673 loss: 9.00882128e-07
Iter: 1674 loss: 9.03045e-07
Iter: 1675 loss: 9.00908276e-07
Iter: 1676 loss: 9.00754969e-07
Iter: 1677 loss: 9.005023e-07
Iter: 1678 loss: 9.05699494e-07
Iter: 1679 loss: 9.00550447e-07
Iter: 1680 loss: 9.00296413e-07
Iter: 1681 loss: 9.03364423e-07
Iter: 1682 loss: 9.00318184e-07
Iter: 1683 loss: 9.00252076e-07
Iter: 1684 loss: 9.00263956e-07
Iter: 1685 loss: 9.00097405e-07
Iter: 1686 loss: 9.00132591e-07
Iter: 1687 loss: 9.00045279e-07
Iter: 1688 loss: 8.9989004e-07
Iter: 1689 loss: 8.99832685e-07
Iter: 1690 loss: 8.99784197e-07
Iter: 1691 loss: 8.99655561e-07
Iter: 1692 loss: 9.0079817e-07
Iter: 1693 loss: 8.99647489e-07
Iter: 1694 loss: 8.99549946e-07
Iter: 1695 loss: 8.99499469e-07
Iter: 1696 loss: 8.9946036e-07
Iter: 1697 loss: 8.9924697e-07
Iter: 1698 loss: 8.99855252e-07
Iter: 1699 loss: 8.99191662e-07
Iter: 1700 loss: 8.98996689e-07
Iter: 1701 loss: 8.99591896e-07
Iter: 1702 loss: 8.99031534e-07
Iter: 1703 loss: 8.98854864e-07
Iter: 1704 loss: 8.98830535e-07
Iter: 1705 loss: 8.98697749e-07
Iter: 1706 loss: 8.98557687e-07
Iter: 1707 loss: 9.00517762e-07
Iter: 1708 loss: 8.98609e-07
Iter: 1709 loss: 8.98427686e-07
Iter: 1710 loss: 8.98315363e-07
Iter: 1711 loss: 8.9827904e-07
Iter: 1712 loss: 8.98056612e-07
Iter: 1713 loss: 8.99375095e-07
Iter: 1714 loss: 8.98010683e-07
Iter: 1715 loss: 8.97911036e-07
Iter: 1716 loss: 8.98231406e-07
Iter: 1717 loss: 8.97848679e-07
Iter: 1718 loss: 8.97777909e-07
Iter: 1719 loss: 8.9777194e-07
Iter: 1720 loss: 8.97725386e-07
Iter: 1721 loss: 8.97551729e-07
Iter: 1722 loss: 8.99133397e-07
Iter: 1723 loss: 8.97494886e-07
Iter: 1724 loss: 8.97403311e-07
Iter: 1725 loss: 8.97997211e-07
Iter: 1726 loss: 8.97326231e-07
Iter: 1727 loss: 8.97224425e-07
Iter: 1728 loss: 8.97743291e-07
Iter: 1729 loss: 8.97193559e-07
Iter: 1730 loss: 8.97041332e-07
Iter: 1731 loss: 8.97262282e-07
Iter: 1732 loss: 8.96954816e-07
Iter: 1733 loss: 8.96795768e-07
Iter: 1734 loss: 8.96982556e-07
Iter: 1735 loss: 8.96740858e-07
Iter: 1736 loss: 8.96593406e-07
Iter: 1737 loss: 8.97275356e-07
Iter: 1738 loss: 8.96486824e-07
Iter: 1739 loss: 8.96311576e-07
Iter: 1740 loss: 8.9733004e-07
Iter: 1741 loss: 8.9635347e-07
Iter: 1742 loss: 8.96174924e-07
Iter: 1743 loss: 8.96162817e-07
Iter: 1744 loss: 8.96016672e-07
Iter: 1745 loss: 8.95851542e-07
Iter: 1746 loss: 8.96996312e-07
Iter: 1747 loss: 8.95887922e-07
Iter: 1748 loss: 8.95732114e-07
Iter: 1749 loss: 8.95759626e-07
Iter: 1750 loss: 8.95645485e-07
Iter: 1751 loss: 8.95672883e-07
Iter: 1752 loss: 8.95556695e-07
Iter: 1753 loss: 8.95451251e-07
Iter: 1754 loss: 8.95344215e-07
Iter: 1755 loss: 8.98744588e-07
Iter: 1756 loss: 8.95334665e-07
Iter: 1757 loss: 8.9523769e-07
Iter: 1758 loss: 8.95154187e-07
Iter: 1759 loss: 8.95030155e-07
Iter: 1760 loss: 8.94845243e-07
Iter: 1761 loss: 8.95459493e-07
Iter: 1762 loss: 8.94819095e-07
Iter: 1763 loss: 8.94669654e-07
Iter: 1764 loss: 8.95361154e-07
Iter: 1765 loss: 8.9466181e-07
Iter: 1766 loss: 8.9450873e-07
Iter: 1767 loss: 8.94514812e-07
Iter: 1768 loss: 8.94454615e-07
Iter: 1769 loss: 8.94259301e-07
Iter: 1770 loss: 8.96260303e-07
Iter: 1771 loss: 8.94252366e-07
Iter: 1772 loss: 8.94112361e-07
Iter: 1773 loss: 8.94074105e-07
Iter: 1774 loss: 8.94033633e-07
Iter: 1775 loss: 8.9391358e-07
Iter: 1776 loss: 8.94910556e-07
Iter: 1777 loss: 8.93847812e-07
Iter: 1778 loss: 8.93745323e-07
Iter: 1779 loss: 8.93991e-07
Iter: 1780 loss: 8.93692686e-07
Iter: 1781 loss: 8.9364886e-07
Iter: 1782 loss: 8.93488163e-07
Iter: 1783 loss: 8.9351613e-07
Iter: 1784 loss: 8.93519427e-07
Iter: 1785 loss: 8.93459287e-07
Iter: 1786 loss: 8.93397612e-07
Iter: 1787 loss: 8.93359697e-07
Iter: 1788 loss: 8.93382264e-07
Iter: 1789 loss: 8.93324682e-07
Iter: 1790 loss: 8.93100491e-07
Iter: 1791 loss: 8.9535115e-07
Iter: 1792 loss: 8.93085883e-07
Iter: 1793 loss: 8.92977482e-07
Iter: 1794 loss: 8.92979301e-07
Iter: 1795 loss: 8.92890739e-07
Iter: 1796 loss: 8.92944456e-07
Iter: 1797 loss: 8.92902676e-07
Iter: 1798 loss: 8.927218e-07
Iter: 1799 loss: 8.92848448e-07
Iter: 1800 loss: 8.92682806e-07
Iter: 1801 loss: 8.92564287e-07
Iter: 1802 loss: 8.93614128e-07
Iter: 1803 loss: 8.92574064e-07
Iter: 1804 loss: 8.92439971e-07
Iter: 1805 loss: 8.92386083e-07
Iter: 1806 loss: 8.92329e-07
Iter: 1807 loss: 8.92201683e-07
Iter: 1808 loss: 8.93221227e-07
Iter: 1809 loss: 8.92112098e-07
Iter: 1810 loss: 8.92041385e-07
Iter: 1811 loss: 8.92360674e-07
Iter: 1812 loss: 8.9200131e-07
Iter: 1813 loss: 8.91969876e-07
Iter: 1814 loss: 8.92066566e-07
Iter: 1815 loss: 8.91841e-07
Iter: 1816 loss: 8.91826403e-07
Iter: 1817 loss: 8.92367439e-07
Iter: 1818 loss: 8.91765637e-07
Iter: 1819 loss: 8.91723175e-07
Iter: 1820 loss: 8.92568323e-07
Iter: 1821 loss: 8.91731929e-07
Iter: 1822 loss: 8.91612331e-07
Iter: 1823 loss: 8.91487275e-07
Iter: 1824 loss: 8.9257e-07
Iter: 1825 loss: 8.91485342e-07
Iter: 1826 loss: 8.91332e-07
Iter: 1827 loss: 8.91766263e-07
Iter: 1828 loss: 8.91306968e-07
Iter: 1829 loss: 8.91147579e-07
Iter: 1830 loss: 8.9152951e-07
Iter: 1831 loss: 8.91133e-07
Iter: 1832 loss: 8.90988247e-07
Iter: 1833 loss: 8.91937e-07
Iter: 1834 loss: 8.90976651e-07
Iter: 1835 loss: 8.90909462e-07
Iter: 1836 loss: 8.90922365e-07
Iter: 1837 loss: 8.90875356e-07
Iter: 1838 loss: 8.90752858e-07
Iter: 1839 loss: 8.91189416e-07
Iter: 1840 loss: 8.90693059e-07
Iter: 1841 loss: 8.90600461e-07
Iter: 1842 loss: 8.90765932e-07
Iter: 1843 loss: 8.90600802e-07
Iter: 1844 loss: 8.90388662e-07
Iter: 1845 loss: 8.90580225e-07
Iter: 1846 loss: 8.9032676e-07
Iter: 1847 loss: 8.90143781e-07
Iter: 1848 loss: 8.91517971e-07
Iter: 1849 loss: 8.90140029e-07
Iter: 1850 loss: 8.90089382e-07
Iter: 1851 loss: 8.8994085e-07
Iter: 1852 loss: 8.899367e-07
Iter: 1853 loss: 8.89855585e-07
Iter: 1854 loss: 8.89857574e-07
Iter: 1855 loss: 8.89744229e-07
Iter: 1856 loss: 8.8954306e-07
Iter: 1857 loss: 8.92071682e-07
Iter: 1858 loss: 8.89553064e-07
Iter: 1859 loss: 8.89394641e-07
Iter: 1860 loss: 8.89468879e-07
Iter: 1861 loss: 8.89282774e-07
Iter: 1862 loss: 8.89106445e-07
Iter: 1863 loss: 8.9010922e-07
Iter: 1864 loss: 8.89137596e-07
Iter: 1865 loss: 8.88931936e-07
Iter: 1866 loss: 8.89606554e-07
Iter: 1867 loss: 8.88874069e-07
Iter: 1868 loss: 8.88779198e-07
Iter: 1869 loss: 8.88753e-07
Iter: 1870 loss: 8.88622935e-07
Iter: 1871 loss: 8.88459113e-07
Iter: 1872 loss: 8.89621731e-07
Iter: 1873 loss: 8.88479292e-07
Iter: 1874 loss: 8.88349064e-07
Iter: 1875 loss: 8.88578086e-07
Iter: 1876 loss: 8.88280169e-07
Iter: 1877 loss: 8.88145166e-07
Iter: 1878 loss: 8.88371062e-07
Iter: 1879 loss: 8.88024942e-07
Iter: 1880 loss: 8.87886813e-07
Iter: 1881 loss: 8.88556315e-07
Iter: 1882 loss: 8.8786561e-07
Iter: 1883 loss: 8.87660633e-07
Iter: 1884 loss: 8.87735894e-07
Iter: 1885 loss: 8.87545184e-07
Iter: 1886 loss: 8.87513352e-07
Iter: 1887 loss: 8.87472481e-07
Iter: 1888 loss: 8.87370163e-07
Iter: 1889 loss: 8.87324859e-07
Iter: 1890 loss: 8.87279896e-07
Iter: 1891 loss: 8.87210376e-07
Iter: 1892 loss: 8.87016597e-07
Iter: 1893 loss: 8.8984234e-07
Iter: 1894 loss: 8.86971065e-07
Iter: 1895 loss: 8.86757789e-07
Iter: 1896 loss: 8.89015553e-07
Iter: 1897 loss: 8.86827308e-07
Iter: 1898 loss: 8.86612725e-07
Iter: 1899 loss: 8.8682259e-07
Iter: 1900 loss: 8.86546445e-07
Iter: 1901 loss: 8.86323562e-07
Iter: 1902 loss: 8.86779389e-07
Iter: 1903 loss: 8.86237899e-07
Iter: 1904 loss: 8.86055e-07
Iter: 1905 loss: 8.86461748e-07
Iter: 1906 loss: 8.86028886e-07
Iter: 1907 loss: 8.8578804e-07
Iter: 1908 loss: 8.86238809e-07
Iter: 1909 loss: 8.85635131e-07
Iter: 1910 loss: 8.85505131e-07
Iter: 1911 loss: 8.86611929e-07
Iter: 1912 loss: 8.85425493e-07
Iter: 1913 loss: 8.85305667e-07
Iter: 1914 loss: 8.85160546e-07
Iter: 1915 loss: 8.85090287e-07
Iter: 1916 loss: 8.84890596e-07
Iter: 1917 loss: 8.8796611e-07
Iter: 1918 loss: 8.84864846e-07
Iter: 1919 loss: 8.84752694e-07
Iter: 1920 loss: 8.85769168e-07
Iter: 1921 loss: 8.84760254e-07
Iter: 1922 loss: 8.84660096e-07
Iter: 1923 loss: 8.85009854e-07
Iter: 1924 loss: 8.84598194e-07
Iter: 1925 loss: 8.84520944e-07
Iter: 1926 loss: 8.84234055e-07
Iter: 1927 loss: 8.87340775e-07
Iter: 1928 loss: 8.84187045e-07
Iter: 1929 loss: 8.83958478e-07
Iter: 1930 loss: 8.8530112e-07
Iter: 1931 loss: 8.84044653e-07
Iter: 1932 loss: 8.83728092e-07
Iter: 1933 loss: 8.84173573e-07
Iter: 1934 loss: 8.83763903e-07
Iter: 1935 loss: 8.83521579e-07
Iter: 1936 loss: 8.84768497e-07
Iter: 1937 loss: 8.83502651e-07
Iter: 1938 loss: 8.83384189e-07
Iter: 1939 loss: 8.83282951e-07
Iter: 1940 loss: 8.83261919e-07
Iter: 1941 loss: 8.83034147e-07
Iter: 1942 loss: 8.84219958e-07
Iter: 1943 loss: 8.82946381e-07
Iter: 1944 loss: 8.82823656e-07
Iter: 1945 loss: 8.83400332e-07
Iter: 1946 loss: 8.82724805e-07
Iter: 1947 loss: 8.82566439e-07
Iter: 1948 loss: 8.82922905e-07
Iter: 1949 loss: 8.82502263e-07
Iter: 1950 loss: 8.82334461e-07
Iter: 1951 loss: 8.82899e-07
Iter: 1952 loss: 8.82340942e-07
Iter: 1953 loss: 8.82167285e-07
Iter: 1954 loss: 8.82362542e-07
Iter: 1955 loss: 8.82054451e-07
Iter: 1956 loss: 8.81980611e-07
Iter: 1957 loss: 8.81958215e-07
Iter: 1958 loss: 8.81824576e-07
Iter: 1959 loss: 8.81730557e-07
Iter: 1960 loss: 8.83484063e-07
Iter: 1961 loss: 8.8170475e-07
Iter: 1962 loss: 8.81526717e-07
Iter: 1963 loss: 8.8135107e-07
Iter: 1964 loss: 8.81345329e-07
Iter: 1965 loss: 8.81135747e-07
Iter: 1966 loss: 8.83914538e-07
Iter: 1967 loss: 8.81107269e-07
Iter: 1968 loss: 8.80959419e-07
Iter: 1969 loss: 8.81825542e-07
Iter: 1970 loss: 8.80953e-07
Iter: 1971 loss: 8.80777918e-07
Iter: 1972 loss: 8.80796392e-07
Iter: 1973 loss: 8.80676e-07
Iter: 1974 loss: 8.80488813e-07
Iter: 1975 loss: 8.8073e-07
Iter: 1976 loss: 8.80394168e-07
Iter: 1977 loss: 8.80149514e-07
Iter: 1978 loss: 8.81442475e-07
Iter: 1979 loss: 8.8010114e-07
Iter: 1980 loss: 8.79912136e-07
Iter: 1981 loss: 8.80360403e-07
Iter: 1982 loss: 8.79813911e-07
Iter: 1983 loss: 8.79669074e-07
Iter: 1984 loss: 8.80352843e-07
Iter: 1985 loss: 8.79581535e-07
Iter: 1986 loss: 8.79454944e-07
Iter: 1987 loss: 8.79727736e-07
Iter: 1988 loss: 8.79356207e-07
Iter: 1989 loss: 8.79294817e-07
Iter: 1990 loss: 8.79257414e-07
Iter: 1991 loss: 8.79105585e-07
Iter: 1992 loss: 8.79011282e-07
Iter: 1993 loss: 8.78995706e-07
Iter: 1994 loss: 8.78775666e-07
Iter: 1995 loss: 8.78800279e-07
Iter: 1996 loss: 8.78738604e-07
Iter: 1997 loss: 8.78492244e-07
Iter: 1998 loss: 8.7814459e-07
Iter: 1999 loss: 8.7818745e-07
Iter: 2000 loss: 8.77879643e-07
Iter: 2001 loss: 8.7789482e-07
Iter: 2002 loss: 8.77676314e-07
Iter: 2003 loss: 8.77947457e-07
Iter: 2004 loss: 8.77570528e-07
Iter: 2005 loss: 8.77311777e-07
Iter: 2006 loss: 8.78854848e-07
Iter: 2007 loss: 8.77272498e-07
Iter: 2008 loss: 8.77091907e-07
Iter: 2009 loss: 8.7703296e-07
Iter: 2010 loss: 8.76879653e-07
Iter: 2011 loss: 8.76666832e-07
Iter: 2012 loss: 8.78185688e-07
Iter: 2013 loss: 8.76589695e-07
Iter: 2014 loss: 8.76307467e-07
Iter: 2015 loss: 8.77719458e-07
Iter: 2016 loss: 8.76324236e-07
Iter: 2017 loss: 8.76091121e-07
Iter: 2018 loss: 8.76372837e-07
Iter: 2019 loss: 8.76039167e-07
Iter: 2020 loss: 8.7580537e-07
Iter: 2021 loss: 8.77167508e-07
Iter: 2022 loss: 8.75878129e-07
Iter: 2023 loss: 8.75726414e-07
Iter: 2024 loss: 8.75738351e-07
Iter: 2025 loss: 8.75603689e-07
Iter: 2026 loss: 8.75419119e-07
Iter: 2027 loss: 8.79238314e-07
Iter: 2028 loss: 8.75455441e-07
Iter: 2029 loss: 8.75292642e-07
Iter: 2030 loss: 8.75321234e-07
Iter: 2031 loss: 8.75248134e-07
Iter: 2032 loss: 8.74984664e-07
Iter: 2033 loss: 8.749779e-07
Iter: 2034 loss: 8.74785883e-07
Iter: 2035 loss: 8.74474836e-07
Iter: 2036 loss: 8.75462547e-07
Iter: 2037 loss: 8.7448268e-07
Iter: 2038 loss: 8.74148725e-07
Iter: 2039 loss: 8.74458522e-07
Iter: 2040 loss: 8.74016905e-07
Iter: 2041 loss: 8.73707222e-07
Iter: 2042 loss: 8.74522357e-07
Iter: 2043 loss: 8.73707791e-07
Iter: 2044 loss: 8.73436477e-07
Iter: 2045 loss: 8.75625e-07
Iter: 2046 loss: 8.73403849e-07
Iter: 2047 loss: 8.73206545e-07
Iter: 2048 loss: 8.73279873e-07
Iter: 2049 loss: 8.73057047e-07
Iter: 2050 loss: 8.72890723e-07
Iter: 2051 loss: 8.72980877e-07
Iter: 2052 loss: 8.7275032e-07
Iter: 2053 loss: 8.72426767e-07
Iter: 2054 loss: 8.7460171e-07
Iter: 2055 loss: 8.72464398e-07
Iter: 2056 loss: 8.72224291e-07
Iter: 2057 loss: 8.73813633e-07
Iter: 2058 loss: 8.72212127e-07
Iter: 2059 loss: 8.71997656e-07
Iter: 2060 loss: 8.72952853e-07
Iter: 2061 loss: 8.71952e-07
Iter: 2062 loss: 8.71801262e-07
Iter: 2063 loss: 8.71543875e-07
Iter: 2064 loss: 8.75486364e-07
Iter: 2065 loss: 8.71523127e-07
Iter: 2066 loss: 8.71224245e-07
Iter: 2067 loss: 8.71847305e-07
Iter: 2068 loss: 8.710565e-07
Iter: 2069 loss: 8.70804342e-07
Iter: 2070 loss: 8.73671695e-07
Iter: 2071 loss: 8.70819e-07
Iter: 2072 loss: 8.70623e-07
Iter: 2073 loss: 8.70533484e-07
Iter: 2074 loss: 8.7045828e-07
Iter: 2075 loss: 8.70273539e-07
Iter: 2076 loss: 8.7249191e-07
Iter: 2077 loss: 8.7022795e-07
Iter: 2078 loss: 8.70081124e-07
Iter: 2079 loss: 8.70227609e-07
Iter: 2080 loss: 8.69965618e-07
Iter: 2081 loss: 8.69715109e-07
Iter: 2082 loss: 8.70021552e-07
Iter: 2083 loss: 8.6960523e-07
Iter: 2084 loss: 8.69467272e-07
Iter: 2085 loss: 8.70901772e-07
Iter: 2086 loss: 8.69383541e-07
Iter: 2087 loss: 8.69194878e-07
Iter: 2088 loss: 8.69267069e-07
Iter: 2089 loss: 8.69016674e-07
Iter: 2090 loss: 8.68762868e-07
Iter: 2091 loss: 8.68851203e-07
Iter: 2092 loss: 8.68586369e-07
Iter: 2093 loss: 8.68295274e-07
Iter: 2094 loss: 8.70140695e-07
Iter: 2095 loss: 8.68322559e-07
Iter: 2096 loss: 8.68257871e-07
Iter: 2097 loss: 8.68126051e-07
Iter: 2098 loss: 8.68070742e-07
Iter: 2099 loss: 8.68019129e-07
Iter: 2100 loss: 8.67994856e-07
Iter: 2101 loss: 8.67818414e-07
Iter: 2102 loss: 8.67631059e-07
Iter: 2103 loss: 8.67662663e-07
Iter: 2104 loss: 8.67461381e-07
Iter: 2105 loss: 8.68764118e-07
Iter: 2106 loss: 8.674524e-07
Iter: 2107 loss: 8.67229801e-07
Iter: 2108 loss: 8.67398455e-07
Iter: 2109 loss: 8.67170343e-07
Iter: 2110 loss: 8.66929497e-07
Iter: 2111 loss: 8.67732751e-07
Iter: 2112 loss: 8.66877656e-07
Iter: 2113 loss: 8.66646246e-07
Iter: 2114 loss: 8.67473887e-07
Iter: 2115 loss: 8.66610321e-07
Iter: 2116 loss: 8.66366065e-07
Iter: 2117 loss: 8.66387154e-07
Iter: 2118 loss: 8.66240669e-07
Iter: 2119 loss: 8.66019775e-07
Iter: 2120 loss: 8.68119685e-07
Iter: 2121 loss: 8.66026369e-07
Iter: 2122 loss: 8.65798597e-07
Iter: 2123 loss: 8.66073606e-07
Iter: 2124 loss: 8.65762559e-07
Iter: 2125 loss: 8.65621e-07
Iter: 2126 loss: 8.65702759e-07
Iter: 2127 loss: 8.65460152e-07
Iter: 2128 loss: 8.65237268e-07
Iter: 2129 loss: 8.65741356e-07
Iter: 2130 loss: 8.65160871e-07
Iter: 2131 loss: 8.65312643e-07
Iter: 2132 loss: 8.65094364e-07
Iter: 2133 loss: 8.6504815e-07
Iter: 2134 loss: 8.64884669e-07
Iter: 2135 loss: 8.66632547e-07
Iter: 2136 loss: 8.64893138e-07
Iter: 2137 loss: 8.64760807e-07
Iter: 2138 loss: 8.64740969e-07
Iter: 2139 loss: 8.64633137e-07
Iter: 2140 loss: 8.64453966e-07
Iter: 2141 loss: 8.65253e-07
Iter: 2142 loss: 8.64400135e-07
Iter: 2143 loss: 8.64338062e-07
Iter: 2144 loss: 8.6463433e-07
Iter: 2145 loss: 8.64306514e-07
Iter: 2146 loss: 8.64133938e-07
Iter: 2147 loss: 8.64337721e-07
Iter: 2148 loss: 8.64031904e-07
Iter: 2149 loss: 8.63842047e-07
Iter: 2150 loss: 8.64574531e-07
Iter: 2151 loss: 8.63850971e-07
Iter: 2152 loss: 8.63759851e-07
Iter: 2153 loss: 8.63997798e-07
Iter: 2154 loss: 8.63631e-07
Iter: 2155 loss: 8.63564196e-07
Iter: 2156 loss: 8.64144624e-07
Iter: 2157 loss: 8.63492232e-07
Iter: 2158 loss: 8.63386731e-07
Iter: 2159 loss: 8.63513151e-07
Iter: 2160 loss: 8.63314369e-07
Iter: 2161 loss: 8.63179935e-07
Iter: 2162 loss: 8.63521e-07
Iter: 2163 loss: 8.63074263e-07
Iter: 2164 loss: 8.62906518e-07
Iter: 2165 loss: 8.63213188e-07
Iter: 2166 loss: 8.62856e-07
Iter: 2167 loss: 8.62874344e-07
Iter: 2168 loss: 8.62781633e-07
Iter: 2169 loss: 8.62687841e-07
Iter: 2170 loss: 8.62556e-07
Iter: 2171 loss: 8.65476466e-07
Iter: 2172 loss: 8.62516e-07
Iter: 2173 loss: 8.62488605e-07
Iter: 2174 loss: 8.62379864e-07
Iter: 2175 loss: 8.62312504e-07
Iter: 2176 loss: 8.62230593e-07
Iter: 2177 loss: 8.6322018e-07
Iter: 2178 loss: 8.62162494e-07
Iter: 2179 loss: 8.6213322e-07
Iter: 2180 loss: 8.62499633e-07
Iter: 2181 loss: 8.62111676e-07
Iter: 2182 loss: 8.62023171e-07
Iter: 2183 loss: 8.621044e-07
Iter: 2184 loss: 8.61884416e-07
Iter: 2185 loss: 8.61790795e-07
Iter: 2186 loss: 8.61976275e-07
Iter: 2187 loss: 8.61720252e-07
Iter: 2188 loss: 8.6160685e-07
Iter: 2189 loss: 8.61571039e-07
Iter: 2190 loss: 8.61505328e-07
Iter: 2191 loss: 8.61349292e-07
Iter: 2192 loss: 8.62580578e-07
Iter: 2193 loss: 8.61301601e-07
Iter: 2194 loss: 8.61252317e-07
Iter: 2195 loss: 8.61149374e-07
Iter: 2196 loss: 8.61109584e-07
Iter: 2197 loss: 8.6091535e-07
Iter: 2198 loss: 8.62829268e-07
Iter: 2199 loss: 8.60922114e-07
Iter: 2200 loss: 8.60797627e-07
Iter: 2201 loss: 8.61065132e-07
Iter: 2202 loss: 8.60745274e-07
Iter: 2203 loss: 8.60702869e-07
Iter: 2204 loss: 8.6064972e-07
Iter: 2205 loss: 8.60628404e-07
Iter: 2206 loss: 8.605424e-07
Iter: 2207 loss: 8.62126569e-07
Iter: 2208 loss: 8.60537455e-07
Iter: 2209 loss: 8.60411319e-07
Iter: 2210 loss: 8.60305647e-07
Iter: 2211 loss: 8.6031514e-07
Iter: 2212 loss: 8.60141e-07
Iter: 2213 loss: 8.61429271e-07
Iter: 2214 loss: 8.60100727e-07
Iter: 2215 loss: 8.60057639e-07
Iter: 2216 loss: 8.6063028e-07
Iter: 2217 loss: 8.60085663e-07
Iter: 2218 loss: 8.59905185e-07
Iter: 2219 loss: 8.60061e-07
Iter: 2220 loss: 8.5983163e-07
Iter: 2221 loss: 8.59762793e-07
Iter: 2222 loss: 8.59777117e-07
Iter: 2223 loss: 8.59700776e-07
Iter: 2224 loss: 8.59572708e-07
Iter: 2225 loss: 8.59989882e-07
Iter: 2226 loss: 8.59518764e-07
Iter: 2227 loss: 8.59461579e-07
Iter: 2228 loss: 8.60112664e-07
Iter: 2229 loss: 8.59400586e-07
Iter: 2230 loss: 8.59276781e-07
Iter: 2231 loss: 8.59124384e-07
Iter: 2232 loss: 8.62678746e-07
Iter: 2233 loss: 8.59175941e-07
Iter: 2234 loss: 8.58994042e-07
Iter: 2235 loss: 8.59038778e-07
Iter: 2236 loss: 8.5901786e-07
Iter: 2237 loss: 8.59597492e-07
Iter: 2238 loss: 8.59018826e-07
Iter: 2239 loss: 8.58940211e-07
Iter: 2240 loss: 8.58872738e-07
Iter: 2241 loss: 8.58875637e-07
Iter: 2242 loss: 8.58734893e-07
Iter: 2243 loss: 8.5879276e-07
Iter: 2244 loss: 8.58698741e-07
Iter: 2245 loss: 8.58493763e-07
Iter: 2246 loss: 8.58955389e-07
Iter: 2247 loss: 8.58529688e-07
Iter: 2248 loss: 8.5839747e-07
Iter: 2249 loss: 8.58534179e-07
Iter: 2250 loss: 8.58304475e-07
Iter: 2251 loss: 8.58119506e-07
Iter: 2252 loss: 8.58340627e-07
Iter: 2253 loss: 8.58108876e-07
Iter: 2254 loss: 8.58004228e-07
Iter: 2255 loss: 8.59632905e-07
Iter: 2256 loss: 8.57998657e-07
Iter: 2257 loss: 8.57933401e-07
Iter: 2258 loss: 8.57905889e-07
Iter: 2259 loss: 8.57793054e-07
Iter: 2260 loss: 8.57699376e-07
Iter: 2261 loss: 8.57872408e-07
Iter: 2262 loss: 8.57661462e-07
Iter: 2263 loss: 8.57489908e-07
Iter: 2264 loss: 8.57857458e-07
Iter: 2265 loss: 8.57441933e-07
Iter: 2266 loss: 8.57303633e-07
Iter: 2267 loss: 8.58137241e-07
Iter: 2268 loss: 8.57293855e-07
Iter: 2269 loss: 8.57190798e-07
Iter: 2270 loss: 8.57615078e-07
Iter: 2271 loss: 8.57175792e-07
Iter: 2272 loss: 8.5710974e-07
Iter: 2273 loss: 8.58034355e-07
Iter: 2274 loss: 8.57106556e-07
Iter: 2275 loss: 8.56981e-07
Iter: 2276 loss: 8.56889528e-07
Iter: 2277 loss: 8.57971145e-07
Iter: 2278 loss: 8.5686122e-07
Iter: 2279 loss: 8.56693475e-07
Iter: 2280 loss: 8.5799968e-07
Iter: 2281 loss: 8.56597353e-07
Iter: 2282 loss: 8.56584677e-07
Iter: 2283 loss: 8.56574218e-07
Iter: 2284 loss: 8.56550059e-07
Iter: 2285 loss: 8.56300915e-07
Iter: 2286 loss: 8.56937504e-07
Iter: 2287 loss: 8.56279598e-07
Iter: 2288 loss: 8.56159716e-07
Iter: 2289 loss: 8.56225483e-07
Iter: 2290 loss: 8.56056772e-07
Iter: 2291 loss: 8.55922451e-07
Iter: 2292 loss: 8.56528231e-07
Iter: 2293 loss: 8.55823316e-07
Iter: 2294 loss: 8.55780797e-07
Iter: 2295 loss: 8.55861344e-07
Iter: 2296 loss: 8.5573356e-07
Iter: 2297 loss: 8.55604526e-07
Iter: 2298 loss: 8.56193139e-07
Iter: 2299 loss: 8.5550073e-07
Iter: 2300 loss: 8.5545679e-07
Iter: 2301 loss: 8.56067913e-07
Iter: 2302 loss: 8.55437065e-07
Iter: 2303 loss: 8.55338101e-07
Iter: 2304 loss: 8.55209578e-07
Iter: 2305 loss: 8.5519855e-07
Iter: 2306 loss: 8.55138865e-07
Iter: 2307 loss: 8.55094299e-07
Iter: 2308 loss: 8.54996074e-07
Iter: 2309 loss: 8.55261646e-07
Iter: 2310 loss: 8.55013e-07
Iter: 2311 loss: 8.54977657e-07
Iter: 2312 loss: 8.54878635e-07
Iter: 2313 loss: 8.56710415e-07
Iter: 2314 loss: 8.54861639e-07
Iter: 2315 loss: 8.54784105e-07
Iter: 2316 loss: 8.55011081e-07
Iter: 2317 loss: 8.54712596e-07
Iter: 2318 loss: 8.54589246e-07
Iter: 2319 loss: 8.54872724e-07
Iter: 2320 loss: 8.54540417e-07
Iter: 2321 loss: 8.54396717e-07
Iter: 2322 loss: 8.54873917e-07
Iter: 2323 loss: 8.54405187e-07
Iter: 2324 loss: 8.54295536e-07
Iter: 2325 loss: 8.54262112e-07
Iter: 2326 loss: 8.54196173e-07
Iter: 2327 loss: 8.54011716e-07
Iter: 2328 loss: 8.54066968e-07
Iter: 2329 loss: 8.53811571e-07
Iter: 2330 loss: 8.53704194e-07
Iter: 2331 loss: 8.54702307e-07
Iter: 2332 loss: 8.53727954e-07
Iter: 2333 loss: 8.53509448e-07
Iter: 2334 loss: 8.54120458e-07
Iter: 2335 loss: 8.53505469e-07
Iter: 2336 loss: 8.53368306e-07
Iter: 2337 loss: 8.53929066e-07
Iter: 2338 loss: 8.53390247e-07
Iter: 2339 loss: 8.53277186e-07
Iter: 2340 loss: 8.53344545e-07
Iter: 2341 loss: 8.53208803e-07
Iter: 2342 loss: 8.5316583e-07
Iter: 2343 loss: 8.53121037e-07
Iter: 2344 loss: 8.53047823e-07
Iter: 2345 loss: 8.52999392e-07
Iter: 2346 loss: 8.52966764e-07
Iter: 2347 loss: 8.52908613e-07
Iter: 2348 loss: 8.5280368e-07
Iter: 2349 loss: 8.5282818e-07
Iter: 2350 loss: 8.52728476e-07
Iter: 2351 loss: 8.53102392e-07
Iter: 2352 loss: 8.52637186e-07
Iter: 2353 loss: 8.52591825e-07
Iter: 2354 loss: 8.52611151e-07
Iter: 2355 loss: 8.52457219e-07
Iter: 2356 loss: 8.52316532e-07
Iter: 2357 loss: 8.53165034e-07
Iter: 2358 loss: 8.52338133e-07
Iter: 2359 loss: 8.52218932e-07
Iter: 2360 loss: 8.52627522e-07
Iter: 2361 loss: 8.52229505e-07
Iter: 2362 loss: 8.52138669e-07
Iter: 2363 loss: 8.51957623e-07
Iter: 2364 loss: 8.51932157e-07
Iter: 2365 loss: 8.51796756e-07
Iter: 2366 loss: 8.53219149e-07
Iter: 2367 loss: 8.51773848e-07
Iter: 2368 loss: 8.51591949e-07
Iter: 2369 loss: 8.51575294e-07
Iter: 2370 loss: 8.51500431e-07
Iter: 2371 loss: 8.51407719e-07
Iter: 2372 loss: 8.51385494e-07
Iter: 2373 loss: 8.51302786e-07
Iter: 2374 loss: 8.51309892e-07
Iter: 2375 loss: 8.51272262e-07
Iter: 2376 loss: 8.51209165e-07
Iter: 2377 loss: 8.51169659e-07
Iter: 2378 loss: 8.51126856e-07
Iter: 2379 loss: 8.51070297e-07
Iter: 2380 loss: 8.51046309e-07
Iter: 2381 loss: 8.50951096e-07
Iter: 2382 loss: 8.50897209e-07
Iter: 2383 loss: 8.50916479e-07
Iter: 2384 loss: 8.50766185e-07
Iter: 2385 loss: 8.51233949e-07
Iter: 2386 loss: 8.50683534e-07
Iter: 2387 loss: 8.50578544e-07
Iter: 2388 loss: 8.51236905e-07
Iter: 2389 loss: 8.505491e-07
Iter: 2390 loss: 8.50445531e-07
Iter: 2391 loss: 8.50307117e-07
Iter: 2392 loss: 8.50336676e-07
Iter: 2393 loss: 8.50278354e-07
Iter: 2394 loss: 8.50211507e-07
Iter: 2395 loss: 8.50168249e-07
Iter: 2396 loss: 8.50011702e-07
Iter: 2397 loss: 8.52961762e-07
Iter: 2398 loss: 8.49991466e-07
Iter: 2399 loss: 8.49782055e-07
Iter: 2400 loss: 8.50596848e-07
Iter: 2401 loss: 8.49668879e-07
Iter: 2402 loss: 8.49527851e-07
Iter: 2403 loss: 8.49710261e-07
Iter: 2404 loss: 8.49505568e-07
Iter: 2405 loss: 8.49288142e-07
Iter: 2406 loss: 8.5108411e-07
Iter: 2407 loss: 8.49218679e-07
Iter: 2408 loss: 8.49157573e-07
Iter: 2409 loss: 8.50355491e-07
Iter: 2410 loss: 8.49126536e-07
Iter: 2411 loss: 8.49062474e-07
Iter: 2412 loss: 8.49436674e-07
Iter: 2413 loss: 8.49073444e-07
Iter: 2414 loss: 8.48985735e-07
Iter: 2415 loss: 8.48836578e-07
Iter: 2416 loss: 8.51064101e-07
Iter: 2417 loss: 8.48786385e-07
Iter: 2418 loss: 8.48653031e-07
Iter: 2419 loss: 8.49331855e-07
Iter: 2420 loss: 8.48623358e-07
Iter: 2421 loss: 8.48483808e-07
Iter: 2422 loss: 8.49010746e-07
Iter: 2423 loss: 8.48399111e-07
Iter: 2424 loss: 8.48273032e-07
Iter: 2425 loss: 8.48748186e-07
Iter: 2426 loss: 8.48216473e-07
Iter: 2427 loss: 8.48128821e-07
Iter: 2428 loss: 8.48225454e-07
Iter: 2429 loss: 8.4802565e-07
Iter: 2430 loss: 8.47955732e-07
Iter: 2431 loss: 8.48756713e-07
Iter: 2432 loss: 8.47862395e-07
Iter: 2433 loss: 8.47844547e-07
Iter: 2434 loss: 8.48191235e-07
Iter: 2435 loss: 8.47800777e-07
Iter: 2436 loss: 8.4776e-07
Iter: 2437 loss: 8.47508545e-07
Iter: 2438 loss: 8.51412324e-07
Iter: 2439 loss: 8.47489559e-07
Iter: 2440 loss: 8.47324884e-07
Iter: 2441 loss: 8.49154162e-07
Iter: 2442 loss: 8.47363367e-07
Iter: 2443 loss: 8.47178171e-07
Iter: 2444 loss: 8.47404522e-07
Iter: 2445 loss: 8.47129684e-07
Iter: 2446 loss: 8.47154524e-07
Iter: 2447 loss: 8.47079718e-07
Iter: 2448 loss: 8.46982346e-07
Iter: 2449 loss: 8.46953469e-07
Iter: 2450 loss: 8.4693238e-07
Iter: 2451 loss: 8.46846035e-07
Iter: 2452 loss: 8.4678436e-07
Iter: 2453 loss: 8.46789817e-07
Iter: 2454 loss: 8.46615819e-07
Iter: 2455 loss: 8.47106321e-07
Iter: 2456 loss: 8.46624914e-07
Iter: 2457 loss: 8.46451826e-07
Iter: 2458 loss: 8.47102342e-07
Iter: 2459 loss: 8.46483772e-07
Iter: 2460 loss: 8.46337855e-07
Iter: 2461 loss: 8.46255887e-07
Iter: 2462 loss: 8.46222406e-07
Iter: 2463 loss: 8.4610582e-07
Iter: 2464 loss: 8.47197668e-07
Iter: 2465 loss: 8.46072965e-07
Iter: 2466 loss: 8.45915281e-07
Iter: 2467 loss: 8.46211037e-07
Iter: 2468 loss: 8.45910392e-07
Iter: 2469 loss: 8.45762202e-07
Iter: 2470 loss: 8.45990712e-07
Iter: 2471 loss: 8.45698196e-07
Iter: 2472 loss: 8.4553443e-07
Iter: 2473 loss: 8.45677448e-07
Iter: 2474 loss: 8.4548924e-07
Iter: 2475 loss: 8.45319278e-07
Iter: 2476 loss: 8.45801424e-07
Iter: 2477 loss: 8.45323541e-07
Iter: 2478 loss: 8.45203e-07
Iter: 2479 loss: 8.45189e-07
Iter: 2480 loss: 8.45093211e-07
Iter: 2481 loss: 8.45270847e-07
Iter: 2482 loss: 8.45029319e-07
Iter: 2483 loss: 8.44938086e-07
Iter: 2484 loss: 8.44847364e-07
Iter: 2485 loss: 8.44861233e-07
Iter: 2486 loss: 8.44785063e-07
Iter: 2487 loss: 8.45582178e-07
Iter: 2488 loss: 8.44749877e-07
Iter: 2489 loss: 8.44683143e-07
Iter: 2490 loss: 8.44510055e-07
Iter: 2491 loss: 8.44505905e-07
Iter: 2492 loss: 8.44323e-07
Iter: 2493 loss: 8.44964404e-07
Iter: 2494 loss: 8.44313149e-07
Iter: 2495 loss: 8.44197132e-07
Iter: 2496 loss: 8.44964e-07
Iter: 2497 loss: 8.44198837e-07
Iter: 2498 loss: 8.44043257e-07
Iter: 2499 loss: 8.44112833e-07
Iter: 2500 loss: 8.43917519e-07
Iter: 2501 loss: 8.43801899e-07
Iter: 2502 loss: 8.43949408e-07
Iter: 2503 loss: 8.43769783e-07
Iter: 2504 loss: 8.43606756e-07
Iter: 2505 loss: 8.44208e-07
Iter: 2506 loss: 8.43517682e-07
Iter: 2507 loss: 8.43406383e-07
Iter: 2508 loss: 8.43724e-07
Iter: 2509 loss: 8.43412124e-07
Iter: 2510 loss: 8.43318844e-07
Iter: 2511 loss: 8.4395208e-07
Iter: 2512 loss: 8.43281e-07
Iter: 2513 loss: 8.43270413e-07
Iter: 2514 loss: 8.43181624e-07
Iter: 2515 loss: 8.43174291e-07
Iter: 2516 loss: 8.43028033e-07
Iter: 2517 loss: 8.45113391e-07
Iter: 2518 loss: 8.43075043e-07
Iter: 2519 loss: 8.4292526e-07
Iter: 2520 loss: 8.42865347e-07
Iter: 2521 loss: 8.42907639e-07
Iter: 2522 loss: 8.42651048e-07
Iter: 2523 loss: 8.43957309e-07
Iter: 2524 loss: 8.42680038e-07
Iter: 2525 loss: 8.42549753e-07
Iter: 2526 loss: 8.42642578e-07
Iter: 2527 loss: 8.42490692e-07
Iter: 2528 loss: 8.42252746e-07
Iter: 2529 loss: 8.42947486e-07
Iter: 2530 loss: 8.42282816e-07
Iter: 2531 loss: 8.42139457e-07
Iter: 2532 loss: 8.42569079e-07
Iter: 2533 loss: 8.42131783e-07
Iter: 2534 loss: 8.4194977e-07
Iter: 2535 loss: 8.41845463e-07
Iter: 2536 loss: 8.417461e-07
Iter: 2537 loss: 8.41660835e-07
Iter: 2538 loss: 8.41638155e-07
Iter: 2539 loss: 8.41542146e-07
Iter: 2540 loss: 8.41620306e-07
Iter: 2541 loss: 8.41446536e-07
Iter: 2542 loss: 8.41360134e-07
Iter: 2543 loss: 8.41526116e-07
Iter: 2544 loss: 8.41261226e-07
Iter: 2545 loss: 8.41189717e-07
Iter: 2546 loss: 8.41547717e-07
Iter: 2547 loss: 8.41158908e-07
Iter: 2548 loss: 8.41062388e-07
Iter: 2549 loss: 8.41016458e-07
Iter: 2550 loss: 8.40987241e-07
Iter: 2551 loss: 8.41242411e-07
Iter: 2552 loss: 8.40970756e-07
Iter: 2553 loss: 8.40934376e-07
Iter: 2554 loss: 8.40863265e-07
Iter: 2555 loss: 8.40862867e-07
Iter: 2556 loss: 8.40762084e-07
Iter: 2557 loss: 8.40810685e-07
Iter: 2558 loss: 8.40686425e-07
Iter: 2559 loss: 8.40563189e-07
Iter: 2560 loss: 8.41245196e-07
Iter: 2561 loss: 8.40539428e-07
Iter: 2562 loss: 8.40511404e-07
Iter: 2563 loss: 8.40466328e-07
Iter: 2564 loss: 8.40409257e-07
Iter: 2565 loss: 8.40271071e-07
Iter: 2566 loss: 8.41043629e-07
Iter: 2567 loss: 8.40304665e-07
Iter: 2568 loss: 8.4013891e-07
Iter: 2569 loss: 8.40341499e-07
Iter: 2570 loss: 8.40169491e-07
Iter: 2571 loss: 8.40049e-07
Iter: 2572 loss: 8.40070697e-07
Iter: 2573 loss: 8.39926599e-07
Iter: 2574 loss: 8.39864e-07
Iter: 2575 loss: 8.39846507e-07
Iter: 2576 loss: 8.39757263e-07
Iter: 2577 loss: 8.39676659e-07
Iter: 2578 loss: 8.3965574e-07
Iter: 2579 loss: 8.39512836e-07
Iter: 2580 loss: 8.39954225e-07
Iter: 2581 loss: 8.39450252e-07
Iter: 2582 loss: 8.39311269e-07
Iter: 2583 loss: 8.39351287e-07
Iter: 2584 loss: 8.39250959e-07
Iter: 2585 loss: 8.39115842e-07
Iter: 2586 loss: 8.40846099e-07
Iter: 2587 loss: 8.39116183e-07
Iter: 2588 loss: 8.390939e-07
Iter: 2589 loss: 8.39057293e-07
Iter: 2590 loss: 8.3904979e-07
Iter: 2591 loss: 8.38955089e-07
Iter: 2592 loss: 8.39433199e-07
Iter: 2593 loss: 8.38916378e-07
Iter: 2594 loss: 8.38814231e-07
Iter: 2595 loss: 8.39146082e-07
Iter: 2596 loss: 8.38744938e-07
Iter: 2597 loss: 8.38685878e-07
Iter: 2598 loss: 8.38989251e-07
Iter: 2599 loss: 8.38633241e-07
Iter: 2600 loss: 8.38563551e-07
Iter: 2601 loss: 8.38577478e-07
Iter: 2602 loss: 8.3848056e-07
Iter: 2603 loss: 8.38418714e-07
Iter: 2604 loss: 8.38741641e-07
Iter: 2605 loss: 8.3832623e-07
Iter: 2606 loss: 8.38221354e-07
Iter: 2607 loss: 8.38445771e-07
Iter: 2608 loss: 8.38218853e-07
Iter: 2609 loss: 8.38115341e-07
Iter: 2610 loss: 8.38483857e-07
Iter: 2611 loss: 8.38040364e-07
Iter: 2612 loss: 8.37987159e-07
Iter: 2613 loss: 8.37960613e-07
Iter: 2614 loss: 8.37961807e-07
Iter: 2615 loss: 8.37832e-07
Iter: 2616 loss: 8.39063887e-07
Iter: 2617 loss: 8.3782129e-07
Iter: 2618 loss: 8.37752395e-07
Iter: 2619 loss: 8.37914e-07
Iter: 2620 loss: 8.37714879e-07
Iter: 2621 loss: 8.3764877e-07
Iter: 2622 loss: 8.38138078e-07
Iter: 2623 loss: 8.37606933e-07
Iter: 2624 loss: 8.3754145e-07
Iter: 2625 loss: 8.37943617e-07
Iter: 2626 loss: 8.37520759e-07
Iter: 2627 loss: 8.37528148e-07
Iter: 2628 loss: 8.37547532e-07
Iter: 2629 loss: 8.37535651e-07
Iter: 2630 loss: 8.37498305e-07
Iter: 2631 loss: 8.37540028e-07
Iter: 2632 loss: 8.37548953e-07
Iter: 2633 loss: 8.37552648e-07
Iter: 2634 loss: 8.3755009e-07
Iter: 2635 loss: 8.37553216e-07
Iter: 2636 loss: 8.37510868e-07
Iter: 2637 loss: 8.37526898e-07
Iter: 2638 loss: 8.37527125e-07
Iter: 2639 loss: 8.37488528e-07
Iter: 2640 loss: 8.37507514e-07
Iter: 2641 loss: 8.37508082e-07
Iter: 2642 loss: 8.37519394e-07
Iter: 2643 loss: 8.37527125e-07
Iter: 2644 loss: 8.37526898e-07
Iter: 2645 loss: 8.37522066e-07
Iter: 2646 loss: 8.37522521e-07
Iter: 2647 loss: 8.37519394e-07
Iter: 2648 loss: 8.37521895e-07
Iter: 2649 loss: 8.37521839e-07
Iter: 2650 loss: 8.37519394e-07
Iter: 2651 loss: 8.37519735e-07
Iter: 2652 loss: 8.37521839e-07
Iter: 2653 loss: 8.37521839e-07
Iter: 2654 loss: 8.37519735e-07
Iter: 2655 loss: 8.37414518e-07
Iter: 2656 loss: 8.37382288e-07
Iter: 2657 loss: 8.37301968e-07
Iter: 2658 loss: 8.37380185e-07
Iter: 2659 loss: 8.37228754e-07
Iter: 2660 loss: 8.3718e-07
Iter: 2661 loss: 8.37515813e-07
Iter: 2662 loss: 8.37162418e-07
Iter: 2663 loss: 8.37066295e-07
Iter: 2664 loss: 8.37225741e-07
Iter: 2665 loss: 8.36979098e-07
Iter: 2666 loss: 8.3689406e-07
Iter: 2667 loss: 8.37041227e-07
Iter: 2668 loss: 8.3686308e-07
Iter: 2669 loss: 8.36778838e-07
Iter: 2670 loss: 8.37078744e-07
Iter: 2671 loss: 8.3678276e-07
Iter: 2672 loss: 8.36627919e-07
Iter: 2673 loss: 8.36785887e-07
Iter: 2674 loss: 8.36624281e-07
Iter: 2675 loss: 8.36519e-07
Iter: 2676 loss: 8.36877632e-07
Iter: 2677 loss: 8.36483366e-07
Iter: 2678 loss: 8.36482059e-07
Iter: 2679 loss: 8.36584206e-07
Iter: 2680 loss: 8.36385766e-07
Iter: 2681 loss: 8.36303855e-07
Iter: 2682 loss: 8.37205221e-07
Iter: 2683 loss: 8.36314484e-07
Iter: 2684 loss: 8.36262075e-07
Iter: 2685 loss: 8.36200684e-07
Iter: 2686 loss: 8.36212223e-07
Iter: 2687 loss: 8.36128834e-07
Iter: 2688 loss: 8.36068409e-07
Iter: 2689 loss: 8.36070171e-07
Iter: 2690 loss: 8.35891115e-07
Iter: 2691 loss: 8.36860522e-07
Iter: 2692 loss: 8.3589731e-07
Iter: 2693 loss: 8.35824835e-07
Iter: 2694 loss: 8.36003096e-07
Iter: 2695 loss: 8.35845753e-07
Iter: 2696 loss: 8.35788228e-07
Iter: 2697 loss: 8.35886794e-07
Iter: 2698 loss: 8.35700064e-07
Iter: 2699 loss: 8.35643618e-07
Iter: 2700 loss: 8.36009178e-07
Iter: 2701 loss: 8.35645153e-07
Iter: 2702 loss: 8.35556534e-07
Iter: 2703 loss: 8.35523394e-07
Iter: 2704 loss: 8.35456149e-07
Iter: 2705 loss: 8.35384469e-07
Iter: 2706 loss: 8.36359902e-07
Iter: 2707 loss: 8.354192e-07
Iter: 2708 loss: 8.35382366e-07
Iter: 2709 loss: 8.35344395e-07
Iter: 2710 loss: 8.35314609e-07
Iter: 2711 loss: 8.35146238e-07
Iter: 2712 loss: 8.35556705e-07
Iter: 2713 loss: 8.35135438e-07
Iter: 2714 loss: 8.35114179e-07
Iter: 2715 loss: 8.35122592e-07
Iter: 2716 loss: 8.3510389e-07
Iter: 2717 loss: 8.35101503e-07
Iter: 2718 loss: 8.35059893e-07
Iter: 2719 loss: 8.34977868e-07
Iter: 2720 loss: 8.34908917e-07
Iter: 2721 loss: 8.34935463e-07
Iter: 2722 loss: 8.34845537e-07
Iter: 2723 loss: 8.35019137e-07
Iter: 2724 loss: 8.34802393e-07
Iter: 2725 loss: 8.34735374e-07
Iter: 2726 loss: 8.34594857e-07
Iter: 2727 loss: 8.34564389e-07
Iter: 2728 loss: 8.34564901e-07
Iter: 2729 loss: 8.34478499e-07
Iter: 2730 loss: 8.34444108e-07
Iter: 2731 loss: 8.34476452e-07
Iter: 2732 loss: 8.34403409e-07
Iter: 2733 loss: 8.34303194e-07
Iter: 2734 loss: 8.34737307e-07
Iter: 2735 loss: 8.34282957e-07
Iter: 2736 loss: 8.34223385e-07
Iter: 2737 loss: 8.34471166e-07
Iter: 2738 loss: 8.34237312e-07
Iter: 2739 loss: 8.34101684e-07
Iter: 2740 loss: 8.34035859e-07
Iter: 2741 loss: 8.34009825e-07
Iter: 2742 loss: 8.33935303e-07
Iter: 2743 loss: 8.35170283e-07
Iter: 2744 loss: 8.33928254e-07
Iter: 2745 loss: 8.33889601e-07
Iter: 2746 loss: 8.33856916e-07
Iter: 2747 loss: 8.33843274e-07
Iter: 2748 loss: 8.33741524e-07
Iter: 2749 loss: 8.33754598e-07
Iter: 2750 loss: 8.33702245e-07
Iter: 2751 loss: 8.33774152e-07
Iter: 2752 loss: 8.33745958e-07
Iter: 2753 loss: 8.33684112e-07
Iter: 2754 loss: 8.33616753e-07
Iter: 2755 loss: 8.33599e-07
Iter: 2756 loss: 8.33539616e-07
Iter: 2757 loss: 8.3358691e-07
Iter: 2758 loss: 8.33425929e-07
Iter: 2759 loss: 8.33338845e-07
Iter: 2760 loss: 8.34053708e-07
Iter: 2761 loss: 8.33342654e-07
Iter: 2762 loss: 8.33276545e-07
Iter: 2763 loss: 8.33311731e-07
Iter: 2764 loss: 8.33244599e-07
Iter: 2765 loss: 8.33177296e-07
Iter: 2766 loss: 8.34111916e-07
Iter: 2767 loss: 8.33152512e-07
Iter: 2768 loss: 8.33056617e-07
Iter: 2769 loss: 8.33037916e-07
Iter: 2770 loss: 8.3302848e-07
Iter: 2771 loss: 8.32960495e-07
Iter: 2772 loss: 8.33609647e-07
Iter: 2773 loss: 8.32980618e-07
Iter: 2774 loss: 8.3291e-07
Iter: 2775 loss: 8.32884211e-07
Iter: 2776 loss: 8.3285704e-07
Iter: 2777 loss: 8.32765e-07
Iter: 2778 loss: 8.33054116e-07
Iter: 2779 loss: 8.32682815e-07
Iter: 2780 loss: 8.32713567e-07
Iter: 2781 loss: 8.32656724e-07
Iter: 2782 loss: 8.32655815e-07
Iter: 2783 loss: 8.32590217e-07
Iter: 2784 loss: 8.32576291e-07
Iter: 2785 loss: 8.32542469e-07
Iter: 2786 loss: 8.3248085e-07
Iter: 2787 loss: 8.3249904e-07
Iter: 2788 loss: 8.32413207e-07
Iter: 2789 loss: 8.32763817e-07
Iter: 2790 loss: 8.3246465e-07
Iter: 2791 loss: 8.32322485e-07
Iter: 2792 loss: 8.32211299e-07
Iter: 2793 loss: 8.34169157e-07
Iter: 2794 loss: 8.32243359e-07
Iter: 2795 loss: 8.32160936e-07
Iter: 2796 loss: 8.33172635e-07
Iter: 2797 loss: 8.3216662e-07
Iter: 2798 loss: 8.32066462e-07
Iter: 2799 loss: 8.31947204e-07
Iter: 2800 loss: 8.32008e-07
Iter: 2801 loss: 8.31902184e-07
Iter: 2802 loss: 8.32533942e-07
Iter: 2803 loss: 8.31901275e-07
Iter: 2804 loss: 8.31856653e-07
Iter: 2805 loss: 8.31959539e-07
Iter: 2806 loss: 8.31816408e-07
Iter: 2807 loss: 8.31750242e-07
Iter: 2808 loss: 8.31677539e-07
Iter: 2809 loss: 8.31637578e-07
Iter: 2810 loss: 8.31633429e-07
Iter: 2811 loss: 8.31968578e-07
Iter: 2812 loss: 8.31636953e-07
Iter: 2813 loss: 8.31522925e-07
Iter: 2814 loss: 8.31527e-07
Iter: 2815 loss: 8.31446812e-07
Iter: 2816 loss: 8.3139588e-07
Iter: 2817 loss: 8.32264448e-07
Iter: 2818 loss: 8.31390594e-07
Iter: 2819 loss: 8.31323234e-07
Iter: 2820 loss: 8.31850969e-07
Iter: 2821 loss: 8.31322495e-07
Iter: 2822 loss: 8.3127469e-07
Iter: 2823 loss: 8.31203351e-07
Iter: 2824 loss: 8.31947375e-07
Iter: 2825 loss: 8.31220916e-07
Iter: 2826 loss: 8.3112252e-07
Iter: 2827 loss: 8.31803675e-07
Iter: 2828 loss: 8.31139175e-07
Iter: 2829 loss: 8.31103307e-07
Iter: 2830 loss: 8.309745e-07
Iter: 2831 loss: 8.30996782e-07
Iter: 2832 loss: 8.3091652e-07
Iter: 2833 loss: 8.31819364e-07
Iter: 2834 loss: 8.30914871e-07
Iter: 2835 loss: 8.30815111e-07
Iter: 2836 loss: 8.30870931e-07
Iter: 2837 loss: 8.30745364e-07
Iter: 2838 loss: 8.30682666e-07
Iter: 2839 loss: 8.30722797e-07
Iter: 2840 loss: 8.30589386e-07
Iter: 2841 loss: 8.30543911e-07
Iter: 2842 loss: 8.31569537e-07
Iter: 2843 loss: 8.30509634e-07
Iter: 2844 loss: 8.30485135e-07
Iter: 2845 loss: 8.30448585e-07
Iter: 2846 loss: 8.30443298e-07
Iter: 2847 loss: 8.30418116e-07
Iter: 2848 loss: 8.3091436e-07
Iter: 2849 loss: 8.30320573e-07
Iter: 2850 loss: 8.30331771e-07
Iter: 2851 loss: 8.30340525e-07
Iter: 2852 loss: 8.30329498e-07
Iter: 2853 loss: 8.30328304e-07
Iter: 2854 loss: 8.30331942e-07
Iter: 2855 loss: 8.30344618e-07
Iter: 2856 loss: 8.30315798e-07
Iter: 2857 loss: 8.30328304e-07
Iter: 2858 loss: 8.3031432e-07
Iter: 2859 loss: 8.30314661e-07
Iter: 2860 loss: 8.30311535e-07
Iter: 2861 loss: 8.3032279e-07
Iter: 2862 loss: 8.30321767e-07
Iter: 2863 loss: 8.30309773e-07
Iter: 2864 loss: 8.30312274e-07
Iter: 2865 loss: 8.30314718e-07
Iter: 2866 loss: 8.30323927e-07
Iter: 2867 loss: 8.30319891e-07
Iter: 2868 loss: 8.30327906e-07
Iter: 2869 loss: 8.30320744e-07
Iter: 2870 loss: 8.30323415e-07
Iter: 2871 loss: 8.30321937e-07
Iter: 2872 loss: 8.30322563e-07
Iter: 2873 loss: 8.3032154e-07
Iter: 2874 loss: 8.30320573e-07
Iter: 2875 loss: 8.3032154e-07
Iter: 2876 loss: 8.3032154e-07
Iter: 2877 loss: 8.3032154e-07
Iter: 2878 loss: 8.30320573e-07
Iter: 2879 loss: 8.3032154e-07
Iter: 2880 loss: 8.30320573e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_8000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a5dc3e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a5dc5f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a5dc3ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1aa21186a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a5dbdcea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a5dbdc048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a5db38f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38419730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38419950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a383d5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a383d52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a3839df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a383968c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a3835e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38327620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a383b0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a3830bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38296ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38398950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38296048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38233510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a381ef268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38233e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a381aac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a381aaf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a3816fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38169d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a3816f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a380eb158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a380e10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a380b5400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38089158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a38089510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a380a7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a3804f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1a20679c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.14131727e-06
Iter: 2 loss: 2.2814449e-05
Iter: 3 loss: 6.82600739e-06
Iter: 4 loss: 6.03704348e-06
Iter: 5 loss: 5.06101424e-06
Iter: 6 loss: 4.97682686e-06
Iter: 7 loss: 4.29050397e-06
Iter: 8 loss: 4.38144934e-06
Iter: 9 loss: 3.76771936e-06
Iter: 10 loss: 3.16429282e-06
Iter: 11 loss: 9.656158e-06
Iter: 12 loss: 3.15021316e-06
Iter: 13 loss: 2.99286171e-06
Iter: 14 loss: 3.07528626e-06
Iter: 15 loss: 2.88891533e-06
Iter: 16 loss: 2.68628582e-06
Iter: 17 loss: 3.73527109e-06
Iter: 18 loss: 2.65396784e-06
Iter: 19 loss: 2.55433633e-06
Iter: 20 loss: 3.45916078e-06
Iter: 21 loss: 2.54982342e-06
Iter: 22 loss: 2.47970138e-06
Iter: 23 loss: 2.39074143e-06
Iter: 24 loss: 2.38398184e-06
Iter: 25 loss: 2.30030901e-06
Iter: 26 loss: 3.34708739e-06
Iter: 27 loss: 2.29949865e-06
Iter: 28 loss: 2.26045586e-06
Iter: 29 loss: 2.23015604e-06
Iter: 30 loss: 2.21787695e-06
Iter: 31 loss: 2.16072931e-06
Iter: 32 loss: 2.40412055e-06
Iter: 33 loss: 2.14878605e-06
Iter: 34 loss: 2.12381269e-06
Iter: 35 loss: 2.21824803e-06
Iter: 36 loss: 2.11779798e-06
Iter: 37 loss: 2.07342237e-06
Iter: 38 loss: 2.11412316e-06
Iter: 39 loss: 2.04766548e-06
Iter: 40 loss: 2.01932016e-06
Iter: 41 loss: 2.02204183e-06
Iter: 42 loss: 1.99741089e-06
Iter: 43 loss: 1.97078498e-06
Iter: 44 loss: 2.03361833e-06
Iter: 45 loss: 1.96083079e-06
Iter: 46 loss: 1.92735934e-06
Iter: 47 loss: 1.94380482e-06
Iter: 48 loss: 1.90489402e-06
Iter: 49 loss: 1.88765307e-06
Iter: 50 loss: 2.06282175e-06
Iter: 51 loss: 1.88715342e-06
Iter: 52 loss: 1.86857346e-06
Iter: 53 loss: 1.86655734e-06
Iter: 54 loss: 1.85307476e-06
Iter: 55 loss: 1.83459224e-06
Iter: 56 loss: 2.10343433e-06
Iter: 57 loss: 1.83456666e-06
Iter: 58 loss: 1.8236683e-06
Iter: 59 loss: 1.80712914e-06
Iter: 60 loss: 1.80683094e-06
Iter: 61 loss: 1.78705159e-06
Iter: 62 loss: 1.98384032e-06
Iter: 63 loss: 1.78634923e-06
Iter: 64 loss: 1.7771406e-06
Iter: 65 loss: 1.80714767e-06
Iter: 66 loss: 1.77453455e-06
Iter: 67 loss: 1.76300557e-06
Iter: 68 loss: 1.7842558e-06
Iter: 69 loss: 1.7580544e-06
Iter: 70 loss: 1.75998412e-06
Iter: 71 loss: 1.7546347e-06
Iter: 72 loss: 1.75117134e-06
Iter: 73 loss: 1.74403272e-06
Iter: 74 loss: 1.86720911e-06
Iter: 75 loss: 1.74387333e-06
Iter: 76 loss: 1.73532135e-06
Iter: 77 loss: 1.71613556e-06
Iter: 78 loss: 1.98798307e-06
Iter: 79 loss: 1.71524175e-06
Iter: 80 loss: 1.70525755e-06
Iter: 81 loss: 1.70505075e-06
Iter: 82 loss: 1.69560565e-06
Iter: 83 loss: 1.70634587e-06
Iter: 84 loss: 1.69038492e-06
Iter: 85 loss: 1.67934195e-06
Iter: 86 loss: 1.7179683e-06
Iter: 87 loss: 1.67643532e-06
Iter: 88 loss: 1.66900645e-06
Iter: 89 loss: 1.67604276e-06
Iter: 90 loss: 1.66477935e-06
Iter: 91 loss: 1.65373297e-06
Iter: 92 loss: 1.72048783e-06
Iter: 93 loss: 1.65242682e-06
Iter: 94 loss: 1.64769165e-06
Iter: 95 loss: 1.66077734e-06
Iter: 96 loss: 1.64606229e-06
Iter: 97 loss: 1.63951427e-06
Iter: 98 loss: 1.63453558e-06
Iter: 99 loss: 1.63244817e-06
Iter: 100 loss: 1.62579988e-06
Iter: 101 loss: 1.66580185e-06
Iter: 102 loss: 1.62500214e-06
Iter: 103 loss: 1.61707919e-06
Iter: 104 loss: 1.62406332e-06
Iter: 105 loss: 1.61250455e-06
Iter: 106 loss: 1.60684306e-06
Iter: 107 loss: 1.60673903e-06
Iter: 108 loss: 1.60533716e-06
Iter: 109 loss: 1.60459729e-06
Iter: 110 loss: 1.60323316e-06
Iter: 111 loss: 1.59867022e-06
Iter: 112 loss: 1.59816591e-06
Iter: 113 loss: 1.59362048e-06
Iter: 114 loss: 1.58677642e-06
Iter: 115 loss: 1.66015786e-06
Iter: 116 loss: 1.58660669e-06
Iter: 117 loss: 1.58243699e-06
Iter: 118 loss: 1.57481645e-06
Iter: 119 loss: 1.76101514e-06
Iter: 120 loss: 1.57481963e-06
Iter: 121 loss: 1.56999988e-06
Iter: 122 loss: 1.56927456e-06
Iter: 123 loss: 1.56580154e-06
Iter: 124 loss: 1.57204056e-06
Iter: 125 loss: 1.5642911e-06
Iter: 126 loss: 1.55945304e-06
Iter: 127 loss: 1.55805026e-06
Iter: 128 loss: 1.55516523e-06
Iter: 129 loss: 1.55141379e-06
Iter: 130 loss: 1.60015372e-06
Iter: 131 loss: 1.55137536e-06
Iter: 132 loss: 1.54724398e-06
Iter: 133 loss: 1.54384372e-06
Iter: 134 loss: 1.54265263e-06
Iter: 135 loss: 1.53805468e-06
Iter: 136 loss: 1.59994113e-06
Iter: 137 loss: 1.53792644e-06
Iter: 138 loss: 1.53500253e-06
Iter: 139 loss: 1.53383724e-06
Iter: 140 loss: 1.53237443e-06
Iter: 141 loss: 1.52967459e-06
Iter: 142 loss: 1.52941857e-06
Iter: 143 loss: 1.52741632e-06
Iter: 144 loss: 1.55015266e-06
Iter: 145 loss: 1.52736447e-06
Iter: 146 loss: 1.52659766e-06
Iter: 147 loss: 1.52465805e-06
Iter: 148 loss: 1.54346912e-06
Iter: 149 loss: 1.5244234e-06
Iter: 150 loss: 1.52137955e-06
Iter: 151 loss: 1.51614404e-06
Iter: 152 loss: 1.51610891e-06
Iter: 153 loss: 1.51165068e-06
Iter: 154 loss: 1.54835197e-06
Iter: 155 loss: 1.51144343e-06
Iter: 156 loss: 1.50673372e-06
Iter: 157 loss: 1.51323172e-06
Iter: 158 loss: 1.50437484e-06
Iter: 159 loss: 1.50183257e-06
Iter: 160 loss: 1.5018577e-06
Iter: 161 loss: 1.49945197e-06
Iter: 162 loss: 1.49567836e-06
Iter: 163 loss: 1.4957119e-06
Iter: 164 loss: 1.49199616e-06
Iter: 165 loss: 1.53475958e-06
Iter: 166 loss: 1.49197103e-06
Iter: 167 loss: 1.48938386e-06
Iter: 168 loss: 1.49543416e-06
Iter: 169 loss: 1.48850268e-06
Iter: 170 loss: 1.48471076e-06
Iter: 171 loss: 1.48343543e-06
Iter: 172 loss: 1.48124207e-06
Iter: 173 loss: 1.47860749e-06
Iter: 174 loss: 1.50032e-06
Iter: 175 loss: 1.47842638e-06
Iter: 176 loss: 1.47721732e-06
Iter: 177 loss: 1.47698006e-06
Iter: 178 loss: 1.47578658e-06
Iter: 179 loss: 1.47280889e-06
Iter: 180 loss: 1.5132922e-06
Iter: 181 loss: 1.47260221e-06
Iter: 182 loss: 1.47067749e-06
Iter: 183 loss: 1.48229242e-06
Iter: 184 loss: 1.47037883e-06
Iter: 185 loss: 1.46889602e-06
Iter: 186 loss: 1.46716275e-06
Iter: 187 loss: 1.46703815e-06
Iter: 188 loss: 1.46399475e-06
Iter: 189 loss: 1.48024787e-06
Iter: 190 loss: 1.4636621e-06
Iter: 191 loss: 1.4618762e-06
Iter: 192 loss: 1.45868557e-06
Iter: 193 loss: 1.53192525e-06
Iter: 194 loss: 1.45870126e-06
Iter: 195 loss: 1.45724971e-06
Iter: 196 loss: 1.45648164e-06
Iter: 197 loss: 1.45514548e-06
Iter: 198 loss: 1.45414288e-06
Iter: 199 loss: 1.45364811e-06
Iter: 200 loss: 1.45097022e-06
Iter: 201 loss: 1.4579897e-06
Iter: 202 loss: 1.45003423e-06
Iter: 203 loss: 1.4484549e-06
Iter: 204 loss: 1.46041134e-06
Iter: 205 loss: 1.44833598e-06
Iter: 206 loss: 1.44670969e-06
Iter: 207 loss: 1.44720843e-06
Iter: 208 loss: 1.44566434e-06
Iter: 209 loss: 1.44349e-06
Iter: 210 loss: 1.45160902e-06
Iter: 211 loss: 1.44296905e-06
Iter: 212 loss: 1.44374053e-06
Iter: 213 loss: 1.44236958e-06
Iter: 214 loss: 1.44197577e-06
Iter: 215 loss: 1.44051614e-06
Iter: 216 loss: 1.43820216e-06
Iter: 217 loss: 1.43807256e-06
Iter: 218 loss: 1.43673628e-06
Iter: 219 loss: 1.43643024e-06
Iter: 220 loss: 1.43546606e-06
Iter: 221 loss: 1.43484351e-06
Iter: 222 loss: 1.43437831e-06
Iter: 223 loss: 1.43243778e-06
Iter: 224 loss: 1.43535078e-06
Iter: 225 loss: 1.43139141e-06
Iter: 226 loss: 1.42977387e-06
Iter: 227 loss: 1.43689613e-06
Iter: 228 loss: 1.42944782e-06
Iter: 229 loss: 1.42762167e-06
Iter: 230 loss: 1.42743238e-06
Iter: 231 loss: 1.42613862e-06
Iter: 232 loss: 1.42452507e-06
Iter: 233 loss: 1.42805357e-06
Iter: 234 loss: 1.42387876e-06
Iter: 235 loss: 1.42188969e-06
Iter: 236 loss: 1.43849684e-06
Iter: 237 loss: 1.42176827e-06
Iter: 238 loss: 1.42051204e-06
Iter: 239 loss: 1.42841748e-06
Iter: 240 loss: 1.4203639e-06
Iter: 241 loss: 1.41922942e-06
Iter: 242 loss: 1.41731277e-06
Iter: 243 loss: 1.46364027e-06
Iter: 244 loss: 1.41724968e-06
Iter: 245 loss: 1.41676765e-06
Iter: 246 loss: 1.41596104e-06
Iter: 247 loss: 1.4151949e-06
Iter: 248 loss: 1.42501949e-06
Iter: 249 loss: 1.41521957e-06
Iter: 250 loss: 1.41472208e-06
Iter: 251 loss: 1.41325177e-06
Iter: 252 loss: 1.41354394e-06
Iter: 253 loss: 1.41176588e-06
Iter: 254 loss: 1.40955399e-06
Iter: 255 loss: 1.43279033e-06
Iter: 256 loss: 1.40945019e-06
Iter: 257 loss: 1.40808618e-06
Iter: 258 loss: 1.41053829e-06
Iter: 259 loss: 1.40753502e-06
Iter: 260 loss: 1.40551845e-06
Iter: 261 loss: 1.40806605e-06
Iter: 262 loss: 1.40455677e-06
Iter: 263 loss: 1.40331781e-06
Iter: 264 loss: 1.40604857e-06
Iter: 265 loss: 1.4027712e-06
Iter: 266 loss: 1.40080783e-06
Iter: 267 loss: 1.40054908e-06
Iter: 268 loss: 1.39915358e-06
Iter: 269 loss: 1.39785345e-06
Iter: 270 loss: 1.41716544e-06
Iter: 271 loss: 1.39786198e-06
Iter: 272 loss: 1.39654696e-06
Iter: 273 loss: 1.39444865e-06
Iter: 274 loss: 1.39448571e-06
Iter: 275 loss: 1.393086e-06
Iter: 276 loss: 1.39306587e-06
Iter: 277 loss: 1.39196163e-06
Iter: 278 loss: 1.39289739e-06
Iter: 279 loss: 1.39136296e-06
Iter: 280 loss: 1.38984137e-06
Iter: 281 loss: 1.40095085e-06
Iter: 282 loss: 1.38969426e-06
Iter: 283 loss: 1.3890533e-06
Iter: 284 loss: 1.38890778e-06
Iter: 285 loss: 1.3886247e-06
Iter: 286 loss: 1.38775658e-06
Iter: 287 loss: 1.38715654e-06
Iter: 288 loss: 1.38652081e-06
Iter: 289 loss: 1.38472899e-06
Iter: 290 loss: 1.39809913e-06
Iter: 291 loss: 1.38455925e-06
Iter: 292 loss: 1.38344444e-06
Iter: 293 loss: 1.38446376e-06
Iter: 294 loss: 1.38273708e-06
Iter: 295 loss: 1.38087955e-06
Iter: 296 loss: 1.39281406e-06
Iter: 297 loss: 1.38070084e-06
Iter: 298 loss: 1.37967436e-06
Iter: 299 loss: 1.37922757e-06
Iter: 300 loss: 1.37873542e-06
Iter: 301 loss: 1.37702909e-06
Iter: 302 loss: 1.38786856e-06
Iter: 303 loss: 1.37683116e-06
Iter: 304 loss: 1.3756927e-06
Iter: 305 loss: 1.38294718e-06
Iter: 306 loss: 1.37555173e-06
Iter: 307 loss: 1.37454913e-06
Iter: 308 loss: 1.37290908e-06
Iter: 309 loss: 1.37293637e-06
Iter: 310 loss: 1.37178858e-06
Iter: 311 loss: 1.38957125e-06
Iter: 312 loss: 1.37184281e-06
Iter: 313 loss: 1.37073562e-06
Iter: 314 loss: 1.37040843e-06
Iter: 315 loss: 1.36987785e-06
Iter: 316 loss: 1.36984761e-06
Iter: 317 loss: 1.36931499e-06
Iter: 318 loss: 1.36870267e-06
Iter: 319 loss: 1.36991787e-06
Iter: 320 loss: 1.36846722e-06
Iter: 321 loss: 1.368055e-06
Iter: 322 loss: 1.36677681e-06
Iter: 323 loss: 1.37483437e-06
Iter: 324 loss: 1.36645804e-06
Iter: 325 loss: 1.36479673e-06
Iter: 326 loss: 1.37546238e-06
Iter: 327 loss: 1.36465587e-06
Iter: 328 loss: 1.36359404e-06
Iter: 329 loss: 1.36370045e-06
Iter: 330 loss: 1.36282608e-06
Iter: 331 loss: 1.36115864e-06
Iter: 332 loss: 1.36561789e-06
Iter: 333 loss: 1.36065478e-06
Iter: 334 loss: 1.35947744e-06
Iter: 335 loss: 1.36388439e-06
Iter: 336 loss: 1.35925734e-06
Iter: 337 loss: 1.35786468e-06
Iter: 338 loss: 1.36154017e-06
Iter: 339 loss: 1.35746552e-06
Iter: 340 loss: 1.35619848e-06
Iter: 341 loss: 1.36492918e-06
Iter: 342 loss: 1.35599134e-06
Iter: 343 loss: 1.35522623e-06
Iter: 344 loss: 1.35384926e-06
Iter: 345 loss: 1.35378696e-06
Iter: 346 loss: 1.35293635e-06
Iter: 347 loss: 1.35282676e-06
Iter: 348 loss: 1.352205e-06
Iter: 349 loss: 1.35209552e-06
Iter: 350 loss: 1.35166522e-06
Iter: 351 loss: 1.35126652e-06
Iter: 352 loss: 1.35121331e-06
Iter: 353 loss: 1.35057689e-06
Iter: 354 loss: 1.3497397e-06
Iter: 355 loss: 1.34965842e-06
Iter: 356 loss: 1.34918196e-06
Iter: 357 loss: 1.34825063e-06
Iter: 358 loss: 1.36727613e-06
Iter: 359 loss: 1.34818424e-06
Iter: 360 loss: 1.34669017e-06
Iter: 361 loss: 1.3538704e-06
Iter: 362 loss: 1.346408e-06
Iter: 363 loss: 1.34528636e-06
Iter: 364 loss: 1.34769743e-06
Iter: 365 loss: 1.34487323e-06
Iter: 366 loss: 1.34370248e-06
Iter: 367 loss: 1.34325705e-06
Iter: 368 loss: 1.34273114e-06
Iter: 369 loss: 1.34156267e-06
Iter: 370 loss: 1.34159905e-06
Iter: 371 loss: 1.34069512e-06
Iter: 372 loss: 1.34166862e-06
Iter: 373 loss: 1.34010929e-06
Iter: 374 loss: 1.33886817e-06
Iter: 375 loss: 1.34176594e-06
Iter: 376 loss: 1.33831259e-06
Iter: 377 loss: 1.33742628e-06
Iter: 378 loss: 1.33897049e-06
Iter: 379 loss: 1.33697495e-06
Iter: 380 loss: 1.33567323e-06
Iter: 381 loss: 1.34105346e-06
Iter: 382 loss: 1.33544427e-06
Iter: 383 loss: 1.33467825e-06
Iter: 384 loss: 1.34199468e-06
Iter: 385 loss: 1.33468927e-06
Iter: 386 loss: 1.33420087e-06
Iter: 387 loss: 1.33423691e-06
Iter: 388 loss: 1.33397873e-06
Iter: 389 loss: 1.33310459e-06
Iter: 390 loss: 1.33314086e-06
Iter: 391 loss: 1.33219908e-06
Iter: 392 loss: 1.33120284e-06
Iter: 393 loss: 1.33121512e-06
Iter: 394 loss: 1.3303171e-06
Iter: 395 loss: 1.32929324e-06
Iter: 396 loss: 1.32911032e-06
Iter: 397 loss: 1.32810737e-06
Iter: 398 loss: 1.32803689e-06
Iter: 399 loss: 1.32750938e-06
Iter: 400 loss: 1.32756759e-06
Iter: 401 loss: 1.32709454e-06
Iter: 402 loss: 1.32616981e-06
Iter: 403 loss: 1.32676132e-06
Iter: 404 loss: 1.32557977e-06
Iter: 405 loss: 1.32479886e-06
Iter: 406 loss: 1.32907928e-06
Iter: 407 loss: 1.32472724e-06
Iter: 408 loss: 1.32374851e-06
Iter: 409 loss: 1.32292098e-06
Iter: 410 loss: 1.32264233e-06
Iter: 411 loss: 1.3215822e-06
Iter: 412 loss: 1.32962123e-06
Iter: 413 loss: 1.32152229e-06
Iter: 414 loss: 1.32072103e-06
Iter: 415 loss: 1.32250352e-06
Iter: 416 loss: 1.32041293e-06
Iter: 417 loss: 1.31985576e-06
Iter: 418 loss: 1.3198794e-06
Iter: 419 loss: 1.31928141e-06
Iter: 420 loss: 1.32053015e-06
Iter: 421 loss: 1.31910929e-06
Iter: 422 loss: 1.31881848e-06
Iter: 423 loss: 1.31811e-06
Iter: 424 loss: 1.31887191e-06
Iter: 425 loss: 1.31747288e-06
Iter: 426 loss: 1.31688716e-06
Iter: 427 loss: 1.31680099e-06
Iter: 428 loss: 1.31607703e-06
Iter: 429 loss: 1.31574427e-06
Iter: 430 loss: 1.31537774e-06
Iter: 431 loss: 1.31409251e-06
Iter: 432 loss: 1.32202604e-06
Iter: 433 loss: 1.31397212e-06
Iter: 434 loss: 1.31325919e-06
Iter: 435 loss: 1.31942329e-06
Iter: 436 loss: 1.31316915e-06
Iter: 437 loss: 1.31256411e-06
Iter: 438 loss: 1.31212346e-06
Iter: 439 loss: 1.31183526e-06
Iter: 440 loss: 1.31094453e-06
Iter: 441 loss: 1.31748993e-06
Iter: 442 loss: 1.31080014e-06
Iter: 443 loss: 1.30979925e-06
Iter: 444 loss: 1.30992203e-06
Iter: 445 loss: 1.30908916e-06
Iter: 446 loss: 1.30800686e-06
Iter: 447 loss: 1.31496881e-06
Iter: 448 loss: 1.30793205e-06
Iter: 449 loss: 1.30711283e-06
Iter: 450 loss: 1.30676335e-06
Iter: 451 loss: 1.30635317e-06
Iter: 452 loss: 1.30638773e-06
Iter: 453 loss: 1.30574529e-06
Iter: 454 loss: 1.30536023e-06
Iter: 455 loss: 1.30523438e-06
Iter: 456 loss: 1.3049937e-06
Iter: 457 loss: 1.30468811e-06
Iter: 458 loss: 1.30392539e-06
Iter: 459 loss: 1.317277e-06
Iter: 460 loss: 1.30391209e-06
Iter: 461 loss: 1.30297371e-06
Iter: 462 loss: 1.30565286e-06
Iter: 463 loss: 1.30264129e-06
Iter: 464 loss: 1.30191245e-06
Iter: 465 loss: 1.30168712e-06
Iter: 466 loss: 1.30113085e-06
Iter: 467 loss: 1.30010267e-06
Iter: 468 loss: 1.30009516e-06
Iter: 469 loss: 1.29953582e-06
Iter: 470 loss: 1.30059789e-06
Iter: 471 loss: 1.29927116e-06
Iter: 472 loss: 1.29862224e-06
Iter: 473 loss: 1.30058095e-06
Iter: 474 loss: 1.29836508e-06
Iter: 475 loss: 1.2977996e-06
Iter: 476 loss: 1.29961325e-06
Iter: 477 loss: 1.29759906e-06
Iter: 478 loss: 1.29697105e-06
Iter: 479 loss: 1.2979217e-06
Iter: 480 loss: 1.29660907e-06
Iter: 481 loss: 1.29589637e-06
Iter: 482 loss: 1.29964485e-06
Iter: 483 loss: 1.29577916e-06
Iter: 484 loss: 1.29521788e-06
Iter: 485 loss: 1.2962339e-06
Iter: 486 loss: 1.29505293e-06
Iter: 487 loss: 1.29421755e-06
Iter: 488 loss: 1.29775685e-06
Iter: 489 loss: 1.29405919e-06
Iter: 490 loss: 1.29356249e-06
Iter: 491 loss: 1.29318892e-06
Iter: 492 loss: 1.29296222e-06
Iter: 493 loss: 1.29239913e-06
Iter: 494 loss: 1.29237276e-06
Iter: 495 loss: 1.29189425e-06
Iter: 496 loss: 1.29088028e-06
Iter: 497 loss: 1.29152204e-06
Iter: 498 loss: 1.29024693e-06
Iter: 499 loss: 1.28944191e-06
Iter: 500 loss: 1.29400223e-06
Iter: 501 loss: 1.28934562e-06
Iter: 502 loss: 1.28835768e-06
Iter: 503 loss: 1.28901434e-06
Iter: 504 loss: 1.28777435e-06
Iter: 505 loss: 1.28700799e-06
Iter: 506 loss: 1.28699844e-06
Iter: 507 loss: 1.28655574e-06
Iter: 508 loss: 1.28634679e-06
Iter: 509 loss: 1.28603733e-06
Iter: 510 loss: 1.28528677e-06
Iter: 511 loss: 1.29104387e-06
Iter: 512 loss: 1.28523857e-06
Iter: 513 loss: 1.28485044e-06
Iter: 514 loss: 1.28500903e-06
Iter: 515 loss: 1.28453985e-06
Iter: 516 loss: 1.28387728e-06
Iter: 517 loss: 1.28620161e-06
Iter: 518 loss: 1.28371619e-06
Iter: 519 loss: 1.283855e-06
Iter: 520 loss: 1.28345278e-06
Iter: 521 loss: 1.28330043e-06
Iter: 522 loss: 1.28291072e-06
Iter: 523 loss: 1.28498539e-06
Iter: 524 loss: 1.28280885e-06
Iter: 525 loss: 1.28210684e-06
Iter: 526 loss: 1.28179954e-06
Iter: 527 loss: 1.28143779e-06
Iter: 528 loss: 1.280643e-06
Iter: 529 loss: 1.29067303e-06
Iter: 530 loss: 1.28068473e-06
Iter: 531 loss: 1.28016109e-06
Iter: 532 loss: 1.27959333e-06
Iter: 533 loss: 1.27964984e-06
Iter: 534 loss: 1.27872318e-06
Iter: 535 loss: 1.28355987e-06
Iter: 536 loss: 1.27867406e-06
Iter: 537 loss: 1.27805606e-06
Iter: 538 loss: 1.27997941e-06
Iter: 539 loss: 1.27786723e-06
Iter: 540 loss: 1.27706608e-06
Iter: 541 loss: 1.27683552e-06
Iter: 542 loss: 1.27629608e-06
Iter: 543 loss: 1.2755338e-06
Iter: 544 loss: 1.27553858e-06
Iter: 545 loss: 1.27498504e-06
Iter: 546 loss: 1.27456281e-06
Iter: 547 loss: 1.27433429e-06
Iter: 548 loss: 1.27360568e-06
Iter: 549 loss: 1.28194301e-06
Iter: 550 loss: 1.27356532e-06
Iter: 551 loss: 1.27348881e-06
Iter: 552 loss: 1.27343094e-06
Iter: 553 loss: 1.27312614e-06
Iter: 554 loss: 1.27262274e-06
Iter: 555 loss: 1.28183228e-06
Iter: 556 loss: 1.27263991e-06
Iter: 557 loss: 1.27208261e-06
Iter: 558 loss: 1.27258272e-06
Iter: 559 loss: 1.27187081e-06
Iter: 560 loss: 1.2714122e-06
Iter: 561 loss: 1.27251963e-06
Iter: 562 loss: 1.27123189e-06
Iter: 563 loss: 1.27057e-06
Iter: 564 loss: 1.2705641e-06
Iter: 565 loss: 1.27007343e-06
Iter: 566 loss: 1.26943701e-06
Iter: 567 loss: 1.27345857e-06
Iter: 568 loss: 1.26938016e-06
Iter: 569 loss: 1.26876523e-06
Iter: 570 loss: 1.26830673e-06
Iter: 571 loss: 1.26809277e-06
Iter: 572 loss: 1.26763371e-06
Iter: 573 loss: 1.26756402e-06
Iter: 574 loss: 1.26712257e-06
Iter: 575 loss: 1.26669613e-06
Iter: 576 loss: 1.26662417e-06
Iter: 577 loss: 1.2656069e-06
Iter: 578 loss: 1.26864336e-06
Iter: 579 loss: 1.26535008e-06
Iter: 580 loss: 1.26459258e-06
Iter: 581 loss: 1.26931036e-06
Iter: 582 loss: 1.26455257e-06
Iter: 583 loss: 1.26407531e-06
Iter: 584 loss: 1.26749023e-06
Iter: 585 loss: 1.26411771e-06
Iter: 586 loss: 1.26353336e-06
Iter: 587 loss: 1.26508644e-06
Iter: 588 loss: 1.2634016e-06
Iter: 589 loss: 1.26316e-06
Iter: 590 loss: 1.26292389e-06
Iter: 591 loss: 1.26287489e-06
Iter: 592 loss: 1.26249097e-06
Iter: 593 loss: 1.26217924e-06
Iter: 594 loss: 1.26200655e-06
Iter: 595 loss: 1.26135478e-06
Iter: 596 loss: 1.26649138e-06
Iter: 597 loss: 1.26133568e-06
Iter: 598 loss: 1.26087548e-06
Iter: 599 loss: 1.26094506e-06
Iter: 600 loss: 1.26052987e-06
Iter: 601 loss: 1.25985366e-06
Iter: 602 loss: 1.26084024e-06
Iter: 603 loss: 1.25948236e-06
Iter: 604 loss: 1.25885049e-06
Iter: 605 loss: 1.26093607e-06
Iter: 606 loss: 1.2586388e-06
Iter: 607 loss: 1.25782094e-06
Iter: 608 loss: 1.26030977e-06
Iter: 609 loss: 1.25751728e-06
Iter: 610 loss: 1.25694896e-06
Iter: 611 loss: 1.25991562e-06
Iter: 612 loss: 1.25687961e-06
Iter: 613 loss: 1.25638894e-06
Iter: 614 loss: 1.25656061e-06
Iter: 615 loss: 1.25599684e-06
Iter: 616 loss: 1.25530687e-06
Iter: 617 loss: 1.25957115e-06
Iter: 618 loss: 1.25518125e-06
Iter: 619 loss: 1.25505903e-06
Iter: 620 loss: 1.25486974e-06
Iter: 621 loss: 1.25478869e-06
Iter: 622 loss: 1.25436839e-06
Iter: 623 loss: 1.25483916e-06
Iter: 624 loss: 1.25404392e-06
Iter: 625 loss: 1.25333315e-06
Iter: 626 loss: 1.25608085e-06
Iter: 627 loss: 1.25317115e-06
Iter: 628 loss: 1.25265296e-06
Iter: 629 loss: 1.25463771e-06
Iter: 630 loss: 1.25256338e-06
Iter: 631 loss: 1.25194879e-06
Iter: 632 loss: 1.25192832e-06
Iter: 633 loss: 1.25149836e-06
Iter: 634 loss: 1.25076554e-06
Iter: 635 loss: 1.25496399e-06
Iter: 636 loss: 1.25065901e-06
Iter: 637 loss: 1.25015617e-06
Iter: 638 loss: 1.24974133e-06
Iter: 639 loss: 1.24953885e-06
Iter: 640 loss: 1.2489952e-06
Iter: 641 loss: 1.24899634e-06
Iter: 642 loss: 1.24857797e-06
Iter: 643 loss: 1.24816927e-06
Iter: 644 loss: 1.24813255e-06
Iter: 645 loss: 1.24752455e-06
Iter: 646 loss: 1.25375448e-06
Iter: 647 loss: 1.24749806e-06
Iter: 648 loss: 1.24713654e-06
Iter: 649 loss: 1.24832104e-06
Iter: 650 loss: 1.24709618e-06
Iter: 651 loss: 1.24686744e-06
Iter: 652 loss: 1.24681901e-06
Iter: 653 loss: 1.24664371e-06
Iter: 654 loss: 1.24602695e-06
Iter: 655 loss: 1.25063275e-06
Iter: 656 loss: 1.24598444e-06
Iter: 657 loss: 1.24553276e-06
Iter: 658 loss: 1.24630628e-06
Iter: 659 loss: 1.24526548e-06
Iter: 660 loss: 1.24458018e-06
Iter: 661 loss: 1.24643668e-06
Iter: 662 loss: 1.24444625e-06
Iter: 663 loss: 1.24368239e-06
Iter: 664 loss: 1.24651774e-06
Iter: 665 loss: 1.24356234e-06
Iter: 666 loss: 1.24306212e-06
Iter: 667 loss: 1.2432364e-06
Iter: 668 loss: 1.24276721e-06
Iter: 669 loss: 1.24193082e-06
Iter: 670 loss: 1.24257463e-06
Iter: 671 loss: 1.24145436e-06
Iter: 672 loss: 1.24085057e-06
Iter: 673 loss: 1.24802591e-06
Iter: 674 loss: 1.24080373e-06
Iter: 675 loss: 1.24020153e-06
Iter: 676 loss: 1.24028736e-06
Iter: 677 loss: 1.23974576e-06
Iter: 678 loss: 1.2391738e-06
Iter: 679 loss: 1.24340841e-06
Iter: 680 loss: 1.23907887e-06
Iter: 681 loss: 1.23849929e-06
Iter: 682 loss: 1.23951736e-06
Iter: 683 loss: 1.23825498e-06
Iter: 684 loss: 1.23805785e-06
Iter: 685 loss: 1.2379603e-06
Iter: 686 loss: 1.23769962e-06
Iter: 687 loss: 1.2376795e-06
Iter: 688 loss: 1.23751204e-06
Iter: 689 loss: 1.23726522e-06
Iter: 690 loss: 1.23684504e-06
Iter: 691 loss: 1.24249857e-06
Iter: 692 loss: 1.23681434e-06
Iter: 693 loss: 1.23623772e-06
Iter: 694 loss: 1.2403442e-06
Iter: 695 loss: 1.23620771e-06
Iter: 696 loss: 1.23576717e-06
Iter: 697 loss: 1.23613563e-06
Iter: 698 loss: 1.23558243e-06
Iter: 699 loss: 1.23495965e-06
Iter: 700 loss: 1.23612904e-06
Iter: 701 loss: 1.2346776e-06
Iter: 702 loss: 1.23414975e-06
Iter: 703 loss: 1.23712539e-06
Iter: 704 loss: 1.23411519e-06
Iter: 705 loss: 1.23360599e-06
Iter: 706 loss: 1.23307063e-06
Iter: 707 loss: 1.23302084e-06
Iter: 708 loss: 1.23265033e-06
Iter: 709 loss: 1.23258974e-06
Iter: 710 loss: 1.23224095e-06
Iter: 711 loss: 1.23208565e-06
Iter: 712 loss: 1.23193263e-06
Iter: 713 loss: 1.23139398e-06
Iter: 714 loss: 1.23335985e-06
Iter: 715 loss: 1.23120117e-06
Iter: 716 loss: 1.23098198e-06
Iter: 717 loss: 1.23099028e-06
Iter: 718 loss: 1.23076916e-06
Iter: 719 loss: 1.23112932e-06
Iter: 720 loss: 1.23069856e-06
Iter: 721 loss: 1.2303941e-06
Iter: 722 loss: 1.22984738e-06
Iter: 723 loss: 1.23777204e-06
Iter: 724 loss: 1.22979498e-06
Iter: 725 loss: 1.22942356e-06
Iter: 726 loss: 1.2313576e-06
Iter: 727 loss: 1.22926508e-06
Iter: 728 loss: 1.22882989e-06
Iter: 729 loss: 1.22929112e-06
Iter: 730 loss: 1.22850281e-06
Iter: 731 loss: 1.2280085e-06
Iter: 732 loss: 1.23189773e-06
Iter: 733 loss: 1.22793972e-06
Iter: 734 loss: 1.22765709e-06
Iter: 735 loss: 1.22736128e-06
Iter: 736 loss: 1.22727943e-06
Iter: 737 loss: 1.22667529e-06
Iter: 738 loss: 1.22980055e-06
Iter: 739 loss: 1.22655604e-06
Iter: 740 loss: 1.22612869e-06
Iter: 741 loss: 1.22630638e-06
Iter: 742 loss: 1.2258638e-06
Iter: 743 loss: 1.22520123e-06
Iter: 744 loss: 1.23019618e-06
Iter: 745 loss: 1.22513461e-06
Iter: 746 loss: 1.22479537e-06
Iter: 747 loss: 1.22660549e-06
Iter: 748 loss: 1.2246943e-06
Iter: 749 loss: 1.22443657e-06
Iter: 750 loss: 1.22538131e-06
Iter: 751 loss: 1.22436086e-06
Iter: 752 loss: 1.2240281e-06
Iter: 753 loss: 1.22797019e-06
Iter: 754 loss: 1.22396796e-06
Iter: 755 loss: 1.2237756e-06
Iter: 756 loss: 1.22362303e-06
Iter: 757 loss: 1.2235854e-06
Iter: 758 loss: 1.22330437e-06
Iter: 759 loss: 1.22266033e-06
Iter: 760 loss: 1.23299e-06
Iter: 761 loss: 1.22265396e-06
Iter: 762 loss: 1.22206939e-06
Iter: 763 loss: 1.22951656e-06
Iter: 764 loss: 1.22205063e-06
Iter: 765 loss: 1.22161987e-06
Iter: 766 loss: 1.22219967e-06
Iter: 767 loss: 1.22141273e-06
Iter: 768 loss: 1.22081315e-06
Iter: 769 loss: 1.2216658e-06
Iter: 770 loss: 1.2205262e-06
Iter: 771 loss: 1.22015524e-06
Iter: 772 loss: 1.22289623e-06
Iter: 773 loss: 1.2201117e-06
Iter: 774 loss: 1.21967105e-06
Iter: 775 loss: 1.21912922e-06
Iter: 776 loss: 1.21913797e-06
Iter: 777 loss: 1.21857272e-06
Iter: 778 loss: 1.21859568e-06
Iter: 779 loss: 1.21813378e-06
Iter: 780 loss: 1.2184762e-06
Iter: 781 loss: 1.21789799e-06
Iter: 782 loss: 1.21731978e-06
Iter: 783 loss: 1.22012239e-06
Iter: 784 loss: 1.21720257e-06
Iter: 785 loss: 1.21717881e-06
Iter: 786 loss: 1.21703295e-06
Iter: 787 loss: 1.2168606e-06
Iter: 788 loss: 1.21656615e-06
Iter: 789 loss: 1.22004622e-06
Iter: 790 loss: 1.21652556e-06
Iter: 791 loss: 1.2160441e-06
Iter: 792 loss: 1.215976e-06
Iter: 793 loss: 1.21566313e-06
Iter: 794 loss: 1.21529115e-06
Iter: 795 loss: 1.21594712e-06
Iter: 796 loss: 1.21510152e-06
Iter: 797 loss: 1.21460289e-06
Iter: 798 loss: 1.21708217e-06
Iter: 799 loss: 1.21448102e-06
Iter: 800 loss: 1.21405594e-06
Iter: 801 loss: 1.21503422e-06
Iter: 802 loss: 1.2139202e-06
Iter: 803 loss: 1.21342009e-06
Iter: 804 loss: 1.21318351e-06
Iter: 805 loss: 1.21298172e-06
Iter: 806 loss: 1.21237349e-06
Iter: 807 loss: 1.21979724e-06
Iter: 808 loss: 1.21235871e-06
Iter: 809 loss: 1.21203993e-06
Iter: 810 loss: 1.21169114e-06
Iter: 811 loss: 1.21159178e-06
Iter: 812 loss: 1.21109042e-06
Iter: 813 loss: 1.21850508e-06
Iter: 814 loss: 1.21110065e-06
Iter: 815 loss: 1.21074095e-06
Iter: 816 loss: 1.2114026e-06
Iter: 817 loss: 1.2106118e-06
Iter: 818 loss: 1.21022504e-06
Iter: 819 loss: 1.21465064e-06
Iter: 820 loss: 1.21026119e-06
Iter: 821 loss: 1.20984839e-06
Iter: 822 loss: 1.20978257e-06
Iter: 823 loss: 1.20950597e-06
Iter: 824 loss: 1.20916218e-06
Iter: 825 loss: 1.20966047e-06
Iter: 826 loss: 1.209071e-06
Iter: 827 loss: 1.2087213e-06
Iter: 828 loss: 1.20822597e-06
Iter: 829 loss: 1.20822824e-06
Iter: 830 loss: 1.2078068e-06
Iter: 831 loss: 1.21408902e-06
Iter: 832 loss: 1.20780646e-06
Iter: 833 loss: 1.20733068e-06
Iter: 834 loss: 1.20798882e-06
Iter: 835 loss: 1.20727236e-06
Iter: 836 loss: 1.20671893e-06
Iter: 837 loss: 1.20723917e-06
Iter: 838 loss: 1.20651578e-06
Iter: 839 loss: 1.20603079e-06
Iter: 840 loss: 1.20691357e-06
Iter: 841 loss: 1.20579591e-06
Iter: 842 loss: 1.20521224e-06
Iter: 843 loss: 1.20675713e-06
Iter: 844 loss: 1.2049677e-06
Iter: 845 loss: 1.20451705e-06
Iter: 846 loss: 1.20588334e-06
Iter: 847 loss: 1.20434993e-06
Iter: 848 loss: 1.20377342e-06
Iter: 849 loss: 1.20620166e-06
Iter: 850 loss: 1.20369805e-06
Iter: 851 loss: 1.20333038e-06
Iter: 852 loss: 1.20699281e-06
Iter: 853 loss: 1.20336836e-06
Iter: 854 loss: 1.20312245e-06
Iter: 855 loss: 1.20314803e-06
Iter: 856 loss: 1.20299183e-06
Iter: 857 loss: 1.20264338e-06
Iter: 858 loss: 1.20328059e-06
Iter: 859 loss: 1.20234517e-06
Iter: 860 loss: 1.20178015e-06
Iter: 861 loss: 1.20690038e-06
Iter: 862 loss: 1.20175491e-06
Iter: 863 loss: 1.2013852e-06
Iter: 864 loss: 1.20135121e-06
Iter: 865 loss: 1.20109348e-06
Iter: 866 loss: 1.2005172e-06
Iter: 867 loss: 1.20237257e-06
Iter: 868 loss: 1.20029983e-06
Iter: 869 loss: 1.19991887e-06
Iter: 870 loss: 1.20349227e-06
Iter: 871 loss: 1.19989477e-06
Iter: 872 loss: 1.19944571e-06
Iter: 873 loss: 1.19895572e-06
Iter: 874 loss: 1.19893593e-06
Iter: 875 loss: 1.19838069e-06
Iter: 876 loss: 1.20389473e-06
Iter: 877 loss: 1.19830452e-06
Iter: 878 loss: 1.19794595e-06
Iter: 879 loss: 1.19818969e-06
Iter: 880 loss: 1.19766185e-06
Iter: 881 loss: 1.19716992e-06
Iter: 882 loss: 1.20041e-06
Iter: 883 loss: 1.19709625e-06
Iter: 884 loss: 1.19670062e-06
Iter: 885 loss: 1.19786864e-06
Iter: 886 loss: 1.19661058e-06
Iter: 887 loss: 1.19633387e-06
Iter: 888 loss: 1.1963175e-06
Iter: 889 loss: 1.19605681e-06
Iter: 890 loss: 1.19567301e-06
Iter: 891 loss: 1.19567653e-06
Iter: 892 loss: 1.19546667e-06
Iter: 893 loss: 1.19533308e-06
Iter: 894 loss: 1.19520155e-06
Iter: 895 loss: 1.19476317e-06
Iter: 896 loss: 1.19535616e-06
Iter: 897 loss: 1.194476e-06
Iter: 898 loss: 1.19419838e-06
Iter: 899 loss: 1.19648757e-06
Iter: 900 loss: 1.19409651e-06
Iter: 901 loss: 1.19380547e-06
Iter: 902 loss: 1.19405081e-06
Iter: 903 loss: 1.19360652e-06
Iter: 904 loss: 1.19309527e-06
Iter: 905 loss: 1.1940831e-06
Iter: 906 loss: 1.19290257e-06
Iter: 907 loss: 1.19251149e-06
Iter: 908 loss: 1.19290678e-06
Iter: 909 loss: 1.19229048e-06
Iter: 910 loss: 1.19177628e-06
Iter: 911 loss: 1.19375613e-06
Iter: 912 loss: 1.19169556e-06
Iter: 913 loss: 1.19136223e-06
Iter: 914 loss: 1.19347908e-06
Iter: 915 loss: 1.19129948e-06
Iter: 916 loss: 1.19101867e-06
Iter: 917 loss: 1.19136484e-06
Iter: 918 loss: 1.19079527e-06
Iter: 919 loss: 1.19058177e-06
Iter: 920 loss: 1.19059018e-06
Iter: 921 loss: 1.19031654e-06
Iter: 922 loss: 1.19119272e-06
Iter: 923 loss: 1.1902506e-06
Iter: 924 loss: 1.19013021e-06
Iter: 925 loss: 1.18966909e-06
Iter: 926 loss: 1.19137451e-06
Iter: 927 loss: 1.18951834e-06
Iter: 928 loss: 1.188998e-06
Iter: 929 loss: 1.19504045e-06
Iter: 930 loss: 1.18903222e-06
Iter: 931 loss: 1.18865682e-06
Iter: 932 loss: 1.18893854e-06
Iter: 933 loss: 1.1884614e-06
Iter: 934 loss: 1.18801859e-06
Iter: 935 loss: 1.18881007e-06
Iter: 936 loss: 1.18784146e-06
Iter: 937 loss: 1.18753485e-06
Iter: 938 loss: 1.19144124e-06
Iter: 939 loss: 1.18749415e-06
Iter: 940 loss: 1.18727098e-06
Iter: 941 loss: 1.18677292e-06
Iter: 942 loss: 1.19671927e-06
Iter: 943 loss: 1.1867362e-06
Iter: 944 loss: 1.18623439e-06
Iter: 945 loss: 1.19182187e-06
Iter: 946 loss: 1.18620733e-06
Iter: 947 loss: 1.18578851e-06
Iter: 948 loss: 1.18560104e-06
Iter: 949 loss: 1.18544358e-06
Iter: 950 loss: 1.18492108e-06
Iter: 951 loss: 1.19155197e-06
Iter: 952 loss: 1.18494063e-06
Iter: 953 loss: 1.18460389e-06
Iter: 954 loss: 1.18552384e-06
Iter: 955 loss: 1.18457831e-06
Iter: 956 loss: 1.18437811e-06
Iter: 957 loss: 1.18439357e-06
Iter: 958 loss: 1.18422349e-06
Iter: 959 loss: 1.18386311e-06
Iter: 960 loss: 1.18801745e-06
Iter: 961 loss: 1.18383855e-06
Iter: 962 loss: 1.18349431e-06
Iter: 963 loss: 1.18386106e-06
Iter: 964 loss: 1.18341723e-06
Iter: 965 loss: 1.1828738e-06
Iter: 966 loss: 1.18299272e-06
Iter: 967 loss: 1.18252694e-06
Iter: 968 loss: 1.1820523e-06
Iter: 969 loss: 1.18687285e-06
Iter: 970 loss: 1.18205776e-06
Iter: 971 loss: 1.18169032e-06
Iter: 972 loss: 1.18143532e-06
Iter: 973 loss: 1.18122443e-06
Iter: 974 loss: 1.18094863e-06
Iter: 975 loss: 1.18097387e-06
Iter: 976 loss: 1.18075536e-06
Iter: 977 loss: 1.18074115e-06
Iter: 978 loss: 1.18049184e-06
Iter: 979 loss: 1.18007506e-06
Iter: 980 loss: 1.18069943e-06
Iter: 981 loss: 1.1798877e-06
Iter: 982 loss: 1.17955233e-06
Iter: 983 loss: 1.18148239e-06
Iter: 984 loss: 1.17945831e-06
Iter: 985 loss: 1.17912043e-06
Iter: 986 loss: 1.1807283e-06
Iter: 987 loss: 1.17909542e-06
Iter: 988 loss: 1.17893023e-06
Iter: 989 loss: 1.17890818e-06
Iter: 990 loss: 1.17870877e-06
Iter: 991 loss: 1.17865784e-06
Iter: 992 loss: 1.17850573e-06
Iter: 993 loss: 1.1783286e-06
Iter: 994 loss: 1.17807565e-06
Iter: 995 loss: 1.1780844e-06
Iter: 996 loss: 1.17774448e-06
Iter: 997 loss: 1.17974866e-06
Iter: 998 loss: 1.17768582e-06
Iter: 999 loss: 1.17747811e-06
Iter: 1000 loss: 1.17754712e-06
Iter: 1001 loss: 1.17728791e-06
Iter: 1002 loss: 1.17687216e-06
Iter: 1003 loss: 1.17852096e-06
Iter: 1004 loss: 1.17676518e-06
Iter: 1005 loss: 1.17652439e-06
Iter: 1006 loss: 1.17666377e-06
Iter: 1007 loss: 1.17636432e-06
Iter: 1008 loss: 1.17590162e-06
Iter: 1009 loss: 1.1768949e-06
Iter: 1010 loss: 1.17574928e-06
Iter: 1011 loss: 1.17537536e-06
Iter: 1012 loss: 1.1776383e-06
Iter: 1013 loss: 1.17529748e-06
Iter: 1014 loss: 1.17502009e-06
Iter: 1015 loss: 1.17470279e-06
Iter: 1016 loss: 1.17467948e-06
Iter: 1017 loss: 1.17444256e-06
Iter: 1018 loss: 1.17436298e-06
Iter: 1019 loss: 1.17418574e-06
Iter: 1020 loss: 1.17419074e-06
Iter: 1021 loss: 1.17402499e-06
Iter: 1022 loss: 1.17413299e-06
Iter: 1023 loss: 1.17388845e-06
Iter: 1024 loss: 1.17373031e-06
Iter: 1025 loss: 1.1733764e-06
Iter: 1026 loss: 1.17339698e-06
Iter: 1027 loss: 1.17312049e-06
Iter: 1028 loss: 1.17414697e-06
Iter: 1029 loss: 1.17305126e-06
Iter: 1030 loss: 1.1727534e-06
Iter: 1031 loss: 1.17283707e-06
Iter: 1032 loss: 1.17253217e-06
Iter: 1033 loss: 1.17221543e-06
Iter: 1034 loss: 1.17500042e-06
Iter: 1035 loss: 1.17210334e-06
Iter: 1036 loss: 1.17189325e-06
Iter: 1037 loss: 1.1715955e-06
Iter: 1038 loss: 1.17155673e-06
Iter: 1039 loss: 1.17110062e-06
Iter: 1040 loss: 1.17544107e-06
Iter: 1041 loss: 1.17105935e-06
Iter: 1042 loss: 1.17071704e-06
Iter: 1043 loss: 1.1704326e-06
Iter: 1044 loss: 1.17024047e-06
Iter: 1045 loss: 1.16953515e-06
Iter: 1046 loss: 1.17253967e-06
Iter: 1047 loss: 1.16938941e-06
Iter: 1048 loss: 1.16895865e-06
Iter: 1049 loss: 1.16965259e-06
Iter: 1050 loss: 1.16870888e-06
Iter: 1051 loss: 1.16839988e-06
Iter: 1052 loss: 1.16835986e-06
Iter: 1053 loss: 1.16812066e-06
Iter: 1054 loss: 1.17064883e-06
Iter: 1055 loss: 1.1680886e-06
Iter: 1056 loss: 1.16796366e-06
Iter: 1057 loss: 1.16762419e-06
Iter: 1058 loss: 1.16767092e-06
Iter: 1059 loss: 1.16733725e-06
Iter: 1060 loss: 1.16705269e-06
Iter: 1061 loss: 1.16690148e-06
Iter: 1062 loss: 1.1665395e-06
Iter: 1063 loss: 1.17108345e-06
Iter: 1064 loss: 1.16650972e-06
Iter: 1065 loss: 1.16619958e-06
Iter: 1066 loss: 1.16628621e-06
Iter: 1067 loss: 1.16597e-06
Iter: 1068 loss: 1.16560977e-06
Iter: 1069 loss: 1.16811702e-06
Iter: 1070 loss: 1.165448e-06
Iter: 1071 loss: 1.16525484e-06
Iter: 1072 loss: 1.16521142e-06
Iter: 1073 loss: 1.16504543e-06
Iter: 1074 loss: 1.16467663e-06
Iter: 1075 loss: 1.16797992e-06
Iter: 1076 loss: 1.16461013e-06
Iter: 1077 loss: 1.16440174e-06
Iter: 1078 loss: 1.16440049e-06
Iter: 1079 loss: 1.16421438e-06
Iter: 1080 loss: 1.16373337e-06
Iter: 1081 loss: 1.16399451e-06
Iter: 1082 loss: 1.16349133e-06
Iter: 1083 loss: 1.1632734e-06
Iter: 1084 loss: 1.16326123e-06
Iter: 1085 loss: 1.16302e-06
Iter: 1086 loss: 1.1656615e-06
Iter: 1087 loss: 1.16299384e-06
Iter: 1088 loss: 1.16286026e-06
Iter: 1089 loss: 1.16262345e-06
Iter: 1090 loss: 1.16266e-06
Iter: 1091 loss: 1.1623813e-06
Iter: 1092 loss: 1.16254932e-06
Iter: 1093 loss: 1.16219167e-06
Iter: 1094 loss: 1.16195713e-06
Iter: 1095 loss: 1.16221236e-06
Iter: 1096 loss: 1.16183571e-06
Iter: 1097 loss: 1.16141973e-06
Iter: 1098 loss: 1.16188585e-06
Iter: 1099 loss: 1.16116621e-06
Iter: 1100 loss: 1.16085221e-06
Iter: 1101 loss: 1.16331e-06
Iter: 1102 loss: 1.16085153e-06
Iter: 1103 loss: 1.16050614e-06
Iter: 1104 loss: 1.16049227e-06
Iter: 1105 loss: 1.16031197e-06
Iter: 1106 loss: 1.15992907e-06
Iter: 1107 loss: 1.16255717e-06
Iter: 1108 loss: 1.15989667e-06
Iter: 1109 loss: 1.15965179e-06
Iter: 1110 loss: 1.15992657e-06
Iter: 1111 loss: 1.15949695e-06
Iter: 1112 loss: 1.15915168e-06
Iter: 1113 loss: 1.16038245e-06
Iter: 1114 loss: 1.15915054e-06
Iter: 1115 loss: 1.15886655e-06
Iter: 1116 loss: 1.15899138e-06
Iter: 1117 loss: 1.15877037e-06
Iter: 1118 loss: 1.15867147e-06
Iter: 1119 loss: 1.15856869e-06
Iter: 1120 loss: 1.1584201e-06
Iter: 1121 loss: 1.15826674e-06
Iter: 1122 loss: 1.15827368e-06
Iter: 1123 loss: 1.15802345e-06
Iter: 1124 loss: 1.15809212e-06
Iter: 1125 loss: 1.15789226e-06
Iter: 1126 loss: 1.15766954e-06
Iter: 1127 loss: 1.15759497e-06
Iter: 1128 loss: 1.15739431e-06
Iter: 1129 loss: 1.15719615e-06
Iter: 1130 loss: 1.15985972e-06
Iter: 1131 loss: 1.15713431e-06
Iter: 1132 loss: 1.15692455e-06
Iter: 1133 loss: 1.15675573e-06
Iter: 1134 loss: 1.15669354e-06
Iter: 1135 loss: 1.15637431e-06
Iter: 1136 loss: 1.15795638e-06
Iter: 1137 loss: 1.15628768e-06
Iter: 1138 loss: 1.15598345e-06
Iter: 1139 loss: 1.15668115e-06
Iter: 1140 loss: 1.15588193e-06
Iter: 1141 loss: 1.15565092e-06
Iter: 1142 loss: 1.1560868e-06
Iter: 1143 loss: 1.15547152e-06
Iter: 1144 loss: 1.15509818e-06
Iter: 1145 loss: 1.15637e-06
Iter: 1146 loss: 1.15503622e-06
Iter: 1147 loss: 1.15471153e-06
Iter: 1148 loss: 1.15495561e-06
Iter: 1149 loss: 1.15449734e-06
Iter: 1150 loss: 1.15468458e-06
Iter: 1151 loss: 1.15444459e-06
Iter: 1152 loss: 1.1543176e-06
Iter: 1153 loss: 1.1542395e-06
Iter: 1154 loss: 1.15414605e-06
Iter: 1155 loss: 1.15407624e-06
Iter: 1156 loss: 1.15390333e-06
Iter: 1157 loss: 1.15392857e-06
Iter: 1158 loss: 1.15364958e-06
Iter: 1159 loss: 1.15392913e-06
Iter: 1160 loss: 1.15343914e-06
Iter: 1161 loss: 1.15322223e-06
Iter: 1162 loss: 1.15423836e-06
Iter: 1163 loss: 1.1531564e-06
Iter: 1164 loss: 1.15284138e-06
Iter: 1165 loss: 1.1526821e-06
Iter: 1166 loss: 1.15253806e-06
Iter: 1167 loss: 1.15219541e-06
Iter: 1168 loss: 1.15643229e-06
Iter: 1169 loss: 1.15220519e-06
Iter: 1170 loss: 1.15193666e-06
Iter: 1171 loss: 1.15199464e-06
Iter: 1172 loss: 1.15183434e-06
Iter: 1173 loss: 1.15146338e-06
Iter: 1174 loss: 1.15279659e-06
Iter: 1175 loss: 1.15137925e-06
Iter: 1176 loss: 1.15115654e-06
Iter: 1177 loss: 1.15165744e-06
Iter: 1178 loss: 1.15101057e-06
Iter: 1179 loss: 1.15064768e-06
Iter: 1180 loss: 1.15083071e-06
Iter: 1181 loss: 1.15048499e-06
Iter: 1182 loss: 1.15026978e-06
Iter: 1183 loss: 1.15022726e-06
Iter: 1184 loss: 1.14999625e-06
Iter: 1185 loss: 1.1508663e-06
Iter: 1186 loss: 1.14988848e-06
Iter: 1187 loss: 1.14977752e-06
Iter: 1188 loss: 1.14954094e-06
Iter: 1189 loss: 1.14950114e-06
Iter: 1190 loss: 1.14924262e-06
Iter: 1191 loss: 1.15020089e-06
Iter: 1192 loss: 1.14919601e-06
Iter: 1193 loss: 1.14893783e-06
Iter: 1194 loss: 1.14906993e-06
Iter: 1195 loss: 1.14874558e-06
Iter: 1196 loss: 1.14837519e-06
Iter: 1197 loss: 1.14962768e-06
Iter: 1198 loss: 1.14833097e-06
Iter: 1199 loss: 1.14804197e-06
Iter: 1200 loss: 1.14831437e-06
Iter: 1201 loss: 1.1479201e-06
Iter: 1202 loss: 1.14738327e-06
Iter: 1203 loss: 1.14785564e-06
Iter: 1204 loss: 1.14717022e-06
Iter: 1205 loss: 1.14682939e-06
Iter: 1206 loss: 1.1507766e-06
Iter: 1207 loss: 1.14679801e-06
Iter: 1208 loss: 1.1465396e-06
Iter: 1209 loss: 1.14662453e-06
Iter: 1210 loss: 1.1463103e-06
Iter: 1211 loss: 1.14600175e-06
Iter: 1212 loss: 1.14785348e-06
Iter: 1213 loss: 1.1459e-06
Iter: 1214 loss: 1.14570696e-06
Iter: 1215 loss: 1.14669638e-06
Iter: 1216 loss: 1.14569207e-06
Iter: 1217 loss: 1.14544468e-06
Iter: 1218 loss: 1.14833176e-06
Iter: 1219 loss: 1.14545742e-06
Iter: 1220 loss: 1.14536533e-06
Iter: 1221 loss: 1.14513e-06
Iter: 1222 loss: 1.15001944e-06
Iter: 1223 loss: 1.14513693e-06
Iter: 1224 loss: 1.14490626e-06
Iter: 1225 loss: 1.14528052e-06
Iter: 1226 loss: 1.14477359e-06
Iter: 1227 loss: 1.14450154e-06
Iter: 1228 loss: 1.14482941e-06
Iter: 1229 loss: 1.14439752e-06
Iter: 1230 loss: 1.14410966e-06
Iter: 1231 loss: 1.14638101e-06
Iter: 1232 loss: 1.14412876e-06
Iter: 1233 loss: 1.14395584e-06
Iter: 1234 loss: 1.14397199e-06
Iter: 1235 loss: 1.14380259e-06
Iter: 1236 loss: 1.14353952e-06
Iter: 1237 loss: 1.14502154e-06
Iter: 1238 loss: 1.14353668e-06
Iter: 1239 loss: 1.1433616e-06
Iter: 1240 loss: 1.14355112e-06
Iter: 1241 loss: 1.14327941e-06
Iter: 1242 loss: 1.14303532e-06
Iter: 1243 loss: 1.14320801e-06
Iter: 1244 loss: 1.14289946e-06
Iter: 1245 loss: 1.14261798e-06
Iter: 1246 loss: 1.14401541e-06
Iter: 1247 loss: 1.14254863e-06
Iter: 1248 loss: 1.14231898e-06
Iter: 1249 loss: 1.14238833e-06
Iter: 1250 loss: 1.14218358e-06
Iter: 1251 loss: 1.14220165e-06
Iter: 1252 loss: 1.14197292e-06
Iter: 1253 loss: 1.14191482e-06
Iter: 1254 loss: 1.14168347e-06
Iter: 1255 loss: 1.14454633e-06
Iter: 1256 loss: 1.14172281e-06
Iter: 1257 loss: 1.14153079e-06
Iter: 1258 loss: 1.14171542e-06
Iter: 1259 loss: 1.14138743e-06
Iter: 1260 loss: 1.14113857e-06
Iter: 1261 loss: 1.14184081e-06
Iter: 1262 loss: 1.14103966e-06
Iter: 1263 loss: 1.14084901e-06
Iter: 1264 loss: 1.14142733e-06
Iter: 1265 loss: 1.14077852e-06
Iter: 1266 loss: 1.14052864e-06
Iter: 1267 loss: 1.14066461e-06
Iter: 1268 loss: 1.14037289e-06
Iter: 1269 loss: 1.14011254e-06
Iter: 1270 loss: 1.14162208e-06
Iter: 1271 loss: 1.14007412e-06
Iter: 1272 loss: 1.13983504e-06
Iter: 1273 loss: 1.13995429e-06
Iter: 1274 loss: 1.13968883e-06
Iter: 1275 loss: 1.13943065e-06
Iter: 1276 loss: 1.14153238e-06
Iter: 1277 loss: 1.13942428e-06
Iter: 1278 loss: 1.1392101e-06
Iter: 1279 loss: 1.1391943e-06
Iter: 1280 loss: 1.13911301e-06
Iter: 1281 loss: 1.13878662e-06
Iter: 1282 loss: 1.14032389e-06
Iter: 1283 loss: 1.13872807e-06
Iter: 1284 loss: 1.13877172e-06
Iter: 1285 loss: 1.13867077e-06
Iter: 1286 loss: 1.138583e-06
Iter: 1287 loss: 1.13833732e-06
Iter: 1288 loss: 1.13974193e-06
Iter: 1289 loss: 1.13827423e-06
Iter: 1290 loss: 1.13799808e-06
Iter: 1291 loss: 1.13820897e-06
Iter: 1292 loss: 1.13775309e-06
Iter: 1293 loss: 1.1374417e-06
Iter: 1294 loss: 1.13917497e-06
Iter: 1295 loss: 1.13737246e-06
Iter: 1296 loss: 1.1371319e-06
Iter: 1297 loss: 1.13762985e-06
Iter: 1298 loss: 1.13701378e-06
Iter: 1299 loss: 1.13671933e-06
Iter: 1300 loss: 1.1373088e-06
Iter: 1301 loss: 1.13666033e-06
Iter: 1302 loss: 1.1363752e-06
Iter: 1303 loss: 1.13662566e-06
Iter: 1304 loss: 1.13622525e-06
Iter: 1305 loss: 1.13588271e-06
Iter: 1306 loss: 1.13761394e-06
Iter: 1307 loss: 1.13585634e-06
Iter: 1308 loss: 1.13561487e-06
Iter: 1309 loss: 1.13622309e-06
Iter: 1310 loss: 1.1355321e-06
Iter: 1311 loss: 1.13523583e-06
Iter: 1312 loss: 1.13548094e-06
Iter: 1313 loss: 1.13499391e-06
Iter: 1314 loss: 1.13472584e-06
Iter: 1315 loss: 1.13764111e-06
Iter: 1316 loss: 1.13471606e-06
Iter: 1317 loss: 1.13469582e-06
Iter: 1318 loss: 1.13463398e-06
Iter: 1319 loss: 1.13457622e-06
Iter: 1320 loss: 1.13435556e-06
Iter: 1321 loss: 1.13618466e-06
Iter: 1322 loss: 1.13429314e-06
Iter: 1323 loss: 1.13408669e-06
Iter: 1324 loss: 1.13494264e-06
Iter: 1325 loss: 1.13406873e-06
Iter: 1326 loss: 1.13389319e-06
Iter: 1327 loss: 1.13411193e-06
Iter: 1328 loss: 1.13380918e-06
Iter: 1329 loss: 1.13353849e-06
Iter: 1330 loss: 1.13366411e-06
Iter: 1331 loss: 1.13336569e-06
Iter: 1332 loss: 1.13304645e-06
Iter: 1333 loss: 1.134424e-06
Iter: 1334 loss: 1.13298427e-06
Iter: 1335 loss: 1.13265298e-06
Iter: 1336 loss: 1.1326008e-06
Iter: 1337 loss: 1.13243243e-06
Iter: 1338 loss: 1.13209308e-06
Iter: 1339 loss: 1.13536157e-06
Iter: 1340 loss: 1.1321174e-06
Iter: 1341 loss: 1.13181784e-06
Iter: 1342 loss: 1.13181829e-06
Iter: 1343 loss: 1.1316456e-06
Iter: 1344 loss: 1.13120655e-06
Iter: 1345 loss: 1.13335432e-06
Iter: 1346 loss: 1.13121325e-06
Iter: 1347 loss: 1.13096723e-06
Iter: 1348 loss: 1.13139299e-06
Iter: 1349 loss: 1.13088424e-06
Iter: 1350 loss: 1.13067642e-06
Iter: 1351 loss: 1.13247688e-06
Iter: 1352 loss: 1.13060639e-06
Iter: 1353 loss: 1.13029705e-06
Iter: 1354 loss: 1.13134092e-06
Iter: 1355 loss: 1.130172e-06
Iter: 1356 loss: 1.13005e-06
Iter: 1357 loss: 1.12992075e-06
Iter: 1358 loss: 1.12992325e-06
Iter: 1359 loss: 1.12974203e-06
Iter: 1360 loss: 1.12984105e-06
Iter: 1361 loss: 1.12960367e-06
Iter: 1362 loss: 1.12942689e-06
Iter: 1363 loss: 1.13082388e-06
Iter: 1364 loss: 1.12941063e-06
Iter: 1365 loss: 1.12922112e-06
Iter: 1366 loss: 1.12929138e-06
Iter: 1367 loss: 1.12910993e-06
Iter: 1368 loss: 1.12884845e-06
Iter: 1369 loss: 1.12889029e-06
Iter: 1370 loss: 1.12867565e-06
Iter: 1371 loss: 1.12834482e-06
Iter: 1372 loss: 1.13018189e-06
Iter: 1373 loss: 1.12833811e-06
Iter: 1374 loss: 1.12803536e-06
Iter: 1375 loss: 1.12865632e-06
Iter: 1376 loss: 1.12804992e-06
Iter: 1377 loss: 1.12775911e-06
Iter: 1378 loss: 1.12832686e-06
Iter: 1379 loss: 1.12767202e-06
Iter: 1380 loss: 1.12742669e-06
Iter: 1381 loss: 1.12774012e-06
Iter: 1382 loss: 1.12731925e-06
Iter: 1383 loss: 1.12703151e-06
Iter: 1384 loss: 1.12859288e-06
Iter: 1385 loss: 1.12706607e-06
Iter: 1386 loss: 1.12701855e-06
Iter: 1387 loss: 1.12692862e-06
Iter: 1388 loss: 1.12684688e-06
Iter: 1389 loss: 1.12666305e-06
Iter: 1390 loss: 1.12647899e-06
Iter: 1391 loss: 1.12640146e-06
Iter: 1392 loss: 1.12598889e-06
Iter: 1393 loss: 1.13148076e-06
Iter: 1394 loss: 1.12599605e-06
Iter: 1395 loss: 1.12580346e-06
Iter: 1396 loss: 1.12597979e-06
Iter: 1397 loss: 1.12566067e-06
Iter: 1398 loss: 1.12533212e-06
Iter: 1399 loss: 1.1268545e-06
Iter: 1400 loss: 1.12528994e-06
Iter: 1401 loss: 1.12512157e-06
Iter: 1402 loss: 1.12567739e-06
Iter: 1403 loss: 1.12506848e-06
Iter: 1404 loss: 1.12487373e-06
Iter: 1405 loss: 1.12462067e-06
Iter: 1406 loss: 1.1245761e-06
Iter: 1407 loss: 1.12427892e-06
Iter: 1408 loss: 1.12915166e-06
Iter: 1409 loss: 1.12424812e-06
Iter: 1410 loss: 1.12406383e-06
Iter: 1411 loss: 1.12418081e-06
Iter: 1412 loss: 1.12392081e-06
Iter: 1413 loss: 1.1236973e-06
Iter: 1414 loss: 1.12465079e-06
Iter: 1415 loss: 1.12360499e-06
Iter: 1416 loss: 1.12330099e-06
Iter: 1417 loss: 1.12329235e-06
Iter: 1418 loss: 1.12310863e-06
Iter: 1419 loss: 1.12346436e-06
Iter: 1420 loss: 1.12305861e-06
Iter: 1421 loss: 1.12294242e-06
Iter: 1422 loss: 1.12280873e-06
Iter: 1423 loss: 1.12596467e-06
Iter: 1424 loss: 1.12283215e-06
Iter: 1425 loss: 1.12268879e-06
Iter: 1426 loss: 1.12241651e-06
Iter: 1427 loss: 1.12240593e-06
Iter: 1428 loss: 1.12209455e-06
Iter: 1429 loss: 1.12554972e-06
Iter: 1430 loss: 1.12209239e-06
Iter: 1431 loss: 1.12189787e-06
Iter: 1432 loss: 1.12198984e-06
Iter: 1433 loss: 1.12173643e-06
Iter: 1434 loss: 1.12150019e-06
Iter: 1435 loss: 1.12300916e-06
Iter: 1436 loss: 1.1215003e-06
Iter: 1437 loss: 1.1212469e-06
Iter: 1438 loss: 1.12163229e-06
Iter: 1439 loss: 1.12117993e-06
Iter: 1440 loss: 1.12088833e-06
Iter: 1441 loss: 1.12065425e-06
Iter: 1442 loss: 1.12057478e-06
Iter: 1443 loss: 1.12028897e-06
Iter: 1444 loss: 1.12029306e-06
Iter: 1445 loss: 1.12010162e-06
Iter: 1446 loss: 1.12003704e-06
Iter: 1447 loss: 1.11995541e-06
Iter: 1448 loss: 1.11965244e-06
Iter: 1449 loss: 1.12017392e-06
Iter: 1450 loss: 1.1195433e-06
Iter: 1451 loss: 1.11925954e-06
Iter: 1452 loss: 1.12007456e-06
Iter: 1453 loss: 1.11915324e-06
Iter: 1454 loss: 1.11943245e-06
Iter: 1455 loss: 1.11904342e-06
Iter: 1456 loss: 1.11900499e-06
Iter: 1457 loss: 1.11887948e-06
Iter: 1458 loss: 1.11898021e-06
Iter: 1459 loss: 1.11873896e-06
Iter: 1460 loss: 1.1184959e-06
Iter: 1461 loss: 1.11918087e-06
Iter: 1462 loss: 1.11839256e-06
Iter: 1463 loss: 1.11827262e-06
Iter: 1464 loss: 1.12010241e-06
Iter: 1465 loss: 1.11824147e-06
Iter: 1466 loss: 1.11812619e-06
Iter: 1467 loss: 1.11805139e-06
Iter: 1468 loss: 1.11796976e-06
Iter: 1469 loss: 1.11778672e-06
Iter: 1470 loss: 1.11816598e-06
Iter: 1471 loss: 1.11764041e-06
Iter: 1472 loss: 1.11745476e-06
Iter: 1473 loss: 1.11850045e-06
Iter: 1474 loss: 1.11740496e-06
Iter: 1475 loss: 1.11715e-06
Iter: 1476 loss: 1.11729082e-06
Iter: 1477 loss: 1.11701866e-06
Iter: 1478 loss: 1.1167665e-06
Iter: 1479 loss: 1.11830627e-06
Iter: 1480 loss: 1.11678253e-06
Iter: 1481 loss: 1.11661859e-06
Iter: 1482 loss: 1.11673444e-06
Iter: 1483 loss: 1.11652514e-06
Iter: 1484 loss: 1.11624195e-06
Iter: 1485 loss: 1.11727161e-06
Iter: 1486 loss: 1.11627446e-06
Iter: 1487 loss: 1.11614622e-06
Iter: 1488 loss: 1.11608904e-06
Iter: 1489 loss: 1.11596137e-06
Iter: 1490 loss: 1.11593215e-06
Iter: 1491 loss: 1.115857e-06
Iter: 1492 loss: 1.11578788e-06
Iter: 1493 loss: 1.11554687e-06
Iter: 1494 loss: 1.11609711e-06
Iter: 1495 loss: 1.11549048e-06
Iter: 1496 loss: 1.11518113e-06
Iter: 1497 loss: 1.11619647e-06
Iter: 1498 loss: 1.11514271e-06
Iter: 1499 loss: 1.11493762e-06
Iter: 1500 loss: 1.11528266e-06
Iter: 1501 loss: 1.11483268e-06
Iter: 1502 loss: 1.1145778e-06
Iter: 1503 loss: 1.11501299e-06
Iter: 1504 loss: 1.11446411e-06
Iter: 1505 loss: 1.11418467e-06
Iter: 1506 loss: 1.11534916e-06
Iter: 1507 loss: 1.11416693e-06
Iter: 1508 loss: 1.11395161e-06
Iter: 1509 loss: 1.11508791e-06
Iter: 1510 loss: 1.11393354e-06
Iter: 1511 loss: 1.11372924e-06
Iter: 1512 loss: 1.11437168e-06
Iter: 1513 loss: 1.11363556e-06
Iter: 1514 loss: 1.11349209e-06
Iter: 1515 loss: 1.11338113e-06
Iter: 1516 loss: 1.11334953e-06
Iter: 1517 loss: 1.11311169e-06
Iter: 1518 loss: 1.1151003e-06
Iter: 1519 loss: 1.11307611e-06
Iter: 1520 loss: 1.11292309e-06
Iter: 1521 loss: 1.11327176e-06
Iter: 1522 loss: 1.11281076e-06
Iter: 1523 loss: 1.11264171e-06
Iter: 1524 loss: 1.11399277e-06
Iter: 1525 loss: 1.11263216e-06
Iter: 1526 loss: 1.11241707e-06
Iter: 1527 loss: 1.1129747e-06
Iter: 1528 loss: 1.11232566e-06
Iter: 1529 loss: 1.11223812e-06
Iter: 1530 loss: 1.11211034e-06
Iter: 1531 loss: 1.11530517e-06
Iter: 1532 loss: 1.11203985e-06
Iter: 1533 loss: 1.11186455e-06
Iter: 1534 loss: 1.11328427e-06
Iter: 1535 loss: 1.11183772e-06
Iter: 1536 loss: 1.1116897e-06
Iter: 1537 loss: 1.11148324e-06
Iter: 1538 loss: 1.11144925e-06
Iter: 1539 loss: 1.11114332e-06
Iter: 1540 loss: 1.11247323e-06
Iter: 1541 loss: 1.11108375e-06
Iter: 1542 loss: 1.110825e-06
Iter: 1543 loss: 1.11253189e-06
Iter: 1544 loss: 1.11079544e-06
Iter: 1545 loss: 1.110624e-06
Iter: 1546 loss: 1.11047245e-06
Iter: 1547 loss: 1.11042641e-06
Iter: 1548 loss: 1.11016243e-06
Iter: 1549 loss: 1.11146846e-06
Iter: 1550 loss: 1.11012048e-06
Iter: 1551 loss: 1.10990209e-06
Iter: 1552 loss: 1.11122665e-06
Iter: 1553 loss: 1.10986707e-06
Iter: 1554 loss: 1.10965834e-06
Iter: 1555 loss: 1.11029158e-06
Iter: 1556 loss: 1.10959672e-06
Iter: 1557 loss: 1.10942551e-06
Iter: 1558 loss: 1.10943176e-06
Iter: 1559 loss: 1.10932035e-06
Iter: 1560 loss: 1.10920428e-06
Iter: 1561 loss: 1.10922178e-06
Iter: 1562 loss: 1.10903704e-06
Iter: 1563 loss: 1.1090749e-06
Iter: 1564 loss: 1.10892938e-06
Iter: 1565 loss: 1.10883025e-06
Iter: 1566 loss: 1.10877704e-06
Iter: 1567 loss: 1.10872907e-06
Iter: 1568 loss: 1.10859992e-06
Iter: 1569 loss: 1.10836663e-06
Iter: 1570 loss: 1.10834924e-06
Iter: 1571 loss: 1.10802148e-06
Iter: 1572 loss: 1.10916699e-06
Iter: 1573 loss: 1.10792109e-06
Iter: 1574 loss: 1.10770225e-06
Iter: 1575 loss: 1.10975657e-06
Iter: 1576 loss: 1.10767655e-06
Iter: 1577 loss: 1.10746919e-06
Iter: 1578 loss: 1.10826591e-06
Iter: 1579 loss: 1.1074369e-06
Iter: 1580 loss: 1.10721828e-06
Iter: 1581 loss: 1.10728502e-06
Iter: 1582 loss: 1.1071063e-06
Iter: 1583 loss: 1.10686869e-06
Iter: 1584 loss: 1.10880558e-06
Iter: 1585 loss: 1.10686892e-06
Iter: 1586 loss: 1.10672545e-06
Iter: 1587 loss: 1.10662086e-06
Iter: 1588 loss: 1.106534e-06
Iter: 1589 loss: 1.10630481e-06
Iter: 1590 loss: 1.10812027e-06
Iter: 1591 loss: 1.10625592e-06
Iter: 1592 loss: 1.10601889e-06
Iter: 1593 loss: 1.10659903e-06
Iter: 1594 loss: 1.10596602e-06
Iter: 1595 loss: 1.10590622e-06
Iter: 1596 loss: 1.10586882e-06
Iter: 1597 loss: 1.10577867e-06
Iter: 1598 loss: 1.10557187e-06
Iter: 1599 loss: 1.10657288e-06
Iter: 1600 loss: 1.10546659e-06
Iter: 1601 loss: 1.10529913e-06
Iter: 1602 loss: 1.10549649e-06
Iter: 1603 loss: 1.10521876e-06
Iter: 1604 loss: 1.10493158e-06
Iter: 1605 loss: 1.10592418e-06
Iter: 1606 loss: 1.10486076e-06
Iter: 1607 loss: 1.10466794e-06
Iter: 1608 loss: 1.10573933e-06
Iter: 1609 loss: 1.1046028e-06
Iter: 1610 loss: 1.10442136e-06
Iter: 1611 loss: 1.10428084e-06
Iter: 1612 loss: 1.1042024e-06
Iter: 1613 loss: 1.1039815e-06
Iter: 1614 loss: 1.10507131e-06
Iter: 1615 loss: 1.10386884e-06
Iter: 1616 loss: 1.10363248e-06
Iter: 1617 loss: 1.1047639e-06
Iter: 1618 loss: 1.10353812e-06
Iter: 1619 loss: 1.10336941e-06
Iter: 1620 loss: 1.10407177e-06
Iter: 1621 loss: 1.10329506e-06
Iter: 1622 loss: 1.10311839e-06
Iter: 1623 loss: 1.10294866e-06
Iter: 1624 loss: 1.10289534e-06
Iter: 1625 loss: 1.10270048e-06
Iter: 1626 loss: 1.10270526e-06
Iter: 1627 loss: 1.10263522e-06
Iter: 1628 loss: 1.10301903e-06
Iter: 1629 loss: 1.10254678e-06
Iter: 1630 loss: 1.10243673e-06
Iter: 1631 loss: 1.10386554e-06
Iter: 1632 loss: 1.1025146e-06
Iter: 1633 loss: 1.10236329e-06
Iter: 1634 loss: 1.10221822e-06
Iter: 1635 loss: 1.10219139e-06
Iter: 1636 loss: 1.10202711e-06
Iter: 1637 loss: 1.10202382e-06
Iter: 1638 loss: 1.10191775e-06
Iter: 1639 loss: 1.10170242e-06
Iter: 1640 loss: 1.10160522e-06
Iter: 1641 loss: 1.10153292e-06
Iter: 1642 loss: 1.10129417e-06
Iter: 1643 loss: 1.1028003e-06
Iter: 1644 loss: 1.10127053e-06
Iter: 1645 loss: 1.10104202e-06
Iter: 1646 loss: 1.10186988e-06
Iter: 1647 loss: 1.10101905e-06
Iter: 1648 loss: 1.10075712e-06
Iter: 1649 loss: 1.10125745e-06
Iter: 1650 loss: 1.10077156e-06
Iter: 1651 loss: 1.10054532e-06
Iter: 1652 loss: 1.10063888e-06
Iter: 1653 loss: 1.10039855e-06
Iter: 1654 loss: 1.10018379e-06
Iter: 1655 loss: 1.10205156e-06
Iter: 1656 loss: 1.1001614e-06
Iter: 1657 loss: 1.09996472e-06
Iter: 1658 loss: 1.09993061e-06
Iter: 1659 loss: 1.09980169e-06
Iter: 1660 loss: 1.09950565e-06
Iter: 1661 loss: 1.10075939e-06
Iter: 1662 loss: 1.09944062e-06
Iter: 1663 loss: 1.09926964e-06
Iter: 1664 loss: 1.10159476e-06
Iter: 1665 loss: 1.09928419e-06
Iter: 1666 loss: 1.09919597e-06
Iter: 1667 loss: 1.09918301e-06
Iter: 1668 loss: 1.09910525e-06
Iter: 1669 loss: 1.09885991e-06
Iter: 1670 loss: 1.10049257e-06
Iter: 1671 loss: 1.09884581e-06
Iter: 1672 loss: 1.09864027e-06
Iter: 1673 loss: 1.09890686e-06
Iter: 1674 loss: 1.09856148e-06
Iter: 1675 loss: 1.09831353e-06
Iter: 1676 loss: 1.09855205e-06
Iter: 1677 loss: 1.0982402e-06
Iter: 1678 loss: 1.09794337e-06
Iter: 1679 loss: 1.09957602e-06
Iter: 1680 loss: 1.09790267e-06
Iter: 1681 loss: 1.09767291e-06
Iter: 1682 loss: 1.09793632e-06
Iter: 1683 loss: 1.09756104e-06
Iter: 1684 loss: 1.09728853e-06
Iter: 1685 loss: 1.09854614e-06
Iter: 1686 loss: 1.09719417e-06
Iter: 1687 loss: 1.09702546e-06
Iter: 1688 loss: 1.09700773e-06
Iter: 1689 loss: 1.09689188e-06
Iter: 1690 loss: 1.0965332e-06
Iter: 1691 loss: 1.09759367e-06
Iter: 1692 loss: 1.09642258e-06
Iter: 1693 loss: 1.09620748e-06
Iter: 1694 loss: 1.09919574e-06
Iter: 1695 loss: 1.09627649e-06
Iter: 1696 loss: 1.09612836e-06
Iter: 1697 loss: 1.09594134e-06
Iter: 1698 loss: 1.09590314e-06
Iter: 1699 loss: 1.09590201e-06
Iter: 1700 loss: 1.09580651e-06
Iter: 1701 loss: 1.09567372e-06
Iter: 1702 loss: 1.09575888e-06
Iter: 1703 loss: 1.09563734e-06
Iter: 1704 loss: 1.09552593e-06
Iter: 1705 loss: 1.09538655e-06
Iter: 1706 loss: 1.09873986e-06
Iter: 1707 loss: 1.09532971e-06
Iter: 1708 loss: 1.09515952e-06
Iter: 1709 loss: 1.09533539e-06
Iter: 1710 loss: 1.09500388e-06
Iter: 1711 loss: 1.09483301e-06
Iter: 1712 loss: 1.09572454e-06
Iter: 1713 loss: 1.09479026e-06
Iter: 1714 loss: 1.09453526e-06
Iter: 1715 loss: 1.0947947e-06
Iter: 1716 loss: 1.09440543e-06
Iter: 1717 loss: 1.09418602e-06
Iter: 1718 loss: 1.09572579e-06
Iter: 1719 loss: 1.09415282e-06
Iter: 1720 loss: 1.09394659e-06
Iter: 1721 loss: 1.09418215e-06
Iter: 1722 loss: 1.09383245e-06
Iter: 1723 loss: 1.09365772e-06
Iter: 1724 loss: 1.09428515e-06
Iter: 1725 loss: 1.09350685e-06
Iter: 1726 loss: 1.09330836e-06
Iter: 1727 loss: 1.09355597e-06
Iter: 1728 loss: 1.09318353e-06
Iter: 1729 loss: 1.09297366e-06
Iter: 1730 loss: 1.0953986e-06
Iter: 1731 loss: 1.09294e-06
Iter: 1732 loss: 1.09281427e-06
Iter: 1733 loss: 1.09328244e-06
Iter: 1734 loss: 1.0927638e-06
Iter: 1735 loss: 1.09271264e-06
Iter: 1736 loss: 1.09269536e-06
Iter: 1737 loss: 1.09258417e-06
Iter: 1738 loss: 1.09242114e-06
Iter: 1739 loss: 1.09449093e-06
Iter: 1740 loss: 1.09241682e-06
Iter: 1741 loss: 1.09218672e-06
Iter: 1742 loss: 1.09315408e-06
Iter: 1743 loss: 1.09215262e-06
Iter: 1744 loss: 1.09196071e-06
Iter: 1745 loss: 1.09170674e-06
Iter: 1746 loss: 1.09168946e-06
Iter: 1747 loss: 1.09152734e-06
Iter: 1748 loss: 1.09498728e-06
Iter: 1749 loss: 1.09152347e-06
Iter: 1750 loss: 1.09133407e-06
Iter: 1751 loss: 1.09168536e-06
Iter: 1752 loss: 1.09132952e-06
Iter: 1753 loss: 1.09113739e-06
Iter: 1754 loss: 1.09158668e-06
Iter: 1755 loss: 1.09108078e-06
Iter: 1756 loss: 1.09092593e-06
Iter: 1757 loss: 1.09162784e-06
Iter: 1758 loss: 1.09085647e-06
Iter: 1759 loss: 1.09075233e-06
Iter: 1760 loss: 1.09076484e-06
Iter: 1761 loss: 1.09065832e-06
Iter: 1762 loss: 1.09046255e-06
Iter: 1763 loss: 1.09108146e-06
Iter: 1764 loss: 1.09043958e-06
Iter: 1765 loss: 1.09025314e-06
Iter: 1766 loss: 1.09133623e-06
Iter: 1767 loss: 1.09027383e-06
Iter: 1768 loss: 1.09019243e-06
Iter: 1769 loss: 1.09019675e-06
Iter: 1770 loss: 1.09009784e-06
Iter: 1771 loss: 1.09003372e-06
Iter: 1772 loss: 1.09217308e-06
Iter: 1773 loss: 1.08998813e-06
Iter: 1774 loss: 1.08989207e-06
Iter: 1775 loss: 1.08992094e-06
Iter: 1776 loss: 1.0898201e-06
Iter: 1777 loss: 1.08965401e-06
Iter: 1778 loss: 1.08975951e-06
Iter: 1779 loss: 1.08949894e-06
Iter: 1780 loss: 1.08929498e-06
Iter: 1781 loss: 1.08951963e-06
Iter: 1782 loss: 1.08922075e-06
Iter: 1783 loss: 1.08895165e-06
Iter: 1784 loss: 1.08954691e-06
Iter: 1785 loss: 1.08886229e-06
Iter: 1786 loss: 1.08877975e-06
Iter: 1787 loss: 1.09066548e-06
Iter: 1788 loss: 1.08871882e-06
Iter: 1789 loss: 1.08859433e-06
Iter: 1790 loss: 1.08837048e-06
Iter: 1791 loss: 1.08838549e-06
Iter: 1792 loss: 1.08814515e-06
Iter: 1793 loss: 1.0898932e-06
Iter: 1794 loss: 1.08807637e-06
Iter: 1795 loss: 1.08795894e-06
Iter: 1796 loss: 1.08832523e-06
Iter: 1797 loss: 1.08784479e-06
Iter: 1798 loss: 1.08763231e-06
Iter: 1799 loss: 1.08815334e-06
Iter: 1800 loss: 1.08762231e-06
Iter: 1801 loss: 1.08745962e-06
Iter: 1802 loss: 1.08745166e-06
Iter: 1803 loss: 1.08728455e-06
Iter: 1804 loss: 1.08759127e-06
Iter: 1805 loss: 1.0872277e-06
Iter: 1806 loss: 1.08714721e-06
Iter: 1807 loss: 1.08697122e-06
Iter: 1808 loss: 1.08989889e-06
Iter: 1809 loss: 1.08695281e-06
Iter: 1810 loss: 1.08674226e-06
Iter: 1811 loss: 1.08755557e-06
Iter: 1812 loss: 1.08670611e-06
Iter: 1813 loss: 1.08651932e-06
Iter: 1814 loss: 1.08711788e-06
Iter: 1815 loss: 1.08642166e-06
Iter: 1816 loss: 1.08621e-06
Iter: 1817 loss: 1.08634845e-06
Iter: 1818 loss: 1.08602342e-06
Iter: 1819 loss: 1.08579479e-06
Iter: 1820 loss: 1.08592212e-06
Iter: 1821 loss: 1.0856395e-06
Iter: 1822 loss: 1.08529548e-06
Iter: 1823 loss: 1.08857921e-06
Iter: 1824 loss: 1.08533959e-06
Iter: 1825 loss: 1.08513177e-06
Iter: 1826 loss: 1.08532413e-06
Iter: 1827 loss: 1.08493077e-06
Iter: 1828 loss: 1.08469737e-06
Iter: 1829 loss: 1.08466486e-06
Iter: 1830 loss: 1.08442134e-06
Iter: 1831 loss: 1.08428719e-06
Iter: 1832 loss: 1.08426627e-06
Iter: 1833 loss: 1.084171e-06
Iter: 1834 loss: 1.08487222e-06
Iter: 1835 loss: 1.08413019e-06
Iter: 1836 loss: 1.08399354e-06
Iter: 1837 loss: 1.0849958e-06
Iter: 1838 loss: 1.08400184e-06
Iter: 1839 loss: 1.08390282e-06
Iter: 1840 loss: 1.08364588e-06
Iter: 1841 loss: 1.08745348e-06
Iter: 1842 loss: 1.08369591e-06
Iter: 1843 loss: 1.08348365e-06
Iter: 1844 loss: 1.08381766e-06
Iter: 1845 loss: 1.08338179e-06
Iter: 1846 loss: 1.08322877e-06
Iter: 1847 loss: 1.08340032e-06
Iter: 1848 loss: 1.08306483e-06
Iter: 1849 loss: 1.08281165e-06
Iter: 1850 loss: 1.08409267e-06
Iter: 1851 loss: 1.08283814e-06
Iter: 1852 loss: 1.08259e-06
Iter: 1853 loss: 1.08266045e-06
Iter: 1854 loss: 1.08246422e-06
Iter: 1855 loss: 1.0822431e-06
Iter: 1856 loss: 1.08409745e-06
Iter: 1857 loss: 1.08222616e-06
Iter: 1858 loss: 1.08203358e-06
Iter: 1859 loss: 1.08206586e-06
Iter: 1860 loss: 1.08194286e-06
Iter: 1861 loss: 1.08168456e-06
Iter: 1862 loss: 1.08269228e-06
Iter: 1863 loss: 1.08157838e-06
Iter: 1864 loss: 1.08137317e-06
Iter: 1865 loss: 1.08152949e-06
Iter: 1866 loss: 1.08122879e-06
Iter: 1867 loss: 1.0810611e-06
Iter: 1868 loss: 1.08417646e-06
Iter: 1869 loss: 1.08104337e-06
Iter: 1870 loss: 1.0809066e-06
Iter: 1871 loss: 1.08290271e-06
Iter: 1872 loss: 1.08085783e-06
Iter: 1873 loss: 1.08078007e-06
Iter: 1874 loss: 1.08064785e-06
Iter: 1875 loss: 1.08061454e-06
Iter: 1876 loss: 1.08049687e-06
Iter: 1877 loss: 1.08024187e-06
Iter: 1878 loss: 1.08027916e-06
Iter: 1879 loss: 1.08003246e-06
Iter: 1880 loss: 1.08304289e-06
Iter: 1881 loss: 1.08003178e-06
Iter: 1882 loss: 1.07986079e-06
Iter: 1883 loss: 1.08007293e-06
Iter: 1884 loss: 1.0797645e-06
Iter: 1885 loss: 1.07958533e-06
Iter: 1886 loss: 1.07948756e-06
Iter: 1887 loss: 1.0793915e-06
Iter: 1888 loss: 1.07917583e-06
Iter: 1889 loss: 1.081238e-06
Iter: 1890 loss: 1.07915116e-06
Iter: 1891 loss: 1.07901428e-06
Iter: 1892 loss: 1.07889628e-06
Iter: 1893 loss: 1.0788176e-06
Iter: 1894 loss: 1.07861388e-06
Iter: 1895 loss: 1.07857727e-06
Iter: 1896 loss: 1.07846358e-06
Iter: 1897 loss: 1.07823359e-06
Iter: 1898 loss: 1.0781971e-06
Iter: 1899 loss: 1.07810376e-06
Iter: 1900 loss: 1.07804226e-06
Iter: 1901 loss: 1.07794494e-06
Iter: 1902 loss: 1.07917162e-06
Iter: 1903 loss: 1.07792562e-06
Iter: 1904 loss: 1.07785411e-06
Iter: 1905 loss: 1.07773735e-06
Iter: 1906 loss: 1.07773553e-06
Iter: 1907 loss: 1.07757182e-06
Iter: 1908 loss: 1.0773748e-06
Iter: 1909 loss: 1.08205222e-06
Iter: 1910 loss: 1.07738015e-06
Iter: 1911 loss: 1.07710821e-06
Iter: 1912 loss: 1.07920437e-06
Iter: 1913 loss: 1.07712231e-06
Iter: 1914 loss: 1.07690346e-06
Iter: 1915 loss: 1.07760957e-06
Iter: 1916 loss: 1.07683593e-06
Iter: 1917 loss: 1.07662913e-06
Iter: 1918 loss: 1.07685423e-06
Iter: 1919 loss: 1.07651601e-06
Iter: 1920 loss: 1.07624714e-06
Iter: 1921 loss: 1.07647293e-06
Iter: 1922 loss: 1.07612914e-06
Iter: 1923 loss: 1.07579433e-06
Iter: 1924 loss: 1.07760707e-06
Iter: 1925 loss: 1.07582946e-06
Iter: 1926 loss: 1.07562641e-06
Iter: 1927 loss: 1.07634037e-06
Iter: 1928 loss: 1.07561505e-06
Iter: 1929 loss: 1.07540177e-06
Iter: 1930 loss: 1.0753447e-06
Iter: 1931 loss: 1.07525148e-06
Iter: 1932 loss: 1.07498306e-06
Iter: 1933 loss: 1.07732717e-06
Iter: 1934 loss: 1.07502387e-06
Iter: 1935 loss: 1.07491678e-06
Iter: 1936 loss: 1.07494839e-06
Iter: 1937 loss: 1.07487756e-06
Iter: 1938 loss: 1.07476831e-06
Iter: 1939 loss: 1.07475364e-06
Iter: 1940 loss: 1.07458209e-06
Iter: 1941 loss: 1.07463143e-06
Iter: 1942 loss: 1.07449273e-06
Iter: 1943 loss: 1.07439348e-06
Iter: 1944 loss: 1.07426513e-06
Iter: 1945 loss: 1.07422966e-06
Iter: 1946 loss: 1.07397045e-06
Iter: 1947 loss: 1.07488609e-06
Iter: 1948 loss: 1.07387928e-06
Iter: 1949 loss: 1.07365736e-06
Iter: 1950 loss: 1.07538722e-06
Iter: 1951 loss: 1.07360825e-06
Iter: 1952 loss: 1.07349979e-06
Iter: 1953 loss: 1.07329538e-06
Iter: 1954 loss: 1.07326775e-06
Iter: 1955 loss: 1.07301253e-06
Iter: 1956 loss: 1.07538608e-06
Iter: 1957 loss: 1.07298524e-06
Iter: 1958 loss: 1.07279311e-06
Iter: 1959 loss: 1.0731053e-06
Iter: 1960 loss: 1.07273354e-06
Iter: 1961 loss: 1.07243682e-06
Iter: 1962 loss: 1.07386768e-06
Iter: 1963 loss: 1.07238748e-06
Iter: 1964 loss: 1.07220683e-06
Iter: 1965 loss: 1.07275946e-06
Iter: 1966 loss: 1.07221581e-06
Iter: 1967 loss: 1.07209235e-06
Iter: 1968 loss: 1.07208484e-06
Iter: 1969 loss: 1.0720164e-06
Iter: 1970 loss: 1.07198684e-06
Iter: 1971 loss: 1.07192e-06
Iter: 1972 loss: 1.07181449e-06
Iter: 1973 loss: 1.07197911e-06
Iter: 1974 loss: 1.07173628e-06
Iter: 1975 loss: 1.07153733e-06
Iter: 1976 loss: 1.07136123e-06
Iter: 1977 loss: 1.07136407e-06
Iter: 1978 loss: 1.07106109e-06
Iter: 1979 loss: 1.07361666e-06
Iter: 1980 loss: 1.07105757e-06
Iter: 1981 loss: 1.0709258e-06
Iter: 1982 loss: 1.07160395e-06
Iter: 1983 loss: 1.07086362e-06
Iter: 1984 loss: 1.07066194e-06
Iter: 1985 loss: 1.07047151e-06
Iter: 1986 loss: 1.0704432e-06
Iter: 1987 loss: 1.07020537e-06
Iter: 1988 loss: 1.07236951e-06
Iter: 1989 loss: 1.07018263e-06
Iter: 1990 loss: 1.06999289e-06
Iter: 1991 loss: 1.07045059e-06
Iter: 1992 loss: 1.06988136e-06
Iter: 1993 loss: 1.06973835e-06
Iter: 1994 loss: 1.07084804e-06
Iter: 1995 loss: 1.06970197e-06
Iter: 1996 loss: 1.06951575e-06
Iter: 1997 loss: 1.06946686e-06
Iter: 1998 loss: 1.06936659e-06
Iter: 1999 loss: 1.06939535e-06
Iter: 2000 loss: 1.06927e-06
Iter: 2001 loss: 1.06922494e-06
Iter: 2002 loss: 1.06925404e-06
Iter: 2003 loss: 1.06913785e-06
Iter: 2004 loss: 1.06907851e-06
Iter: 2005 loss: 1.06905054e-06
Iter: 2006 loss: 1.06902041e-06
Iter: 2007 loss: 1.06889e-06
Iter: 2008 loss: 1.06874006e-06
Iter: 2009 loss: 1.06868504e-06
Iter: 2010 loss: 1.06851076e-06
Iter: 2011 loss: 1.06933749e-06
Iter: 2012 loss: 1.06844902e-06
Iter: 2013 loss: 1.06832169e-06
Iter: 2014 loss: 1.06893845e-06
Iter: 2015 loss: 1.06831419e-06
Iter: 2016 loss: 1.06811081e-06
Iter: 2017 loss: 1.0687304e-06
Iter: 2018 loss: 1.06806579e-06
Iter: 2019 loss: 1.06790196e-06
Iter: 2020 loss: 1.06793379e-06
Iter: 2021 loss: 1.06785546e-06
Iter: 2022 loss: 1.06766163e-06
Iter: 2023 loss: 1.06795869e-06
Iter: 2024 loss: 1.06756238e-06
Iter: 2025 loss: 1.06741118e-06
Iter: 2026 loss: 1.06876269e-06
Iter: 2027 loss: 1.06733251e-06
Iter: 2028 loss: 1.06710615e-06
Iter: 2029 loss: 1.06718051e-06
Iter: 2030 loss: 1.06698781e-06
Iter: 2031 loss: 1.067006e-06
Iter: 2032 loss: 1.06688844e-06
Iter: 2033 loss: 1.06686161e-06
Iter: 2034 loss: 1.06690663e-06
Iter: 2035 loss: 1.06679147e-06
Iter: 2036 loss: 1.06666698e-06
Iter: 2037 loss: 1.06660843e-06
Iter: 2038 loss: 1.06657535e-06
Iter: 2039 loss: 1.06644893e-06
Iter: 2040 loss: 1.06675975e-06
Iter: 2041 loss: 1.06632501e-06
Iter: 2042 loss: 1.06627044e-06
Iter: 2043 loss: 1.06638834e-06
Iter: 2044 loss: 1.06619382e-06
Iter: 2045 loss: 1.06606183e-06
Iter: 2046 loss: 1.06629784e-06
Iter: 2047 loss: 1.06599862e-06
Iter: 2048 loss: 1.06582149e-06
Iter: 2049 loss: 1.06701418e-06
Iter: 2050 loss: 1.06576817e-06
Iter: 2051 loss: 1.0656704e-06
Iter: 2052 loss: 1.06550669e-06
Iter: 2053 loss: 1.0654893e-06
Iter: 2054 loss: 1.06515517e-06
Iter: 2055 loss: 1.06659286e-06
Iter: 2056 loss: 1.06516495e-06
Iter: 2057 loss: 1.06497657e-06
Iter: 2058 loss: 1.06551192e-06
Iter: 2059 loss: 1.06495816e-06
Iter: 2060 loss: 1.06466496e-06
Iter: 2061 loss: 1.06514904e-06
Iter: 2062 loss: 1.06456332e-06
Iter: 2063 loss: 1.06449306e-06
Iter: 2064 loss: 1.06449806e-06
Iter: 2065 loss: 1.0643771e-06
Iter: 2066 loss: 1.06453695e-06
Iter: 2067 loss: 1.06431855e-06
Iter: 2068 loss: 1.0642126e-06
Iter: 2069 loss: 1.06409016e-06
Iter: 2070 loss: 1.0640357e-06
Iter: 2071 loss: 1.06391303e-06
Iter: 2072 loss: 1.06473055e-06
Iter: 2073 loss: 1.06381856e-06
Iter: 2074 loss: 1.06375103e-06
Iter: 2075 loss: 1.06363677e-06
Iter: 2076 loss: 1.06357129e-06
Iter: 2077 loss: 1.06331731e-06
Iter: 2078 loss: 1.06408845e-06
Iter: 2079 loss: 1.06325e-06
Iter: 2080 loss: 1.06310881e-06
Iter: 2081 loss: 1.06434368e-06
Iter: 2082 loss: 1.06306675e-06
Iter: 2083 loss: 1.06285756e-06
Iter: 2084 loss: 1.06283801e-06
Iter: 2085 loss: 1.06268953e-06
Iter: 2086 loss: 1.06247956e-06
Iter: 2087 loss: 1.06349273e-06
Iter: 2088 loss: 1.06241657e-06
Iter: 2089 loss: 1.06225207e-06
Iter: 2090 loss: 1.06244545e-06
Iter: 2091 loss: 1.06207926e-06
Iter: 2092 loss: 1.06185428e-06
Iter: 2093 loss: 1.06361313e-06
Iter: 2094 loss: 1.06179368e-06
Iter: 2095 loss: 1.06169853e-06
Iter: 2096 loss: 1.06223672e-06
Iter: 2097 loss: 1.06169375e-06
Iter: 2098 loss: 1.0615106e-06
Iter: 2099 loss: 1.06288735e-06
Iter: 2100 loss: 1.06144739e-06
Iter: 2101 loss: 1.0613519e-06
Iter: 2102 loss: 1.06114794e-06
Iter: 2103 loss: 1.06121252e-06
Iter: 2104 loss: 1.06101015e-06
Iter: 2105 loss: 1.06193681e-06
Iter: 2106 loss: 1.06100879e-06
Iter: 2107 loss: 1.06081825e-06
Iter: 2108 loss: 1.06075549e-06
Iter: 2109 loss: 1.06071866e-06
Iter: 2110 loss: 1.0605379e-06
Iter: 2111 loss: 1.06168329e-06
Iter: 2112 loss: 1.0605545e-06
Iter: 2113 loss: 1.06034963e-06
Iter: 2114 loss: 1.06052426e-06
Iter: 2115 loss: 1.06025846e-06
Iter: 2116 loss: 1.0600902e-06
Iter: 2117 loss: 1.06049015e-06
Iter: 2118 loss: 1.05998151e-06
Iter: 2119 loss: 1.05984645e-06
Iter: 2120 loss: 1.0602464e-06
Iter: 2121 loss: 1.05976301e-06
Iter: 2122 loss: 1.05954655e-06
Iter: 2123 loss: 1.0599606e-06
Iter: 2124 loss: 1.05953222e-06
Iter: 2125 loss: 1.05935874e-06
Iter: 2126 loss: 1.06120638e-06
Iter: 2127 loss: 1.05939853e-06
Iter: 2128 loss: 1.05929257e-06
Iter: 2129 loss: 1.05925199e-06
Iter: 2130 loss: 1.05913e-06
Iter: 2131 loss: 1.05912602e-06
Iter: 2132 loss: 1.05906724e-06
Iter: 2133 loss: 1.05905042e-06
Iter: 2134 loss: 1.05891968e-06
Iter: 2135 loss: 1.06032098e-06
Iter: 2136 loss: 1.058885e-06
Iter: 2137 loss: 1.05878303e-06
Iter: 2138 loss: 1.05916217e-06
Iter: 2139 loss: 1.05874369e-06
Iter: 2140 loss: 1.05854758e-06
Iter: 2141 loss: 1.05899198e-06
Iter: 2142 loss: 1.05843674e-06
Iter: 2143 loss: 1.05834977e-06
Iter: 2144 loss: 1.05854542e-06
Iter: 2145 loss: 1.05830168e-06
Iter: 2146 loss: 1.05810545e-06
Iter: 2147 loss: 1.0582221e-06
Iter: 2148 loss: 1.05804372e-06
Iter: 2149 loss: 1.05777212e-06
Iter: 2150 loss: 1.0596757e-06
Iter: 2151 loss: 1.05779304e-06
Iter: 2152 loss: 1.05767515e-06
Iter: 2153 loss: 1.05752338e-06
Iter: 2154 loss: 1.05747631e-06
Iter: 2155 loss: 1.05721938e-06
Iter: 2156 loss: 1.05825893e-06
Iter: 2157 loss: 1.05718982e-06
Iter: 2158 loss: 1.05702361e-06
Iter: 2159 loss: 1.05775052e-06
Iter: 2160 loss: 1.05699064e-06
Iter: 2161 loss: 1.05674224e-06
Iter: 2162 loss: 1.056972e-06
Iter: 2163 loss: 1.05661582e-06
Iter: 2164 loss: 1.05683353e-06
Iter: 2165 loss: 1.05656477e-06
Iter: 2166 loss: 1.05650588e-06
Iter: 2167 loss: 1.05638469e-06
Iter: 2168 loss: 1.05719266e-06
Iter: 2169 loss: 1.05633865e-06
Iter: 2170 loss: 1.05616164e-06
Iter: 2171 loss: 1.05662411e-06
Iter: 2172 loss: 1.05603635e-06
Iter: 2173 loss: 1.05588924e-06
Iter: 2174 loss: 1.0578749e-06
Iter: 2175 loss: 1.05587128e-06
Iter: 2176 loss: 1.05578977e-06
Iter: 2177 loss: 1.05575464e-06
Iter: 2178 loss: 1.05570427e-06
Iter: 2179 loss: 1.0556023e-06
Iter: 2180 loss: 1.05587526e-06
Iter: 2181 loss: 1.05549475e-06
Iter: 2182 loss: 1.05532536e-06
Iter: 2183 loss: 1.0557419e-06
Iter: 2184 loss: 1.05534536e-06
Iter: 2185 loss: 1.05518166e-06
Iter: 2186 loss: 1.05536378e-06
Iter: 2187 loss: 1.05506695e-06
Iter: 2188 loss: 1.05492677e-06
Iter: 2189 loss: 1.05528261e-06
Iter: 2190 loss: 1.05486788e-06
Iter: 2191 loss: 1.05464028e-06
Iter: 2192 loss: 1.05511572e-06
Iter: 2193 loss: 1.05461186e-06
Iter: 2194 loss: 1.0544012e-06
Iter: 2195 loss: 1.05559729e-06
Iter: 2196 loss: 1.05436243e-06
Iter: 2197 loss: 1.05435163e-06
Iter: 2198 loss: 1.05432787e-06
Iter: 2199 loss: 1.05429399e-06
Iter: 2200 loss: 1.05413528e-06
Iter: 2201 loss: 1.05720858e-06
Iter: 2202 loss: 1.05415165e-06
Iter: 2203 loss: 1.05403296e-06
Iter: 2204 loss: 1.05396975e-06
Iter: 2205 loss: 1.05390586e-06
Iter: 2206 loss: 1.05370759e-06
Iter: 2207 loss: 1.05537163e-06
Iter: 2208 loss: 1.05372044e-06
Iter: 2209 loss: 1.05357e-06
Iter: 2210 loss: 1.05363449e-06
Iter: 2211 loss: 1.05346032e-06
Iter: 2212 loss: 1.05336494e-06
Iter: 2213 loss: 1.0540216e-06
Iter: 2214 loss: 1.05332754e-06
Iter: 2215 loss: 1.05323852e-06
Iter: 2216 loss: 1.05325057e-06
Iter: 2217 loss: 1.05318463e-06
Iter: 2218 loss: 1.05298818e-06
Iter: 2219 loss: 1.05379956e-06
Iter: 2220 loss: 1.0529435e-06
Iter: 2221 loss: 1.05283425e-06
Iter: 2222 loss: 1.05277923e-06
Iter: 2223 loss: 1.05276081e-06
Iter: 2224 loss: 1.05248591e-06
Iter: 2225 loss: 1.05279491e-06
Iter: 2226 loss: 1.05240088e-06
Iter: 2227 loss: 1.05215031e-06
Iter: 2228 loss: 1.05307e-06
Iter: 2229 loss: 1.05206334e-06
Iter: 2230 loss: 1.05182653e-06
Iter: 2231 loss: 1.05265894e-06
Iter: 2232 loss: 1.05175764e-06
Iter: 2233 loss: 1.05164872e-06
Iter: 2234 loss: 1.05277138e-06
Iter: 2235 loss: 1.05158847e-06
Iter: 2236 loss: 1.05154095e-06
Iter: 2237 loss: 1.05156437e-06
Iter: 2238 loss: 1.0514525e-06
Iter: 2239 loss: 1.05125014e-06
Iter: 2240 loss: 1.05172671e-06
Iter: 2241 loss: 1.05115942e-06
Iter: 2242 loss: 1.05102947e-06
Iter: 2243 loss: 1.05099207e-06
Iter: 2244 loss: 1.05081938e-06
Iter: 2245 loss: 1.05104698e-06
Iter: 2246 loss: 1.0507265e-06
Iter: 2247 loss: 1.05052459e-06
Iter: 2248 loss: 1.05080176e-06
Iter: 2249 loss: 1.05044035e-06
Iter: 2250 loss: 1.05023332e-06
Iter: 2251 loss: 1.05065988e-06
Iter: 2252 loss: 1.05019808e-06
Iter: 2253 loss: 1.05000981e-06
Iter: 2254 loss: 1.05030324e-06
Iter: 2255 loss: 1.04987748e-06
Iter: 2256 loss: 1.04968126e-06
Iter: 2257 loss: 1.05108359e-06
Iter: 2258 loss: 1.04967728e-06
Iter: 2259 loss: 1.04952733e-06
Iter: 2260 loss: 1.04932269e-06
Iter: 2261 loss: 1.04929052e-06
Iter: 2262 loss: 1.04908577e-06
Iter: 2263 loss: 1.05183085e-06
Iter: 2264 loss: 1.04911953e-06
Iter: 2265 loss: 1.0489573e-06
Iter: 2266 loss: 1.0486367e-06
Iter: 2267 loss: 1.05441381e-06
Iter: 2268 loss: 1.04866626e-06
Iter: 2269 loss: 1.04908872e-06
Iter: 2270 loss: 1.04852245e-06
Iter: 2271 loss: 1.04844833e-06
Iter: 2272 loss: 1.04845117e-06
Iter: 2273 loss: 1.04843377e-06
Iter: 2274 loss: 1.04831258e-06
Iter: 2275 loss: 1.04817684e-06
Iter: 2276 loss: 1.04815467e-06
Iter: 2277 loss: 1.04797914e-06
Iter: 2278 loss: 1.04921867e-06
Iter: 2279 loss: 1.04799187e-06
Iter: 2280 loss: 1.04787546e-06
Iter: 2281 loss: 1.04783703e-06
Iter: 2282 loss: 1.04779292e-06
Iter: 2283 loss: 1.0476092e-06
Iter: 2284 loss: 1.0480743e-06
Iter: 2285 loss: 1.04755691e-06
Iter: 2286 loss: 1.04746846e-06
Iter: 2287 loss: 1.04765013e-06
Iter: 2288 loss: 1.04735e-06
Iter: 2289 loss: 1.04725018e-06
Iter: 2290 loss: 1.04788592e-06
Iter: 2291 loss: 1.04720584e-06
Iter: 2292 loss: 1.04708784e-06
Iter: 2293 loss: 1.04750006e-06
Iter: 2294 loss: 1.04706442e-06
Iter: 2295 loss: 1.04691117e-06
Iter: 2296 loss: 1.04660705e-06
Iter: 2297 loss: 1.04810738e-06
Iter: 2298 loss: 1.04649348e-06
Iter: 2299 loss: 1.04660853e-06
Iter: 2300 loss: 1.04628907e-06
Iter: 2301 loss: 1.04620233e-06
Iter: 2302 loss: 1.04599e-06
Iter: 2303 loss: 1.04602941e-06
Iter: 2304 loss: 1.04608557e-06
Iter: 2305 loss: 1.04597211e-06
Iter: 2306 loss: 1.04582443e-06
Iter: 2307 loss: 1.04601554e-06
Iter: 2308 loss: 1.04587798e-06
Iter: 2309 loss: 1.04575906e-06
Iter: 2310 loss: 1.0456647e-06
Iter: 2311 loss: 1.04833168e-06
Iter: 2312 loss: 1.04565049e-06
Iter: 2313 loss: 1.04554624e-06
Iter: 2314 loss: 1.04558967e-06
Iter: 2315 loss: 1.04542551e-06
Iter: 2316 loss: 1.0452876e-06
Iter: 2317 loss: 1.04552896e-06
Iter: 2318 loss: 1.04525543e-06
Iter: 2319 loss: 1.04510627e-06
Iter: 2320 loss: 1.04514015e-06
Iter: 2321 loss: 1.04494472e-06
Iter: 2322 loss: 1.04480182e-06
Iter: 2323 loss: 1.04732169e-06
Iter: 2324 loss: 1.044805e-06
Iter: 2325 loss: 1.04468131e-06
Iter: 2326 loss: 1.04452033e-06
Iter: 2327 loss: 1.04449305e-06
Iter: 2328 loss: 1.04429955e-06
Iter: 2329 loss: 1.04639048e-06
Iter: 2330 loss: 1.04427977e-06
Iter: 2331 loss: 1.04426135e-06
Iter: 2332 loss: 1.04449259e-06
Iter: 2333 loss: 1.04420246e-06
Iter: 2334 loss: 1.04410287e-06
Iter: 2335 loss: 1.04379444e-06
Iter: 2336 loss: 1.04856849e-06
Iter: 2337 loss: 1.04382968e-06
Iter: 2338 loss: 1.04354774e-06
Iter: 2339 loss: 1.04614674e-06
Iter: 2340 loss: 1.04354513e-06
Iter: 2341 loss: 1.04335766e-06
Iter: 2342 loss: 1.04392052e-06
Iter: 2343 loss: 1.04327569e-06
Iter: 2344 loss: 1.0431886e-06
Iter: 2345 loss: 1.04313949e-06
Iter: 2346 loss: 1.04309333e-06
Iter: 2347 loss: 1.04299897e-06
Iter: 2348 loss: 1.04465914e-06
Iter: 2349 loss: 1.04302512e-06
Iter: 2350 loss: 1.04290314e-06
Iter: 2351 loss: 1.04275932e-06
Iter: 2352 loss: 1.04272567e-06
Iter: 2353 loss: 1.04259345e-06
Iter: 2354 loss: 1.04449509e-06
Iter: 2355 loss: 1.04258424e-06
Iter: 2356 loss: 1.0425224e-06
Iter: 2357 loss: 1.04251046e-06
Iter: 2358 loss: 1.04239393e-06
Iter: 2359 loss: 1.0421569e-06
Iter: 2360 loss: 1.04230753e-06
Iter: 2361 loss: 1.04204912e-06
Iter: 2362 loss: 1.04192145e-06
Iter: 2363 loss: 1.04279502e-06
Iter: 2364 loss: 1.04188211e-06
Iter: 2365 loss: 1.04172682e-06
Iter: 2366 loss: 1.04156516e-06
Iter: 2367 loss: 1.0415697e-06
Iter: 2368 loss: 1.0413363e-06
Iter: 2369 loss: 1.04139349e-06
Iter: 2370 loss: 1.04126957e-06
Iter: 2371 loss: 1.04136643e-06
Iter: 2372 loss: 1.04120329e-06
Iter: 2373 loss: 1.04105686e-06
Iter: 2374 loss: 1.04095216e-06
Iter: 2375 loss: 1.04089258e-06
Iter: 2376 loss: 1.04074513e-06
Iter: 2377 loss: 1.04276864e-06
Iter: 2378 loss: 1.04070159e-06
Iter: 2379 loss: 1.04063031e-06
Iter: 2380 loss: 1.04061576e-06
Iter: 2381 loss: 1.04061041e-06
Iter: 2382 loss: 1.04042635e-06
Iter: 2383 loss: 1.04130572e-06
Iter: 2384 loss: 1.04040839e-06
Iter: 2385 loss: 1.04025855e-06
Iter: 2386 loss: 1.0416087e-06
Iter: 2387 loss: 1.04025685e-06
Iter: 2388 loss: 1.04016453e-06
Iter: 2389 loss: 1.04006335e-06
Iter: 2390 loss: 1.04004278e-06
Iter: 2391 loss: 1.03984519e-06
Iter: 2392 loss: 1.04098149e-06
Iter: 2393 loss: 1.03988418e-06
Iter: 2394 loss: 1.03971729e-06
Iter: 2395 loss: 1.03975447e-06
Iter: 2396 loss: 1.03961406e-06
Iter: 2397 loss: 1.03937612e-06
Iter: 2398 loss: 1.04015885e-06
Iter: 2399 loss: 1.03930734e-06
Iter: 2400 loss: 1.03918239e-06
Iter: 2401 loss: 1.03940374e-06
Iter: 2402 loss: 1.03913419e-06
Iter: 2403 loss: 1.03896741e-06
Iter: 2404 loss: 1.03930279e-06
Iter: 2405 loss: 1.03888624e-06
Iter: 2406 loss: 1.03878904e-06
Iter: 2407 loss: 1.04006756e-06
Iter: 2408 loss: 1.0387497e-06
Iter: 2409 loss: 1.03864659e-06
Iter: 2410 loss: 1.03855541e-06
Iter: 2411 loss: 1.03855746e-06
Iter: 2412 loss: 1.03830121e-06
Iter: 2413 loss: 1.03953812e-06
Iter: 2414 loss: 1.03824368e-06
Iter: 2415 loss: 1.03812897e-06
Iter: 2416 loss: 1.03807986e-06
Iter: 2417 loss: 1.03799277e-06
Iter: 2418 loss: 1.03798334e-06
Iter: 2419 loss: 1.03786783e-06
Iter: 2420 loss: 1.03787124e-06
Iter: 2421 loss: 1.03784123e-06
Iter: 2422 loss: 1.03783827e-06
Iter: 2423 loss: 1.03785851e-06
Iter: 2424 loss: 1.03783782e-06
Iter: 2425 loss: 1.03783873e-06
Iter: 2426 loss: 1.03782054e-06
Iter: 2427 loss: 1.03782986e-06
Iter: 2428 loss: 1.03784328e-06
Iter: 2429 loss: 1.03784362e-06
Iter: 2430 loss: 1.03784669e-06
Iter: 2431 loss: 1.03784521e-06
Iter: 2432 loss: 1.0378601e-06
Iter: 2433 loss: 1.03786351e-06
Iter: 2434 loss: 1.0378659e-06
Iter: 2435 loss: 1.03786488e-06
Iter: 2436 loss: 1.03787261e-06
Iter: 2437 loss: 1.03787136e-06
Iter: 2438 loss: 1.03786965e-06
Iter: 2439 loss: 1.0378684e-06
Iter: 2440 loss: 1.03786795e-06
Iter: 2441 loss: 1.03786829e-06
Iter: 2442 loss: 1.03786965e-06
Iter: 2443 loss: 1.03786829e-06
Iter: 2444 loss: 1.03786829e-06
Iter: 2445 loss: 1.03786965e-06
Iter: 2446 loss: 1.03764773e-06
Iter: 2447 loss: 1.03927437e-06
Iter: 2448 loss: 1.03764728e-06
Iter: 2449 loss: 1.03755042e-06
Iter: 2450 loss: 1.03752598e-06
Iter: 2451 loss: 1.03743162e-06
Iter: 2452 loss: 1.03727325e-06
Iter: 2453 loss: 1.0389507e-06
Iter: 2454 loss: 1.0372496e-06
Iter: 2455 loss: 1.0371939e-06
Iter: 2456 loss: 1.03715229e-06
Iter: 2457 loss: 1.03709112e-06
Iter: 2458 loss: 1.0369663e-06
Iter: 2459 loss: 1.03732214e-06
Iter: 2460 loss: 1.03691991e-06
Iter: 2461 loss: 1.03682191e-06
Iter: 2462 loss: 1.03703326e-06
Iter: 2463 loss: 1.03677917e-06
Iter: 2464 loss: 1.03667321e-06
Iter: 2465 loss: 1.03681884e-06
Iter: 2466 loss: 1.03659158e-06
Iter: 2467 loss: 1.03650814e-06
Iter: 2468 loss: 1.03790626e-06
Iter: 2469 loss: 1.036507e-06
Iter: 2470 loss: 1.03646278e-06
Iter: 2471 loss: 1.03627781e-06
Iter: 2472 loss: 1.03980028e-06
Iter: 2473 loss: 1.03628258e-06
Iter: 2474 loss: 1.03632283e-06
Iter: 2475 loss: 1.03624075e-06
Iter: 2476 loss: 1.03619016e-06
Iter: 2477 loss: 1.03612513e-06
Iter: 2478 loss: 1.03612797e-06
Iter: 2479 loss: 1.03603509e-06
Iter: 2480 loss: 1.0359297e-06
Iter: 2481 loss: 1.03709124e-06
Iter: 2482 loss: 1.03591435e-06
Iter: 2483 loss: 1.03579919e-06
Iter: 2484 loss: 1.03666207e-06
Iter: 2485 loss: 1.03580521e-06
Iter: 2486 loss: 1.03563661e-06
Iter: 2487 loss: 1.03563184e-06
Iter: 2488 loss: 1.03553509e-06
Iter: 2489 loss: 1.03539935e-06
Iter: 2490 loss: 1.03594971e-06
Iter: 2491 loss: 1.03532329e-06
Iter: 2492 loss: 1.03527475e-06
Iter: 2493 loss: 1.03523678e-06
Iter: 2494 loss: 1.03520983e-06
Iter: 2495 loss: 1.03506966e-06
Iter: 2496 loss: 1.03507114e-06
Iter: 2497 loss: 1.03492903e-06
Iter: 2498 loss: 1.03615685e-06
Iter: 2499 loss: 1.03486559e-06
Iter: 2500 loss: 1.03477919e-06
Iter: 2501 loss: 1.03491436e-06
Iter: 2502 loss: 1.03480829e-06
Iter: 2503 loss: 1.03464242e-06
Iter: 2504 loss: 1.0347876e-06
Iter: 2505 loss: 1.03464095e-06
Iter: 2506 loss: 1.03450952e-06
Iter: 2507 loss: 1.03528305e-06
Iter: 2508 loss: 1.03451953e-06
Iter: 2509 loss: 1.03445393e-06
Iter: 2510 loss: 1.03542436e-06
Iter: 2511 loss: 1.03446644e-06
Iter: 2512 loss: 1.03442358e-06
Iter: 2513 loss: 1.03432706e-06
Iter: 2514 loss: 1.03535626e-06
Iter: 2515 loss: 1.03430375e-06
Iter: 2516 loss: 1.03420211e-06
Iter: 2517 loss: 1.03418847e-06
Iter: 2518 loss: 1.03408343e-06
Iter: 2519 loss: 1.03395541e-06
Iter: 2520 loss: 1.03482671e-06
Iter: 2521 loss: 1.0339304e-06
Iter: 2522 loss: 1.03380899e-06
Iter: 2523 loss: 1.03458945e-06
Iter: 2524 loss: 1.03381046e-06
Iter: 2525 loss: 1.03376613e-06
Iter: 2526 loss: 1.03367006e-06
Iter: 2527 loss: 1.03364619e-06
Iter: 2528 loss: 1.03348066e-06
Iter: 2529 loss: 1.03509751e-06
Iter: 2530 loss: 1.03355035e-06
Iter: 2531 loss: 1.03345303e-06
Iter: 2532 loss: 1.03373168e-06
Iter: 2533 loss: 1.03346042e-06
Iter: 2534 loss: 1.03339357e-06
Iter: 2535 loss: 1.0333074e-06
Iter: 2536 loss: 1.03325817e-06
Iter: 2537 loss: 1.03316427e-06
Iter: 2538 loss: 1.03412754e-06
Iter: 2539 loss: 1.03318325e-06
Iter: 2540 loss: 1.03304228e-06
Iter: 2541 loss: 1.03291927e-06
Iter: 2542 loss: 1.03287414e-06
Iter: 2543 loss: 1.0329835e-06
Iter: 2544 loss: 1.03282298e-06
Iter: 2545 loss: 1.03282775e-06
Iter: 2546 loss: 1.03282105e-06
Iter: 2547 loss: 1.0328115e-06
Iter: 2548 loss: 1.0328406e-06
Iter: 2549 loss: 1.03280695e-06
Iter: 2550 loss: 1.03283867e-06
Iter: 2551 loss: 1.03282048e-06
Iter: 2552 loss: 1.03281104e-06
Iter: 2553 loss: 1.03283219e-06
Iter: 2554 loss: 1.03280354e-06
Iter: 2555 loss: 1.03283071e-06
Iter: 2556 loss: 1.03281604e-06
Iter: 2557 loss: 1.03283492e-06
Iter: 2558 loss: 1.03282241e-06
Iter: 2559 loss: 1.03282775e-06
Iter: 2560 loss: 1.0328306e-06
Iter: 2561 loss: 1.03281991e-06
Iter: 2562 loss: 1.03282071e-06
Iter: 2563 loss: 1.03282605e-06
Iter: 2564 loss: 1.03282332e-06
Iter: 2565 loss: 1.03282446e-06
Iter: 2566 loss: 1.03282412e-06
Iter: 2567 loss: 1.03282423e-06
Iter: 2568 loss: 1.03282423e-06
Iter: 2569 loss: 1.03282332e-06
Iter: 2570 loss: 1.03282423e-06
Iter: 2571 loss: 1.0326512e-06
Iter: 2572 loss: 1.03437628e-06
Iter: 2573 loss: 1.03262141e-06
Iter: 2574 loss: 1.03253819e-06
Iter: 2575 loss: 1.03244224e-06
Iter: 2576 loss: 1.03522484e-06
Iter: 2577 loss: 1.03239927e-06
Iter: 2578 loss: 1.03232719e-06
Iter: 2579 loss: 1.03230673e-06
Iter: 2580 loss: 1.03225875e-06
Iter: 2581 loss: 1.03211403e-06
Iter: 2582 loss: 1.0320698e-06
Iter: 2583 loss: 1.03200364e-06
Iter: 2584 loss: 1.03198022e-06
Iter: 2585 loss: 1.03189529e-06
Iter: 2586 loss: 1.03204115e-06
Iter: 2587 loss: 1.03185766e-06
Iter: 2588 loss: 1.03173363e-06
Iter: 2589 loss: 1.03159869e-06
Iter: 2590 loss: 1.03156901e-06
Iter: 2591 loss: 1.03149091e-06
Iter: 2592 loss: 1.0327517e-06
Iter: 2593 loss: 1.03147204e-06
Iter: 2594 loss: 1.03135767e-06
Iter: 2595 loss: 1.03131515e-06
Iter: 2596 loss: 1.03132447e-06
Iter: 2597 loss: 1.0311785e-06
Iter: 2598 loss: 1.03157777e-06
Iter: 2599 loss: 1.03108346e-06
Iter: 2600 loss: 1.03101934e-06
Iter: 2601 loss: 1.0318912e-06
Iter: 2602 loss: 1.03103275e-06
Iter: 2603 loss: 1.03099296e-06
Iter: 2604 loss: 1.03097523e-06
Iter: 2605 loss: 1.03093043e-06
Iter: 2606 loss: 1.03086654e-06
Iter: 2607 loss: 1.03116588e-06
Iter: 2608 loss: 1.03081368e-06
Iter: 2609 loss: 1.03071443e-06
Iter: 2610 loss: 1.03112848e-06
Iter: 2611 loss: 1.03063894e-06
Iter: 2612 loss: 1.03058244e-06
Iter: 2613 loss: 1.03133812e-06
Iter: 2614 loss: 1.03055777e-06
Iter: 2615 loss: 1.03051298e-06
Iter: 2616 loss: 1.03042271e-06
Iter: 2617 loss: 1.030455e-06
Iter: 2618 loss: 1.03032835e-06
Iter: 2619 loss: 1.03032085e-06
Iter: 2620 loss: 1.03028344e-06
Iter: 2621 loss: 1.03028924e-06
Iter: 2622 loss: 1.03024036e-06
Iter: 2623 loss: 1.03012144e-06
Iter: 2624 loss: 1.03006357e-06
Iter: 2625 loss: 1.03007324e-06
Iter: 2626 loss: 1.02992749e-06
Iter: 2627 loss: 1.02994386e-06
Iter: 2628 loss: 1.02987383e-06
Iter: 2629 loss: 1.0297889e-06
Iter: 2630 loss: 1.02980664e-06
Iter: 2631 loss: 1.0296676e-06
Iter: 2632 loss: 1.03015e-06
Iter: 2633 loss: 1.02968079e-06
Iter: 2634 loss: 1.02969648e-06
Iter: 2635 loss: 1.02966101e-06
Iter: 2636 loss: 1.02963679e-06
Iter: 2637 loss: 1.02951185e-06
Iter: 2638 loss: 1.03001651e-06
Iter: 2639 loss: 1.02947058e-06
Iter: 2640 loss: 1.02935894e-06
Iter: 2641 loss: 1.02947502e-06
Iter: 2642 loss: 1.02935951e-06
Iter: 2643 loss: 1.02923616e-06
Iter: 2644 loss: 1.02943113e-06
Iter: 2645 loss: 1.02920535e-06
Iter: 2646 loss: 1.02905312e-06
Iter: 2647 loss: 1.03004913e-06
Iter: 2648 loss: 1.02906984e-06
Iter: 2649 loss: 1.02895308e-06
Iter: 2650 loss: 1.02892454e-06
Iter: 2651 loss: 1.02886929e-06
Iter: 2652 loss: 1.02876618e-06
Iter: 2653 loss: 1.02877573e-06
Iter: 2654 loss: 1.0286908e-06
Iter: 2655 loss: 1.0287954e-06
Iter: 2656 loss: 1.0286235e-06
Iter: 2657 loss: 1.02854733e-06
Iter: 2658 loss: 1.02834747e-06
Iter: 2659 loss: 1.03222578e-06
Iter: 2660 loss: 1.02839977e-06
Iter: 2661 loss: 1.02832132e-06
Iter: 2662 loss: 1.02824083e-06
Iter: 2663 loss: 1.02820763e-06
Iter: 2664 loss: 1.02804972e-06
Iter: 2665 loss: 1.02803892e-06
Iter: 2666 loss: 1.02792694e-06
Iter: 2667 loss: 1.02792603e-06
Iter: 2668 loss: 1.02785032e-06
Iter: 2669 loss: 1.02856825e-06
Iter: 2670 loss: 1.02780598e-06
Iter: 2671 loss: 1.02781371e-06
Iter: 2672 loss: 1.02779586e-06
Iter: 2673 loss: 1.02778267e-06
Iter: 2674 loss: 1.02783213e-06
Iter: 2675 loss: 1.02780371e-06
Iter: 2676 loss: 1.02781223e-06
Iter: 2677 loss: 1.02778449e-06
Iter: 2678 loss: 1.02779632e-06
Iter: 2679 loss: 1.02782519e-06
Iter: 2680 loss: 1.02781519e-06
Iter: 2681 loss: 1.02780245e-06
Iter: 2682 loss: 1.02781689e-06
Iter: 2683 loss: 1.02781223e-06
Iter: 2684 loss: 1.02780496e-06
Iter: 2685 loss: 1.02780677e-06
Iter: 2686 loss: 1.0277995e-06
Iter: 2687 loss: 1.02780632e-06
Iter: 2688 loss: 1.0278078e-06
Iter: 2689 loss: 1.02780768e-06
Iter: 2690 loss: 1.02780859e-06
Iter: 2691 loss: 1.02780825e-06
Iter: 2692 loss: 1.02780632e-06
Iter: 2693 loss: 1.02780848e-06
Iter: 2694 loss: 1.02780632e-06
Iter: 2695 loss: 1.02780632e-06
Iter: 2696 loss: 1.02780848e-06
Iter: 2697 loss: 1.02748368e-06
Iter: 2698 loss: 1.03060438e-06
Iter: 2699 loss: 1.02745764e-06
Iter: 2700 loss: 1.02731758e-06
Iter: 2701 loss: 1.02731087e-06
Iter: 2702 loss: 1.02719082e-06
Iter: 2703 loss: 1.02744934e-06
Iter: 2704 loss: 1.02712454e-06
Iter: 2705 loss: 1.02700938e-06
Iter: 2706 loss: 1.02757e-06
Iter: 2707 loss: 1.02705019e-06
Iter: 2708 loss: 1.02690956e-06
Iter: 2709 loss: 1.02715296e-06
Iter: 2710 loss: 1.02687147e-06
Iter: 2711 loss: 1.02677632e-06
Iter: 2712 loss: 1.02683362e-06
Iter: 2713 loss: 1.02670845e-06
Iter: 2714 loss: 1.02657509e-06
Iter: 2715 loss: 1.02663262e-06
Iter: 2716 loss: 1.02650256e-06
Iter: 2717 loss: 1.02642139e-06
Iter: 2718 loss: 1.02671027e-06
Iter: 2719 loss: 1.02633521e-06
Iter: 2720 loss: 1.02624188e-06
Iter: 2721 loss: 1.02649255e-06
Iter: 2722 loss: 1.02618446e-06
Iter: 2723 loss: 1.02610386e-06
Iter: 2724 loss: 1.02608101e-06
Iter: 2725 loss: 1.02601257e-06
Iter: 2726 loss: 1.02598449e-06
Iter: 2727 loss: 1.02597573e-06
Iter: 2728 loss: 1.02591503e-06
Iter: 2729 loss: 1.02574108e-06
Iter: 2730 loss: 1.02816205e-06
Iter: 2731 loss: 1.02576473e-06
Iter: 2732 loss: 1.02554418e-06
Iter: 2733 loss: 1.02629519e-06
Iter: 2734 loss: 1.02555703e-06
Iter: 2735 loss: 1.02545562e-06
Iter: 2736 loss: 1.02587876e-06
Iter: 2737 loss: 1.02542833e-06
Iter: 2738 loss: 1.02531021e-06
Iter: 2739 loss: 1.02577587e-06
Iter: 2740 loss: 1.02531089e-06
Iter: 2741 loss: 1.02512581e-06
Iter: 2742 loss: 1.02526053e-06
Iter: 2743 loss: 1.02509239e-06
Iter: 2744 loss: 1.02495278e-06
Iter: 2745 loss: 1.02652007e-06
Iter: 2746 loss: 1.02492618e-06
Iter: 2747 loss: 1.02486547e-06
Iter: 2748 loss: 1.02493243e-06
Iter: 2749 loss: 1.02476145e-06
Iter: 2750 loss: 1.02466663e-06
Iter: 2751 loss: 1.02467857e-06
Iter: 2752 loss: 1.02463957e-06
Iter: 2753 loss: 1.02447621e-06
Iter: 2754 loss: 1.02528634e-06
Iter: 2755 loss: 1.0244645e-06
Iter: 2756 loss: 1.02437025e-06
Iter: 2757 loss: 1.02504782e-06
Iter: 2758 loss: 1.0243898e-06
Iter: 2759 loss: 1.02428783e-06
Iter: 2760 loss: 1.02548233e-06
Iter: 2761 loss: 1.02427e-06
Iter: 2762 loss: 1.02423314e-06
Iter: 2763 loss: 1.02415015e-06
Iter: 2764 loss: 1.02587921e-06
Iter: 2765 loss: 1.02415765e-06
Iter: 2766 loss: 1.02407898e-06
Iter: 2767 loss: 1.02402032e-06
Iter: 2768 loss: 1.02400509e-06
Iter: 2769 loss: 1.0238648e-06
Iter: 2770 loss: 1.02428692e-06
Iter: 2771 loss: 1.02384047e-06
Iter: 2772 loss: 1.02367881e-06
Iter: 2773 loss: 1.02386889e-06
Iter: 2774 loss: 1.02363538e-06
Iter: 2775 loss: 1.02345643e-06
Iter: 2776 loss: 1.02517674e-06
Iter: 2777 loss: 1.02349952e-06
Iter: 2778 loss: 1.0233814e-06
Iter: 2779 loss: 1.02358831e-06
Iter: 2780 loss: 1.02337094e-06
Iter: 2781 loss: 1.02329318e-06
Iter: 2782 loss: 1.02390095e-06
Iter: 2783 loss: 1.02330216e-06
Iter: 2784 loss: 1.02323952e-06
Iter: 2785 loss: 1.02327522e-06
Iter: 2786 loss: 1.02318472e-06
Iter: 2787 loss: 1.02312742e-06
Iter: 2788 loss: 1.02306672e-06
Iter: 2789 loss: 1.02300294e-06
Iter: 2790 loss: 1.02291301e-06
Iter: 2791 loss: 1.02324111e-06
Iter: 2792 loss: 1.02287595e-06
Iter: 2793 loss: 1.02282843e-06
Iter: 2794 loss: 1.02278409e-06
Iter: 2795 loss: 1.02272497e-06
Iter: 2796 loss: 1.02262788e-06
Iter: 2797 loss: 1.02263971e-06
Iter: 2798 loss: 1.02260606e-06
Iter: 2799 loss: 1.02254148e-06
Iter: 2800 loss: 1.02254535e-06
Iter: 2801 loss: 1.02237755e-06
Iter: 2802 loss: 1.02267541e-06
Iter: 2803 loss: 1.02236277e-06
Iter: 2804 loss: 1.02224521e-06
Iter: 2805 loss: 1.02241074e-06
Iter: 2806 loss: 1.02214699e-06
Iter: 2807 loss: 1.02200693e-06
Iter: 2808 loss: 1.02266245e-06
Iter: 2809 loss: 1.02196191e-06
Iter: 2810 loss: 1.0218539e-06
Iter: 2811 loss: 1.02254648e-06
Iter: 2812 loss: 1.02188142e-06
Iter: 2813 loss: 1.02171498e-06
Iter: 2814 loss: 1.02182275e-06
Iter: 2815 loss: 1.02161175e-06
Iter: 2816 loss: 1.02152057e-06
Iter: 2817 loss: 1.02295485e-06
Iter: 2818 loss: 1.02147089e-06
Iter: 2819 loss: 1.02141917e-06
Iter: 2820 loss: 1.02139029e-06
Iter: 2821 loss: 1.02141166e-06
Iter: 2822 loss: 1.02128786e-06
Iter: 2823 loss: 1.02154115e-06
Iter: 2824 loss: 1.02122328e-06
Iter: 2825 loss: 1.02114416e-06
Iter: 2826 loss: 1.02121044e-06
Iter: 2827 loss: 1.02110153e-06
Iter: 2828 loss: 1.02113233e-06
Iter: 2829 loss: 1.02110846e-06
Iter: 2830 loss: 1.02102604e-06
Iter: 2831 loss: 1.02102319e-06
Iter: 2832 loss: 1.02095021e-06
Iter: 2833 loss: 1.0208953e-06
Iter: 2834 loss: 1.02085505e-06
Iter: 2835 loss: 1.02082481e-06
Iter: 2836 loss: 1.0207101e-06
Iter: 2837 loss: 1.02108197e-06
Iter: 2838 loss: 1.02062791e-06
Iter: 2839 loss: 1.02052581e-06
Iter: 2840 loss: 1.02102149e-06
Iter: 2841 loss: 1.02053843e-06
Iter: 2842 loss: 1.02043805e-06
Iter: 2843 loss: 1.02069441e-06
Iter: 2844 loss: 1.02043202e-06
Iter: 2845 loss: 1.02030845e-06
Iter: 2846 loss: 1.02079207e-06
Iter: 2847 loss: 1.02024558e-06
Iter: 2848 loss: 1.0201702e-06
Iter: 2849 loss: 1.02040008e-06
Iter: 2850 loss: 1.02013757e-06
Iter: 2851 loss: 1.0200514e-06
Iter: 2852 loss: 1.0201984e-06
Iter: 2853 loss: 1.0200074e-06
Iter: 2854 loss: 1.01992373e-06
Iter: 2855 loss: 1.02012632e-06
Iter: 2856 loss: 1.01983596e-06
Iter: 2857 loss: 1.01980231e-06
Iter: 2858 loss: 1.02039462e-06
Iter: 2859 loss: 1.01978173e-06
Iter: 2860 loss: 1.01976e-06
Iter: 2861 loss: 1.02023967e-06
Iter: 2862 loss: 1.0197723e-06
Iter: 2863 loss: 1.01974979e-06
Iter: 2864 loss: 1.01960802e-06
Iter: 2865 loss: 1.01963133e-06
Iter: 2866 loss: 1.01956607e-06
Iter: 2867 loss: 1.019563e-06
Iter: 2868 loss: 1.01953765e-06
Iter: 2869 loss: 1.0194284e-06
Iter: 2870 loss: 1.01977571e-06
Iter: 2871 loss: 1.01938122e-06
Iter: 2872 loss: 1.01932733e-06
Iter: 2873 loss: 1.01941771e-06
Iter: 2874 loss: 1.01929777e-06
Iter: 2875 loss: 1.01916498e-06
Iter: 2876 loss: 1.01974138e-06
Iter: 2877 loss: 1.01917e-06
Iter: 2878 loss: 1.01906835e-06
Iter: 2879 loss: 1.01953185e-06
Iter: 2880 loss: 1.01909347e-06
Iter: 2881 loss: 1.01907767e-06
Iter: 2882 loss: 1.0191452e-06
Iter: 2883 loss: 1.01903402e-06
Iter: 2884 loss: 1.01895421e-06
Iter: 2885 loss: 1.01902742e-06
Iter: 2886 loss: 1.01891601e-06
Iter: 2887 loss: 1.0188337e-06
Iter: 2888 loss: 1.01892283e-06
Iter: 2889 loss: 1.01879812e-06
Iter: 2890 loss: 1.01868852e-06
Iter: 2891 loss: 1.01891078e-06
Iter: 2892 loss: 1.0186767e-06
Iter: 2893 loss: 1.01866181e-06
Iter: 2894 loss: 1.01862292e-06
Iter: 2895 loss: 1.01862406e-06
Iter: 2896 loss: 1.01861974e-06
Iter: 2897 loss: 1.01862315e-06
Iter: 2898 loss: 1.01860246e-06
Iter: 2899 loss: 1.01862224e-06
Iter: 2900 loss: 1.01863168e-06
Iter: 2901 loss: 1.01860405e-06
Iter: 2902 loss: 1.01863361e-06
Iter: 2903 loss: 1.0186177e-06
Iter: 2904 loss: 1.01862543e-06
Iter: 2905 loss: 1.0186177e-06
Iter: 2906 loss: 1.01861383e-06
Iter: 2907 loss: 1.01862599e-06
Iter: 2908 loss: 1.01861337e-06
Iter: 2909 loss: 1.01862179e-06
Iter: 2910 loss: 1.01862793e-06
Iter: 2911 loss: 1.01862497e-06
Iter: 2912 loss: 1.01862418e-06
Iter: 2913 loss: 1.01862315e-06
Iter: 2914 loss: 1.01862406e-06
Iter: 2915 loss: 1.01862429e-06
Iter: 2916 loss: 1.01862429e-06
Iter: 2917 loss: 1.01862315e-06
Iter: 2918 loss: 1.01862429e-06
Iter: 2919 loss: 1.01862429e-06
Iter: 2920 loss: 1.01862315e-06
Iter: 2921 loss: 1.01844307e-06
Iter: 2922 loss: 1.01979458e-06
Iter: 2923 loss: 1.01845308e-06
Iter: 2924 loss: 1.01836622e-06
Iter: 2925 loss: 1.01846297e-06
Iter: 2926 loss: 1.01834041e-06
Iter: 2927 loss: 1.01818046e-06
Iter: 2928 loss: 1.01878879e-06
Iter: 2929 loss: 1.01822036e-06
Iter: 2930 loss: 1.0181484e-06
Iter: 2931 loss: 1.0181509e-06
Iter: 2932 loss: 1.01808268e-06
Iter: 2933 loss: 1.0180155e-06
Iter: 2934 loss: 1.01870262e-06
Iter: 2935 loss: 1.01802107e-06
Iter: 2936 loss: 1.01796695e-06
Iter: 2937 loss: 1.01796354e-06
Iter: 2938 loss: 1.01790874e-06
Iter: 2939 loss: 1.01779551e-06
Iter: 2940 loss: 1.01834053e-06
Iter: 2941 loss: 1.01774344e-06
Iter: 2942 loss: 1.01775572e-06
Iter: 2943 loss: 1.01774322e-06
Iter: 2944 loss: 1.0177182e-06
Iter: 2945 loss: 1.01772685e-06
Iter: 2946 loss: 1.01770672e-06
Iter: 2947 loss: 1.01774265e-06
Iter: 2948 loss: 1.01775595e-06
Iter: 2949 loss: 1.01775186e-06
Iter: 2950 loss: 1.0177157e-06
Iter: 2951 loss: 1.01772969e-06
Iter: 2952 loss: 1.01774503e-06
Iter: 2953 loss: 1.01774731e-06
Iter: 2954 loss: 1.01773503e-06
Iter: 2955 loss: 1.01773901e-06
Iter: 2956 loss: 1.01773799e-06
Iter: 2957 loss: 1.01773742e-06
Iter: 2958 loss: 1.01773685e-06
Iter: 2959 loss: 1.01774117e-06
Iter: 2960 loss: 1.01773855e-06
Iter: 2961 loss: 1.01774208e-06
Iter: 2962 loss: 1.01774344e-06
Iter: 2963 loss: 1.01774469e-06
Iter: 2964 loss: 1.01774458e-06
Iter: 2965 loss: 1.01774413e-06
Iter: 2966 loss: 1.01774413e-06
Iter: 2967 loss: 1.01774458e-06
Iter: 2968 loss: 1.01761987e-06
Iter: 2969 loss: 1.01829687e-06
Iter: 2970 loss: 1.0176301e-06
Iter: 2971 loss: 1.01768433e-06
Iter: 2972 loss: 1.01759633e-06
Iter: 2973 loss: 1.01758428e-06
Iter: 2974 loss: 1.01746593e-06
Iter: 2975 loss: 1.01749015e-06
Iter: 2976 loss: 1.01741443e-06
Iter: 2977 loss: 1.01745854e-06
Iter: 2978 loss: 1.01733963e-06
Iter: 2979 loss: 1.01726e-06
Iter: 2980 loss: 1.01743183e-06
Iter: 2981 loss: 1.01722981e-06
Iter: 2982 loss: 1.01712499e-06
Iter: 2983 loss: 1.01727346e-06
Iter: 2984 loss: 1.01707019e-06
Iter: 2985 loss: 1.01697685e-06
Iter: 2986 loss: 1.0177489e-06
Iter: 2987 loss: 1.0169606e-06
Iter: 2988 loss: 1.01684907e-06
Iter: 2989 loss: 1.01714545e-06
Iter: 2990 loss: 1.01687863e-06
Iter: 2991 loss: 1.01678643e-06
Iter: 2992 loss: 1.01685328e-06
Iter: 2993 loss: 1.01676187e-06
Iter: 2994 loss: 1.01659964e-06
Iter: 2995 loss: 1.0173236e-06
Iter: 2996 loss: 1.01657474e-06
Iter: 2997 loss: 1.0165412e-06
Iter: 2998 loss: 1.01669752e-06
Iter: 2999 loss: 1.01656769e-06
Iter: 3000 loss: 1.01642922e-06
Iter: 3001 loss: 1.01645446e-06
Iter: 3002 loss: 1.0163335e-06
Iter: 3003 loss: 1.01628484e-06
Iter: 3004 loss: 1.01686237e-06
Iter: 3005 loss: 1.01624232e-06
Iter: 3006 loss: 1.01622697e-06
Iter: 3007 loss: 1.0162446e-06
Iter: 3008 loss: 1.01622686e-06
Iter: 3009 loss: 1.01619662e-06
Iter: 3010 loss: 1.01611454e-06
Iter: 3011 loss: 1.01721753e-06
Iter: 3012 loss: 1.01612568e-06
Iter: 3013 loss: 1.01598403e-06
Iter: 3014 loss: 1.01603291e-06
Iter: 3015 loss: 1.01591797e-06
Iter: 3016 loss: 1.01586659e-06
Iter: 3017 loss: 1.0161491e-06
Iter: 3018 loss: 1.01578962e-06
Iter: 3019 loss: 1.01578121e-06
Iter: 3020 loss: 1.01592491e-06
Iter: 3021 loss: 1.01576734e-06
Iter: 3022 loss: 1.01560727e-06
Iter: 3023 loss: 1.0161e-06
Iter: 3024 loss: 1.01560886e-06
Iter: 3025 loss: 1.01546243e-06
Iter: 3026 loss: 1.01574506e-06
Iter: 3027 loss: 1.01552405e-06
Iter: 3028 loss: 1.01545447e-06
Iter: 3029 loss: 1.01604701e-06
Iter: 3030 loss: 1.01543503e-06
Iter: 3031 loss: 1.01542162e-06
Iter: 3032 loss: 1.01536557e-06
Iter: 3033 loss: 1.01530952e-06
Iter: 3034 loss: 1.01521346e-06
Iter: 3035 loss: 1.0152753e-06
Iter: 3036 loss: 1.01512728e-06
Iter: 3037 loss: 1.01507317e-06
Iter: 3038 loss: 1.01523983e-06
Iter: 3039 loss: 1.01501826e-06
Iter: 3040 loss: 1.01495516e-06
Iter: 3041 loss: 1.01603803e-06
Iter: 3042 loss: 1.01490832e-06
Iter: 3043 loss: 1.01487319e-06
Iter: 3044 loss: 1.01543765e-06
Iter: 3045 loss: 1.01488558e-06
Iter: 3046 loss: 1.01486557e-06
Iter: 3047 loss: 1.01476e-06
Iter: 3048 loss: 1.01643013e-06
Iter: 3049 loss: 1.01470778e-06
Iter: 3050 loss: 1.01464911e-06
Iter: 3051 loss: 1.01452838e-06
Iter: 3052 loss: 1.01455453e-06
Iter: 3053 loss: 1.01448359e-06
Iter: 3054 loss: 1.01549142e-06
Iter: 3055 loss: 1.01449632e-06
Iter: 3056 loss: 1.01437695e-06
Iter: 3057 loss: 1.01446744e-06
Iter: 3058 loss: 1.01436797e-06
Iter: 3059 loss: 1.01425667e-06
Iter: 3060 loss: 1.01502178e-06
Iter: 3061 loss: 1.01426974e-06
Iter: 3062 loss: 1.01415901e-06
Iter: 3063 loss: 1.01420505e-06
Iter: 3064 loss: 1.01410444e-06
Iter: 3065 loss: 1.0140493e-06
Iter: 3066 loss: 1.01469686e-06
Iter: 3067 loss: 1.01408727e-06
Iter: 3068 loss: 1.01401019e-06
Iter: 3069 loss: 1.01416174e-06
Iter: 3070 loss: 1.01398541e-06
Iter: 3071 loss: 1.01391709e-06
Iter: 3072 loss: 1.01384558e-06
Iter: 3073 loss: 1.01384262e-06
Iter: 3074 loss: 1.01377725e-06
Iter: 3075 loss: 1.01378942e-06
Iter: 3076 loss: 1.01370074e-06
Iter: 3077 loss: 1.01375076e-06
Iter: 3078 loss: 1.0137145e-06
Iter: 3079 loss: 1.01364401e-06
Iter: 3080 loss: 1.01462103e-06
Iter: 3081 loss: 1.01362821e-06
Iter: 3082 loss: 1.01356852e-06
Iter: 3083 loss: 1.01345131e-06
Iter: 3084 loss: 1.01342926e-06
Iter: 3085 loss: 1.01331023e-06
Iter: 3086 loss: 1.01367209e-06
Iter: 3087 loss: 1.01325054e-06
Iter: 3088 loss: 1.01314708e-06
Iter: 3089 loss: 1.01347473e-06
Iter: 3090 loss: 1.01312207e-06
Iter: 3091 loss: 1.013011e-06
Iter: 3092 loss: 1.01369221e-06
Iter: 3093 loss: 1.01299747e-06
Iter: 3094 loss: 1.01291016e-06
Iter: 3095 loss: 1.01309377e-06
Iter: 3096 loss: 1.01283831e-06
Iter: 3097 loss: 1.01272371e-06
Iter: 3098 loss: 1.01326725e-06
Iter: 3099 loss: 1.01274657e-06
Iter: 3100 loss: 1.01268199e-06
Iter: 3101 loss: 1.01287321e-06
Iter: 3102 loss: 1.01263208e-06
Iter: 3103 loss: 1.01260162e-06
Iter: 3104 loss: 1.01263981e-06
Iter: 3105 loss: 1.01252681e-06
Iter: 3106 loss: 1.01251351e-06
Iter: 3107 loss: 1.01267915e-06
Iter: 3108 loss: 1.01249e-06
Iter: 3109 loss: 1.01237185e-06
Iter: 3110 loss: 1.01236719e-06
Iter: 3111 loss: 1.01231421e-06
Iter: 3112 loss: 1.01223418e-06
Iter: 3113 loss: 1.01220837e-06
Iter: 3114 loss: 1.01213197e-06
Iter: 3115 loss: 1.01219757e-06
Iter: 3116 loss: 1.01206297e-06
Iter: 3117 loss: 1.01199385e-06
Iter: 3118 loss: 1.01181922e-06
Iter: 3119 loss: 1.01181593e-06
Iter: 3120 loss: 1.01169144e-06
Iter: 3121 loss: 1.01364299e-06
Iter: 3122 loss: 1.01160458e-06
Iter: 3123 loss: 1.0115923e-06
Iter: 3124 loss: 1.01161277e-06
Iter: 3125 loss: 1.01142132e-06
Iter: 3126 loss: 1.01136629e-06
Iter: 3127 loss: 1.01328601e-06
Iter: 3128 loss: 1.01140233e-06
Iter: 3129 loss: 1.01131059e-06
Iter: 3130 loss: 1.01139437e-06
Iter: 3131 loss: 1.01125352e-06
Iter: 3132 loss: 1.01118326e-06
Iter: 3133 loss: 1.01127125e-06
Iter: 3134 loss: 1.0111512e-06
Iter: 3135 loss: 1.01104149e-06
Iter: 3136 loss: 1.01134106e-06
Iter: 3137 loss: 1.01103819e-06
Iter: 3138 loss: 1.0109045e-06
Iter: 3139 loss: 1.01096566e-06
Iter: 3140 loss: 1.0108738e-06
Iter: 3141 loss: 1.01078967e-06
Iter: 3142 loss: 1.01156525e-06
Iter: 3143 loss: 1.0108e-06
Iter: 3144 loss: 1.01071362e-06
Iter: 3145 loss: 1.01154114e-06
Iter: 3146 loss: 1.0107276e-06
Iter: 3147 loss: 1.01072112e-06
Iter: 3148 loss: 1.01065518e-06
Iter: 3149 loss: 1.01141893e-06
Iter: 3150 loss: 1.01061357e-06
Iter: 3151 loss: 1.01048329e-06
Iter: 3152 loss: 1.01059175e-06
Iter: 3153 loss: 1.01044702e-06
Iter: 3154 loss: 1.01031264e-06
Iter: 3155 loss: 1.01099613e-06
Iter: 3156 loss: 1.01025978e-06
Iter: 3157 loss: 1.01017361e-06
Iter: 3158 loss: 1.01014825e-06
Iter: 3159 loss: 1.01012301e-06
Iter: 3160 loss: 1.01003491e-06
Iter: 3161 loss: 1.01000205e-06
Iter: 3162 loss: 1.00992099e-06
Iter: 3163 loss: 1.01001774e-06
Iter: 3164 loss: 1.00987404e-06
Iter: 3165 loss: 1.00977581e-06
Iter: 3166 loss: 1.01078444e-06
Iter: 3167 loss: 1.00979605e-06
Iter: 3168 loss: 1.00972341e-06
Iter: 3169 loss: 1.00969692e-06
Iter: 3170 loss: 1.00967361e-06
Iter: 3171 loss: 1.00960926e-06
Iter: 3172 loss: 1.00960426e-06
Iter: 3173 loss: 1.00947e-06
Iter: 3174 loss: 1.00938951e-06
Iter: 3175 loss: 1.01008516e-06
Iter: 3176 loss: 1.00939576e-06
Iter: 3177 loss: 1.00929742e-06
Iter: 3178 loss: 1.00930788e-06
Iter: 3179 loss: 1.00931061e-06
Iter: 3180 loss: 1.0093014e-06
Iter: 3181 loss: 1.0093022e-06
Iter: 3182 loss: 1.00929719e-06
Iter: 3183 loss: 1.00929719e-06
Iter: 3184 loss: 1.00930106e-06
Iter: 3185 loss: 1.00932721e-06
Iter: 3186 loss: 1.00928696e-06
Iter: 3187 loss: 1.00929424e-06
Iter: 3188 loss: 1.00928696e-06
Iter: 3189 loss: 1.00932061e-06
Iter: 3190 loss: 1.00935017e-06
Iter: 3191 loss: 1.00930356e-06
Iter: 3192 loss: 1.00934255e-06
Iter: 3193 loss: 1.00932425e-06
Iter: 3194 loss: 1.00931072e-06
Iter: 3195 loss: 1.00931697e-06
Iter: 3196 loss: 1.00931857e-06
Iter: 3197 loss: 1.00931231e-06
Iter: 3198 loss: 1.00931015e-06
Iter: 3199 loss: 1.00930765e-06
Iter: 3200 loss: 1.00931e-06
Iter: 3201 loss: 1.0093097e-06
Iter: 3202 loss: 1.00931015e-06
Iter: 3203 loss: 1.00930788e-06
Iter: 3204 loss: 1.00931015e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/300_300_300_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3
+ date
Mon Nov  9 02:04:07 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_1000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 3 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_1000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808454730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80847f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80849d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80849dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80849d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808418620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808418400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8083f8400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8083adae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808345400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80835f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80831f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80836dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80831f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8082886a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8082b2048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808245a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808202f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808214a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808202378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8081db6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80818c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80819c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808158e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80816c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80816c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8080c1c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8080cc048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8080f76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8080a2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8080a86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8080f7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80806f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc808015a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc80167a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8016a6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.86657075e-06
Iter: 2 loss: 4.23749771e-06
Iter: 3 loss: 3.01779255e-06
Iter: 4 loss: 2.53310327e-06
Iter: 5 loss: 3.36956282e-06
Iter: 6 loss: 2.31823196e-06
Iter: 7 loss: 2.08169513e-06
Iter: 8 loss: 2.21698565e-06
Iter: 9 loss: 1.92782431e-06
Iter: 10 loss: 1.67044732e-06
Iter: 11 loss: 2.51731672e-06
Iter: 12 loss: 1.59913259e-06
Iter: 13 loss: 1.49815151e-06
Iter: 14 loss: 2.48775768e-06
Iter: 15 loss: 1.49440223e-06
Iter: 16 loss: 1.43985108e-06
Iter: 17 loss: 1.38483438e-06
Iter: 18 loss: 1.37378629e-06
Iter: 19 loss: 1.2841308e-06
Iter: 20 loss: 2.19585854e-06
Iter: 21 loss: 1.28150748e-06
Iter: 22 loss: 1.23513928e-06
Iter: 23 loss: 1.34379172e-06
Iter: 24 loss: 1.21807113e-06
Iter: 25 loss: 1.17019897e-06
Iter: 26 loss: 1.27293424e-06
Iter: 27 loss: 1.15128444e-06
Iter: 28 loss: 1.12888927e-06
Iter: 29 loss: 1.27030478e-06
Iter: 30 loss: 1.12626617e-06
Iter: 31 loss: 1.10452254e-06
Iter: 32 loss: 1.0855382e-06
Iter: 33 loss: 1.07974142e-06
Iter: 34 loss: 1.05708295e-06
Iter: 35 loss: 1.33101094e-06
Iter: 36 loss: 1.05669892e-06
Iter: 37 loss: 1.03786419e-06
Iter: 38 loss: 1.0509151e-06
Iter: 39 loss: 1.02611853e-06
Iter: 40 loss: 1.03418415e-06
Iter: 41 loss: 1.01612557e-06
Iter: 42 loss: 1.01170826e-06
Iter: 43 loss: 1.00097122e-06
Iter: 44 loss: 1.11319423e-06
Iter: 45 loss: 9.99698614e-07
Iter: 46 loss: 9.88412467e-07
Iter: 47 loss: 9.99687927e-07
Iter: 48 loss: 9.82041684e-07
Iter: 49 loss: 9.6692122e-07
Iter: 50 loss: 1.08699032e-06
Iter: 51 loss: 9.6588883e-07
Iter: 52 loss: 9.5893563e-07
Iter: 53 loss: 9.46328555e-07
Iter: 54 loss: 1.252012e-06
Iter: 55 loss: 9.46277964e-07
Iter: 56 loss: 9.35335208e-07
Iter: 57 loss: 9.35060257e-07
Iter: 58 loss: 9.29000862e-07
Iter: 59 loss: 9.39001893e-07
Iter: 60 loss: 9.26215705e-07
Iter: 61 loss: 9.17535203e-07
Iter: 62 loss: 9.14805639e-07
Iter: 63 loss: 9.09730659e-07
Iter: 64 loss: 9.0344156e-07
Iter: 65 loss: 9.03449347e-07
Iter: 66 loss: 8.98834287e-07
Iter: 67 loss: 8.94190634e-07
Iter: 68 loss: 8.93319793e-07
Iter: 69 loss: 8.86833107e-07
Iter: 70 loss: 9.34532e-07
Iter: 71 loss: 8.86251712e-07
Iter: 72 loss: 8.80144682e-07
Iter: 73 loss: 8.73329e-07
Iter: 74 loss: 8.72305804e-07
Iter: 75 loss: 8.74514456e-07
Iter: 76 loss: 8.6910751e-07
Iter: 77 loss: 8.65384e-07
Iter: 78 loss: 8.65327877e-07
Iter: 79 loss: 8.6231654e-07
Iter: 80 loss: 8.5817112e-07
Iter: 81 loss: 8.50239758e-07
Iter: 82 loss: 1.01511682e-06
Iter: 83 loss: 8.50209574e-07
Iter: 84 loss: 8.43462146e-07
Iter: 85 loss: 9.00382929e-07
Iter: 86 loss: 8.43125065e-07
Iter: 87 loss: 8.37661048e-07
Iter: 88 loss: 8.61625722e-07
Iter: 89 loss: 8.36590516e-07
Iter: 90 loss: 8.30047327e-07
Iter: 91 loss: 8.29696489e-07
Iter: 92 loss: 8.24607696e-07
Iter: 93 loss: 8.19016293e-07
Iter: 94 loss: 8.45165e-07
Iter: 95 loss: 8.18071328e-07
Iter: 96 loss: 8.12517271e-07
Iter: 97 loss: 8.23342873e-07
Iter: 98 loss: 8.10353242e-07
Iter: 99 loss: 8.05094601e-07
Iter: 100 loss: 8.44969804e-07
Iter: 101 loss: 8.04777414e-07
Iter: 102 loss: 8.01868055e-07
Iter: 103 loss: 8.00470787e-07
Iter: 104 loss: 7.99095574e-07
Iter: 105 loss: 7.93737399e-07
Iter: 106 loss: 8.12834116e-07
Iter: 107 loss: 7.92278058e-07
Iter: 108 loss: 7.88724833e-07
Iter: 109 loss: 7.99339603e-07
Iter: 110 loss: 7.8769483e-07
Iter: 111 loss: 7.84057306e-07
Iter: 112 loss: 7.95773815e-07
Iter: 113 loss: 7.82992402e-07
Iter: 114 loss: 7.80030234e-07
Iter: 115 loss: 7.79910351e-07
Iter: 116 loss: 7.7895163e-07
Iter: 117 loss: 7.76484796e-07
Iter: 118 loss: 7.98175961e-07
Iter: 119 loss: 7.76161e-07
Iter: 120 loss: 7.7307152e-07
Iter: 121 loss: 7.72478472e-07
Iter: 122 loss: 7.70366057e-07
Iter: 123 loss: 7.67004792e-07
Iter: 124 loss: 7.81903395e-07
Iter: 125 loss: 7.66348478e-07
Iter: 126 loss: 7.62657407e-07
Iter: 127 loss: 7.91996115e-07
Iter: 128 loss: 7.62491425e-07
Iter: 129 loss: 7.5997815e-07
Iter: 130 loss: 7.67026904e-07
Iter: 131 loss: 7.59191778e-07
Iter: 132 loss: 7.57257794e-07
Iter: 133 loss: 7.55242e-07
Iter: 134 loss: 7.54949156e-07
Iter: 135 loss: 7.52679341e-07
Iter: 136 loss: 7.52618575e-07
Iter: 137 loss: 7.50730351e-07
Iter: 138 loss: 7.51266839e-07
Iter: 139 loss: 7.49269645e-07
Iter: 140 loss: 7.46334649e-07
Iter: 141 loss: 7.47204126e-07
Iter: 142 loss: 7.44191198e-07
Iter: 143 loss: 7.41069186e-07
Iter: 144 loss: 7.55096437e-07
Iter: 145 loss: 7.40599887e-07
Iter: 146 loss: 7.38284655e-07
Iter: 147 loss: 7.72311182e-07
Iter: 148 loss: 7.38247934e-07
Iter: 149 loss: 7.3566423e-07
Iter: 150 loss: 7.41285476e-07
Iter: 151 loss: 7.34619562e-07
Iter: 152 loss: 7.33650495e-07
Iter: 153 loss: 7.31666432e-07
Iter: 154 loss: 7.68662858e-07
Iter: 155 loss: 7.31609248e-07
Iter: 156 loss: 7.28637247e-07
Iter: 157 loss: 7.35215792e-07
Iter: 158 loss: 7.27521467e-07
Iter: 159 loss: 7.25135862e-07
Iter: 160 loss: 7.37477535e-07
Iter: 161 loss: 7.247599e-07
Iter: 162 loss: 7.22699951e-07
Iter: 163 loss: 7.22663572e-07
Iter: 164 loss: 7.20977766e-07
Iter: 165 loss: 7.19332832e-07
Iter: 166 loss: 7.19121545e-07
Iter: 167 loss: 7.17857802e-07
Iter: 168 loss: 7.17925445e-07
Iter: 169 loss: 7.16786076e-07
Iter: 170 loss: 7.15010458e-07
Iter: 171 loss: 7.13396446e-07
Iter: 172 loss: 7.12918e-07
Iter: 173 loss: 7.10836616e-07
Iter: 174 loss: 7.27325073e-07
Iter: 175 loss: 7.1069644e-07
Iter: 176 loss: 7.08259677e-07
Iter: 177 loss: 7.09099595e-07
Iter: 178 loss: 7.06602464e-07
Iter: 179 loss: 7.04267563e-07
Iter: 180 loss: 7.04226295e-07
Iter: 181 loss: 7.0298529e-07
Iter: 182 loss: 7.03978912e-07
Iter: 183 loss: 7.02198179e-07
Iter: 184 loss: 6.99573434e-07
Iter: 185 loss: 7.06229287e-07
Iter: 186 loss: 6.98684062e-07
Iter: 187 loss: 6.97526502e-07
Iter: 188 loss: 6.96673283e-07
Iter: 189 loss: 6.96251732e-07
Iter: 190 loss: 6.94407674e-07
Iter: 191 loss: 6.91572779e-07
Iter: 192 loss: 6.91423736e-07
Iter: 193 loss: 6.89354067e-07
Iter: 194 loss: 6.89428248e-07
Iter: 195 loss: 6.87571514e-07
Iter: 196 loss: 6.8893803e-07
Iter: 197 loss: 6.86495298e-07
Iter: 198 loss: 6.84870713e-07
Iter: 199 loss: 6.84952852e-07
Iter: 200 loss: 6.83682572e-07
Iter: 201 loss: 6.83792223e-07
Iter: 202 loss: 6.82660584e-07
Iter: 203 loss: 6.80869221e-07
Iter: 204 loss: 6.82701057e-07
Iter: 205 loss: 6.79874177e-07
Iter: 206 loss: 6.78005222e-07
Iter: 207 loss: 6.87850388e-07
Iter: 208 loss: 6.77746925e-07
Iter: 209 loss: 6.76150819e-07
Iter: 210 loss: 6.74685793e-07
Iter: 211 loss: 6.7429994e-07
Iter: 212 loss: 6.72245164e-07
Iter: 213 loss: 7.00151645e-07
Iter: 214 loss: 6.72284671e-07
Iter: 215 loss: 6.71442535e-07
Iter: 216 loss: 6.71355508e-07
Iter: 217 loss: 6.70361032e-07
Iter: 218 loss: 6.69051815e-07
Iter: 219 loss: 6.68946882e-07
Iter: 220 loss: 6.67262839e-07
Iter: 221 loss: 6.70687541e-07
Iter: 222 loss: 6.66598567e-07
Iter: 223 loss: 6.65312484e-07
Iter: 224 loss: 6.64216486e-07
Iter: 225 loss: 6.63831429e-07
Iter: 226 loss: 6.61832189e-07
Iter: 227 loss: 6.7262522e-07
Iter: 228 loss: 6.6160311e-07
Iter: 229 loss: 6.60164574e-07
Iter: 230 loss: 6.61262789e-07
Iter: 231 loss: 6.59228419e-07
Iter: 232 loss: 6.5721872e-07
Iter: 233 loss: 6.70375414e-07
Iter: 234 loss: 6.56991e-07
Iter: 235 loss: 6.55918882e-07
Iter: 236 loss: 6.71948e-07
Iter: 237 loss: 6.55943722e-07
Iter: 238 loss: 6.55137285e-07
Iter: 239 loss: 6.5292096e-07
Iter: 240 loss: 6.67653353e-07
Iter: 241 loss: 6.52452798e-07
Iter: 242 loss: 6.50228117e-07
Iter: 243 loss: 6.76372e-07
Iter: 244 loss: 6.50163315e-07
Iter: 245 loss: 6.48539299e-07
Iter: 246 loss: 6.49595393e-07
Iter: 247 loss: 6.47469619e-07
Iter: 248 loss: 6.45764089e-07
Iter: 249 loss: 6.60432079e-07
Iter: 250 loss: 6.45749196e-07
Iter: 251 loss: 6.45285468e-07
Iter: 252 loss: 6.45268642e-07
Iter: 253 loss: 6.44623356e-07
Iter: 254 loss: 6.43756493e-07
Iter: 255 loss: 6.43771045e-07
Iter: 256 loss: 6.427274e-07
Iter: 257 loss: 6.43691124e-07
Iter: 258 loss: 6.42016573e-07
Iter: 259 loss: 6.41218435e-07
Iter: 260 loss: 6.4789765e-07
Iter: 261 loss: 6.41228269e-07
Iter: 262 loss: 6.40460257e-07
Iter: 263 loss: 6.38868812e-07
Iter: 264 loss: 6.64141794e-07
Iter: 265 loss: 6.38791562e-07
Iter: 266 loss: 6.37333926e-07
Iter: 267 loss: 6.5378606e-07
Iter: 268 loss: 6.37276571e-07
Iter: 269 loss: 6.36110258e-07
Iter: 270 loss: 6.3585037e-07
Iter: 271 loss: 6.35158756e-07
Iter: 272 loss: 6.33867444e-07
Iter: 273 loss: 6.33934917e-07
Iter: 274 loss: 6.32855176e-07
Iter: 275 loss: 6.34158937e-07
Iter: 276 loss: 6.32265e-07
Iter: 277 loss: 6.3086992e-07
Iter: 278 loss: 6.3053119e-07
Iter: 279 loss: 6.29650344e-07
Iter: 280 loss: 6.28040652e-07
Iter: 281 loss: 6.34533876e-07
Iter: 282 loss: 6.27622171e-07
Iter: 283 loss: 6.25914254e-07
Iter: 284 loss: 6.26989276e-07
Iter: 285 loss: 6.24793529e-07
Iter: 286 loss: 6.24346342e-07
Iter: 287 loss: 6.2404888e-07
Iter: 288 loss: 6.23160645e-07
Iter: 289 loss: 6.24521135e-07
Iter: 290 loss: 6.22740288e-07
Iter: 291 loss: 6.22002176e-07
Iter: 292 loss: 6.20625428e-07
Iter: 293 loss: 6.5118877e-07
Iter: 294 loss: 6.20630885e-07
Iter: 295 loss: 6.19542959e-07
Iter: 296 loss: 6.32102285e-07
Iter: 297 loss: 6.19517948e-07
Iter: 298 loss: 6.18530748e-07
Iter: 299 loss: 6.18044851e-07
Iter: 300 loss: 6.17638e-07
Iter: 301 loss: 6.16350576e-07
Iter: 302 loss: 6.27317377e-07
Iter: 303 loss: 6.16342049e-07
Iter: 304 loss: 6.15469332e-07
Iter: 305 loss: 6.1551242e-07
Iter: 306 loss: 6.14824671e-07
Iter: 307 loss: 6.13321731e-07
Iter: 308 loss: 6.15246e-07
Iter: 309 loss: 6.12484371e-07
Iter: 310 loss: 6.11735459e-07
Iter: 311 loss: 6.11624387e-07
Iter: 312 loss: 6.11011842e-07
Iter: 313 loss: 6.09498784e-07
Iter: 314 loss: 6.2381e-07
Iter: 315 loss: 6.0924549e-07
Iter: 316 loss: 6.07504546e-07
Iter: 317 loss: 6.24846734e-07
Iter: 318 loss: 6.07470895e-07
Iter: 319 loss: 6.06530307e-07
Iter: 320 loss: 6.06747847e-07
Iter: 321 loss: 6.05874448e-07
Iter: 322 loss: 6.05250193e-07
Iter: 323 loss: 6.05064258e-07
Iter: 324 loss: 6.04641059e-07
Iter: 325 loss: 6.03658918e-07
Iter: 326 loss: 6.18979868e-07
Iter: 327 loss: 6.03650506e-07
Iter: 328 loss: 6.02715318e-07
Iter: 329 loss: 6.02138755e-07
Iter: 330 loss: 6.01798945e-07
Iter: 331 loss: 6.00540488e-07
Iter: 332 loss: 6.12054464e-07
Iter: 333 loss: 6.00529745e-07
Iter: 334 loss: 5.99535383e-07
Iter: 335 loss: 5.99781e-07
Iter: 336 loss: 5.98762085e-07
Iter: 337 loss: 5.97757492e-07
Iter: 338 loss: 6.14856049e-07
Iter: 339 loss: 5.97772441e-07
Iter: 340 loss: 5.97092821e-07
Iter: 341 loss: 5.97675694e-07
Iter: 342 loss: 5.96691734e-07
Iter: 343 loss: 5.95596475e-07
Iter: 344 loss: 5.95281733e-07
Iter: 345 loss: 5.94568803e-07
Iter: 346 loss: 5.93577681e-07
Iter: 347 loss: 6.02378236e-07
Iter: 348 loss: 5.93566483e-07
Iter: 349 loss: 5.92611286e-07
Iter: 350 loss: 5.92852587e-07
Iter: 351 loss: 5.91898299e-07
Iter: 352 loss: 5.90640411e-07
Iter: 353 loss: 6.00914859e-07
Iter: 354 loss: 5.90606703e-07
Iter: 355 loss: 5.89708e-07
Iter: 356 loss: 5.92557058e-07
Iter: 357 loss: 5.89425e-07
Iter: 358 loss: 5.88473142e-07
Iter: 359 loss: 5.87896864e-07
Iter: 360 loss: 5.875e-07
Iter: 361 loss: 5.86878798e-07
Iter: 362 loss: 5.8661908e-07
Iter: 363 loss: 5.86267333e-07
Iter: 364 loss: 5.85416842e-07
Iter: 365 loss: 5.90701916e-07
Iter: 366 loss: 5.8517287e-07
Iter: 367 loss: 5.84017528e-07
Iter: 368 loss: 5.83364795e-07
Iter: 369 loss: 5.82754922e-07
Iter: 370 loss: 5.81478957e-07
Iter: 371 loss: 5.9244843e-07
Iter: 372 loss: 5.81446955e-07
Iter: 373 loss: 5.80175936e-07
Iter: 374 loss: 5.82918119e-07
Iter: 375 loss: 5.79682705e-07
Iter: 376 loss: 5.79063624e-07
Iter: 377 loss: 5.89626097e-07
Iter: 378 loss: 5.79080222e-07
Iter: 379 loss: 5.78412141e-07
Iter: 380 loss: 5.77463425e-07
Iter: 381 loss: 5.77456262e-07
Iter: 382 loss: 5.76204513e-07
Iter: 383 loss: 5.83959036e-07
Iter: 384 loss: 5.76020284e-07
Iter: 385 loss: 5.75105844e-07
Iter: 386 loss: 5.75922513e-07
Iter: 387 loss: 5.74520129e-07
Iter: 388 loss: 5.73193802e-07
Iter: 389 loss: 5.79096366e-07
Iter: 390 loss: 5.72780152e-07
Iter: 391 loss: 5.72017882e-07
Iter: 392 loss: 5.80614e-07
Iter: 393 loss: 5.71913517e-07
Iter: 394 loss: 5.71386238e-07
Iter: 395 loss: 5.71713542e-07
Iter: 396 loss: 5.70908639e-07
Iter: 397 loss: 5.69919e-07
Iter: 398 loss: 5.77122137e-07
Iter: 399 loss: 5.69788881e-07
Iter: 400 loss: 5.69185318e-07
Iter: 401 loss: 5.68511041e-07
Iter: 402 loss: 5.68464088e-07
Iter: 403 loss: 5.67656741e-07
Iter: 404 loss: 5.6634974e-07
Iter: 405 loss: 5.66343829e-07
Iter: 406 loss: 5.65279549e-07
Iter: 407 loss: 5.65226458e-07
Iter: 408 loss: 5.6439336e-07
Iter: 409 loss: 5.64552e-07
Iter: 410 loss: 5.63731248e-07
Iter: 411 loss: 5.62882803e-07
Iter: 412 loss: 5.75032857e-07
Iter: 413 loss: 5.62855917e-07
Iter: 414 loss: 5.62145146e-07
Iter: 415 loss: 5.63211472e-07
Iter: 416 loss: 5.61878664e-07
Iter: 417 loss: 5.60968942e-07
Iter: 418 loss: 5.60804153e-07
Iter: 419 loss: 5.60173248e-07
Iter: 420 loss: 5.59390799e-07
Iter: 421 loss: 5.67047778e-07
Iter: 422 loss: 5.59357431e-07
Iter: 423 loss: 5.58674515e-07
Iter: 424 loss: 5.595532e-07
Iter: 425 loss: 5.58265128e-07
Iter: 426 loss: 5.57378371e-07
Iter: 427 loss: 5.61473655e-07
Iter: 428 loss: 5.57258204e-07
Iter: 429 loss: 5.56672e-07
Iter: 430 loss: 5.6027443e-07
Iter: 431 loss: 5.56656914e-07
Iter: 432 loss: 5.56052385e-07
Iter: 433 loss: 5.57967383e-07
Iter: 434 loss: 5.55855536e-07
Iter: 435 loss: 5.553851e-07
Iter: 436 loss: 5.54833775e-07
Iter: 437 loss: 5.54724e-07
Iter: 438 loss: 5.54190876e-07
Iter: 439 loss: 5.54754706e-07
Iter: 440 loss: 5.53901941e-07
Iter: 441 loss: 5.53048835e-07
Iter: 442 loss: 5.53609652e-07
Iter: 443 loss: 5.52574249e-07
Iter: 444 loss: 5.51772246e-07
Iter: 445 loss: 5.55625661e-07
Iter: 446 loss: 5.51641961e-07
Iter: 447 loss: 5.50708478e-07
Iter: 448 loss: 5.49876802e-07
Iter: 449 loss: 5.49625724e-07
Iter: 450 loss: 5.48824914e-07
Iter: 451 loss: 5.48746243e-07
Iter: 452 loss: 5.48087371e-07
Iter: 453 loss: 5.48207936e-07
Iter: 454 loss: 5.47514219e-07
Iter: 455 loss: 5.46480862e-07
Iter: 456 loss: 5.51124231e-07
Iter: 457 loss: 5.46325168e-07
Iter: 458 loss: 5.45741159e-07
Iter: 459 loss: 5.452099e-07
Iter: 460 loss: 5.45109174e-07
Iter: 461 loss: 5.44264594e-07
Iter: 462 loss: 5.55762369e-07
Iter: 463 loss: 5.44221336e-07
Iter: 464 loss: 5.43862768e-07
Iter: 465 loss: 5.44158581e-07
Iter: 466 loss: 5.43610668e-07
Iter: 467 loss: 5.42930877e-07
Iter: 468 loss: 5.45044202e-07
Iter: 469 loss: 5.42781549e-07
Iter: 470 loss: 5.42161047e-07
Iter: 471 loss: 5.41373254e-07
Iter: 472 loss: 5.41325448e-07
Iter: 473 loss: 5.40467681e-07
Iter: 474 loss: 5.48914841e-07
Iter: 475 loss: 5.40389351e-07
Iter: 476 loss: 5.39957227e-07
Iter: 477 loss: 5.39216444e-07
Iter: 478 loss: 5.39218775e-07
Iter: 479 loss: 5.38364475e-07
Iter: 480 loss: 5.45577223e-07
Iter: 481 loss: 5.38371296e-07
Iter: 482 loss: 5.37733058e-07
Iter: 483 loss: 5.3761238e-07
Iter: 484 loss: 5.37115341e-07
Iter: 485 loss: 5.36213747e-07
Iter: 486 loss: 5.42908651e-07
Iter: 487 loss: 5.3612564e-07
Iter: 488 loss: 5.35481377e-07
Iter: 489 loss: 5.35390825e-07
Iter: 490 loss: 5.34892706e-07
Iter: 491 loss: 5.33868e-07
Iter: 492 loss: 5.39847804e-07
Iter: 493 loss: 5.33784657e-07
Iter: 494 loss: 5.33113052e-07
Iter: 495 loss: 5.38797451e-07
Iter: 496 loss: 5.33020341e-07
Iter: 497 loss: 5.32467425e-07
Iter: 498 loss: 5.33675802e-07
Iter: 499 loss: 5.32265744e-07
Iter: 500 loss: 5.31424689e-07
Iter: 501 loss: 5.34137087e-07
Iter: 502 loss: 5.31188334e-07
Iter: 503 loss: 5.30653892e-07
Iter: 504 loss: 5.31130354e-07
Iter: 505 loss: 5.3030692e-07
Iter: 506 loss: 5.29821534e-07
Iter: 507 loss: 5.31091473e-07
Iter: 508 loss: 5.2960371e-07
Iter: 509 loss: 5.28950579e-07
Iter: 510 loss: 5.27888915e-07
Iter: 511 loss: 5.27881355e-07
Iter: 512 loss: 5.2703524e-07
Iter: 513 loss: 5.3630265e-07
Iter: 514 loss: 5.26993858e-07
Iter: 515 loss: 5.26261147e-07
Iter: 516 loss: 5.26035535e-07
Iter: 517 loss: 5.25609835e-07
Iter: 518 loss: 5.24842335e-07
Iter: 519 loss: 5.33588604e-07
Iter: 520 loss: 5.24900088e-07
Iter: 521 loss: 5.24194263e-07
Iter: 522 loss: 5.23854055e-07
Iter: 523 loss: 5.23548522e-07
Iter: 524 loss: 5.22607934e-07
Iter: 525 loss: 5.31395244e-07
Iter: 526 loss: 5.22518e-07
Iter: 527 loss: 5.21937864e-07
Iter: 528 loss: 5.20886601e-07
Iter: 529 loss: 5.20882679e-07
Iter: 530 loss: 5.20586468e-07
Iter: 531 loss: 5.20256663e-07
Iter: 532 loss: 5.19918444e-07
Iter: 533 loss: 5.22955531e-07
Iter: 534 loss: 5.19821356e-07
Iter: 535 loss: 5.19406626e-07
Iter: 536 loss: 5.19008609e-07
Iter: 537 loss: 5.18955574e-07
Iter: 538 loss: 5.18348486e-07
Iter: 539 loss: 5.19297487e-07
Iter: 540 loss: 5.17970761e-07
Iter: 541 loss: 5.17349463e-07
Iter: 542 loss: 5.20780532e-07
Iter: 543 loss: 5.17221679e-07
Iter: 544 loss: 5.16749424e-07
Iter: 545 loss: 5.17383114e-07
Iter: 546 loss: 5.16476348e-07
Iter: 547 loss: 5.15791e-07
Iter: 548 loss: 5.16809052e-07
Iter: 549 loss: 5.15536499e-07
Iter: 550 loss: 5.15049578e-07
Iter: 551 loss: 5.14967496e-07
Iter: 552 loss: 5.14656e-07
Iter: 553 loss: 5.13899408e-07
Iter: 554 loss: 5.18982347e-07
Iter: 555 loss: 5.13881901e-07
Iter: 556 loss: 5.13335635e-07
Iter: 557 loss: 5.13923226e-07
Iter: 558 loss: 5.13028169e-07
Iter: 559 loss: 5.12180577e-07
Iter: 560 loss: 5.14575163e-07
Iter: 561 loss: 5.11983444e-07
Iter: 562 loss: 5.1132605e-07
Iter: 563 loss: 5.14807596e-07
Iter: 564 loss: 5.11258463e-07
Iter: 565 loss: 5.10676102e-07
Iter: 566 loss: 5.11513747e-07
Iter: 567 loss: 5.10317307e-07
Iter: 568 loss: 5.09842607e-07
Iter: 569 loss: 5.09788947e-07
Iter: 570 loss: 5.09637403e-07
Iter: 571 loss: 5.09140932e-07
Iter: 572 loss: 5.14222222e-07
Iter: 573 loss: 5.09041172e-07
Iter: 574 loss: 5.08422374e-07
Iter: 575 loss: 5.09704932e-07
Iter: 576 loss: 5.08178516e-07
Iter: 577 loss: 5.07469281e-07
Iter: 578 loss: 5.1367573e-07
Iter: 579 loss: 5.07465245e-07
Iter: 580 loss: 5.07092352e-07
Iter: 581 loss: 5.06822971e-07
Iter: 582 loss: 5.06709398e-07
Iter: 583 loss: 5.06066101e-07
Iter: 584 loss: 5.06781e-07
Iter: 585 loss: 5.05655635e-07
Iter: 586 loss: 5.05223227e-07
Iter: 587 loss: 5.05219703e-07
Iter: 588 loss: 5.04771037e-07
Iter: 589 loss: 5.04167929e-07
Iter: 590 loss: 5.04118248e-07
Iter: 591 loss: 5.03417709e-07
Iter: 592 loss: 5.08796688e-07
Iter: 593 loss: 5.03372689e-07
Iter: 594 loss: 5.02825969e-07
Iter: 595 loss: 5.03031629e-07
Iter: 596 loss: 5.02522539e-07
Iter: 597 loss: 5.01795e-07
Iter: 598 loss: 5.05434286e-07
Iter: 599 loss: 5.01622935e-07
Iter: 600 loss: 5.01437341e-07
Iter: 601 loss: 5.01369414e-07
Iter: 602 loss: 5.01103671e-07
Iter: 603 loss: 5.00672513e-07
Iter: 604 loss: 5.00650515e-07
Iter: 605 loss: 5.00145518e-07
Iter: 606 loss: 5.00051e-07
Iter: 607 loss: 4.99652856e-07
Iter: 608 loss: 4.99263081e-07
Iter: 609 loss: 5.05898925e-07
Iter: 610 loss: 4.99212774e-07
Iter: 611 loss: 4.98825045e-07
Iter: 612 loss: 4.98977442e-07
Iter: 613 loss: 4.98495069e-07
Iter: 614 loss: 4.97879284e-07
Iter: 615 loss: 4.98545546e-07
Iter: 616 loss: 4.97542032e-07
Iter: 617 loss: 4.97054828e-07
Iter: 618 loss: 4.99962368e-07
Iter: 619 loss: 4.96958251e-07
Iter: 620 loss: 4.96589678e-07
Iter: 621 loss: 4.96046312e-07
Iter: 622 loss: 4.95976451e-07
Iter: 623 loss: 4.95518748e-07
Iter: 624 loss: 4.9550647e-07
Iter: 625 loss: 4.95135566e-07
Iter: 626 loss: 4.94578046e-07
Iter: 627 loss: 4.94612209e-07
Iter: 628 loss: 4.93847836e-07
Iter: 629 loss: 4.97004919e-07
Iter: 630 loss: 4.93688674e-07
Iter: 631 loss: 4.93435437e-07
Iter: 632 loss: 4.93412927e-07
Iter: 633 loss: 4.92980575e-07
Iter: 634 loss: 4.93443792e-07
Iter: 635 loss: 4.92736433e-07
Iter: 636 loss: 4.92438971e-07
Iter: 637 loss: 4.91999913e-07
Iter: 638 loss: 4.91967853e-07
Iter: 639 loss: 4.91492415e-07
Iter: 640 loss: 4.9333886e-07
Iter: 641 loss: 4.91491e-07
Iter: 642 loss: 4.91029652e-07
Iter: 643 loss: 4.92772358e-07
Iter: 644 loss: 4.9086691e-07
Iter: 645 loss: 4.9041364e-07
Iter: 646 loss: 4.91427102e-07
Iter: 647 loss: 4.90214234e-07
Iter: 648 loss: 4.89790921e-07
Iter: 649 loss: 4.89839181e-07
Iter: 650 loss: 4.89548313e-07
Iter: 651 loss: 4.8886551e-07
Iter: 652 loss: 4.89935474e-07
Iter: 653 loss: 4.88574585e-07
Iter: 654 loss: 4.88114836e-07
Iter: 655 loss: 4.90570812e-07
Iter: 656 loss: 4.88112391e-07
Iter: 657 loss: 4.87569e-07
Iter: 658 loss: 4.89065144e-07
Iter: 659 loss: 4.8740236e-07
Iter: 660 loss: 4.86961198e-07
Iter: 661 loss: 4.88629098e-07
Iter: 662 loss: 4.86833414e-07
Iter: 663 loss: 4.86522254e-07
Iter: 664 loss: 4.86018394e-07
Iter: 665 loss: 4.8599486e-07
Iter: 666 loss: 4.86448585e-07
Iter: 667 loss: 4.85728663e-07
Iter: 668 loss: 4.8553153e-07
Iter: 669 loss: 4.85165515e-07
Iter: 670 loss: 4.88239834e-07
Iter: 671 loss: 4.85098155e-07
Iter: 672 loss: 4.84458724e-07
Iter: 673 loss: 4.84836733e-07
Iter: 674 loss: 4.84122893e-07
Iter: 675 loss: 4.83609824e-07
Iter: 676 loss: 4.836416e-07
Iter: 677 loss: 4.83195038e-07
Iter: 678 loss: 4.8365888e-07
Iter: 679 loss: 4.82998871e-07
Iter: 680 loss: 4.82406108e-07
Iter: 681 loss: 4.82658095e-07
Iter: 682 loss: 4.82008375e-07
Iter: 683 loss: 4.81368318e-07
Iter: 684 loss: 4.84358623e-07
Iter: 685 loss: 4.81307836e-07
Iter: 686 loss: 4.80898905e-07
Iter: 687 loss: 4.81135828e-07
Iter: 688 loss: 4.80622e-07
Iter: 689 loss: 4.80056258e-07
Iter: 690 loss: 4.82565383e-07
Iter: 691 loss: 4.79945072e-07
Iter: 692 loss: 4.79453774e-07
Iter: 693 loss: 4.82806854e-07
Iter: 694 loss: 4.79413643e-07
Iter: 695 loss: 4.79014e-07
Iter: 696 loss: 4.78552579e-07
Iter: 697 loss: 4.78533707e-07
Iter: 698 loss: 4.78611071e-07
Iter: 699 loss: 4.78282061e-07
Iter: 700 loss: 4.78104198e-07
Iter: 701 loss: 4.77940716e-07
Iter: 702 loss: 4.77856929e-07
Iter: 703 loss: 4.77533831e-07
Iter: 704 loss: 4.76987111e-07
Iter: 705 loss: 4.86808631e-07
Iter: 706 loss: 4.76957837e-07
Iter: 707 loss: 4.76594437e-07
Iter: 708 loss: 4.80758274e-07
Iter: 709 loss: 4.76566754e-07
Iter: 710 loss: 4.76140343e-07
Iter: 711 loss: 4.76751126e-07
Iter: 712 loss: 4.75953044e-07
Iter: 713 loss: 4.75428436e-07
Iter: 714 loss: 4.7740383e-07
Iter: 715 loss: 4.75348259e-07
Iter: 716 loss: 4.74939e-07
Iter: 717 loss: 4.76329319e-07
Iter: 718 loss: 4.74837123e-07
Iter: 719 loss: 4.7442316e-07
Iter: 720 loss: 4.7430342e-07
Iter: 721 loss: 4.74060414e-07
Iter: 722 loss: 4.73597083e-07
Iter: 723 loss: 4.78891366e-07
Iter: 724 loss: 4.73576e-07
Iter: 725 loss: 4.73273587e-07
Iter: 726 loss: 4.73913303e-07
Iter: 727 loss: 4.73141483e-07
Iter: 728 loss: 4.7269063e-07
Iter: 729 loss: 4.73342311e-07
Iter: 730 loss: 4.72506713e-07
Iter: 731 loss: 4.72149793e-07
Iter: 732 loss: 4.7294148e-07
Iter: 733 loss: 4.72031246e-07
Iter: 734 loss: 4.71892321e-07
Iter: 735 loss: 4.71780851e-07
Iter: 736 loss: 4.71616829e-07
Iter: 737 loss: 4.71182034e-07
Iter: 738 loss: 4.75301533e-07
Iter: 739 loss: 4.71174928e-07
Iter: 740 loss: 4.70847311e-07
Iter: 741 loss: 4.7132022e-07
Iter: 742 loss: 4.7069517e-07
Iter: 743 loss: 4.70254122e-07
Iter: 744 loss: 4.71607677e-07
Iter: 745 loss: 4.70137905e-07
Iter: 746 loss: 4.69782208e-07
Iter: 747 loss: 4.73718558e-07
Iter: 748 loss: 4.6971968e-07
Iter: 749 loss: 4.6947531e-07
Iter: 750 loss: 4.69302165e-07
Iter: 751 loss: 4.69229178e-07
Iter: 752 loss: 4.68778126e-07
Iter: 753 loss: 4.70538566e-07
Iter: 754 loss: 4.68654378e-07
Iter: 755 loss: 4.68249425e-07
Iter: 756 loss: 4.69640497e-07
Iter: 757 loss: 4.68165751e-07
Iter: 758 loss: 4.67713335e-07
Iter: 759 loss: 4.67599136e-07
Iter: 760 loss: 4.67396717e-07
Iter: 761 loss: 4.67024421e-07
Iter: 762 loss: 4.67070919e-07
Iter: 763 loss: 4.66801453e-07
Iter: 764 loss: 4.66446068e-07
Iter: 765 loss: 4.66433733e-07
Iter: 766 loss: 4.6637183e-07
Iter: 767 loss: 4.66224179e-07
Iter: 768 loss: 4.66087897e-07
Iter: 769 loss: 4.66242341e-07
Iter: 770 loss: 4.65972619e-07
Iter: 771 loss: 4.65804561e-07
Iter: 772 loss: 4.65334494e-07
Iter: 773 loss: 4.68218786e-07
Iter: 774 loss: 4.65241158e-07
Iter: 775 loss: 4.6458473e-07
Iter: 776 loss: 4.69201098e-07
Iter: 777 loss: 4.64480763e-07
Iter: 778 loss: 4.64053073e-07
Iter: 779 loss: 4.68743224e-07
Iter: 780 loss: 4.64003506e-07
Iter: 781 loss: 4.63707181e-07
Iter: 782 loss: 4.65876752e-07
Iter: 783 loss: 4.63635303e-07
Iter: 784 loss: 4.63357821e-07
Iter: 785 loss: 4.63730743e-07
Iter: 786 loss: 4.63206817e-07
Iter: 787 loss: 4.6291936e-07
Iter: 788 loss: 4.62941045e-07
Iter: 789 loss: 4.62649353e-07
Iter: 790 loss: 4.62289108e-07
Iter: 791 loss: 4.6596432e-07
Iter: 792 loss: 4.62294139e-07
Iter: 793 loss: 4.61980108e-07
Iter: 794 loss: 4.61913601e-07
Iter: 795 loss: 4.61730508e-07
Iter: 796 loss: 4.61364493e-07
Iter: 797 loss: 4.6349669e-07
Iter: 798 loss: 4.61295087e-07
Iter: 799 loss: 4.60974348e-07
Iter: 800 loss: 4.61943074e-07
Iter: 801 loss: 4.60924525e-07
Iter: 802 loss: 4.60699169e-07
Iter: 803 loss: 4.6074635e-07
Iter: 804 loss: 4.60575336e-07
Iter: 805 loss: 4.60246042e-07
Iter: 806 loss: 4.64413176e-07
Iter: 807 loss: 4.6017459e-07
Iter: 808 loss: 4.59832222e-07
Iter: 809 loss: 4.59419965e-07
Iter: 810 loss: 4.59383102e-07
Iter: 811 loss: 4.58698054e-07
Iter: 812 loss: 4.63895873e-07
Iter: 813 loss: 4.5857621e-07
Iter: 814 loss: 4.58179329e-07
Iter: 815 loss: 4.61486138e-07
Iter: 816 loss: 4.58132092e-07
Iter: 817 loss: 4.5769093e-07
Iter: 818 loss: 4.58977752e-07
Iter: 819 loss: 4.5758452e-07
Iter: 820 loss: 4.57219755e-07
Iter: 821 loss: 4.57826957e-07
Iter: 822 loss: 4.57132757e-07
Iter: 823 loss: 4.567259e-07
Iter: 824 loss: 4.56311227e-07
Iter: 825 loss: 4.56253417e-07
Iter: 826 loss: 4.55834055e-07
Iter: 827 loss: 4.5577238e-07
Iter: 828 loss: 4.554783e-07
Iter: 829 loss: 4.55208919e-07
Iter: 830 loss: 4.55161029e-07
Iter: 831 loss: 4.54695964e-07
Iter: 832 loss: 4.58707405e-07
Iter: 833 loss: 4.5468758e-07
Iter: 834 loss: 4.5450679e-07
Iter: 835 loss: 4.54477942e-07
Iter: 836 loss: 4.54297719e-07
Iter: 837 loss: 4.54242524e-07
Iter: 838 loss: 4.54164251e-07
Iter: 839 loss: 4.5390172e-07
Iter: 840 loss: 4.53513053e-07
Iter: 841 loss: 4.60472307e-07
Iter: 842 loss: 4.53497194e-07
Iter: 843 loss: 4.53029514e-07
Iter: 844 loss: 4.56496878e-07
Iter: 845 loss: 4.5296639e-07
Iter: 846 loss: 4.52670406e-07
Iter: 847 loss: 4.53856842e-07
Iter: 848 loss: 4.52560073e-07
Iter: 849 loss: 4.52254966e-07
Iter: 850 loss: 4.54776369e-07
Iter: 851 loss: 4.52256e-07
Iter: 852 loss: 4.52028587e-07
Iter: 853 loss: 4.52581361e-07
Iter: 854 loss: 4.51944345e-07
Iter: 855 loss: 4.51734365e-07
Iter: 856 loss: 4.51516769e-07
Iter: 857 loss: 4.51443555e-07
Iter: 858 loss: 4.51114317e-07
Iter: 859 loss: 4.52923302e-07
Iter: 860 loss: 4.51123526e-07
Iter: 861 loss: 4.50685093e-07
Iter: 862 loss: 4.51143791e-07
Iter: 863 loss: 4.5054594e-07
Iter: 864 loss: 4.50026732e-07
Iter: 865 loss: 4.51523363e-07
Iter: 866 loss: 4.49925238e-07
Iter: 867 loss: 4.49671347e-07
Iter: 868 loss: 4.4961547e-07
Iter: 869 loss: 4.49443348e-07
Iter: 870 loss: 4.49824938e-07
Iter: 871 loss: 4.49299421e-07
Iter: 872 loss: 4.49109478e-07
Iter: 873 loss: 4.48884066e-07
Iter: 874 loss: 4.4888418e-07
Iter: 875 loss: 4.4848764e-07
Iter: 876 loss: 4.48670761e-07
Iter: 877 loss: 4.48303183e-07
Iter: 878 loss: 4.47832946e-07
Iter: 879 loss: 4.48680169e-07
Iter: 880 loss: 4.47614525e-07
Iter: 881 loss: 4.47276705e-07
Iter: 882 loss: 4.48679828e-07
Iter: 883 loss: 4.47232622e-07
Iter: 884 loss: 4.46830285e-07
Iter: 885 loss: 4.4869941e-07
Iter: 886 loss: 4.46711e-07
Iter: 887 loss: 4.46384888e-07
Iter: 888 loss: 4.47896213e-07
Iter: 889 loss: 4.46323952e-07
Iter: 890 loss: 4.46151148e-07
Iter: 891 loss: 4.45863265e-07
Iter: 892 loss: 4.45842289e-07
Iter: 893 loss: 4.45350736e-07
Iter: 894 loss: 4.47073035e-07
Iter: 895 loss: 4.45208315e-07
Iter: 896 loss: 4.44956498e-07
Iter: 897 loss: 4.4909325e-07
Iter: 898 loss: 4.4495448e-07
Iter: 899 loss: 4.44756097e-07
Iter: 900 loss: 4.44392072e-07
Iter: 901 loss: 4.44382806e-07
Iter: 902 loss: 4.44318886e-07
Iter: 903 loss: 4.44238083e-07
Iter: 904 loss: 4.43973761e-07
Iter: 905 loss: 4.44028217e-07
Iter: 906 loss: 4.43838303e-07
Iter: 907 loss: 4.4364225e-07
Iter: 908 loss: 4.43306305e-07
Iter: 909 loss: 4.43298546e-07
Iter: 910 loss: 4.42968798e-07
Iter: 911 loss: 4.45550768e-07
Iter: 912 loss: 4.42876967e-07
Iter: 913 loss: 4.42607558e-07
Iter: 914 loss: 4.42584735e-07
Iter: 915 loss: 4.42399113e-07
Iter: 916 loss: 4.4204603e-07
Iter: 917 loss: 4.44098447e-07
Iter: 918 loss: 4.41962698e-07
Iter: 919 loss: 4.41692805e-07
Iter: 920 loss: 4.41729071e-07
Iter: 921 loss: 4.41543648e-07
Iter: 922 loss: 4.41233794e-07
Iter: 923 loss: 4.47594516e-07
Iter: 924 loss: 4.41264945e-07
Iter: 925 loss: 4.40960207e-07
Iter: 926 loss: 4.43036583e-07
Iter: 927 loss: 4.40928147e-07
Iter: 928 loss: 4.40608801e-07
Iter: 929 loss: 4.40628696e-07
Iter: 930 loss: 4.40330695e-07
Iter: 931 loss: 4.40194555e-07
Iter: 932 loss: 4.40142742e-07
Iter: 933 loss: 4.40040026e-07
Iter: 934 loss: 4.40095477e-07
Iter: 935 loss: 4.39914913e-07
Iter: 936 loss: 4.39739949e-07
Iter: 937 loss: 4.39743303e-07
Iter: 938 loss: 4.39610744e-07
Iter: 939 loss: 4.39401447e-07
Iter: 940 loss: 4.39402982e-07
Iter: 941 loss: 4.39177029e-07
Iter: 942 loss: 4.39443227e-07
Iter: 943 loss: 4.39077098e-07
Iter: 944 loss: 4.38824628e-07
Iter: 945 loss: 4.38744451e-07
Iter: 946 loss: 4.38558601e-07
Iter: 947 loss: 4.38314032e-07
Iter: 948 loss: 4.41611746e-07
Iter: 949 loss: 4.38296752e-07
Iter: 950 loss: 4.38119571e-07
Iter: 951 loss: 4.38876555e-07
Iter: 952 loss: 4.38030412e-07
Iter: 953 loss: 4.37807017e-07
Iter: 954 loss: 4.39132833e-07
Iter: 955 loss: 4.37775725e-07
Iter: 956 loss: 4.37634924e-07
Iter: 957 loss: 4.37416816e-07
Iter: 958 loss: 4.43426359e-07
Iter: 959 loss: 4.37425683e-07
Iter: 960 loss: 4.37024937e-07
Iter: 961 loss: 4.39048137e-07
Iter: 962 loss: 4.36961784e-07
Iter: 963 loss: 4.36763457e-07
Iter: 964 loss: 4.36744472e-07
Iter: 965 loss: 4.36561947e-07
Iter: 966 loss: 4.36294897e-07
Iter: 967 loss: 4.40204275e-07
Iter: 968 loss: 4.36277105e-07
Iter: 969 loss: 4.36168875e-07
Iter: 970 loss: 4.36173053e-07
Iter: 971 loss: 4.36017331e-07
Iter: 972 loss: 4.3588426e-07
Iter: 973 loss: 4.35910977e-07
Iter: 974 loss: 4.35687781e-07
Iter: 975 loss: 4.35428035e-07
Iter: 976 loss: 4.35385402e-07
Iter: 977 loss: 4.35187218e-07
Iter: 978 loss: 4.35954973e-07
Iter: 979 loss: 4.35132506e-07
Iter: 980 loss: 4.34867729e-07
Iter: 981 loss: 4.34827825e-07
Iter: 982 loss: 4.34615743e-07
Iter: 983 loss: 4.34388028e-07
Iter: 984 loss: 4.36489017e-07
Iter: 985 loss: 4.34356423e-07
Iter: 986 loss: 4.34128822e-07
Iter: 987 loss: 4.34675741e-07
Iter: 988 loss: 4.34046626e-07
Iter: 989 loss: 4.3389349e-07
Iter: 990 loss: 4.3543e-07
Iter: 991 loss: 4.33850118e-07
Iter: 992 loss: 4.33792252e-07
Iter: 993 loss: 4.33575224e-07
Iter: 994 loss: 4.3355908e-07
Iter: 995 loss: 4.33314028e-07
Iter: 996 loss: 4.34222585e-07
Iter: 997 loss: 4.33260936e-07
Iter: 998 loss: 4.33048456e-07
Iter: 999 loss: 4.33228507e-07
Iter: 1000 loss: 4.32914049e-07
Iter: 1001 loss: 4.32826255e-07
Iter: 1002 loss: 4.32803176e-07
Iter: 1003 loss: 4.32679684e-07
Iter: 1004 loss: 4.33156174e-07
Iter: 1005 loss: 4.32659675e-07
Iter: 1006 loss: 4.32604594e-07
Iter: 1007 loss: 4.32524246e-07
Iter: 1008 loss: 4.32494176e-07
Iter: 1009 loss: 4.32269474e-07
Iter: 1010 loss: 4.31994323e-07
Iter: 1011 loss: 4.31947086e-07
Iter: 1012 loss: 4.31648886e-07
Iter: 1013 loss: 4.34785875e-07
Iter: 1014 loss: 4.31617821e-07
Iter: 1015 loss: 4.31399229e-07
Iter: 1016 loss: 4.3115935e-07
Iter: 1017 loss: 4.31139284e-07
Iter: 1018 loss: 4.30838327e-07
Iter: 1019 loss: 4.30828237e-07
Iter: 1020 loss: 4.30681865e-07
Iter: 1021 loss: 4.31514366e-07
Iter: 1022 loss: 4.30644207e-07
Iter: 1023 loss: 4.3042786e-07
Iter: 1024 loss: 4.30518242e-07
Iter: 1025 loss: 4.30262162e-07
Iter: 1026 loss: 4.3004141e-07
Iter: 1027 loss: 4.30740556e-07
Iter: 1028 loss: 4.30013131e-07
Iter: 1029 loss: 4.29790873e-07
Iter: 1030 loss: 4.29513307e-07
Iter: 1031 loss: 4.29524022e-07
Iter: 1032 loss: 4.29380208e-07
Iter: 1033 loss: 4.2926311e-07
Iter: 1034 loss: 4.29168779e-07
Iter: 1035 loss: 4.30584606e-07
Iter: 1036 loss: 4.29168949e-07
Iter: 1037 loss: 4.29107217e-07
Iter: 1038 loss: 4.28890985e-07
Iter: 1039 loss: 4.32194952e-07
Iter: 1040 loss: 4.28845794e-07
Iter: 1041 loss: 4.28581387e-07
Iter: 1042 loss: 4.28825246e-07
Iter: 1043 loss: 4.28436294e-07
Iter: 1044 loss: 4.28175554e-07
Iter: 1045 loss: 4.28941803e-07
Iter: 1046 loss: 4.28155886e-07
Iter: 1047 loss: 4.27834181e-07
Iter: 1048 loss: 4.27664418e-07
Iter: 1049 loss: 4.27519808e-07
Iter: 1050 loss: 4.2728189e-07
Iter: 1051 loss: 4.30587193e-07
Iter: 1052 loss: 4.2727163e-07
Iter: 1053 loss: 4.27014015e-07
Iter: 1054 loss: 4.27271516e-07
Iter: 1055 loss: 4.26842092e-07
Iter: 1056 loss: 4.26594909e-07
Iter: 1057 loss: 4.29740737e-07
Iter: 1058 loss: 4.266156e-07
Iter: 1059 loss: 4.26464226e-07
Iter: 1060 loss: 4.26229946e-07
Iter: 1061 loss: 4.2624518e-07
Iter: 1062 loss: 4.25915033e-07
Iter: 1063 loss: 4.26989658e-07
Iter: 1064 loss: 4.25854e-07
Iter: 1065 loss: 4.25711562e-07
Iter: 1066 loss: 4.27926e-07
Iter: 1067 loss: 4.25677285e-07
Iter: 1068 loss: 4.25501639e-07
Iter: 1069 loss: 4.27131027e-07
Iter: 1070 loss: 4.25478817e-07
Iter: 1071 loss: 4.25353164e-07
Iter: 1072 loss: 4.25286942e-07
Iter: 1073 loss: 4.25188432e-07
Iter: 1074 loss: 4.24980215e-07
Iter: 1075 loss: 4.2530516e-07
Iter: 1076 loss: 4.24892534e-07
Iter: 1077 loss: 4.24702307e-07
Iter: 1078 loss: 4.24550791e-07
Iter: 1079 loss: 4.24485478e-07
Iter: 1080 loss: 4.24145924e-07
Iter: 1081 loss: 4.25179707e-07
Iter: 1082 loss: 4.24000916e-07
Iter: 1083 loss: 4.23770587e-07
Iter: 1084 loss: 4.24636141e-07
Iter: 1085 loss: 4.23667899e-07
Iter: 1086 loss: 4.23390247e-07
Iter: 1087 loss: 4.2337939e-07
Iter: 1088 loss: 4.23106655e-07
Iter: 1089 loss: 4.22814082e-07
Iter: 1090 loss: 4.22829658e-07
Iter: 1091 loss: 4.22616438e-07
Iter: 1092 loss: 4.22828322e-07
Iter: 1093 loss: 4.22485613e-07
Iter: 1094 loss: 4.22155495e-07
Iter: 1095 loss: 4.21784591e-07
Iter: 1096 loss: 4.21774757e-07
Iter: 1097 loss: 4.21308442e-07
Iter: 1098 loss: 4.24906631e-07
Iter: 1099 loss: 4.21308584e-07
Iter: 1100 loss: 4.21089169e-07
Iter: 1101 loss: 4.23895841e-07
Iter: 1102 loss: 4.21044206e-07
Iter: 1103 loss: 4.20777837e-07
Iter: 1104 loss: 4.21625657e-07
Iter: 1105 loss: 4.20691777e-07
Iter: 1106 loss: 4.20575532e-07
Iter: 1107 loss: 4.20683165e-07
Iter: 1108 loss: 4.20454967e-07
Iter: 1109 loss: 4.20271704e-07
Iter: 1110 loss: 4.19910663e-07
Iter: 1111 loss: 4.27636081e-07
Iter: 1112 loss: 4.19870389e-07
Iter: 1113 loss: 4.19566163e-07
Iter: 1114 loss: 4.19530181e-07
Iter: 1115 loss: 4.19323811e-07
Iter: 1116 loss: 4.18972576e-07
Iter: 1117 loss: 4.18950322e-07
Iter: 1118 loss: 4.18451435e-07
Iter: 1119 loss: 4.22644575e-07
Iter: 1120 loss: 4.18441402e-07
Iter: 1121 loss: 4.18170373e-07
Iter: 1122 loss: 4.18390073e-07
Iter: 1123 loss: 4.17972046e-07
Iter: 1124 loss: 4.17619589e-07
Iter: 1125 loss: 4.20759733e-07
Iter: 1126 loss: 4.1760822e-07
Iter: 1127 loss: 4.17281854e-07
Iter: 1128 loss: 4.17548023e-07
Iter: 1129 loss: 4.17089609e-07
Iter: 1130 loss: 4.16849758e-07
Iter: 1131 loss: 4.16782626e-07
Iter: 1132 loss: 4.16583788e-07
Iter: 1133 loss: 4.16358517e-07
Iter: 1134 loss: 4.16337912e-07
Iter: 1135 loss: 4.16168064e-07
Iter: 1136 loss: 4.18065923e-07
Iter: 1137 loss: 4.16094053e-07
Iter: 1138 loss: 4.1600822e-07
Iter: 1139 loss: 4.15807961e-07
Iter: 1140 loss: 4.19700029e-07
Iter: 1141 loss: 4.1579878e-07
Iter: 1142 loss: 4.1540028e-07
Iter: 1143 loss: 4.15886802e-07
Iter: 1144 loss: 4.15251293e-07
Iter: 1145 loss: 4.14972817e-07
Iter: 1146 loss: 4.16088341e-07
Iter: 1147 loss: 4.14898125e-07
Iter: 1148 loss: 4.14550186e-07
Iter: 1149 loss: 4.14355782e-07
Iter: 1150 loss: 4.14247893e-07
Iter: 1151 loss: 4.13915018e-07
Iter: 1152 loss: 4.188677e-07
Iter: 1153 loss: 4.13908225e-07
Iter: 1154 loss: 4.13652174e-07
Iter: 1155 loss: 4.13560826e-07
Iter: 1156 loss: 4.13480961e-07
Iter: 1157 loss: 4.13126088e-07
Iter: 1158 loss: 4.16993458e-07
Iter: 1159 loss: 4.13116595e-07
Iter: 1160 loss: 4.12850312e-07
Iter: 1161 loss: 4.13847232e-07
Iter: 1162 loss: 4.12856167e-07
Iter: 1163 loss: 4.12600087e-07
Iter: 1164 loss: 4.12207896e-07
Iter: 1165 loss: 4.12206418e-07
Iter: 1166 loss: 4.11909468e-07
Iter: 1167 loss: 4.11916943e-07
Iter: 1168 loss: 4.11778899e-07
Iter: 1169 loss: 4.11733311e-07
Iter: 1170 loss: 4.11638581e-07
Iter: 1171 loss: 4.1136056e-07
Iter: 1172 loss: 4.15099095e-07
Iter: 1173 loss: 4.1132995e-07
Iter: 1174 loss: 4.11062132e-07
Iter: 1175 loss: 4.12708346e-07
Iter: 1176 loss: 4.1095285e-07
Iter: 1177 loss: 4.10753444e-07
Iter: 1178 loss: 4.10847179e-07
Iter: 1179 loss: 4.10606674e-07
Iter: 1180 loss: 4.10329392e-07
Iter: 1181 loss: 4.10584676e-07
Iter: 1182 loss: 4.10153547e-07
Iter: 1183 loss: 4.09858529e-07
Iter: 1184 loss: 4.11955739e-07
Iter: 1185 loss: 4.09779e-07
Iter: 1186 loss: 4.09553252e-07
Iter: 1187 loss: 4.09574398e-07
Iter: 1188 loss: 4.09361718e-07
Iter: 1189 loss: 4.08936955e-07
Iter: 1190 loss: 4.11246361e-07
Iter: 1191 loss: 4.08879117e-07
Iter: 1192 loss: 4.08655723e-07
Iter: 1193 loss: 4.12088525e-07
Iter: 1194 loss: 4.08659332e-07
Iter: 1195 loss: 4.0851603e-07
Iter: 1196 loss: 4.08081263e-07
Iter: 1197 loss: 4.14365047e-07
Iter: 1198 loss: 4.08094195e-07
Iter: 1199 loss: 4.07791788e-07
Iter: 1200 loss: 4.11704661e-07
Iter: 1201 loss: 4.07779083e-07
Iter: 1202 loss: 4.07600538e-07
Iter: 1203 loss: 4.07603466e-07
Iter: 1204 loss: 4.07461641e-07
Iter: 1205 loss: 4.07311887e-07
Iter: 1206 loss: 4.07279288e-07
Iter: 1207 loss: 4.07091676e-07
Iter: 1208 loss: 4.0796985e-07
Iter: 1209 loss: 4.07021275e-07
Iter: 1210 loss: 4.06806208e-07
Iter: 1211 loss: 4.0662141e-07
Iter: 1212 loss: 4.06643892e-07
Iter: 1213 loss: 4.06313745e-07
Iter: 1214 loss: 4.07523572e-07
Iter: 1215 loss: 4.06223734e-07
Iter: 1216 loss: 4.05959071e-07
Iter: 1217 loss: 4.07357533e-07
Iter: 1218 loss: 4.0594864e-07
Iter: 1219 loss: 4.05725132e-07
Iter: 1220 loss: 4.05773051e-07
Iter: 1221 loss: 4.05571228e-07
Iter: 1222 loss: 4.05256e-07
Iter: 1223 loss: 4.06899858e-07
Iter: 1224 loss: 4.05269844e-07
Iter: 1225 loss: 4.05057904e-07
Iter: 1226 loss: 4.06343133e-07
Iter: 1227 loss: 4.05012258e-07
Iter: 1228 loss: 4.04758481e-07
Iter: 1229 loss: 4.04714399e-07
Iter: 1230 loss: 4.04560723e-07
Iter: 1231 loss: 4.04304359e-07
Iter: 1232 loss: 4.04778177e-07
Iter: 1233 loss: 4.04194509e-07
Iter: 1234 loss: 4.04044499e-07
Iter: 1235 loss: 4.03972791e-07
Iter: 1236 loss: 4.03842051e-07
Iter: 1237 loss: 4.03768581e-07
Iter: 1238 loss: 4.03621812e-07
Iter: 1239 loss: 4.03444432e-07
Iter: 1240 loss: 4.03921291e-07
Iter: 1241 loss: 4.03415243e-07
Iter: 1242 loss: 4.03223055e-07
Iter: 1243 loss: 4.03068555e-07
Iter: 1244 loss: 4.02980476e-07
Iter: 1245 loss: 4.02683554e-07
Iter: 1246 loss: 4.03807093e-07
Iter: 1247 loss: 4.0257288e-07
Iter: 1248 loss: 4.02353351e-07
Iter: 1249 loss: 4.03165814e-07
Iter: 1250 loss: 4.02288549e-07
Iter: 1251 loss: 4.0205714e-07
Iter: 1252 loss: 4.0274935e-07
Iter: 1253 loss: 4.01955162e-07
Iter: 1254 loss: 4.01731626e-07
Iter: 1255 loss: 4.02375804e-07
Iter: 1256 loss: 4.01687828e-07
Iter: 1257 loss: 4.01467048e-07
Iter: 1258 loss: 4.0225e-07
Iter: 1259 loss: 4.01424131e-07
Iter: 1260 loss: 4.01184536e-07
Iter: 1261 loss: 4.02479429e-07
Iter: 1262 loss: 4.01090745e-07
Iter: 1263 loss: 4.00947641e-07
Iter: 1264 loss: 4.00844e-07
Iter: 1265 loss: 4.00798086e-07
Iter: 1266 loss: 4.00503211e-07
Iter: 1267 loss: 4.01447807e-07
Iter: 1268 loss: 4.00465495e-07
Iter: 1269 loss: 4.00158484e-07
Iter: 1270 loss: 4.03444631e-07
Iter: 1271 loss: 4.001229e-07
Iter: 1272 loss: 3.9999631e-07
Iter: 1273 loss: 3.99835244e-07
Iter: 1274 loss: 3.99863382e-07
Iter: 1275 loss: 3.9961671e-07
Iter: 1276 loss: 3.99752253e-07
Iter: 1277 loss: 3.99416592e-07
Iter: 1278 loss: 3.99109496e-07
Iter: 1279 loss: 4.00564943e-07
Iter: 1280 loss: 3.99084968e-07
Iter: 1281 loss: 3.98898464e-07
Iter: 1282 loss: 3.98809e-07
Iter: 1283 loss: 3.98721795e-07
Iter: 1284 loss: 3.98449401e-07
Iter: 1285 loss: 4.01055644e-07
Iter: 1286 loss: 3.98443e-07
Iter: 1287 loss: 3.98226462e-07
Iter: 1288 loss: 3.98409981e-07
Iter: 1289 loss: 3.98135882e-07
Iter: 1290 loss: 3.97879148e-07
Iter: 1291 loss: 3.98804644e-07
Iter: 1292 loss: 3.97821736e-07
Iter: 1293 loss: 3.97665389e-07
Iter: 1294 loss: 3.9963254e-07
Iter: 1295 loss: 3.976362e-07
Iter: 1296 loss: 3.97494318e-07
Iter: 1297 loss: 3.97318217e-07
Iter: 1298 loss: 3.97292922e-07
Iter: 1299 loss: 3.970938e-07
Iter: 1300 loss: 3.98122779e-07
Iter: 1301 loss: 3.97068249e-07
Iter: 1302 loss: 3.97070806e-07
Iter: 1303 loss: 3.96964651e-07
Iter: 1304 loss: 3.9689462e-07
Iter: 1305 loss: 3.96700784e-07
Iter: 1306 loss: 3.97139e-07
Iter: 1307 loss: 3.96553332e-07
Iter: 1308 loss: 3.96358388e-07
Iter: 1309 loss: 3.96357336e-07
Iter: 1310 loss: 3.96167763e-07
Iter: 1311 loss: 3.96233162e-07
Iter: 1312 loss: 3.9605041e-07
Iter: 1313 loss: 3.95823e-07
Iter: 1314 loss: 3.96046318e-07
Iter: 1315 loss: 3.95673936e-07
Iter: 1316 loss: 3.95451423e-07
Iter: 1317 loss: 3.96852727e-07
Iter: 1318 loss: 3.95422205e-07
Iter: 1319 loss: 3.9526e-07
Iter: 1320 loss: 3.9530957e-07
Iter: 1321 loss: 3.95171185e-07
Iter: 1322 loss: 3.94919198e-07
Iter: 1323 loss: 3.9770805e-07
Iter: 1324 loss: 3.94909847e-07
Iter: 1325 loss: 3.94770524e-07
Iter: 1326 loss: 3.95145776e-07
Iter: 1327 loss: 3.94771774e-07
Iter: 1328 loss: 3.94611e-07
Iter: 1329 loss: 3.94444697e-07
Iter: 1330 loss: 3.94390042e-07
Iter: 1331 loss: 3.94064642e-07
Iter: 1332 loss: 3.95630707e-07
Iter: 1333 loss: 3.94082633e-07
Iter: 1334 loss: 3.93949904e-07
Iter: 1335 loss: 3.95505594e-07
Iter: 1336 loss: 3.93952917e-07
Iter: 1337 loss: 3.93773576e-07
Iter: 1338 loss: 3.93687088e-07
Iter: 1339 loss: 3.93595656e-07
Iter: 1340 loss: 3.93505388e-07
Iter: 1341 loss: 3.93443884e-07
Iter: 1342 loss: 3.93439734e-07
Iter: 1343 loss: 3.93182489e-07
Iter: 1344 loss: 3.93496578e-07
Iter: 1345 loss: 3.93122889e-07
Iter: 1346 loss: 3.92832874e-07
Iter: 1347 loss: 3.93649884e-07
Iter: 1348 loss: 3.92753236e-07
Iter: 1349 loss: 3.92555251e-07
Iter: 1350 loss: 3.92392451e-07
Iter: 1351 loss: 3.92333e-07
Iter: 1352 loss: 3.91992046e-07
Iter: 1353 loss: 3.93419072e-07
Iter: 1354 loss: 3.91908884e-07
Iter: 1355 loss: 3.91670881e-07
Iter: 1356 loss: 3.92370623e-07
Iter: 1357 loss: 3.91591584e-07
Iter: 1358 loss: 3.91335931e-07
Iter: 1359 loss: 3.94134332e-07
Iter: 1360 loss: 3.91347669e-07
Iter: 1361 loss: 3.91199762e-07
Iter: 1362 loss: 3.91846072e-07
Iter: 1363 loss: 3.9121079e-07
Iter: 1364 loss: 3.9105791e-07
Iter: 1365 loss: 3.90895764e-07
Iter: 1366 loss: 3.90892268e-07
Iter: 1367 loss: 3.90687035e-07
Iter: 1368 loss: 3.9263935e-07
Iter: 1369 loss: 3.90653668e-07
Iter: 1370 loss: 3.90571017e-07
Iter: 1371 loss: 3.90561809e-07
Iter: 1372 loss: 3.9053694e-07
Iter: 1373 loss: 3.90295497e-07
Iter: 1374 loss: 3.91268e-07
Iter: 1375 loss: 3.90246413e-07
Iter: 1376 loss: 3.89960974e-07
Iter: 1377 loss: 3.91654453e-07
Iter: 1378 loss: 3.89955915e-07
Iter: 1379 loss: 3.89838647e-07
Iter: 1380 loss: 3.90225e-07
Iter: 1381 loss: 3.89739228e-07
Iter: 1382 loss: 3.89540673e-07
Iter: 1383 loss: 3.8939362e-07
Iter: 1384 loss: 3.89319496e-07
Iter: 1385 loss: 3.89046079e-07
Iter: 1386 loss: 3.90662024e-07
Iter: 1387 loss: 3.89033715e-07
Iter: 1388 loss: 3.88771383e-07
Iter: 1389 loss: 3.88582805e-07
Iter: 1390 loss: 3.88511069e-07
Iter: 1391 loss: 3.88288839e-07
Iter: 1392 loss: 3.88247258e-07
Iter: 1393 loss: 3.88078774e-07
Iter: 1394 loss: 3.88578428e-07
Iter: 1395 loss: 3.88033925e-07
Iter: 1396 loss: 3.87820592e-07
Iter: 1397 loss: 3.87685532e-07
Iter: 1398 loss: 3.87630621e-07
Iter: 1399 loss: 3.87367237e-07
Iter: 1400 loss: 3.89909246e-07
Iter: 1401 loss: 3.87420272e-07
Iter: 1402 loss: 3.87280835e-07
Iter: 1403 loss: 3.8730451e-07
Iter: 1404 loss: 3.87199634e-07
Iter: 1405 loss: 3.86962085e-07
Iter: 1406 loss: 3.88888168e-07
Iter: 1407 loss: 3.86905981e-07
Iter: 1408 loss: 3.86725162e-07
Iter: 1409 loss: 3.87722281e-07
Iter: 1410 loss: 3.86665278e-07
Iter: 1411 loss: 3.86493355e-07
Iter: 1412 loss: 3.87384716e-07
Iter: 1413 loss: 3.86430656e-07
Iter: 1414 loss: 3.86263395e-07
Iter: 1415 loss: 3.8620621e-07
Iter: 1416 loss: 3.86124071e-07
Iter: 1417 loss: 3.85866e-07
Iter: 1418 loss: 3.86212889e-07
Iter: 1419 loss: 3.85768118e-07
Iter: 1420 loss: 3.85560213e-07
Iter: 1421 loss: 3.86067427e-07
Iter: 1422 loss: 3.85412136e-07
Iter: 1423 loss: 3.85205169e-07
Iter: 1424 loss: 3.86284341e-07
Iter: 1425 loss: 3.85247972e-07
Iter: 1426 loss: 3.85040181e-07
Iter: 1427 loss: 3.86442025e-07
Iter: 1428 loss: 3.85011788e-07
Iter: 1429 loss: 3.84850154e-07
Iter: 1430 loss: 3.84907338e-07
Iter: 1431 loss: 3.84695312e-07
Iter: 1432 loss: 3.84547803e-07
Iter: 1433 loss: 3.84937948e-07
Iter: 1434 loss: 3.84520604e-07
Iter: 1435 loss: 3.84382588e-07
Iter: 1436 loss: 3.84400607e-07
Iter: 1437 loss: 3.84241275e-07
Iter: 1438 loss: 3.84094648e-07
Iter: 1439 loss: 3.84100133e-07
Iter: 1440 loss: 3.83936026e-07
Iter: 1441 loss: 3.83992017e-07
Iter: 1442 loss: 3.83872447e-07
Iter: 1443 loss: 3.83643055e-07
Iter: 1444 loss: 3.83895781e-07
Iter: 1445 loss: 3.83576037e-07
Iter: 1446 loss: 3.83370491e-07
Iter: 1447 loss: 3.83351448e-07
Iter: 1448 loss: 3.83224318e-07
Iter: 1449 loss: 3.83028834e-07
Iter: 1450 loss: 3.88098869e-07
Iter: 1451 loss: 3.82987736e-07
Iter: 1452 loss: 3.82680071e-07
Iter: 1453 loss: 3.83804036e-07
Iter: 1454 loss: 3.8260373e-07
Iter: 1455 loss: 3.82379596e-07
Iter: 1456 loss: 3.82680668e-07
Iter: 1457 loss: 3.82263039e-07
Iter: 1458 loss: 3.82033221e-07
Iter: 1459 loss: 3.83492193e-07
Iter: 1460 loss: 3.82002867e-07
Iter: 1461 loss: 3.81838561e-07
Iter: 1462 loss: 3.81867494e-07
Iter: 1463 loss: 3.81722344e-07
Iter: 1464 loss: 3.81435314e-07
Iter: 1465 loss: 3.86107985e-07
Iter: 1466 loss: 3.81429658e-07
Iter: 1467 loss: 3.81250118e-07
Iter: 1468 loss: 3.81235338e-07
Iter: 1469 loss: 3.81110681e-07
Iter: 1470 loss: 3.82499422e-07
Iter: 1471 loss: 3.81118269e-07
Iter: 1472 loss: 3.80971841e-07
Iter: 1473 loss: 3.80698594e-07
Iter: 1474 loss: 3.83718515e-07
Iter: 1475 loss: 3.80714368e-07
Iter: 1476 loss: 3.80429242e-07
Iter: 1477 loss: 3.81917573e-07
Iter: 1478 loss: 3.8041739e-07
Iter: 1479 loss: 3.8019266e-07
Iter: 1480 loss: 3.80438223e-07
Iter: 1481 loss: 3.80097021e-07
Iter: 1482 loss: 3.79915548e-07
Iter: 1483 loss: 3.8092702e-07
Iter: 1484 loss: 3.79807659e-07
Iter: 1485 loss: 3.79587533e-07
Iter: 1486 loss: 3.79819397e-07
Iter: 1487 loss: 3.79506929e-07
Iter: 1488 loss: 3.79205346e-07
Iter: 1489 loss: 3.7925895e-07
Iter: 1490 loss: 3.78977148e-07
Iter: 1491 loss: 3.78717971e-07
Iter: 1492 loss: 3.79991945e-07
Iter: 1493 loss: 3.78654931e-07
Iter: 1494 loss: 3.7835639e-07
Iter: 1495 loss: 3.79384119e-07
Iter: 1496 loss: 3.78261689e-07
Iter: 1497 loss: 3.78058388e-07
Iter: 1498 loss: 3.78052277e-07
Iter: 1499 loss: 3.77903177e-07
Iter: 1500 loss: 3.77759932e-07
Iter: 1501 loss: 3.77723268e-07
Iter: 1502 loss: 3.77588123e-07
Iter: 1503 loss: 3.77602248e-07
Iter: 1504 loss: 3.77428933e-07
Iter: 1505 loss: 3.77288103e-07
Iter: 1506 loss: 3.77275626e-07
Iter: 1507 loss: 3.77121523e-07
Iter: 1508 loss: 3.77375301e-07
Iter: 1509 loss: 3.77024094e-07
Iter: 1510 loss: 3.76796805e-07
Iter: 1511 loss: 3.7668724e-07
Iter: 1512 loss: 3.76581966e-07
Iter: 1513 loss: 3.76376875e-07
Iter: 1514 loss: 3.7640558e-07
Iter: 1515 loss: 3.76212029e-07
Iter: 1516 loss: 3.7637443e-07
Iter: 1517 loss: 3.76171158e-07
Iter: 1518 loss: 3.7589524e-07
Iter: 1519 loss: 3.76147909e-07
Iter: 1520 loss: 3.75773027e-07
Iter: 1521 loss: 3.75527407e-07
Iter: 1522 loss: 3.75474741e-07
Iter: 1523 loss: 3.75305e-07
Iter: 1524 loss: 3.75009876e-07
Iter: 1525 loss: 3.78952677e-07
Iter: 1526 loss: 3.75001378e-07
Iter: 1527 loss: 3.74830847e-07
Iter: 1528 loss: 3.75182083e-07
Iter: 1529 loss: 3.74747e-07
Iter: 1530 loss: 3.74533784e-07
Iter: 1531 loss: 3.7633319e-07
Iter: 1532 loss: 3.74515537e-07
Iter: 1533 loss: 3.74378601e-07
Iter: 1534 loss: 3.75456551e-07
Iter: 1535 loss: 3.74363395e-07
Iter: 1536 loss: 3.74238283e-07
Iter: 1537 loss: 3.74240926e-07
Iter: 1538 loss: 3.74123232e-07
Iter: 1539 loss: 3.73985529e-07
Iter: 1540 loss: 3.73798144e-07
Iter: 1541 loss: 3.73767335e-07
Iter: 1542 loss: 3.73511568e-07
Iter: 1543 loss: 3.75177308e-07
Iter: 1544 loss: 3.73453503e-07
Iter: 1545 loss: 3.73323587e-07
Iter: 1546 loss: 3.74104872e-07
Iter: 1547 loss: 3.7332731e-07
Iter: 1548 loss: 3.73099169e-07
Iter: 1549 loss: 3.73168774e-07
Iter: 1550 loss: 3.73023113e-07
Iter: 1551 loss: 3.72869238e-07
Iter: 1552 loss: 3.7414614e-07
Iter: 1553 loss: 3.7288936e-07
Iter: 1554 loss: 3.7277249e-07
Iter: 1555 loss: 3.72595e-07
Iter: 1556 loss: 3.72555434e-07
Iter: 1557 loss: 3.72351479e-07
Iter: 1558 loss: 3.73597e-07
Iter: 1559 loss: 3.72340537e-07
Iter: 1560 loss: 3.72121434e-07
Iter: 1561 loss: 3.72066609e-07
Iter: 1562 loss: 3.71998055e-07
Iter: 1563 loss: 3.71855521e-07
Iter: 1564 loss: 3.71801832e-07
Iter: 1565 loss: 3.71685843e-07
Iter: 1566 loss: 3.72166653e-07
Iter: 1567 loss: 3.71708239e-07
Iter: 1568 loss: 3.71604131e-07
Iter: 1569 loss: 3.71776224e-07
Iter: 1570 loss: 3.71501358e-07
Iter: 1571 loss: 3.71375478e-07
Iter: 1572 loss: 3.71138668e-07
Iter: 1573 loss: 3.7508903e-07
Iter: 1574 loss: 3.7113665e-07
Iter: 1575 loss: 3.7093514e-07
Iter: 1576 loss: 3.71862029e-07
Iter: 1577 loss: 3.70847914e-07
Iter: 1578 loss: 3.70699638e-07
Iter: 1579 loss: 3.71700935e-07
Iter: 1580 loss: 3.70654703e-07
Iter: 1581 loss: 3.70479512e-07
Iter: 1582 loss: 3.70934345e-07
Iter: 1583 loss: 3.70408458e-07
Iter: 1584 loss: 3.70302473e-07
Iter: 1585 loss: 3.70294487e-07
Iter: 1586 loss: 3.70172359e-07
Iter: 1587 loss: 3.69977101e-07
Iter: 1588 loss: 3.70671813e-07
Iter: 1589 loss: 3.69919263e-07
Iter: 1590 loss: 3.69736483e-07
Iter: 1591 loss: 3.700479e-07
Iter: 1592 loss: 3.69658864e-07
Iter: 1593 loss: 3.69451044e-07
Iter: 1594 loss: 3.69738473e-07
Iter: 1595 loss: 3.69388431e-07
Iter: 1596 loss: 3.69169243e-07
Iter: 1597 loss: 3.70802582e-07
Iter: 1598 loss: 3.69158442e-07
Iter: 1599 loss: 3.69101372e-07
Iter: 1600 loss: 3.70204276e-07
Iter: 1601 loss: 3.69087758e-07
Iter: 1602 loss: 3.68989674e-07
Iter: 1603 loss: 3.69327921e-07
Iter: 1604 loss: 3.68960912e-07
Iter: 1605 loss: 3.68823464e-07
Iter: 1606 loss: 3.68750477e-07
Iter: 1607 loss: 3.68681526e-07
Iter: 1608 loss: 3.68567612e-07
Iter: 1609 loss: 3.68436162e-07
Iter: 1610 loss: 3.68435337e-07
Iter: 1611 loss: 3.68266853e-07
Iter: 1612 loss: 3.69690667e-07
Iter: 1613 loss: 3.68248948e-07
Iter: 1614 loss: 3.68091662e-07
Iter: 1615 loss: 3.68737034e-07
Iter: 1616 loss: 3.68089616e-07
Iter: 1617 loss: 3.67963594e-07
Iter: 1618 loss: 3.67971268e-07
Iter: 1619 loss: 3.67859684e-07
Iter: 1620 loss: 3.67718854e-07
Iter: 1621 loss: 3.68121533e-07
Iter: 1622 loss: 3.67660874e-07
Iter: 1623 loss: 3.67501684e-07
Iter: 1624 loss: 3.67897144e-07
Iter: 1625 loss: 3.67441828e-07
Iter: 1626 loss: 3.67363384e-07
Iter: 1627 loss: 3.67676193e-07
Iter: 1628 loss: 3.67301595e-07
Iter: 1629 loss: 3.67138966e-07
Iter: 1630 loss: 3.67378902e-07
Iter: 1631 loss: 3.67086699e-07
Iter: 1632 loss: 3.66954168e-07
Iter: 1633 loss: 3.66943311e-07
Iter: 1634 loss: 3.66876407e-07
Iter: 1635 loss: 3.67333769e-07
Iter: 1636 loss: 3.66862253e-07
Iter: 1637 loss: 3.6677028e-07
Iter: 1638 loss: 3.6685816e-07
Iter: 1639 loss: 3.66752488e-07
Iter: 1640 loss: 3.66681036e-07
Iter: 1641 loss: 3.66460824e-07
Iter: 1642 loss: 3.69084432e-07
Iter: 1643 loss: 3.66417851e-07
Iter: 1644 loss: 3.66270882e-07
Iter: 1645 loss: 3.6761827e-07
Iter: 1646 loss: 3.66280659e-07
Iter: 1647 loss: 3.66182803e-07
Iter: 1648 loss: 3.66563256e-07
Iter: 1649 loss: 3.66140142e-07
Iter: 1650 loss: 3.65999313e-07
Iter: 1651 loss: 3.66754676e-07
Iter: 1652 loss: 3.65964468e-07
Iter: 1653 loss: 3.65858625e-07
Iter: 1654 loss: 3.65909898e-07
Iter: 1655 loss: 3.65770688e-07
Iter: 1656 loss: 3.65612436e-07
Iter: 1657 loss: 3.65725185e-07
Iter: 1658 loss: 3.6548596e-07
Iter: 1659 loss: 3.65322762e-07
Iter: 1660 loss: 3.66454572e-07
Iter: 1661 loss: 3.6530156e-07
Iter: 1662 loss: 3.65164396e-07
Iter: 1663 loss: 3.65201629e-07
Iter: 1664 loss: 3.65089477e-07
Iter: 1665 loss: 3.64949926e-07
Iter: 1666 loss: 3.6653239e-07
Iter: 1667 loss: 3.64950978e-07
Iter: 1668 loss: 3.64841867e-07
Iter: 1669 loss: 3.66244649e-07
Iter: 1670 loss: 3.64831038e-07
Iter: 1671 loss: 3.64770244e-07
Iter: 1672 loss: 3.64746768e-07
Iter: 1673 loss: 3.6469936e-07
Iter: 1674 loss: 3.6456521e-07
Iter: 1675 loss: 3.64639448e-07
Iter: 1676 loss: 3.64509134e-07
Iter: 1677 loss: 3.64416138e-07
Iter: 1678 loss: 3.64391269e-07
Iter: 1679 loss: 3.64335904e-07
Iter: 1680 loss: 3.64165203e-07
Iter: 1681 loss: 3.64726503e-07
Iter: 1682 loss: 3.64132291e-07
Iter: 1683 loss: 3.64025141e-07
Iter: 1684 loss: 3.64785166e-07
Iter: 1685 loss: 3.64021531e-07
Iter: 1686 loss: 3.639027e-07
Iter: 1687 loss: 3.64102533e-07
Iter: 1688 loss: 3.63808e-07
Iter: 1689 loss: 3.63692379e-07
Iter: 1690 loss: 3.63975687e-07
Iter: 1691 loss: 3.63591482e-07
Iter: 1692 loss: 3.6345017e-07
Iter: 1693 loss: 3.63366041e-07
Iter: 1694 loss: 3.63303172e-07
Iter: 1695 loss: 3.63064146e-07
Iter: 1696 loss: 3.65398648e-07
Iter: 1697 loss: 3.63055563e-07
Iter: 1698 loss: 3.62917604e-07
Iter: 1699 loss: 3.62954211e-07
Iter: 1700 loss: 3.62842343e-07
Iter: 1701 loss: 3.62750086e-07
Iter: 1702 loss: 3.62737666e-07
Iter: 1703 loss: 3.62629123e-07
Iter: 1704 loss: 3.62917376e-07
Iter: 1705 loss: 3.62578476e-07
Iter: 1706 loss: 3.62528283e-07
Iter: 1707 loss: 3.62461833e-07
Iter: 1708 loss: 3.62474111e-07
Iter: 1709 loss: 3.62336436e-07
Iter: 1710 loss: 3.62221e-07
Iter: 1711 loss: 3.62165167e-07
Iter: 1712 loss: 3.62026412e-07
Iter: 1713 loss: 3.6290669e-07
Iter: 1714 loss: 3.61954477e-07
Iter: 1715 loss: 3.61851079e-07
Iter: 1716 loss: 3.62079504e-07
Iter: 1717 loss: 3.61781758e-07
Iter: 1718 loss: 3.6161191e-07
Iter: 1719 loss: 3.62548235e-07
Iter: 1720 loss: 3.61596e-07
Iter: 1721 loss: 3.61442119e-07
Iter: 1722 loss: 3.62319668e-07
Iter: 1723 loss: 3.61447547e-07
Iter: 1724 loss: 3.61331161e-07
Iter: 1725 loss: 3.61267411e-07
Iter: 1726 loss: 3.61220941e-07
Iter: 1727 loss: 3.61060131e-07
Iter: 1728 loss: 3.61702917e-07
Iter: 1729 loss: 3.61031937e-07
Iter: 1730 loss: 3.609168e-07
Iter: 1731 loss: 3.60922172e-07
Iter: 1732 loss: 3.60825197e-07
Iter: 1733 loss: 3.6070719e-07
Iter: 1734 loss: 3.60662341e-07
Iter: 1735 loss: 3.60636193e-07
Iter: 1736 loss: 3.60632299e-07
Iter: 1737 loss: 3.60587819e-07
Iter: 1738 loss: 3.60433802e-07
Iter: 1739 loss: 3.60448382e-07
Iter: 1740 loss: 3.60342199e-07
Iter: 1741 loss: 3.60627155e-07
Iter: 1742 loss: 3.6028689e-07
Iter: 1743 loss: 3.6018605e-07
Iter: 1744 loss: 3.60209725e-07
Iter: 1745 loss: 3.6008845e-07
Iter: 1746 loss: 3.59929402e-07
Iter: 1747 loss: 3.60031805e-07
Iter: 1748 loss: 3.59813413e-07
Iter: 1749 loss: 3.59637113e-07
Iter: 1750 loss: 3.61600627e-07
Iter: 1751 loss: 3.59658912e-07
Iter: 1752 loss: 3.59494095e-07
Iter: 1753 loss: 3.59359916e-07
Iter: 1754 loss: 3.59359e-07
Iter: 1755 loss: 3.59089967e-07
Iter: 1756 loss: 3.61203291e-07
Iter: 1757 loss: 3.59097726e-07
Iter: 1758 loss: 3.58956555e-07
Iter: 1759 loss: 3.59046339e-07
Iter: 1760 loss: 3.58837724e-07
Iter: 1761 loss: 3.58671912e-07
Iter: 1762 loss: 3.58890901e-07
Iter: 1763 loss: 3.58576727e-07
Iter: 1764 loss: 3.58390764e-07
Iter: 1765 loss: 3.58529e-07
Iter: 1766 loss: 3.5833088e-07
Iter: 1767 loss: 3.58079774e-07
Iter: 1768 loss: 3.58697122e-07
Iter: 1769 loss: 3.58028529e-07
Iter: 1770 loss: 3.58108394e-07
Iter: 1771 loss: 3.57938e-07
Iter: 1772 loss: 3.57871556e-07
Iter: 1773 loss: 3.57750253e-07
Iter: 1774 loss: 3.59501115e-07
Iter: 1775 loss: 3.57747979e-07
Iter: 1776 loss: 3.57582508e-07
Iter: 1777 loss: 3.58029411e-07
Iter: 1778 loss: 3.57498806e-07
Iter: 1779 loss: 3.57355589e-07
Iter: 1780 loss: 3.57983481e-07
Iter: 1781 loss: 3.57326826e-07
Iter: 1782 loss: 3.57229e-07
Iter: 1783 loss: 3.5705375e-07
Iter: 1784 loss: 3.57045252e-07
Iter: 1785 loss: 3.56820919e-07
Iter: 1786 loss: 3.58414553e-07
Iter: 1787 loss: 3.56830554e-07
Iter: 1788 loss: 3.56667158e-07
Iter: 1789 loss: 3.56709165e-07
Iter: 1790 loss: 3.5657331e-07
Iter: 1791 loss: 3.56340166e-07
Iter: 1792 loss: 3.57053722e-07
Iter: 1793 loss: 3.56238957e-07
Iter: 1794 loss: 3.56095285e-07
Iter: 1795 loss: 3.56532553e-07
Iter: 1796 loss: 3.56020337e-07
Iter: 1797 loss: 3.55869787e-07
Iter: 1798 loss: 3.56608638e-07
Iter: 1799 loss: 3.55809647e-07
Iter: 1800 loss: 3.5572873e-07
Iter: 1801 loss: 3.5576511e-07
Iter: 1802 loss: 3.55620557e-07
Iter: 1803 loss: 3.55461935e-07
Iter: 1804 loss: 3.56647263e-07
Iter: 1805 loss: 3.55418479e-07
Iter: 1806 loss: 3.55295612e-07
Iter: 1807 loss: 3.56315184e-07
Iter: 1808 loss: 3.55296606e-07
Iter: 1809 loss: 3.5521407e-07
Iter: 1810 loss: 3.55184767e-07
Iter: 1811 loss: 3.55168424e-07
Iter: 1812 loss: 3.55070711e-07
Iter: 1813 loss: 3.5506946e-07
Iter: 1814 loss: 3.5498681e-07
Iter: 1815 loss: 3.54865e-07
Iter: 1816 loss: 3.5549445e-07
Iter: 1817 loss: 3.5484905e-07
Iter: 1818 loss: 3.54733629e-07
Iter: 1819 loss: 3.54869911e-07
Iter: 1820 loss: 3.54724023e-07
Iter: 1821 loss: 3.54577281e-07
Iter: 1822 loss: 3.54515578e-07
Iter: 1823 loss: 3.54456745e-07
Iter: 1824 loss: 3.5432916e-07
Iter: 1825 loss: 3.54339363e-07
Iter: 1826 loss: 3.54199813e-07
Iter: 1827 loss: 3.54049348e-07
Iter: 1828 loss: 3.54067794e-07
Iter: 1829 loss: 3.53872167e-07
Iter: 1830 loss: 3.5555118e-07
Iter: 1831 loss: 3.53916931e-07
Iter: 1832 loss: 3.53772236e-07
Iter: 1833 loss: 3.53764392e-07
Iter: 1834 loss: 3.53678445e-07
Iter: 1835 loss: 3.53536848e-07
Iter: 1836 loss: 3.54884918e-07
Iter: 1837 loss: 3.53543925e-07
Iter: 1838 loss: 3.53519624e-07
Iter: 1839 loss: 3.53525593e-07
Iter: 1840 loss: 3.53451327e-07
Iter: 1841 loss: 3.53391044e-07
Iter: 1842 loss: 3.53403493e-07
Iter: 1843 loss: 3.53311918e-07
Iter: 1844 loss: 3.53339544e-07
Iter: 1845 loss: 3.5330504e-07
Iter: 1846 loss: 3.53186692e-07
Iter: 1847 loss: 3.53852158e-07
Iter: 1848 loss: 3.5318115e-07
Iter: 1849 loss: 3.53116349e-07
Iter: 1850 loss: 3.53032362e-07
Iter: 1851 loss: 3.53054418e-07
Iter: 1852 loss: 3.52935785e-07
Iter: 1853 loss: 3.53114842e-07
Iter: 1854 loss: 3.52875759e-07
Iter: 1855 loss: 3.52755819e-07
Iter: 1856 loss: 3.52985893e-07
Iter: 1857 loss: 3.52693377e-07
Iter: 1858 loss: 3.52539701e-07
Iter: 1859 loss: 3.5317521e-07
Iter: 1860 loss: 3.52510625e-07
Iter: 1861 loss: 3.52457221e-07
Iter: 1862 loss: 3.52844211e-07
Iter: 1863 loss: 3.52402424e-07
Iter: 1864 loss: 3.5231119e-07
Iter: 1865 loss: 3.52208019e-07
Iter: 1866 loss: 3.52171611e-07
Iter: 1867 loss: 3.52137448e-07
Iter: 1868 loss: 3.52110732e-07
Iter: 1869 loss: 3.52078871e-07
Iter: 1870 loss: 3.52803369e-07
Iter: 1871 loss: 3.52046555e-07
Iter: 1872 loss: 3.51996562e-07
Iter: 1873 loss: 3.51898507e-07
Iter: 1874 loss: 3.51900326e-07
Iter: 1875 loss: 3.5182552e-07
Iter: 1876 loss: 3.52167e-07
Iter: 1877 loss: 3.518021e-07
Iter: 1878 loss: 3.51748838e-07
Iter: 1879 loss: 3.51834814e-07
Iter: 1880 loss: 3.51687561e-07
Iter: 1881 loss: 3.51594451e-07
Iter: 1882 loss: 3.51696173e-07
Iter: 1883 loss: 3.51533458e-07
Iter: 1884 loss: 3.51448591e-07
Iter: 1885 loss: 3.51858773e-07
Iter: 1886 loss: 3.51456208e-07
Iter: 1887 loss: 3.51370602e-07
Iter: 1888 loss: 3.51317e-07
Iter: 1889 loss: 3.51327344e-07
Iter: 1890 loss: 3.51211213e-07
Iter: 1891 loss: 3.51912661e-07
Iter: 1892 loss: 3.51189726e-07
Iter: 1893 loss: 3.51142035e-07
Iter: 1894 loss: 3.51321063e-07
Iter: 1895 loss: 3.51120207e-07
Iter: 1896 loss: 3.50998562e-07
Iter: 1897 loss: 3.51086e-07
Iter: 1898 loss: 3.50964e-07
Iter: 1899 loss: 3.50886495e-07
Iter: 1900 loss: 3.5143961e-07
Iter: 1901 loss: 3.5087524e-07
Iter: 1902 loss: 3.50784262e-07
Iter: 1903 loss: 3.51403912e-07
Iter: 1904 loss: 3.507906e-07
Iter: 1905 loss: 3.5071929e-07
Iter: 1906 loss: 3.50777697e-07
Iter: 1907 loss: 3.50693483e-07
Iter: 1908 loss: 3.50640789e-07
Iter: 1909 loss: 3.50823143e-07
Iter: 1910 loss: 3.50619842e-07
Iter: 1911 loss: 3.5054407e-07
Iter: 1912 loss: 3.50604125e-07
Iter: 1913 loss: 3.50533952e-07
Iter: 1914 loss: 3.50447976e-07
Iter: 1915 loss: 3.50450449e-07
Iter: 1916 loss: 3.50401365e-07
Iter: 1917 loss: 3.50270881e-07
Iter: 1918 loss: 3.50761866e-07
Iter: 1919 loss: 3.50298876e-07
Iter: 1920 loss: 3.50183853e-07
Iter: 1921 loss: 3.50187e-07
Iter: 1922 loss: 3.50144717e-07
Iter: 1923 loss: 3.50026e-07
Iter: 1924 loss: 3.50302372e-07
Iter: 1925 loss: 3.49974755e-07
Iter: 1926 loss: 3.49927888e-07
Iter: 1927 loss: 3.50739754e-07
Iter: 1928 loss: 3.49910465e-07
Iter: 1929 loss: 3.49806413e-07
Iter: 1930 loss: 3.49824091e-07
Iter: 1931 loss: 3.49779725e-07
Iter: 1932 loss: 3.49705317e-07
Iter: 1933 loss: 3.50159212e-07
Iter: 1934 loss: 3.49697331e-07
Iter: 1935 loss: 3.49630227e-07
Iter: 1936 loss: 3.5013278e-07
Iter: 1937 loss: 3.49665697e-07
Iter: 1938 loss: 3.49618745e-07
Iter: 1939 loss: 3.49624031e-07
Iter: 1940 loss: 3.4954121e-07
Iter: 1941 loss: 3.49527426e-07
Iter: 1942 loss: 3.49603908e-07
Iter: 1943 loss: 3.49491813e-07
Iter: 1944 loss: 3.49451824e-07
Iter: 1945 loss: 3.49565767e-07
Iter: 1946 loss: 3.49450318e-07
Iter: 1947 loss: 3.49382475e-07
Iter: 1948 loss: 3.4949673e-07
Iter: 1949 loss: 3.49376734e-07
Iter: 1950 loss: 3.49298659e-07
Iter: 1951 loss: 3.49569433e-07
Iter: 1952 loss: 3.49272142e-07
Iter: 1953 loss: 3.49220016e-07
Iter: 1954 loss: 3.49153879e-07
Iter: 1955 loss: 3.49169682e-07
Iter: 1956 loss: 3.49092602e-07
Iter: 1957 loss: 3.49960601e-07
Iter: 1958 loss: 3.49062248e-07
Iter: 1959 loss: 3.49047639e-07
Iter: 1960 loss: 3.4903394e-07
Iter: 1961 loss: 3.48980393e-07
Iter: 1962 loss: 3.48941398e-07
Iter: 1963 loss: 3.49435936e-07
Iter: 1964 loss: 3.48894901e-07
Iter: 1965 loss: 3.48863409e-07
Iter: 1966 loss: 3.48868213e-07
Iter: 1967 loss: 3.4879497e-07
Iter: 1968 loss: 3.48769561e-07
Iter: 1969 loss: 3.48954501e-07
Iter: 1970 loss: 3.48720789e-07
Iter: 1971 loss: 3.48676195e-07
Iter: 1972 loss: 3.48649365e-07
Iter: 1973 loss: 3.48627907e-07
Iter: 1974 loss: 3.48598519e-07
Iter: 1975 loss: 3.49582081e-07
Iter: 1976 loss: 3.48565038e-07
Iter: 1977 loss: 3.4853673e-07
Iter: 1978 loss: 3.48574986e-07
Iter: 1979 loss: 3.48462038e-07
Iter: 1980 loss: 3.48428529e-07
Iter: 1981 loss: 3.48749154e-07
Iter: 1982 loss: 3.484015e-07
Iter: 1983 loss: 3.48332549e-07
Iter: 1984 loss: 3.48393826e-07
Iter: 1985 loss: 3.48316775e-07
Iter: 1986 loss: 3.48217981e-07
Iter: 1987 loss: 3.48301199e-07
Iter: 1988 loss: 3.48186916e-07
Iter: 1989 loss: 3.48105033e-07
Iter: 1990 loss: 3.4847892e-07
Iter: 1991 loss: 3.4807789e-07
Iter: 1992 loss: 3.4800064e-07
Iter: 1993 loss: 3.48055693e-07
Iter: 1994 loss: 3.47951072e-07
Iter: 1995 loss: 3.47832383e-07
Iter: 1996 loss: 3.48871112e-07
Iter: 1997 loss: 3.47818627e-07
Iter: 1998 loss: 3.47808e-07
Iter: 1999 loss: 3.47812289e-07
Iter: 2000 loss: 3.47754963e-07
Iter: 2001 loss: 3.47717332e-07
Iter: 2002 loss: 3.47970087e-07
Iter: 2003 loss: 3.47670237e-07
Iter: 2004 loss: 3.47680924e-07
Iter: 2005 loss: 3.47647472e-07
Iter: 2006 loss: 3.47668163e-07
Iter: 2007 loss: 3.47653554e-07
Iter: 2008 loss: 3.47653327e-07
Iter: 2009 loss: 3.47629538e-07
Iter: 2010 loss: 3.47636956e-07
Iter: 2011 loss: 3.476394e-07
Iter: 2012 loss: 3.47635904e-07
Iter: 2013 loss: 3.47645482e-07
Iter: 2014 loss: 3.47613224e-07
Iter: 2015 loss: 3.47633517e-07
Iter: 2016 loss: 3.47639741e-07
Iter: 2017 loss: 3.47630277e-07
Iter: 2018 loss: 3.47651223e-07
Iter: 2019 loss: 3.47641503e-07
Iter: 2020 loss: 3.47644402e-07
Iter: 2021 loss: 3.47651508e-07
Iter: 2022 loss: 3.4764372e-07
Iter: 2023 loss: 3.47648154e-07
Iter: 2024 loss: 3.47645084e-07
Iter: 2025 loss: 3.47647131e-07
Iter: 2026 loss: 3.47647131e-07
Iter: 2027 loss: 3.47647472e-07
Iter: 2028 loss: 3.47647983e-07
Iter: 2029 loss: 3.47647983e-07
Iter: 2030 loss: 3.47647983e-07
Iter: 2031 loss: 3.47647983e-07
Iter: 2032 loss: 3.47647472e-07
Iter: 2033 loss: 3.47647983e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_4000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 3 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_4000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4884c7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff48848f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4883ff9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4884978c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff48851fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4883ff510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4883a7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff488374048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff488374488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff48830b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff48830b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff48831d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff48831dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4882a21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4882897b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff488255950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff488265f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff482443ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff482444d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4824432f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4824226a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff482435268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff482422f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff482380f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff482380ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff482368ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4822fdd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4823682f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff48233b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4822e20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4822ee400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4822a20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4822a27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff482291ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4822121e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff482231f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.43411648e-06
Iter: 2 loss: 3.2822461e-06
Iter: 3 loss: 2.72812986e-06
Iter: 4 loss: 2.28314093e-06
Iter: 5 loss: 3.04837204e-06
Iter: 6 loss: 2.08524716e-06
Iter: 7 loss: 1.91879735e-06
Iter: 8 loss: 1.65694007e-06
Iter: 9 loss: 1.65405049e-06
Iter: 10 loss: 1.5440479e-06
Iter: 11 loss: 1.50986887e-06
Iter: 12 loss: 1.46724096e-06
Iter: 13 loss: 1.51252584e-06
Iter: 14 loss: 1.44392072e-06
Iter: 15 loss: 1.39264318e-06
Iter: 16 loss: 1.36274571e-06
Iter: 17 loss: 1.34111133e-06
Iter: 18 loss: 1.29593923e-06
Iter: 19 loss: 1.97261534e-06
Iter: 20 loss: 1.29586317e-06
Iter: 21 loss: 1.25920974e-06
Iter: 22 loss: 1.28640454e-06
Iter: 23 loss: 1.23669906e-06
Iter: 24 loss: 1.22381414e-06
Iter: 25 loss: 1.22126926e-06
Iter: 26 loss: 1.21121889e-06
Iter: 27 loss: 1.19292258e-06
Iter: 28 loss: 1.6276889e-06
Iter: 29 loss: 1.19293645e-06
Iter: 30 loss: 1.16946671e-06
Iter: 31 loss: 1.30708725e-06
Iter: 32 loss: 1.16655087e-06
Iter: 33 loss: 1.15347473e-06
Iter: 34 loss: 1.13994724e-06
Iter: 35 loss: 1.13747694e-06
Iter: 36 loss: 1.11407076e-06
Iter: 37 loss: 1.37109976e-06
Iter: 38 loss: 1.11354291e-06
Iter: 39 loss: 1.1133543e-06
Iter: 40 loss: 1.10940323e-06
Iter: 41 loss: 1.10466829e-06
Iter: 42 loss: 1.09086341e-06
Iter: 43 loss: 1.15444504e-06
Iter: 44 loss: 1.08594418e-06
Iter: 45 loss: 1.07429469e-06
Iter: 46 loss: 1.15204193e-06
Iter: 47 loss: 1.07306516e-06
Iter: 48 loss: 1.06356674e-06
Iter: 49 loss: 1.0550159e-06
Iter: 50 loss: 1.05263621e-06
Iter: 51 loss: 1.05349977e-06
Iter: 52 loss: 1.04705077e-06
Iter: 53 loss: 1.0438556e-06
Iter: 54 loss: 1.04122944e-06
Iter: 55 loss: 1.04026833e-06
Iter: 56 loss: 1.03507466e-06
Iter: 57 loss: 1.04454421e-06
Iter: 58 loss: 1.03278217e-06
Iter: 59 loss: 1.02898082e-06
Iter: 60 loss: 1.04014191e-06
Iter: 61 loss: 1.02783827e-06
Iter: 62 loss: 1.02181889e-06
Iter: 63 loss: 1.02022705e-06
Iter: 64 loss: 1.01645537e-06
Iter: 65 loss: 1.01138085e-06
Iter: 66 loss: 1.02664239e-06
Iter: 67 loss: 1.00985892e-06
Iter: 68 loss: 1.00314151e-06
Iter: 69 loss: 1.02090075e-06
Iter: 70 loss: 1.0008406e-06
Iter: 71 loss: 9.96709332e-07
Iter: 72 loss: 1.05710023e-06
Iter: 73 loss: 9.96771178e-07
Iter: 74 loss: 9.93231424e-07
Iter: 75 loss: 9.95115215e-07
Iter: 76 loss: 9.90939384e-07
Iter: 77 loss: 9.86772534e-07
Iter: 78 loss: 9.867681e-07
Iter: 79 loss: 9.85239694e-07
Iter: 80 loss: 9.82699817e-07
Iter: 81 loss: 9.82667302e-07
Iter: 82 loss: 9.7985e-07
Iter: 83 loss: 9.7469615e-07
Iter: 84 loss: 9.74683417e-07
Iter: 85 loss: 9.70982228e-07
Iter: 86 loss: 9.70975e-07
Iter: 87 loss: 9.67364144e-07
Iter: 88 loss: 9.69923803e-07
Iter: 89 loss: 9.65176469e-07
Iter: 90 loss: 9.62680588e-07
Iter: 91 loss: 9.62459808e-07
Iter: 92 loss: 9.61083742e-07
Iter: 93 loss: 9.57228167e-07
Iter: 94 loss: 9.77596414e-07
Iter: 95 loss: 9.56002e-07
Iter: 96 loss: 9.53254698e-07
Iter: 97 loss: 9.52979e-07
Iter: 98 loss: 9.505751e-07
Iter: 99 loss: 9.50592835e-07
Iter: 100 loss: 9.48693696e-07
Iter: 101 loss: 9.46278078e-07
Iter: 102 loss: 9.73660917e-07
Iter: 103 loss: 9.46255227e-07
Iter: 104 loss: 9.44614897e-07
Iter: 105 loss: 9.427701e-07
Iter: 106 loss: 9.42534939e-07
Iter: 107 loss: 9.39907125e-07
Iter: 108 loss: 9.6839392e-07
Iter: 109 loss: 9.39805e-07
Iter: 110 loss: 9.38321193e-07
Iter: 111 loss: 9.51991808e-07
Iter: 112 loss: 9.38241612e-07
Iter: 113 loss: 9.36601623e-07
Iter: 114 loss: 9.4115552e-07
Iter: 115 loss: 9.36131414e-07
Iter: 116 loss: 9.34475509e-07
Iter: 117 loss: 9.33056128e-07
Iter: 118 loss: 9.32598766e-07
Iter: 119 loss: 9.30995839e-07
Iter: 120 loss: 9.29647967e-07
Iter: 121 loss: 9.29198904e-07
Iter: 122 loss: 9.26121629e-07
Iter: 123 loss: 9.40098175e-07
Iter: 124 loss: 9.25529775e-07
Iter: 125 loss: 9.23722e-07
Iter: 126 loss: 9.30211058e-07
Iter: 127 loss: 9.23270704e-07
Iter: 128 loss: 9.20684499e-07
Iter: 129 loss: 9.26132032e-07
Iter: 130 loss: 9.19686727e-07
Iter: 131 loss: 9.17944931e-07
Iter: 132 loss: 9.25089751e-07
Iter: 133 loss: 9.17550324e-07
Iter: 134 loss: 9.16022714e-07
Iter: 135 loss: 9.13290194e-07
Iter: 136 loss: 9.74563818e-07
Iter: 137 loss: 9.13285191e-07
Iter: 138 loss: 9.1141419e-07
Iter: 139 loss: 9.11352231e-07
Iter: 140 loss: 9.09711503e-07
Iter: 141 loss: 9.09122207e-07
Iter: 142 loss: 9.0822175e-07
Iter: 143 loss: 9.07135416e-07
Iter: 144 loss: 9.07165372e-07
Iter: 145 loss: 9.06092851e-07
Iter: 146 loss: 9.09111407e-07
Iter: 147 loss: 9.05801585e-07
Iter: 148 loss: 9.0486003e-07
Iter: 149 loss: 9.04863441e-07
Iter: 150 loss: 9.04589115e-07
Iter: 151 loss: 9.03661e-07
Iter: 152 loss: 9.10781523e-07
Iter: 153 loss: 9.035424e-07
Iter: 154 loss: 9.0213706e-07
Iter: 155 loss: 9.00573639e-07
Iter: 156 loss: 9.00418172e-07
Iter: 157 loss: 8.99123734e-07
Iter: 158 loss: 8.99119243e-07
Iter: 159 loss: 8.97804341e-07
Iter: 160 loss: 8.98803592e-07
Iter: 161 loss: 8.97038433e-07
Iter: 162 loss: 8.95670951e-07
Iter: 163 loss: 9.05510319e-07
Iter: 164 loss: 8.95591313e-07
Iter: 165 loss: 8.9475e-07
Iter: 166 loss: 8.92806725e-07
Iter: 167 loss: 9.207277e-07
Iter: 168 loss: 8.92686103e-07
Iter: 169 loss: 8.91823504e-07
Iter: 170 loss: 8.91442596e-07
Iter: 171 loss: 8.90674528e-07
Iter: 172 loss: 8.91896548e-07
Iter: 173 loss: 8.90245417e-07
Iter: 174 loss: 8.89175453e-07
Iter: 175 loss: 8.87579063e-07
Iter: 176 loss: 8.87530803e-07
Iter: 177 loss: 8.86059127e-07
Iter: 178 loss: 8.88229295e-07
Iter: 179 loss: 8.85389341e-07
Iter: 180 loss: 8.83781922e-07
Iter: 181 loss: 9.02481759e-07
Iter: 182 loss: 8.83714279e-07
Iter: 183 loss: 8.83706264e-07
Iter: 184 loss: 8.83334735e-07
Iter: 185 loss: 8.82969744e-07
Iter: 186 loss: 8.81700714e-07
Iter: 187 loss: 8.82807342e-07
Iter: 188 loss: 8.80587947e-07
Iter: 189 loss: 8.79248717e-07
Iter: 190 loss: 8.9264995e-07
Iter: 191 loss: 8.79227969e-07
Iter: 192 loss: 8.7802033e-07
Iter: 193 loss: 8.76737545e-07
Iter: 194 loss: 8.76623915e-07
Iter: 195 loss: 8.7542162e-07
Iter: 196 loss: 8.75403771e-07
Iter: 197 loss: 8.74281e-07
Iter: 198 loss: 8.75396836e-07
Iter: 199 loss: 8.73680392e-07
Iter: 200 loss: 8.72145961e-07
Iter: 201 loss: 8.7842e-07
Iter: 202 loss: 8.71909606e-07
Iter: 203 loss: 8.70887845e-07
Iter: 204 loss: 8.71632e-07
Iter: 205 loss: 8.70360793e-07
Iter: 206 loss: 8.69118423e-07
Iter: 207 loss: 8.77879245e-07
Iter: 208 loss: 8.69001667e-07
Iter: 209 loss: 8.68320114e-07
Iter: 210 loss: 8.72278406e-07
Iter: 211 loss: 8.68326367e-07
Iter: 212 loss: 8.67673464e-07
Iter: 213 loss: 8.66530286e-07
Iter: 214 loss: 8.92578157e-07
Iter: 215 loss: 8.66495384e-07
Iter: 216 loss: 8.65455377e-07
Iter: 217 loss: 8.7908893e-07
Iter: 218 loss: 8.65455149e-07
Iter: 219 loss: 8.64728634e-07
Iter: 220 loss: 8.63844377e-07
Iter: 221 loss: 8.63791797e-07
Iter: 222 loss: 8.63863363e-07
Iter: 223 loss: 8.63291689e-07
Iter: 224 loss: 8.62829609e-07
Iter: 225 loss: 8.64022809e-07
Iter: 226 loss: 8.62693469e-07
Iter: 227 loss: 8.62346837e-07
Iter: 228 loss: 8.61423644e-07
Iter: 229 loss: 8.65805077e-07
Iter: 230 loss: 8.61115552e-07
Iter: 231 loss: 8.60102489e-07
Iter: 232 loss: 8.64107392e-07
Iter: 233 loss: 8.59892793e-07
Iter: 234 loss: 8.58549583e-07
Iter: 235 loss: 8.60479417e-07
Iter: 236 loss: 8.57867235e-07
Iter: 237 loss: 8.57007421e-07
Iter: 238 loss: 8.62070237e-07
Iter: 239 loss: 8.56859685e-07
Iter: 240 loss: 8.55906194e-07
Iter: 241 loss: 8.58194426e-07
Iter: 242 loss: 8.55525343e-07
Iter: 243 loss: 8.54920188e-07
Iter: 244 loss: 8.5493167e-07
Iter: 245 loss: 8.54626251e-07
Iter: 246 loss: 8.53688334e-07
Iter: 247 loss: 8.62218883e-07
Iter: 248 loss: 8.53624783e-07
Iter: 249 loss: 8.52881101e-07
Iter: 250 loss: 8.52862968e-07
Iter: 251 loss: 8.52359278e-07
Iter: 252 loss: 8.52512244e-07
Iter: 253 loss: 8.51925336e-07
Iter: 254 loss: 8.51190634e-07
Iter: 255 loss: 8.53163783e-07
Iter: 256 loss: 8.50946435e-07
Iter: 257 loss: 8.50515619e-07
Iter: 258 loss: 8.56166139e-07
Iter: 259 loss: 8.50544097e-07
Iter: 260 loss: 8.50150172e-07
Iter: 261 loss: 8.50741685e-07
Iter: 262 loss: 8.49911714e-07
Iter: 263 loss: 8.49494256e-07
Iter: 264 loss: 8.48470165e-07
Iter: 265 loss: 8.60505e-07
Iter: 266 loss: 8.48413265e-07
Iter: 267 loss: 8.4760029e-07
Iter: 268 loss: 8.52043797e-07
Iter: 269 loss: 8.47466765e-07
Iter: 270 loss: 8.46554e-07
Iter: 271 loss: 8.47176182e-07
Iter: 272 loss: 8.4600066e-07
Iter: 273 loss: 8.45269767e-07
Iter: 274 loss: 8.47112176e-07
Iter: 275 loss: 8.45008572e-07
Iter: 276 loss: 8.44211627e-07
Iter: 277 loss: 8.50375955e-07
Iter: 278 loss: 8.44132103e-07
Iter: 279 loss: 8.43661439e-07
Iter: 280 loss: 8.45965303e-07
Iter: 281 loss: 8.43572593e-07
Iter: 282 loss: 8.42934071e-07
Iter: 283 loss: 8.42160546e-07
Iter: 284 loss: 8.42074712e-07
Iter: 285 loss: 8.4159592e-07
Iter: 286 loss: 8.41571364e-07
Iter: 287 loss: 8.41092856e-07
Iter: 288 loss: 8.40383109e-07
Iter: 289 loss: 8.40325129e-07
Iter: 290 loss: 8.39838151e-07
Iter: 291 loss: 8.39806773e-07
Iter: 292 loss: 8.39565473e-07
Iter: 293 loss: 8.41628889e-07
Iter: 294 loss: 8.3952051e-07
Iter: 295 loss: 8.39318e-07
Iter: 296 loss: 8.38795472e-07
Iter: 297 loss: 8.46688465e-07
Iter: 298 loss: 8.38840151e-07
Iter: 299 loss: 8.38102835e-07
Iter: 300 loss: 8.3815678e-07
Iter: 301 loss: 8.37600282e-07
Iter: 302 loss: 8.36982167e-07
Iter: 303 loss: 8.38757501e-07
Iter: 304 loss: 8.36806407e-07
Iter: 305 loss: 8.36088589e-07
Iter: 306 loss: 8.39149379e-07
Iter: 307 loss: 8.35954324e-07
Iter: 308 loss: 8.35495143e-07
Iter: 309 loss: 8.35177502e-07
Iter: 310 loss: 8.35014589e-07
Iter: 311 loss: 8.34299499e-07
Iter: 312 loss: 8.44808937e-07
Iter: 313 loss: 8.34280911e-07
Iter: 314 loss: 8.33863112e-07
Iter: 315 loss: 8.35853598e-07
Iter: 316 loss: 8.33808826e-07
Iter: 317 loss: 8.33322702e-07
Iter: 318 loss: 8.32399e-07
Iter: 319 loss: 8.54286668e-07
Iter: 320 loss: 8.32380124e-07
Iter: 321 loss: 8.31953059e-07
Iter: 322 loss: 8.31868249e-07
Iter: 323 loss: 8.31436353e-07
Iter: 324 loss: 8.31020202e-07
Iter: 325 loss: 8.30890258e-07
Iter: 326 loss: 8.30505655e-07
Iter: 327 loss: 8.30448641e-07
Iter: 328 loss: 8.30125259e-07
Iter: 329 loss: 8.3013208e-07
Iter: 330 loss: 8.29900955e-07
Iter: 331 loss: 8.29590192e-07
Iter: 332 loss: 8.29010105e-07
Iter: 333 loss: 8.428662e-07
Iter: 334 loss: 8.28995667e-07
Iter: 335 loss: 8.28233397e-07
Iter: 336 loss: 8.31877969e-07
Iter: 337 loss: 8.28108966e-07
Iter: 338 loss: 8.27492215e-07
Iter: 339 loss: 8.27044232e-07
Iter: 340 loss: 8.26838857e-07
Iter: 341 loss: 8.26217843e-07
Iter: 342 loss: 8.26205678e-07
Iter: 343 loss: 8.25831819e-07
Iter: 344 loss: 8.25296581e-07
Iter: 345 loss: 8.25297263e-07
Iter: 346 loss: 8.24633389e-07
Iter: 347 loss: 8.34124421e-07
Iter: 348 loss: 8.24580752e-07
Iter: 349 loss: 8.2413419e-07
Iter: 350 loss: 8.2432723e-07
Iter: 351 loss: 8.23782329e-07
Iter: 352 loss: 8.23084292e-07
Iter: 353 loss: 8.23699679e-07
Iter: 354 loss: 8.22762445e-07
Iter: 355 loss: 8.2213495e-07
Iter: 356 loss: 8.21800086e-07
Iter: 357 loss: 8.21604829e-07
Iter: 358 loss: 8.20779633e-07
Iter: 359 loss: 8.20800608e-07
Iter: 360 loss: 8.20383661e-07
Iter: 361 loss: 8.26058567e-07
Iter: 362 loss: 8.20399407e-07
Iter: 363 loss: 8.19888e-07
Iter: 364 loss: 8.19719673e-07
Iter: 365 loss: 8.19517368e-07
Iter: 366 loss: 8.19131401e-07
Iter: 367 loss: 8.20296805e-07
Iter: 368 loss: 8.18981789e-07
Iter: 369 loss: 8.1874515e-07
Iter: 370 loss: 8.18941658e-07
Iter: 371 loss: 8.18574e-07
Iter: 372 loss: 8.18130275e-07
Iter: 373 loss: 8.19032039e-07
Iter: 374 loss: 8.17998512e-07
Iter: 375 loss: 8.17578496e-07
Iter: 376 loss: 8.19075694e-07
Iter: 377 loss: 8.17454634e-07
Iter: 378 loss: 8.16997215e-07
Iter: 379 loss: 8.16348916e-07
Iter: 380 loss: 8.16375859e-07
Iter: 381 loss: 8.15658666e-07
Iter: 382 loss: 8.20306923e-07
Iter: 383 loss: 8.15620069e-07
Iter: 384 loss: 8.1494386e-07
Iter: 385 loss: 8.15754788e-07
Iter: 386 loss: 8.14574435e-07
Iter: 387 loss: 8.14083876e-07
Iter: 388 loss: 8.1405e-07
Iter: 389 loss: 8.13723545e-07
Iter: 390 loss: 8.13110319e-07
Iter: 391 loss: 8.13125041e-07
Iter: 392 loss: 8.12347878e-07
Iter: 393 loss: 8.17282853e-07
Iter: 394 loss: 8.12301096e-07
Iter: 395 loss: 8.11827e-07
Iter: 396 loss: 8.11864652e-07
Iter: 397 loss: 8.11372388e-07
Iter: 398 loss: 8.1153496e-07
Iter: 399 loss: 8.1101058e-07
Iter: 400 loss: 8.10857728e-07
Iter: 401 loss: 8.10589e-07
Iter: 402 loss: 8.16592603e-07
Iter: 403 loss: 8.10548102e-07
Iter: 404 loss: 8.10216534e-07
Iter: 405 loss: 8.09583128e-07
Iter: 406 loss: 8.22726861e-07
Iter: 407 loss: 8.09593928e-07
Iter: 408 loss: 8.09336029e-07
Iter: 409 loss: 8.0925912e-07
Iter: 410 loss: 8.08920277e-07
Iter: 411 loss: 8.08679317e-07
Iter: 412 loss: 8.08583422e-07
Iter: 413 loss: 8.08080131e-07
Iter: 414 loss: 8.10466759e-07
Iter: 415 loss: 8.08043183e-07
Iter: 416 loss: 8.07628737e-07
Iter: 417 loss: 8.08181539e-07
Iter: 418 loss: 8.07438312e-07
Iter: 419 loss: 8.06987259e-07
Iter: 420 loss: 8.07047968e-07
Iter: 421 loss: 8.06528931e-07
Iter: 422 loss: 8.06019727e-07
Iter: 423 loss: 8.09978474e-07
Iter: 424 loss: 8.05954414e-07
Iter: 425 loss: 8.05310947e-07
Iter: 426 loss: 8.04601768e-07
Iter: 427 loss: 8.04538217e-07
Iter: 428 loss: 8.039367e-07
Iter: 429 loss: 8.1355256e-07
Iter: 430 loss: 8.03888952e-07
Iter: 431 loss: 8.03450689e-07
Iter: 432 loss: 8.02711213e-07
Iter: 433 loss: 8.02723321e-07
Iter: 434 loss: 8.04405545e-07
Iter: 435 loss: 8.02514251e-07
Iter: 436 loss: 8.02383738e-07
Iter: 437 loss: 8.0225584e-07
Iter: 438 loss: 8.06129492e-07
Iter: 439 loss: 8.02230716e-07
Iter: 440 loss: 8.01950137e-07
Iter: 441 loss: 8.01515966e-07
Iter: 442 loss: 8.01544388e-07
Iter: 443 loss: 8.01195654e-07
Iter: 444 loss: 8.01155e-07
Iter: 445 loss: 8.0085789e-07
Iter: 446 loss: 8.01101e-07
Iter: 447 loss: 8.00721807e-07
Iter: 448 loss: 8.00212263e-07
Iter: 449 loss: 8.00169119e-07
Iter: 450 loss: 7.9990582e-07
Iter: 451 loss: 7.99455563e-07
Iter: 452 loss: 8.02730483e-07
Iter: 453 loss: 7.99388e-07
Iter: 454 loss: 7.98943688e-07
Iter: 455 loss: 7.98053861e-07
Iter: 456 loss: 7.98056362e-07
Iter: 457 loss: 7.97479117e-07
Iter: 458 loss: 7.97410735e-07
Iter: 459 loss: 7.96969744e-07
Iter: 460 loss: 7.95950427e-07
Iter: 461 loss: 8.06963556e-07
Iter: 462 loss: 7.95871e-07
Iter: 463 loss: 7.95161e-07
Iter: 464 loss: 7.95125e-07
Iter: 465 loss: 7.94736e-07
Iter: 466 loss: 7.96169559e-07
Iter: 467 loss: 7.94666789e-07
Iter: 468 loss: 7.94083917e-07
Iter: 469 loss: 7.97310747e-07
Iter: 470 loss: 7.94084883e-07
Iter: 471 loss: 7.93883373e-07
Iter: 472 loss: 7.93499282e-07
Iter: 473 loss: 7.93520712e-07
Iter: 474 loss: 7.93137247e-07
Iter: 475 loss: 7.9299241e-07
Iter: 476 loss: 7.9278044e-07
Iter: 477 loss: 7.92138962e-07
Iter: 478 loss: 7.97110204e-07
Iter: 479 loss: 7.92126116e-07
Iter: 480 loss: 7.91763341e-07
Iter: 481 loss: 7.92102298e-07
Iter: 482 loss: 7.91526872e-07
Iter: 483 loss: 7.91072239e-07
Iter: 484 loss: 7.91674893e-07
Iter: 485 loss: 7.90767e-07
Iter: 486 loss: 7.90350782e-07
Iter: 487 loss: 7.94613356e-07
Iter: 488 loss: 7.90317927e-07
Iter: 489 loss: 7.90030754e-07
Iter: 490 loss: 7.89502792e-07
Iter: 491 loss: 7.89480737e-07
Iter: 492 loss: 7.89152523e-07
Iter: 493 loss: 7.89158435e-07
Iter: 494 loss: 7.88793159e-07
Iter: 495 loss: 7.88341708e-07
Iter: 496 loss: 7.88330055e-07
Iter: 497 loss: 7.87635372e-07
Iter: 498 loss: 7.90366869e-07
Iter: 499 loss: 7.87522708e-07
Iter: 500 loss: 7.8712651e-07
Iter: 501 loss: 7.8859955e-07
Iter: 502 loss: 7.87020383e-07
Iter: 503 loss: 7.86615942e-07
Iter: 504 loss: 7.91547222e-07
Iter: 505 loss: 7.86563191e-07
Iter: 506 loss: 7.86421253e-07
Iter: 507 loss: 7.86108842e-07
Iter: 508 loss: 7.92341666e-07
Iter: 509 loss: 7.86147893e-07
Iter: 510 loss: 7.85746636e-07
Iter: 511 loss: 7.8548851e-07
Iter: 512 loss: 7.85381701e-07
Iter: 513 loss: 7.84918257e-07
Iter: 514 loss: 7.89950207e-07
Iter: 515 loss: 7.84864142e-07
Iter: 516 loss: 7.84460383e-07
Iter: 517 loss: 7.84433837e-07
Iter: 518 loss: 7.84128133e-07
Iter: 519 loss: 7.83777864e-07
Iter: 520 loss: 7.83799464e-07
Iter: 521 loss: 7.83433734e-07
Iter: 522 loss: 7.83032135e-07
Iter: 523 loss: 7.83004452e-07
Iter: 524 loss: 7.82443522e-07
Iter: 525 loss: 7.85990778e-07
Iter: 526 loss: 7.82304e-07
Iter: 527 loss: 7.81935228e-07
Iter: 528 loss: 7.82521056e-07
Iter: 529 loss: 7.8170649e-07
Iter: 530 loss: 7.81085078e-07
Iter: 531 loss: 7.81360939e-07
Iter: 532 loss: 7.80638459e-07
Iter: 533 loss: 7.80353616e-07
Iter: 534 loss: 7.80356572e-07
Iter: 535 loss: 7.80002722e-07
Iter: 536 loss: 7.80791879e-07
Iter: 537 loss: 7.7988534e-07
Iter: 538 loss: 7.79439461e-07
Iter: 539 loss: 7.81790561e-07
Iter: 540 loss: 7.79351808e-07
Iter: 541 loss: 7.79190145e-07
Iter: 542 loss: 7.78750803e-07
Iter: 543 loss: 7.84654162e-07
Iter: 544 loss: 7.78740741e-07
Iter: 545 loss: 7.78101082e-07
Iter: 546 loss: 7.78414e-07
Iter: 547 loss: 7.77749506e-07
Iter: 548 loss: 7.77170328e-07
Iter: 549 loss: 7.78281446e-07
Iter: 550 loss: 7.76914135e-07
Iter: 551 loss: 7.76204729e-07
Iter: 552 loss: 7.81227868e-07
Iter: 553 loss: 7.7618563e-07
Iter: 554 loss: 7.75724175e-07
Iter: 555 loss: 7.75539434e-07
Iter: 556 loss: 7.75326953e-07
Iter: 557 loss: 7.74996863e-07
Iter: 558 loss: 7.74931323e-07
Iter: 559 loss: 7.74645628e-07
Iter: 560 loss: 7.74469527e-07
Iter: 561 loss: 7.74401656e-07
Iter: 562 loss: 7.73900069e-07
Iter: 563 loss: 7.7473004e-07
Iter: 564 loss: 7.73666841e-07
Iter: 565 loss: 7.73293436e-07
Iter: 566 loss: 7.76473939e-07
Iter: 567 loss: 7.73281556e-07
Iter: 568 loss: 7.73007741e-07
Iter: 569 loss: 7.72709484e-07
Iter: 570 loss: 7.72601766e-07
Iter: 571 loss: 7.72466706e-07
Iter: 572 loss: 7.72425722e-07
Iter: 573 loss: 7.72253429e-07
Iter: 574 loss: 7.73506713e-07
Iter: 575 loss: 7.72205e-07
Iter: 576 loss: 7.72083411e-07
Iter: 577 loss: 7.71677151e-07
Iter: 578 loss: 7.74771706e-07
Iter: 579 loss: 7.71622e-07
Iter: 580 loss: 7.71207169e-07
Iter: 581 loss: 7.73552642e-07
Iter: 582 loss: 7.71165446e-07
Iter: 583 loss: 7.70873839e-07
Iter: 584 loss: 7.7028443e-07
Iter: 585 loss: 7.81675794e-07
Iter: 586 loss: 7.70293e-07
Iter: 587 loss: 7.69634823e-07
Iter: 588 loss: 7.77746891e-07
Iter: 589 loss: 7.69634767e-07
Iter: 590 loss: 7.69280632e-07
Iter: 591 loss: 7.68707764e-07
Iter: 592 loss: 7.68702762e-07
Iter: 593 loss: 7.68340612e-07
Iter: 594 loss: 7.68268478e-07
Iter: 595 loss: 7.67919232e-07
Iter: 596 loss: 7.69312066e-07
Iter: 597 loss: 7.67880238e-07
Iter: 598 loss: 7.67600454e-07
Iter: 599 loss: 7.67597e-07
Iter: 600 loss: 7.67357506e-07
Iter: 601 loss: 7.67108872e-07
Iter: 602 loss: 7.67239271e-07
Iter: 603 loss: 7.66934306e-07
Iter: 604 loss: 7.6649826e-07
Iter: 605 loss: 7.67876543e-07
Iter: 606 loss: 7.66403e-07
Iter: 607 loss: 7.66350638e-07
Iter: 608 loss: 7.66228482e-07
Iter: 609 loss: 7.66059486e-07
Iter: 610 loss: 7.65848199e-07
Iter: 611 loss: 7.71434657e-07
Iter: 612 loss: 7.65845471e-07
Iter: 613 loss: 7.65474738e-07
Iter: 614 loss: 7.65815855e-07
Iter: 615 loss: 7.65310347e-07
Iter: 616 loss: 7.65038862e-07
Iter: 617 loss: 7.66315338e-07
Iter: 618 loss: 7.64988442e-07
Iter: 619 loss: 7.64682511e-07
Iter: 620 loss: 7.642696e-07
Iter: 621 loss: 7.64222705e-07
Iter: 622 loss: 7.63893922e-07
Iter: 623 loss: 7.63911089e-07
Iter: 624 loss: 7.63591288e-07
Iter: 625 loss: 7.6317292e-07
Iter: 626 loss: 7.63212711e-07
Iter: 627 loss: 7.62874947e-07
Iter: 628 loss: 7.62869092e-07
Iter: 629 loss: 7.62614718e-07
Iter: 630 loss: 7.63395633e-07
Iter: 631 loss: 7.62553668e-07
Iter: 632 loss: 7.62261e-07
Iter: 633 loss: 7.62121317e-07
Iter: 634 loss: 7.61950332e-07
Iter: 635 loss: 7.61761e-07
Iter: 636 loss: 7.61933e-07
Iter: 637 loss: 7.61562887e-07
Iter: 638 loss: 7.61229217e-07
Iter: 639 loss: 7.64348385e-07
Iter: 640 loss: 7.61201e-07
Iter: 641 loss: 7.60931471e-07
Iter: 642 loss: 7.64190872e-07
Iter: 643 loss: 7.60903e-07
Iter: 644 loss: 7.60769467e-07
Iter: 645 loss: 7.60513672e-07
Iter: 646 loss: 7.6562651e-07
Iter: 647 loss: 7.60514467e-07
Iter: 648 loss: 7.60165e-07
Iter: 649 loss: 7.60220132e-07
Iter: 650 loss: 7.59868044e-07
Iter: 651 loss: 7.5954847e-07
Iter: 652 loss: 7.62591753e-07
Iter: 653 loss: 7.59505326e-07
Iter: 654 loss: 7.59250497e-07
Iter: 655 loss: 7.58693545e-07
Iter: 656 loss: 7.70628958e-07
Iter: 657 loss: 7.58637952e-07
Iter: 658 loss: 7.58180533e-07
Iter: 659 loss: 7.659429e-07
Iter: 660 loss: 7.58196052e-07
Iter: 661 loss: 7.57901375e-07
Iter: 662 loss: 7.57720954e-07
Iter: 663 loss: 7.57576458e-07
Iter: 664 loss: 7.57197938e-07
Iter: 665 loss: 7.5720834e-07
Iter: 666 loss: 7.56978125e-07
Iter: 667 loss: 7.58311103e-07
Iter: 668 loss: 7.56974543e-07
Iter: 669 loss: 7.56807935e-07
Iter: 670 loss: 7.5639997e-07
Iter: 671 loss: 7.62839534e-07
Iter: 672 loss: 7.56397e-07
Iter: 673 loss: 7.56107283e-07
Iter: 674 loss: 7.57114265e-07
Iter: 675 loss: 7.55984729e-07
Iter: 676 loss: 7.55812209e-07
Iter: 677 loss: 7.55715803e-07
Iter: 678 loss: 7.5559592e-07
Iter: 679 loss: 7.55351437e-07
Iter: 680 loss: 7.55348765e-07
Iter: 681 loss: 7.55218366e-07
Iter: 682 loss: 7.55405608e-07
Iter: 683 loss: 7.55095243e-07
Iter: 684 loss: 7.54802e-07
Iter: 685 loss: 7.54764073e-07
Iter: 686 loss: 7.54564951e-07
Iter: 687 loss: 7.54314e-07
Iter: 688 loss: 7.5703349e-07
Iter: 689 loss: 7.54301368e-07
Iter: 690 loss: 7.54050234e-07
Iter: 691 loss: 7.53671429e-07
Iter: 692 loss: 7.5371662e-07
Iter: 693 loss: 7.53380959e-07
Iter: 694 loss: 7.53390736e-07
Iter: 695 loss: 7.53147219e-07
Iter: 696 loss: 7.53027621e-07
Iter: 697 loss: 7.52941219e-07
Iter: 698 loss: 7.52618348e-07
Iter: 699 loss: 7.52623e-07
Iter: 700 loss: 7.52459755e-07
Iter: 701 loss: 7.52375286e-07
Iter: 702 loss: 7.5229724e-07
Iter: 703 loss: 7.51943958e-07
Iter: 704 loss: 7.51842776e-07
Iter: 705 loss: 7.51644393e-07
Iter: 706 loss: 7.51875e-07
Iter: 707 loss: 7.51541506e-07
Iter: 708 loss: 7.51415882e-07
Iter: 709 loss: 7.51155198e-07
Iter: 710 loss: 7.55125029e-07
Iter: 711 loss: 7.51107e-07
Iter: 712 loss: 7.50812148e-07
Iter: 713 loss: 7.51201412e-07
Iter: 714 loss: 7.50649065e-07
Iter: 715 loss: 7.50413676e-07
Iter: 716 loss: 7.52235565e-07
Iter: 717 loss: 7.50367e-07
Iter: 718 loss: 7.50147478e-07
Iter: 719 loss: 7.49766173e-07
Iter: 720 loss: 7.4977936e-07
Iter: 721 loss: 7.49472292e-07
Iter: 722 loss: 7.54542498e-07
Iter: 723 loss: 7.49414482e-07
Iter: 724 loss: 7.49235141e-07
Iter: 725 loss: 7.48968546e-07
Iter: 726 loss: 7.48923924e-07
Iter: 727 loss: 7.48545403e-07
Iter: 728 loss: 7.52431333e-07
Iter: 729 loss: 7.48563423e-07
Iter: 730 loss: 7.48349692e-07
Iter: 731 loss: 7.49119181e-07
Iter: 732 loss: 7.48295861e-07
Iter: 733 loss: 7.48000105e-07
Iter: 734 loss: 7.48462924e-07
Iter: 735 loss: 7.47899776e-07
Iter: 736 loss: 7.47589e-07
Iter: 737 loss: 7.48107e-07
Iter: 738 loss: 7.4750244e-07
Iter: 739 loss: 7.47298373e-07
Iter: 740 loss: 7.48775278e-07
Iter: 741 loss: 7.47313095e-07
Iter: 742 loss: 7.47023705e-07
Iter: 743 loss: 7.47459353e-07
Iter: 744 loss: 7.4685795e-07
Iter: 745 loss: 7.46719593e-07
Iter: 746 loss: 7.46828789e-07
Iter: 747 loss: 7.46626711e-07
Iter: 748 loss: 7.46439071e-07
Iter: 749 loss: 7.4631987e-07
Iter: 750 loss: 7.46232956e-07
Iter: 751 loss: 7.4586967e-07
Iter: 752 loss: 7.47262106e-07
Iter: 753 loss: 7.45769739e-07
Iter: 754 loss: 7.4550212e-07
Iter: 755 loss: 7.46100852e-07
Iter: 756 loss: 7.45442492e-07
Iter: 757 loss: 7.45098816e-07
Iter: 758 loss: 7.45143268e-07
Iter: 759 loss: 7.44906458e-07
Iter: 760 loss: 7.44564716e-07
Iter: 761 loss: 7.46864316e-07
Iter: 762 loss: 7.44514182e-07
Iter: 763 loss: 7.44247757e-07
Iter: 764 loss: 7.44581712e-07
Iter: 765 loss: 7.44142426e-07
Iter: 766 loss: 7.43913915e-07
Iter: 767 loss: 7.43871624e-07
Iter: 768 loss: 7.43816827e-07
Iter: 769 loss: 7.43518058e-07
Iter: 770 loss: 7.47434228e-07
Iter: 771 loss: 7.43519479e-07
Iter: 772 loss: 7.43272949e-07
Iter: 773 loss: 7.43277212e-07
Iter: 774 loss: 7.43066153e-07
Iter: 775 loss: 7.44463819e-07
Iter: 776 loss: 7.43067403e-07
Iter: 777 loss: 7.42976113e-07
Iter: 778 loss: 7.42812404e-07
Iter: 779 loss: 7.46800765e-07
Iter: 780 loss: 7.42791883e-07
Iter: 781 loss: 7.42519774e-07
Iter: 782 loss: 7.42519e-07
Iter: 783 loss: 7.42252382e-07
Iter: 784 loss: 7.41855615e-07
Iter: 785 loss: 7.44146689e-07
Iter: 786 loss: 7.41848794e-07
Iter: 787 loss: 7.41561905e-07
Iter: 788 loss: 7.41685199e-07
Iter: 789 loss: 7.41335441e-07
Iter: 790 loss: 7.40929579e-07
Iter: 791 loss: 7.42569682e-07
Iter: 792 loss: 7.40874384e-07
Iter: 793 loss: 7.40507176e-07
Iter: 794 loss: 7.40772691e-07
Iter: 795 loss: 7.40328232e-07
Iter: 796 loss: 7.398869e-07
Iter: 797 loss: 7.42228394e-07
Iter: 798 loss: 7.39861434e-07
Iter: 799 loss: 7.39622578e-07
Iter: 800 loss: 7.42107034e-07
Iter: 801 loss: 7.3960274e-07
Iter: 802 loss: 7.39378265e-07
Iter: 803 loss: 7.39016684e-07
Iter: 804 loss: 7.47778756e-07
Iter: 805 loss: 7.39020152e-07
Iter: 806 loss: 7.38806e-07
Iter: 807 loss: 7.38778795e-07
Iter: 808 loss: 7.38602353e-07
Iter: 809 loss: 7.38585641e-07
Iter: 810 loss: 7.38470476e-07
Iter: 811 loss: 7.38229517e-07
Iter: 812 loss: 7.39814482e-07
Iter: 813 loss: 7.3810844e-07
Iter: 814 loss: 7.37864696e-07
Iter: 815 loss: 7.40953737e-07
Iter: 816 loss: 7.37867651e-07
Iter: 817 loss: 7.37620041e-07
Iter: 818 loss: 7.37681319e-07
Iter: 819 loss: 7.37453263e-07
Iter: 820 loss: 7.37160121e-07
Iter: 821 loss: 7.38446e-07
Iter: 822 loss: 7.37117148e-07
Iter: 823 loss: 7.36897505e-07
Iter: 824 loss: 7.36884658e-07
Iter: 825 loss: 7.36654783e-07
Iter: 826 loss: 7.36228969e-07
Iter: 827 loss: 7.36598054e-07
Iter: 828 loss: 7.35937761e-07
Iter: 829 loss: 7.35621484e-07
Iter: 830 loss: 7.38734911e-07
Iter: 831 loss: 7.35640924e-07
Iter: 832 loss: 7.35346248e-07
Iter: 833 loss: 7.35822141e-07
Iter: 834 loss: 7.35238e-07
Iter: 835 loss: 7.35027584e-07
Iter: 836 loss: 7.3812123e-07
Iter: 837 loss: 7.35043955e-07
Iter: 838 loss: 7.34900482e-07
Iter: 839 loss: 7.34502407e-07
Iter: 840 loss: 7.37860319e-07
Iter: 841 loss: 7.34468472e-07
Iter: 842 loss: 7.34368427e-07
Iter: 843 loss: 7.34235527e-07
Iter: 844 loss: 7.34110472e-07
Iter: 845 loss: 7.35531557e-07
Iter: 846 loss: 7.3405954e-07
Iter: 847 loss: 7.33976776e-07
Iter: 848 loss: 7.3375486e-07
Iter: 849 loss: 7.3409683e-07
Iter: 850 loss: 7.33527202e-07
Iter: 851 loss: 7.33285e-07
Iter: 852 loss: 7.33269474e-07
Iter: 853 loss: 7.33037155e-07
Iter: 854 loss: 7.33158913e-07
Iter: 855 loss: 7.3287481e-07
Iter: 856 loss: 7.32424837e-07
Iter: 857 loss: 7.33459842e-07
Iter: 858 loss: 7.32303761e-07
Iter: 859 loss: 7.31963951e-07
Iter: 860 loss: 7.31665295e-07
Iter: 861 loss: 7.31617376e-07
Iter: 862 loss: 7.3112983e-07
Iter: 863 loss: 7.31134662e-07
Iter: 864 loss: 7.30929287e-07
Iter: 865 loss: 7.31927685e-07
Iter: 866 loss: 7.30908937e-07
Iter: 867 loss: 7.30682586e-07
Iter: 868 loss: 7.30846693e-07
Iter: 869 loss: 7.30494207e-07
Iter: 870 loss: 7.3025069e-07
Iter: 871 loss: 7.32992419e-07
Iter: 872 loss: 7.30266549e-07
Iter: 873 loss: 7.30028205e-07
Iter: 874 loss: 7.29671342e-07
Iter: 875 loss: 7.29685894e-07
Iter: 876 loss: 7.29764565e-07
Iter: 877 loss: 7.29486942e-07
Iter: 878 loss: 7.29357907e-07
Iter: 879 loss: 7.29176236e-07
Iter: 880 loss: 7.2916589e-07
Iter: 881 loss: 7.29003887e-07
Iter: 882 loss: 7.28622297e-07
Iter: 883 loss: 7.32402953e-07
Iter: 884 loss: 7.28573e-07
Iter: 885 loss: 7.2821922e-07
Iter: 886 loss: 7.28202963e-07
Iter: 887 loss: 7.27965471e-07
Iter: 888 loss: 7.29042654e-07
Iter: 889 loss: 7.27919428e-07
Iter: 890 loss: 7.27597239e-07
Iter: 891 loss: 7.27475822e-07
Iter: 892 loss: 7.27304553e-07
Iter: 893 loss: 7.27005613e-07
Iter: 894 loss: 7.28298176e-07
Iter: 895 loss: 7.27027555e-07
Iter: 896 loss: 7.2672816e-07
Iter: 897 loss: 7.26961446e-07
Iter: 898 loss: 7.26522785e-07
Iter: 899 loss: 7.26315875e-07
Iter: 900 loss: 7.28818804e-07
Iter: 901 loss: 7.26287794e-07
Iter: 902 loss: 7.26051667e-07
Iter: 903 loss: 7.25959467e-07
Iter: 904 loss: 7.25766881e-07
Iter: 905 loss: 7.25582254e-07
Iter: 906 loss: 7.25568384e-07
Iter: 907 loss: 7.25456232e-07
Iter: 908 loss: 7.25377049e-07
Iter: 909 loss: 7.25342943e-07
Iter: 910 loss: 7.25127109e-07
Iter: 911 loss: 7.27753843e-07
Iter: 912 loss: 7.25194639e-07
Iter: 913 loss: 7.25004838e-07
Iter: 914 loss: 7.24779113e-07
Iter: 915 loss: 7.24779511e-07
Iter: 916 loss: 7.24621714e-07
Iter: 917 loss: 7.24348808e-07
Iter: 918 loss: 7.24323968e-07
Iter: 919 loss: 7.23982e-07
Iter: 920 loss: 7.26239705e-07
Iter: 921 loss: 7.23966309e-07
Iter: 922 loss: 7.23674475e-07
Iter: 923 loss: 7.23880817e-07
Iter: 924 loss: 7.23525034e-07
Iter: 925 loss: 7.23229505e-07
Iter: 926 loss: 7.26654434e-07
Iter: 927 loss: 7.23189657e-07
Iter: 928 loss: 7.23031349e-07
Iter: 929 loss: 7.23434255e-07
Iter: 930 loss: 7.22965297e-07
Iter: 931 loss: 7.22690629e-07
Iter: 932 loss: 7.22430059e-07
Iter: 933 loss: 7.22395839e-07
Iter: 934 loss: 7.22127083e-07
Iter: 935 loss: 7.25627274e-07
Iter: 936 loss: 7.2213993e-07
Iter: 937 loss: 7.21938477e-07
Iter: 938 loss: 7.21928302e-07
Iter: 939 loss: 7.21738843e-07
Iter: 940 loss: 7.21474464e-07
Iter: 941 loss: 7.25286895e-07
Iter: 942 loss: 7.21459855e-07
Iter: 943 loss: 7.21302058e-07
Iter: 944 loss: 7.2124044e-07
Iter: 945 loss: 7.2111186e-07
Iter: 946 loss: 7.2094e-07
Iter: 947 loss: 7.20953494e-07
Iter: 948 loss: 7.20788819e-07
Iter: 949 loss: 7.20593448e-07
Iter: 950 loss: 7.20587877e-07
Iter: 951 loss: 7.20353341e-07
Iter: 952 loss: 7.20074695e-07
Iter: 953 loss: 7.20061621e-07
Iter: 954 loss: 7.19794e-07
Iter: 955 loss: 7.22222e-07
Iter: 956 loss: 7.19799345e-07
Iter: 957 loss: 7.1958209e-07
Iter: 958 loss: 7.20032176e-07
Iter: 959 loss: 7.19489037e-07
Iter: 960 loss: 7.19228638e-07
Iter: 961 loss: 7.19786954e-07
Iter: 962 loss: 7.19176057e-07
Iter: 963 loss: 7.18954936e-07
Iter: 964 loss: 7.19034233e-07
Iter: 965 loss: 7.18904289e-07
Iter: 966 loss: 7.1866009e-07
Iter: 967 loss: 7.19375635e-07
Iter: 968 loss: 7.18582669e-07
Iter: 969 loss: 7.183977e-07
Iter: 970 loss: 7.1814e-07
Iter: 971 loss: 7.18076535e-07
Iter: 972 loss: 7.17816761e-07
Iter: 973 loss: 7.2242932e-07
Iter: 974 loss: 7.1782307e-07
Iter: 975 loss: 7.17574494e-07
Iter: 976 loss: 7.17337116e-07
Iter: 977 loss: 7.1734479e-07
Iter: 978 loss: 7.17424712e-07
Iter: 979 loss: 7.17170906e-07
Iter: 980 loss: 7.17034936e-07
Iter: 981 loss: 7.17161129e-07
Iter: 982 loss: 7.16938473e-07
Iter: 983 loss: 7.1680364e-07
Iter: 984 loss: 7.16449222e-07
Iter: 985 loss: 7.23773212e-07
Iter: 986 loss: 7.16446095e-07
Iter: 987 loss: 7.16140505e-07
Iter: 988 loss: 7.19574075e-07
Iter: 989 loss: 7.16157444e-07
Iter: 990 loss: 7.15918191e-07
Iter: 991 loss: 7.15837132e-07
Iter: 992 loss: 7.15750843e-07
Iter: 993 loss: 7.15415126e-07
Iter: 994 loss: 7.16727413e-07
Iter: 995 loss: 7.15352769e-07
Iter: 996 loss: 7.15167516e-07
Iter: 997 loss: 7.15812e-07
Iter: 998 loss: 7.15115902e-07
Iter: 999 loss: 7.14908765e-07
Iter: 1000 loss: 7.15366241e-07
Iter: 1001 loss: 7.14884e-07
Iter: 1002 loss: 7.14673092e-07
Iter: 1003 loss: 7.15146939e-07
Iter: 1004 loss: 7.14644443e-07
Iter: 1005 loss: 7.14447424e-07
Iter: 1006 loss: 7.14403768e-07
Iter: 1007 loss: 7.14260864e-07
Iter: 1008 loss: 7.14088287e-07
Iter: 1009 loss: 7.16547788e-07
Iter: 1010 loss: 7.14074645e-07
Iter: 1011 loss: 7.13924692e-07
Iter: 1012 loss: 7.13776558e-07
Iter: 1013 loss: 7.13713121e-07
Iter: 1014 loss: 7.13783322e-07
Iter: 1015 loss: 7.13600343e-07
Iter: 1016 loss: 7.13491e-07
Iter: 1017 loss: 7.13359327e-07
Iter: 1018 loss: 7.15487886e-07
Iter: 1019 loss: 7.13368649e-07
Iter: 1020 loss: 7.13112684e-07
Iter: 1021 loss: 7.13268207e-07
Iter: 1022 loss: 7.12958354e-07
Iter: 1023 loss: 7.12686756e-07
Iter: 1024 loss: 7.15161377e-07
Iter: 1025 loss: 7.12659e-07
Iter: 1026 loss: 7.12542601e-07
Iter: 1027 loss: 7.12349674e-07
Iter: 1028 loss: 7.12337396e-07
Iter: 1029 loss: 7.12009694e-07
Iter: 1030 loss: 7.1399694e-07
Iter: 1031 loss: 7.11931e-07
Iter: 1032 loss: 7.11793575e-07
Iter: 1033 loss: 7.12270435e-07
Iter: 1034 loss: 7.11743041e-07
Iter: 1035 loss: 7.11564e-07
Iter: 1036 loss: 7.11523739e-07
Iter: 1037 loss: 7.11379357e-07
Iter: 1038 loss: 7.11144594e-07
Iter: 1039 loss: 7.13395764e-07
Iter: 1040 loss: 7.11145958e-07
Iter: 1041 loss: 7.11021073e-07
Iter: 1042 loss: 7.10765107e-07
Iter: 1043 loss: 7.15874762e-07
Iter: 1044 loss: 7.10797281e-07
Iter: 1045 loss: 7.10590712e-07
Iter: 1046 loss: 7.10569225e-07
Iter: 1047 loss: 7.10407107e-07
Iter: 1048 loss: 7.10212475e-07
Iter: 1049 loss: 7.10210145e-07
Iter: 1050 loss: 7.10596453e-07
Iter: 1051 loss: 7.10202812e-07
Iter: 1052 loss: 7.10103791e-07
Iter: 1053 loss: 7.09973278e-07
Iter: 1054 loss: 7.10001245e-07
Iter: 1055 loss: 7.09811957e-07
Iter: 1056 loss: 7.0966513e-07
Iter: 1057 loss: 7.09611186e-07
Iter: 1058 loss: 7.09484198e-07
Iter: 1059 loss: 7.09428832e-07
Iter: 1060 loss: 7.09314236e-07
Iter: 1061 loss: 7.09166329e-07
Iter: 1062 loss: 7.09159679e-07
Iter: 1063 loss: 7.08898824e-07
Iter: 1064 loss: 7.09587539e-07
Iter: 1065 loss: 7.08814923e-07
Iter: 1066 loss: 7.08677646e-07
Iter: 1067 loss: 7.09372102e-07
Iter: 1068 loss: 7.08628477e-07
Iter: 1069 loss: 7.08483526e-07
Iter: 1070 loss: 7.08846187e-07
Iter: 1071 loss: 7.08347557e-07
Iter: 1072 loss: 7.08220398e-07
Iter: 1073 loss: 7.0866065e-07
Iter: 1074 loss: 7.08187372e-07
Iter: 1075 loss: 7.08029916e-07
Iter: 1076 loss: 7.07886215e-07
Iter: 1077 loss: 7.07801348e-07
Iter: 1078 loss: 7.07631557e-07
Iter: 1079 loss: 7.08407924e-07
Iter: 1080 loss: 7.07612344e-07
Iter: 1081 loss: 7.07323295e-07
Iter: 1082 loss: 7.07969662e-07
Iter: 1083 loss: 7.07269919e-07
Iter: 1084 loss: 7.07067954e-07
Iter: 1085 loss: 7.08164634e-07
Iter: 1086 loss: 7.07063407e-07
Iter: 1087 loss: 7.06958247e-07
Iter: 1088 loss: 7.06977744e-07
Iter: 1089 loss: 7.06911578e-07
Iter: 1090 loss: 7.06736444e-07
Iter: 1091 loss: 7.10237e-07
Iter: 1092 loss: 7.06775722e-07
Iter: 1093 loss: 7.06622529e-07
Iter: 1094 loss: 7.06307674e-07
Iter: 1095 loss: 7.10792847e-07
Iter: 1096 loss: 7.06332514e-07
Iter: 1097 loss: 7.06027663e-07
Iter: 1098 loss: 7.10079291e-07
Iter: 1099 loss: 7.06022092e-07
Iter: 1100 loss: 7.05834168e-07
Iter: 1101 loss: 7.06463311e-07
Iter: 1102 loss: 7.05840137e-07
Iter: 1103 loss: 7.05553873e-07
Iter: 1104 loss: 7.06502e-07
Iter: 1105 loss: 7.05542163e-07
Iter: 1106 loss: 7.05406819e-07
Iter: 1107 loss: 7.05835419e-07
Iter: 1108 loss: 7.05386e-07
Iter: 1109 loss: 7.05225887e-07
Iter: 1110 loss: 7.04944853e-07
Iter: 1111 loss: 7.04991635e-07
Iter: 1112 loss: 7.0480661e-07
Iter: 1113 loss: 7.0477472e-07
Iter: 1114 loss: 7.04694401e-07
Iter: 1115 loss: 7.04579463e-07
Iter: 1116 loss: 7.04515685e-07
Iter: 1117 loss: 7.04309514e-07
Iter: 1118 loss: 7.04508579e-07
Iter: 1119 loss: 7.04172294e-07
Iter: 1120 loss: 7.04051672e-07
Iter: 1121 loss: 7.05006187e-07
Iter: 1122 loss: 7.0401984e-07
Iter: 1123 loss: 7.03802925e-07
Iter: 1124 loss: 7.04859076e-07
Iter: 1125 loss: 7.0375728e-07
Iter: 1126 loss: 7.03666274e-07
Iter: 1127 loss: 7.03620344e-07
Iter: 1128 loss: 7.03540763e-07
Iter: 1129 loss: 7.03455e-07
Iter: 1130 loss: 7.03342948e-07
Iter: 1131 loss: 7.03278261e-07
Iter: 1132 loss: 7.03142405e-07
Iter: 1133 loss: 7.04890681e-07
Iter: 1134 loss: 7.03096759e-07
Iter: 1135 loss: 7.02960904e-07
Iter: 1136 loss: 7.03016156e-07
Iter: 1137 loss: 7.0283977e-07
Iter: 1138 loss: 7.02704426e-07
Iter: 1139 loss: 7.04404101e-07
Iter: 1140 loss: 7.02649913e-07
Iter: 1141 loss: 7.02561351e-07
Iter: 1142 loss: 7.02773036e-07
Iter: 1143 loss: 7.02506782e-07
Iter: 1144 loss: 7.02391731e-07
Iter: 1145 loss: 7.0216754e-07
Iter: 1146 loss: 7.02169928e-07
Iter: 1147 loss: 7.02012926e-07
Iter: 1148 loss: 7.04506078e-07
Iter: 1149 loss: 7.02017644e-07
Iter: 1150 loss: 7.01817953e-07
Iter: 1151 loss: 7.0178578e-07
Iter: 1152 loss: 7.01681188e-07
Iter: 1153 loss: 7.01462e-07
Iter: 1154 loss: 7.02920261e-07
Iter: 1155 loss: 7.01446197e-07
Iter: 1156 loss: 7.01306192e-07
Iter: 1157 loss: 7.0155096e-07
Iter: 1158 loss: 7.0128533e-07
Iter: 1159 loss: 7.01089448e-07
Iter: 1160 loss: 7.0145677e-07
Iter: 1161 loss: 7.00974056e-07
Iter: 1162 loss: 7.00897886e-07
Iter: 1163 loss: 7.00808073e-07
Iter: 1164 loss: 7.00797841e-07
Iter: 1165 loss: 7.00646922e-07
Iter: 1166 loss: 7.00608211e-07
Iter: 1167 loss: 7.00498163e-07
Iter: 1168 loss: 7.00345822e-07
Iter: 1169 loss: 7.02368709e-07
Iter: 1170 loss: 7.00316832e-07
Iter: 1171 loss: 7.00238445e-07
Iter: 1172 loss: 7.00064163e-07
Iter: 1173 loss: 7.00065129e-07
Iter: 1174 loss: 6.99832299e-07
Iter: 1175 loss: 6.99850943e-07
Iter: 1176 loss: 6.99695931e-07
Iter: 1177 loss: 6.99646932e-07
Iter: 1178 loss: 6.99603447e-07
Iter: 1179 loss: 6.99299108e-07
Iter: 1180 loss: 6.9986072e-07
Iter: 1181 loss: 6.99234e-07
Iter: 1182 loss: 6.99073439e-07
Iter: 1183 loss: 6.99936095e-07
Iter: 1184 loss: 6.99056159e-07
Iter: 1185 loss: 6.98902454e-07
Iter: 1186 loss: 6.98884492e-07
Iter: 1187 loss: 6.98738461e-07
Iter: 1188 loss: 6.98554061e-07
Iter: 1189 loss: 7.00100259e-07
Iter: 1190 loss: 6.98519e-07
Iter: 1191 loss: 6.98441227e-07
Iter: 1192 loss: 6.99362431e-07
Iter: 1193 loss: 6.98418035e-07
Iter: 1194 loss: 6.98329131e-07
Iter: 1195 loss: 6.98062308e-07
Iter: 1196 loss: 6.98067254e-07
Iter: 1197 loss: 6.97899281e-07
Iter: 1198 loss: 6.97784401e-07
Iter: 1199 loss: 6.97754331e-07
Iter: 1200 loss: 6.97540258e-07
Iter: 1201 loss: 6.9871885e-07
Iter: 1202 loss: 6.97480459e-07
Iter: 1203 loss: 6.97349719e-07
Iter: 1204 loss: 6.97780933e-07
Iter: 1205 loss: 6.97280143e-07
Iter: 1206 loss: 6.97166797e-07
Iter: 1207 loss: 6.97272071e-07
Iter: 1208 loss: 6.97043447e-07
Iter: 1209 loss: 6.96878487e-07
Iter: 1210 loss: 6.9809397e-07
Iter: 1211 loss: 6.9690293e-07
Iter: 1212 loss: 6.96728307e-07
Iter: 1213 loss: 6.96592451e-07
Iter: 1214 loss: 6.96576194e-07
Iter: 1215 loss: 6.96277823e-07
Iter: 1216 loss: 6.97967153e-07
Iter: 1217 loss: 6.96280154e-07
Iter: 1218 loss: 6.96108145e-07
Iter: 1219 loss: 6.96129803e-07
Iter: 1220 loss: 6.9599497e-07
Iter: 1221 loss: 6.95761344e-07
Iter: 1222 loss: 6.96673681e-07
Iter: 1223 loss: 6.95767199e-07
Iter: 1224 loss: 6.95564e-07
Iter: 1225 loss: 6.96410325e-07
Iter: 1226 loss: 6.95539484e-07
Iter: 1227 loss: 6.95397603e-07
Iter: 1228 loss: 6.9663173e-07
Iter: 1229 loss: 6.95437961e-07
Iter: 1230 loss: 6.95322e-07
Iter: 1231 loss: 6.95050744e-07
Iter: 1232 loss: 6.95078541e-07
Iter: 1233 loss: 6.94937171e-07
Iter: 1234 loss: 6.9493e-07
Iter: 1235 loss: 6.94803589e-07
Iter: 1236 loss: 6.94611686e-07
Iter: 1237 loss: 6.94979349e-07
Iter: 1238 loss: 6.94511925e-07
Iter: 1239 loss: 6.94334744e-07
Iter: 1240 loss: 6.95249184e-07
Iter: 1241 loss: 6.94310131e-07
Iter: 1242 loss: 6.94079858e-07
Iter: 1243 loss: 6.94369362e-07
Iter: 1244 loss: 6.94002779e-07
Iter: 1245 loss: 6.93842935e-07
Iter: 1246 loss: 6.96387133e-07
Iter: 1247 loss: 6.93872153e-07
Iter: 1248 loss: 6.93777906e-07
Iter: 1249 loss: 6.9361829e-07
Iter: 1250 loss: 6.93607547e-07
Iter: 1251 loss: 6.93451284e-07
Iter: 1252 loss: 6.94312462e-07
Iter: 1253 loss: 6.93326342e-07
Iter: 1254 loss: 6.93271e-07
Iter: 1255 loss: 6.93487721e-07
Iter: 1256 loss: 6.93230447e-07
Iter: 1257 loss: 6.93027914e-07
Iter: 1258 loss: 6.93192874e-07
Iter: 1259 loss: 6.92896833e-07
Iter: 1260 loss: 6.92813842e-07
Iter: 1261 loss: 6.92759841e-07
Iter: 1262 loss: 6.927296e-07
Iter: 1263 loss: 6.9364819e-07
Iter: 1264 loss: 6.92725507e-07
Iter: 1265 loss: 6.92703736e-07
Iter: 1266 loss: 6.92475339e-07
Iter: 1267 loss: 6.93240395e-07
Iter: 1268 loss: 6.92415313e-07
Iter: 1269 loss: 6.92227e-07
Iter: 1270 loss: 6.93372158e-07
Iter: 1271 loss: 6.92237165e-07
Iter: 1272 loss: 6.92056744e-07
Iter: 1273 loss: 6.92091874e-07
Iter: 1274 loss: 6.91898265e-07
Iter: 1275 loss: 6.9180652e-07
Iter: 1276 loss: 6.93514608e-07
Iter: 1277 loss: 6.91781906e-07
Iter: 1278 loss: 6.91695277e-07
Iter: 1279 loss: 6.91861487e-07
Iter: 1280 loss: 6.91591367e-07
Iter: 1281 loss: 6.91441642e-07
Iter: 1282 loss: 6.92066919e-07
Iter: 1283 loss: 6.91414357e-07
Iter: 1284 loss: 6.9127907e-07
Iter: 1285 loss: 6.91295327e-07
Iter: 1286 loss: 6.91199602e-07
Iter: 1287 loss: 6.9096734e-07
Iter: 1288 loss: 6.91029e-07
Iter: 1289 loss: 6.90821821e-07
Iter: 1290 loss: 6.90615821e-07
Iter: 1291 loss: 6.90627814e-07
Iter: 1292 loss: 6.90480476e-07
Iter: 1293 loss: 6.90249863e-07
Iter: 1294 loss: 6.9023065e-07
Iter: 1295 loss: 6.90298066e-07
Iter: 1296 loss: 6.9009991e-07
Iter: 1297 loss: 6.90010438e-07
Iter: 1298 loss: 6.89997648e-07
Iter: 1299 loss: 6.89944386e-07
Iter: 1300 loss: 6.89850538e-07
Iter: 1301 loss: 6.8968393e-07
Iter: 1302 loss: 6.93355219e-07
Iter: 1303 loss: 6.89666308e-07
Iter: 1304 loss: 6.89464173e-07
Iter: 1305 loss: 6.90695288e-07
Iter: 1306 loss: 6.89393744e-07
Iter: 1307 loss: 6.89210651e-07
Iter: 1308 loss: 6.89005219e-07
Iter: 1309 loss: 6.88980208e-07
Iter: 1310 loss: 6.88633691e-07
Iter: 1311 loss: 6.90860077e-07
Iter: 1312 loss: 6.88602313e-07
Iter: 1313 loss: 6.88323269e-07
Iter: 1314 loss: 6.89714057e-07
Iter: 1315 loss: 6.88306613e-07
Iter: 1316 loss: 6.8805241e-07
Iter: 1317 loss: 6.90109403e-07
Iter: 1318 loss: 6.88070202e-07
Iter: 1319 loss: 6.87967486e-07
Iter: 1320 loss: 6.87864599e-07
Iter: 1321 loss: 6.87772513e-07
Iter: 1322 loss: 6.87615852e-07
Iter: 1323 loss: 6.88016712e-07
Iter: 1324 loss: 6.87455781e-07
Iter: 1325 loss: 6.87240799e-07
Iter: 1326 loss: 6.89193939e-07
Iter: 1327 loss: 6.87284569e-07
Iter: 1328 loss: 6.87132797e-07
Iter: 1329 loss: 6.87300201e-07
Iter: 1330 loss: 6.87049692e-07
Iter: 1331 loss: 6.86876319e-07
Iter: 1332 loss: 6.86845851e-07
Iter: 1333 loss: 6.86819931e-07
Iter: 1334 loss: 6.86698286e-07
Iter: 1335 loss: 6.86678504e-07
Iter: 1336 loss: 6.86536055e-07
Iter: 1337 loss: 6.86311864e-07
Iter: 1338 loss: 6.86305384e-07
Iter: 1339 loss: 6.8612303e-07
Iter: 1340 loss: 6.86156113e-07
Iter: 1341 loss: 6.8600616e-07
Iter: 1342 loss: 6.85863824e-07
Iter: 1343 loss: 6.8583455e-07
Iter: 1344 loss: 6.85651571e-07
Iter: 1345 loss: 6.87130239e-07
Iter: 1346 loss: 6.85679765e-07
Iter: 1347 loss: 6.85466148e-07
Iter: 1348 loss: 6.85572843e-07
Iter: 1349 loss: 6.85386908e-07
Iter: 1350 loss: 6.85188581e-07
Iter: 1351 loss: 6.85884629e-07
Iter: 1352 loss: 6.85162036e-07
Iter: 1353 loss: 6.84997076e-07
Iter: 1354 loss: 6.85094165e-07
Iter: 1355 loss: 6.84842803e-07
Iter: 1356 loss: 6.84648398e-07
Iter: 1357 loss: 6.86015e-07
Iter: 1358 loss: 6.84646523e-07
Iter: 1359 loss: 6.84456154e-07
Iter: 1360 loss: 6.84584961e-07
Iter: 1361 loss: 6.84361964e-07
Iter: 1362 loss: 6.84254474e-07
Iter: 1363 loss: 6.85669704e-07
Iter: 1364 loss: 6.84249926e-07
Iter: 1365 loss: 6.84108272e-07
Iter: 1366 loss: 6.84415966e-07
Iter: 1367 loss: 6.84083034e-07
Iter: 1368 loss: 6.83962753e-07
Iter: 1369 loss: 6.84077065e-07
Iter: 1370 loss: 6.83901931e-07
Iter: 1371 loss: 6.83810583e-07
Iter: 1372 loss: 6.83830763e-07
Iter: 1373 loss: 6.83712813e-07
Iter: 1374 loss: 6.83562803e-07
Iter: 1375 loss: 6.83542453e-07
Iter: 1376 loss: 6.83439339e-07
Iter: 1377 loss: 6.83263579e-07
Iter: 1378 loss: 6.83250448e-07
Iter: 1379 loss: 6.83169674e-07
Iter: 1380 loss: 6.83068549e-07
Iter: 1381 loss: 6.83027679e-07
Iter: 1382 loss: 6.82859536e-07
Iter: 1383 loss: 6.83619191e-07
Iter: 1384 loss: 6.82779728e-07
Iter: 1385 loss: 6.82592429e-07
Iter: 1386 loss: 6.82509494e-07
Iter: 1387 loss: 6.82442248e-07
Iter: 1388 loss: 6.82251084e-07
Iter: 1389 loss: 6.8484934e-07
Iter: 1390 loss: 6.82251425e-07
Iter: 1391 loss: 6.82069867e-07
Iter: 1392 loss: 6.82070379e-07
Iter: 1393 loss: 6.81921279e-07
Iter: 1394 loss: 6.818575e-07
Iter: 1395 loss: 6.81839822e-07
Iter: 1396 loss: 6.8178656e-07
Iter: 1397 loss: 6.82841e-07
Iter: 1398 loss: 6.81751e-07
Iter: 1399 loss: 6.81671736e-07
Iter: 1400 loss: 6.81548102e-07
Iter: 1401 loss: 6.81529741e-07
Iter: 1402 loss: 6.81438337e-07
Iter: 1403 loss: 6.81689471e-07
Iter: 1404 loss: 6.81417816e-07
Iter: 1405 loss: 6.81254278e-07
Iter: 1406 loss: 6.81553615e-07
Iter: 1407 loss: 6.81187601e-07
Iter: 1408 loss: 6.81091876e-07
Iter: 1409 loss: 6.81122572e-07
Iter: 1410 loss: 6.80995413e-07
Iter: 1411 loss: 6.80839378e-07
Iter: 1412 loss: 6.80992514e-07
Iter: 1413 loss: 6.8074678e-07
Iter: 1414 loss: 6.80593303e-07
Iter: 1415 loss: 6.81419863e-07
Iter: 1416 loss: 6.80554706e-07
Iter: 1417 loss: 6.80335233e-07
Iter: 1418 loss: 6.80633434e-07
Iter: 1419 loss: 6.80267e-07
Iter: 1420 loss: 6.80064602e-07
Iter: 1421 loss: 6.80925211e-07
Iter: 1422 loss: 6.80028393e-07
Iter: 1423 loss: 6.79867867e-07
Iter: 1424 loss: 6.801111e-07
Iter: 1425 loss: 6.79781351e-07
Iter: 1426 loss: 6.79595303e-07
Iter: 1427 loss: 6.7987628e-07
Iter: 1428 loss: 6.79510208e-07
Iter: 1429 loss: 6.79332743e-07
Iter: 1430 loss: 6.81036568e-07
Iter: 1431 loss: 6.79310574e-07
Iter: 1432 loss: 6.79166533e-07
Iter: 1433 loss: 6.79225195e-07
Iter: 1434 loss: 6.79091841e-07
Iter: 1435 loss: 6.7899424e-07
Iter: 1436 loss: 6.79026e-07
Iter: 1437 loss: 6.7885486e-07
Iter: 1438 loss: 6.79018115e-07
Iter: 1439 loss: 6.78815297e-07
Iter: 1440 loss: 6.78687115e-07
Iter: 1441 loss: 6.7868541e-07
Iter: 1442 loss: 6.78578033e-07
Iter: 1443 loss: 6.78453148e-07
Iter: 1444 loss: 6.80353537e-07
Iter: 1445 loss: 6.7843223e-07
Iter: 1446 loss: 6.78302172e-07
Iter: 1447 loss: 6.78084348e-07
Iter: 1448 loss: 6.7809583e-07
Iter: 1449 loss: 6.77865216e-07
Iter: 1450 loss: 6.79023742e-07
Iter: 1451 loss: 6.77767389e-07
Iter: 1452 loss: 6.77605669e-07
Iter: 1453 loss: 6.77584126e-07
Iter: 1454 loss: 6.77433718e-07
Iter: 1455 loss: 6.77147909e-07
Iter: 1456 loss: 6.79741504e-07
Iter: 1457 loss: 6.77152968e-07
Iter: 1458 loss: 6.7697448e-07
Iter: 1459 loss: 6.76998e-07
Iter: 1460 loss: 6.76837658e-07
Iter: 1461 loss: 6.76640582e-07
Iter: 1462 loss: 6.77514777e-07
Iter: 1463 loss: 6.76529794e-07
Iter: 1464 loss: 6.76304523e-07
Iter: 1465 loss: 6.76801449e-07
Iter: 1466 loss: 6.76257912e-07
Iter: 1467 loss: 6.76178274e-07
Iter: 1468 loss: 6.76111142e-07
Iter: 1469 loss: 6.76070272e-07
Iter: 1470 loss: 6.759131e-07
Iter: 1471 loss: 6.79225764e-07
Iter: 1472 loss: 6.75922934e-07
Iter: 1473 loss: 6.75789352e-07
Iter: 1474 loss: 6.75877743e-07
Iter: 1475 loss: 6.75724095e-07
Iter: 1476 loss: 6.75478532e-07
Iter: 1477 loss: 6.76069703e-07
Iter: 1478 loss: 6.75418789e-07
Iter: 1479 loss: 6.75249908e-07
Iter: 1480 loss: 6.76132345e-07
Iter: 1481 loss: 6.75218e-07
Iter: 1482 loss: 6.75122692e-07
Iter: 1483 loss: 6.75210742e-07
Iter: 1484 loss: 6.75038e-07
Iter: 1485 loss: 6.74862804e-07
Iter: 1486 loss: 6.75139461e-07
Iter: 1487 loss: 6.74743319e-07
Iter: 1488 loss: 6.74555622e-07
Iter: 1489 loss: 6.74695627e-07
Iter: 1490 loss: 6.7444455e-07
Iter: 1491 loss: 6.74270836e-07
Iter: 1492 loss: 6.76806053e-07
Iter: 1493 loss: 6.74297894e-07
Iter: 1494 loss: 6.74091723e-07
Iter: 1495 loss: 6.73982413e-07
Iter: 1496 loss: 6.73973148e-07
Iter: 1497 loss: 6.73771808e-07
Iter: 1498 loss: 6.74630087e-07
Iter: 1499 loss: 6.73726049e-07
Iter: 1500 loss: 6.73620093e-07
Iter: 1501 loss: 6.74469675e-07
Iter: 1502 loss: 6.73622253e-07
Iter: 1503 loss: 6.73435125e-07
Iter: 1504 loss: 6.73929151e-07
Iter: 1505 loss: 6.73379361e-07
Iter: 1506 loss: 6.73329e-07
Iter: 1507 loss: 6.73144484e-07
Iter: 1508 loss: 6.75339493e-07
Iter: 1509 loss: 6.73093837e-07
Iter: 1510 loss: 6.729436e-07
Iter: 1511 loss: 6.7395888e-07
Iter: 1512 loss: 6.72884312e-07
Iter: 1513 loss: 6.72739134e-07
Iter: 1514 loss: 6.74078e-07
Iter: 1515 loss: 6.72803594e-07
Iter: 1516 loss: 6.72599413e-07
Iter: 1517 loss: 6.72509088e-07
Iter: 1518 loss: 6.72507156e-07
Iter: 1519 loss: 6.7233e-07
Iter: 1520 loss: 6.73893e-07
Iter: 1521 loss: 6.72318777e-07
Iter: 1522 loss: 6.72130795e-07
Iter: 1523 loss: 6.72376586e-07
Iter: 1524 loss: 6.72141e-07
Iter: 1525 loss: 6.71955149e-07
Iter: 1526 loss: 6.71908197e-07
Iter: 1527 loss: 6.71772568e-07
Iter: 1528 loss: 6.71609541e-07
Iter: 1529 loss: 6.71951625e-07
Iter: 1530 loss: 6.71546104e-07
Iter: 1531 loss: 6.71335215e-07
Iter: 1532 loss: 6.73168415e-07
Iter: 1533 loss: 6.71334305e-07
Iter: 1534 loss: 6.71188559e-07
Iter: 1535 loss: 6.71080613e-07
Iter: 1536 loss: 6.71035878e-07
Iter: 1537 loss: 6.71034627e-07
Iter: 1538 loss: 6.70984207e-07
Iter: 1539 loss: 6.70824761e-07
Iter: 1540 loss: 6.7066037e-07
Iter: 1541 loss: 6.7432444e-07
Iter: 1542 loss: 6.70712e-07
Iter: 1543 loss: 6.70470172e-07
Iter: 1544 loss: 6.70263603e-07
Iter: 1545 loss: 6.70270424e-07
Iter: 1546 loss: 6.70048735e-07
Iter: 1547 loss: 6.73206159e-07
Iter: 1548 loss: 6.70073632e-07
Iter: 1549 loss: 6.69848248e-07
Iter: 1550 loss: 6.70130362e-07
Iter: 1551 loss: 6.69831593e-07
Iter: 1552 loss: 6.69524411e-07
Iter: 1553 loss: 6.70576924e-07
Iter: 1554 loss: 6.69480642e-07
Iter: 1555 loss: 6.69319149e-07
Iter: 1556 loss: 6.69905376e-07
Iter: 1557 loss: 6.69274755e-07
Iter: 1558 loss: 6.69181702e-07
Iter: 1559 loss: 6.6952407e-07
Iter: 1560 loss: 6.69135943e-07
Iter: 1561 loss: 6.68966607e-07
Iter: 1562 loss: 6.69468704e-07
Iter: 1563 loss: 6.68941084e-07
Iter: 1564 loss: 6.68843199e-07
Iter: 1565 loss: 6.68660618e-07
Iter: 1566 loss: 6.68647658e-07
Iter: 1567 loss: 6.68513223e-07
Iter: 1568 loss: 6.68518453e-07
Iter: 1569 loss: 6.68409598e-07
Iter: 1570 loss: 6.68892881e-07
Iter: 1571 loss: 6.68382256e-07
Iter: 1572 loss: 6.68312509e-07
Iter: 1573 loss: 6.68502366e-07
Iter: 1574 loss: 6.6824623e-07
Iter: 1575 loss: 6.68156758e-07
Iter: 1576 loss: 6.68064445e-07
Iter: 1577 loss: 6.68064331e-07
Iter: 1578 loss: 6.67887662e-07
Iter: 1579 loss: 6.67765903e-07
Iter: 1580 loss: 6.67736799e-07
Iter: 1581 loss: 6.67551831e-07
Iter: 1582 loss: 6.7047813e-07
Iter: 1583 loss: 6.6755041e-07
Iter: 1584 loss: 6.67416259e-07
Iter: 1585 loss: 6.67801828e-07
Iter: 1586 loss: 6.67411257e-07
Iter: 1587 loss: 6.67261475e-07
Iter: 1588 loss: 6.67365839e-07
Iter: 1589 loss: 6.6719997e-07
Iter: 1590 loss: 6.67048425e-07
Iter: 1591 loss: 6.67525e-07
Iter: 1592 loss: 6.67027678e-07
Iter: 1593 loss: 6.66852259e-07
Iter: 1594 loss: 6.6714108e-07
Iter: 1595 loss: 6.66797916e-07
Iter: 1596 loss: 6.66646429e-07
Iter: 1597 loss: 6.67248969e-07
Iter: 1598 loss: 6.66576852e-07
Iter: 1599 loss: 6.6644e-07
Iter: 1600 loss: 6.66326059e-07
Iter: 1601 loss: 6.66283313e-07
Iter: 1602 loss: 6.66186907e-07
Iter: 1603 loss: 6.66167466e-07
Iter: 1604 loss: 6.66161554e-07
Iter: 1605 loss: 6.66135463e-07
Iter: 1606 loss: 6.66095161e-07
Iter: 1607 loss: 6.66002336e-07
Iter: 1608 loss: 6.67361576e-07
Iter: 1609 loss: 6.6596e-07
Iter: 1610 loss: 6.65796506e-07
Iter: 1611 loss: 6.6560176e-07
Iter: 1612 loss: 6.65570951e-07
Iter: 1613 loss: 6.65372113e-07
Iter: 1614 loss: 6.66452536e-07
Iter: 1615 loss: 6.65334483e-07
Iter: 1616 loss: 6.65120297e-07
Iter: 1617 loss: 6.66411609e-07
Iter: 1618 loss: 6.65072e-07
Iter: 1619 loss: 6.64964e-07
Iter: 1620 loss: 6.65590164e-07
Iter: 1621 loss: 6.64908384e-07
Iter: 1622 loss: 6.647345e-07
Iter: 1623 loss: 6.64965626e-07
Iter: 1624 loss: 6.64619051e-07
Iter: 1625 loss: 6.64502068e-07
Iter: 1626 loss: 6.65452546e-07
Iter: 1627 loss: 6.64493427e-07
Iter: 1628 loss: 6.64364165e-07
Iter: 1629 loss: 6.64402364e-07
Iter: 1630 loss: 6.64288564e-07
Iter: 1631 loss: 6.64165498e-07
Iter: 1632 loss: 6.64471031e-07
Iter: 1633 loss: 6.64060906e-07
Iter: 1634 loss: 6.63950118e-07
Iter: 1635 loss: 6.64148274e-07
Iter: 1636 loss: 6.6390237e-07
Iter: 1637 loss: 6.63771175e-07
Iter: 1638 loss: 6.6378152e-07
Iter: 1639 loss: 6.6366789e-07
Iter: 1640 loss: 6.63926869e-07
Iter: 1641 loss: 6.63623041e-07
Iter: 1642 loss: 6.63548576e-07
Iter: 1643 loss: 6.63486958e-07
Iter: 1644 loss: 6.63490368e-07
Iter: 1645 loss: 6.63326318e-07
Iter: 1646 loss: 6.63300398e-07
Iter: 1647 loss: 6.63223659e-07
Iter: 1648 loss: 6.63066885e-07
Iter: 1649 loss: 6.63839614e-07
Iter: 1650 loss: 6.62992136e-07
Iter: 1651 loss: 6.62868672e-07
Iter: 1652 loss: 6.63278797e-07
Iter: 1653 loss: 6.62809953e-07
Iter: 1654 loss: 6.62687512e-07
Iter: 1655 loss: 6.62673131e-07
Iter: 1656 loss: 6.62575928e-07
Iter: 1657 loss: 6.62443085e-07
Iter: 1658 loss: 6.6246e-07
Iter: 1659 loss: 6.6232235e-07
Iter: 1660 loss: 6.6362594e-07
Iter: 1661 loss: 6.62250955e-07
Iter: 1662 loss: 6.62166826e-07
Iter: 1663 loss: 6.62359696e-07
Iter: 1664 loss: 6.62112711e-07
Iter: 1665 loss: 6.61996523e-07
Iter: 1666 loss: 6.61992942e-07
Iter: 1667 loss: 6.6188943e-07
Iter: 1668 loss: 6.61790693e-07
Iter: 1669 loss: 6.62932621e-07
Iter: 1670 loss: 6.61808372e-07
Iter: 1671 loss: 6.61631475e-07
Iter: 1672 loss: 6.62768286e-07
Iter: 1673 loss: 6.61680758e-07
Iter: 1674 loss: 6.61562183e-07
Iter: 1675 loss: 6.6144645e-07
Iter: 1676 loss: 6.6424559e-07
Iter: 1677 loss: 6.61388867e-07
Iter: 1678 loss: 6.6125591e-07
Iter: 1679 loss: 6.61477145e-07
Iter: 1680 loss: 6.61217655e-07
Iter: 1681 loss: 6.61070487e-07
Iter: 1682 loss: 6.61364766e-07
Iter: 1683 loss: 6.60950832e-07
Iter: 1684 loss: 6.60848343e-07
Iter: 1685 loss: 6.61726574e-07
Iter: 1686 loss: 6.60814919e-07
Iter: 1687 loss: 6.60670935e-07
Iter: 1688 loss: 6.60837259e-07
Iter: 1689 loss: 6.60563956e-07
Iter: 1690 loss: 6.60475735e-07
Iter: 1691 loss: 6.62018579e-07
Iter: 1692 loss: 6.60489377e-07
Iter: 1693 loss: 6.60457431e-07
Iter: 1694 loss: 6.60325668e-07
Iter: 1695 loss: 6.60328737e-07
Iter: 1696 loss: 6.60249725e-07
Iter: 1697 loss: 6.60210276e-07
Iter: 1698 loss: 6.60154342e-07
Iter: 1699 loss: 6.60145361e-07
Iter: 1700 loss: 6.60134333e-07
Iter: 1701 loss: 6.60032811e-07
Iter: 1702 loss: 6.60122453e-07
Iter: 1703 loss: 6.59939133e-07
Iter: 1704 loss: 6.5990605e-07
Iter: 1705 loss: 6.59852219e-07
Iter: 1706 loss: 6.59856596e-07
Iter: 1707 loss: 6.59843181e-07
Iter: 1708 loss: 6.59846933e-07
Iter: 1709 loss: 6.59836e-07
Iter: 1710 loss: 6.5982988e-07
Iter: 1711 loss: 6.59847046e-07
Iter: 1712 loss: 6.59872057e-07
Iter: 1713 loss: 6.5984608e-07
Iter: 1714 loss: 6.59871489e-07
Iter: 1715 loss: 6.59854322e-07
Iter: 1716 loss: 6.59849093e-07
Iter: 1717 loss: 6.59864156e-07
Iter: 1718 loss: 6.59848467e-07
Iter: 1719 loss: 6.59857e-07
Iter: 1720 loss: 6.59856653e-07
Iter: 1721 loss: 6.59855971e-07
Iter: 1722 loss: 6.59849206e-07
Iter: 1723 loss: 6.59848581e-07
Iter: 1724 loss: 6.59862394e-07
Iter: 1725 loss: 6.5985239e-07
Iter: 1726 loss: 6.59861598e-07
Iter: 1727 loss: 6.5985239e-07
Iter: 1728 loss: 6.598612e-07
Iter: 1729 loss: 6.59852333e-07
Iter: 1730 loss: 6.59852333e-07
Iter: 1731 loss: 6.598612e-07
Iter: 1732 loss: 6.59646048e-07
Iter: 1733 loss: 6.61000286e-07
Iter: 1734 loss: 6.5958011e-07
Iter: 1735 loss: 6.5947836e-07
Iter: 1736 loss: 6.59355237e-07
Iter: 1737 loss: 6.59323803e-07
Iter: 1738 loss: 6.59186412e-07
Iter: 1739 loss: 6.59156285e-07
Iter: 1740 loss: 6.59014631e-07
Iter: 1741 loss: 6.58957276e-07
Iter: 1742 loss: 6.60472836e-07
Iter: 1743 loss: 6.58964154e-07
Iter: 1744 loss: 6.58848251e-07
Iter: 1745 loss: 6.59038278e-07
Iter: 1746 loss: 6.58775264e-07
Iter: 1747 loss: 6.58666067e-07
Iter: 1748 loss: 6.59344892e-07
Iter: 1749 loss: 6.58615e-07
Iter: 1750 loss: 6.58558179e-07
Iter: 1751 loss: 6.58496333e-07
Iter: 1752 loss: 6.58503666e-07
Iter: 1753 loss: 6.58370709e-07
Iter: 1754 loss: 6.58857971e-07
Iter: 1755 loss: 6.58345812e-07
Iter: 1756 loss: 6.58249e-07
Iter: 1757 loss: 6.5871717e-07
Iter: 1758 loss: 6.58265e-07
Iter: 1759 loss: 6.58116505e-07
Iter: 1760 loss: 6.58039198e-07
Iter: 1761 loss: 6.58008219e-07
Iter: 1762 loss: 6.58123781e-07
Iter: 1763 loss: 6.5792733e-07
Iter: 1764 loss: 6.57937505e-07
Iter: 1765 loss: 6.57937221e-07
Iter: 1766 loss: 6.57940802e-07
Iter: 1767 loss: 6.57946316e-07
Iter: 1768 loss: 6.5792068e-07
Iter: 1769 loss: 6.57933469e-07
Iter: 1770 loss: 6.57924943e-07
Iter: 1771 loss: 6.57933867e-07
Iter: 1772 loss: 6.57932731e-07
Iter: 1773 loss: 6.57922214e-07
Iter: 1774 loss: 6.57936482e-07
Iter: 1775 loss: 6.57946089e-07
Iter: 1776 loss: 6.57930968e-07
Iter: 1777 loss: 6.57923067e-07
Iter: 1778 loss: 6.5792085e-07
Iter: 1779 loss: 6.57927103e-07
Iter: 1780 loss: 6.57927e-07
Iter: 1781 loss: 6.5792932e-07
Iter: 1782 loss: 6.5793165e-07
Iter: 1783 loss: 6.57930286e-07
Iter: 1784 loss: 6.57929604e-07
Iter: 1785 loss: 6.5792949e-07
Iter: 1786 loss: 6.5792949e-07
Iter: 1787 loss: 6.57927e-07
Iter: 1788 loss: 6.57929263e-07
Iter: 1789 loss: 6.57927e-07
Iter: 1790 loss: 6.57929263e-07
Iter: 1791 loss: 6.57927e-07
Iter: 1792 loss: 6.57929263e-07
Iter: 1793 loss: 6.57682051e-07
Iter: 1794 loss: 6.57702117e-07
Iter: 1795 loss: 6.57481e-07
Iter: 1796 loss: 6.58428689e-07
Iter: 1797 loss: 6.57530336e-07
Iter: 1798 loss: 6.57362534e-07
Iter: 1799 loss: 6.57366741e-07
Iter: 1800 loss: 6.57281078e-07
Iter: 1801 loss: 6.57076157e-07
Iter: 1802 loss: 6.57162e-07
Iter: 1803 loss: 6.56994473e-07
Iter: 1804 loss: 6.56869588e-07
Iter: 1805 loss: 6.57480314e-07
Iter: 1806 loss: 6.56835823e-07
Iter: 1807 loss: 6.56707641e-07
Iter: 1808 loss: 6.56871293e-07
Iter: 1809 loss: 6.56598388e-07
Iter: 1810 loss: 6.56548764e-07
Iter: 1811 loss: 6.5773429e-07
Iter: 1812 loss: 6.56538077e-07
Iter: 1813 loss: 6.56457814e-07
Iter: 1814 loss: 6.56414613e-07
Iter: 1815 loss: 6.56361067e-07
Iter: 1816 loss: 6.5631184e-07
Iter: 1817 loss: 6.56555756e-07
Iter: 1818 loss: 6.56271709e-07
Iter: 1819 loss: 6.56189798e-07
Iter: 1820 loss: 6.56109535e-07
Iter: 1821 loss: 6.56104362e-07
Iter: 1822 loss: 6.55992835e-07
Iter: 1823 loss: 6.5602444e-07
Iter: 1824 loss: 6.55920758e-07
Iter: 1825 loss: 6.55950942e-07
Iter: 1826 loss: 6.55883127e-07
Iter: 1827 loss: 6.55827137e-07
Iter: 1828 loss: 6.55682584e-07
Iter: 1829 loss: 6.58604677e-07
Iter: 1830 loss: 6.55667463e-07
Iter: 1831 loss: 6.55512508e-07
Iter: 1832 loss: 6.57340536e-07
Iter: 1833 loss: 6.55507392e-07
Iter: 1834 loss: 6.55382678e-07
Iter: 1835 loss: 6.55346298e-07
Iter: 1836 loss: 6.55294855e-07
Iter: 1837 loss: 6.55081124e-07
Iter: 1838 loss: 6.56685074e-07
Iter: 1839 loss: 6.55097551e-07
Iter: 1840 loss: 6.55012627e-07
Iter: 1841 loss: 6.55328961e-07
Iter: 1842 loss: 6.5495766e-07
Iter: 1843 loss: 6.54886207e-07
Iter: 1844 loss: 6.55049519e-07
Iter: 1845 loss: 6.54809071e-07
Iter: 1846 loss: 6.54790199e-07
Iter: 1847 loss: 6.55513475e-07
Iter: 1848 loss: 6.54768769e-07
Iter: 1849 loss: 6.54717383e-07
Iter: 1850 loss: 6.54727046e-07
Iter: 1851 loss: 6.54653036e-07
Iter: 1852 loss: 6.54586643e-07
Iter: 1853 loss: 6.5494919e-07
Iter: 1854 loss: 6.54534e-07
Iter: 1855 loss: 6.54519454e-07
Iter: 1856 loss: 6.54802534e-07
Iter: 1857 loss: 6.54489895e-07
Iter: 1858 loss: 6.54467044e-07
Iter: 1859 loss: 6.54904284e-07
Iter: 1860 loss: 6.54461815e-07
Iter: 1861 loss: 6.54408211e-07
Iter: 1862 loss: 6.54337441e-07
Iter: 1863 loss: 6.55627332e-07
Iter: 1864 loss: 6.54353073e-07
Iter: 1865 loss: 6.54222845e-07
Iter: 1866 loss: 6.54431744e-07
Iter: 1867 loss: 6.54193855e-07
Iter: 1868 loss: 6.54071641e-07
Iter: 1869 loss: 6.54278494e-07
Iter: 1870 loss: 6.53982681e-07
Iter: 1871 loss: 6.53924644e-07
Iter: 1872 loss: 6.5391265e-07
Iter: 1873 loss: 6.53806296e-07
Iter: 1874 loss: 6.53637471e-07
Iter: 1875 loss: 6.53638438e-07
Iter: 1876 loss: 6.53570737e-07
Iter: 1877 loss: 6.53627808e-07
Iter: 1878 loss: 6.53503889e-07
Iter: 1879 loss: 6.53370591e-07
Iter: 1880 loss: 6.54239e-07
Iter: 1881 loss: 6.53375082e-07
Iter: 1882 loss: 6.53266511e-07
Iter: 1883 loss: 6.53287657e-07
Iter: 1884 loss: 6.53176471e-07
Iter: 1885 loss: 6.53052666e-07
Iter: 1886 loss: 6.53228653e-07
Iter: 1887 loss: 6.52977462e-07
Iter: 1888 loss: 6.52866561e-07
Iter: 1889 loss: 6.52859228e-07
Iter: 1890 loss: 6.52818187e-07
Iter: 1891 loss: 6.53126449e-07
Iter: 1892 loss: 6.52792835e-07
Iter: 1893 loss: 6.52745371e-07
Iter: 1894 loss: 6.52630888e-07
Iter: 1895 loss: 6.54708e-07
Iter: 1896 loss: 6.52692847e-07
Iter: 1897 loss: 6.52504298e-07
Iter: 1898 loss: 6.52999574e-07
Iter: 1899 loss: 6.52512597e-07
Iter: 1900 loss: 6.52467406e-07
Iter: 1901 loss: 6.5239476e-07
Iter: 1902 loss: 6.52335927e-07
Iter: 1903 loss: 6.52214169e-07
Iter: 1904 loss: 6.53198356e-07
Iter: 1905 loss: 6.52208143e-07
Iter: 1906 loss: 6.52113158e-07
Iter: 1907 loss: 6.51938819e-07
Iter: 1908 loss: 6.51945584e-07
Iter: 1909 loss: 6.51814275e-07
Iter: 1910 loss: 6.51839116e-07
Iter: 1911 loss: 6.51701839e-07
Iter: 1912 loss: 6.51944447e-07
Iter: 1913 loss: 6.51686662e-07
Iter: 1914 loss: 6.51581e-07
Iter: 1915 loss: 6.5191449e-07
Iter: 1916 loss: 6.51506582e-07
Iter: 1917 loss: 6.51437517e-07
Iter: 1918 loss: 6.516849e-07
Iter: 1919 loss: 6.51381356e-07
Iter: 1920 loss: 6.51270284e-07
Iter: 1921 loss: 6.51284438e-07
Iter: 1922 loss: 6.51216169e-07
Iter: 1923 loss: 6.51209859e-07
Iter: 1924 loss: 6.51133064e-07
Iter: 1925 loss: 6.51106461e-07
Iter: 1926 loss: 6.51083155e-07
Iter: 1927 loss: 6.51055529e-07
Iter: 1928 loss: 6.50959464e-07
Iter: 1929 loss: 6.50839866e-07
Iter: 1930 loss: 6.5082088e-07
Iter: 1931 loss: 6.50683262e-07
Iter: 1932 loss: 6.5169354e-07
Iter: 1933 loss: 6.50643415e-07
Iter: 1934 loss: 6.50514949e-07
Iter: 1935 loss: 6.5039734e-07
Iter: 1936 loss: 6.50395691e-07
Iter: 1937 loss: 6.50242555e-07
Iter: 1938 loss: 6.51697292e-07
Iter: 1939 loss: 6.50256595e-07
Iter: 1940 loss: 6.50102265e-07
Iter: 1941 loss: 6.50131881e-07
Iter: 1942 loss: 6.49978745e-07
Iter: 1943 loss: 6.499032e-07
Iter: 1944 loss: 6.50894151e-07
Iter: 1945 loss: 6.49900244e-07
Iter: 1946 loss: 6.49780077e-07
Iter: 1947 loss: 6.49896833e-07
Iter: 1948 loss: 6.49747e-07
Iter: 1949 loss: 6.49650929e-07
Iter: 1950 loss: 6.49612332e-07
Iter: 1951 loss: 6.4956123e-07
Iter: 1952 loss: 6.49455103e-07
Iter: 1953 loss: 6.49843059e-07
Iter: 1954 loss: 6.49430717e-07
Iter: 1955 loss: 6.4929867e-07
Iter: 1956 loss: 6.49298499e-07
Iter: 1957 loss: 6.49233129e-07
Iter: 1958 loss: 6.49627452e-07
Iter: 1959 loss: 6.49242565e-07
Iter: 1960 loss: 6.4917117e-07
Iter: 1961 loss: 6.49057256e-07
Iter: 1962 loss: 6.50812922e-07
Iter: 1963 loss: 6.49058052e-07
Iter: 1964 loss: 6.48839432e-07
Iter: 1965 loss: 6.49115464e-07
Iter: 1966 loss: 6.4881317e-07
Iter: 1967 loss: 6.48685727e-07
Iter: 1968 loss: 6.48792536e-07
Iter: 1969 loss: 6.48626269e-07
Iter: 1970 loss: 6.48403613e-07
Iter: 1971 loss: 6.49347271e-07
Iter: 1972 loss: 6.48362857e-07
Iter: 1973 loss: 6.48279752e-07
Iter: 1974 loss: 6.48440619e-07
Iter: 1975 loss: 6.48182436e-07
Iter: 1976 loss: 6.47983484e-07
Iter: 1977 loss: 6.48398554e-07
Iter: 1978 loss: 6.47934485e-07
Iter: 1979 loss: 6.47798743e-07
Iter: 1980 loss: 6.47991e-07
Iter: 1981 loss: 6.47704496e-07
Iter: 1982 loss: 6.47548e-07
Iter: 1983 loss: 6.48383605e-07
Iter: 1984 loss: 6.47509182e-07
Iter: 1985 loss: 6.47386173e-07
Iter: 1986 loss: 6.49064191e-07
Iter: 1987 loss: 6.47381512e-07
Iter: 1988 loss: 6.47334957e-07
Iter: 1989 loss: 6.47197e-07
Iter: 1990 loss: 6.47194497e-07
Iter: 1991 loss: 6.47247418e-07
Iter: 1992 loss: 6.47127536e-07
Iter: 1993 loss: 6.47095078e-07
Iter: 1994 loss: 6.47012541e-07
Iter: 1995 loss: 6.47027832e-07
Iter: 1996 loss: 6.46933245e-07
Iter: 1997 loss: 6.46915623e-07
Iter: 1998 loss: 6.46883109e-07
Iter: 1999 loss: 6.46761805e-07
Iter: 2000 loss: 6.46880494e-07
Iter: 2001 loss: 6.46699277e-07
Iter: 2002 loss: 6.46544549e-07
Iter: 2003 loss: 6.47812328e-07
Iter: 2004 loss: 6.46488672e-07
Iter: 2005 loss: 6.46379817e-07
Iter: 2006 loss: 6.46713033e-07
Iter: 2007 loss: 6.46396643e-07
Iter: 2008 loss: 6.46257774e-07
Iter: 2009 loss: 6.4627875e-07
Iter: 2010 loss: 6.46167678e-07
Iter: 2011 loss: 6.46037506e-07
Iter: 2012 loss: 6.4716329e-07
Iter: 2013 loss: 6.46025683e-07
Iter: 2014 loss: 6.45930584e-07
Iter: 2015 loss: 6.45829914e-07
Iter: 2016 loss: 6.45844807e-07
Iter: 2017 loss: 6.45706734e-07
Iter: 2018 loss: 6.45723219e-07
Iter: 2019 loss: 6.45611294e-07
Iter: 2020 loss: 6.45726459e-07
Iter: 2021 loss: 6.45602881e-07
Iter: 2022 loss: 6.45464695e-07
Iter: 2023 loss: 6.45490104e-07
Iter: 2024 loss: 6.45320483e-07
Iter: 2025 loss: 6.45457817e-07
Iter: 2026 loss: 6.45312e-07
Iter: 2027 loss: 6.45262105e-07
Iter: 2028 loss: 6.45264549e-07
Iter: 2029 loss: 6.45411546e-07
Iter: 2030 loss: 6.45206455e-07
Iter: 2031 loss: 6.45069349e-07
Iter: 2032 loss: 6.45338446e-07
Iter: 2033 loss: 6.45052637e-07
Iter: 2034 loss: 6.44977092e-07
Iter: 2035 loss: 6.44897455e-07
Iter: 2036 loss: 6.44815e-07
Iter: 2037 loss: 6.44659849e-07
Iter: 2038 loss: 6.46845706e-07
Iter: 2039 loss: 6.44671445e-07
Iter: 2040 loss: 6.44598572e-07
Iter: 2041 loss: 6.44684519e-07
Iter: 2042 loss: 6.44534055e-07
Iter: 2043 loss: 6.44402462e-07
Iter: 2044 loss: 6.44257511e-07
Iter: 2045 loss: 6.44233353e-07
Iter: 2046 loss: 6.44081922e-07
Iter: 2047 loss: 6.45888349e-07
Iter: 2048 loss: 6.44072941e-07
Iter: 2049 loss: 6.43963517e-07
Iter: 2050 loss: 6.44135e-07
Iter: 2051 loss: 6.43882913e-07
Iter: 2052 loss: 6.43769908e-07
Iter: 2053 loss: 6.44034913e-07
Iter: 2054 loss: 6.43687486e-07
Iter: 2055 loss: 6.4356675e-07
Iter: 2056 loss: 6.43935e-07
Iter: 2057 loss: 6.43483133e-07
Iter: 2058 loss: 6.43385306e-07
Iter: 2059 loss: 6.43424187e-07
Iter: 2060 loss: 6.43329713e-07
Iter: 2061 loss: 6.4396977e-07
Iter: 2062 loss: 6.43358931e-07
Iter: 2063 loss: 6.43353587e-07
Iter: 2064 loss: 6.43229555e-07
Iter: 2065 loss: 6.43503199e-07
Iter: 2066 loss: 6.43120188e-07
Iter: 2067 loss: 6.4302418e-07
Iter: 2068 loss: 6.43771614e-07
Iter: 2069 loss: 6.43027875e-07
Iter: 2070 loss: 6.42932832e-07
Iter: 2071 loss: 6.42862801e-07
Iter: 2072 loss: 6.42818179e-07
Iter: 2073 loss: 6.42745931e-07
Iter: 2074 loss: 6.42750365e-07
Iter: 2075 loss: 6.42661462e-07
Iter: 2076 loss: 6.42514e-07
Iter: 2077 loss: 6.42524355e-07
Iter: 2078 loss: 6.4240669e-07
Iter: 2079 loss: 6.43099554e-07
Iter: 2080 loss: 6.42396799e-07
Iter: 2081 loss: 6.42269242e-07
Iter: 2082 loss: 6.42360419e-07
Iter: 2083 loss: 6.42205691e-07
Iter: 2084 loss: 6.42053237e-07
Iter: 2085 loss: 6.4257074e-07
Iter: 2086 loss: 6.4197576e-07
Iter: 2087 loss: 6.41881627e-07
Iter: 2088 loss: 6.42077566e-07
Iter: 2089 loss: 6.41847066e-07
Iter: 2090 loss: 6.41693248e-07
Iter: 2091 loss: 6.42122757e-07
Iter: 2092 loss: 6.41603037e-07
Iter: 2093 loss: 6.41538747e-07
Iter: 2094 loss: 6.4155131e-07
Iter: 2095 loss: 6.4149458e-07
Iter: 2096 loss: 6.41520046e-07
Iter: 2097 loss: 6.41452175e-07
Iter: 2098 loss: 6.41417955e-07
Iter: 2099 loss: 6.41238671e-07
Iter: 2100 loss: 6.41883901e-07
Iter: 2101 loss: 6.41120096e-07
Iter: 2102 loss: 6.40984126e-07
Iter: 2103 loss: 6.42923e-07
Iter: 2104 loss: 6.40982421e-07
Iter: 2105 loss: 6.40832809e-07
Iter: 2106 loss: 6.41181259e-07
Iter: 2107 loss: 6.40797111e-07
Iter: 2108 loss: 6.4070673e-07
Iter: 2109 loss: 6.40709857e-07
Iter: 2110 loss: 6.40676319e-07
Iter: 2111 loss: 6.40460712e-07
Iter: 2112 loss: 6.42095415e-07
Iter: 2113 loss: 6.40477083e-07
Iter: 2114 loss: 6.40325879e-07
Iter: 2115 loss: 6.41547103e-07
Iter: 2116 loss: 6.40298822e-07
Iter: 2117 loss: 6.40163762e-07
Iter: 2118 loss: 6.41273402e-07
Iter: 2119 loss: 6.40151711e-07
Iter: 2120 loss: 6.40079463e-07
Iter: 2121 loss: 6.40511473e-07
Iter: 2122 loss: 6.40025803e-07
Iter: 2123 loss: 6.39957193e-07
Iter: 2124 loss: 6.39814289e-07
Iter: 2125 loss: 6.41511406e-07
Iter: 2126 loss: 6.3982236e-07
Iter: 2127 loss: 6.39906148e-07
Iter: 2128 loss: 6.39758241e-07
Iter: 2129 loss: 6.39716063e-07
Iter: 2130 loss: 6.39985842e-07
Iter: 2131 loss: 6.39675761e-07
Iter: 2132 loss: 6.3965922e-07
Iter: 2133 loss: 6.39531322e-07
Iter: 2134 loss: 6.40439907e-07
Iter: 2135 loss: 6.39526206e-07
Iter: 2136 loss: 6.39438554e-07
Iter: 2137 loss: 6.40086341e-07
Iter: 2138 loss: 6.39433438e-07
Iter: 2139 loss: 6.3936568e-07
Iter: 2140 loss: 6.39290192e-07
Iter: 2141 loss: 6.3926e-07
Iter: 2142 loss: 6.39122788e-07
Iter: 2143 loss: 6.40344865e-07
Iter: 2144 loss: 6.39166501e-07
Iter: 2145 loss: 6.3907288e-07
Iter: 2146 loss: 6.39080611e-07
Iter: 2147 loss: 6.38979827e-07
Iter: 2148 loss: 6.38860456e-07
Iter: 2149 loss: 6.3941792e-07
Iter: 2150 loss: 6.38780421e-07
Iter: 2151 loss: 6.3871812e-07
Iter: 2152 loss: 6.39119378e-07
Iter: 2153 loss: 6.38692541e-07
Iter: 2154 loss: 6.38628705e-07
Iter: 2155 loss: 6.38509221e-07
Iter: 2156 loss: 6.40849294e-07
Iter: 2157 loss: 6.38521385e-07
Iter: 2158 loss: 6.38410484e-07
Iter: 2159 loss: 6.38381835e-07
Iter: 2160 loss: 6.38329652e-07
Iter: 2161 loss: 6.38208348e-07
Iter: 2162 loss: 6.40435132e-07
Iter: 2163 loss: 6.38178904e-07
Iter: 2164 loss: 6.38240749e-07
Iter: 2165 loss: 6.38147867e-07
Iter: 2166 loss: 6.38096822e-07
Iter: 2167 loss: 6.3817464e-07
Iter: 2168 loss: 6.38048107e-07
Iter: 2169 loss: 6.38001893e-07
Iter: 2170 loss: 6.37850576e-07
Iter: 2171 loss: 6.40291319e-07
Iter: 2172 loss: 6.37901053e-07
Iter: 2173 loss: 6.37738765e-07
Iter: 2174 loss: 6.38006838e-07
Iter: 2175 loss: 6.37676408e-07
Iter: 2176 loss: 6.37508606e-07
Iter: 2177 loss: 6.37924757e-07
Iter: 2178 loss: 6.37514063e-07
Iter: 2179 loss: 6.37299365e-07
Iter: 2180 loss: 6.37842106e-07
Iter: 2181 loss: 6.37265e-07
Iter: 2182 loss: 6.37135486e-07
Iter: 2183 loss: 6.37392418e-07
Iter: 2184 loss: 6.37130142e-07
Iter: 2185 loss: 6.369998e-07
Iter: 2186 loss: 6.37938e-07
Iter: 2187 loss: 6.3702123e-07
Iter: 2188 loss: 6.36929258e-07
Iter: 2189 loss: 6.37012079e-07
Iter: 2190 loss: 6.36905611e-07
Iter: 2191 loss: 6.36788741e-07
Iter: 2192 loss: 6.36700463e-07
Iter: 2193 loss: 6.36654192e-07
Iter: 2194 loss: 6.3659661e-07
Iter: 2195 loss: 6.36548293e-07
Iter: 2196 loss: 6.36498157e-07
Iter: 2197 loss: 6.36434038e-07
Iter: 2198 loss: 6.38376832e-07
Iter: 2199 loss: 6.36418577e-07
Iter: 2200 loss: 6.36391178e-07
Iter: 2201 loss: 6.3634883e-07
Iter: 2202 loss: 6.36267487e-07
Iter: 2203 loss: 6.36251571e-07
Iter: 2204 loss: 6.36228265e-07
Iter: 2205 loss: 6.36175344e-07
Iter: 2206 loss: 6.36060577e-07
Iter: 2207 loss: 6.38974711e-07
Iter: 2208 loss: 6.36032723e-07
Iter: 2209 loss: 6.35901642e-07
Iter: 2210 loss: 6.37715402e-07
Iter: 2211 loss: 6.35960305e-07
Iter: 2212 loss: 6.35792389e-07
Iter: 2213 loss: 6.3606484e-07
Iter: 2214 loss: 6.35754589e-07
Iter: 2215 loss: 6.35730828e-07
Iter: 2216 loss: 6.35918695e-07
Iter: 2217 loss: 6.35674837e-07
Iter: 2218 loss: 6.35604351e-07
Iter: 2219 loss: 6.35688593e-07
Iter: 2220 loss: 6.35552e-07
Iter: 2221 loss: 6.35444223e-07
Iter: 2222 loss: 6.35740207e-07
Iter: 2223 loss: 6.35425067e-07
Iter: 2224 loss: 6.35356173e-07
Iter: 2225 loss: 6.35672109e-07
Iter: 2226 loss: 6.3530365e-07
Iter: 2227 loss: 6.35243396e-07
Iter: 2228 loss: 6.35179674e-07
Iter: 2229 loss: 6.35144033e-07
Iter: 2230 loss: 6.35037907e-07
Iter: 2231 loss: 6.36179038e-07
Iter: 2232 loss: 6.35052231e-07
Iter: 2233 loss: 6.34994592e-07
Iter: 2234 loss: 6.35047741e-07
Iter: 2235 loss: 6.34948947e-07
Iter: 2236 loss: 6.34860839e-07
Iter: 2237 loss: 6.34866694e-07
Iter: 2238 loss: 6.3479996e-07
Iter: 2239 loss: 6.3470668e-07
Iter: 2240 loss: 6.3470543e-07
Iter: 2241 loss: 6.3462528e-07
Iter: 2242 loss: 6.34441733e-07
Iter: 2243 loss: 6.3819374e-07
Iter: 2244 loss: 6.34441221e-07
Iter: 2245 loss: 6.34303e-07
Iter: 2246 loss: 6.34301671e-07
Iter: 2247 loss: 6.34231242e-07
Iter: 2248 loss: 6.3402814e-07
Iter: 2249 loss: 6.34037178e-07
Iter: 2250 loss: 6.33975105e-07
Iter: 2251 loss: 6.33990794e-07
Iter: 2252 loss: 6.33902346e-07
Iter: 2253 loss: 6.34251819e-07
Iter: 2254 loss: 6.33893364e-07
Iter: 2255 loss: 6.33807872e-07
Iter: 2256 loss: 6.33685147e-07
Iter: 2257 loss: 6.36509469e-07
Iter: 2258 loss: 6.33713455e-07
Iter: 2259 loss: 6.33556169e-07
Iter: 2260 loss: 6.34188382e-07
Iter: 2261 loss: 6.33542413e-07
Iter: 2262 loss: 6.33449531e-07
Iter: 2263 loss: 6.33423213e-07
Iter: 2264 loss: 6.33318564e-07
Iter: 2265 loss: 6.33217724e-07
Iter: 2266 loss: 6.34063895e-07
Iter: 2267 loss: 6.33166565e-07
Iter: 2268 loss: 6.33057766e-07
Iter: 2269 loss: 6.33525644e-07
Iter: 2270 loss: 6.33031391e-07
Iter: 2271 loss: 6.33023e-07
Iter: 2272 loss: 6.33001832e-07
Iter: 2273 loss: 6.33005243e-07
Iter: 2274 loss: 6.3296136e-07
Iter: 2275 loss: 6.32989156e-07
Iter: 2276 loss: 6.3297216e-07
Iter: 2277 loss: 6.3297523e-07
Iter: 2278 loss: 6.32987053e-07
Iter: 2279 loss: 6.32986144e-07
Iter: 2280 loss: 6.32983415e-07
Iter: 2281 loss: 6.3299143e-07
Iter: 2282 loss: 6.32975684e-07
Iter: 2283 loss: 6.32993476e-07
Iter: 2284 loss: 6.33002969e-07
Iter: 2285 loss: 6.329999e-07
Iter: 2286 loss: 6.32997455e-07
Iter: 2287 loss: 6.33002742e-07
Iter: 2288 loss: 6.33000411e-07
Iter: 2289 loss: 6.33004561e-07
Iter: 2290 loss: 6.33003367e-07
Iter: 2291 loss: 6.33001946e-07
Iter: 2292 loss: 6.33003879e-07
Iter: 2293 loss: 6.33004e-07
Iter: 2294 loss: 6.33001946e-07
Iter: 2295 loss: 6.33002e-07
Iter: 2296 loss: 6.33004e-07
Iter: 2297 loss: 6.33004e-07
Iter: 2298 loss: 6.33002e-07
Iter: 2299 loss: 6.32907813e-07
Iter: 2300 loss: 6.33306513e-07
Iter: 2301 loss: 6.32880756e-07
Iter: 2302 loss: 6.32836077e-07
Iter: 2303 loss: 6.3270943e-07
Iter: 2304 loss: 6.34932405e-07
Iter: 2305 loss: 6.32701358e-07
Iter: 2306 loss: 6.32607e-07
Iter: 2307 loss: 6.32583806e-07
Iter: 2308 loss: 6.32538e-07
Iter: 2309 loss: 6.32419244e-07
Iter: 2310 loss: 6.33701688e-07
Iter: 2311 loss: 6.32417937e-07
Iter: 2312 loss: 6.32338924e-07
Iter: 2313 loss: 6.32410661e-07
Iter: 2314 loss: 6.32319598e-07
Iter: 2315 loss: 6.3216379e-07
Iter: 2316 loss: 6.32393267e-07
Iter: 2317 loss: 6.32115132e-07
Iter: 2318 loss: 6.31978764e-07
Iter: 2319 loss: 6.33001378e-07
Iter: 2320 loss: 6.31959324e-07
Iter: 2321 loss: 6.31918397e-07
Iter: 2322 loss: 6.31907e-07
Iter: 2323 loss: 6.31861781e-07
Iter: 2324 loss: 6.31783166e-07
Iter: 2325 loss: 6.32418789e-07
Iter: 2326 loss: 6.31811417e-07
Iter: 2327 loss: 6.31738203e-07
Iter: 2328 loss: 6.31725868e-07
Iter: 2329 loss: 6.31711373e-07
Iter: 2330 loss: 6.31593196e-07
Iter: 2331 loss: 6.32725971e-07
Iter: 2332 loss: 6.31587113e-07
Iter: 2333 loss: 6.31569549e-07
Iter: 2334 loss: 6.31504236e-07
Iter: 2335 loss: 6.31493435e-07
Iter: 2336 loss: 6.31455464e-07
Iter: 2337 loss: 6.31457453e-07
Iter: 2338 loss: 6.31377e-07
Iter: 2339 loss: 6.3129454e-07
Iter: 2340 loss: 6.32181298e-07
Iter: 2341 loss: 6.31263333e-07
Iter: 2342 loss: 6.31243381e-07
Iter: 2343 loss: 6.31196315e-07
Iter: 2344 loss: 6.31131456e-07
Iter: 2345 loss: 6.31026353e-07
Iter: 2346 loss: 6.31399644e-07
Iter: 2347 loss: 6.31024704e-07
Iter: 2348 loss: 6.30944953e-07
Iter: 2349 loss: 6.31785838e-07
Iter: 2350 loss: 6.30910677e-07
Iter: 2351 loss: 6.30856164e-07
Iter: 2352 loss: 6.30824843e-07
Iter: 2353 loss: 6.3083445e-07
Iter: 2354 loss: 6.30732075e-07
Iter: 2355 loss: 6.30676936e-07
Iter: 2356 loss: 6.30644763e-07
Iter: 2357 loss: 6.3051732e-07
Iter: 2358 loss: 6.30946545e-07
Iter: 2359 loss: 6.30458203e-07
Iter: 2360 loss: 6.30380555e-07
Iter: 2361 loss: 6.31172554e-07
Iter: 2362 loss: 6.30409204e-07
Iter: 2363 loss: 6.30259251e-07
Iter: 2364 loss: 6.30241175e-07
Iter: 2365 loss: 6.30214117e-07
Iter: 2366 loss: 6.30135332e-07
Iter: 2367 loss: 6.30114e-07
Iter: 2368 loss: 6.30089289e-07
Iter: 2369 loss: 6.30038926e-07
Iter: 2370 loss: 6.30720876e-07
Iter: 2371 loss: 6.2998663e-07
Iter: 2372 loss: 6.29947863e-07
Iter: 2373 loss: 6.30173759e-07
Iter: 2374 loss: 6.2994377e-07
Iter: 2375 loss: 6.29840088e-07
Iter: 2376 loss: 6.30581e-07
Iter: 2377 loss: 6.2986544e-07
Iter: 2378 loss: 6.29825422e-07
Iter: 2379 loss: 6.29723559e-07
Iter: 2380 loss: 6.31638841e-07
Iter: 2381 loss: 6.29748286e-07
Iter: 2382 loss: 6.29610327e-07
Iter: 2383 loss: 6.30540171e-07
Iter: 2384 loss: 6.29592478e-07
Iter: 2385 loss: 6.29517e-07
Iter: 2386 loss: 6.29954457e-07
Iter: 2387 loss: 6.2949897e-07
Iter: 2388 loss: 6.29412853e-07
Iter: 2389 loss: 6.29331794e-07
Iter: 2390 loss: 6.29301894e-07
Iter: 2391 loss: 6.29222257e-07
Iter: 2392 loss: 6.30050181e-07
Iter: 2393 loss: 6.29193721e-07
Iter: 2394 loss: 6.29111469e-07
Iter: 2395 loss: 6.29006593e-07
Iter: 2396 loss: 6.28957764e-07
Iter: 2397 loss: 6.28841406e-07
Iter: 2398 loss: 6.28849307e-07
Iter: 2399 loss: 6.28795249e-07
Iter: 2400 loss: 6.29259375e-07
Iter: 2401 loss: 6.28823216e-07
Iter: 2402 loss: 6.28753583e-07
Iter: 2403 loss: 6.28685939e-07
Iter: 2404 loss: 6.28656892e-07
Iter: 2405 loss: 6.28611588e-07
Iter: 2406 loss: 6.28715384e-07
Iter: 2407 loss: 6.28570831e-07
Iter: 2408 loss: 6.28497503e-07
Iter: 2409 loss: 6.28441114e-07
Iter: 2410 loss: 6.28432645e-07
Iter: 2411 loss: 6.28380803e-07
Iter: 2412 loss: 6.28394559e-07
Iter: 2413 loss: 6.28335329e-07
Iter: 2414 loss: 6.28299347e-07
Iter: 2415 loss: 6.2830361e-07
Iter: 2416 loss: 6.28204816e-07
Iter: 2417 loss: 6.28467262e-07
Iter: 2418 loss: 6.28176338e-07
Iter: 2419 loss: 6.28117164e-07
Iter: 2420 loss: 6.2820942e-07
Iter: 2421 loss: 6.28081921e-07
Iter: 2422 loss: 6.27948566e-07
Iter: 2423 loss: 6.28424061e-07
Iter: 2424 loss: 6.27905592e-07
Iter: 2425 loss: 6.27813392e-07
Iter: 2426 loss: 6.28168095e-07
Iter: 2427 loss: 6.27807651e-07
Iter: 2428 loss: 6.27777695e-07
Iter: 2429 loss: 6.27654686e-07
Iter: 2430 loss: 6.27686404e-07
Iter: 2431 loss: 6.27537929e-07
Iter: 2432 loss: 6.2892e-07
Iter: 2433 loss: 6.27550833e-07
Iter: 2434 loss: 6.27527e-07
Iter: 2435 loss: 6.27488703e-07
Iter: 2436 loss: 6.27470683e-07
Iter: 2437 loss: 6.27327495e-07
Iter: 2438 loss: 6.28441342e-07
Iter: 2439 loss: 6.27264626e-07
Iter: 2440 loss: 6.27213581e-07
Iter: 2441 loss: 6.278662e-07
Iter: 2442 loss: 6.27212557e-07
Iter: 2443 loss: 6.2715111e-07
Iter: 2444 loss: 6.2705e-07
Iter: 2445 loss: 6.27059876e-07
Iter: 2446 loss: 6.26976032e-07
Iter: 2447 loss: 6.26936071e-07
Iter: 2448 loss: 6.26936526e-07
Iter: 2449 loss: 6.26955682e-07
Iter: 2450 loss: 6.26886958e-07
Iter: 2451 loss: 6.26833923e-07
Iter: 2452 loss: 6.26717906e-07
Iter: 2453 loss: 6.26711e-07
Iter: 2454 loss: 6.26649069e-07
Iter: 2455 loss: 6.2665606e-07
Iter: 2456 loss: 6.26605811e-07
Iter: 2457 loss: 6.26589099e-07
Iter: 2458 loss: 6.26547035e-07
Iter: 2459 loss: 6.26457734e-07
Iter: 2460 loss: 6.26619624e-07
Iter: 2461 loss: 6.26443239e-07
Iter: 2462 loss: 6.26299936e-07
Iter: 2463 loss: 6.26347514e-07
Iter: 2464 loss: 6.26318865e-07
Iter: 2465 loss: 6.26134806e-07
Iter: 2466 loss: 6.27744612e-07
Iter: 2467 loss: 6.26157714e-07
Iter: 2468 loss: 6.26048745e-07
Iter: 2469 loss: 6.26823237e-07
Iter: 2470 loss: 6.26047154e-07
Iter: 2471 loss: 6.25997131e-07
Iter: 2472 loss: 6.25905272e-07
Iter: 2473 loss: 6.26522819e-07
Iter: 2474 loss: 6.25883331e-07
Iter: 2475 loss: 6.25730877e-07
Iter: 2476 loss: 6.27000077e-07
Iter: 2477 loss: 6.25770895e-07
Iter: 2478 loss: 6.25708708e-07
Iter: 2479 loss: 6.25804262e-07
Iter: 2480 loss: 6.25668235e-07
Iter: 2481 loss: 6.25605935e-07
Iter: 2482 loss: 6.25804205e-07
Iter: 2483 loss: 6.25601842e-07
Iter: 2484 loss: 6.25524081e-07
Iter: 2485 loss: 6.25667326e-07
Iter: 2486 loss: 6.25509927e-07
Iter: 2487 loss: 6.2539209e-07
Iter: 2488 loss: 6.25351447e-07
Iter: 2489 loss: 6.25349344e-07
Iter: 2490 loss: 6.25271696e-07
Iter: 2491 loss: 6.25274311e-07
Iter: 2492 loss: 6.25220764e-07
Iter: 2493 loss: 6.25248958e-07
Iter: 2494 loss: 6.25186544e-07
Iter: 2495 loss: 6.25090877e-07
Iter: 2496 loss: 6.25373673e-07
Iter: 2497 loss: 6.25072289e-07
Iter: 2498 loss: 6.25007715e-07
Iter: 2499 loss: 6.24981112e-07
Iter: 2500 loss: 6.24948257e-07
Iter: 2501 loss: 6.24881636e-07
Iter: 2502 loss: 6.24882603e-07
Iter: 2503 loss: 6.24833547e-07
Iter: 2504 loss: 6.2485833e-07
Iter: 2505 loss: 6.2482377e-07
Iter: 2506 loss: 6.24755501e-07
Iter: 2507 loss: 6.24682229e-07
Iter: 2508 loss: 6.2622712e-07
Iter: 2509 loss: 6.24674385e-07
Iter: 2510 loss: 6.24527843e-07
Iter: 2511 loss: 6.25215932e-07
Iter: 2512 loss: 6.2453887e-07
Iter: 2513 loss: 6.24484187e-07
Iter: 2514 loss: 6.25012433e-07
Iter: 2515 loss: 6.24482e-07
Iter: 2516 loss: 6.24406255e-07
Iter: 2517 loss: 6.24290465e-07
Iter: 2518 loss: 6.24296035e-07
Iter: 2519 loss: 6.24175357e-07
Iter: 2520 loss: 6.25211214e-07
Iter: 2521 loss: 6.24153927e-07
Iter: 2522 loss: 6.24069799e-07
Iter: 2523 loss: 6.23995561e-07
Iter: 2524 loss: 6.23996129e-07
Iter: 2525 loss: 6.23977314e-07
Iter: 2526 loss: 6.23951337e-07
Iter: 2527 loss: 6.2387096e-07
Iter: 2528 loss: 6.23912342e-07
Iter: 2529 loss: 6.2383549e-07
Iter: 2530 loss: 6.23794335e-07
Iter: 2531 loss: 6.23765857e-07
Iter: 2532 loss: 6.23716687e-07
Iter: 2533 loss: 6.23628694e-07
Iter: 2534 loss: 6.23662459e-07
Iter: 2535 loss: 6.23581229e-07
Iter: 2536 loss: 6.23515291e-07
Iter: 2537 loss: 6.23522e-07
Iter: 2538 loss: 6.23404674e-07
Iter: 2539 loss: 6.23440428e-07
Iter: 2540 loss: 6.23367839e-07
Iter: 2541 loss: 6.23342032e-07
Iter: 2542 loss: 6.23227493e-07
Iter: 2543 loss: 6.24346114e-07
Iter: 2544 loss: 6.23242386e-07
Iter: 2545 loss: 6.23172866e-07
Iter: 2546 loss: 6.23814969e-07
Iter: 2547 loss: 6.23177698e-07
Iter: 2548 loss: 6.23149788e-07
Iter: 2549 loss: 6.23129552e-07
Iter: 2550 loss: 6.23081e-07
Iter: 2551 loss: 6.22981077e-07
Iter: 2552 loss: 6.2326194e-07
Iter: 2553 loss: 6.22940718e-07
Iter: 2554 loss: 6.22863581e-07
Iter: 2555 loss: 6.2329616e-07
Iter: 2556 loss: 6.22867447e-07
Iter: 2557 loss: 6.2277428e-07
Iter: 2558 loss: 6.2331992e-07
Iter: 2559 loss: 6.22759558e-07
Iter: 2560 loss: 6.2271306e-07
Iter: 2561 loss: 6.22650532e-07
Iter: 2562 loss: 6.22656e-07
Iter: 2563 loss: 6.22526727e-07
Iter: 2564 loss: 6.23621361e-07
Iter: 2565 loss: 6.22568564e-07
Iter: 2566 loss: 6.22488187e-07
Iter: 2567 loss: 6.2266929e-07
Iter: 2568 loss: 6.22471077e-07
Iter: 2569 loss: 6.2245249e-07
Iter: 2570 loss: 6.22432481e-07
Iter: 2571 loss: 6.22372e-07
Iter: 2572 loss: 6.22310154e-07
Iter: 2573 loss: 6.22984771e-07
Iter: 2574 loss: 6.22326468e-07
Iter: 2575 loss: 6.22239099e-07
Iter: 2576 loss: 6.22229379e-07
Iter: 2577 loss: 6.22198058e-07
Iter: 2578 loss: 6.22114214e-07
Iter: 2579 loss: 6.22148605e-07
Iter: 2580 loss: 6.22094149e-07
Iter: 2581 loss: 6.22026221e-07
Iter: 2582 loss: 6.22362506e-07
Iter: 2583 loss: 6.22023947e-07
Iter: 2584 loss: 6.22008088e-07
Iter: 2585 loss: 6.21899346e-07
Iter: 2586 loss: 6.21870186e-07
Iter: 2587 loss: 6.21720687e-07
Iter: 2588 loss: 6.22416565e-07
Iter: 2589 loss: 6.21775939e-07
Iter: 2590 loss: 6.21642471e-07
Iter: 2591 loss: 6.21647871e-07
Iter: 2592 loss: 6.21589834e-07
Iter: 2593 loss: 6.21426352e-07
Iter: 2594 loss: 6.22697712e-07
Iter: 2595 loss: 6.21427091e-07
Iter: 2596 loss: 6.21323579e-07
Iter: 2597 loss: 6.21506899e-07
Iter: 2598 loss: 6.21286802e-07
Iter: 2599 loss: 6.21229e-07
Iter: 2600 loss: 6.21173342e-07
Iter: 2601 loss: 6.21135541e-07
Iter: 2602 loss: 6.21061361e-07
Iter: 2603 loss: 6.21056188e-07
Iter: 2604 loss: 6.21002187e-07
Iter: 2605 loss: 6.21286347e-07
Iter: 2606 loss: 6.21004403e-07
Iter: 2607 loss: 6.20933065e-07
Iter: 2608 loss: 6.20869059e-07
Iter: 2609 loss: 6.20858373e-07
Iter: 2610 loss: 6.2078891e-07
Iter: 2611 loss: 6.20976891e-07
Iter: 2612 loss: 6.20748324e-07
Iter: 2613 loss: 6.20697563e-07
Iter: 2614 loss: 6.20907258e-07
Iter: 2615 loss: 6.20669312e-07
Iter: 2616 loss: 6.20572678e-07
Iter: 2617 loss: 6.2054886e-07
Iter: 2618 loss: 6.20506853e-07
Iter: 2619 loss: 6.2045126e-07
Iter: 2620 loss: 6.21034587e-07
Iter: 2621 loss: 6.20404876e-07
Iter: 2622 loss: 6.2031944e-07
Iter: 2623 loss: 6.20321657e-07
Iter: 2624 loss: 6.20285732e-07
Iter: 2625 loss: 6.20174774e-07
Iter: 2626 loss: 6.20863489e-07
Iter: 2627 loss: 6.20156356e-07
Iter: 2628 loss: 6.20055175e-07
Iter: 2629 loss: 6.20181311e-07
Iter: 2630 loss: 6.19996854e-07
Iter: 2631 loss: 6.19896127e-07
Iter: 2632 loss: 6.20356559e-07
Iter: 2633 loss: 6.19837692e-07
Iter: 2634 loss: 6.19763625e-07
Iter: 2635 loss: 6.19799948e-07
Iter: 2636 loss: 6.19728326e-07
Iter: 2637 loss: 6.19622824e-07
Iter: 2638 loss: 6.20964727e-07
Iter: 2639 loss: 6.1962885e-07
Iter: 2640 loss: 6.19557511e-07
Iter: 2641 loss: 6.20397941e-07
Iter: 2642 loss: 6.19572688e-07
Iter: 2643 loss: 6.19553362e-07
Iter: 2644 loss: 6.19516811e-07
Iter: 2645 loss: 6.19464913e-07
Iter: 2646 loss: 6.19434047e-07
Iter: 2647 loss: 6.19465e-07
Iter: 2648 loss: 6.19362936e-07
Iter: 2649 loss: 6.19279376e-07
Iter: 2650 loss: 6.19305126e-07
Iter: 2651 loss: 6.19258458e-07
Iter: 2652 loss: 6.19142838e-07
Iter: 2653 loss: 6.19859e-07
Iter: 2654 loss: 6.1916262e-07
Iter: 2655 loss: 6.19104412e-07
Iter: 2656 loss: 6.19197465e-07
Iter: 2657 loss: 6.19059733e-07
Iter: 2658 loss: 6.19006073e-07
Iter: 2659 loss: 6.18989816e-07
Iter: 2660 loss: 6.18927572e-07
Iter: 2661 loss: 6.18877607e-07
Iter: 2662 loss: 6.19413413e-07
Iter: 2663 loss: 6.18846059e-07
Iter: 2664 loss: 6.18791773e-07
Iter: 2665 loss: 6.18844524e-07
Iter: 2666 loss: 6.18758861e-07
Iter: 2667 loss: 6.18699289e-07
Iter: 2668 loss: 6.19103218e-07
Iter: 2669 loss: 6.18675813e-07
Iter: 2670 loss: 6.18590775e-07
Iter: 2671 loss: 6.18915692e-07
Iter: 2672 loss: 6.1861823e-07
Iter: 2673 loss: 6.18556442e-07
Iter: 2674 loss: 6.19079401e-07
Iter: 2675 loss: 6.18539389e-07
Iter: 2676 loss: 6.18497666e-07
Iter: 2677 loss: 6.18577815e-07
Iter: 2678 loss: 6.18513639e-07
Iter: 2679 loss: 6.18436957e-07
Iter: 2680 loss: 6.18426498e-07
Iter: 2681 loss: 6.19158413e-07
Iter: 2682 loss: 6.1838989e-07
Iter: 2683 loss: 6.18307922e-07
Iter: 2684 loss: 6.1902756e-07
Iter: 2685 loss: 6.18295473e-07
Iter: 2686 loss: 6.18216632e-07
Iter: 2687 loss: 6.18437525e-07
Iter: 2688 loss: 6.18245735e-07
Iter: 2689 loss: 6.18211402e-07
Iter: 2690 loss: 6.18326e-07
Iter: 2691 loss: 6.18174681e-07
Iter: 2692 loss: 6.18088336e-07
Iter: 2693 loss: 6.18008e-07
Iter: 2694 loss: 6.18039223e-07
Iter: 2695 loss: 6.18009267e-07
Iter: 2696 loss: 6.17969704e-07
Iter: 2697 loss: 6.17988348e-07
Iter: 2698 loss: 6.17961632e-07
Iter: 2699 loss: 6.17968226e-07
Iter: 2700 loss: 6.17938099e-07
Iter: 2701 loss: 6.17959699e-07
Iter: 2702 loss: 6.17941396e-07
Iter: 2703 loss: 6.17949922e-07
Iter: 2704 loss: 6.17975104e-07
Iter: 2705 loss: 6.17959131e-07
Iter: 2706 loss: 6.17959699e-07
Iter: 2707 loss: 6.17962655e-07
Iter: 2708 loss: 6.17955379e-07
Iter: 2709 loss: 6.17969192e-07
Iter: 2710 loss: 6.1796618e-07
Iter: 2711 loss: 6.17965156e-07
Iter: 2712 loss: 6.1796743e-07
Iter: 2713 loss: 6.17967203e-07
Iter: 2714 loss: 6.17970613e-07
Iter: 2715 loss: 6.1796834e-07
Iter: 2716 loss: 6.17971068e-07
Iter: 2717 loss: 6.17968908e-07
Iter: 2718 loss: 6.17970841e-07
Iter: 2719 loss: 6.17970841e-07
Iter: 2720 loss: 6.17970272e-07
Iter: 2721 loss: 6.17970841e-07
Iter: 2722 loss: 6.17970272e-07
Iter: 2723 loss: 6.17827766e-07
Iter: 2724 loss: 6.18869308e-07
Iter: 2725 loss: 6.17818614e-07
Iter: 2726 loss: 6.17734e-07
Iter: 2727 loss: 6.17888077e-07
Iter: 2728 loss: 6.17672526e-07
Iter: 2729 loss: 6.17569526e-07
Iter: 2730 loss: 6.18551667e-07
Iter: 2731 loss: 6.17555202e-07
Iter: 2732 loss: 6.17538262e-07
Iter: 2733 loss: 6.17566116e-07
Iter: 2734 loss: 6.17529849e-07
Iter: 2735 loss: 6.17532294e-07
Iter: 2736 loss: 6.1752786e-07
Iter: 2737 loss: 6.17515298e-07
Iter: 2738 loss: 6.17552928e-07
Iter: 2739 loss: 6.17534852e-07
Iter: 2740 loss: 6.17542582e-07
Iter: 2741 loss: 6.17548039e-07
Iter: 2742 loss: 6.17544742e-07
Iter: 2743 loss: 6.17559294e-07
Iter: 2744 loss: 6.17546846e-07
Iter: 2745 loss: 6.17549745e-07
Iter: 2746 loss: 6.17553724e-07
Iter: 2747 loss: 6.17544629e-07
Iter: 2748 loss: 6.17542753e-07
Iter: 2749 loss: 6.17553269e-07
Iter: 2750 loss: 6.17554178e-07
Iter: 2751 loss: 6.17556907e-07
Iter: 2752 loss: 6.17558158e-07
Iter: 2753 loss: 6.17552587e-07
Iter: 2754 loss: 6.17556509e-07
Iter: 2755 loss: 6.17555543e-07
Iter: 2756 loss: 6.17556111e-07
Iter: 2757 loss: 6.17555543e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 3 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_8000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff634234598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff634239840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff634234488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6617819d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff63426fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff63426f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6341d57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff63418e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff63418e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff63416bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff63416b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff634125f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff63413d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6341001e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6340ce620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff63414ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6340c68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff634027f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff63415e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff634027048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff620601378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff620633268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff620601b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff620607bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6205a46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff620540ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff62057d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff620540268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6205020d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6204d50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff620505400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff62044b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff62044b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff62049fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff620414268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6203c9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.65825827e-06
Iter: 2 loss: 3.44468071e-06
Iter: 3 loss: 2.83305576e-06
Iter: 4 loss: 2.3242535e-06
Iter: 5 loss: 4.10557277e-06
Iter: 6 loss: 2.19230083e-06
Iter: 7 loss: 2.04089338e-06
Iter: 8 loss: 1.76903973e-06
Iter: 9 loss: 8.42508e-06
Iter: 10 loss: 1.7689888e-06
Iter: 11 loss: 1.60128116e-06
Iter: 12 loss: 1.59096635e-06
Iter: 13 loss: 1.5425386e-06
Iter: 14 loss: 1.58799367e-06
Iter: 15 loss: 1.51471204e-06
Iter: 16 loss: 1.45514559e-06
Iter: 17 loss: 1.45573426e-06
Iter: 18 loss: 1.40767315e-06
Iter: 19 loss: 1.3613942e-06
Iter: 20 loss: 1.97119743e-06
Iter: 21 loss: 1.36113249e-06
Iter: 22 loss: 1.31781633e-06
Iter: 23 loss: 1.33718186e-06
Iter: 24 loss: 1.28834836e-06
Iter: 25 loss: 1.26140355e-06
Iter: 26 loss: 1.26113173e-06
Iter: 27 loss: 1.25080851e-06
Iter: 28 loss: 1.24362396e-06
Iter: 29 loss: 1.2399405e-06
Iter: 30 loss: 1.21832932e-06
Iter: 31 loss: 1.24455255e-06
Iter: 32 loss: 1.20705067e-06
Iter: 33 loss: 1.18906746e-06
Iter: 34 loss: 1.1781907e-06
Iter: 35 loss: 1.17085551e-06
Iter: 36 loss: 1.16137437e-06
Iter: 37 loss: 1.15724197e-06
Iter: 38 loss: 1.14778459e-06
Iter: 39 loss: 1.14777822e-06
Iter: 40 loss: 1.14215061e-06
Iter: 41 loss: 1.12721659e-06
Iter: 42 loss: 1.23306734e-06
Iter: 43 loss: 1.12394036e-06
Iter: 44 loss: 1.11494273e-06
Iter: 45 loss: 1.17631021e-06
Iter: 46 loss: 1.11407633e-06
Iter: 47 loss: 1.10363135e-06
Iter: 48 loss: 1.12175348e-06
Iter: 49 loss: 1.09896644e-06
Iter: 50 loss: 1.09005009e-06
Iter: 51 loss: 1.14528757e-06
Iter: 52 loss: 1.08889526e-06
Iter: 53 loss: 1.0842773e-06
Iter: 54 loss: 1.07757717e-06
Iter: 55 loss: 1.0773482e-06
Iter: 56 loss: 1.07504979e-06
Iter: 57 loss: 1.07354754e-06
Iter: 58 loss: 1.0711467e-06
Iter: 59 loss: 1.07225901e-06
Iter: 60 loss: 1.06948914e-06
Iter: 61 loss: 1.06539073e-06
Iter: 62 loss: 1.06375489e-06
Iter: 63 loss: 1.06149616e-06
Iter: 64 loss: 1.05794811e-06
Iter: 65 loss: 1.09794371e-06
Iter: 66 loss: 1.05787092e-06
Iter: 67 loss: 1.05417917e-06
Iter: 68 loss: 1.04827245e-06
Iter: 69 loss: 1.04824881e-06
Iter: 70 loss: 1.04269452e-06
Iter: 71 loss: 1.06354673e-06
Iter: 72 loss: 1.04130186e-06
Iter: 73 loss: 1.03477305e-06
Iter: 74 loss: 1.06458526e-06
Iter: 75 loss: 1.0335873e-06
Iter: 76 loss: 1.03655884e-06
Iter: 77 loss: 1.03255684e-06
Iter: 78 loss: 1.03149046e-06
Iter: 79 loss: 1.02816284e-06
Iter: 80 loss: 1.03431216e-06
Iter: 81 loss: 1.02600211e-06
Iter: 82 loss: 1.02176614e-06
Iter: 83 loss: 1.05950858e-06
Iter: 84 loss: 1.02153433e-06
Iter: 85 loss: 1.01980231e-06
Iter: 86 loss: 1.02061279e-06
Iter: 87 loss: 1.01868886e-06
Iter: 88 loss: 1.01533442e-06
Iter: 89 loss: 1.0254e-06
Iter: 90 loss: 1.01430942e-06
Iter: 91 loss: 1.01273099e-06
Iter: 92 loss: 1.01287526e-06
Iter: 93 loss: 1.011476e-06
Iter: 94 loss: 1.00906175e-06
Iter: 95 loss: 1.02761646e-06
Iter: 96 loss: 1.00890281e-06
Iter: 97 loss: 1.00739021e-06
Iter: 98 loss: 1.0105382e-06
Iter: 99 loss: 1.00677505e-06
Iter: 100 loss: 1.00485454e-06
Iter: 101 loss: 1.00223792e-06
Iter: 102 loss: 1.00209434e-06
Iter: 103 loss: 1.00066472e-06
Iter: 104 loss: 1.00041e-06
Iter: 105 loss: 9.9920976e-07
Iter: 106 loss: 9.96547669e-07
Iter: 107 loss: 1.03603281e-06
Iter: 108 loss: 9.96456833e-07
Iter: 109 loss: 9.94980155e-07
Iter: 110 loss: 9.94882839e-07
Iter: 111 loss: 9.93989374e-07
Iter: 112 loss: 1.00643342e-06
Iter: 113 loss: 9.93974368e-07
Iter: 114 loss: 9.9283e-07
Iter: 115 loss: 9.90978833e-07
Iter: 116 loss: 9.90977924e-07
Iter: 117 loss: 9.89610498e-07
Iter: 118 loss: 9.89345835e-07
Iter: 119 loss: 9.88487614e-07
Iter: 120 loss: 9.8616124e-07
Iter: 121 loss: 9.86063469e-07
Iter: 122 loss: 9.8425744e-07
Iter: 123 loss: 9.82188112e-07
Iter: 124 loss: 9.9369322e-07
Iter: 125 loss: 9.81889912e-07
Iter: 126 loss: 9.79652896e-07
Iter: 127 loss: 9.97725e-07
Iter: 128 loss: 9.7953523e-07
Iter: 129 loss: 9.78542403e-07
Iter: 130 loss: 9.79157448e-07
Iter: 131 loss: 9.77938271e-07
Iter: 132 loss: 9.7650809e-07
Iter: 133 loss: 9.75128614e-07
Iter: 134 loss: 9.74773911e-07
Iter: 135 loss: 9.73130454e-07
Iter: 136 loss: 9.85033921e-07
Iter: 137 loss: 9.73023134e-07
Iter: 138 loss: 9.71331474e-07
Iter: 139 loss: 9.77097e-07
Iter: 140 loss: 9.70891733e-07
Iter: 141 loss: 9.69990197e-07
Iter: 142 loss: 9.80067284e-07
Iter: 143 loss: 9.69990879e-07
Iter: 144 loss: 9.69131406e-07
Iter: 145 loss: 9.67737378e-07
Iter: 146 loss: 9.67791607e-07
Iter: 147 loss: 9.67609139e-07
Iter: 148 loss: 9.67215897e-07
Iter: 149 loss: 9.66787638e-07
Iter: 150 loss: 9.70144e-07
Iter: 151 loss: 9.66746711e-07
Iter: 152 loss: 9.66509788e-07
Iter: 153 loss: 9.65648269e-07
Iter: 154 loss: 9.67583787e-07
Iter: 155 loss: 9.65108e-07
Iter: 156 loss: 9.63773346e-07
Iter: 157 loss: 9.72009275e-07
Iter: 158 loss: 9.63676484e-07
Iter: 159 loss: 9.62523472e-07
Iter: 160 loss: 9.60129e-07
Iter: 161 loss: 1.00066882e-06
Iter: 162 loss: 9.60110128e-07
Iter: 163 loss: 9.60935381e-07
Iter: 164 loss: 9.59292e-07
Iter: 165 loss: 9.58535e-07
Iter: 166 loss: 9.58034548e-07
Iter: 167 loss: 9.57804446e-07
Iter: 168 loss: 9.56571625e-07
Iter: 169 loss: 9.60075226e-07
Iter: 170 loss: 9.5621e-07
Iter: 171 loss: 9.55475116e-07
Iter: 172 loss: 9.54871552e-07
Iter: 173 loss: 9.546809e-07
Iter: 174 loss: 9.53388849e-07
Iter: 175 loss: 9.69054781e-07
Iter: 176 loss: 9.53405674e-07
Iter: 177 loss: 9.52824735e-07
Iter: 178 loss: 9.53785275e-07
Iter: 179 loss: 9.52580876e-07
Iter: 180 loss: 9.517845e-07
Iter: 181 loss: 9.53784934e-07
Iter: 182 loss: 9.51494826e-07
Iter: 183 loss: 9.5101251e-07
Iter: 184 loss: 9.56213285e-07
Iter: 185 loss: 9.51026323e-07
Iter: 186 loss: 9.50528261e-07
Iter: 187 loss: 9.5264096e-07
Iter: 188 loss: 9.50441404e-07
Iter: 189 loss: 9.50024912e-07
Iter: 190 loss: 9.49008722e-07
Iter: 191 loss: 9.58297733e-07
Iter: 192 loss: 9.48861043e-07
Iter: 193 loss: 9.48018737e-07
Iter: 194 loss: 9.5318569e-07
Iter: 195 loss: 9.47924718e-07
Iter: 196 loss: 9.47022102e-07
Iter: 197 loss: 9.46497153e-07
Iter: 198 loss: 9.46115051e-07
Iter: 199 loss: 9.44985061e-07
Iter: 200 loss: 9.44589715e-07
Iter: 201 loss: 9.43962277e-07
Iter: 202 loss: 9.43407429e-07
Iter: 203 loss: 9.4299412e-07
Iter: 204 loss: 9.42339057e-07
Iter: 205 loss: 9.43024702e-07
Iter: 206 loss: 9.41965936e-07
Iter: 207 loss: 9.41057692e-07
Iter: 208 loss: 9.40111192e-07
Iter: 209 loss: 9.3996249e-07
Iter: 210 loss: 9.39095571e-07
Iter: 211 loss: 9.45909278e-07
Iter: 212 loss: 9.39009e-07
Iter: 213 loss: 9.38108883e-07
Iter: 214 loss: 9.39541906e-07
Iter: 215 loss: 9.37674713e-07
Iter: 216 loss: 9.37180857e-07
Iter: 217 loss: 9.4218467e-07
Iter: 218 loss: 9.37164714e-07
Iter: 219 loss: 9.36789718e-07
Iter: 220 loss: 9.40683e-07
Iter: 221 loss: 9.36757374e-07
Iter: 222 loss: 9.36330366e-07
Iter: 223 loss: 9.3742949e-07
Iter: 224 loss: 9.3614517e-07
Iter: 225 loss: 9.35901312e-07
Iter: 226 loss: 9.35877608e-07
Iter: 227 loss: 9.35694231e-07
Iter: 228 loss: 9.35316791e-07
Iter: 229 loss: 9.3442145e-07
Iter: 230 loss: 9.45448051e-07
Iter: 231 loss: 9.34349089e-07
Iter: 232 loss: 9.33648778e-07
Iter: 233 loss: 9.33597335e-07
Iter: 234 loss: 9.3313713e-07
Iter: 235 loss: 9.3224071e-07
Iter: 236 loss: 9.50256094e-07
Iter: 237 loss: 9.32272314e-07
Iter: 238 loss: 9.31691602e-07
Iter: 239 loss: 9.3167057e-07
Iter: 240 loss: 9.31173531e-07
Iter: 241 loss: 9.31613897e-07
Iter: 242 loss: 9.30877661e-07
Iter: 243 loss: 9.3040569e-07
Iter: 244 loss: 9.30431213e-07
Iter: 245 loss: 9.30134092e-07
Iter: 246 loss: 9.29592602e-07
Iter: 247 loss: 9.29622502e-07
Iter: 248 loss: 9.28861255e-07
Iter: 249 loss: 9.30962869e-07
Iter: 250 loss: 9.28639565e-07
Iter: 251 loss: 9.2816839e-07
Iter: 252 loss: 9.28005647e-07
Iter: 253 loss: 9.27758094e-07
Iter: 254 loss: 9.27989618e-07
Iter: 255 loss: 9.27503e-07
Iter: 256 loss: 9.27261794e-07
Iter: 257 loss: 9.26870712e-07
Iter: 258 loss: 9.26869234e-07
Iter: 259 loss: 9.2649168e-07
Iter: 260 loss: 9.2591074e-07
Iter: 261 loss: 9.25912e-07
Iter: 262 loss: 9.25182519e-07
Iter: 263 loss: 9.33995409e-07
Iter: 264 loss: 9.25144434e-07
Iter: 265 loss: 9.24820483e-07
Iter: 266 loss: 9.24129154e-07
Iter: 267 loss: 9.38217681e-07
Iter: 268 loss: 9.24102835e-07
Iter: 269 loss: 9.23314701e-07
Iter: 270 loss: 9.31277441e-07
Iter: 271 loss: 9.23255129e-07
Iter: 272 loss: 9.22776167e-07
Iter: 273 loss: 9.22458753e-07
Iter: 274 loss: 9.22197842e-07
Iter: 275 loss: 9.21584729e-07
Iter: 276 loss: 9.21579385e-07
Iter: 277 loss: 9.21159199e-07
Iter: 278 loss: 9.21978085e-07
Iter: 279 loss: 9.20998673e-07
Iter: 280 loss: 9.20353614e-07
Iter: 281 loss: 9.21487e-07
Iter: 282 loss: 9.20065e-07
Iter: 283 loss: 9.19574177e-07
Iter: 284 loss: 9.21953074e-07
Iter: 285 loss: 9.19470835e-07
Iter: 286 loss: 9.19077308e-07
Iter: 287 loss: 9.19019612e-07
Iter: 288 loss: 9.18781097e-07
Iter: 289 loss: 9.18680144e-07
Iter: 290 loss: 9.18432761e-07
Iter: 291 loss: 9.1833067e-07
Iter: 292 loss: 9.17988757e-07
Iter: 293 loss: 9.18412411e-07
Iter: 294 loss: 9.17744387e-07
Iter: 295 loss: 9.17101488e-07
Iter: 296 loss: 9.20849061e-07
Iter: 297 loss: 9.17040097e-07
Iter: 298 loss: 9.1659723e-07
Iter: 299 loss: 9.19190029e-07
Iter: 300 loss: 9.16584156e-07
Iter: 301 loss: 9.16155e-07
Iter: 302 loss: 9.15349688e-07
Iter: 303 loss: 9.15364694e-07
Iter: 304 loss: 9.14814223e-07
Iter: 305 loss: 9.19654099e-07
Iter: 306 loss: 9.14790121e-07
Iter: 307 loss: 9.14342479e-07
Iter: 308 loss: 9.14587361e-07
Iter: 309 loss: 9.13999372e-07
Iter: 310 loss: 9.13564e-07
Iter: 311 loss: 9.16049e-07
Iter: 312 loss: 9.13469307e-07
Iter: 313 loss: 9.12940095e-07
Iter: 314 loss: 9.149486e-07
Iter: 315 loss: 9.12773544e-07
Iter: 316 loss: 9.1239167e-07
Iter: 317 loss: 9.16113663e-07
Iter: 318 loss: 9.12343921e-07
Iter: 319 loss: 9.12127575e-07
Iter: 320 loss: 9.11507641e-07
Iter: 321 loss: 9.1692084e-07
Iter: 322 loss: 9.11387588e-07
Iter: 323 loss: 9.12014343e-07
Iter: 324 loss: 9.11145378e-07
Iter: 325 loss: 9.10941367e-07
Iter: 326 loss: 9.10930339e-07
Iter: 327 loss: 9.10778965e-07
Iter: 328 loss: 9.10532549e-07
Iter: 329 loss: 9.09858e-07
Iter: 330 loss: 9.1567415e-07
Iter: 331 loss: 9.09790117e-07
Iter: 332 loss: 9.09161031e-07
Iter: 333 loss: 9.16404474e-07
Iter: 334 loss: 9.0914574e-07
Iter: 335 loss: 9.08666152e-07
Iter: 336 loss: 9.08862944e-07
Iter: 337 loss: 9.08289167e-07
Iter: 338 loss: 9.07908316e-07
Iter: 339 loss: 9.07930371e-07
Iter: 340 loss: 9.0767071e-07
Iter: 341 loss: 9.07185949e-07
Iter: 342 loss: 9.15962517e-07
Iter: 343 loss: 9.07159233e-07
Iter: 344 loss: 9.06604157e-07
Iter: 345 loss: 9.0880468e-07
Iter: 346 loss: 9.06504056e-07
Iter: 347 loss: 9.06006335e-07
Iter: 348 loss: 9.07260642e-07
Iter: 349 loss: 9.0589333e-07
Iter: 350 loss: 9.05554202e-07
Iter: 351 loss: 9.0981132e-07
Iter: 352 loss: 9.05577053e-07
Iter: 353 loss: 9.05288402e-07
Iter: 354 loss: 9.05228319e-07
Iter: 355 loss: 9.05070692e-07
Iter: 356 loss: 9.04562e-07
Iter: 357 loss: 9.0425624e-07
Iter: 358 loss: 9.04051376e-07
Iter: 359 loss: 9.04341903e-07
Iter: 360 loss: 9.03808655e-07
Iter: 361 loss: 9.03577757e-07
Iter: 362 loss: 9.03286207e-07
Iter: 363 loss: 9.03251e-07
Iter: 364 loss: 9.02896659e-07
Iter: 365 loss: 9.02069e-07
Iter: 366 loss: 9.15715304e-07
Iter: 367 loss: 9.02033094e-07
Iter: 368 loss: 9.01551459e-07
Iter: 369 loss: 9.01535486e-07
Iter: 370 loss: 9.01247859e-07
Iter: 371 loss: 9.00806299e-07
Iter: 372 loss: 9.00792315e-07
Iter: 373 loss: 9.00454268e-07
Iter: 374 loss: 9.00423117e-07
Iter: 375 loss: 9.00218e-07
Iter: 376 loss: 8.99911242e-07
Iter: 377 loss: 8.99923293e-07
Iter: 378 loss: 8.99391239e-07
Iter: 379 loss: 9.00365364e-07
Iter: 380 loss: 8.99226961e-07
Iter: 381 loss: 8.9885e-07
Iter: 382 loss: 9.00161467e-07
Iter: 383 loss: 8.98727535e-07
Iter: 384 loss: 8.98435246e-07
Iter: 385 loss: 9.00955968e-07
Iter: 386 loss: 8.98370615e-07
Iter: 387 loss: 8.98068663e-07
Iter: 388 loss: 8.9833668e-07
Iter: 389 loss: 8.97871871e-07
Iter: 390 loss: 8.97451571e-07
Iter: 391 loss: 8.98275289e-07
Iter: 392 loss: 8.97299287e-07
Iter: 393 loss: 8.97239602e-07
Iter: 394 loss: 8.97096527e-07
Iter: 395 loss: 8.96950098e-07
Iter: 396 loss: 8.96580389e-07
Iter: 397 loss: 8.96179529e-07
Iter: 398 loss: 8.9601042e-07
Iter: 399 loss: 8.95396511e-07
Iter: 400 loss: 9.04988212e-07
Iter: 401 loss: 8.95382072e-07
Iter: 402 loss: 8.94956202e-07
Iter: 403 loss: 8.94912432e-07
Iter: 404 loss: 8.9460309e-07
Iter: 405 loss: 8.93982e-07
Iter: 406 loss: 8.9855007e-07
Iter: 407 loss: 8.93921765e-07
Iter: 408 loss: 8.93565243e-07
Iter: 409 loss: 8.95068411e-07
Iter: 410 loss: 8.93506353e-07
Iter: 411 loss: 8.93085598e-07
Iter: 412 loss: 8.9305297e-07
Iter: 413 loss: 8.92733567e-07
Iter: 414 loss: 8.92303433e-07
Iter: 415 loss: 8.93967353e-07
Iter: 416 loss: 8.92250966e-07
Iter: 417 loss: 8.91840045e-07
Iter: 418 loss: 8.91884156e-07
Iter: 419 loss: 8.91489151e-07
Iter: 420 loss: 8.91142406e-07
Iter: 421 loss: 8.95597225e-07
Iter: 422 loss: 8.91117224e-07
Iter: 423 loss: 8.90759168e-07
Iter: 424 loss: 8.90399122e-07
Iter: 425 loss: 8.90256729e-07
Iter: 426 loss: 8.90009233e-07
Iter: 427 loss: 8.89939372e-07
Iter: 428 loss: 8.89646117e-07
Iter: 429 loss: 8.90512e-07
Iter: 430 loss: 8.89546527e-07
Iter: 431 loss: 8.89352236e-07
Iter: 432 loss: 8.88815407e-07
Iter: 433 loss: 8.89924081e-07
Iter: 434 loss: 8.88500836e-07
Iter: 435 loss: 8.87983788e-07
Iter: 436 loss: 8.87971225e-07
Iter: 437 loss: 8.87484816e-07
Iter: 438 loss: 8.87062299e-07
Iter: 439 loss: 8.86999374e-07
Iter: 440 loss: 8.86507451e-07
Iter: 441 loss: 8.86495855e-07
Iter: 442 loss: 8.86090561e-07
Iter: 443 loss: 8.86341468e-07
Iter: 444 loss: 8.85835e-07
Iter: 445 loss: 8.85410884e-07
Iter: 446 loss: 8.88933812e-07
Iter: 447 loss: 8.85368365e-07
Iter: 448 loss: 8.85094e-07
Iter: 449 loss: 8.84894803e-07
Iter: 450 loss: 8.84793337e-07
Iter: 451 loss: 8.84359622e-07
Iter: 452 loss: 8.86789394e-07
Iter: 453 loss: 8.84282031e-07
Iter: 454 loss: 8.84090525e-07
Iter: 455 loss: 8.86104317e-07
Iter: 456 loss: 8.84082453e-07
Iter: 457 loss: 8.8385525e-07
Iter: 458 loss: 8.84091264e-07
Iter: 459 loss: 8.83752364e-07
Iter: 460 loss: 8.83656e-07
Iter: 461 loss: 8.83587518e-07
Iter: 462 loss: 8.83531868e-07
Iter: 463 loss: 8.83245775e-07
Iter: 464 loss: 8.84815e-07
Iter: 465 loss: 8.83162272e-07
Iter: 466 loss: 8.82799e-07
Iter: 467 loss: 8.83150733e-07
Iter: 468 loss: 8.8260856e-07
Iter: 469 loss: 8.82237e-07
Iter: 470 loss: 8.82087477e-07
Iter: 471 loss: 8.81856863e-07
Iter: 472 loss: 8.81471749e-07
Iter: 473 loss: 8.81429855e-07
Iter: 474 loss: 8.81109315e-07
Iter: 475 loss: 8.81156893e-07
Iter: 476 loss: 8.80843402e-07
Iter: 477 loss: 8.80484663e-07
Iter: 478 loss: 8.84668736e-07
Iter: 479 loss: 8.80480911e-07
Iter: 480 loss: 8.80227049e-07
Iter: 481 loss: 8.80432822e-07
Iter: 482 loss: 8.8002173e-07
Iter: 483 loss: 8.79638435e-07
Iter: 484 loss: 8.80599032e-07
Iter: 485 loss: 8.79482286e-07
Iter: 486 loss: 8.79208642e-07
Iter: 487 loss: 8.79777872e-07
Iter: 488 loss: 8.79084951e-07
Iter: 489 loss: 8.78585865e-07
Iter: 490 loss: 8.78879916e-07
Iter: 491 loss: 8.78322908e-07
Iter: 492 loss: 8.78171249e-07
Iter: 493 loss: 8.78003675e-07
Iter: 494 loss: 8.77844855e-07
Iter: 495 loss: 8.78443643e-07
Iter: 496 loss: 8.77796083e-07
Iter: 497 loss: 8.77664775e-07
Iter: 498 loss: 8.77265e-07
Iter: 499 loss: 8.80578e-07
Iter: 500 loss: 8.77242428e-07
Iter: 501 loss: 8.76881074e-07
Iter: 502 loss: 8.79092227e-07
Iter: 503 loss: 8.76825766e-07
Iter: 504 loss: 8.76537854e-07
Iter: 505 loss: 8.76730155e-07
Iter: 506 loss: 8.76399724e-07
Iter: 507 loss: 8.76109425e-07
Iter: 508 loss: 8.77149205e-07
Iter: 509 loss: 8.76010063e-07
Iter: 510 loss: 8.75661385e-07
Iter: 511 loss: 8.76287743e-07
Iter: 512 loss: 8.75544742e-07
Iter: 513 loss: 8.75268256e-07
Iter: 514 loss: 8.75993692e-07
Iter: 515 loss: 8.75211413e-07
Iter: 516 loss: 8.74873081e-07
Iter: 517 loss: 8.77066896e-07
Iter: 518 loss: 8.74811349e-07
Iter: 519 loss: 8.74579428e-07
Iter: 520 loss: 8.74687601e-07
Iter: 521 loss: 8.74421517e-07
Iter: 522 loss: 8.74036232e-07
Iter: 523 loss: 8.73996783e-07
Iter: 524 loss: 8.73720296e-07
Iter: 525 loss: 8.73497868e-07
Iter: 526 loss: 8.73455292e-07
Iter: 527 loss: 8.73246449e-07
Iter: 528 loss: 8.74379e-07
Iter: 529 loss: 8.73218e-07
Iter: 530 loss: 8.72995656e-07
Iter: 531 loss: 8.72635269e-07
Iter: 532 loss: 8.72624582e-07
Iter: 533 loss: 8.7225169e-07
Iter: 534 loss: 8.74203238e-07
Iter: 535 loss: 8.72220085e-07
Iter: 536 loss: 8.72008e-07
Iter: 537 loss: 8.71597308e-07
Iter: 538 loss: 8.7161925e-07
Iter: 539 loss: 8.71140401e-07
Iter: 540 loss: 8.75801675e-07
Iter: 541 loss: 8.71129771e-07
Iter: 542 loss: 8.7087875e-07
Iter: 543 loss: 8.71049963e-07
Iter: 544 loss: 8.70739086e-07
Iter: 545 loss: 8.70446115e-07
Iter: 546 loss: 8.71810869e-07
Iter: 547 loss: 8.70406e-07
Iter: 548 loss: 8.70088684e-07
Iter: 549 loss: 8.69980568e-07
Iter: 550 loss: 8.69880409e-07
Iter: 551 loss: 8.69588689e-07
Iter: 552 loss: 8.72764247e-07
Iter: 553 loss: 8.69558278e-07
Iter: 554 loss: 8.69304358e-07
Iter: 555 loss: 8.69583801e-07
Iter: 556 loss: 8.69186238e-07
Iter: 557 loss: 8.68844268e-07
Iter: 558 loss: 8.70823897e-07
Iter: 559 loss: 8.68796747e-07
Iter: 560 loss: 8.68579605e-07
Iter: 561 loss: 8.68216148e-07
Iter: 562 loss: 8.74904117e-07
Iter: 563 loss: 8.68217626e-07
Iter: 564 loss: 8.68017764e-07
Iter: 565 loss: 8.6782768e-07
Iter: 566 loss: 8.67664312e-07
Iter: 567 loss: 8.67571885e-07
Iter: 568 loss: 8.67503e-07
Iter: 569 loss: 8.67301424e-07
Iter: 570 loss: 8.67611732e-07
Iter: 571 loss: 8.67234576e-07
Iter: 572 loss: 8.66971e-07
Iter: 573 loss: 8.66882374e-07
Iter: 574 loss: 8.66738787e-07
Iter: 575 loss: 8.66478047e-07
Iter: 576 loss: 8.67899303e-07
Iter: 577 loss: 8.6645889e-07
Iter: 578 loss: 8.66241351e-07
Iter: 579 loss: 8.66184564e-07
Iter: 580 loss: 8.66028813e-07
Iter: 581 loss: 8.65794448e-07
Iter: 582 loss: 8.68849611e-07
Iter: 583 loss: 8.65788081e-07
Iter: 584 loss: 8.65636423e-07
Iter: 585 loss: 8.65459e-07
Iter: 586 loss: 8.65374943e-07
Iter: 587 loss: 8.64981871e-07
Iter: 588 loss: 8.66675e-07
Iter: 589 loss: 8.6492355e-07
Iter: 590 loss: 8.6467935e-07
Iter: 591 loss: 8.64708738e-07
Iter: 592 loss: 8.6453332e-07
Iter: 593 loss: 8.64178389e-07
Iter: 594 loss: 8.71649263e-07
Iter: 595 loss: 8.6418288e-07
Iter: 596 loss: 8.64026902e-07
Iter: 597 loss: 8.63993705e-07
Iter: 598 loss: 8.63730747e-07
Iter: 599 loss: 8.63798e-07
Iter: 600 loss: 8.63533728e-07
Iter: 601 loss: 8.63326e-07
Iter: 602 loss: 8.63748255e-07
Iter: 603 loss: 8.63230468e-07
Iter: 604 loss: 8.63031232e-07
Iter: 605 loss: 8.63745527e-07
Iter: 606 loss: 8.6302191e-07
Iter: 607 loss: 8.62808292e-07
Iter: 608 loss: 8.62421359e-07
Iter: 609 loss: 8.62431e-07
Iter: 610 loss: 8.62104287e-07
Iter: 611 loss: 8.65688776e-07
Iter: 612 loss: 8.62078423e-07
Iter: 613 loss: 8.61828084e-07
Iter: 614 loss: 8.61524313e-07
Iter: 615 loss: 8.61482306e-07
Iter: 616 loss: 8.61221167e-07
Iter: 617 loss: 8.61203603e-07
Iter: 618 loss: 8.6095082e-07
Iter: 619 loss: 8.60595094e-07
Iter: 620 loss: 8.60605383e-07
Iter: 621 loss: 8.60374371e-07
Iter: 622 loss: 8.63859213e-07
Iter: 623 loss: 8.60324064e-07
Iter: 624 loss: 8.60095724e-07
Iter: 625 loss: 8.6034504e-07
Iter: 626 loss: 8.59976e-07
Iter: 627 loss: 8.59701e-07
Iter: 628 loss: 8.60922114e-07
Iter: 629 loss: 8.59625629e-07
Iter: 630 loss: 8.59431e-07
Iter: 631 loss: 8.59076124e-07
Iter: 632 loss: 8.59082775e-07
Iter: 633 loss: 8.5968037e-07
Iter: 634 loss: 8.58939529e-07
Iter: 635 loss: 8.58903718e-07
Iter: 636 loss: 8.58714316e-07
Iter: 637 loss: 8.59896716e-07
Iter: 638 loss: 8.58689305e-07
Iter: 639 loss: 8.58416684e-07
Iter: 640 loss: 8.58415e-07
Iter: 641 loss: 8.58184876e-07
Iter: 642 loss: 8.58031797e-07
Iter: 643 loss: 8.60795353e-07
Iter: 644 loss: 8.58014914e-07
Iter: 645 loss: 8.57812267e-07
Iter: 646 loss: 8.57585746e-07
Iter: 647 loss: 8.57549537e-07
Iter: 648 loss: 8.57308692e-07
Iter: 649 loss: 8.5855595e-07
Iter: 650 loss: 8.57221835e-07
Iter: 651 loss: 8.56992301e-07
Iter: 652 loss: 8.56661643e-07
Iter: 653 loss: 8.566833e-07
Iter: 654 loss: 8.56375834e-07
Iter: 655 loss: 8.60273417e-07
Iter: 656 loss: 8.56367819e-07
Iter: 657 loss: 8.56091447e-07
Iter: 658 loss: 8.56846555e-07
Iter: 659 loss: 8.5602278e-07
Iter: 660 loss: 8.55793246e-07
Iter: 661 loss: 8.57421412e-07
Iter: 662 loss: 8.55788869e-07
Iter: 663 loss: 8.55528128e-07
Iter: 664 loss: 8.55425583e-07
Iter: 665 loss: 8.55337248e-07
Iter: 666 loss: 8.55095834e-07
Iter: 667 loss: 8.57593363e-07
Iter: 668 loss: 8.55043e-07
Iter: 669 loss: 8.54911605e-07
Iter: 670 loss: 8.55561382e-07
Iter: 671 loss: 8.54886196e-07
Iter: 672 loss: 8.54696111e-07
Iter: 673 loss: 8.54946848e-07
Iter: 674 loss: 8.54591235e-07
Iter: 675 loss: 8.54471068e-07
Iter: 676 loss: 8.54517964e-07
Iter: 677 loss: 8.54424e-07
Iter: 678 loss: 8.5430537e-07
Iter: 679 loss: 8.54006316e-07
Iter: 680 loss: 8.58751321e-07
Iter: 681 loss: 8.53995687e-07
Iter: 682 loss: 8.53850054e-07
Iter: 683 loss: 8.53765187e-07
Iter: 684 loss: 8.53675829e-07
Iter: 685 loss: 8.53542e-07
Iter: 686 loss: 8.53476195e-07
Iter: 687 loss: 8.53214601e-07
Iter: 688 loss: 8.53612335e-07
Iter: 689 loss: 8.5311575e-07
Iter: 690 loss: 8.52890537e-07
Iter: 691 loss: 8.53104325e-07
Iter: 692 loss: 8.52736889e-07
Iter: 693 loss: 8.52482e-07
Iter: 694 loss: 8.54490963e-07
Iter: 695 loss: 8.52451876e-07
Iter: 696 loss: 8.52243147e-07
Iter: 697 loss: 8.52745131e-07
Iter: 698 loss: 8.52205289e-07
Iter: 699 loss: 8.51948471e-07
Iter: 700 loss: 8.51999289e-07
Iter: 701 loss: 8.51783511e-07
Iter: 702 loss: 8.5159752e-07
Iter: 703 loss: 8.52718927e-07
Iter: 704 loss: 8.51543177e-07
Iter: 705 loss: 8.51364859e-07
Iter: 706 loss: 8.52699827e-07
Iter: 707 loss: 8.51404e-07
Iter: 708 loss: 8.51246909e-07
Iter: 709 loss: 8.51730761e-07
Iter: 710 loss: 8.51196319e-07
Iter: 711 loss: 8.51119466e-07
Iter: 712 loss: 8.51044774e-07
Iter: 713 loss: 8.51036532e-07
Iter: 714 loss: 8.50874926e-07
Iter: 715 loss: 8.50757033e-07
Iter: 716 loss: 8.50696e-07
Iter: 717 loss: 8.50553192e-07
Iter: 718 loss: 8.50543529e-07
Iter: 719 loss: 8.50406423e-07
Iter: 720 loss: 8.50254878e-07
Iter: 721 loss: 8.50219237e-07
Iter: 722 loss: 8.50019e-07
Iter: 723 loss: 8.50647382e-07
Iter: 724 loss: 8.49897333e-07
Iter: 725 loss: 8.49680532e-07
Iter: 726 loss: 8.49521598e-07
Iter: 727 loss: 8.49438379e-07
Iter: 728 loss: 8.49159846e-07
Iter: 729 loss: 8.53461756e-07
Iter: 730 loss: 8.49138246e-07
Iter: 731 loss: 8.48967375e-07
Iter: 732 loss: 8.49025469e-07
Iter: 733 loss: 8.4881367e-07
Iter: 734 loss: 8.4855958e-07
Iter: 735 loss: 8.50169499e-07
Iter: 736 loss: 8.48472212e-07
Iter: 737 loss: 8.48358e-07
Iter: 738 loss: 8.48374953e-07
Iter: 739 loss: 8.48262061e-07
Iter: 740 loss: 8.48091645e-07
Iter: 741 loss: 8.48094885e-07
Iter: 742 loss: 8.47919409e-07
Iter: 743 loss: 8.47774459e-07
Iter: 744 loss: 8.47721878e-07
Iter: 745 loss: 8.47629053e-07
Iter: 746 loss: 8.47608135e-07
Iter: 747 loss: 8.47557828e-07
Iter: 748 loss: 8.47348474e-07
Iter: 749 loss: 8.47885076e-07
Iter: 750 loss: 8.4725707e-07
Iter: 751 loss: 8.47078866e-07
Iter: 752 loss: 8.48747163e-07
Iter: 753 loss: 8.47092451e-07
Iter: 754 loss: 8.46921466e-07
Iter: 755 loss: 8.4668369e-07
Iter: 756 loss: 8.46681644e-07
Iter: 757 loss: 8.46463763e-07
Iter: 758 loss: 8.48545824e-07
Iter: 759 loss: 8.46449439e-07
Iter: 760 loss: 8.4628789e-07
Iter: 761 loss: 8.45919317e-07
Iter: 762 loss: 8.50796368e-07
Iter: 763 loss: 8.45891634e-07
Iter: 764 loss: 8.45695e-07
Iter: 765 loss: 8.45701493e-07
Iter: 766 loss: 8.45468e-07
Iter: 767 loss: 8.45690352e-07
Iter: 768 loss: 8.45360773e-07
Iter: 769 loss: 8.45194393e-07
Iter: 770 loss: 8.46652938e-07
Iter: 771 loss: 8.45219688e-07
Iter: 772 loss: 8.45062573e-07
Iter: 773 loss: 8.45085651e-07
Iter: 774 loss: 8.44962642e-07
Iter: 775 loss: 8.44818942e-07
Iter: 776 loss: 8.44841168e-07
Iter: 777 loss: 8.44725832e-07
Iter: 778 loss: 8.44586395e-07
Iter: 779 loss: 8.44557235e-07
Iter: 780 loss: 8.44390399e-07
Iter: 781 loss: 8.44379031e-07
Iter: 782 loss: 8.44306555e-07
Iter: 783 loss: 8.44013243e-07
Iter: 784 loss: 8.44664271e-07
Iter: 785 loss: 8.43968849e-07
Iter: 786 loss: 8.43749774e-07
Iter: 787 loss: 8.45065188e-07
Iter: 788 loss: 8.43727435e-07
Iter: 789 loss: 8.43533826e-07
Iter: 790 loss: 8.43441626e-07
Iter: 791 loss: 8.43356133e-07
Iter: 792 loss: 8.43166958e-07
Iter: 793 loss: 8.44563715e-07
Iter: 794 loss: 8.43136092e-07
Iter: 795 loss: 8.42917757e-07
Iter: 796 loss: 8.42520649e-07
Iter: 797 loss: 8.42519967e-07
Iter: 798 loss: 8.42271788e-07
Iter: 799 loss: 8.42239956e-07
Iter: 800 loss: 8.42002805e-07
Iter: 801 loss: 8.41789188e-07
Iter: 802 loss: 8.41684482e-07
Iter: 803 loss: 8.4161428e-07
Iter: 804 loss: 8.41602173e-07
Iter: 805 loss: 8.41462906e-07
Iter: 806 loss: 8.4283289e-07
Iter: 807 loss: 8.41466658e-07
Iter: 808 loss: 8.41324663e-07
Iter: 809 loss: 8.41646511e-07
Iter: 810 loss: 8.41266683e-07
Iter: 811 loss: 8.41160272e-07
Iter: 812 loss: 8.41125143e-07
Iter: 813 loss: 8.41085e-07
Iter: 814 loss: 8.40956545e-07
Iter: 815 loss: 8.40738608e-07
Iter: 816 loss: 8.40730252e-07
Iter: 817 loss: 8.40480197e-07
Iter: 818 loss: 8.42680606e-07
Iter: 819 loss: 8.404254e-07
Iter: 820 loss: 8.40269195e-07
Iter: 821 loss: 8.40916357e-07
Iter: 822 loss: 8.4022497e-07
Iter: 823 loss: 8.40015673e-07
Iter: 824 loss: 8.39893914e-07
Iter: 825 loss: 8.39794893e-07
Iter: 826 loss: 8.39591223e-07
Iter: 827 loss: 8.40167786e-07
Iter: 828 loss: 8.39531e-07
Iter: 829 loss: 8.39281597e-07
Iter: 830 loss: 8.39731115e-07
Iter: 831 loss: 8.39135907e-07
Iter: 832 loss: 8.38917288e-07
Iter: 833 loss: 8.39691552e-07
Iter: 834 loss: 8.38880624e-07
Iter: 835 loss: 8.38632275e-07
Iter: 836 loss: 8.38776259e-07
Iter: 837 loss: 8.38470669e-07
Iter: 838 loss: 8.38331744e-07
Iter: 839 loss: 8.40073142e-07
Iter: 840 loss: 8.38276947e-07
Iter: 841 loss: 8.38124322e-07
Iter: 842 loss: 8.38087317e-07
Iter: 843 loss: 8.37997e-07
Iter: 844 loss: 8.37825212e-07
Iter: 845 loss: 8.37823563e-07
Iter: 846 loss: 8.37714481e-07
Iter: 847 loss: 8.376241e-07
Iter: 848 loss: 8.40338146e-07
Iter: 849 loss: 8.37635525e-07
Iter: 850 loss: 8.37439586e-07
Iter: 851 loss: 8.37362791e-07
Iter: 852 loss: 8.37298728e-07
Iter: 853 loss: 8.37072321e-07
Iter: 854 loss: 8.38977371e-07
Iter: 855 loss: 8.37032417e-07
Iter: 856 loss: 8.36906224e-07
Iter: 857 loss: 8.36984782e-07
Iter: 858 loss: 8.36847562e-07
Iter: 859 loss: 8.36647814e-07
Iter: 860 loss: 8.37224547e-07
Iter: 861 loss: 8.36558684e-07
Iter: 862 loss: 8.36408617e-07
Iter: 863 loss: 8.36904519e-07
Iter: 864 loss: 8.36367803e-07
Iter: 865 loss: 8.36217509e-07
Iter: 866 loss: 8.35900892e-07
Iter: 867 loss: 8.40822281e-07
Iter: 868 loss: 8.35883384e-07
Iter: 869 loss: 8.35637707e-07
Iter: 870 loss: 8.35631909e-07
Iter: 871 loss: 8.35476726e-07
Iter: 872 loss: 8.3612963e-07
Iter: 873 loss: 8.35386e-07
Iter: 874 loss: 8.35241e-07
Iter: 875 loss: 8.35370201e-07
Iter: 876 loss: 8.35172386e-07
Iter: 877 loss: 8.34964567e-07
Iter: 878 loss: 8.3655425e-07
Iter: 879 loss: 8.34962407e-07
Iter: 880 loss: 8.3479506e-07
Iter: 881 loss: 8.36143784e-07
Iter: 882 loss: 8.34800744e-07
Iter: 883 loss: 8.34723949e-07
Iter: 884 loss: 8.3455609e-07
Iter: 885 loss: 8.36562378e-07
Iter: 886 loss: 8.34568141e-07
Iter: 887 loss: 8.34372827e-07
Iter: 888 loss: 8.34418927e-07
Iter: 889 loss: 8.34195589e-07
Iter: 890 loss: 8.33975434e-07
Iter: 891 loss: 8.36363029e-07
Iter: 892 loss: 8.33950935e-07
Iter: 893 loss: 8.33854187e-07
Iter: 894 loss: 8.33720947e-07
Iter: 895 loss: 8.33683885e-07
Iter: 896 loss: 8.33432296e-07
Iter: 897 loss: 8.35699836e-07
Iter: 898 loss: 8.33438776e-07
Iter: 899 loss: 8.33340891e-07
Iter: 900 loss: 8.3339711e-07
Iter: 901 loss: 8.3325483e-07
Iter: 902 loss: 8.33080207e-07
Iter: 903 loss: 8.33029617e-07
Iter: 904 loss: 8.32965384e-07
Iter: 905 loss: 8.3282174e-07
Iter: 906 loss: 8.33645629e-07
Iter: 907 loss: 8.32775186e-07
Iter: 908 loss: 8.32608066e-07
Iter: 909 loss: 8.32788e-07
Iter: 910 loss: 8.32515411e-07
Iter: 911 loss: 8.32325554e-07
Iter: 912 loss: 8.33468789e-07
Iter: 913 loss: 8.32342664e-07
Iter: 914 loss: 8.32233127e-07
Iter: 915 loss: 8.33626245e-07
Iter: 916 loss: 8.32224373e-07
Iter: 917 loss: 8.32041849e-07
Iter: 918 loss: 8.3184176e-07
Iter: 919 loss: 8.31859666e-07
Iter: 920 loss: 8.31699367e-07
Iter: 921 loss: 8.31993134e-07
Iter: 922 loss: 8.31639454e-07
Iter: 923 loss: 8.31463865e-07
Iter: 924 loss: 8.31563057e-07
Iter: 925 loss: 8.31356488e-07
Iter: 926 loss: 8.31220405e-07
Iter: 927 loss: 8.33000456e-07
Iter: 928 loss: 8.31209036e-07
Iter: 929 loss: 8.31080627e-07
Iter: 930 loss: 8.31060902e-07
Iter: 931 loss: 8.30956594e-07
Iter: 932 loss: 8.30724275e-07
Iter: 933 loss: 8.31188459e-07
Iter: 934 loss: 8.30668114e-07
Iter: 935 loss: 8.30517251e-07
Iter: 936 loss: 8.31049533e-07
Iter: 937 loss: 8.30439831e-07
Iter: 938 loss: 8.30295448e-07
Iter: 939 loss: 8.30041586e-07
Iter: 940 loss: 8.300442e-07
Iter: 941 loss: 8.29845249e-07
Iter: 942 loss: 8.31892805e-07
Iter: 943 loss: 8.29832061e-07
Iter: 944 loss: 8.29577175e-07
Iter: 945 loss: 8.29797955e-07
Iter: 946 loss: 8.29454507e-07
Iter: 947 loss: 8.29336045e-07
Iter: 948 loss: 8.29352075e-07
Iter: 949 loss: 8.29204055e-07
Iter: 950 loss: 8.29536702e-07
Iter: 951 loss: 8.29170517e-07
Iter: 952 loss: 8.29010673e-07
Iter: 953 loss: 8.28711e-07
Iter: 954 loss: 8.3210341e-07
Iter: 955 loss: 8.28699967e-07
Iter: 956 loss: 8.2853245e-07
Iter: 957 loss: 8.28528641e-07
Iter: 958 loss: 8.28397219e-07
Iter: 959 loss: 8.28267389e-07
Iter: 960 loss: 8.28217253e-07
Iter: 961 loss: 8.28003863e-07
Iter: 962 loss: 8.29254475e-07
Iter: 963 loss: 8.27970325e-07
Iter: 964 loss: 8.2779394e-07
Iter: 965 loss: 8.28592306e-07
Iter: 966 loss: 8.27755684e-07
Iter: 967 loss: 8.27568385e-07
Iter: 968 loss: 8.27465215e-07
Iter: 969 loss: 8.27379552e-07
Iter: 970 loss: 8.27203735e-07
Iter: 971 loss: 8.29113446e-07
Iter: 972 loss: 8.27222607e-07
Iter: 973 loss: 8.27075041e-07
Iter: 974 loss: 8.26780706e-07
Iter: 975 loss: 8.31608361e-07
Iter: 976 loss: 8.26775135e-07
Iter: 977 loss: 8.26585222e-07
Iter: 978 loss: 8.26585051e-07
Iter: 979 loss: 8.26422308e-07
Iter: 980 loss: 8.26879955e-07
Iter: 981 loss: 8.2636268e-07
Iter: 982 loss: 8.26226312e-07
Iter: 983 loss: 8.26219662e-07
Iter: 984 loss: 8.26112796e-07
Iter: 985 loss: 8.25992913e-07
Iter: 986 loss: 8.25968641e-07
Iter: 987 loss: 8.25835173e-07
Iter: 988 loss: 8.25715233e-07
Iter: 989 loss: 8.25691359e-07
Iter: 990 loss: 8.2544841e-07
Iter: 991 loss: 8.27532062e-07
Iter: 992 loss: 8.25422376e-07
Iter: 993 loss: 8.25273958e-07
Iter: 994 loss: 8.25895427e-07
Iter: 995 loss: 8.25193581e-07
Iter: 996 loss: 8.25058407e-07
Iter: 997 loss: 8.24955805e-07
Iter: 998 loss: 8.24920562e-07
Iter: 999 loss: 8.24641234e-07
Iter: 1000 loss: 8.27530357e-07
Iter: 1001 loss: 8.24675453e-07
Iter: 1002 loss: 8.24539143e-07
Iter: 1003 loss: 8.2444933e-07
Iter: 1004 loss: 8.2442989e-07
Iter: 1005 loss: 8.24184326e-07
Iter: 1006 loss: 8.24169035e-07
Iter: 1007 loss: 8.24019e-07
Iter: 1008 loss: 8.23692233e-07
Iter: 1009 loss: 8.23928588e-07
Iter: 1010 loss: 8.23502546e-07
Iter: 1011 loss: 8.23177402e-07
Iter: 1012 loss: 8.27384383e-07
Iter: 1013 loss: 8.23217249e-07
Iter: 1014 loss: 8.23155517e-07
Iter: 1015 loss: 8.2314e-07
Iter: 1016 loss: 8.230395e-07
Iter: 1017 loss: 8.22946845e-07
Iter: 1018 loss: 8.26024575e-07
Iter: 1019 loss: 8.22917229e-07
Iter: 1020 loss: 8.22744937e-07
Iter: 1021 loss: 8.2264188e-07
Iter: 1022 loss: 8.22591687e-07
Iter: 1023 loss: 8.22393929e-07
Iter: 1024 loss: 8.23581161e-07
Iter: 1025 loss: 8.22382333e-07
Iter: 1026 loss: 8.22186621e-07
Iter: 1027 loss: 8.22443099e-07
Iter: 1028 loss: 8.22135291e-07
Iter: 1029 loss: 8.22001596e-07
Iter: 1030 loss: 8.23331789e-07
Iter: 1031 loss: 8.21983917e-07
Iter: 1032 loss: 8.21881486e-07
Iter: 1033 loss: 8.22054744e-07
Iter: 1034 loss: 8.21830213e-07
Iter: 1035 loss: 8.2170277e-07
Iter: 1036 loss: 8.21632057e-07
Iter: 1037 loss: 8.21580329e-07
Iter: 1038 loss: 8.21413835e-07
Iter: 1039 loss: 8.22064521e-07
Iter: 1040 loss: 8.21411959e-07
Iter: 1041 loss: 8.21225854e-07
Iter: 1042 loss: 8.21082267e-07
Iter: 1043 loss: 8.21056346e-07
Iter: 1044 loss: 8.20884679e-07
Iter: 1045 loss: 8.21993922e-07
Iter: 1046 loss: 8.20863306e-07
Iter: 1047 loss: 8.20628657e-07
Iter: 1048 loss: 8.21701633e-07
Iter: 1049 loss: 8.20649461e-07
Iter: 1050 loss: 8.20445678e-07
Iter: 1051 loss: 8.22559173e-07
Iter: 1052 loss: 8.20456307e-07
Iter: 1053 loss: 8.20385537e-07
Iter: 1054 loss: 8.20324601e-07
Iter: 1055 loss: 8.20301125e-07
Iter: 1056 loss: 8.20187779e-07
Iter: 1057 loss: 8.20005823e-07
Iter: 1058 loss: 8.20020205e-07
Iter: 1059 loss: 8.1988469e-07
Iter: 1060 loss: 8.1990936e-07
Iter: 1061 loss: 8.19799e-07
Iter: 1062 loss: 8.19671641e-07
Iter: 1063 loss: 8.19687273e-07
Iter: 1064 loss: 8.19496563e-07
Iter: 1065 loss: 8.2100496e-07
Iter: 1066 loss: 8.19475815e-07
Iter: 1067 loss: 8.19364175e-07
Iter: 1068 loss: 8.20134289e-07
Iter: 1069 loss: 8.19350305e-07
Iter: 1070 loss: 8.19256115e-07
Iter: 1071 loss: 8.19106958e-07
Iter: 1072 loss: 8.22084701e-07
Iter: 1073 loss: 8.19104e-07
Iter: 1074 loss: 8.18942e-07
Iter: 1075 loss: 8.21274966e-07
Iter: 1076 loss: 8.18941032e-07
Iter: 1077 loss: 8.18809156e-07
Iter: 1078 loss: 8.1856524e-07
Iter: 1079 loss: 8.18548244e-07
Iter: 1080 loss: 8.18409717e-07
Iter: 1081 loss: 8.18416311e-07
Iter: 1082 loss: 8.18352817e-07
Iter: 1083 loss: 8.1833565e-07
Iter: 1084 loss: 8.18240778e-07
Iter: 1085 loss: 8.18086392e-07
Iter: 1086 loss: 8.1980005e-07
Iter: 1087 loss: 8.18022158e-07
Iter: 1088 loss: 8.17920181e-07
Iter: 1089 loss: 8.1914618e-07
Iter: 1090 loss: 8.17901423e-07
Iter: 1091 loss: 8.17825594e-07
Iter: 1092 loss: 8.17665182e-07
Iter: 1093 loss: 8.20589207e-07
Iter: 1094 loss: 8.17630053e-07
Iter: 1095 loss: 8.17478337e-07
Iter: 1096 loss: 8.18447916e-07
Iter: 1097 loss: 8.17477144e-07
Iter: 1098 loss: 8.17363457e-07
Iter: 1099 loss: 8.17568548e-07
Iter: 1100 loss: 8.17284899e-07
Iter: 1101 loss: 8.17161549e-07
Iter: 1102 loss: 8.17621469e-07
Iter: 1103 loss: 8.17129148e-07
Iter: 1104 loss: 8.17028649e-07
Iter: 1105 loss: 8.17695366e-07
Iter: 1106 loss: 8.17040416e-07
Iter: 1107 loss: 8.16921784e-07
Iter: 1108 loss: 8.16761258e-07
Iter: 1109 loss: 8.21071922e-07
Iter: 1110 loss: 8.1672988e-07
Iter: 1111 loss: 8.16577767e-07
Iter: 1112 loss: 8.18262151e-07
Iter: 1113 loss: 8.16602494e-07
Iter: 1114 loss: 8.16457941e-07
Iter: 1115 loss: 8.16233751e-07
Iter: 1116 loss: 8.16243414e-07
Iter: 1117 loss: 8.16233751e-07
Iter: 1118 loss: 8.16137799e-07
Iter: 1119 loss: 8.16085958e-07
Iter: 1120 loss: 8.16637566e-07
Iter: 1121 loss: 8.16089596e-07
Iter: 1122 loss: 8.16005581e-07
Iter: 1123 loss: 8.158284e-07
Iter: 1124 loss: 8.17015234e-07
Iter: 1125 loss: 8.15783267e-07
Iter: 1126 loss: 8.15692033e-07
Iter: 1127 loss: 8.16470958e-07
Iter: 1128 loss: 8.15651106e-07
Iter: 1129 loss: 8.15540091e-07
Iter: 1130 loss: 8.15368708e-07
Iter: 1131 loss: 8.15370754e-07
Iter: 1132 loss: 8.15148837e-07
Iter: 1133 loss: 8.15179419e-07
Iter: 1134 loss: 8.15082899e-07
Iter: 1135 loss: 8.14967962e-07
Iter: 1136 loss: 8.14974896e-07
Iter: 1137 loss: 8.14802775e-07
Iter: 1138 loss: 8.16148315e-07
Iter: 1139 loss: 8.14813063e-07
Iter: 1140 loss: 8.14697557e-07
Iter: 1141 loss: 8.15214833e-07
Iter: 1142 loss: 8.14658733e-07
Iter: 1143 loss: 8.14567784e-07
Iter: 1144 loss: 8.14308692e-07
Iter: 1145 loss: 8.17789726e-07
Iter: 1146 loss: 8.14272312e-07
Iter: 1147 loss: 8.14123609e-07
Iter: 1148 loss: 8.14156806e-07
Iter: 1149 loss: 8.13988436e-07
Iter: 1150 loss: 8.14049031e-07
Iter: 1151 loss: 8.13927784e-07
Iter: 1152 loss: 8.13844395e-07
Iter: 1153 loss: 8.13832571e-07
Iter: 1154 loss: 8.13756628e-07
Iter: 1155 loss: 8.1425361e-07
Iter: 1156 loss: 8.13766064e-07
Iter: 1157 loss: 8.13685176e-07
Iter: 1158 loss: 8.13574502e-07
Iter: 1159 loss: 8.14131113e-07
Iter: 1160 loss: 8.13512e-07
Iter: 1161 loss: 8.13413692e-07
Iter: 1162 loss: 8.1343876e-07
Iter: 1163 loss: 8.13359293e-07
Iter: 1164 loss: 8.13164888e-07
Iter: 1165 loss: 8.15227111e-07
Iter: 1166 loss: 8.13137717e-07
Iter: 1167 loss: 8.12954227e-07
Iter: 1168 loss: 8.12953374e-07
Iter: 1169 loss: 8.12839176e-07
Iter: 1170 loss: 8.12683652e-07
Iter: 1171 loss: 8.12682345e-07
Iter: 1172 loss: 8.12514884e-07
Iter: 1173 loss: 8.13116117e-07
Iter: 1174 loss: 8.1241916e-07
Iter: 1175 loss: 8.12288704e-07
Iter: 1176 loss: 8.12249255e-07
Iter: 1177 loss: 8.12108397e-07
Iter: 1178 loss: 8.11940424e-07
Iter: 1179 loss: 8.13998497e-07
Iter: 1180 loss: 8.11944915e-07
Iter: 1181 loss: 8.11803488e-07
Iter: 1182 loss: 8.12459e-07
Iter: 1183 loss: 8.1179229e-07
Iter: 1184 loss: 8.1167741e-07
Iter: 1185 loss: 8.11481e-07
Iter: 1186 loss: 8.11483346e-07
Iter: 1187 loss: 8.1132697e-07
Iter: 1188 loss: 8.12439168e-07
Iter: 1189 loss: 8.11282632e-07
Iter: 1190 loss: 8.11228233e-07
Iter: 1191 loss: 8.11204245e-07
Iter: 1192 loss: 8.11123243e-07
Iter: 1193 loss: 8.10977895e-07
Iter: 1194 loss: 8.10960842e-07
Iter: 1195 loss: 8.10878248e-07
Iter: 1196 loss: 8.10638142e-07
Iter: 1197 loss: 8.15392411e-07
Iter: 1198 loss: 8.10662584e-07
Iter: 1199 loss: 8.1050888e-07
Iter: 1200 loss: 8.10534345e-07
Iter: 1201 loss: 8.10403208e-07
Iter: 1202 loss: 8.10408324e-07
Iter: 1203 loss: 8.10338292e-07
Iter: 1204 loss: 8.10165034e-07
Iter: 1205 loss: 8.09959431e-07
Iter: 1206 loss: 8.09927769e-07
Iter: 1207 loss: 8.09742232e-07
Iter: 1208 loss: 8.1234316e-07
Iter: 1209 loss: 8.09735809e-07
Iter: 1210 loss: 8.09604558e-07
Iter: 1211 loss: 8.0922797e-07
Iter: 1212 loss: 8.16543e-07
Iter: 1213 loss: 8.09208188e-07
Iter: 1214 loss: 8.09033679e-07
Iter: 1215 loss: 8.11633072e-07
Iter: 1216 loss: 8.09034645e-07
Iter: 1217 loss: 8.08821142e-07
Iter: 1218 loss: 8.09636958e-07
Iter: 1219 loss: 8.08780669e-07
Iter: 1220 loss: 8.08677669e-07
Iter: 1221 loss: 8.08697791e-07
Iter: 1222 loss: 8.08586719e-07
Iter: 1223 loss: 8.08539653e-07
Iter: 1224 loss: 8.08504637e-07
Iter: 1225 loss: 8.08382197e-07
Iter: 1226 loss: 8.10113534e-07
Iter: 1227 loss: 8.08410505e-07
Iter: 1228 loss: 8.08323193e-07
Iter: 1229 loss: 8.08230141e-07
Iter: 1230 loss: 8.09789299e-07
Iter: 1231 loss: 8.08200866e-07
Iter: 1232 loss: 8.08052675e-07
Iter: 1233 loss: 8.08172729e-07
Iter: 1234 loss: 8.07976733e-07
Iter: 1235 loss: 8.07882941e-07
Iter: 1236 loss: 8.08401069e-07
Iter: 1237 loss: 8.07870094e-07
Iter: 1238 loss: 8.07700587e-07
Iter: 1239 loss: 8.07639e-07
Iter: 1240 loss: 8.07557512e-07
Iter: 1241 loss: 8.07430411e-07
Iter: 1242 loss: 8.08830237e-07
Iter: 1243 loss: 8.07385618e-07
Iter: 1244 loss: 8.07250331e-07
Iter: 1245 loss: 8.07037111e-07
Iter: 1246 loss: 8.07029437e-07
Iter: 1247 loss: 8.06948265e-07
Iter: 1248 loss: 8.06882895e-07
Iter: 1249 loss: 8.06777052e-07
Iter: 1250 loss: 8.06484e-07
Iter: 1251 loss: 8.12500161e-07
Iter: 1252 loss: 8.06511309e-07
Iter: 1253 loss: 8.06263699e-07
Iter: 1254 loss: 8.09372295e-07
Iter: 1255 loss: 8.06254036e-07
Iter: 1256 loss: 8.06120511e-07
Iter: 1257 loss: 8.06604703e-07
Iter: 1258 loss: 8.06075718e-07
Iter: 1259 loss: 8.05911e-07
Iter: 1260 loss: 8.06541379e-07
Iter: 1261 loss: 8.05866762e-07
Iter: 1262 loss: 8.05737216e-07
Iter: 1263 loss: 8.0574091e-07
Iter: 1264 loss: 8.05712375e-07
Iter: 1265 loss: 8.05569471e-07
Iter: 1266 loss: 8.0567645e-07
Iter: 1267 loss: 8.05483182e-07
Iter: 1268 loss: 8.05399111e-07
Iter: 1269 loss: 8.07220886e-07
Iter: 1270 loss: 8.05396837e-07
Iter: 1271 loss: 8.05258537e-07
Iter: 1272 loss: 8.05179297e-07
Iter: 1273 loss: 8.05163836e-07
Iter: 1274 loss: 8.04994556e-07
Iter: 1275 loss: 8.06761193e-07
Iter: 1276 loss: 8.05015816e-07
Iter: 1277 loss: 8.0490031e-07
Iter: 1278 loss: 8.05004902e-07
Iter: 1279 loss: 8.04860917e-07
Iter: 1280 loss: 8.04659294e-07
Iter: 1281 loss: 8.04710055e-07
Iter: 1282 loss: 8.04529577e-07
Iter: 1283 loss: 8.04450451e-07
Iter: 1284 loss: 8.05302875e-07
Iter: 1285 loss: 8.04422825e-07
Iter: 1286 loss: 8.04280319e-07
Iter: 1287 loss: 8.04024864e-07
Iter: 1288 loss: 8.09664073e-07
Iter: 1289 loss: 8.04029924e-07
Iter: 1290 loss: 8.03853538e-07
Iter: 1291 loss: 8.03837e-07
Iter: 1292 loss: 8.03721889e-07
Iter: 1293 loss: 8.03580576e-07
Iter: 1294 loss: 8.03528451e-07
Iter: 1295 loss: 8.03473199e-07
Iter: 1296 loss: 8.03449893e-07
Iter: 1297 loss: 8.0337179e-07
Iter: 1298 loss: 8.03989565e-07
Iter: 1299 loss: 8.03356215e-07
Iter: 1300 loss: 8.03294427e-07
Iter: 1301 loss: 8.03204216e-07
Iter: 1302 loss: 8.05692707e-07
Iter: 1303 loss: 8.03171474e-07
Iter: 1304 loss: 8.03071e-07
Iter: 1305 loss: 8.03233e-07
Iter: 1306 loss: 8.03001967e-07
Iter: 1307 loss: 8.02885097e-07
Iter: 1308 loss: 8.0269831e-07
Iter: 1309 loss: 8.06345611e-07
Iter: 1310 loss: 8.02690124e-07
Iter: 1311 loss: 8.02593547e-07
Iter: 1312 loss: 8.02564387e-07
Iter: 1313 loss: 8.02444163e-07
Iter: 1314 loss: 8.02393629e-07
Iter: 1315 loss: 8.02292675e-07
Iter: 1316 loss: 8.0220758e-07
Iter: 1317 loss: 8.03527e-07
Iter: 1318 loss: 8.02180239e-07
Iter: 1319 loss: 8.02055411e-07
Iter: 1320 loss: 8.02006468e-07
Iter: 1321 loss: 8.01987881e-07
Iter: 1322 loss: 8.01789156e-07
Iter: 1323 loss: 8.02104523e-07
Iter: 1324 loss: 8.01719e-07
Iter: 1325 loss: 8.01607428e-07
Iter: 1326 loss: 8.02282e-07
Iter: 1327 loss: 8.0156093e-07
Iter: 1328 loss: 8.01416149e-07
Iter: 1329 loss: 8.01333897e-07
Iter: 1330 loss: 8.01240844e-07
Iter: 1331 loss: 8.01494082e-07
Iter: 1332 loss: 8.01186616e-07
Iter: 1333 loss: 8.01159e-07
Iter: 1334 loss: 8.01090209e-07
Iter: 1335 loss: 8.01113345e-07
Iter: 1336 loss: 8.01005e-07
Iter: 1337 loss: 8.00952819e-07
Iter: 1338 loss: 8.00899898e-07
Iter: 1339 loss: 8.00820885e-07
Iter: 1340 loss: 8.01400915e-07
Iter: 1341 loss: 8.00779617e-07
Iter: 1342 loss: 8.00686735e-07
Iter: 1343 loss: 8.00556506e-07
Iter: 1344 loss: 8.04416e-07
Iter: 1345 loss: 8.00590556e-07
Iter: 1346 loss: 8.00410476e-07
Iter: 1347 loss: 8.02784257e-07
Iter: 1348 loss: 8.00371822e-07
Iter: 1349 loss: 8.00255634e-07
Iter: 1350 loss: 8.00270413e-07
Iter: 1351 loss: 8.0016224e-07
Iter: 1352 loss: 8.00011719e-07
Iter: 1353 loss: 8.0173e-07
Iter: 1354 loss: 7.99999384e-07
Iter: 1355 loss: 7.99868644e-07
Iter: 1356 loss: 7.99672421e-07
Iter: 1357 loss: 7.99677423e-07
Iter: 1358 loss: 7.9948552e-07
Iter: 1359 loss: 8.01200372e-07
Iter: 1360 loss: 7.99462327e-07
Iter: 1361 loss: 7.99332554e-07
Iter: 1362 loss: 7.99569648e-07
Iter: 1363 loss: 7.99270254e-07
Iter: 1364 loss: 7.99173165e-07
Iter: 1365 loss: 7.99975226e-07
Iter: 1366 loss: 7.99171289e-07
Iter: 1367 loss: 7.99048735e-07
Iter: 1368 loss: 7.99416455e-07
Iter: 1369 loss: 7.9898291e-07
Iter: 1370 loss: 7.98952897e-07
Iter: 1371 loss: 7.98996325e-07
Iter: 1372 loss: 7.9891629e-07
Iter: 1373 loss: 7.98820111e-07
Iter: 1374 loss: 7.98657766e-07
Iter: 1375 loss: 7.98678514e-07
Iter: 1376 loss: 7.98500196e-07
Iter: 1377 loss: 7.99798386e-07
Iter: 1378 loss: 7.9848445e-07
Iter: 1379 loss: 7.98391227e-07
Iter: 1380 loss: 7.98150268e-07
Iter: 1381 loss: 8.01871636e-07
Iter: 1382 loss: 7.9816391e-07
Iter: 1383 loss: 7.98136625e-07
Iter: 1384 loss: 7.98047381e-07
Iter: 1385 loss: 7.97962343e-07
Iter: 1386 loss: 7.97928351e-07
Iter: 1387 loss: 7.97892085e-07
Iter: 1388 loss: 7.9781546e-07
Iter: 1389 loss: 7.98444432e-07
Iter: 1390 loss: 7.97775328e-07
Iter: 1391 loss: 7.97714563e-07
Iter: 1392 loss: 7.9778539e-07
Iter: 1393 loss: 7.97652092e-07
Iter: 1394 loss: 7.97569157e-07
Iter: 1395 loss: 7.97624068e-07
Iter: 1396 loss: 7.97505379e-07
Iter: 1397 loss: 7.97454277e-07
Iter: 1398 loss: 7.98104224e-07
Iter: 1399 loss: 7.97441544e-07
Iter: 1400 loss: 7.97341386e-07
Iter: 1401 loss: 7.97621624e-07
Iter: 1402 loss: 7.97330586e-07
Iter: 1403 loss: 7.97227813e-07
Iter: 1404 loss: 7.97119753e-07
Iter: 1405 loss: 7.97135385e-07
Iter: 1406 loss: 7.9704887e-07
Iter: 1407 loss: 7.9784877e-07
Iter: 1408 loss: 7.9705e-07
Iter: 1409 loss: 7.96953486e-07
Iter: 1410 loss: 7.96832637e-07
Iter: 1411 loss: 7.96819165e-07
Iter: 1412 loss: 7.96653353e-07
Iter: 1413 loss: 7.97235543e-07
Iter: 1414 loss: 7.96631866e-07
Iter: 1415 loss: 7.96548932e-07
Iter: 1416 loss: 7.964112e-07
Iter: 1417 loss: 7.96404493e-07
Iter: 1418 loss: 7.96235611e-07
Iter: 1419 loss: 7.98919643e-07
Iter: 1420 loss: 7.96237146e-07
Iter: 1421 loss: 7.96094e-07
Iter: 1422 loss: 7.96291658e-07
Iter: 1423 loss: 7.96045356e-07
Iter: 1424 loss: 7.95873575e-07
Iter: 1425 loss: 7.96295353e-07
Iter: 1426 loss: 7.95819119e-07
Iter: 1427 loss: 7.95723395e-07
Iter: 1428 loss: 7.95829237e-07
Iter: 1429 loss: 7.95655069e-07
Iter: 1430 loss: 7.95486471e-07
Iter: 1431 loss: 7.95554854e-07
Iter: 1432 loss: 7.95375058e-07
Iter: 1433 loss: 7.9541843e-07
Iter: 1434 loss: 7.95358119e-07
Iter: 1435 loss: 7.95332085e-07
Iter: 1436 loss: 7.95317533e-07
Iter: 1437 loss: 7.95267113e-07
Iter: 1438 loss: 7.95198673e-07
Iter: 1439 loss: 7.95066057e-07
Iter: 1440 loss: 7.97044379e-07
Iter: 1441 loss: 7.95031951e-07
Iter: 1442 loss: 7.94884954e-07
Iter: 1443 loss: 7.95952701e-07
Iter: 1444 loss: 7.94893197e-07
Iter: 1445 loss: 7.94766379e-07
Iter: 1446 loss: 7.94987386e-07
Iter: 1447 loss: 7.94686173e-07
Iter: 1448 loss: 7.94559071e-07
Iter: 1449 loss: 7.94910306e-07
Iter: 1450 loss: 7.94507059e-07
Iter: 1451 loss: 7.94402354e-07
Iter: 1452 loss: 7.94247683e-07
Iter: 1453 loss: 7.9419965e-07
Iter: 1454 loss: 7.94036112e-07
Iter: 1455 loss: 7.94044581e-07
Iter: 1456 loss: 7.93928734e-07
Iter: 1457 loss: 7.93706135e-07
Iter: 1458 loss: 7.93683512e-07
Iter: 1459 loss: 7.93621382e-07
Iter: 1460 loss: 7.93541062e-07
Iter: 1461 loss: 7.93496724e-07
Iter: 1462 loss: 7.93526056e-07
Iter: 1463 loss: 7.93463812e-07
Iter: 1464 loss: 7.93375534e-07
Iter: 1465 loss: 7.93411573e-07
Iter: 1466 loss: 7.93320282e-07
Iter: 1467 loss: 7.93303059e-07
Iter: 1468 loss: 7.93284244e-07
Iter: 1469 loss: 7.93263155e-07
Iter: 1470 loss: 7.93173967e-07
Iter: 1471 loss: 7.94133257e-07
Iter: 1472 loss: 7.9316527e-07
Iter: 1473 loss: 7.93064146e-07
Iter: 1474 loss: 7.92969558e-07
Iter: 1475 loss: 7.92979677e-07
Iter: 1476 loss: 7.92852347e-07
Iter: 1477 loss: 7.92826086e-07
Iter: 1478 loss: 7.92757874e-07
Iter: 1479 loss: 7.92932383e-07
Iter: 1480 loss: 7.92716889e-07
Iter: 1481 loss: 7.92581e-07
Iter: 1482 loss: 7.92517142e-07
Iter: 1483 loss: 7.92489573e-07
Iter: 1484 loss: 7.92322339e-07
Iter: 1485 loss: 7.92356445e-07
Iter: 1486 loss: 7.9223355e-07
Iter: 1487 loss: 7.92023741e-07
Iter: 1488 loss: 7.93898721e-07
Iter: 1489 loss: 7.92022945e-07
Iter: 1490 loss: 7.91951834e-07
Iter: 1491 loss: 7.92013395e-07
Iter: 1492 loss: 7.91874641e-07
Iter: 1493 loss: 7.91714115e-07
Iter: 1494 loss: 7.92426476e-07
Iter: 1495 loss: 7.91702405e-07
Iter: 1496 loss: 7.91621176e-07
Iter: 1497 loss: 7.92331093e-07
Iter: 1498 loss: 7.91617254e-07
Iter: 1499 loss: 7.91582409e-07
Iter: 1500 loss: 7.91920627e-07
Iter: 1501 loss: 7.91600485e-07
Iter: 1502 loss: 7.91493505e-07
Iter: 1503 loss: 7.91363505e-07
Iter: 1504 loss: 7.91376749e-07
Iter: 1505 loss: 7.9127085e-07
Iter: 1506 loss: 7.91579396e-07
Iter: 1507 loss: 7.9122907e-07
Iter: 1508 loss: 7.91179e-07
Iter: 1509 loss: 7.91032789e-07
Iter: 1510 loss: 7.91000502e-07
Iter: 1511 loss: 7.90892045e-07
Iter: 1512 loss: 7.90916715e-07
Iter: 1513 loss: 7.90823549e-07
Iter: 1514 loss: 7.90962645e-07
Iter: 1515 loss: 7.90760282e-07
Iter: 1516 loss: 7.90662057e-07
Iter: 1517 loss: 7.90523131e-07
Iter: 1518 loss: 7.90493232e-07
Iter: 1519 loss: 7.90348054e-07
Iter: 1520 loss: 7.90678257e-07
Iter: 1521 loss: 7.90319348e-07
Iter: 1522 loss: 7.90128354e-07
Iter: 1523 loss: 7.90350327e-07
Iter: 1524 loss: 7.90030185e-07
Iter: 1525 loss: 7.89901094e-07
Iter: 1526 loss: 7.91794207e-07
Iter: 1527 loss: 7.89917e-07
Iter: 1528 loss: 7.89762e-07
Iter: 1529 loss: 7.89750516e-07
Iter: 1530 loss: 7.89692194e-07
Iter: 1531 loss: 7.89602097e-07
Iter: 1532 loss: 7.91351965e-07
Iter: 1533 loss: 7.89578507e-07
Iter: 1534 loss: 7.89538433e-07
Iter: 1535 loss: 7.89512228e-07
Iter: 1536 loss: 7.89500405e-07
Iter: 1537 loss: 7.89402918e-07
Iter: 1538 loss: 7.89434068e-07
Iter: 1539 loss: 7.89293836e-07
Iter: 1540 loss: 7.89135584e-07
Iter: 1541 loss: 7.90521767e-07
Iter: 1542 loss: 7.89087323e-07
Iter: 1543 loss: 7.89019509e-07
Iter: 1544 loss: 7.89143769e-07
Iter: 1545 loss: 7.88983357e-07
Iter: 1546 loss: 7.88832892e-07
Iter: 1547 loss: 7.8945294e-07
Iter: 1548 loss: 7.8879043e-07
Iter: 1549 loss: 7.88691864e-07
Iter: 1550 loss: 7.89335388e-07
Iter: 1551 loss: 7.88688226e-07
Iter: 1552 loss: 7.8860063e-07
Iter: 1553 loss: 7.88438967e-07
Iter: 1554 loss: 7.90142792e-07
Iter: 1555 loss: 7.88414e-07
Iter: 1556 loss: 7.88280317e-07
Iter: 1557 loss: 7.88310444e-07
Iter: 1558 loss: 7.88224042e-07
Iter: 1559 loss: 7.88064085e-07
Iter: 1560 loss: 7.88099271e-07
Iter: 1561 loss: 7.88040381e-07
Iter: 1562 loss: 7.87969384e-07
Iter: 1563 loss: 7.87917656e-07
Iter: 1564 loss: 7.87867e-07
Iter: 1565 loss: 7.87861495e-07
Iter: 1566 loss: 7.87764861e-07
Iter: 1567 loss: 7.87754288e-07
Iter: 1568 loss: 7.87671581e-07
Iter: 1569 loss: 7.8779965e-07
Iter: 1570 loss: 7.87654699e-07
Iter: 1571 loss: 7.87581939e-07
Iter: 1572 loss: 7.87502074e-07
Iter: 1573 loss: 7.8749531e-07
Iter: 1574 loss: 7.87372812e-07
Iter: 1575 loss: 7.87299882e-07
Iter: 1576 loss: 7.87246108e-07
Iter: 1577 loss: 7.87167551e-07
Iter: 1578 loss: 7.87974272e-07
Iter: 1579 loss: 7.87160729e-07
Iter: 1580 loss: 7.8707717e-07
Iter: 1581 loss: 7.86997475e-07
Iter: 1582 loss: 7.86959731e-07
Iter: 1583 loss: 7.86821829e-07
Iter: 1584 loss: 7.87610645e-07
Iter: 1585 loss: 7.86824899e-07
Iter: 1586 loss: 7.86675287e-07
Iter: 1587 loss: 7.86522151e-07
Iter: 1588 loss: 7.86464966e-07
Iter: 1589 loss: 7.86337409e-07
Iter: 1590 loss: 7.88647128e-07
Iter: 1591 loss: 7.86284545e-07
Iter: 1592 loss: 7.86234295e-07
Iter: 1593 loss: 7.8610492e-07
Iter: 1594 loss: 7.86114e-07
Iter: 1595 loss: 7.86024884e-07
Iter: 1596 loss: 7.86155738e-07
Iter: 1597 loss: 7.85965e-07
Iter: 1598 loss: 7.85897385e-07
Iter: 1599 loss: 7.85786597e-07
Iter: 1600 loss: 7.85789439e-07
Iter: 1601 loss: 7.85686495e-07
Iter: 1602 loss: 7.86496798e-07
Iter: 1603 loss: 7.85668362e-07
Iter: 1604 loss: 7.85577299e-07
Iter: 1605 loss: 7.85751809e-07
Iter: 1606 loss: 7.85566328e-07
Iter: 1607 loss: 7.85453722e-07
Iter: 1608 loss: 7.85298823e-07
Iter: 1609 loss: 7.86675514e-07
Iter: 1610 loss: 7.85232373e-07
Iter: 1611 loss: 7.85286943e-07
Iter: 1612 loss: 7.85167344e-07
Iter: 1613 loss: 7.85104589e-07
Iter: 1614 loss: 7.84930592e-07
Iter: 1615 loss: 7.87930389e-07
Iter: 1616 loss: 7.84910753e-07
Iter: 1617 loss: 7.84710551e-07
Iter: 1618 loss: 7.86247085e-07
Iter: 1619 loss: 7.84652229e-07
Iter: 1620 loss: 7.84563213e-07
Iter: 1621 loss: 7.84576628e-07
Iter: 1622 loss: 7.84452141e-07
Iter: 1623 loss: 7.8433618e-07
Iter: 1624 loss: 7.86008059e-07
Iter: 1625 loss: 7.84305257e-07
Iter: 1626 loss: 7.84261488e-07
Iter: 1627 loss: 7.84244151e-07
Iter: 1628 loss: 7.84175086e-07
Iter: 1629 loss: 7.84082545e-07
Iter: 1630 loss: 7.84975214e-07
Iter: 1631 loss: 7.84103349e-07
Iter: 1632 loss: 7.84002623e-07
Iter: 1633 loss: 7.85104817e-07
Iter: 1634 loss: 7.84017629e-07
Iter: 1635 loss: 7.83967096e-07
Iter: 1636 loss: 7.84025815e-07
Iter: 1637 loss: 7.83947485e-07
Iter: 1638 loss: 7.83882172e-07
Iter: 1639 loss: 7.83726591e-07
Iter: 1640 loss: 7.8374012e-07
Iter: 1641 loss: 7.83580504e-07
Iter: 1642 loss: 7.84641543e-07
Iter: 1643 loss: 7.83599887e-07
Iter: 1644 loss: 7.83526e-07
Iter: 1645 loss: 7.83467272e-07
Iter: 1646 loss: 7.8346e-07
Iter: 1647 loss: 7.83329142e-07
Iter: 1648 loss: 7.84375345e-07
Iter: 1649 loss: 7.83334372e-07
Iter: 1650 loss: 7.83245127e-07
Iter: 1651 loss: 7.83799521e-07
Iter: 1652 loss: 7.83227847e-07
Iter: 1653 loss: 7.83171117e-07
Iter: 1654 loss: 7.83049927e-07
Iter: 1655 loss: 7.84525241e-07
Iter: 1656 loss: 7.82995699e-07
Iter: 1657 loss: 7.82843586e-07
Iter: 1658 loss: 7.84513418e-07
Iter: 1659 loss: 7.82808513e-07
Iter: 1660 loss: 7.82683173e-07
Iter: 1661 loss: 7.8261678e-07
Iter: 1662 loss: 7.82570169e-07
Iter: 1663 loss: 7.82491327e-07
Iter: 1664 loss: 7.82457334e-07
Iter: 1665 loss: 7.8241311e-07
Iter: 1666 loss: 7.826211e-07
Iter: 1667 loss: 7.82357063e-07
Iter: 1668 loss: 7.82285667e-07
Iter: 1669 loss: 7.82486495e-07
Iter: 1670 loss: 7.82263612e-07
Iter: 1671 loss: 7.8217704e-07
Iter: 1672 loss: 7.82416123e-07
Iter: 1673 loss: 7.82175334e-07
Iter: 1674 loss: 7.82096038e-07
Iter: 1675 loss: 7.82066877e-07
Iter: 1676 loss: 7.82046868e-07
Iter: 1677 loss: 7.81954e-07
Iter: 1678 loss: 7.82246445e-07
Iter: 1679 loss: 7.81885433e-07
Iter: 1680 loss: 7.81867584e-07
Iter: 1681 loss: 7.81962626e-07
Iter: 1682 loss: 7.81818073e-07
Iter: 1683 loss: 7.817236e-07
Iter: 1684 loss: 7.82023676e-07
Iter: 1685 loss: 7.8168307e-07
Iter: 1686 loss: 7.81626738e-07
Iter: 1687 loss: 7.82149755e-07
Iter: 1688 loss: 7.8156495e-07
Iter: 1689 loss: 7.81516519e-07
Iter: 1690 loss: 7.81359404e-07
Iter: 1691 loss: 7.82405323e-07
Iter: 1692 loss: 7.81323763e-07
Iter: 1693 loss: 7.81136691e-07
Iter: 1694 loss: 7.81162385e-07
Iter: 1695 loss: 7.81036704e-07
Iter: 1696 loss: 7.80993162e-07
Iter: 1697 loss: 7.80948199e-07
Iter: 1698 loss: 7.80861455e-07
Iter: 1699 loss: 7.80851281e-07
Iter: 1700 loss: 7.80784603e-07
Iter: 1701 loss: 7.81176652e-07
Iter: 1702 loss: 7.80786081e-07
Iter: 1703 loss: 7.80770733e-07
Iter: 1704 loss: 7.80818709e-07
Iter: 1705 loss: 7.80753567e-07
Iter: 1706 loss: 7.80690357e-07
Iter: 1707 loss: 7.80583548e-07
Iter: 1708 loss: 7.82681582e-07
Iter: 1709 loss: 7.80569394e-07
Iter: 1710 loss: 7.80525681e-07
Iter: 1711 loss: 7.81558469e-07
Iter: 1712 loss: 7.80532e-07
Iter: 1713 loss: 7.80480377e-07
Iter: 1714 loss: 7.80406083e-07
Iter: 1715 loss: 7.8039136e-07
Iter: 1716 loss: 7.80284495e-07
Iter: 1717 loss: 7.81183e-07
Iter: 1718 loss: 7.80303878e-07
Iter: 1719 loss: 7.80257949e-07
Iter: 1720 loss: 7.80747428e-07
Iter: 1721 loss: 7.80212758e-07
Iter: 1722 loss: 7.80169216e-07
Iter: 1723 loss: 7.80013579e-07
Iter: 1724 loss: 7.81122253e-07
Iter: 1725 loss: 7.79987829e-07
Iter: 1726 loss: 7.79875734e-07
Iter: 1727 loss: 7.79889547e-07
Iter: 1728 loss: 7.798e-07
Iter: 1729 loss: 7.79683774e-07
Iter: 1730 loss: 7.79656943e-07
Iter: 1731 loss: 7.7961073e-07
Iter: 1732 loss: 7.80702862e-07
Iter: 1733 loss: 7.79582e-07
Iter: 1734 loss: 7.7956372e-07
Iter: 1735 loss: 7.79535071e-07
Iter: 1736 loss: 7.79497555e-07
Iter: 1737 loss: 7.7947783e-07
Iter: 1738 loss: 7.79460095e-07
Iter: 1739 loss: 7.79367156e-07
Iter: 1740 loss: 7.79720779e-07
Iter: 1741 loss: 7.79380741e-07
Iter: 1742 loss: 7.79323216e-07
Iter: 1743 loss: 7.79242896e-07
Iter: 1744 loss: 7.79259381e-07
Iter: 1745 loss: 7.79172638e-07
Iter: 1746 loss: 7.79728964e-07
Iter: 1747 loss: 7.79178777e-07
Iter: 1748 loss: 7.79154448e-07
Iter: 1749 loss: 7.79191225e-07
Iter: 1750 loss: 7.79106699e-07
Iter: 1751 loss: 7.78986305e-07
Iter: 1752 loss: 7.78988351e-07
Iter: 1753 loss: 7.78934634e-07
Iter: 1754 loss: 7.78820549e-07
Iter: 1755 loss: 7.79550874e-07
Iter: 1756 loss: 7.78810147e-07
Iter: 1757 loss: 7.78729714e-07
Iter: 1758 loss: 7.7859238e-07
Iter: 1759 loss: 7.82174936e-07
Iter: 1760 loss: 7.7857419e-07
Iter: 1761 loss: 7.78464482e-07
Iter: 1762 loss: 7.78470508e-07
Iter: 1763 loss: 7.78374215e-07
Iter: 1764 loss: 7.78234835e-07
Iter: 1765 loss: 7.78239723e-07
Iter: 1766 loss: 7.78253366e-07
Iter: 1767 loss: 7.78205e-07
Iter: 1768 loss: 7.78150309e-07
Iter: 1769 loss: 7.78450271e-07
Iter: 1770 loss: 7.78138599e-07
Iter: 1771 loss: 7.78094204e-07
Iter: 1772 loss: 7.78031392e-07
Iter: 1773 loss: 7.7962352e-07
Iter: 1774 loss: 7.77999503e-07
Iter: 1775 loss: 7.77946696e-07
Iter: 1776 loss: 7.78301569e-07
Iter: 1777 loss: 7.77953574e-07
Iter: 1778 loss: 7.77878938e-07
Iter: 1779 loss: 7.77868365e-07
Iter: 1780 loss: 7.77862112e-07
Iter: 1781 loss: 7.77727337e-07
Iter: 1782 loss: 7.7800297e-07
Iter: 1783 loss: 7.77696869e-07
Iter: 1784 loss: 7.77628316e-07
Iter: 1785 loss: 7.78077833e-07
Iter: 1786 loss: 7.77600235e-07
Iter: 1787 loss: 7.77556238e-07
Iter: 1788 loss: 7.77485184e-07
Iter: 1789 loss: 7.77426578e-07
Iter: 1790 loss: 7.77347282e-07
Iter: 1791 loss: 7.7853656e-07
Iter: 1792 loss: 7.7734046e-07
Iter: 1793 loss: 7.77264518e-07
Iter: 1794 loss: 7.77193065e-07
Iter: 1795 loss: 7.77189314e-07
Iter: 1796 loss: 7.77073069e-07
Iter: 1797 loss: 7.7779066e-07
Iter: 1798 loss: 7.7707557e-07
Iter: 1799 loss: 7.77003834e-07
Iter: 1800 loss: 7.76950515e-07
Iter: 1801 loss: 7.76913225e-07
Iter: 1802 loss: 7.76916806e-07
Iter: 1803 loss: 7.76850811e-07
Iter: 1804 loss: 7.76830689e-07
Iter: 1805 loss: 7.76823242e-07
Iter: 1806 loss: 7.76803347e-07
Iter: 1807 loss: 7.76717457e-07
Iter: 1808 loss: 7.76637307e-07
Iter: 1809 loss: 7.77887749e-07
Iter: 1810 loss: 7.76622414e-07
Iter: 1811 loss: 7.76549484e-07
Iter: 1812 loss: 7.76535217e-07
Iter: 1813 loss: 7.76470415e-07
Iter: 1814 loss: 7.76564548e-07
Iter: 1815 loss: 7.76439208e-07
Iter: 1816 loss: 7.76361162e-07
Iter: 1817 loss: 7.76237414e-07
Iter: 1818 loss: 7.7623622e-07
Iter: 1819 loss: 7.76163574e-07
Iter: 1820 loss: 7.76318302e-07
Iter: 1821 loss: 7.7614061e-07
Iter: 1822 loss: 7.7604227e-07
Iter: 1823 loss: 7.7608081e-07
Iter: 1824 loss: 7.75983e-07
Iter: 1825 loss: 7.76136176e-07
Iter: 1826 loss: 7.7597133e-07
Iter: 1827 loss: 7.75895955e-07
Iter: 1828 loss: 7.75837066e-07
Iter: 1829 loss: 7.75823537e-07
Iter: 1830 loss: 7.75743501e-07
Iter: 1831 loss: 7.75924718e-07
Iter: 1832 loss: 7.75723606e-07
Iter: 1833 loss: 7.75625608e-07
Iter: 1834 loss: 7.75671595e-07
Iter: 1835 loss: 7.75541253e-07
Iter: 1836 loss: 7.75492708e-07
Iter: 1837 loss: 7.75865487e-07
Iter: 1838 loss: 7.75476735e-07
Iter: 1839 loss: 7.75460705e-07
Iter: 1840 loss: 7.75440697e-07
Iter: 1841 loss: 7.75385e-07
Iter: 1842 loss: 7.75330591e-07
Iter: 1843 loss: 7.75318142e-07
Iter: 1844 loss: 7.75275453e-07
Iter: 1845 loss: 7.75398e-07
Iter: 1846 loss: 7.75275339e-07
Iter: 1847 loss: 7.75177e-07
Iter: 1848 loss: 7.75114302e-07
Iter: 1849 loss: 7.75070873e-07
Iter: 1850 loss: 7.75034778e-07
Iter: 1851 loss: 7.75466333e-07
Iter: 1852 loss: 7.75028127e-07
Iter: 1853 loss: 7.74944567e-07
Iter: 1854 loss: 7.74861348e-07
Iter: 1855 loss: 7.7487681e-07
Iter: 1856 loss: 7.74807575e-07
Iter: 1857 loss: 7.74790351e-07
Iter: 1858 loss: 7.74777618e-07
Iter: 1859 loss: 7.74839691e-07
Iter: 1860 loss: 7.74709633e-07
Iter: 1861 loss: 7.7467746e-07
Iter: 1862 loss: 7.7493587e-07
Iter: 1863 loss: 7.74635168e-07
Iter: 1864 loss: 7.74615273e-07
Iter: 1865 loss: 7.74550358e-07
Iter: 1866 loss: 7.74550699e-07
Iter: 1867 loss: 7.74444743e-07
Iter: 1868 loss: 7.75137437e-07
Iter: 1869 loss: 7.74443151e-07
Iter: 1870 loss: 7.74390287e-07
Iter: 1871 loss: 7.74442583e-07
Iter: 1872 loss: 7.74362604e-07
Iter: 1873 loss: 7.74290129e-07
Iter: 1874 loss: 7.7428615e-07
Iter: 1875 loss: 7.74246075e-07
Iter: 1876 loss: 7.74209241e-07
Iter: 1877 loss: 7.74186788e-07
Iter: 1878 loss: 7.74146372e-07
Iter: 1879 loss: 7.74102887e-07
Iter: 1880 loss: 7.74096634e-07
Iter: 1881 loss: 7.73937359e-07
Iter: 1882 loss: 7.74828152e-07
Iter: 1883 loss: 7.73926274e-07
Iter: 1884 loss: 7.73843226e-07
Iter: 1885 loss: 7.73899046e-07
Iter: 1886 loss: 7.73804913e-07
Iter: 1887 loss: 7.73698389e-07
Iter: 1888 loss: 7.73936e-07
Iter: 1889 loss: 7.73733746e-07
Iter: 1890 loss: 7.73651266e-07
Iter: 1891 loss: 7.74197929e-07
Iter: 1892 loss: 7.73677698e-07
Iter: 1893 loss: 7.73590614e-07
Iter: 1894 loss: 7.73491081e-07
Iter: 1895 loss: 7.73496083e-07
Iter: 1896 loss: 7.73426848e-07
Iter: 1897 loss: 7.7342213e-07
Iter: 1898 loss: 7.73363126e-07
Iter: 1899 loss: 7.73245176e-07
Iter: 1900 loss: 7.74425871e-07
Iter: 1901 loss: 7.73246882e-07
Iter: 1902 loss: 7.73108923e-07
Iter: 1903 loss: 7.73899e-07
Iter: 1904 loss: 7.73092779e-07
Iter: 1905 loss: 7.73088686e-07
Iter: 1906 loss: 7.73048e-07
Iter: 1907 loss: 7.73025931e-07
Iter: 1908 loss: 7.72916565e-07
Iter: 1909 loss: 7.72913609e-07
Iter: 1910 loss: 7.72848239e-07
Iter: 1911 loss: 7.72926569e-07
Iter: 1912 loss: 7.72808619e-07
Iter: 1913 loss: 7.72717556e-07
Iter: 1914 loss: 7.72666112e-07
Iter: 1915 loss: 7.7262257e-07
Iter: 1916 loss: 7.72463864e-07
Iter: 1917 loss: 7.74213561e-07
Iter: 1918 loss: 7.72481656e-07
Iter: 1919 loss: 7.72411113e-07
Iter: 1920 loss: 7.72447947e-07
Iter: 1921 loss: 7.7236524e-07
Iter: 1922 loss: 7.72248541e-07
Iter: 1923 loss: 7.72228077e-07
Iter: 1924 loss: 7.72161684e-07
Iter: 1925 loss: 7.72050043e-07
Iter: 1926 loss: 7.72537817e-07
Iter: 1927 loss: 7.72030262e-07
Iter: 1928 loss: 7.71926807e-07
Iter: 1929 loss: 7.72427882e-07
Iter: 1930 loss: 7.71898e-07
Iter: 1931 loss: 7.71829832e-07
Iter: 1932 loss: 7.71836199e-07
Iter: 1933 loss: 7.71764576e-07
Iter: 1934 loss: 7.71620762e-07
Iter: 1935 loss: 7.72554e-07
Iter: 1936 loss: 7.71611099e-07
Iter: 1937 loss: 7.71535611e-07
Iter: 1938 loss: 7.71519581e-07
Iter: 1939 loss: 7.7144864e-07
Iter: 1940 loss: 7.71906457e-07
Iter: 1941 loss: 7.71433747e-07
Iter: 1942 loss: 7.71322561e-07
Iter: 1943 loss: 7.71376335e-07
Iter: 1944 loss: 7.71291411e-07
Iter: 1945 loss: 7.71210807e-07
Iter: 1946 loss: 7.71206828e-07
Iter: 1947 loss: 7.71154077e-07
Iter: 1948 loss: 7.71097916e-07
Iter: 1949 loss: 7.71086889e-07
Iter: 1950 loss: 7.71051646e-07
Iter: 1951 loss: 7.70978318e-07
Iter: 1952 loss: 7.71542602e-07
Iter: 1953 loss: 7.70954102e-07
Iter: 1954 loss: 7.70888846e-07
Iter: 1955 loss: 7.7100276e-07
Iter: 1956 loss: 7.70824045e-07
Iter: 1957 loss: 7.70745146e-07
Iter: 1958 loss: 7.71381e-07
Iter: 1959 loss: 7.70726274e-07
Iter: 1960 loss: 7.70666873e-07
Iter: 1961 loss: 7.70552219e-07
Iter: 1962 loss: 7.71907821e-07
Iter: 1963 loss: 7.7054284e-07
Iter: 1964 loss: 7.70399311e-07
Iter: 1965 loss: 7.72351427e-07
Iter: 1966 loss: 7.70411134e-07
Iter: 1967 loss: 7.70342865e-07
Iter: 1968 loss: 7.70479346e-07
Iter: 1969 loss: 7.7031325e-07
Iter: 1970 loss: 7.70203542e-07
Iter: 1971 loss: 7.70955808e-07
Iter: 1972 loss: 7.7017188e-07
Iter: 1973 loss: 7.70111114e-07
Iter: 1974 loss: 7.70129873e-07
Iter: 1975 loss: 7.7010543e-07
Iter: 1976 loss: 7.70009422e-07
Iter: 1977 loss: 7.70020733e-07
Iter: 1978 loss: 7.69970256e-07
Iter: 1979 loss: 7.69938936e-07
Iter: 1980 loss: 7.69904e-07
Iter: 1981 loss: 7.69831786e-07
Iter: 1982 loss: 7.6986106e-07
Iter: 1983 loss: 7.69810185e-07
Iter: 1984 loss: 7.69738278e-07
Iter: 1985 loss: 7.70022098e-07
Iter: 1986 loss: 7.69728558e-07
Iter: 1987 loss: 7.69703206e-07
Iter: 1988 loss: 7.69882774e-07
Iter: 1989 loss: 7.69652274e-07
Iter: 1990 loss: 7.69609073e-07
Iter: 1991 loss: 7.69663757e-07
Iter: 1992 loss: 7.69571443e-07
Iter: 1993 loss: 7.69480721e-07
Iter: 1994 loss: 7.69519545e-07
Iter: 1995 loss: 7.69440135e-07
Iter: 1996 loss: 7.69338726e-07
Iter: 1997 loss: 7.70388738e-07
Iter: 1998 loss: 7.69327585e-07
Iter: 1999 loss: 7.69193775e-07
Iter: 2000 loss: 7.69180303e-07
Iter: 2001 loss: 7.69129201e-07
Iter: 2002 loss: 7.69246071e-07
Iter: 2003 loss: 7.69112319e-07
Iter: 2004 loss: 7.68980499e-07
Iter: 2005 loss: 7.69052065e-07
Iter: 2006 loss: 7.68914902e-07
Iter: 2007 loss: 7.68876419e-07
Iter: 2008 loss: 7.68859593e-07
Iter: 2009 loss: 7.68802465e-07
Iter: 2010 loss: 7.68731411e-07
Iter: 2011 loss: 7.6873232e-07
Iter: 2012 loss: 7.68702193e-07
Iter: 2013 loss: 7.68578047e-07
Iter: 2014 loss: 7.68572932e-07
Iter: 2015 loss: 7.68498296e-07
Iter: 2016 loss: 7.68598511e-07
Iter: 2017 loss: 7.68397058e-07
Iter: 2018 loss: 7.68281268e-07
Iter: 2019 loss: 7.68288771e-07
Iter: 2020 loss: 7.68216751e-07
Iter: 2021 loss: 7.68284508e-07
Iter: 2022 loss: 7.68188329e-07
Iter: 2023 loss: 7.68126142e-07
Iter: 2024 loss: 7.68392e-07
Iter: 2025 loss: 7.680826e-07
Iter: 2026 loss: 7.68010864e-07
Iter: 2027 loss: 7.6874187e-07
Iter: 2028 loss: 7.68008931e-07
Iter: 2029 loss: 7.67969823e-07
Iter: 2030 loss: 7.67812935e-07
Iter: 2031 loss: 7.6921981e-07
Iter: 2032 loss: 7.67837662e-07
Iter: 2033 loss: 7.67673498e-07
Iter: 2034 loss: 7.68875111e-07
Iter: 2035 loss: 7.67684526e-07
Iter: 2036 loss: 7.67562142e-07
Iter: 2037 loss: 7.67599772e-07
Iter: 2038 loss: 7.67499273e-07
Iter: 2039 loss: 7.67334427e-07
Iter: 2040 loss: 7.68947189e-07
Iter: 2041 loss: 7.67325218e-07
Iter: 2042 loss: 7.67255926e-07
Iter: 2043 loss: 7.67487165e-07
Iter: 2044 loss: 7.67253084e-07
Iter: 2045 loss: 7.67176118e-07
Iter: 2046 loss: 7.68015298e-07
Iter: 2047 loss: 7.67147185e-07
Iter: 2048 loss: 7.6712081e-07
Iter: 2049 loss: 7.67039296e-07
Iter: 2050 loss: 7.68399104e-07
Iter: 2051 loss: 7.67027e-07
Iter: 2052 loss: 7.6694505e-07
Iter: 2053 loss: 7.66984783e-07
Iter: 2054 loss: 7.66913843e-07
Iter: 2055 loss: 7.66840571e-07
Iter: 2056 loss: 7.67358529e-07
Iter: 2057 loss: 7.66807204e-07
Iter: 2058 loss: 7.6672859e-07
Iter: 2059 loss: 7.66716198e-07
Iter: 2060 loss: 7.66671576e-07
Iter: 2061 loss: 7.66608196e-07
Iter: 2062 loss: 7.6770641e-07
Iter: 2063 loss: 7.66606e-07
Iter: 2064 loss: 7.66479104e-07
Iter: 2065 loss: 7.66549874e-07
Iter: 2066 loss: 7.66466428e-07
Iter: 2067 loss: 7.66366156e-07
Iter: 2068 loss: 7.66526796e-07
Iter: 2069 loss: 7.66338303e-07
Iter: 2070 loss: 7.66258609e-07
Iter: 2071 loss: 7.66423682e-07
Iter: 2072 loss: 7.6623212e-07
Iter: 2073 loss: 7.6616e-07
Iter: 2074 loss: 7.66544531e-07
Iter: 2075 loss: 7.66117466e-07
Iter: 2076 loss: 7.66080404e-07
Iter: 2077 loss: 7.66095809e-07
Iter: 2078 loss: 7.660758e-07
Iter: 2079 loss: 7.66227572e-07
Iter: 2080 loss: 7.66057667e-07
Iter: 2081 loss: 7.66019639e-07
Iter: 2082 loss: 7.65956656e-07
Iter: 2083 loss: 7.67013773e-07
Iter: 2084 loss: 7.65964103e-07
Iter: 2085 loss: 7.65886057e-07
Iter: 2086 loss: 7.66065e-07
Iter: 2087 loss: 7.65907828e-07
Iter: 2088 loss: 7.6586042e-07
Iter: 2089 loss: 7.65759296e-07
Iter: 2090 loss: 7.65724621e-07
Iter: 2091 loss: 7.65635662e-07
Iter: 2092 loss: 7.66571588e-07
Iter: 2093 loss: 7.65657092e-07
Iter: 2094 loss: 7.65575692e-07
Iter: 2095 loss: 7.65559037e-07
Iter: 2096 loss: 7.65510208e-07
Iter: 2097 loss: 7.65386233e-07
Iter: 2098 loss: 7.65939319e-07
Iter: 2099 loss: 7.6540357e-07
Iter: 2100 loss: 7.65304833e-07
Iter: 2101 loss: 7.65521463e-07
Iter: 2102 loss: 7.6526112e-07
Iter: 2103 loss: 7.6516676e-07
Iter: 2104 loss: 7.66010544e-07
Iter: 2105 loss: 7.65178356e-07
Iter: 2106 loss: 7.65105767e-07
Iter: 2107 loss: 7.65024083e-07
Iter: 2108 loss: 7.65073196e-07
Iter: 2109 loss: 7.64922277e-07
Iter: 2110 loss: 7.65464961e-07
Iter: 2111 loss: 7.64912215e-07
Iter: 2112 loss: 7.64847e-07
Iter: 2113 loss: 7.64853098e-07
Iter: 2114 loss: 7.64812285e-07
Iter: 2115 loss: 7.64763399e-07
Iter: 2116 loss: 7.64747824e-07
Iter: 2117 loss: 7.64675747e-07
Iter: 2118 loss: 7.64536139e-07
Iter: 2119 loss: 7.67544634e-07
Iter: 2120 loss: 7.64532729e-07
Iter: 2121 loss: 7.64431775e-07
Iter: 2122 loss: 7.65659252e-07
Iter: 2123 loss: 7.64431775e-07
Iter: 2124 loss: 7.64369872e-07
Iter: 2125 loss: 7.64222364e-07
Iter: 2126 loss: 7.67163215e-07
Iter: 2127 loss: 7.64212132e-07
Iter: 2128 loss: 7.64113281e-07
Iter: 2129 loss: 7.65669313e-07
Iter: 2130 loss: 7.64113679e-07
Iter: 2131 loss: 7.64015624e-07
Iter: 2132 loss: 7.6408827e-07
Iter: 2133 loss: 7.63971116e-07
Iter: 2134 loss: 7.63869593e-07
Iter: 2135 loss: 7.64671256e-07
Iter: 2136 loss: 7.6388153e-07
Iter: 2137 loss: 7.63800301e-07
Iter: 2138 loss: 7.63871128e-07
Iter: 2139 loss: 7.6375909e-07
Iter: 2140 loss: 7.63676098e-07
Iter: 2141 loss: 7.64069e-07
Iter: 2142 loss: 7.63649837e-07
Iter: 2143 loss: 7.63571336e-07
Iter: 2144 loss: 7.6370776e-07
Iter: 2145 loss: 7.63558091e-07
Iter: 2146 loss: 7.63505284e-07
Iter: 2147 loss: 7.63547234e-07
Iter: 2148 loss: 7.63436503e-07
Iter: 2149 loss: 7.63473508e-07
Iter: 2150 loss: 7.63401772e-07
Iter: 2151 loss: 7.634e-07
Iter: 2152 loss: 7.63339642e-07
Iter: 2153 loss: 7.64147103e-07
Iter: 2154 loss: 7.63363346e-07
Iter: 2155 loss: 7.63316621e-07
Iter: 2156 loss: 7.63332707e-07
Iter: 2157 loss: 7.63287403e-07
Iter: 2158 loss: 7.63250853e-07
Iter: 2159 loss: 7.64062634e-07
Iter: 2160 loss: 7.6327e-07
Iter: 2161 loss: 7.63246533e-07
Iter: 2162 loss: 7.63134551e-07
Iter: 2163 loss: 7.64339575e-07
Iter: 2164 loss: 7.63132903e-07
Iter: 2165 loss: 7.63082767e-07
Iter: 2166 loss: 7.63080948e-07
Iter: 2167 loss: 7.6305821e-07
Iter: 2168 loss: 7.62973855e-07
Iter: 2169 loss: 7.64630954e-07
Iter: 2170 loss: 7.62974253e-07
Iter: 2171 loss: 7.6287597e-07
Iter: 2172 loss: 7.6378e-07
Iter: 2173 loss: 7.62876311e-07
Iter: 2174 loss: 7.62779109e-07
Iter: 2175 loss: 7.63303603e-07
Iter: 2176 loss: 7.6281367e-07
Iter: 2177 loss: 7.62724881e-07
Iter: 2178 loss: 7.63338448e-07
Iter: 2179 loss: 7.6269464e-07
Iter: 2180 loss: 7.62650188e-07
Iter: 2181 loss: 7.62557193e-07
Iter: 2182 loss: 7.64328e-07
Iter: 2183 loss: 7.6258118e-07
Iter: 2184 loss: 7.62594254e-07
Iter: 2185 loss: 7.62547472e-07
Iter: 2186 loss: 7.62501713e-07
Iter: 2187 loss: 7.62681793e-07
Iter: 2188 loss: 7.62481477e-07
Iter: 2189 loss: 7.62495063e-07
Iter: 2190 loss: 7.62480795e-07
Iter: 2191 loss: 7.62496938e-07
Iter: 2192 loss: 7.62502395e-07
Iter: 2193 loss: 7.62477839e-07
Iter: 2194 loss: 7.62492846e-07
Iter: 2195 loss: 7.62494949e-07
Iter: 2196 loss: 7.62470677e-07
Iter: 2197 loss: 7.62495347e-07
Iter: 2198 loss: 7.62496029e-07
Iter: 2199 loss: 7.6248e-07
Iter: 2200 loss: 7.62485627e-07
Iter: 2201 loss: 7.62480568e-07
Iter: 2202 loss: 7.62489947e-07
Iter: 2203 loss: 7.62479885e-07
Iter: 2204 loss: 7.62485456e-07
Iter: 2205 loss: 7.62483637e-07
Iter: 2206 loss: 7.62483182e-07
Iter: 2207 loss: 7.62479885e-07
Iter: 2208 loss: 7.62482728e-07
Iter: 2209 loss: 7.62481307e-07
Iter: 2210 loss: 7.62481591e-07
Iter: 2211 loss: 7.62481591e-07
Iter: 2212 loss: 7.62482728e-07
Iter: 2213 loss: 7.62481591e-07
Iter: 2214 loss: 7.62482728e-07
Iter: 2215 loss: 7.62355e-07
Iter: 2216 loss: 7.64587412e-07
Iter: 2217 loss: 7.6235051e-07
Iter: 2218 loss: 7.62336413e-07
Iter: 2219 loss: 7.62294576e-07
Iter: 2220 loss: 7.6228514e-07
Iter: 2221 loss: 7.62233071e-07
Iter: 2222 loss: 7.6224228e-07
Iter: 2223 loss: 7.62212267e-07
Iter: 2224 loss: 7.62342665e-07
Iter: 2225 loss: 7.62193622e-07
Iter: 2226 loss: 7.62136551e-07
Iter: 2227 loss: 7.62089144e-07
Iter: 2228 loss: 7.62085904e-07
Iter: 2229 loss: 7.62035143e-07
Iter: 2230 loss: 7.6227218e-07
Iter: 2231 loss: 7.62044351e-07
Iter: 2232 loss: 7.61954198e-07
Iter: 2233 loss: 7.61979209e-07
Iter: 2234 loss: 7.61924923e-07
Iter: 2235 loss: 7.61867796e-07
Iter: 2236 loss: 7.62091531e-07
Iter: 2237 loss: 7.61853869e-07
Iter: 2238 loss: 7.6184358e-07
Iter: 2239 loss: 7.62316176e-07
Iter: 2240 loss: 7.61837669e-07
Iter: 2241 loss: 7.6184574e-07
Iter: 2242 loss: 7.61821866e-07
Iter: 2243 loss: 7.61840056e-07
Iter: 2244 loss: 7.61807541e-07
Iter: 2245 loss: 7.61815784e-07
Iter: 2246 loss: 7.6181459e-07
Iter: 2247 loss: 7.61846877e-07
Iter: 2248 loss: 7.61827323e-07
Iter: 2249 loss: 7.61814704e-07
Iter: 2250 loss: 7.61824424e-07
Iter: 2251 loss: 7.61823799e-07
Iter: 2252 loss: 7.61836702e-07
Iter: 2253 loss: 7.61834144e-07
Iter: 2254 loss: 7.61828801e-07
Iter: 2255 loss: 7.61837669e-07
Iter: 2256 loss: 7.61843239e-07
Iter: 2257 loss: 7.61839033e-07
Iter: 2258 loss: 7.61837555e-07
Iter: 2259 loss: 7.61838e-07
Iter: 2260 loss: 7.61838521e-07
Iter: 2261 loss: 7.61837725e-07
Iter: 2262 loss: 7.61838464e-07
Iter: 2263 loss: 7.61838578e-07
Iter: 2264 loss: 7.6183818e-07
Iter: 2265 loss: 7.6183818e-07
Iter: 2266 loss: 7.61838578e-07
Iter: 2267 loss: 7.61798219e-07
Iter: 2268 loss: 7.6197955e-07
Iter: 2269 loss: 7.6179424e-07
Iter: 2270 loss: 7.61815897e-07
Iter: 2271 loss: 7.61799868e-07
Iter: 2272 loss: 7.61784e-07
Iter: 2273 loss: 7.61807144e-07
Iter: 2274 loss: 7.61800607e-07
Iter: 2275 loss: 7.61814931e-07
Iter: 2276 loss: 7.61799129e-07
Iter: 2277 loss: 7.61799754e-07
Iter: 2278 loss: 7.61797253e-07
Iter: 2279 loss: 7.61789522e-07
Iter: 2280 loss: 7.61788215e-07
Iter: 2281 loss: 7.61788897e-07
Iter: 2282 loss: 7.61800152e-07
Iter: 2283 loss: 7.61785657e-07
Iter: 2284 loss: 7.61791171e-07
Iter: 2285 loss: 7.6179532e-07
Iter: 2286 loss: 7.61793103e-07
Iter: 2287 loss: 7.6179731e-07
Iter: 2288 loss: 7.61793274e-07
Iter: 2289 loss: 7.61797423e-07
Iter: 2290 loss: 7.61793387e-07
Iter: 2291 loss: 7.6179748e-07
Iter: 2292 loss: 7.61797423e-07
Iter: 2293 loss: 7.61797423e-07
Iter: 2294 loss: 7.61793387e-07
Iter: 2295 loss: 7.61797423e-07
Iter: 2296 loss: 7.61793387e-07
Iter: 2297 loss: 7.61709202e-07
Iter: 2298 loss: 7.62789284e-07
Iter: 2299 loss: 7.61709316e-07
Iter: 2300 loss: 7.61703689e-07
Iter: 2301 loss: 7.61761e-07
Iter: 2302 loss: 7.61672538e-07
Iter: 2303 loss: 7.61632805e-07
Iter: 2304 loss: 7.61603133e-07
Iter: 2305 loss: 7.6162371e-07
Iter: 2306 loss: 7.61585625e-07
Iter: 2307 loss: 7.6203753e-07
Iter: 2308 loss: 7.61577212e-07
Iter: 2309 loss: 7.61561296e-07
Iter: 2310 loss: 7.61518322e-07
Iter: 2311 loss: 7.61507181e-07
Iter: 2312 loss: 7.61473132e-07
Iter: 2313 loss: 7.6151548e-07
Iter: 2314 loss: 7.61417823e-07
Iter: 2315 loss: 7.61392471e-07
Iter: 2316 loss: 7.61483136e-07
Iter: 2317 loss: 7.613869e-07
Iter: 2318 loss: 7.61317438e-07
Iter: 2319 loss: 7.61405317e-07
Iter: 2320 loss: 7.61329488e-07
Iter: 2321 loss: 7.61266222e-07
Iter: 2322 loss: 7.61437548e-07
Iter: 2323 loss: 7.61300498e-07
Iter: 2324 loss: 7.61242632e-07
Iter: 2325 loss: 7.61255137e-07
Iter: 2326 loss: 7.6123024e-07
Iter: 2327 loss: 7.61156798e-07
Iter: 2328 loss: 7.61160891e-07
Iter: 2329 loss: 7.61170554e-07
Iter: 2330 loss: 7.61150318e-07
Iter: 2331 loss: 7.61141735e-07
Iter: 2332 loss: 7.61156741e-07
Iter: 2333 loss: 7.61177148e-07
Iter: 2334 loss: 7.61150261e-07
Iter: 2335 loss: 7.61160663e-07
Iter: 2336 loss: 7.61163562e-07
Iter: 2337 loss: 7.611809e-07
Iter: 2338 loss: 7.61155547e-07
Iter: 2339 loss: 7.61173169e-07
Iter: 2340 loss: 7.61170384e-07
Iter: 2341 loss: 7.61165211e-07
Iter: 2342 loss: 7.61159583e-07
Iter: 2343 loss: 7.61172942e-07
Iter: 2344 loss: 7.61162255e-07
Iter: 2345 loss: 7.61161573e-07
Iter: 2346 loss: 7.61163221e-07
Iter: 2347 loss: 7.61161971e-07
Iter: 2348 loss: 7.61161346e-07
Iter: 2349 loss: 7.61161573e-07
Iter: 2350 loss: 7.61161402e-07
Iter: 2351 loss: 7.61161459e-07
Iter: 2352 loss: 7.61161971e-07
Iter: 2353 loss: 7.61161459e-07
Iter: 2354 loss: 7.61161971e-07
Iter: 2355 loss: 7.61078809e-07
Iter: 2356 loss: 7.61535944e-07
Iter: 2357 loss: 7.61074489e-07
Iter: 2358 loss: 7.60991782e-07
Iter: 2359 loss: 7.6098712e-07
Iter: 2360 loss: 7.60985756e-07
Iter: 2361 loss: 7.60934597e-07
Iter: 2362 loss: 7.6093238e-07
Iter: 2363 loss: 7.60898104e-07
Iter: 2364 loss: 7.60873093e-07
Iter: 2365 loss: 7.60887247e-07
Iter: 2366 loss: 7.60794308e-07
Iter: 2367 loss: 7.61200454e-07
Iter: 2368 loss: 7.6078652e-07
Iter: 2369 loss: 7.60756791e-07
Iter: 2370 loss: 7.60843477e-07
Iter: 2371 loss: 7.60747696e-07
Iter: 2372 loss: 7.60683861e-07
Iter: 2373 loss: 7.60727858e-07
Iter: 2374 loss: 7.60633725e-07
Iter: 2375 loss: 7.60609623e-07
Iter: 2376 loss: 7.60684031e-07
Iter: 2377 loss: 7.60593537e-07
Iter: 2378 loss: 7.60551245e-07
Iter: 2379 loss: 7.61023784e-07
Iter: 2380 loss: 7.60558692e-07
Iter: 2381 loss: 7.60549824e-07
Iter: 2382 loss: 7.60520606e-07
Iter: 2383 loss: 7.60491503e-07
Iter: 2384 loss: 7.60450462e-07
Iter: 2385 loss: 7.60844614e-07
Iter: 2386 loss: 7.60482862e-07
Iter: 2387 loss: 7.60395608e-07
Iter: 2388 loss: 7.60404191e-07
Iter: 2389 loss: 7.60396688e-07
Iter: 2390 loss: 7.60360933e-07
Iter: 2391 loss: 7.60811e-07
Iter: 2392 loss: 7.60335581e-07
Iter: 2393 loss: 7.60301646e-07
Iter: 2394 loss: 7.6030085e-07
Iter: 2395 loss: 7.60282717e-07
Iter: 2396 loss: 7.60252249e-07
Iter: 2397 loss: 7.60225817e-07
Iter: 2398 loss: 7.60199612e-07
Iter: 2399 loss: 7.60191483e-07
Iter: 2400 loss: 7.60208593e-07
Iter: 2401 loss: 7.60120599e-07
Iter: 2402 loss: 7.60533851e-07
Iter: 2403 loss: 7.60101386e-07
Iter: 2404 loss: 7.60101329e-07
Iter: 2405 loss: 7.602913e-07
Iter: 2406 loss: 7.60078592e-07
Iter: 2407 loss: 7.60060516e-07
Iter: 2408 loss: 7.60011517e-07
Iter: 2409 loss: 7.61287197e-07
Iter: 2410 loss: 7.60022544e-07
Iter: 2411 loss: 7.599848e-07
Iter: 2412 loss: 7.59988e-07
Iter: 2413 loss: 7.59928241e-07
Iter: 2414 loss: 7.60302328e-07
Iter: 2415 loss: 7.59954673e-07
Iter: 2416 loss: 7.59917157e-07
Iter: 2417 loss: 7.59900331e-07
Iter: 2418 loss: 7.59877764e-07
Iter: 2419 loss: 7.59856619e-07
Iter: 2420 loss: 7.59950467e-07
Iter: 2421 loss: 7.59860086e-07
Iter: 2422 loss: 7.59840759e-07
Iter: 2423 loss: 7.59766806e-07
Iter: 2424 loss: 7.60994e-07
Iter: 2425 loss: 7.59767829e-07
Iter: 2426 loss: 7.59705188e-07
Iter: 2427 loss: 7.5971252e-07
Iter: 2428 loss: 7.59681029e-07
Iter: 2429 loss: 7.597273e-07
Iter: 2430 loss: 7.59663294e-07
Iter: 2431 loss: 7.59649424e-07
Iter: 2432 loss: 7.59769932e-07
Iter: 2433 loss: 7.59631121e-07
Iter: 2434 loss: 7.59614295e-07
Iter: 2435 loss: 7.59679779e-07
Iter: 2436 loss: 7.59584054e-07
Iter: 2437 loss: 7.59564898e-07
Iter: 2438 loss: 7.59522e-07
Iter: 2439 loss: 7.59523118e-07
Iter: 2440 loss: 7.59497084e-07
Iter: 2441 loss: 7.59908232e-07
Iter: 2442 loss: 7.59481509e-07
Iter: 2443 loss: 7.59480031e-07
Iter: 2444 loss: 7.59423699e-07
Iter: 2445 loss: 7.59422278e-07
Iter: 2446 loss: 7.59391e-07
Iter: 2447 loss: 7.59369073e-07
Iter: 2448 loss: 7.59312911e-07
Iter: 2449 loss: 7.59786303e-07
Iter: 2450 loss: 7.59316606e-07
Iter: 2451 loss: 7.59316436e-07
Iter: 2452 loss: 7.59280283e-07
Iter: 2453 loss: 7.59446721e-07
Iter: 2454 loss: 7.59274485e-07
Iter: 2455 loss: 7.5922685e-07
Iter: 2456 loss: 7.59439843e-07
Iter: 2457 loss: 7.59193e-07
Iter: 2458 loss: 7.59131808e-07
Iter: 2459 loss: 7.59213e-07
Iter: 2460 loss: 7.59152158e-07
Iter: 2461 loss: 7.59088152e-07
Iter: 2462 loss: 7.5936839e-07
Iter: 2463 loss: 7.59058196e-07
Iter: 2464 loss: 7.59019372e-07
Iter: 2465 loss: 7.59308932e-07
Iter: 2466 loss: 7.59028239e-07
Iter: 2467 loss: 7.58995725e-07
Iter: 2468 loss: 7.58915348e-07
Iter: 2469 loss: 7.58955935e-07
Iter: 2470 loss: 7.58867372e-07
Iter: 2471 loss: 7.59604632e-07
Iter: 2472 loss: 7.58872716e-07
Iter: 2473 loss: 7.58861688e-07
Iter: 2474 loss: 7.58872091e-07
Iter: 2475 loss: 7.588377e-07
Iter: 2476 loss: 7.58781653e-07
Iter: 2477 loss: 7.58796318e-07
Iter: 2478 loss: 7.58771193e-07
Iter: 2479 loss: 7.58724696e-07
Iter: 2480 loss: 7.59034322e-07
Iter: 2481 loss: 7.5873e-07
Iter: 2482 loss: 7.58696956e-07
Iter: 2483 loss: 7.59105831e-07
Iter: 2484 loss: 7.58691272e-07
Iter: 2485 loss: 7.58651765e-07
Iter: 2486 loss: 7.58641e-07
Iter: 2487 loss: 7.59411478e-07
Iter: 2488 loss: 7.58611918e-07
Iter: 2489 loss: 7.58581905e-07
Iter: 2490 loss: 7.58734359e-07
Iter: 2491 loss: 7.58579063e-07
Iter: 2492 loss: 7.58535862e-07
Iter: 2493 loss: 7.58466456e-07
Iter: 2494 loss: 7.58485726e-07
Iter: 2495 loss: 7.5840552e-07
Iter: 2496 loss: 7.5842172e-07
Iter: 2497 loss: 7.58359761e-07
Iter: 2498 loss: 7.58379144e-07
Iter: 2499 loss: 7.58333385e-07
Iter: 2500 loss: 7.58242209e-07
Iter: 2501 loss: 7.58566841e-07
Iter: 2502 loss: 7.58273359e-07
Iter: 2503 loss: 7.58188264e-07
Iter: 2504 loss: 7.58677118e-07
Iter: 2505 loss: 7.58197132e-07
Iter: 2506 loss: 7.58180136e-07
Iter: 2507 loss: 7.58149156e-07
Iter: 2508 loss: 7.58147394e-07
Iter: 2509 loss: 7.58117778e-07
Iter: 2510 loss: 7.58486294e-07
Iter: 2511 loss: 7.58085662e-07
Iter: 2512 loss: 7.58052806e-07
Iter: 2513 loss: 7.57982207e-07
Iter: 2514 loss: 7.58573492e-07
Iter: 2515 loss: 7.5799511e-07
Iter: 2516 loss: 7.57870623e-07
Iter: 2517 loss: 7.58700423e-07
Iter: 2518 loss: 7.57848852e-07
Iter: 2519 loss: 7.57818725e-07
Iter: 2520 loss: 7.58353451e-07
Iter: 2521 loss: 7.57809289e-07
Iter: 2522 loss: 7.5776228e-07
Iter: 2523 loss: 7.57757448e-07
Iter: 2524 loss: 7.57708619e-07
Iter: 2525 loss: 7.57701741e-07
Iter: 2526 loss: 7.57772796e-07
Iter: 2527 loss: 7.57676105e-07
Iter: 2528 loss: 7.57646944e-07
Iter: 2529 loss: 7.57663e-07
Iter: 2530 loss: 7.57620171e-07
Iter: 2531 loss: 7.5758669e-07
Iter: 2532 loss: 7.57907685e-07
Iter: 2533 loss: 7.57564749e-07
Iter: 2534 loss: 7.57546445e-07
Iter: 2535 loss: 7.57586065e-07
Iter: 2536 loss: 7.5752655e-07
Iter: 2537 loss: 7.57509724e-07
Iter: 2538 loss: 7.57685314e-07
Iter: 2539 loss: 7.57505404e-07
Iter: 2540 loss: 7.57442308e-07
Iter: 2541 loss: 7.57464363e-07
Iter: 2542 loss: 7.57403427e-07
Iter: 2543 loss: 7.57355e-07
Iter: 2544 loss: 7.57513476e-07
Iter: 2545 loss: 7.57344196e-07
Iter: 2546 loss: 7.57313501e-07
Iter: 2547 loss: 7.57453677e-07
Iter: 2548 loss: 7.57282237e-07
Iter: 2549 loss: 7.5728633e-07
Iter: 2550 loss: 7.57282237e-07
Iter: 2551 loss: 7.57236819e-07
Iter: 2552 loss: 7.57262285e-07
Iter: 2553 loss: 7.57259158e-07
Iter: 2554 loss: 7.57272915e-07
Iter: 2555 loss: 7.57285875e-07
Iter: 2556 loss: 7.57262796e-07
Iter: 2557 loss: 7.57275e-07
Iter: 2558 loss: 7.5726166e-07
Iter: 2559 loss: 7.57269731e-07
Iter: 2560 loss: 7.57264957e-07
Iter: 2561 loss: 7.57261205e-07
Iter: 2562 loss: 7.572703e-07
Iter: 2563 loss: 7.5726939e-07
Iter: 2564 loss: 7.57271778e-07
Iter: 2565 loss: 7.57275757e-07
Iter: 2566 loss: 7.57289229e-07
Iter: 2567 loss: 7.57281782e-07
Iter: 2568 loss: 7.57288149e-07
Iter: 2569 loss: 7.57287239e-07
Iter: 2570 loss: 7.57285136e-07
Iter: 2571 loss: 7.57284056e-07
Iter: 2572 loss: 7.57283317e-07
Iter: 2573 loss: 7.57281782e-07
Iter: 2574 loss: 7.57283317e-07
Iter: 2575 loss: 7.57147518e-07
Iter: 2576 loss: 7.58743738e-07
Iter: 2577 loss: 7.57133421e-07
Iter: 2578 loss: 7.5749665e-07
Iter: 2579 loss: 7.57111195e-07
Iter: 2580 loss: 7.57090675e-07
Iter: 2581 loss: 7.57069586e-07
Iter: 2582 loss: 7.57225337e-07
Iter: 2583 loss: 7.57054636e-07
Iter: 2584 loss: 7.56975396e-07
Iter: 2585 loss: 7.57614885e-07
Iter: 2586 loss: 7.56986083e-07
Iter: 2587 loss: 7.56958798e-07
Iter: 2588 loss: 7.56997e-07
Iter: 2589 loss: 7.56919917e-07
Iter: 2590 loss: 7.56889563e-07
Iter: 2591 loss: 7.57399732e-07
Iter: 2592 loss: 7.56911163e-07
Iter: 2593 loss: 7.56890586e-07
Iter: 2594 loss: 7.56974089e-07
Iter: 2595 loss: 7.56865802e-07
Iter: 2596 loss: 7.56848863e-07
Iter: 2597 loss: 7.56804184e-07
Iter: 2598 loss: 7.57792634e-07
Iter: 2599 loss: 7.56805093e-07
Iter: 2600 loss: 7.56741542e-07
Iter: 2601 loss: 7.57079533e-07
Iter: 2602 loss: 7.56752456e-07
Iter: 2603 loss: 7.56691e-07
Iter: 2604 loss: 7.56805775e-07
Iter: 2605 loss: 7.56689e-07
Iter: 2606 loss: 7.5662831e-07
Iter: 2607 loss: 7.56661564e-07
Iter: 2608 loss: 7.56629902e-07
Iter: 2609 loss: 7.56571865e-07
Iter: 2610 loss: 7.56567033e-07
Iter: 2611 loss: 7.56549525e-07
Iter: 2612 loss: 7.56472048e-07
Iter: 2613 loss: 7.57198279e-07
Iter: 2614 loss: 7.56449708e-07
Iter: 2615 loss: 7.56440159e-07
Iter: 2616 loss: 7.56428506e-07
Iter: 2617 loss: 7.56399e-07
Iter: 2618 loss: 7.56354211e-07
Iter: 2619 loss: 7.57351813e-07
Iter: 2620 loss: 7.56328745e-07
Iter: 2621 loss: 7.562885e-07
Iter: 2622 loss: 7.56390932e-07
Iter: 2623 loss: 7.56288387e-07
Iter: 2624 loss: 7.56242287e-07
Iter: 2625 loss: 7.56192e-07
Iter: 2626 loss: 7.56195902e-07
Iter: 2627 loss: 7.56156453e-07
Iter: 2628 loss: 7.56138036e-07
Iter: 2629 loss: 7.56112172e-07
Iter: 2630 loss: 7.56071358e-07
Iter: 2631 loss: 7.56080226e-07
Iter: 2632 loss: 7.56033614e-07
Iter: 2633 loss: 7.56092845e-07
Iter: 2634 loss: 7.56007864e-07
Iter: 2635 loss: 7.55956648e-07
Iter: 2636 loss: 7.56232225e-07
Iter: 2637 loss: 7.55932774e-07
Iter: 2638 loss: 7.55912424e-07
Iter: 2639 loss: 7.56024519e-07
Iter: 2640 loss: 7.55903557e-07
Iter: 2641 loss: 7.55852852e-07
Iter: 2642 loss: 7.55980182e-07
Iter: 2643 loss: 7.55830513e-07
Iter: 2644 loss: 7.55827728e-07
Iter: 2645 loss: 7.55764859e-07
Iter: 2646 loss: 7.55738427e-07
Iter: 2647 loss: 7.55718474e-07
Iter: 2648 loss: 7.55992517e-07
Iter: 2649 loss: 7.5571586e-07
Iter: 2650 loss: 7.5565913e-07
Iter: 2651 loss: 7.55660551e-07
Iter: 2652 loss: 7.55605697e-07
Iter: 2653 loss: 7.55563633e-07
Iter: 2654 loss: 7.55574547e-07
Iter: 2655 loss: 7.55524866e-07
Iter: 2656 loss: 7.55550388e-07
Iter: 2657 loss: 7.55523729e-07
Iter: 2658 loss: 7.55427038e-07
Iter: 2659 loss: 7.55536348e-07
Iter: 2660 loss: 7.55386395e-07
Iter: 2661 loss: 7.55356382e-07
Iter: 2662 loss: 7.55438577e-07
Iter: 2663 loss: 7.55346207e-07
Iter: 2664 loss: 7.55308e-07
Iter: 2665 loss: 7.55330802e-07
Iter: 2666 loss: 7.55288e-07
Iter: 2667 loss: 7.55267195e-07
Iter: 2668 loss: 7.55234282e-07
Iter: 2669 loss: 7.55203416e-07
Iter: 2670 loss: 7.55208475e-07
Iter: 2671 loss: 7.55162091e-07
Iter: 2672 loss: 7.55112865e-07
Iter: 2673 loss: 7.55555561e-07
Iter: 2674 loss: 7.55064e-07
Iter: 2675 loss: 7.5503624e-07
Iter: 2676 loss: 7.55207054e-07
Iter: 2677 loss: 7.55002475e-07
Iter: 2678 loss: 7.54943756e-07
Iter: 2679 loss: 7.55512133e-07
Iter: 2680 loss: 7.54951259e-07
Iter: 2681 loss: 7.54909365e-07
Iter: 2682 loss: 7.55159647e-07
Iter: 2683 loss: 7.5493233e-07
Iter: 2684 loss: 7.54902146e-07
Iter: 2685 loss: 7.54886116e-07
Iter: 2686 loss: 7.5486065e-07
Iter: 2687 loss: 7.54854568e-07
Iter: 2688 loss: 7.5485e-07
Iter: 2689 loss: 7.54827568e-07
Iter: 2690 loss: 7.54778853e-07
Iter: 2691 loss: 7.54774533e-07
Iter: 2692 loss: 7.54725534e-07
Iter: 2693 loss: 7.54656071e-07
Iter: 2694 loss: 7.54776352e-07
Iter: 2695 loss: 7.54652888e-07
Iter: 2696 loss: 7.54547841e-07
Iter: 2697 loss: 7.55141116e-07
Iter: 2698 loss: 7.5455614e-07
Iter: 2699 loss: 7.54512257e-07
Iter: 2700 loss: 7.54811765e-07
Iter: 2701 loss: 7.54477e-07
Iter: 2702 loss: 7.5443495e-07
Iter: 2703 loss: 7.54322627e-07
Iter: 2704 loss: 7.5584876e-07
Iter: 2705 loss: 7.5428261e-07
Iter: 2706 loss: 7.54182224e-07
Iter: 2707 loss: 7.55720635e-07
Iter: 2708 loss: 7.54189841e-07
Iter: 2709 loss: 7.54123107e-07
Iter: 2710 loss: 7.54148232e-07
Iter: 2711 loss: 7.54046141e-07
Iter: 2712 loss: 7.54034033e-07
Iter: 2713 loss: 7.54017663e-07
Iter: 2714 loss: 7.53958204e-07
Iter: 2715 loss: 7.54179325e-07
Iter: 2716 loss: 7.53958e-07
Iter: 2717 loss: 7.53920858e-07
Iter: 2718 loss: 7.53998165e-07
Iter: 2719 loss: 7.53895392e-07
Iter: 2720 loss: 7.53875838e-07
Iter: 2721 loss: 7.53880613e-07
Iter: 2722 loss: 7.53856625e-07
Iter: 2723 loss: 7.53779091e-07
Iter: 2724 loss: 7.53801885e-07
Iter: 2725 loss: 7.53766699e-07
Iter: 2726 loss: 7.53741e-07
Iter: 2727 loss: 7.54206496e-07
Iter: 2728 loss: 7.53674271e-07
Iter: 2729 loss: 7.5367268e-07
Iter: 2730 loss: 7.536e-07
Iter: 2731 loss: 7.53620611e-07
Iter: 2732 loss: 7.53584175e-07
Iter: 2733 loss: 7.54225198e-07
Iter: 2734 loss: 7.53584345e-07
Iter: 2735 loss: 7.53516929e-07
Iter: 2736 loss: 7.53637778e-07
Iter: 2737 loss: 7.53488848e-07
Iter: 2738 loss: 7.53440474e-07
Iter: 2739 loss: 7.53479e-07
Iter: 2740 loss: 7.53381073e-07
Iter: 2741 loss: 7.53321842e-07
Iter: 2742 loss: 7.53285065e-07
Iter: 2743 loss: 7.53292511e-07
Iter: 2744 loss: 7.53192751e-07
Iter: 2745 loss: 7.53206109e-07
Iter: 2746 loss: 7.53105951e-07
Iter: 2747 loss: 7.53245843e-07
Iter: 2748 loss: 7.53125619e-07
Iter: 2749 loss: 7.5300585e-07
Iter: 2750 loss: 7.53839515e-07
Iter: 2751 loss: 7.53030804e-07
Iter: 2752 loss: 7.52976462e-07
Iter: 2753 loss: 7.52907226e-07
Iter: 2754 loss: 7.5292e-07
Iter: 2755 loss: 7.5284396e-07
Iter: 2756 loss: 7.52909102e-07
Iter: 2757 loss: 7.5285368e-07
Iter: 2758 loss: 7.52759206e-07
Iter: 2759 loss: 7.52851122e-07
Iter: 2760 loss: 7.52722144e-07
Iter: 2761 loss: 7.52620963e-07
Iter: 2762 loss: 7.53000108e-07
Iter: 2763 loss: 7.52612777e-07
Iter: 2764 loss: 7.52541212e-07
Iter: 2765 loss: 7.52592655e-07
Iter: 2766 loss: 7.52482777e-07
Iter: 2767 loss: 7.52387507e-07
Iter: 2768 loss: 7.5305627e-07
Iter: 2769 loss: 7.52425933e-07
Iter: 2770 loss: 7.5233379e-07
Iter: 2771 loss: 7.52327765e-07
Iter: 2772 loss: 7.5231651e-07
Iter: 2773 loss: 7.52202197e-07
Iter: 2774 loss: 7.52440883e-07
Iter: 2775 loss: 7.52209303e-07
Iter: 2776 loss: 7.52137282e-07
Iter: 2777 loss: 7.52038488e-07
Iter: 2778 loss: 7.52021151e-07
Iter: 2779 loss: 7.51943332e-07
Iter: 2780 loss: 7.52982e-07
Iter: 2781 loss: 7.51908203e-07
Iter: 2782 loss: 7.51884613e-07
Iter: 2783 loss: 7.51887342e-07
Iter: 2784 loss: 7.5181481e-07
Iter: 2785 loss: 7.51795483e-07
Iter: 2786 loss: 7.5177536e-07
Iter: 2787 loss: 7.51764e-07
Iter: 2788 loss: 7.51874268e-07
Iter: 2789 loss: 7.51715447e-07
Iter: 2790 loss: 7.51683672e-07
Iter: 2791 loss: 7.51610344e-07
Iter: 2792 loss: 7.52963501e-07
Iter: 2793 loss: 7.51585787e-07
Iter: 2794 loss: 7.51502512e-07
Iter: 2795 loss: 7.5148796e-07
Iter: 2796 loss: 7.51415826e-07
Iter: 2797 loss: 7.51436801e-07
Iter: 2798 loss: 7.51405423e-07
Iter: 2799 loss: 7.51349035e-07
Iter: 2800 loss: 7.51350171e-07
Iter: 2801 loss: 7.51343464e-07
Iter: 2802 loss: 7.51328116e-07
Iter: 2803 loss: 7.51293612e-07
Iter: 2804 loss: 7.51206471e-07
Iter: 2805 loss: 7.51208859e-07
Iter: 2806 loss: 7.5114383e-07
Iter: 2807 loss: 7.51123764e-07
Iter: 2808 loss: 7.5121261e-07
Iter: 2809 loss: 7.51092841e-07
Iter: 2810 loss: 7.50998765e-07
Iter: 2811 loss: 7.51462721e-07
Iter: 2812 loss: 7.50996492e-07
Iter: 2813 loss: 7.51005871e-07
Iter: 2814 loss: 7.50994275e-07
Iter: 2815 loss: 7.51001153e-07
Iter: 2816 loss: 7.51010191e-07
Iter: 2817 loss: 7.50995355e-07
Iter: 2818 loss: 7.51011271e-07
Iter: 2819 loss: 7.50999334e-07
Iter: 2820 loss: 7.50991831e-07
Iter: 2821 loss: 7.50992513e-07
Iter: 2822 loss: 7.50992967e-07
Iter: 2823 loss: 7.5101309e-07
Iter: 2824 loss: 7.50983872e-07
Iter: 2825 loss: 7.50994388e-07
Iter: 2826 loss: 7.51002631e-07
Iter: 2827 loss: 7.50993649e-07
Iter: 2828 loss: 7.50995355e-07
Iter: 2829 loss: 7.51003e-07
Iter: 2830 loss: 7.50996833e-07
Iter: 2831 loss: 7.50998822e-07
Iter: 2832 loss: 7.50997572e-07
Iter: 2833 loss: 7.50997742e-07
Iter: 2834 loss: 7.50996378e-07
Iter: 2835 loss: 7.50997e-07
Iter: 2836 loss: 7.50997e-07
Iter: 2837 loss: 7.5099706e-07
Iter: 2838 loss: 7.50997742e-07
Iter: 2839 loss: 7.50937772e-07
Iter: 2840 loss: 7.51580103e-07
Iter: 2841 loss: 7.50920094e-07
Iter: 2842 loss: 7.50853815e-07
Iter: 2843 loss: 7.51692e-07
Iter: 2844 loss: 7.50854497e-07
Iter: 2845 loss: 7.50824029e-07
Iter: 2846 loss: 7.50833692e-07
Iter: 2847 loss: 7.50782078e-07
Iter: 2848 loss: 7.50763e-07
Iter: 2849 loss: 7.50699883e-07
Iter: 2850 loss: 7.5201865e-07
Iter: 2851 loss: 7.50693744e-07
Iter: 2852 loss: 7.50644062e-07
Iter: 2853 loss: 7.50803224e-07
Iter: 2854 loss: 7.50643721e-07
Iter: 2855 loss: 7.50560332e-07
Iter: 2856 loss: 7.50491722e-07
Iter: 2857 loss: 7.51368532e-07
Iter: 2858 loss: 7.5048797e-07
Iter: 2859 loss: 7.50446134e-07
Iter: 2860 loss: 7.50429422e-07
Iter: 2861 loss: 7.5039668e-07
Iter: 2862 loss: 7.50396055e-07
Iter: 2863 loss: 7.50361778e-07
Iter: 2864 loss: 7.50262927e-07
Iter: 2865 loss: 7.50899062e-07
Iter: 2866 loss: 7.50267873e-07
Iter: 2867 loss: 7.50226718e-07
Iter: 2868 loss: 7.50254571e-07
Iter: 2869 loss: 7.50186359e-07
Iter: 2870 loss: 7.50088475e-07
Iter: 2871 loss: 7.50036349e-07
Iter: 2872 loss: 7.50011e-07
Iter: 2873 loss: 7.49963704e-07
Iter: 2874 loss: 7.50743709e-07
Iter: 2875 loss: 7.49959838e-07
Iter: 2876 loss: 7.4990794e-07
Iter: 2877 loss: 7.49977062e-07
Iter: 2878 loss: 7.49893047e-07
Iter: 2879 loss: 7.49875767e-07
Iter: 2880 loss: 7.49860078e-07
Iter: 2881 loss: 7.49822107e-07
Iter: 2882 loss: 7.49800734e-07
Iter: 2883 loss: 7.49793344e-07
Iter: 2884 loss: 7.49747187e-07
Iter: 2885 loss: 7.49815513e-07
Iter: 2886 loss: 7.49730702e-07
Iter: 2887 loss: 7.49703418e-07
Iter: 2888 loss: 7.49711432e-07
Iter: 2889 loss: 7.49657431e-07
Iter: 2890 loss: 7.49637593e-07
Iter: 2891 loss: 7.49550964e-07
Iter: 2892 loss: 7.49540163e-07
Iter: 2893 loss: 7.49466039e-07
Iter: 2894 loss: 7.49929427e-07
Iter: 2895 loss: 7.4948025e-07
Iter: 2896 loss: 7.49356e-07
Iter: 2897 loss: 7.49704952e-07
Iter: 2898 loss: 7.49315291e-07
Iter: 2899 loss: 7.49245885e-07
Iter: 2900 loss: 7.50070399e-07
Iter: 2901 loss: 7.49231049e-07
Iter: 2902 loss: 7.4918762e-07
Iter: 2903 loss: 7.49104458e-07
Iter: 2904 loss: 7.49101559e-07
Iter: 2905 loss: 7.49040282e-07
Iter: 2906 loss: 7.49638616e-07
Iter: 2907 loss: 7.49022206e-07
Iter: 2908 loss: 7.48996854e-07
Iter: 2909 loss: 7.48981165e-07
Iter: 2910 loss: 7.48933871e-07
Iter: 2911 loss: 7.48900334e-07
Iter: 2912 loss: 7.4891534e-07
Iter: 2913 loss: 7.48863954e-07
Iter: 2914 loss: 7.49113781e-07
Iter: 2915 loss: 7.48833031e-07
Iter: 2916 loss: 7.48801767e-07
Iter: 2917 loss: 7.48786817e-07
Iter: 2918 loss: 7.4972354e-07
Iter: 2919 loss: 7.48800062e-07
Iter: 2920 loss: 7.48746402e-07
Iter: 2921 loss: 7.48917728e-07
Iter: 2922 loss: 7.48714172e-07
Iter: 2923 loss: 7.48697744e-07
Iter: 2924 loss: 7.48641639e-07
Iter: 2925 loss: 7.48580703e-07
Iter: 2926 loss: 7.48499e-07
Iter: 2927 loss: 7.48795173e-07
Iter: 2928 loss: 7.4845542e-07
Iter: 2929 loss: 7.48378852e-07
Iter: 2930 loss: 7.48448883e-07
Iter: 2931 loss: 7.48366119e-07
Iter: 2932 loss: 7.48252887e-07
Iter: 2933 loss: 7.48252e-07
Iter: 2934 loss: 7.48210198e-07
Iter: 2935 loss: 7.48203774e-07
Iter: 2936 loss: 7.48173875e-07
Iter: 2937 loss: 7.48118055e-07
Iter: 2938 loss: 7.48032107e-07
Iter: 2939 loss: 7.48021421e-07
Iter: 2940 loss: 7.47919444e-07
Iter: 2941 loss: 7.47917113e-07
Iter: 2942 loss: 7.47893409e-07
Iter: 2943 loss: 7.47837362e-07
Iter: 2944 loss: 7.47819058e-07
Iter: 2945 loss: 7.47723789e-07
Iter: 2946 loss: 7.48771527e-07
Iter: 2947 loss: 7.477704e-07
Iter: 2948 loss: 7.47721344e-07
Iter: 2949 loss: 7.47702757e-07
Iter: 2950 loss: 7.47678769e-07
Iter: 2951 loss: 7.4760527e-07
Iter: 2952 loss: 7.47639717e-07
Iter: 2953 loss: 7.47609249e-07
Iter: 2954 loss: 7.47515514e-07
Iter: 2955 loss: 7.47766194e-07
Iter: 2956 loss: 7.47521767e-07
Iter: 2957 loss: 7.47454692e-07
Iter: 2958 loss: 7.47353852e-07
Iter: 2959 loss: 7.4736738e-07
Iter: 2960 loss: 7.47200716e-07
Iter: 2961 loss: 7.47654894e-07
Iter: 2962 loss: 7.4719253e-07
Iter: 2963 loss: 7.47122328e-07
Iter: 2964 loss: 7.47968784e-07
Iter: 2965 loss: 7.47145407e-07
Iter: 2966 loss: 7.47040076e-07
Iter: 2967 loss: 7.47029731e-07
Iter: 2968 loss: 7.46945489e-07
Iter: 2969 loss: 7.46895125e-07
Iter: 2970 loss: 7.47105901e-07
Iter: 2971 loss: 7.46884893e-07
Iter: 2972 loss: 7.46798491e-07
Iter: 2973 loss: 7.4684408e-07
Iter: 2974 loss: 7.46720161e-07
Iter: 2975 loss: 7.46652631e-07
Iter: 2976 loss: 7.47299168e-07
Iter: 2977 loss: 7.46637681e-07
Iter: 2978 loss: 7.46628643e-07
Iter: 2979 loss: 7.46629382e-07
Iter: 2980 loss: 7.46572141e-07
Iter: 2981 loss: 7.4654281e-07
Iter: 2982 loss: 7.47665354e-07
Iter: 2983 loss: 7.46485739e-07
Iter: 2984 loss: 7.46439582e-07
Iter: 2985 loss: 7.46782689e-07
Iter: 2986 loss: 7.4646033e-07
Iter: 2987 loss: 7.46379499e-07
Iter: 2988 loss: 7.46307933e-07
Iter: 2989 loss: 7.46317255e-07
Iter: 2990 loss: 7.46181968e-07
Iter: 2991 loss: 7.46722208e-07
Iter: 2992 loss: 7.46130695e-07
Iter: 2993 loss: 7.46081128e-07
Iter: 2994 loss: 7.45948398e-07
Iter: 2995 loss: 7.45951752e-07
Iter: 2996 loss: 7.45840794e-07
Iter: 2997 loss: 7.45827265e-07
Iter: 2998 loss: 7.45758257e-07
Iter: 2999 loss: 7.45880868e-07
Iter: 3000 loss: 7.45716363e-07
Iter: 3001 loss: 7.45612567e-07
Iter: 3002 loss: 7.45865691e-07
Iter: 3003 loss: 7.45567945e-07
Iter: 3004 loss: 7.45476086e-07
Iter: 3005 loss: 7.45409125e-07
Iter: 3006 loss: 7.45433624e-07
Iter: 3007 loss: 7.45301065e-07
Iter: 3008 loss: 7.46450155e-07
Iter: 3009 loss: 7.45305897e-07
Iter: 3010 loss: 7.45236889e-07
Iter: 3011 loss: 7.45632235e-07
Iter: 3012 loss: 7.45221314e-07
Iter: 3013 loss: 7.45182319e-07
Iter: 3014 loss: 7.45208752e-07
Iter: 3015 loss: 7.45108593e-07
Iter: 3016 loss: 7.45040097e-07
Iter: 3017 loss: 7.45027307e-07
Iter: 3018 loss: 7.4498314e-07
Iter: 3019 loss: 7.4490265e-07
Iter: 3020 loss: 7.4495216e-07
Iter: 3021 loss: 7.44849e-07
Iter: 3022 loss: 7.44767647e-07
Iter: 3023 loss: 7.46300884e-07
Iter: 3024 loss: 7.44738259e-07
Iter: 3025 loss: 7.44717568e-07
Iter: 3026 loss: 7.44716885e-07
Iter: 3027 loss: 7.44652425e-07
Iter: 3028 loss: 7.44548856e-07
Iter: 3029 loss: 7.44790952e-07
Iter: 3030 loss: 7.44503723e-07
Iter: 3031 loss: 7.44454155e-07
Iter: 3032 loss: 7.44493718e-07
Iter: 3033 loss: 7.44400495e-07
Iter: 3034 loss: 7.44297779e-07
Iter: 3035 loss: 7.45030945e-07
Iter: 3036 loss: 7.44286126e-07
Iter: 3037 loss: 7.44196541e-07
Iter: 3038 loss: 7.44323756e-07
Iter: 3039 loss: 7.44127874e-07
Iter: 3040 loss: 7.4404204e-07
Iter: 3041 loss: 7.43915678e-07
Iter: 3042 loss: 7.43917099e-07
Iter: 3043 loss: 7.43797e-07
Iter: 3044 loss: 7.45144348e-07
Iter: 3045 loss: 7.4379733e-07
Iter: 3046 loss: 7.4369342e-07
Iter: 3047 loss: 7.43695409e-07
Iter: 3048 loss: 7.43660621e-07
Iter: 3049 loss: 7.43565579e-07
Iter: 3050 loss: 7.43569956e-07
Iter: 3051 loss: 7.4351459e-07
Iter: 3052 loss: 7.4343734e-07
Iter: 3053 loss: 7.46080502e-07
Iter: 3054 loss: 7.43428245e-07
Iter: 3055 loss: 7.4326897e-07
Iter: 3056 loss: 7.44928116e-07
Iter: 3057 loss: 7.43274484e-07
Iter: 3058 loss: 7.43198711e-07
Iter: 3059 loss: 7.43303758e-07
Iter: 3060 loss: 7.43179044e-07
Iter: 3061 loss: 7.43035457e-07
Iter: 3062 loss: 7.43122428e-07
Iter: 3063 loss: 7.42972361e-07
Iter: 3064 loss: 7.42839859e-07
Iter: 3065 loss: 7.4389294e-07
Iter: 3066 loss: 7.42908128e-07
Iter: 3067 loss: 7.42800125e-07
Iter: 3068 loss: 7.42730094e-07
Iter: 3069 loss: 7.42673706e-07
Iter: 3070 loss: 7.42612201e-07
Iter: 3071 loss: 7.42600548e-07
Iter: 3072 loss: 7.42550469e-07
Iter: 3073 loss: 7.42454176e-07
Iter: 3074 loss: 7.43666419e-07
Iter: 3075 loss: 7.42397901e-07
Iter: 3076 loss: 7.42348732e-07
Iter: 3077 loss: 7.43341559e-07
Iter: 3078 loss: 7.42315137e-07
Iter: 3079 loss: 7.4232662e-07
Iter: 3080 loss: 7.42309e-07
Iter: 3081 loss: 7.42240957e-07
Iter: 3082 loss: 7.42235784e-07
Iter: 3083 loss: 7.42716281e-07
Iter: 3084 loss: 7.42213331e-07
Iter: 3085 loss: 7.42128179e-07
Iter: 3086 loss: 7.42134887e-07
Iter: 3087 loss: 7.42074235e-07
Iter: 3088 loss: 7.42003749e-07
Iter: 3089 loss: 7.41845327e-07
Iter: 3090 loss: 7.4558136e-07
Iter: 3091 loss: 7.41832537e-07
Iter: 3092 loss: 7.41782742e-07
Iter: 3093 loss: 7.41758299e-07
Iter: 3094 loss: 7.41661665e-07
Iter: 3095 loss: 7.41542635e-07
Iter: 3096 loss: 7.4152058e-07
Iter: 3097 loss: 7.414028e-07
Iter: 3098 loss: 7.41415647e-07
Iter: 3099 loss: 7.41350618e-07
Iter: 3100 loss: 7.41340159e-07
Iter: 3101 loss: 7.41265353e-07
Iter: 3102 loss: 7.41181623e-07
Iter: 3103 loss: 7.41726524e-07
Iter: 3104 loss: 7.41181168e-07
Iter: 3105 loss: 7.41110512e-07
Iter: 3106 loss: 7.41522399e-07
Iter: 3107 loss: 7.41089821e-07
Iter: 3108 loss: 7.41015754e-07
Iter: 3109 loss: 7.40917926e-07
Iter: 3110 loss: 7.40920143e-07
Iter: 3111 loss: 7.40812709e-07
Iter: 3112 loss: 7.41392228e-07
Iter: 3113 loss: 7.40790938e-07
Iter: 3114 loss: 7.40772805e-07
Iter: 3115 loss: 7.40754274e-07
Iter: 3116 loss: 7.40710732e-07
Iter: 3117 loss: 7.40518374e-07
Iter: 3118 loss: 7.41844474e-07
Iter: 3119 loss: 7.40522523e-07
Iter: 3120 loss: 7.40425492e-07
Iter: 3121 loss: 7.40445898e-07
Iter: 3122 loss: 7.40359212e-07
Iter: 3123 loss: 7.40227279e-07
Iter: 3124 loss: 7.40922701e-07
Iter: 3125 loss: 7.40207724e-07
Iter: 3126 loss: 7.40083863e-07
Iter: 3127 loss: 7.40621147e-07
Iter: 3128 loss: 7.40053906e-07
Iter: 3129 loss: 7.39924076e-07
Iter: 3130 loss: 7.40055611e-07
Iter: 3131 loss: 7.39867573e-07
Iter: 3132 loss: 7.39767188e-07
Iter: 3133 loss: 7.4041435e-07
Iter: 3134 loss: 7.39793734e-07
Iter: 3135 loss: 7.39657139e-07
Iter: 3136 loss: 7.39639859e-07
Iter: 3137 loss: 7.39622351e-07
Iter: 3138 loss: 7.39489053e-07
Iter: 3139 loss: 7.39528559e-07
Iter: 3140 loss: 7.39463871e-07
Iter: 3141 loss: 7.39479e-07
Iter: 3142 loss: 7.39443863e-07
Iter: 3143 loss: 7.39322388e-07
Iter: 3144 loss: 7.39340408e-07
Iter: 3145 loss: 7.3924457e-07
Iter: 3146 loss: 7.39212737e-07
Iter: 3147 loss: 7.40022756e-07
Iter: 3148 loss: 7.39192615e-07
Iter: 3149 loss: 7.39118377e-07
Iter: 3150 loss: 7.39342909e-07
Iter: 3151 loss: 7.39103371e-07
Iter: 3152 loss: 7.39079837e-07
Iter: 3153 loss: 7.39014e-07
Iter: 3154 loss: 7.40162648e-07
Iter: 3155 loss: 7.39000768e-07
Iter: 3156 loss: 7.38938e-07
Iter: 3157 loss: 7.38931249e-07
Iter: 3158 loss: 7.38883728e-07
Iter: 3159 loss: 7.38751169e-07
Iter: 3160 loss: 7.39757468e-07
Iter: 3161 loss: 7.38778454e-07
Iter: 3162 loss: 7.38689948e-07
Iter: 3163 loss: 7.3875708e-07
Iter: 3164 loss: 7.3863248e-07
Iter: 3165 loss: 7.38547214e-07
Iter: 3166 loss: 7.39665211e-07
Iter: 3167 loss: 7.38573704e-07
Iter: 3168 loss: 7.38472124e-07
Iter: 3169 loss: 7.38399649e-07
Iter: 3170 loss: 7.38416702e-07
Iter: 3171 loss: 7.38320864e-07
Iter: 3172 loss: 7.3908916e-07
Iter: 3173 loss: 7.38282097e-07
Iter: 3174 loss: 7.38268341e-07
Iter: 3175 loss: 7.38309e-07
Iter: 3176 loss: 7.38220422e-07
Iter: 3177 loss: 7.38148913e-07
Iter: 3178 loss: 7.38632366e-07
Iter: 3179 loss: 7.38148913e-07
Iter: 3180 loss: 7.38107133e-07
Iter: 3181 loss: 7.38074732e-07
Iter: 3182 loss: 7.38073652e-07
Iter: 3183 loss: 7.38114e-07
Iter: 3184 loss: 7.38072e-07
Iter: 3185 loss: 7.38052847e-07
Iter: 3186 loss: 7.37964911e-07
Iter: 3187 loss: 7.38169433e-07
Iter: 3188 loss: 7.37881578e-07
Iter: 3189 loss: 7.37773917e-07
Iter: 3190 loss: 7.3894e-07
Iter: 3191 loss: 7.37766413e-07
Iter: 3192 loss: 7.37679329e-07
Iter: 3193 loss: 7.37664379e-07
Iter: 3194 loss: 7.37586788e-07
Iter: 3195 loss: 7.37493679e-07
Iter: 3196 loss: 7.38347126e-07
Iter: 3197 loss: 7.37466507e-07
Iter: 3198 loss: 7.37365212e-07
Iter: 3199 loss: 7.37592131e-07
Iter: 3200 loss: 7.37365951e-07
Iter: 3201 loss: 7.37243e-07
Iter: 3202 loss: 7.37572861e-07
Iter: 3203 loss: 7.37217931e-07
Iter: 3204 loss: 7.37128971e-07
Iter: 3205 loss: 7.37210769e-07
Iter: 3206 loss: 7.37077585e-07
Iter: 3207 loss: 7.36956849e-07
Iter: 3208 loss: 7.36932861e-07
Iter: 3209 loss: 7.36841798e-07
Iter: 3210 loss: 7.36760285e-07
Iter: 3211 loss: 7.37745609e-07
Iter: 3212 loss: 7.36712536e-07
Iter: 3213 loss: 7.36617039e-07
Iter: 3214 loss: 7.36863456e-07
Iter: 3215 loss: 7.3659055e-07
Iter: 3216 loss: 7.36530865e-07
Iter: 3217 loss: 7.36511538e-07
Iter: 3218 loss: 7.36455036e-07
Iter: 3219 loss: 7.36468394e-07
Iter: 3220 loss: 7.36466177e-07
Iter: 3221 loss: 7.36356128e-07
Iter: 3222 loss: 7.36225275e-07
Iter: 3223 loss: 7.38126062e-07
Iter: 3224 loss: 7.36264042e-07
Iter: 3225 loss: 7.36133e-07
Iter: 3226 loss: 7.37613618e-07
Iter: 3227 loss: 7.36117101e-07
Iter: 3228 loss: 7.35998242e-07
Iter: 3229 loss: 7.35859658e-07
Iter: 3230 loss: 7.35850392e-07
Iter: 3231 loss: 7.3575643e-07
Iter: 3232 loss: 7.35740571e-07
Iter: 3233 loss: 7.35648882e-07
Iter: 3234 loss: 7.35727326e-07
Iter: 3235 loss: 7.35602953e-07
Iter: 3236 loss: 7.35468632e-07
Iter: 3237 loss: 7.36282232e-07
Iter: 3238 loss: 7.35462379e-07
Iter: 3239 loss: 7.3535557e-07
Iter: 3240 loss: 7.35368815e-07
Iter: 3241 loss: 7.35300773e-07
Iter: 3242 loss: 7.35108415e-07
Iter: 3243 loss: 7.35522292e-07
Iter: 3244 loss: 7.35077833e-07
Iter: 3245 loss: 7.34989953e-07
Iter: 3246 loss: 7.35021899e-07
Iter: 3247 loss: 7.34927085e-07
Iter: 3248 loss: 7.34824539e-07
Iter: 3249 loss: 7.35010644e-07
Iter: 3250 loss: 7.34774403e-07
Iter: 3251 loss: 7.3470153e-07
Iter: 3252 loss: 7.34698119e-07
Iter: 3253 loss: 7.34647529e-07
Iter: 3254 loss: 7.34500873e-07
Iter: 3255 loss: 7.3502008e-07
Iter: 3256 loss: 7.3451622e-07
Iter: 3257 loss: 7.34346884e-07
Iter: 3258 loss: 7.34677428e-07
Iter: 3259 loss: 7.34266393e-07
Iter: 3260 loss: 7.34128776e-07
Iter: 3261 loss: 7.35067033e-07
Iter: 3262 loss: 7.34148898e-07
Iter: 3263 loss: 7.34085e-07
Iter: 3264 loss: 7.33891e-07
Iter: 3265 loss: 7.36863399e-07
Iter: 3266 loss: 7.33917432e-07
Iter: 3267 loss: 7.33792092e-07
Iter: 3268 loss: 7.33779871e-07
Iter: 3269 loss: 7.33694492e-07
Iter: 3270 loss: 7.33671413e-07
Iter: 3271 loss: 7.3361872e-07
Iter: 3272 loss: 7.33477e-07
Iter: 3273 loss: 7.34557773e-07
Iter: 3274 loss: 7.33506965e-07
Iter: 3275 loss: 7.33473371e-07
Iter: 3276 loss: 7.33848708e-07
Iter: 3277 loss: 7.33442107e-07
Iter: 3278 loss: 7.33377135e-07
Iter: 3279 loss: 7.33307445e-07
Iter: 3280 loss: 7.33292495e-07
Iter: 3281 loss: 7.33189609e-07
Iter: 3282 loss: 7.33609852e-07
Iter: 3283 loss: 7.33196089e-07
Iter: 3284 loss: 7.3314618e-07
Iter: 3285 loss: 7.33042839e-07
Iter: 3286 loss: 7.33048751e-07
Iter: 3287 loss: 7.32909314e-07
Iter: 3288 loss: 7.32912213e-07
Iter: 3289 loss: 7.32892318e-07
Iter: 3290 loss: 7.32827402e-07
Iter: 3291 loss: 7.33111051e-07
Iter: 3292 loss: 7.32770445e-07
Iter: 3293 loss: 7.32635726e-07
Iter: 3294 loss: 7.33021466e-07
Iter: 3295 loss: 7.32588035e-07
Iter: 3296 loss: 7.32484637e-07
Iter: 3297 loss: 7.33552213e-07
Iter: 3298 loss: 7.3244189e-07
Iter: 3299 loss: 7.32397325e-07
Iter: 3300 loss: 7.32297622e-07
Iter: 3301 loss: 7.3482164e-07
Iter: 3302 loss: 7.32290232e-07
Iter: 3303 loss: 7.32188596e-07
Iter: 3304 loss: 7.3397274e-07
Iter: 3305 loss: 7.32179615e-07
Iter: 3306 loss: 7.32088552e-07
Iter: 3307 loss: 7.32054446e-07
Iter: 3308 loss: 7.31985438e-07
Iter: 3309 loss: 7.31836963e-07
Iter: 3310 loss: 7.32844512e-07
Iter: 3311 loss: 7.31830255e-07
Iter: 3312 loss: 7.31739533e-07
Iter: 3313 loss: 7.32035517e-07
Iter: 3314 loss: 7.31708894e-07
Iter: 3315 loss: 7.31628575e-07
Iter: 3316 loss: 7.31629086e-07
Iter: 3317 loss: 7.3154763e-07
Iter: 3318 loss: 7.31493969e-07
Iter: 3319 loss: 7.32551712e-07
Iter: 3320 loss: 7.31444288e-07
Iter: 3321 loss: 7.31421153e-07
Iter: 3322 loss: 7.31397677e-07
Iter: 3323 loss: 7.3137295e-07
Iter: 3324 loss: 7.31278703e-07
Iter: 3325 loss: 7.31896591e-07
Iter: 3326 loss: 7.31262048e-07
Iter: 3327 loss: 7.31199918e-07
Iter: 3328 loss: 7.31654836e-07
Iter: 3329 loss: 7.31176272e-07
Iter: 3330 loss: 7.31075204e-07
Iter: 3331 loss: 7.31115392e-07
Iter: 3332 loss: 7.31027626e-07
Iter: 3333 loss: 7.30960721e-07
Iter: 3334 loss: 7.31900286e-07
Iter: 3335 loss: 7.30980332e-07
Iter: 3336 loss: 7.30926e-07
Iter: 3337 loss: 7.30849877e-07
Iter: 3338 loss: 7.308779e-07
Iter: 3339 loss: 7.30727209e-07
Iter: 3340 loss: 7.31452246e-07
Iter: 3341 loss: 7.3075887e-07
Iter: 3342 loss: 7.30674742e-07
Iter: 3343 loss: 7.30728459e-07
Iter: 3344 loss: 7.30650243e-07
Iter: 3345 loss: 7.3052837e-07
Iter: 3346 loss: 7.30733177e-07
Iter: 3347 loss: 7.30505292e-07
Iter: 3348 loss: 7.30448221e-07
Iter: 3349 loss: 7.3125392e-07
Iter: 3350 loss: 7.30463455e-07
Iter: 3351 loss: 7.30385e-07
Iter: 3352 loss: 7.30323279e-07
Iter: 3353 loss: 7.30348347e-07
Iter: 3354 loss: 7.30310205e-07
Iter: 3355 loss: 7.30303555e-07
Iter: 3356 loss: 7.30229658e-07
Iter: 3357 loss: 7.30342435e-07
Iter: 3358 loss: 7.30195609e-07
Iter: 3359 loss: 7.30146269e-07
Iter: 3360 loss: 7.30063846e-07
Iter: 3361 loss: 7.30461295e-07
Iter: 3362 loss: 7.30002284e-07
Iter: 3363 loss: 7.298936e-07
Iter: 3364 loss: 7.31681e-07
Iter: 3365 loss: 7.29901217e-07
Iter: 3366 loss: 7.29783949e-07
Iter: 3367 loss: 7.29758312e-07
Iter: 3368 loss: 7.2971477e-07
Iter: 3369 loss: 7.29541966e-07
Iter: 3370 loss: 7.30841805e-07
Iter: 3371 loss: 7.29539579e-07
Iter: 3372 loss: 7.29460737e-07
Iter: 3373 loss: 7.29623366e-07
Iter: 3374 loss: 7.2943925e-07
Iter: 3375 loss: 7.29366718e-07
Iter: 3376 loss: 7.29560156e-07
Iter: 3377 loss: 7.29316525e-07
Iter: 3378 loss: 7.29254793e-07
Iter: 3379 loss: 7.29946862e-07
Iter: 3380 loss: 7.29214e-07
Iter: 3381 loss: 7.29180215e-07
Iter: 3382 loss: 7.2905874e-07
Iter: 3383 loss: 7.29018893e-07
Iter: 3384 loss: 7.28963187e-07
Iter: 3385 loss: 7.28934765e-07
Iter: 3386 loss: 7.28900545e-07
Iter: 3387 loss: 7.29010139e-07
Iter: 3388 loss: 7.28897e-07
Iter: 3389 loss: 7.28829491e-07
Iter: 3390 loss: 7.29006842e-07
Iter: 3391 loss: 7.2878106e-07
Iter: 3392 loss: 7.28706823e-07
Iter: 3393 loss: 7.28677151e-07
Iter: 3394 loss: 7.28666407e-07
Iter: 3395 loss: 7.28608143e-07
Iter: 3396 loss: 7.28570683e-07
Iter: 3397 loss: 7.28535326e-07
Iter: 3398 loss: 7.28426244e-07
Iter: 3399 loss: 7.28643727e-07
Iter: 3400 loss: 7.28390148e-07
Iter: 3401 loss: 7.28310738e-07
Iter: 3402 loss: 7.29211e-07
Iter: 3403 loss: 7.28286693e-07
Iter: 3404 loss: 7.28231896e-07
Iter: 3405 loss: 7.28107352e-07
Iter: 3406 loss: 7.28105817e-07
Iter: 3407 loss: 7.27984059e-07
Iter: 3408 loss: 7.28983878e-07
Iter: 3409 loss: 7.2798565e-07
Iter: 3410 loss: 7.27862357e-07
Iter: 3411 loss: 7.27931933e-07
Iter: 3412 loss: 7.27824954e-07
Iter: 3413 loss: 7.27722067e-07
Iter: 3414 loss: 7.27744862e-07
Iter: 3415 loss: 7.2770797e-07
Iter: 3416 loss: 7.27708596e-07
Iter: 3417 loss: 7.27652036e-07
Iter: 3418 loss: 7.27580243e-07
Iter: 3419 loss: 7.27923521e-07
Iter: 3420 loss: 7.27598433e-07
Iter: 3421 loss: 7.27523684e-07
Iter: 3422 loss: 7.28206373e-07
Iter: 3423 loss: 7.27529596e-07
Iter: 3424 loss: 7.27482075e-07
Iter: 3425 loss: 7.27449731e-07
Iter: 3426 loss: 7.27454506e-07
Iter: 3427 loss: 7.27403631e-07
Iter: 3428 loss: 7.27330644e-07
Iter: 3429 loss: 7.27366455e-07
Iter: 3430 loss: 7.27293354e-07
Iter: 3431 loss: 7.27749e-07
Iter: 3432 loss: 7.27273971e-07
Iter: 3433 loss: 7.27225313e-07
Iter: 3434 loss: 7.27216445e-07
Iter: 3435 loss: 7.27182623e-07
Iter: 3436 loss: 7.27098154e-07
Iter: 3437 loss: 7.28126736e-07
Iter: 3438 loss: 7.27091788e-07
Iter: 3439 loss: 7.27029487e-07
Iter: 3440 loss: 7.26966277e-07
Iter: 3441 loss: 7.28281407e-07
Iter: 3442 loss: 7.26954966e-07
Iter: 3443 loss: 7.26851738e-07
Iter: 3444 loss: 7.27773966e-07
Iter: 3445 loss: 7.26857365e-07
Iter: 3446 loss: 7.26785117e-07
Iter: 3447 loss: 7.26869757e-07
Iter: 3448 loss: 7.26807855e-07
Iter: 3449 loss: 7.26749818e-07
Iter: 3450 loss: 7.26774829e-07
Iter: 3451 loss: 7.26713097e-07
Iter: 3452 loss: 7.2665091e-07
Iter: 3453 loss: 7.26651308e-07
Iter: 3454 loss: 7.26653184e-07
Iter: 3455 loss: 7.26662734e-07
Iter: 3456 loss: 7.26664439e-07
Iter: 3457 loss: 7.26668759e-07
Iter: 3458 loss: 7.26664553e-07
Iter: 3459 loss: 7.26633743e-07
Iter: 3460 loss: 7.26661881e-07
Iter: 3461 loss: 7.26647784e-07
Iter: 3462 loss: 7.266446e-07
Iter: 3463 loss: 7.26656367e-07
Iter: 3464 loss: 7.26650796e-07
Iter: 3465 loss: 7.26658755e-07
Iter: 3466 loss: 7.26652559e-07
Iter: 3467 loss: 7.26649716e-07
Iter: 3468 loss: 7.26650626e-07
Iter: 3469 loss: 7.26650342e-07
Iter: 3470 loss: 7.26653e-07
Iter: 3471 loss: 7.26653752e-07
Iter: 3472 loss: 7.26650796e-07
Iter: 3473 loss: 7.26650342e-07
Iter: 3474 loss: 7.26651194e-07
Iter: 3475 loss: 7.26651251e-07
Iter: 3476 loss: 7.26652161e-07
Iter: 3477 loss: 7.26651251e-07
Iter: 3478 loss: 7.26651251e-07
Iter: 3479 loss: 7.26651251e-07
Iter: 3480 loss: 7.26651308e-07
Iter: 3481 loss: 7.26651308e-07
Iter: 3482 loss: 7.26652161e-07
Iter: 3483 loss: 7.26651308e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/300_300_300_1
+ for layers in $LAYERS
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0
+ date
Mon Nov  9 02:37:12 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0/500_500_500_500_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_1000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 0 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_1000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2357510378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23575222f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23575bcd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23575f97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2357610268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f235752dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23574a6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23574cb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23574d8bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f235748c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f235742a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f235743cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23573f1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f235740c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2357420ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23573d6598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23573e3048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23573889d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f235733b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2357346e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f235735b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2357311378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f235731ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23572d4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f23572762f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2357288d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2302dba7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2302ddc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2302d70c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2302d8e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2302d441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2302d55bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2302d0e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2302ca7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2302cb9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22dc56a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.66810503e-06
Iter: 2 loss: 1.98151474e-06
Iter: 3 loss: 1.4876166e-06
Iter: 4 loss: 1.26905434e-06
Iter: 5 loss: 1.16093e-06
Iter: 6 loss: 1.0568416e-06
Iter: 7 loss: 9.42811198e-07
Iter: 8 loss: 1.55566204e-06
Iter: 9 loss: 9.25718041e-07
Iter: 10 loss: 8.15781448e-07
Iter: 11 loss: 1.43633315e-06
Iter: 12 loss: 8.00462317e-07
Iter: 13 loss: 7.692596e-07
Iter: 14 loss: 8.62381569e-07
Iter: 15 loss: 7.59857471e-07
Iter: 16 loss: 7.55425162e-07
Iter: 17 loss: 7.52021606e-07
Iter: 18 loss: 7.47299623e-07
Iter: 19 loss: 7.36071058e-07
Iter: 20 loss: 8.65674735e-07
Iter: 21 loss: 7.35090453e-07
Iter: 22 loss: 7.29328576e-07
Iter: 23 loss: 7.7009679e-07
Iter: 24 loss: 7.28799364e-07
Iter: 25 loss: 7.25170423e-07
Iter: 26 loss: 7.25173493e-07
Iter: 27 loss: 7.21704794e-07
Iter: 28 loss: 7.13226541e-07
Iter: 29 loss: 8.06677e-07
Iter: 30 loss: 7.12428687e-07
Iter: 31 loss: 7.04432239e-07
Iter: 32 loss: 7.02910654e-07
Iter: 33 loss: 6.97602331e-07
Iter: 34 loss: 6.8360481e-07
Iter: 35 loss: 7.2385177e-07
Iter: 36 loss: 6.79281186e-07
Iter: 37 loss: 6.78181209e-07
Iter: 38 loss: 6.7555186e-07
Iter: 39 loss: 6.71528596e-07
Iter: 40 loss: 6.70762063e-07
Iter: 41 loss: 6.68048528e-07
Iter: 42 loss: 6.64996492e-07
Iter: 43 loss: 6.74777198e-07
Iter: 44 loss: 6.64139463e-07
Iter: 45 loss: 6.62218611e-07
Iter: 46 loss: 6.62159437e-07
Iter: 47 loss: 6.61041668e-07
Iter: 48 loss: 6.58111958e-07
Iter: 49 loss: 6.77649439e-07
Iter: 50 loss: 6.57353e-07
Iter: 51 loss: 6.56281429e-07
Iter: 52 loss: 6.55355734e-07
Iter: 53 loss: 6.53815334e-07
Iter: 54 loss: 6.53782308e-07
Iter: 55 loss: 6.52625658e-07
Iter: 56 loss: 6.50934226e-07
Iter: 57 loss: 6.47879e-07
Iter: 58 loss: 7.1640909e-07
Iter: 59 loss: 6.47840125e-07
Iter: 60 loss: 6.46786816e-07
Iter: 61 loss: 6.4581991e-07
Iter: 62 loss: 6.44587772e-07
Iter: 63 loss: 6.44211696e-07
Iter: 64 loss: 6.43451301e-07
Iter: 65 loss: 6.42138616e-07
Iter: 66 loss: 6.39421785e-07
Iter: 67 loss: 6.86990802e-07
Iter: 68 loss: 6.39350844e-07
Iter: 69 loss: 6.36671928e-07
Iter: 70 loss: 6.54130133e-07
Iter: 71 loss: 6.36367929e-07
Iter: 72 loss: 6.34485275e-07
Iter: 73 loss: 6.49038952e-07
Iter: 74 loss: 6.34330206e-07
Iter: 75 loss: 6.32899116e-07
Iter: 76 loss: 6.29653528e-07
Iter: 77 loss: 6.68516407e-07
Iter: 78 loss: 6.29348278e-07
Iter: 79 loss: 6.28328223e-07
Iter: 80 loss: 6.27425493e-07
Iter: 81 loss: 6.26116218e-07
Iter: 82 loss: 6.26243263e-07
Iter: 83 loss: 6.25006578e-07
Iter: 84 loss: 6.23939911e-07
Iter: 85 loss: 6.27121153e-07
Iter: 86 loss: 6.23679284e-07
Iter: 87 loss: 6.22526102e-07
Iter: 88 loss: 6.34772789e-07
Iter: 89 loss: 6.22498135e-07
Iter: 90 loss: 6.22046684e-07
Iter: 91 loss: 6.21493086e-07
Iter: 92 loss: 6.21455e-07
Iter: 93 loss: 6.20705e-07
Iter: 94 loss: 6.23026494e-07
Iter: 95 loss: 6.20496792e-07
Iter: 96 loss: 6.19390335e-07
Iter: 97 loss: 6.21459492e-07
Iter: 98 loss: 6.18952697e-07
Iter: 99 loss: 6.17933381e-07
Iter: 100 loss: 6.17062881e-07
Iter: 101 loss: 6.16824821e-07
Iter: 102 loss: 6.15130375e-07
Iter: 103 loss: 6.19551201e-07
Iter: 104 loss: 6.14556484e-07
Iter: 105 loss: 6.12980216e-07
Iter: 106 loss: 6.13016084e-07
Iter: 107 loss: 6.11853466e-07
Iter: 108 loss: 6.10554196e-07
Iter: 109 loss: 6.10366499e-07
Iter: 110 loss: 6.08945072e-07
Iter: 111 loss: 6.12440715e-07
Iter: 112 loss: 6.08455821e-07
Iter: 113 loss: 6.07317929e-07
Iter: 114 loss: 6.07254208e-07
Iter: 115 loss: 6.06807646e-07
Iter: 116 loss: 6.06301967e-07
Iter: 117 loss: 6.06251945e-07
Iter: 118 loss: 6.05967e-07
Iter: 119 loss: 6.05922935e-07
Iter: 120 loss: 6.05527589e-07
Iter: 121 loss: 6.04591662e-07
Iter: 122 loss: 6.1816786e-07
Iter: 123 loss: 6.04530328e-07
Iter: 124 loss: 6.03778403e-07
Iter: 125 loss: 6.07263758e-07
Iter: 126 loss: 6.03625551e-07
Iter: 127 loss: 6.03147384e-07
Iter: 128 loss: 6.0314926e-07
Iter: 129 loss: 6.02738e-07
Iter: 130 loss: 6.01864826e-07
Iter: 131 loss: 6.13608e-07
Iter: 132 loss: 6.01687191e-07
Iter: 133 loss: 6.00729777e-07
Iter: 134 loss: 6.04623665e-07
Iter: 135 loss: 6.00543217e-07
Iter: 136 loss: 5.99933458e-07
Iter: 137 loss: 5.99900659e-07
Iter: 138 loss: 5.99217628e-07
Iter: 139 loss: 5.98748557e-07
Iter: 140 loss: 5.98556312e-07
Iter: 141 loss: 5.97556323e-07
Iter: 142 loss: 5.97419842e-07
Iter: 143 loss: 5.96756138e-07
Iter: 144 loss: 5.96247162e-07
Iter: 145 loss: 5.96097834e-07
Iter: 146 loss: 5.9544135e-07
Iter: 147 loss: 5.94049595e-07
Iter: 148 loss: 6.18871127e-07
Iter: 149 loss: 5.94025153e-07
Iter: 150 loss: 5.93137429e-07
Iter: 151 loss: 6.03113e-07
Iter: 152 loss: 5.93053301e-07
Iter: 153 loss: 5.92537901e-07
Iter: 154 loss: 6.01365912e-07
Iter: 155 loss: 5.9251721e-07
Iter: 156 loss: 5.92277956e-07
Iter: 157 loss: 5.91560479e-07
Iter: 158 loss: 5.96512223e-07
Iter: 159 loss: 5.91449179e-07
Iter: 160 loss: 5.90970558e-07
Iter: 161 loss: 5.90877676e-07
Iter: 162 loss: 5.90485399e-07
Iter: 163 loss: 5.92113736e-07
Iter: 164 loss: 5.9039138e-07
Iter: 165 loss: 5.90090622e-07
Iter: 166 loss: 5.89451531e-07
Iter: 167 loss: 5.98490715e-07
Iter: 168 loss: 5.89398269e-07
Iter: 169 loss: 5.88522482e-07
Iter: 170 loss: 5.94544e-07
Iter: 171 loss: 5.8841556e-07
Iter: 172 loss: 5.87541649e-07
Iter: 173 loss: 5.93820403e-07
Iter: 174 loss: 5.87497311e-07
Iter: 175 loss: 5.86976853e-07
Iter: 176 loss: 5.86122155e-07
Iter: 177 loss: 5.86142278e-07
Iter: 178 loss: 5.85356e-07
Iter: 179 loss: 5.91242042e-07
Iter: 180 loss: 5.85246426e-07
Iter: 181 loss: 5.84552595e-07
Iter: 182 loss: 5.91523531e-07
Iter: 183 loss: 5.8446858e-07
Iter: 184 loss: 5.84179475e-07
Iter: 185 loss: 5.83599558e-07
Iter: 186 loss: 5.96318557e-07
Iter: 187 loss: 5.83683857e-07
Iter: 188 loss: 5.83308633e-07
Iter: 189 loss: 5.83251108e-07
Iter: 190 loss: 5.82917096e-07
Iter: 191 loss: 5.82268171e-07
Iter: 192 loss: 5.9330705e-07
Iter: 193 loss: 5.82251573e-07
Iter: 194 loss: 5.81576217e-07
Iter: 195 loss: 5.84357679e-07
Iter: 196 loss: 5.81431323e-07
Iter: 197 loss: 5.80666892e-07
Iter: 198 loss: 5.85991415e-07
Iter: 199 loss: 5.80616472e-07
Iter: 200 loss: 5.79991138e-07
Iter: 201 loss: 5.79053278e-07
Iter: 202 loss: 5.79015591e-07
Iter: 203 loss: 5.78295442e-07
Iter: 204 loss: 5.82257826e-07
Iter: 205 loss: 5.78251161e-07
Iter: 206 loss: 5.77700916e-07
Iter: 207 loss: 5.8607975e-07
Iter: 208 loss: 5.77693413e-07
Iter: 209 loss: 5.77352e-07
Iter: 210 loss: 5.76846958e-07
Iter: 211 loss: 5.76807111e-07
Iter: 212 loss: 5.76274772e-07
Iter: 213 loss: 5.77051878e-07
Iter: 214 loss: 5.76073262e-07
Iter: 215 loss: 5.75566446e-07
Iter: 216 loss: 5.83445967e-07
Iter: 217 loss: 5.75600779e-07
Iter: 218 loss: 5.75152171e-07
Iter: 219 loss: 5.74156616e-07
Iter: 220 loss: 5.88812213e-07
Iter: 221 loss: 5.74106e-07
Iter: 222 loss: 5.73330396e-07
Iter: 223 loss: 5.81896472e-07
Iter: 224 loss: 5.73308e-07
Iter: 225 loss: 5.72305225e-07
Iter: 226 loss: 5.72097065e-07
Iter: 227 loss: 5.71388739e-07
Iter: 228 loss: 5.70407224e-07
Iter: 229 loss: 5.71626629e-07
Iter: 230 loss: 5.69912459e-07
Iter: 231 loss: 5.6975091e-07
Iter: 232 loss: 5.69543772e-07
Iter: 233 loss: 5.69312476e-07
Iter: 234 loss: 5.68752625e-07
Iter: 235 loss: 5.81847871e-07
Iter: 236 loss: 5.6873364e-07
Iter: 237 loss: 5.68177143e-07
Iter: 238 loss: 5.69339647e-07
Iter: 239 loss: 5.67914412e-07
Iter: 240 loss: 5.6765839e-07
Iter: 241 loss: 5.67609163e-07
Iter: 242 loss: 5.67300276e-07
Iter: 243 loss: 5.66951257e-07
Iter: 244 loss: 5.66901235e-07
Iter: 245 loss: 5.66296706e-07
Iter: 246 loss: 5.65235723e-07
Iter: 247 loss: 5.65223161e-07
Iter: 248 loss: 5.6465052e-07
Iter: 249 loss: 5.64451398e-07
Iter: 250 loss: 5.63735853e-07
Iter: 251 loss: 5.63450726e-07
Iter: 252 loss: 5.62996718e-07
Iter: 253 loss: 5.62192042e-07
Iter: 254 loss: 5.63194249e-07
Iter: 255 loss: 5.61783054e-07
Iter: 256 loss: 5.61605077e-07
Iter: 257 loss: 5.61327965e-07
Iter: 258 loss: 5.61145384e-07
Iter: 259 loss: 5.60522722e-07
Iter: 260 loss: 5.62690957e-07
Iter: 261 loss: 5.60249191e-07
Iter: 262 loss: 5.59472824e-07
Iter: 263 loss: 5.66597635e-07
Iter: 264 loss: 5.59385626e-07
Iter: 265 loss: 5.58801446e-07
Iter: 266 loss: 5.68870064e-07
Iter: 267 loss: 5.58822535e-07
Iter: 268 loss: 5.58531781e-07
Iter: 269 loss: 5.57907128e-07
Iter: 270 loss: 5.64017796e-07
Iter: 271 loss: 5.57858812e-07
Iter: 272 loss: 5.57221483e-07
Iter: 273 loss: 5.66100937e-07
Iter: 274 loss: 5.57183853e-07
Iter: 275 loss: 5.56624684e-07
Iter: 276 loss: 5.59790465e-07
Iter: 277 loss: 5.56556813e-07
Iter: 278 loss: 5.56265377e-07
Iter: 279 loss: 5.5566062e-07
Iter: 280 loss: 5.68568e-07
Iter: 281 loss: 5.5570581e-07
Iter: 282 loss: 5.55013457e-07
Iter: 283 loss: 5.57620581e-07
Iter: 284 loss: 5.54876e-07
Iter: 285 loss: 5.54454573e-07
Iter: 286 loss: 5.54455e-07
Iter: 287 loss: 5.54162568e-07
Iter: 288 loss: 5.5332896e-07
Iter: 289 loss: 5.55594e-07
Iter: 290 loss: 5.52942e-07
Iter: 291 loss: 5.52154233e-07
Iter: 292 loss: 5.52087499e-07
Iter: 293 loss: 5.51228538e-07
Iter: 294 loss: 5.51148219e-07
Iter: 295 loss: 5.50491507e-07
Iter: 296 loss: 5.49881292e-07
Iter: 297 loss: 5.48549281e-07
Iter: 298 loss: 5.74117507e-07
Iter: 299 loss: 5.48522394e-07
Iter: 300 loss: 5.48804735e-07
Iter: 301 loss: 5.47983745e-07
Iter: 302 loss: 5.47577883e-07
Iter: 303 loss: 5.48452761e-07
Iter: 304 loss: 5.47401e-07
Iter: 305 loss: 5.47180207e-07
Iter: 306 loss: 5.46763602e-07
Iter: 307 loss: 5.54751068e-07
Iter: 308 loss: 5.46774061e-07
Iter: 309 loss: 5.46501667e-07
Iter: 310 loss: 5.46503884e-07
Iter: 311 loss: 5.46214721e-07
Iter: 312 loss: 5.45911348e-07
Iter: 313 loss: 5.45862065e-07
Iter: 314 loss: 5.45434375e-07
Iter: 315 loss: 5.44604518e-07
Iter: 316 loss: 5.63535195e-07
Iter: 317 loss: 5.44594286e-07
Iter: 318 loss: 5.43978217e-07
Iter: 319 loss: 5.43948431e-07
Iter: 320 loss: 5.43530291e-07
Iter: 321 loss: 5.42920191e-07
Iter: 322 loss: 5.42900068e-07
Iter: 323 loss: 5.42059638e-07
Iter: 324 loss: 5.45772252e-07
Iter: 325 loss: 5.41959594e-07
Iter: 326 loss: 5.41298277e-07
Iter: 327 loss: 5.40812437e-07
Iter: 328 loss: 5.40599785e-07
Iter: 329 loss: 5.39854909e-07
Iter: 330 loss: 5.4046734e-07
Iter: 331 loss: 5.39483267e-07
Iter: 332 loss: 5.38699453e-07
Iter: 333 loss: 5.44606621e-07
Iter: 334 loss: 5.38623e-07
Iter: 335 loss: 5.37950257e-07
Iter: 336 loss: 5.42592147e-07
Iter: 337 loss: 5.37851861e-07
Iter: 338 loss: 5.37377218e-07
Iter: 339 loss: 5.37383073e-07
Iter: 340 loss: 5.36934124e-07
Iter: 341 loss: 5.36182824e-07
Iter: 342 loss: 5.36633479e-07
Iter: 343 loss: 5.35631614e-07
Iter: 344 loss: 5.35002755e-07
Iter: 345 loss: 5.34940227e-07
Iter: 346 loss: 5.3463441e-07
Iter: 347 loss: 5.34215246e-07
Iter: 348 loss: 5.34172443e-07
Iter: 349 loss: 5.33637376e-07
Iter: 350 loss: 5.36631319e-07
Iter: 351 loss: 5.33592242e-07
Iter: 352 loss: 5.3296236e-07
Iter: 353 loss: 5.3362885e-07
Iter: 354 loss: 5.32645799e-07
Iter: 355 loss: 5.32324748e-07
Iter: 356 loss: 5.3661563e-07
Iter: 357 loss: 5.32315426e-07
Iter: 358 loss: 5.31883757e-07
Iter: 359 loss: 5.3125973e-07
Iter: 360 loss: 5.31226419e-07
Iter: 361 loss: 5.30430384e-07
Iter: 362 loss: 5.32217598e-07
Iter: 363 loss: 5.30180785e-07
Iter: 364 loss: 5.29652823e-07
Iter: 365 loss: 5.35007246e-07
Iter: 366 loss: 5.29657e-07
Iter: 367 loss: 5.29258671e-07
Iter: 368 loss: 5.30766044e-07
Iter: 369 loss: 5.29238719e-07
Iter: 370 loss: 5.28837575e-07
Iter: 371 loss: 5.28718317e-07
Iter: 372 loss: 5.28450812e-07
Iter: 373 loss: 5.28080136e-07
Iter: 374 loss: 5.30651448e-07
Iter: 375 loss: 5.28051942e-07
Iter: 376 loss: 5.27835596e-07
Iter: 377 loss: 5.30778664e-07
Iter: 378 loss: 5.27789837e-07
Iter: 379 loss: 5.27561951e-07
Iter: 380 loss: 5.27020916e-07
Iter: 381 loss: 5.35740298e-07
Iter: 382 loss: 5.27050247e-07
Iter: 383 loss: 5.26576969e-07
Iter: 384 loss: 5.32859815e-07
Iter: 385 loss: 5.26570261e-07
Iter: 386 loss: 5.26227495e-07
Iter: 387 loss: 5.269805e-07
Iter: 388 loss: 5.26114604e-07
Iter: 389 loss: 5.25724488e-07
Iter: 390 loss: 5.26007e-07
Iter: 391 loss: 5.25550718e-07
Iter: 392 loss: 5.24957329e-07
Iter: 393 loss: 5.26382394e-07
Iter: 394 loss: 5.2477975e-07
Iter: 395 loss: 5.24376276e-07
Iter: 396 loss: 5.2431227e-07
Iter: 397 loss: 5.2408808e-07
Iter: 398 loss: 5.23625147e-07
Iter: 399 loss: 5.25485e-07
Iter: 400 loss: 5.23467804e-07
Iter: 401 loss: 5.23087692e-07
Iter: 402 loss: 5.28890268e-07
Iter: 403 loss: 5.23111339e-07
Iter: 404 loss: 5.22877144e-07
Iter: 405 loss: 5.22848723e-07
Iter: 406 loss: 5.22668245e-07
Iter: 407 loss: 5.22402559e-07
Iter: 408 loss: 5.22702294e-07
Iter: 409 loss: 5.22245841e-07
Iter: 410 loss: 5.21893071e-07
Iter: 411 loss: 5.2485376e-07
Iter: 412 loss: 5.21879542e-07
Iter: 413 loss: 5.21497327e-07
Iter: 414 loss: 5.21399556e-07
Iter: 415 loss: 5.21210495e-07
Iter: 416 loss: 5.2080253e-07
Iter: 417 loss: 5.21987715e-07
Iter: 418 loss: 5.20696062e-07
Iter: 419 loss: 5.20304468e-07
Iter: 420 loss: 5.21250229e-07
Iter: 421 loss: 5.20068909e-07
Iter: 422 loss: 5.19650484e-07
Iter: 423 loss: 5.20711865e-07
Iter: 424 loss: 5.19494392e-07
Iter: 425 loss: 5.19148557e-07
Iter: 426 loss: 5.22924893e-07
Iter: 427 loss: 5.1911411e-07
Iter: 428 loss: 5.19007358e-07
Iter: 429 loss: 5.185031e-07
Iter: 430 loss: 5.246917e-07
Iter: 431 loss: 5.18487695e-07
Iter: 432 loss: 5.18004128e-07
Iter: 433 loss: 5.20298215e-07
Iter: 434 loss: 5.17967806e-07
Iter: 435 loss: 5.17752312e-07
Iter: 436 loss: 5.17734406e-07
Iter: 437 loss: 5.17546084e-07
Iter: 438 loss: 5.17382716e-07
Iter: 439 loss: 5.17321894e-07
Iter: 440 loss: 5.16927571e-07
Iter: 441 loss: 5.16559339e-07
Iter: 442 loss: 5.16505338e-07
Iter: 443 loss: 5.16176272e-07
Iter: 444 loss: 5.16069e-07
Iter: 445 loss: 5.15727038e-07
Iter: 446 loss: 5.16261196e-07
Iter: 447 loss: 5.15555598e-07
Iter: 448 loss: 5.15184638e-07
Iter: 449 loss: 5.14893088e-07
Iter: 450 loss: 5.14839314e-07
Iter: 451 loss: 5.14096769e-07
Iter: 452 loss: 5.19577043e-07
Iter: 453 loss: 5.14098758e-07
Iter: 454 loss: 5.13755538e-07
Iter: 455 loss: 5.14791111e-07
Iter: 456 loss: 5.13656801e-07
Iter: 457 loss: 5.13375198e-07
Iter: 458 loss: 5.16171156e-07
Iter: 459 loss: 5.1342937e-07
Iter: 460 loss: 5.13181192e-07
Iter: 461 loss: 5.12672784e-07
Iter: 462 loss: 5.16633122e-07
Iter: 463 loss: 5.12543693e-07
Iter: 464 loss: 5.12078429e-07
Iter: 465 loss: 5.16277282e-07
Iter: 466 loss: 5.12035626e-07
Iter: 467 loss: 5.11722874e-07
Iter: 468 loss: 5.1311639e-07
Iter: 469 loss: 5.11705537e-07
Iter: 470 loss: 5.11283474e-07
Iter: 471 loss: 5.11268127e-07
Iter: 472 loss: 5.10959694e-07
Iter: 473 loss: 5.10362383e-07
Iter: 474 loss: 5.10470159e-07
Iter: 475 loss: 5.09892175e-07
Iter: 476 loss: 5.09443112e-07
Iter: 477 loss: 5.09400252e-07
Iter: 478 loss: 5.09036056e-07
Iter: 479 loss: 5.09294125e-07
Iter: 480 loss: 5.08793278e-07
Iter: 481 loss: 5.08242408e-07
Iter: 482 loss: 5.08318863e-07
Iter: 483 loss: 5.07826599e-07
Iter: 484 loss: 5.07293862e-07
Iter: 485 loss: 5.15031161e-07
Iter: 486 loss: 5.07276923e-07
Iter: 487 loss: 5.07031871e-07
Iter: 488 loss: 5.06845e-07
Iter: 489 loss: 5.0673e-07
Iter: 490 loss: 5.0623737e-07
Iter: 491 loss: 5.10432869e-07
Iter: 492 loss: 5.06267895e-07
Iter: 493 loss: 5.05895741e-07
Iter: 494 loss: 5.05418711e-07
Iter: 495 loss: 5.05502783e-07
Iter: 496 loss: 5.04980676e-07
Iter: 497 loss: 5.06075139e-07
Iter: 498 loss: 5.04862101e-07
Iter: 499 loss: 5.04436457e-07
Iter: 500 loss: 5.06826154e-07
Iter: 501 loss: 5.04358525e-07
Iter: 502 loss: 5.03917249e-07
Iter: 503 loss: 5.0584481e-07
Iter: 504 loss: 5.03803847e-07
Iter: 505 loss: 5.03534693e-07
Iter: 506 loss: 5.03612569e-07
Iter: 507 loss: 5.03322724e-07
Iter: 508 loss: 5.0294932e-07
Iter: 509 loss: 5.04166167e-07
Iter: 510 loss: 5.02894807e-07
Iter: 511 loss: 5.02414366e-07
Iter: 512 loss: 5.03893546e-07
Iter: 513 loss: 5.02289936e-07
Iter: 514 loss: 5.01945e-07
Iter: 515 loss: 5.0247678e-07
Iter: 516 loss: 5.01800514e-07
Iter: 517 loss: 5.01439501e-07
Iter: 518 loss: 5.03960621e-07
Iter: 519 loss: 5.01404315e-07
Iter: 520 loss: 5.01223269e-07
Iter: 521 loss: 5.00761075e-07
Iter: 522 loss: 5.00747092e-07
Iter: 523 loss: 5.00348051e-07
Iter: 524 loss: 5.0631138e-07
Iter: 525 loss: 5.00364138e-07
Iter: 526 loss: 4.99987095e-07
Iter: 527 loss: 4.99849307e-07
Iter: 528 loss: 4.99642908e-07
Iter: 529 loss: 4.99284056e-07
Iter: 530 loss: 4.99162127e-07
Iter: 531 loss: 4.98887744e-07
Iter: 532 loss: 4.98463294e-07
Iter: 533 loss: 5.02720809e-07
Iter: 534 loss: 4.98429415e-07
Iter: 535 loss: 4.98078293e-07
Iter: 536 loss: 4.99367729e-07
Iter: 537 loss: 4.98040436e-07
Iter: 538 loss: 4.97785379e-07
Iter: 539 loss: 4.97849328e-07
Iter: 540 loss: 4.974695e-07
Iter: 541 loss: 4.9713e-07
Iter: 542 loss: 4.98208863e-07
Iter: 543 loss: 4.96948644e-07
Iter: 544 loss: 4.96577854e-07
Iter: 545 loss: 5.00464921e-07
Iter: 546 loss: 4.96573932e-07
Iter: 547 loss: 4.96242819e-07
Iter: 548 loss: 4.96152722e-07
Iter: 549 loss: 4.96033863e-07
Iter: 550 loss: 4.95573659e-07
Iter: 551 loss: 4.9772035e-07
Iter: 552 loss: 4.95563086e-07
Iter: 553 loss: 4.95199117e-07
Iter: 554 loss: 4.94972539e-07
Iter: 555 loss: 4.94787685e-07
Iter: 556 loss: 4.94378412e-07
Iter: 557 loss: 4.94394101e-07
Iter: 558 loss: 4.94092376e-07
Iter: 559 loss: 4.93941457e-07
Iter: 560 loss: 4.93771665e-07
Iter: 561 loss: 4.93302309e-07
Iter: 562 loss: 4.93196353e-07
Iter: 563 loss: 4.92920094e-07
Iter: 564 loss: 4.92673621e-07
Iter: 565 loss: 4.92572497e-07
Iter: 566 loss: 4.92345521e-07
Iter: 567 loss: 4.92591141e-07
Iter: 568 loss: 4.92219e-07
Iter: 569 loss: 4.91991671e-07
Iter: 570 loss: 4.91706714e-07
Iter: 571 loss: 4.9163873e-07
Iter: 572 loss: 4.91147659e-07
Iter: 573 loss: 4.93426342e-07
Iter: 574 loss: 4.91015385e-07
Iter: 575 loss: 4.90656589e-07
Iter: 576 loss: 4.95837639e-07
Iter: 577 loss: 4.90696152e-07
Iter: 578 loss: 4.90484808e-07
Iter: 579 loss: 4.901907e-07
Iter: 580 loss: 4.90146704e-07
Iter: 581 loss: 4.89745332e-07
Iter: 582 loss: 4.92232175e-07
Iter: 583 loss: 4.89697811e-07
Iter: 584 loss: 4.89383694e-07
Iter: 585 loss: 4.8962147e-07
Iter: 586 loss: 4.8911977e-07
Iter: 587 loss: 4.88824526e-07
Iter: 588 loss: 4.91143737e-07
Iter: 589 loss: 4.88799344e-07
Iter: 590 loss: 4.88543265e-07
Iter: 591 loss: 4.88373701e-07
Iter: 592 loss: 4.88247906e-07
Iter: 593 loss: 4.87787588e-07
Iter: 594 loss: 4.8774973e-07
Iter: 595 loss: 4.87394061e-07
Iter: 596 loss: 4.87114676e-07
Iter: 597 loss: 4.91071e-07
Iter: 598 loss: 4.87074658e-07
Iter: 599 loss: 4.86708132e-07
Iter: 600 loss: 4.87022703e-07
Iter: 601 loss: 4.86473141e-07
Iter: 602 loss: 4.85986959e-07
Iter: 603 loss: 4.8633467e-07
Iter: 604 loss: 4.8571485e-07
Iter: 605 loss: 4.85317571e-07
Iter: 606 loss: 4.87752118e-07
Iter: 607 loss: 4.8526357e-07
Iter: 608 loss: 4.84956615e-07
Iter: 609 loss: 4.87503826e-07
Iter: 610 loss: 4.84937402e-07
Iter: 611 loss: 4.84672398e-07
Iter: 612 loss: 4.844253e-07
Iter: 613 loss: 4.84328837e-07
Iter: 614 loss: 4.83969302e-07
Iter: 615 loss: 4.87252237e-07
Iter: 616 loss: 4.83994313e-07
Iter: 617 loss: 4.83749432e-07
Iter: 618 loss: 4.84093846e-07
Iter: 619 loss: 4.83625627e-07
Iter: 620 loss: 4.83365852e-07
Iter: 621 loss: 4.83601411e-07
Iter: 622 loss: 4.8325e-07
Iter: 623 loss: 4.82851419e-07
Iter: 624 loss: 4.8421748e-07
Iter: 625 loss: 4.82657299e-07
Iter: 626 loss: 4.82427311e-07
Iter: 627 loss: 4.82136443e-07
Iter: 628 loss: 4.82095857e-07
Iter: 629 loss: 4.81679933e-07
Iter: 630 loss: 4.83116196e-07
Iter: 631 loss: 4.81560051e-07
Iter: 632 loss: 4.81092798e-07
Iter: 633 loss: 4.83881252e-07
Iter: 634 loss: 4.81004463e-07
Iter: 635 loss: 4.80780614e-07
Iter: 636 loss: 4.81381051e-07
Iter: 637 loss: 4.80640836e-07
Iter: 638 loss: 4.80366737e-07
Iter: 639 loss: 4.80786298e-07
Iter: 640 loss: 4.80268966e-07
Iter: 641 loss: 4.79940581e-07
Iter: 642 loss: 4.82149289e-07
Iter: 643 loss: 4.79912842e-07
Iter: 644 loss: 4.79632263e-07
Iter: 645 loss: 4.80179779e-07
Iter: 646 loss: 4.79514881e-07
Iter: 647 loss: 4.79390906e-07
Iter: 648 loss: 4.800375e-07
Iter: 649 loss: 4.79296318e-07
Iter: 650 loss: 4.79074401e-07
Iter: 651 loss: 4.79044047e-07
Iter: 652 loss: 4.78832476e-07
Iter: 653 loss: 4.78483571e-07
Iter: 654 loss: 4.78807e-07
Iter: 655 loss: 4.78280072e-07
Iter: 656 loss: 4.77869378e-07
Iter: 657 loss: 4.82924406e-07
Iter: 658 loss: 4.77857384e-07
Iter: 659 loss: 4.77602896e-07
Iter: 660 loss: 4.77144397e-07
Iter: 661 loss: 4.85215139e-07
Iter: 662 loss: 4.77135472e-07
Iter: 663 loss: 4.76625e-07
Iter: 664 loss: 4.80987069e-07
Iter: 665 loss: 4.76609785e-07
Iter: 666 loss: 4.76240359e-07
Iter: 667 loss: 4.80595133e-07
Iter: 668 loss: 4.76284612e-07
Iter: 669 loss: 4.76065111e-07
Iter: 670 loss: 4.75925191e-07
Iter: 671 loss: 4.75887759e-07
Iter: 672 loss: 4.75512053e-07
Iter: 673 loss: 4.7588648e-07
Iter: 674 loss: 4.75363379e-07
Iter: 675 loss: 4.75037837e-07
Iter: 676 loss: 4.79082928e-07
Iter: 677 loss: 4.75021096e-07
Iter: 678 loss: 4.74720594e-07
Iter: 679 loss: 4.75414936e-07
Iter: 680 loss: 4.74551484e-07
Iter: 681 loss: 4.7431962e-07
Iter: 682 loss: 4.74508909e-07
Iter: 683 loss: 4.74161823e-07
Iter: 684 loss: 4.73742944e-07
Iter: 685 loss: 4.74391868e-07
Iter: 686 loss: 4.73493685e-07
Iter: 687 loss: 4.73081315e-07
Iter: 688 loss: 4.74555236e-07
Iter: 689 loss: 4.72985931e-07
Iter: 690 loss: 4.72706319e-07
Iter: 691 loss: 4.76927767e-07
Iter: 692 loss: 4.72707598e-07
Iter: 693 loss: 4.72551818e-07
Iter: 694 loss: 4.72154852e-07
Iter: 695 loss: 4.76954824e-07
Iter: 696 loss: 4.72055035e-07
Iter: 697 loss: 4.71720483e-07
Iter: 698 loss: 4.75246736e-07
Iter: 699 loss: 4.71627e-07
Iter: 700 loss: 4.71370868e-07
Iter: 701 loss: 4.71390535e-07
Iter: 702 loss: 4.71185018e-07
Iter: 703 loss: 4.70924306e-07
Iter: 704 loss: 4.7878e-07
Iter: 705 loss: 4.70929166e-07
Iter: 706 loss: 4.70416182e-07
Iter: 707 loss: 4.71187491e-07
Iter: 708 loss: 4.70219305e-07
Iter: 709 loss: 4.69818872e-07
Iter: 710 loss: 4.74913691e-07
Iter: 711 loss: 4.69808725e-07
Iter: 712 loss: 4.6951115e-07
Iter: 713 loss: 4.70037975e-07
Iter: 714 loss: 4.69295713e-07
Iter: 715 loss: 4.68953431e-07
Iter: 716 loss: 4.69170288e-07
Iter: 717 loss: 4.68693543e-07
Iter: 718 loss: 4.68197698e-07
Iter: 719 loss: 4.71029068e-07
Iter: 720 loss: 4.68178484e-07
Iter: 721 loss: 4.67907682e-07
Iter: 722 loss: 4.68357086e-07
Iter: 723 loss: 4.6779121e-07
Iter: 724 loss: 4.67559516e-07
Iter: 725 loss: 4.70049798e-07
Iter: 726 loss: 4.67545505e-07
Iter: 727 loss: 4.67331461e-07
Iter: 728 loss: 4.66991509e-07
Iter: 729 loss: 4.66963229e-07
Iter: 730 loss: 4.66695326e-07
Iter: 731 loss: 4.67676898e-07
Iter: 732 loss: 4.66649311e-07
Iter: 733 loss: 4.66403861e-07
Iter: 734 loss: 4.69062854e-07
Iter: 735 loss: 4.6640244e-07
Iter: 736 loss: 4.66204824e-07
Iter: 737 loss: 4.65851542e-07
Iter: 738 loss: 4.65885819e-07
Iter: 739 loss: 4.6547882e-07
Iter: 740 loss: 4.67166302e-07
Iter: 741 loss: 4.65429366e-07
Iter: 742 loss: 4.65173628e-07
Iter: 743 loss: 4.66792216e-07
Iter: 744 loss: 4.65160952e-07
Iter: 745 loss: 4.64930309e-07
Iter: 746 loss: 4.65708496e-07
Iter: 747 loss: 4.64852803e-07
Iter: 748 loss: 4.64668972e-07
Iter: 749 loss: 4.64841094e-07
Iter: 750 loss: 4.6450549e-07
Iter: 751 loss: 4.64305458e-07
Iter: 752 loss: 4.66373564e-07
Iter: 753 loss: 4.64282863e-07
Iter: 754 loss: 4.6413308e-07
Iter: 755 loss: 4.64089482e-07
Iter: 756 loss: 4.64039601e-07
Iter: 757 loss: 4.63842639e-07
Iter: 758 loss: 4.65456537e-07
Iter: 759 loss: 4.63825842e-07
Iter: 760 loss: 4.6362797e-07
Iter: 761 loss: 4.63386243e-07
Iter: 762 loss: 4.63333436e-07
Iter: 763 loss: 4.63084177e-07
Iter: 764 loss: 4.63254707e-07
Iter: 765 loss: 4.6287596e-07
Iter: 766 loss: 4.62590123e-07
Iter: 767 loss: 4.62620051e-07
Iter: 768 loss: 4.62337141e-07
Iter: 769 loss: 4.62508893e-07
Iter: 770 loss: 4.62203332e-07
Iter: 771 loss: 4.61960838e-07
Iter: 772 loss: 4.62588048e-07
Iter: 773 loss: 4.61893706e-07
Iter: 774 loss: 4.61627366e-07
Iter: 775 loss: 4.6321037e-07
Iter: 776 loss: 4.61663035e-07
Iter: 777 loss: 4.61411815e-07
Iter: 778 loss: 4.62077764e-07
Iter: 779 loss: 4.61336072e-07
Iter: 780 loss: 4.61171794e-07
Iter: 781 loss: 4.61578566e-07
Iter: 782 loss: 4.61072545e-07
Iter: 783 loss: 4.60950559e-07
Iter: 784 loss: 4.61986048e-07
Iter: 785 loss: 4.60935496e-07
Iter: 786 loss: 4.60774203e-07
Iter: 787 loss: 4.60500274e-07
Iter: 788 loss: 4.60486177e-07
Iter: 789 loss: 4.6022825e-07
Iter: 790 loss: 4.64527204e-07
Iter: 791 loss: 4.6022393e-07
Iter: 792 loss: 4.60000138e-07
Iter: 793 loss: 4.59848451e-07
Iter: 794 loss: 4.59755483e-07
Iter: 795 loss: 4.59557e-07
Iter: 796 loss: 4.59460864e-07
Iter: 797 loss: 4.59316595e-07
Iter: 798 loss: 4.59054149e-07
Iter: 799 loss: 4.59115796e-07
Iter: 800 loss: 4.58935347e-07
Iter: 801 loss: 4.5900407e-07
Iter: 802 loss: 4.58817709e-07
Iter: 803 loss: 4.58669803e-07
Iter: 804 loss: 4.58714908e-07
Iter: 805 loss: 4.58560635e-07
Iter: 806 loss: 4.58302281e-07
Iter: 807 loss: 4.60062438e-07
Iter: 808 loss: 4.58337695e-07
Iter: 809 loss: 4.58107422e-07
Iter: 810 loss: 4.58828595e-07
Iter: 811 loss: 4.58086788e-07
Iter: 812 loss: 4.57860153e-07
Iter: 813 loss: 4.5803796e-07
Iter: 814 loss: 4.5775522e-07
Iter: 815 loss: 4.57545e-07
Iter: 816 loss: 4.58407243e-07
Iter: 817 loss: 4.57517558e-07
Iter: 818 loss: 4.57204e-07
Iter: 819 loss: 4.56961203e-07
Iter: 820 loss: 4.56926841e-07
Iter: 821 loss: 4.56636457e-07
Iter: 822 loss: 4.56641175e-07
Iter: 823 loss: 4.56390921e-07
Iter: 824 loss: 4.56456576e-07
Iter: 825 loss: 4.56184068e-07
Iter: 826 loss: 4.56003391e-07
Iter: 827 loss: 4.55834225e-07
Iter: 828 loss: 4.55720567e-07
Iter: 829 loss: 4.55481597e-07
Iter: 830 loss: 4.55487481e-07
Iter: 831 loss: 4.55357394e-07
Iter: 832 loss: 4.55459713e-07
Iter: 833 loss: 4.55216195e-07
Iter: 834 loss: 4.55034e-07
Iter: 835 loss: 4.54744963e-07
Iter: 836 loss: 4.54734391e-07
Iter: 837 loss: 4.54376902e-07
Iter: 838 loss: 4.5927942e-07
Iter: 839 loss: 4.54390317e-07
Iter: 840 loss: 4.54118094e-07
Iter: 841 loss: 4.55788864e-07
Iter: 842 loss: 4.54094106e-07
Iter: 843 loss: 4.53890209e-07
Iter: 844 loss: 4.5402561e-07
Iter: 845 loss: 4.53754751e-07
Iter: 846 loss: 4.53493868e-07
Iter: 847 loss: 4.54708527e-07
Iter: 848 loss: 4.53471529e-07
Iter: 849 loss: 4.53203143e-07
Iter: 850 loss: 4.53299435e-07
Iter: 851 loss: 4.53024313e-07
Iter: 852 loss: 4.52895506e-07
Iter: 853 loss: 4.54930557e-07
Iter: 854 loss: 4.5286049e-07
Iter: 855 loss: 4.5271139e-07
Iter: 856 loss: 4.5287976e-07
Iter: 857 loss: 4.52595e-07
Iter: 858 loss: 4.52439366e-07
Iter: 859 loss: 4.52369875e-07
Iter: 860 loss: 4.52313174e-07
Iter: 861 loss: 4.52099982e-07
Iter: 862 loss: 4.52120787e-07
Iter: 863 loss: 4.51970379e-07
Iter: 864 loss: 4.5189924e-07
Iter: 865 loss: 4.51827248e-07
Iter: 866 loss: 4.51554314e-07
Iter: 867 loss: 4.51377815e-07
Iter: 868 loss: 4.5129616e-07
Iter: 869 loss: 4.51116733e-07
Iter: 870 loss: 4.51086123e-07
Iter: 871 loss: 4.50960101e-07
Iter: 872 loss: 4.51750452e-07
Iter: 873 loss: 4.50885466e-07
Iter: 874 loss: 4.50775815e-07
Iter: 875 loss: 4.50893111e-07
Iter: 876 loss: 4.50677021e-07
Iter: 877 loss: 4.50535197e-07
Iter: 878 loss: 4.51335694e-07
Iter: 879 loss: 4.5044851e-07
Iter: 880 loss: 4.50329367e-07
Iter: 881 loss: 4.50340167e-07
Iter: 882 loss: 4.50193966e-07
Iter: 883 loss: 4.50004592e-07
Iter: 884 loss: 4.5031598e-07
Iter: 885 loss: 4.49881952e-07
Iter: 886 loss: 4.49588697e-07
Iter: 887 loss: 4.50796506e-07
Iter: 888 loss: 4.49566642e-07
Iter: 889 loss: 4.49340178e-07
Iter: 890 loss: 4.49115674e-07
Iter: 891 loss: 4.49083927e-07
Iter: 892 loss: 4.48795021e-07
Iter: 893 loss: 4.51344619e-07
Iter: 894 loss: 4.48810795e-07
Iter: 895 loss: 4.48561394e-07
Iter: 896 loss: 4.48809232e-07
Iter: 897 loss: 4.48433269e-07
Iter: 898 loss: 4.48243043e-07
Iter: 899 loss: 4.48468114e-07
Iter: 900 loss: 4.48088826e-07
Iter: 901 loss: 4.47938902e-07
Iter: 902 loss: 4.49099275e-07
Iter: 903 loss: 4.47917103e-07
Iter: 904 loss: 4.47769082e-07
Iter: 905 loss: 4.4856796e-07
Iter: 906 loss: 4.47727956e-07
Iter: 907 loss: 4.47584597e-07
Iter: 908 loss: 4.4771042e-07
Iter: 909 loss: 4.47477788e-07
Iter: 910 loss: 4.47315756e-07
Iter: 911 loss: 4.48277433e-07
Iter: 912 loss: 4.4727588e-07
Iter: 913 loss: 4.47111375e-07
Iter: 914 loss: 4.47182799e-07
Iter: 915 loss: 4.47016589e-07
Iter: 916 loss: 4.46794559e-07
Iter: 917 loss: 4.46810105e-07
Iter: 918 loss: 4.46603764e-07
Iter: 919 loss: 4.46335747e-07
Iter: 920 loss: 4.46345069e-07
Iter: 921 loss: 4.4617542e-07
Iter: 922 loss: 4.46109823e-07
Iter: 923 loss: 4.46067844e-07
Iter: 924 loss: 4.45910075e-07
Iter: 925 loss: 4.47021307e-07
Iter: 926 loss: 4.4590314e-07
Iter: 927 loss: 4.45721867e-07
Iter: 928 loss: 4.4595231e-07
Iter: 929 loss: 4.45708e-07
Iter: 930 loss: 4.45533544e-07
Iter: 931 loss: 4.45482442e-07
Iter: 932 loss: 4.45377225e-07
Iter: 933 loss: 4.45186657e-07
Iter: 934 loss: 4.45503929e-07
Iter: 935 loss: 4.45079024e-07
Iter: 936 loss: 4.44806858e-07
Iter: 937 loss: 4.47736824e-07
Iter: 938 loss: 4.44823741e-07
Iter: 939 loss: 4.44639397e-07
Iter: 940 loss: 4.44714658e-07
Iter: 941 loss: 4.44534e-07
Iter: 942 loss: 4.44380134e-07
Iter: 943 loss: 4.45329249e-07
Iter: 944 loss: 4.44359273e-07
Iter: 945 loss: 4.44153585e-07
Iter: 946 loss: 4.44284836e-07
Iter: 947 loss: 4.44061811e-07
Iter: 948 loss: 4.43810961e-07
Iter: 949 loss: 4.44055729e-07
Iter: 950 loss: 4.43733938e-07
Iter: 951 loss: 4.43669649e-07
Iter: 952 loss: 4.43612549e-07
Iter: 953 loss: 4.43594985e-07
Iter: 954 loss: 4.43450972e-07
Iter: 955 loss: 4.45737442e-07
Iter: 956 loss: 4.4341536e-07
Iter: 957 loss: 4.43225559e-07
Iter: 958 loss: 4.43942128e-07
Iter: 959 loss: 4.43162293e-07
Iter: 960 loss: 4.42956036e-07
Iter: 961 loss: 4.44022419e-07
Iter: 962 loss: 4.42881884e-07
Iter: 963 loss: 4.42800967e-07
Iter: 964 loss: 4.42691459e-07
Iter: 965 loss: 4.42590306e-07
Iter: 966 loss: 4.423581e-07
Iter: 967 loss: 4.42142834e-07
Iter: 968 loss: 4.4210563e-07
Iter: 969 loss: 4.41981172e-07
Iter: 970 loss: 4.41881753e-07
Iter: 971 loss: 4.41712643e-07
Iter: 972 loss: 4.41821356e-07
Iter: 973 loss: 4.41641617e-07
Iter: 974 loss: 4.41512896e-07
Iter: 975 loss: 4.42145279e-07
Iter: 976 loss: 4.41475208e-07
Iter: 977 loss: 4.41364364e-07
Iter: 978 loss: 4.41485554e-07
Iter: 979 loss: 4.4130843e-07
Iter: 980 loss: 4.4114077e-07
Iter: 981 loss: 4.41161404e-07
Iter: 982 loss: 4.41035809e-07
Iter: 983 loss: 4.40890034e-07
Iter: 984 loss: 4.40894269e-07
Iter: 985 loss: 4.40785158e-07
Iter: 986 loss: 4.40550025e-07
Iter: 987 loss: 4.40548206e-07
Iter: 988 loss: 4.40324186e-07
Iter: 989 loss: 4.41515652e-07
Iter: 990 loss: 4.40271293e-07
Iter: 991 loss: 4.40071744e-07
Iter: 992 loss: 4.41200427e-07
Iter: 993 loss: 4.40103975e-07
Iter: 994 loss: 4.39946859e-07
Iter: 995 loss: 4.39897633e-07
Iter: 996 loss: 4.39787641e-07
Iter: 997 loss: 4.39583403e-07
Iter: 998 loss: 4.39680605e-07
Iter: 999 loss: 4.39360548e-07
Iter: 1000 loss: 4.39390334e-07
Iter: 1001 loss: 4.39293302e-07
Iter: 1002 loss: 4.39225147e-07
Iter: 1003 loss: 4.39112881e-07
Iter: 1004 loss: 4.39076047e-07
Iter: 1005 loss: 4.38895825e-07
Iter: 1006 loss: 4.40002083e-07
Iter: 1007 loss: 4.38874594e-07
Iter: 1008 loss: 4.38713755e-07
Iter: 1009 loss: 4.39181406e-07
Iter: 1010 loss: 4.38581935e-07
Iter: 1011 loss: 4.38461086e-07
Iter: 1012 loss: 4.38570055e-07
Iter: 1013 loss: 4.38346376e-07
Iter: 1014 loss: 4.38210577e-07
Iter: 1015 loss: 4.38954771e-07
Iter: 1016 loss: 4.38162431e-07
Iter: 1017 loss: 4.3799713e-07
Iter: 1018 loss: 4.38383466e-07
Iter: 1019 loss: 4.37916e-07
Iter: 1020 loss: 4.37852293e-07
Iter: 1021 loss: 4.38073e-07
Iter: 1022 loss: 4.37817732e-07
Iter: 1023 loss: 4.37748326e-07
Iter: 1024 loss: 4.38160527e-07
Iter: 1025 loss: 4.37698418e-07
Iter: 1026 loss: 4.37621139e-07
Iter: 1027 loss: 4.37572453e-07
Iter: 1028 loss: 4.37560914e-07
Iter: 1029 loss: 4.37438359e-07
Iter: 1030 loss: 4.37477695e-07
Iter: 1031 loss: 4.37339793e-07
Iter: 1032 loss: 4.37189584e-07
Iter: 1033 loss: 4.38006168e-07
Iter: 1034 loss: 4.37165909e-07
Iter: 1035 loss: 4.37035169e-07
Iter: 1036 loss: 4.37255238e-07
Iter: 1037 loss: 4.36888882e-07
Iter: 1038 loss: 4.36748337e-07
Iter: 1039 loss: 4.37548e-07
Iter: 1040 loss: 4.36774656e-07
Iter: 1041 loss: 4.36613192e-07
Iter: 1042 loss: 4.36961614e-07
Iter: 1043 loss: 4.36586163e-07
Iter: 1044 loss: 4.36464063e-07
Iter: 1045 loss: 4.36472e-07
Iter: 1046 loss: 4.3639406e-07
Iter: 1047 loss: 4.36211337e-07
Iter: 1048 loss: 4.37125266e-07
Iter: 1049 loss: 4.3617618e-07
Iter: 1050 loss: 4.36048623e-07
Iter: 1051 loss: 4.37023346e-07
Iter: 1052 loss: 4.36043706e-07
Iter: 1053 loss: 4.36000079e-07
Iter: 1054 loss: 4.35874313e-07
Iter: 1055 loss: 4.38902134e-07
Iter: 1056 loss: 4.35847312e-07
Iter: 1057 loss: 4.35624258e-07
Iter: 1058 loss: 4.37102301e-07
Iter: 1059 loss: 4.3566169e-07
Iter: 1060 loss: 4.35515517e-07
Iter: 1061 loss: 4.35924449e-07
Iter: 1062 loss: 4.3546828e-07
Iter: 1063 loss: 4.35309801e-07
Iter: 1064 loss: 4.35329923e-07
Iter: 1065 loss: 4.35260461e-07
Iter: 1066 loss: 4.35114117e-07
Iter: 1067 loss: 4.35115e-07
Iter: 1068 loss: 4.34969252e-07
Iter: 1069 loss: 4.34867047e-07
Iter: 1070 loss: 4.3482197e-07
Iter: 1071 loss: 4.34804207e-07
Iter: 1072 loss: 4.34731732e-07
Iter: 1073 loss: 4.3469845e-07
Iter: 1074 loss: 4.34587804e-07
Iter: 1075 loss: 4.34984287e-07
Iter: 1076 loss: 4.34576862e-07
Iter: 1077 loss: 4.34438647e-07
Iter: 1078 loss: 4.34520928e-07
Iter: 1079 loss: 4.34391438e-07
Iter: 1080 loss: 4.34142862e-07
Iter: 1081 loss: 4.34477386e-07
Iter: 1082 loss: 4.34149399e-07
Iter: 1083 loss: 4.34036707e-07
Iter: 1084 loss: 4.35051533e-07
Iter: 1085 loss: 4.34035712e-07
Iter: 1086 loss: 4.33915261e-07
Iter: 1087 loss: 4.33721198e-07
Iter: 1088 loss: 4.33741207e-07
Iter: 1089 loss: 4.33626042e-07
Iter: 1090 loss: 4.33657817e-07
Iter: 1091 loss: 4.33571017e-07
Iter: 1092 loss: 4.3371881e-07
Iter: 1093 loss: 4.33530914e-07
Iter: 1094 loss: 4.33437606e-07
Iter: 1095 loss: 4.33451078e-07
Iter: 1096 loss: 4.33349044e-07
Iter: 1097 loss: 4.33246271e-07
Iter: 1098 loss: 4.33648268e-07
Iter: 1099 loss: 4.33233197e-07
Iter: 1100 loss: 4.33135654e-07
Iter: 1101 loss: 4.33154696e-07
Iter: 1102 loss: 4.33096432e-07
Iter: 1103 loss: 4.32897792e-07
Iter: 1104 loss: 4.36184621e-07
Iter: 1105 loss: 4.32919336e-07
Iter: 1106 loss: 4.32764637e-07
Iter: 1107 loss: 4.34702628e-07
Iter: 1108 loss: 4.32794025e-07
Iter: 1109 loss: 4.32643446e-07
Iter: 1110 loss: 4.32957535e-07
Iter: 1111 loss: 4.32638728e-07
Iter: 1112 loss: 4.32480704e-07
Iter: 1113 loss: 4.32484967e-07
Iter: 1114 loss: 4.32394131e-07
Iter: 1115 loss: 4.32241421e-07
Iter: 1116 loss: 4.3298391e-07
Iter: 1117 loss: 4.32189722e-07
Iter: 1118 loss: 4.32022858e-07
Iter: 1119 loss: 4.32390692e-07
Iter: 1120 loss: 4.31954277e-07
Iter: 1121 loss: 4.31806114e-07
Iter: 1122 loss: 4.31644736e-07
Iter: 1123 loss: 4.31639705e-07
Iter: 1124 loss: 4.31412786e-07
Iter: 1125 loss: 4.34538237e-07
Iter: 1126 loss: 4.31392209e-07
Iter: 1127 loss: 4.3128972e-07
Iter: 1128 loss: 4.31305807e-07
Iter: 1129 loss: 4.31158753e-07
Iter: 1130 loss: 4.3101852e-07
Iter: 1131 loss: 4.31037677e-07
Iter: 1132 loss: 4.30908727e-07
Iter: 1133 loss: 4.30711054e-07
Iter: 1134 loss: 4.31727415e-07
Iter: 1135 loss: 4.30645684e-07
Iter: 1136 loss: 4.30662396e-07
Iter: 1137 loss: 4.30584151e-07
Iter: 1138 loss: 4.30546208e-07
Iter: 1139 loss: 4.30430362e-07
Iter: 1140 loss: 4.31164324e-07
Iter: 1141 loss: 4.30425672e-07
Iter: 1142 loss: 4.30219529e-07
Iter: 1143 loss: 4.32312305e-07
Iter: 1144 loss: 4.30239709e-07
Iter: 1145 loss: 4.30134435e-07
Iter: 1146 loss: 4.31202949e-07
Iter: 1147 loss: 4.30141824e-07
Iter: 1148 loss: 4.30111271e-07
Iter: 1149 loss: 4.29948557e-07
Iter: 1150 loss: 4.31995261e-07
Iter: 1151 loss: 4.29928434e-07
Iter: 1152 loss: 4.297234e-07
Iter: 1153 loss: 4.31617423e-07
Iter: 1154 loss: 4.2966326e-07
Iter: 1155 loss: 4.29566626e-07
Iter: 1156 loss: 4.2952712e-07
Iter: 1157 loss: 4.29440405e-07
Iter: 1158 loss: 4.2929824e-07
Iter: 1159 loss: 4.29719421e-07
Iter: 1160 loss: 4.29276668e-07
Iter: 1161 loss: 4.29030507e-07
Iter: 1162 loss: 4.28873591e-07
Iter: 1163 loss: 4.28796199e-07
Iter: 1164 loss: 4.2861916e-07
Iter: 1165 loss: 4.29680767e-07
Iter: 1166 loss: 4.28501039e-07
Iter: 1167 loss: 4.28335056e-07
Iter: 1168 loss: 4.28317492e-07
Iter: 1169 loss: 4.28205283e-07
Iter: 1170 loss: 4.28008093e-07
Iter: 1171 loss: 4.30663135e-07
Iter: 1172 loss: 4.28005592e-07
Iter: 1173 loss: 4.27861579e-07
Iter: 1174 loss: 4.29207915e-07
Iter: 1175 loss: 4.27824659e-07
Iter: 1176 loss: 4.27716515e-07
Iter: 1177 loss: 4.27474419e-07
Iter: 1178 loss: 4.2901425e-07
Iter: 1179 loss: 4.27390489e-07
Iter: 1180 loss: 4.27153566e-07
Iter: 1181 loss: 4.31299554e-07
Iter: 1182 loss: 4.2713927e-07
Iter: 1183 loss: 4.27012367e-07
Iter: 1184 loss: 4.29213458e-07
Iter: 1185 loss: 4.26969962e-07
Iter: 1186 loss: 4.26900897e-07
Iter: 1187 loss: 4.2678397e-07
Iter: 1188 loss: 4.29717034e-07
Iter: 1189 loss: 4.26746851e-07
Iter: 1190 loss: 4.26556056e-07
Iter: 1191 loss: 4.26601332e-07
Iter: 1192 loss: 4.26512315e-07
Iter: 1193 loss: 4.26406132e-07
Iter: 1194 loss: 4.26350596e-07
Iter: 1195 loss: 4.26173983e-07
Iter: 1196 loss: 4.26499412e-07
Iter: 1197 loss: 4.26085933e-07
Iter: 1198 loss: 4.25794042e-07
Iter: 1199 loss: 4.26169947e-07
Iter: 1200 loss: 4.25662449e-07
Iter: 1201 loss: 4.25411514e-07
Iter: 1202 loss: 4.25406e-07
Iter: 1203 loss: 4.25266791e-07
Iter: 1204 loss: 4.24956795e-07
Iter: 1205 loss: 4.2522322e-07
Iter: 1206 loss: 4.24821025e-07
Iter: 1207 loss: 4.24638e-07
Iter: 1208 loss: 4.24680081e-07
Iter: 1209 loss: 4.24534335e-07
Iter: 1210 loss: 4.24501366e-07
Iter: 1211 loss: 4.24386343e-07
Iter: 1212 loss: 4.24221e-07
Iter: 1213 loss: 4.24182758e-07
Iter: 1214 loss: 4.23978094e-07
Iter: 1215 loss: 4.23765812e-07
Iter: 1216 loss: 4.23770302e-07
Iter: 1217 loss: 4.23631207e-07
Iter: 1218 loss: 4.24152887e-07
Iter: 1219 loss: 4.23562085e-07
Iter: 1220 loss: 4.23452946e-07
Iter: 1221 loss: 4.23327378e-07
Iter: 1222 loss: 4.2331294e-07
Iter: 1223 loss: 4.23163669e-07
Iter: 1224 loss: 4.25218445e-07
Iter: 1225 loss: 4.23138943e-07
Iter: 1226 loss: 4.22968753e-07
Iter: 1227 loss: 4.23013631e-07
Iter: 1228 loss: 4.22917424e-07
Iter: 1229 loss: 4.22843584e-07
Iter: 1230 loss: 4.23486256e-07
Iter: 1231 loss: 4.2279197e-07
Iter: 1232 loss: 4.22666517e-07
Iter: 1233 loss: 4.22522589e-07
Iter: 1234 loss: 4.22566416e-07
Iter: 1235 loss: 4.22326082e-07
Iter: 1236 loss: 4.22748315e-07
Iter: 1237 loss: 4.22247e-07
Iter: 1238 loss: 4.22111384e-07
Iter: 1239 loss: 4.22485016e-07
Iter: 1240 loss: 4.22052892e-07
Iter: 1241 loss: 4.21844192e-07
Iter: 1242 loss: 4.22187043e-07
Iter: 1243 loss: 4.21757534e-07
Iter: 1244 loss: 4.21543859e-07
Iter: 1245 loss: 4.21740367e-07
Iter: 1246 loss: 4.21461266e-07
Iter: 1247 loss: 4.21320095e-07
Iter: 1248 loss: 4.21332345e-07
Iter: 1249 loss: 4.21174605e-07
Iter: 1250 loss: 4.21146467e-07
Iter: 1251 loss: 4.21032297e-07
Iter: 1252 loss: 4.20908947e-07
Iter: 1253 loss: 4.21675537e-07
Iter: 1254 loss: 4.20859237e-07
Iter: 1255 loss: 4.20718692e-07
Iter: 1256 loss: 4.21979166e-07
Iter: 1257 loss: 4.20775365e-07
Iter: 1258 loss: 4.20655851e-07
Iter: 1259 loss: 4.20491887e-07
Iter: 1260 loss: 4.20492796e-07
Iter: 1261 loss: 4.20320816e-07
Iter: 1262 loss: 4.21417781e-07
Iter: 1263 loss: 4.20269146e-07
Iter: 1264 loss: 4.20105181e-07
Iter: 1265 loss: 4.2026e-07
Iter: 1266 loss: 4.20048593e-07
Iter: 1267 loss: 4.19847936e-07
Iter: 1268 loss: 4.20472816e-07
Iter: 1269 loss: 4.19810902e-07
Iter: 1270 loss: 4.19602486e-07
Iter: 1271 loss: 4.19955796e-07
Iter: 1272 loss: 4.19474787e-07
Iter: 1273 loss: 4.19331826e-07
Iter: 1274 loss: 4.20230322e-07
Iter: 1275 loss: 4.19320202e-07
Iter: 1276 loss: 4.19166895e-07
Iter: 1277 loss: 4.19403534e-07
Iter: 1278 loss: 4.19103287e-07
Iter: 1279 loss: 4.19013702e-07
Iter: 1280 loss: 4.19048803e-07
Iter: 1281 loss: 4.18875317e-07
Iter: 1282 loss: 4.18702655e-07
Iter: 1283 loss: 4.20214747e-07
Iter: 1284 loss: 4.18678724e-07
Iter: 1285 loss: 4.18574189e-07
Iter: 1286 loss: 4.18659397e-07
Iter: 1287 loss: 4.18522518e-07
Iter: 1288 loss: 4.18386946e-07
Iter: 1289 loss: 4.18775926e-07
Iter: 1290 loss: 4.1834852e-07
Iter: 1291 loss: 4.18194077e-07
Iter: 1292 loss: 4.18213574e-07
Iter: 1293 loss: 4.18060438e-07
Iter: 1294 loss: 4.1780342e-07
Iter: 1295 loss: 4.19034507e-07
Iter: 1296 loss: 4.17798759e-07
Iter: 1297 loss: 4.1768908e-07
Iter: 1298 loss: 4.1803969e-07
Iter: 1299 loss: 4.17620669e-07
Iter: 1300 loss: 4.17500985e-07
Iter: 1301 loss: 4.17652757e-07
Iter: 1302 loss: 4.17419159e-07
Iter: 1303 loss: 4.17258093e-07
Iter: 1304 loss: 4.17667479e-07
Iter: 1305 loss: 4.17220235e-07
Iter: 1306 loss: 4.17107e-07
Iter: 1307 loss: 4.17785628e-07
Iter: 1308 loss: 4.17108538e-07
Iter: 1309 loss: 4.16935649e-07
Iter: 1310 loss: 4.16938718e-07
Iter: 1311 loss: 4.16856068e-07
Iter: 1312 loss: 4.16734906e-07
Iter: 1313 loss: 4.17001218e-07
Iter: 1314 loss: 4.16646458e-07
Iter: 1315 loss: 4.16541923e-07
Iter: 1316 loss: 4.16507561e-07
Iter: 1317 loss: 4.16436023e-07
Iter: 1318 loss: 4.1625006e-07
Iter: 1319 loss: 4.1624665e-07
Iter: 1320 loss: 4.1615607e-07
Iter: 1321 loss: 4.16936928e-07
Iter: 1322 loss: 4.16132281e-07
Iter: 1323 loss: 4.15925626e-07
Iter: 1324 loss: 4.16600699e-07
Iter: 1325 loss: 4.15852554e-07
Iter: 1326 loss: 4.15678471e-07
Iter: 1327 loss: 4.16051677e-07
Iter: 1328 loss: 4.15614181e-07
Iter: 1329 loss: 4.15483271e-07
Iter: 1330 loss: 4.15530906e-07
Iter: 1331 loss: 4.15325246e-07
Iter: 1332 loss: 4.1510404e-07
Iter: 1333 loss: 4.15528348e-07
Iter: 1334 loss: 4.14985209e-07
Iter: 1335 loss: 4.14805356e-07
Iter: 1336 loss: 4.16710634e-07
Iter: 1337 loss: 4.14786854e-07
Iter: 1338 loss: 4.14611549e-07
Iter: 1339 loss: 4.1492774e-07
Iter: 1340 loss: 4.14567864e-07
Iter: 1341 loss: 4.14419929e-07
Iter: 1342 loss: 4.1439921e-07
Iter: 1343 loss: 4.14316048e-07
Iter: 1344 loss: 4.14076396e-07
Iter: 1345 loss: 4.14781226e-07
Iter: 1346 loss: 4.14011936e-07
Iter: 1347 loss: 4.13918656e-07
Iter: 1348 loss: 4.13953899e-07
Iter: 1349 loss: 4.13806475e-07
Iter: 1350 loss: 4.13562304e-07
Iter: 1351 loss: 4.17719377e-07
Iter: 1352 loss: 4.13559945e-07
Iter: 1353 loss: 4.13380405e-07
Iter: 1354 loss: 4.15650817e-07
Iter: 1355 loss: 4.13425738e-07
Iter: 1356 loss: 4.13238268e-07
Iter: 1357 loss: 4.13898533e-07
Iter: 1358 loss: 4.13204958e-07
Iter: 1359 loss: 4.13046223e-07
Iter: 1360 loss: 4.13122166e-07
Iter: 1361 loss: 4.12986765e-07
Iter: 1362 loss: 4.12766127e-07
Iter: 1363 loss: 4.12870946e-07
Iter: 1364 loss: 4.12594773e-07
Iter: 1365 loss: 4.12327e-07
Iter: 1366 loss: 4.13639668e-07
Iter: 1367 loss: 4.12263603e-07
Iter: 1368 loss: 4.12122915e-07
Iter: 1369 loss: 4.13658967e-07
Iter: 1370 loss: 4.12109586e-07
Iter: 1371 loss: 4.12060501e-07
Iter: 1372 loss: 4.11980267e-07
Iter: 1373 loss: 4.11933854e-07
Iter: 1374 loss: 4.11787795e-07
Iter: 1375 loss: 4.12021677e-07
Iter: 1376 loss: 4.11664473e-07
Iter: 1377 loss: 4.11515828e-07
Iter: 1378 loss: 4.11843047e-07
Iter: 1379 loss: 4.11475668e-07
Iter: 1380 loss: 4.11290017e-07
Iter: 1381 loss: 4.12647495e-07
Iter: 1382 loss: 4.11269525e-07
Iter: 1383 loss: 4.11099165e-07
Iter: 1384 loss: 4.11018618e-07
Iter: 1385 loss: 4.1093358e-07
Iter: 1386 loss: 4.10759299e-07
Iter: 1387 loss: 4.12454312e-07
Iter: 1388 loss: 4.10710811e-07
Iter: 1389 loss: 4.10571943e-07
Iter: 1390 loss: 4.10814692e-07
Iter: 1391 loss: 4.10526951e-07
Iter: 1392 loss: 4.10331722e-07
Iter: 1393 loss: 4.10307877e-07
Iter: 1394 loss: 4.1014988e-07
Iter: 1395 loss: 4.09854579e-07
Iter: 1396 loss: 4.1134092e-07
Iter: 1397 loss: 4.09832836e-07
Iter: 1398 loss: 4.09665972e-07
Iter: 1399 loss: 4.10084652e-07
Iter: 1400 loss: 4.09645338e-07
Iter: 1401 loss: 4.09462928e-07
Iter: 1402 loss: 4.10094913e-07
Iter: 1403 loss: 4.09429447e-07
Iter: 1404 loss: 4.0931647e-07
Iter: 1405 loss: 4.09391134e-07
Iter: 1406 loss: 4.09211566e-07
Iter: 1407 loss: 4.0905087e-07
Iter: 1408 loss: 4.09451161e-07
Iter: 1409 loss: 4.08977144e-07
Iter: 1410 loss: 4.08816561e-07
Iter: 1411 loss: 4.0877768e-07
Iter: 1412 loss: 4.08714641e-07
Iter: 1413 loss: 4.08393561e-07
Iter: 1414 loss: 4.10744178e-07
Iter: 1415 loss: 4.08422125e-07
Iter: 1416 loss: 4.08203903e-07
Iter: 1417 loss: 4.08806386e-07
Iter: 1418 loss: 4.08141034e-07
Iter: 1419 loss: 4.07969196e-07
Iter: 1420 loss: 4.08073902e-07
Iter: 1421 loss: 4.07881942e-07
Iter: 1422 loss: 4.07579591e-07
Iter: 1423 loss: 4.08258927e-07
Iter: 1424 loss: 4.07488585e-07
Iter: 1425 loss: 4.07249331e-07
Iter: 1426 loss: 4.08259382e-07
Iter: 1427 loss: 4.07211786e-07
Iter: 1428 loss: 4.0704893e-07
Iter: 1429 loss: 4.08006173e-07
Iter: 1430 loss: 4.07019144e-07
Iter: 1431 loss: 4.06870271e-07
Iter: 1432 loss: 4.0670659e-07
Iter: 1433 loss: 4.06698916e-07
Iter: 1434 loss: 4.06391848e-07
Iter: 1435 loss: 4.08421727e-07
Iter: 1436 loss: 4.06357486e-07
Iter: 1437 loss: 4.0613125e-07
Iter: 1438 loss: 4.06887e-07
Iter: 1439 loss: 4.06105926e-07
Iter: 1440 loss: 4.05922208e-07
Iter: 1441 loss: 4.05975726e-07
Iter: 1442 loss: 4.05801671e-07
Iter: 1443 loss: 4.05569381e-07
Iter: 1444 loss: 4.05513617e-07
Iter: 1445 loss: 4.05379637e-07
Iter: 1446 loss: 4.05125974e-07
Iter: 1447 loss: 4.0515755e-07
Iter: 1448 loss: 4.05002197e-07
Iter: 1449 loss: 4.05667151e-07
Iter: 1450 loss: 4.04888851e-07
Iter: 1451 loss: 4.04786874e-07
Iter: 1452 loss: 4.04460337e-07
Iter: 1453 loss: 4.10728319e-07
Iter: 1454 loss: 4.04476083e-07
Iter: 1455 loss: 4.0415182e-07
Iter: 1456 loss: 4.09232769e-07
Iter: 1457 loss: 4.04132322e-07
Iter: 1458 loss: 4.03981261e-07
Iter: 1459 loss: 4.04279433e-07
Iter: 1460 loss: 4.03864505e-07
Iter: 1461 loss: 4.03663648e-07
Iter: 1462 loss: 4.04284776e-07
Iter: 1463 loss: 4.03626785e-07
Iter: 1464 loss: 4.03423371e-07
Iter: 1465 loss: 4.03198953e-07
Iter: 1466 loss: 4.03201682e-07
Iter: 1467 loss: 4.02878641e-07
Iter: 1468 loss: 4.02913031e-07
Iter: 1469 loss: 4.02712459e-07
Iter: 1470 loss: 4.03169224e-07
Iter: 1471 loss: 4.02685828e-07
Iter: 1472 loss: 4.02478e-07
Iter: 1473 loss: 4.0225018e-07
Iter: 1474 loss: 4.02213175e-07
Iter: 1475 loss: 4.01877372e-07
Iter: 1476 loss: 4.02778113e-07
Iter: 1477 loss: 4.01736571e-07
Iter: 1478 loss: 4.01464803e-07
Iter: 1479 loss: 4.04157191e-07
Iter: 1480 loss: 4.01470061e-07
Iter: 1481 loss: 4.01209917e-07
Iter: 1482 loss: 4.02314299e-07
Iter: 1483 loss: 4.01162055e-07
Iter: 1484 loss: 4.00904639e-07
Iter: 1485 loss: 4.00672036e-07
Iter: 1486 loss: 4.00584071e-07
Iter: 1487 loss: 4.00334784e-07
Iter: 1488 loss: 4.00353656e-07
Iter: 1489 loss: 4.00165277e-07
Iter: 1490 loss: 3.99939893e-07
Iter: 1491 loss: 3.99937619e-07
Iter: 1492 loss: 3.99552448e-07
Iter: 1493 loss: 4.01786565e-07
Iter: 1494 loss: 3.99498703e-07
Iter: 1495 loss: 3.99212752e-07
Iter: 1496 loss: 3.9935685e-07
Iter: 1497 loss: 3.99022952e-07
Iter: 1498 loss: 3.98727025e-07
Iter: 1499 loss: 3.99711496e-07
Iter: 1500 loss: 3.98672086e-07
Iter: 1501 loss: 3.98356974e-07
Iter: 1502 loss: 4.0019097e-07
Iter: 1503 loss: 3.98283049e-07
Iter: 1504 loss: 3.97951595e-07
Iter: 1505 loss: 3.97905382e-07
Iter: 1506 loss: 3.97705435e-07
Iter: 1507 loss: 3.97298948e-07
Iter: 1508 loss: 3.9774946e-07
Iter: 1509 loss: 3.97147431e-07
Iter: 1510 loss: 3.96792132e-07
Iter: 1511 loss: 3.9747e-07
Iter: 1512 loss: 3.96619896e-07
Iter: 1513 loss: 3.96324765e-07
Iter: 1514 loss: 3.96326016e-07
Iter: 1515 loss: 3.96179331e-07
Iter: 1516 loss: 3.95923394e-07
Iter: 1517 loss: 3.95913275e-07
Iter: 1518 loss: 3.95637471e-07
Iter: 1519 loss: 3.98541715e-07
Iter: 1520 loss: 3.95664983e-07
Iter: 1521 loss: 3.95400491e-07
Iter: 1522 loss: 3.95073585e-07
Iter: 1523 loss: 3.95025609e-07
Iter: 1524 loss: 3.94910785e-07
Iter: 1525 loss: 3.94846722e-07
Iter: 1526 loss: 3.94638789e-07
Iter: 1527 loss: 3.94516178e-07
Iter: 1528 loss: 3.94439581e-07
Iter: 1529 loss: 3.94169319e-07
Iter: 1530 loss: 3.93878736e-07
Iter: 1531 loss: 3.93832465e-07
Iter: 1532 loss: 3.93723667e-07
Iter: 1533 loss: 3.9362186e-07
Iter: 1534 loss: 3.93482139e-07
Iter: 1535 loss: 3.93400683e-07
Iter: 1536 loss: 3.93342447e-07
Iter: 1537 loss: 3.93167568e-07
Iter: 1538 loss: 3.92903416e-07
Iter: 1539 loss: 3.92915467e-07
Iter: 1540 loss: 3.92611213e-07
Iter: 1541 loss: 3.9589591e-07
Iter: 1542 loss: 3.92579949e-07
Iter: 1543 loss: 3.92472259e-07
Iter: 1544 loss: 3.92485646e-07
Iter: 1545 loss: 3.92352234e-07
Iter: 1546 loss: 3.92117585e-07
Iter: 1547 loss: 3.92171614e-07
Iter: 1548 loss: 3.91917951e-07
Iter: 1549 loss: 3.93200082e-07
Iter: 1550 loss: 3.91901835e-07
Iter: 1551 loss: 3.91687735e-07
Iter: 1552 loss: 3.92284534e-07
Iter: 1553 loss: 3.91604e-07
Iter: 1554 loss: 3.91492307e-07
Iter: 1555 loss: 3.913417e-07
Iter: 1556 loss: 3.91320754e-07
Iter: 1557 loss: 3.90984553e-07
Iter: 1558 loss: 3.92909413e-07
Iter: 1559 loss: 3.9091276e-07
Iter: 1560 loss: 3.90833719e-07
Iter: 1561 loss: 3.90768889e-07
Iter: 1562 loss: 3.90739331e-07
Iter: 1563 loss: 3.90558654e-07
Iter: 1564 loss: 3.92583672e-07
Iter: 1565 loss: 3.9055044e-07
Iter: 1566 loss: 3.90373685e-07
Iter: 1567 loss: 3.90601485e-07
Iter: 1568 loss: 3.90331195e-07
Iter: 1569 loss: 3.90295043e-07
Iter: 1570 loss: 3.90332048e-07
Iter: 1571 loss: 3.90203525e-07
Iter: 1572 loss: 3.9007864e-07
Iter: 1573 loss: 3.90045756e-07
Iter: 1574 loss: 3.89977913e-07
Iter: 1575 loss: 3.8992323e-07
Iter: 1576 loss: 3.89884974e-07
Iter: 1577 loss: 3.89792291e-07
Iter: 1578 loss: 3.89875822e-07
Iter: 1579 loss: 3.89760828e-07
Iter: 1580 loss: 3.89687528e-07
Iter: 1581 loss: 3.89601553e-07
Iter: 1582 loss: 3.89569891e-07
Iter: 1583 loss: 3.89398707e-07
Iter: 1584 loss: 3.91642914e-07
Iter: 1585 loss: 3.89407887e-07
Iter: 1586 loss: 3.89329017e-07
Iter: 1587 loss: 3.89092861e-07
Iter: 1588 loss: 3.91135529e-07
Iter: 1589 loss: 3.89029367e-07
Iter: 1590 loss: 3.88741057e-07
Iter: 1591 loss: 3.92588788e-07
Iter: 1592 loss: 3.88735771e-07
Iter: 1593 loss: 3.88457465e-07
Iter: 1594 loss: 3.88174954e-07
Iter: 1595 loss: 3.88128e-07
Iter: 1596 loss: 3.87901792e-07
Iter: 1597 loss: 3.87799616e-07
Iter: 1598 loss: 3.87652278e-07
Iter: 1599 loss: 3.87326793e-07
Iter: 1600 loss: 3.87319602e-07
Iter: 1601 loss: 3.87205e-07
Iter: 1602 loss: 3.87543139e-07
Iter: 1603 loss: 3.87141768e-07
Iter: 1604 loss: 3.87033083e-07
Iter: 1605 loss: 3.86885e-07
Iter: 1606 loss: 3.86891e-07
Iter: 1607 loss: 3.86637339e-07
Iter: 1608 loss: 3.8632021e-07
Iter: 1609 loss: 3.86331067e-07
Iter: 1610 loss: 3.86204533e-07
Iter: 1611 loss: 3.86158206e-07
Iter: 1612 loss: 3.86005723e-07
Iter: 1613 loss: 3.858745e-07
Iter: 1614 loss: 3.85826127e-07
Iter: 1615 loss: 3.85609951e-07
Iter: 1616 loss: 3.88014598e-07
Iter: 1617 loss: 3.85656506e-07
Iter: 1618 loss: 3.85393804e-07
Iter: 1619 loss: 3.85624617e-07
Iter: 1620 loss: 3.85366747e-07
Iter: 1621 loss: 3.85229356e-07
Iter: 1622 loss: 3.84990869e-07
Iter: 1623 loss: 3.90224415e-07
Iter: 1624 loss: 3.84995815e-07
Iter: 1625 loss: 3.84885311e-07
Iter: 1626 loss: 3.84860982e-07
Iter: 1627 loss: 3.84784869e-07
Iter: 1628 loss: 3.8465285e-07
Iter: 1629 loss: 3.84627413e-07
Iter: 1630 loss: 3.84541494e-07
Iter: 1631 loss: 3.84332111e-07
Iter: 1632 loss: 3.8432978e-07
Iter: 1633 loss: 3.84204185e-07
Iter: 1634 loss: 3.84177923e-07
Iter: 1635 loss: 3.84002817e-07
Iter: 1636 loss: 3.83901295e-07
Iter: 1637 loss: 3.83911981e-07
Iter: 1638 loss: 3.83624354e-07
Iter: 1639 loss: 3.83370804e-07
Iter: 1640 loss: 3.83325329e-07
Iter: 1641 loss: 3.82916198e-07
Iter: 1642 loss: 3.84475754e-07
Iter: 1643 loss: 3.82794866e-07
Iter: 1644 loss: 3.82621465e-07
Iter: 1645 loss: 3.82619703e-07
Iter: 1646 loss: 3.82460485e-07
Iter: 1647 loss: 3.82594465e-07
Iter: 1648 loss: 3.82367716e-07
Iter: 1649 loss: 3.82132498e-07
Iter: 1650 loss: 3.8331072e-07
Iter: 1651 loss: 3.82086625e-07
Iter: 1652 loss: 3.82030777e-07
Iter: 1653 loss: 3.81922291e-07
Iter: 1654 loss: 3.81878124e-07
Iter: 1655 loss: 3.81801669e-07
Iter: 1656 loss: 3.82780883e-07
Iter: 1657 loss: 3.81782741e-07
Iter: 1658 loss: 3.81626336e-07
Iter: 1659 loss: 3.82023302e-07
Iter: 1660 loss: 3.81603684e-07
Iter: 1661 loss: 3.81492725e-07
Iter: 1662 loss: 3.81411382e-07
Iter: 1663 loss: 3.81374406e-07
Iter: 1664 loss: 3.8117048e-07
Iter: 1665 loss: 3.81215955e-07
Iter: 1666 loss: 3.80956124e-07
Iter: 1667 loss: 3.80801168e-07
Iter: 1668 loss: 3.8077e-07
Iter: 1669 loss: 3.80681797e-07
Iter: 1670 loss: 3.80627597e-07
Iter: 1671 loss: 3.80601307e-07
Iter: 1672 loss: 3.80385444e-07
Iter: 1673 loss: 3.80499e-07
Iter: 1674 loss: 3.80267238e-07
Iter: 1675 loss: 3.80025483e-07
Iter: 1676 loss: 3.80987501e-07
Iter: 1677 loss: 3.79992514e-07
Iter: 1678 loss: 3.79815106e-07
Iter: 1679 loss: 3.82133123e-07
Iter: 1680 loss: 3.79824201e-07
Iter: 1681 loss: 3.7970608e-07
Iter: 1682 loss: 3.79934477e-07
Iter: 1683 loss: 3.79698037e-07
Iter: 1684 loss: 3.79498431e-07
Iter: 1685 loss: 3.79270148e-07
Iter: 1686 loss: 3.79261e-07
Iter: 1687 loss: 3.79077278e-07
Iter: 1688 loss: 3.79568519e-07
Iter: 1689 loss: 3.79005428e-07
Iter: 1690 loss: 3.78850245e-07
Iter: 1691 loss: 3.78871789e-07
Iter: 1692 loss: 3.7872536e-07
Iter: 1693 loss: 3.78545906e-07
Iter: 1694 loss: 3.78541927e-07
Iter: 1695 loss: 3.78391348e-07
Iter: 1696 loss: 3.78630403e-07
Iter: 1697 loss: 3.78297869e-07
Iter: 1698 loss: 3.78174491e-07
Iter: 1699 loss: 3.79218108e-07
Iter: 1700 loss: 3.78139646e-07
Iter: 1701 loss: 3.77985941e-07
Iter: 1702 loss: 3.78928547e-07
Iter: 1703 loss: 3.77929837e-07
Iter: 1704 loss: 3.77848863e-07
Iter: 1705 loss: 3.77719971e-07
Iter: 1706 loss: 3.77710535e-07
Iter: 1707 loss: 3.77434503e-07
Iter: 1708 loss: 3.78098889e-07
Iter: 1709 loss: 3.77335198e-07
Iter: 1710 loss: 3.77057404e-07
Iter: 1711 loss: 3.79267902e-07
Iter: 1712 loss: 3.77112201e-07
Iter: 1713 loss: 3.76899862e-07
Iter: 1714 loss: 3.77666112e-07
Iter: 1715 loss: 3.76898583e-07
Iter: 1716 loss: 3.76738797e-07
Iter: 1717 loss: 3.77504193e-07
Iter: 1718 loss: 3.76741383e-07
Iter: 1719 loss: 3.76622154e-07
Iter: 1720 loss: 3.76372441e-07
Iter: 1721 loss: 3.80564e-07
Iter: 1722 loss: 3.76381706e-07
Iter: 1723 loss: 3.76274954e-07
Iter: 1724 loss: 3.76264239e-07
Iter: 1725 loss: 3.7616266e-07
Iter: 1726 loss: 3.76543881e-07
Iter: 1727 loss: 3.76162092e-07
Iter: 1728 loss: 3.76066453e-07
Iter: 1729 loss: 3.7598474e-07
Iter: 1730 loss: 3.77652015e-07
Iter: 1731 loss: 3.75956716e-07
Iter: 1732 loss: 3.75816512e-07
Iter: 1733 loss: 3.7665427e-07
Iter: 1734 loss: 3.75763364e-07
Iter: 1735 loss: 3.75669714e-07
Iter: 1736 loss: 3.76263e-07
Iter: 1737 loss: 3.7571931e-07
Iter: 1738 loss: 3.75524365e-07
Iter: 1739 loss: 3.75721868e-07
Iter: 1740 loss: 3.75455812e-07
Iter: 1741 loss: 3.75315352e-07
Iter: 1742 loss: 3.75250806e-07
Iter: 1743 loss: 3.75185323e-07
Iter: 1744 loss: 3.75047961e-07
Iter: 1745 loss: 3.76370167e-07
Iter: 1746 loss: 3.74994187e-07
Iter: 1747 loss: 3.74913185e-07
Iter: 1748 loss: 3.74932171e-07
Iter: 1749 loss: 3.74841704e-07
Iter: 1750 loss: 3.74728131e-07
Iter: 1751 loss: 3.74730575e-07
Iter: 1752 loss: 3.7463434e-07
Iter: 1753 loss: 3.7455294e-07
Iter: 1754 loss: 3.74537535e-07
Iter: 1755 loss: 3.74338839e-07
Iter: 1756 loss: 3.74219724e-07
Iter: 1757 loss: 3.74134459e-07
Iter: 1758 loss: 3.74023045e-07
Iter: 1759 loss: 3.74039985e-07
Iter: 1760 loss: 3.73884177e-07
Iter: 1761 loss: 3.73844159e-07
Iter: 1762 loss: 3.73766852e-07
Iter: 1763 loss: 3.73639779e-07
Iter: 1764 loss: 3.73518333e-07
Iter: 1765 loss: 3.73462655e-07
Iter: 1766 loss: 3.73319665e-07
Iter: 1767 loss: 3.75025053e-07
Iter: 1768 loss: 3.73302385e-07
Iter: 1769 loss: 3.73197423e-07
Iter: 1770 loss: 3.73839725e-07
Iter: 1771 loss: 3.73228318e-07
Iter: 1772 loss: 3.73138391e-07
Iter: 1773 loss: 3.73242131e-07
Iter: 1774 loss: 3.73077285e-07
Iter: 1775 loss: 3.73007168e-07
Iter: 1776 loss: 3.73038745e-07
Iter: 1777 loss: 3.72971073e-07
Iter: 1778 loss: 3.72861024e-07
Iter: 1779 loss: 3.73302157e-07
Iter: 1780 loss: 3.72815236e-07
Iter: 1781 loss: 3.72726333e-07
Iter: 1782 loss: 3.72571151e-07
Iter: 1783 loss: 3.72601e-07
Iter: 1784 loss: 3.72571947e-07
Iter: 1785 loss: 3.72495094e-07
Iter: 1786 loss: 3.72462551e-07
Iter: 1787 loss: 3.72331925e-07
Iter: 1788 loss: 3.75054128e-07
Iter: 1789 loss: 3.72338945e-07
Iter: 1790 loss: 3.7216742e-07
Iter: 1791 loss: 3.72554382e-07
Iter: 1792 loss: 3.72130813e-07
Iter: 1793 loss: 3.720655e-07
Iter: 1794 loss: 3.7204893e-07
Iter: 1795 loss: 3.71994e-07
Iter: 1796 loss: 3.71948886e-07
Iter: 1797 loss: 3.71905344e-07
Iter: 1798 loss: 3.71799473e-07
Iter: 1799 loss: 3.71732199e-07
Iter: 1800 loss: 3.71709262e-07
Iter: 1801 loss: 3.71602312e-07
Iter: 1802 loss: 3.72380612e-07
Iter: 1803 loss: 3.71563885e-07
Iter: 1804 loss: 3.7147413e-07
Iter: 1805 loss: 3.71601288e-07
Iter: 1806 loss: 3.71412796e-07
Iter: 1807 loss: 3.7132412e-07
Iter: 1808 loss: 3.71312382e-07
Iter: 1809 loss: 3.7124434e-07
Iter: 1810 loss: 3.71161832e-07
Iter: 1811 loss: 3.7117843e-07
Iter: 1812 loss: 3.71020064e-07
Iter: 1813 loss: 3.7158685e-07
Iter: 1814 loss: 3.71002869e-07
Iter: 1815 loss: 3.70807498e-07
Iter: 1816 loss: 3.71101351e-07
Iter: 1817 loss: 3.70780128e-07
Iter: 1818 loss: 3.70644557e-07
Iter: 1819 loss: 3.70960606e-07
Iter: 1820 loss: 3.70648252e-07
Iter: 1821 loss: 3.70497617e-07
Iter: 1822 loss: 3.70824125e-07
Iter: 1823 loss: 3.7043111e-07
Iter: 1824 loss: 3.70317707e-07
Iter: 1825 loss: 3.70193e-07
Iter: 1826 loss: 3.70167214e-07
Iter: 1827 loss: 3.69980512e-07
Iter: 1828 loss: 3.69964255e-07
Iter: 1829 loss: 3.69909912e-07
Iter: 1830 loss: 3.69869269e-07
Iter: 1831 loss: 3.69844884e-07
Iter: 1832 loss: 3.69744896e-07
Iter: 1833 loss: 3.6961427e-07
Iter: 1834 loss: 3.6960256e-07
Iter: 1835 loss: 3.69506779e-07
Iter: 1836 loss: 3.70217691e-07
Iter: 1837 loss: 3.69499e-07
Iter: 1838 loss: 3.6940159e-07
Iter: 1839 loss: 3.69868133e-07
Iter: 1840 loss: 3.69417478e-07
Iter: 1841 loss: 3.69281963e-07
Iter: 1842 loss: 3.70027237e-07
Iter: 1843 loss: 3.69295748e-07
Iter: 1844 loss: 3.69243196e-07
Iter: 1845 loss: 3.69207299e-07
Iter: 1846 loss: 3.69173e-07
Iter: 1847 loss: 3.69098245e-07
Iter: 1848 loss: 3.69614412e-07
Iter: 1849 loss: 3.69080453e-07
Iter: 1850 loss: 3.69018693e-07
Iter: 1851 loss: 3.69016391e-07
Iter: 1852 loss: 3.68918165e-07
Iter: 1853 loss: 3.68825255e-07
Iter: 1854 loss: 3.69887715e-07
Iter: 1855 loss: 3.6885217e-07
Iter: 1856 loss: 3.68793138e-07
Iter: 1857 loss: 3.688221e-07
Iter: 1858 loss: 3.68738057e-07
Iter: 1859 loss: 3.68647079e-07
Iter: 1860 loss: 3.69051122e-07
Iter: 1861 loss: 3.68630197e-07
Iter: 1862 loss: 3.6861411e-07
Iter: 1863 loss: 3.68489026e-07
Iter: 1864 loss: 3.68468051e-07
Iter: 1865 loss: 3.683611e-07
Iter: 1866 loss: 3.69164269e-07
Iter: 1867 loss: 3.68359338e-07
Iter: 1868 loss: 3.68244059e-07
Iter: 1869 loss: 3.68244713e-07
Iter: 1870 loss: 3.6819273e-07
Iter: 1871 loss: 3.68081885e-07
Iter: 1872 loss: 3.6908267e-07
Iter: 1873 loss: 3.68062643e-07
Iter: 1874 loss: 3.67999064e-07
Iter: 1875 loss: 3.68002617e-07
Iter: 1876 loss: 3.67968539e-07
Iter: 1877 loss: 3.67911e-07
Iter: 1878 loss: 3.69365097e-07
Iter: 1879 loss: 3.6790027e-07
Iter: 1880 loss: 3.67802784e-07
Iter: 1881 loss: 3.68330291e-07
Iter: 1882 loss: 3.67785702e-07
Iter: 1883 loss: 3.67745628e-07
Iter: 1884 loss: 3.67777261e-07
Iter: 1885 loss: 3.67683441e-07
Iter: 1886 loss: 3.67561341e-07
Iter: 1887 loss: 3.68320798e-07
Iter: 1888 loss: 3.67551195e-07
Iter: 1889 loss: 3.67485e-07
Iter: 1890 loss: 3.67390811e-07
Iter: 1891 loss: 3.67385411e-07
Iter: 1892 loss: 3.67252397e-07
Iter: 1893 loss: 3.68356609e-07
Iter: 1894 loss: 3.67273685e-07
Iter: 1895 loss: 3.67164205e-07
Iter: 1896 loss: 3.67278744e-07
Iter: 1897 loss: 3.67136238e-07
Iter: 1898 loss: 3.67032158e-07
Iter: 1899 loss: 3.66899712e-07
Iter: 1900 loss: 3.66913639e-07
Iter: 1901 loss: 3.66771587e-07
Iter: 1902 loss: 3.67687505e-07
Iter: 1903 loss: 3.66748907e-07
Iter: 1904 loss: 3.66662277e-07
Iter: 1905 loss: 3.66473159e-07
Iter: 1906 loss: 3.70212263e-07
Iter: 1907 loss: 3.66486631e-07
Iter: 1908 loss: 3.66354186e-07
Iter: 1909 loss: 3.66340601e-07
Iter: 1910 loss: 3.66223844e-07
Iter: 1911 loss: 3.66486859e-07
Iter: 1912 loss: 3.662322e-07
Iter: 1913 loss: 3.66157678e-07
Iter: 1914 loss: 3.66007384e-07
Iter: 1915 loss: 3.68856433e-07
Iter: 1916 loss: 3.65997892e-07
Iter: 1917 loss: 3.65895659e-07
Iter: 1918 loss: 3.66519032e-07
Iter: 1919 loss: 3.65886876e-07
Iter: 1920 loss: 3.6579587e-07
Iter: 1921 loss: 3.6656246e-07
Iter: 1922 loss: 3.65773758e-07
Iter: 1923 loss: 3.65771541e-07
Iter: 1924 loss: 3.65714101e-07
Iter: 1925 loss: 3.65749599e-07
Iter: 1926 loss: 3.65642904e-07
Iter: 1927 loss: 3.65620224e-07
Iter: 1928 loss: 3.65568383e-07
Iter: 1929 loss: 3.6548937e-07
Iter: 1930 loss: 3.66060306e-07
Iter: 1931 loss: 3.6546183e-07
Iter: 1932 loss: 3.65429287e-07
Iter: 1933 loss: 3.65414621e-07
Iter: 1934 loss: 3.65436733e-07
Iter: 1935 loss: 3.65414337e-07
Iter: 1936 loss: 3.65407345e-07
Iter: 1937 loss: 3.65391486e-07
Iter: 1938 loss: 3.65401036e-07
Iter: 1939 loss: 3.65417804e-07
Iter: 1940 loss: 3.65404532e-07
Iter: 1941 loss: 3.65400695e-07
Iter: 1942 loss: 3.65428349e-07
Iter: 1943 loss: 3.65398137e-07
Iter: 1944 loss: 3.65401775e-07
Iter: 1945 loss: 3.65387535e-07
Iter: 1946 loss: 3.65401519e-07
Iter: 1947 loss: 3.65411495e-07
Iter: 1948 loss: 3.65416611e-07
Iter: 1949 loss: 3.6541482e-07
Iter: 1950 loss: 3.65420021e-07
Iter: 1951 loss: 3.65416554e-07
Iter: 1952 loss: 3.65416383e-07
Iter: 1953 loss: 3.65417293e-07
Iter: 1954 loss: 3.65415701e-07
Iter: 1955 loss: 3.65415701e-07
Iter: 1956 loss: 3.65414905e-07
Iter: 1957 loss: 3.65415701e-07
Iter: 1958 loss: 3.65414905e-07
Iter: 1959 loss: 3.65415701e-07
Iter: 1960 loss: 3.65240624e-07
Iter: 1961 loss: 3.66552285e-07
Iter: 1962 loss: 3.65264015e-07
Iter: 1963 loss: 3.65191198e-07
Iter: 1964 loss: 3.65384921e-07
Iter: 1965 loss: 3.65197195e-07
Iter: 1966 loss: 3.65125317e-07
Iter: 1967 loss: 3.65752953e-07
Iter: 1968 loss: 3.65128955e-07
Iter: 1969 loss: 3.65092e-07
Iter: 1970 loss: 3.65370767e-07
Iter: 1971 loss: 3.65037948e-07
Iter: 1972 loss: 3.65063812e-07
Iter: 1973 loss: 3.6505736e-07
Iter: 1974 loss: 3.65060316e-07
Iter: 1975 loss: 3.65045025e-07
Iter: 1976 loss: 3.65054888e-07
Iter: 1977 loss: 3.65046077e-07
Iter: 1978 loss: 3.65047811e-07
Iter: 1979 loss: 3.65042439e-07
Iter: 1980 loss: 3.65039398e-07
Iter: 1981 loss: 3.65057474e-07
Iter: 1982 loss: 3.6505196e-07
Iter: 1983 loss: 3.65038829e-07
Iter: 1984 loss: 3.65046731e-07
Iter: 1985 loss: 3.65039227e-07
Iter: 1986 loss: 3.65040535e-07
Iter: 1987 loss: 3.6503863e-07
Iter: 1988 loss: 3.65037863e-07
Iter: 1989 loss: 3.65037863e-07
Iter: 1990 loss: 3.65038687e-07
Iter: 1991 loss: 3.6503792e-07
Iter: 1992 loss: 3.65038e-07
Iter: 1993 loss: 3.65038062e-07
Iter: 1994 loss: 3.65038687e-07
Iter: 1995 loss: 3.65038687e-07
Iter: 1996 loss: 3.65038062e-07
Iter: 1997 loss: 3.65038687e-07
Iter: 1998 loss: 3.65038687e-07
Iter: 1999 loss: 3.65038062e-07
Iter: 2000 loss: 3.65038062e-07
Iter: 2001 loss: 3.65038062e-07
Iter: 2002 loss: 3.65038687e-07
Iter: 2003 loss: 3.65038062e-07
Iter: 2004 loss: 3.65038062e-07
Iter: 2005 loss: 3.65038687e-07
Iter: 2006 loss: 3.65038687e-07
Iter: 2007 loss: 3.65038687e-07
Iter: 2008 loss: 3.65038687e-07
Iter: 2009 loss: 3.65038687e-07
Iter: 2010 loss: 3.65038062e-07
Iter: 2011 loss: 3.65038687e-07
Iter: 2012 loss: 3.65038062e-07
Iter: 2013 loss: 3.65175168e-07
Iter: 2014 loss: 3.6505989e-07
Iter: 2015 loss: 3.65070633e-07
Iter: 2016 loss: 3.65037039e-07
Iter: 2017 loss: 3.65050681e-07
Iter: 2018 loss: 3.65036271e-07
Iter: 2019 loss: 3.65038943e-07
Iter: 2020 loss: 3.65040478e-07
Iter: 2021 loss: 3.65030587e-07
Iter: 2022 loss: 3.65037181e-07
Iter: 2023 loss: 3.65031951e-07
Iter: 2024 loss: 3.65034737e-07
Iter: 2025 loss: 3.65031042e-07
Iter: 2026 loss: 3.65036612e-07
Iter: 2027 loss: 3.65038261e-07
Iter: 2028 loss: 3.65039341e-07
Iter: 2029 loss: 3.65039028e-07
Iter: 2030 loss: 3.65037977e-07
Iter: 2031 loss: 3.65038829e-07
Iter: 2032 loss: 3.65039682e-07
Iter: 2033 loss: 3.65038261e-07
Iter: 2034 loss: 3.65038517e-07
Iter: 2035 loss: 3.65038517e-07
Iter: 2036 loss: 3.65038716e-07
Iter: 2037 loss: 3.65038716e-07
Iter: 2038 loss: 3.65038716e-07
Iter: 2039 loss: 3.65038261e-07
Iter: 2040 loss: 3.65038261e-07
Iter: 2041 loss: 3.65038716e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_4000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 0 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_4000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e20a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e2182f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e2dad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e2f17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e304268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e2e8c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e24f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e1c91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e1ddbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e18a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e12b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e142b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e106620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e1260d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e110ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e0df598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e095048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e08d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e040488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e052ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb557268950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb557279400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5571fee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5572378c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5571dc378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5571f0d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5571a5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5571492f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55715cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55711d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55e1f51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5570c9c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5570e9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55707f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55709ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb55704f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.66050642e-06
Iter: 2 loss: 2.0582047e-06
Iter: 3 loss: 1.49443031e-06
Iter: 4 loss: 1.29078194e-06
Iter: 5 loss: 1.11531335e-06
Iter: 6 loss: 1.06005336e-06
Iter: 7 loss: 9.46367948e-07
Iter: 8 loss: 1.19238882e-06
Iter: 9 loss: 9.02270926e-07
Iter: 10 loss: 8.2341171e-07
Iter: 11 loss: 8.18505669e-07
Iter: 12 loss: 8.00103351e-07
Iter: 13 loss: 8.05583454e-07
Iter: 14 loss: 7.86914256e-07
Iter: 15 loss: 7.8213327e-07
Iter: 16 loss: 7.8089397e-07
Iter: 17 loss: 7.7593387e-07
Iter: 18 loss: 7.67435267e-07
Iter: 19 loss: 7.67403e-07
Iter: 20 loss: 7.63825653e-07
Iter: 21 loss: 7.73872557e-07
Iter: 22 loss: 7.62675427e-07
Iter: 23 loss: 7.57835778e-07
Iter: 24 loss: 7.84408314e-07
Iter: 25 loss: 7.57116368e-07
Iter: 26 loss: 7.5362459e-07
Iter: 27 loss: 7.48932166e-07
Iter: 28 loss: 7.48663297e-07
Iter: 29 loss: 7.44644069e-07
Iter: 30 loss: 7.42568318e-07
Iter: 31 loss: 7.4068862e-07
Iter: 32 loss: 7.35041681e-07
Iter: 33 loss: 7.2810775e-07
Iter: 34 loss: 7.27472923e-07
Iter: 35 loss: 7.22118102e-07
Iter: 36 loss: 7.45109617e-07
Iter: 37 loss: 7.21008064e-07
Iter: 38 loss: 7.17274531e-07
Iter: 39 loss: 7.2274554e-07
Iter: 40 loss: 7.15448493e-07
Iter: 41 loss: 7.13383088e-07
Iter: 42 loss: 7.13347958e-07
Iter: 43 loss: 7.10622658e-07
Iter: 44 loss: 7.08633593e-07
Iter: 45 loss: 7.07701815e-07
Iter: 46 loss: 7.05328262e-07
Iter: 47 loss: 7.16447062e-07
Iter: 48 loss: 7.04843956e-07
Iter: 49 loss: 7.03977094e-07
Iter: 50 loss: 7.03863464e-07
Iter: 51 loss: 7.03053786e-07
Iter: 52 loss: 7.0079733e-07
Iter: 53 loss: 7.13917e-07
Iter: 54 loss: 7.00177281e-07
Iter: 55 loss: 6.98822419e-07
Iter: 56 loss: 6.98801614e-07
Iter: 57 loss: 6.98070664e-07
Iter: 58 loss: 6.98063e-07
Iter: 59 loss: 6.97543499e-07
Iter: 60 loss: 6.9584695e-07
Iter: 61 loss: 6.96313407e-07
Iter: 62 loss: 6.94219068e-07
Iter: 63 loss: 6.95556e-07
Iter: 64 loss: 6.92994377e-07
Iter: 65 loss: 6.92132403e-07
Iter: 66 loss: 6.89882199e-07
Iter: 67 loss: 7.08544235e-07
Iter: 68 loss: 6.89438821e-07
Iter: 69 loss: 6.87076522e-07
Iter: 70 loss: 6.948693e-07
Iter: 71 loss: 6.86383942e-07
Iter: 72 loss: 6.84998213e-07
Iter: 73 loss: 6.85721034e-07
Iter: 74 loss: 6.8408383e-07
Iter: 75 loss: 6.8559325e-07
Iter: 76 loss: 6.83675751e-07
Iter: 77 loss: 6.83392102e-07
Iter: 78 loss: 6.83231065e-07
Iter: 79 loss: 6.83052292e-07
Iter: 80 loss: 6.82627729e-07
Iter: 81 loss: 6.823999e-07
Iter: 82 loss: 6.82228517e-07
Iter: 83 loss: 6.8118203e-07
Iter: 84 loss: 6.84298129e-07
Iter: 85 loss: 6.80806295e-07
Iter: 86 loss: 6.8027714e-07
Iter: 87 loss: 6.80666e-07
Iter: 88 loss: 6.79927041e-07
Iter: 89 loss: 6.79383561e-07
Iter: 90 loss: 6.85015152e-07
Iter: 91 loss: 6.79371396e-07
Iter: 92 loss: 6.78822232e-07
Iter: 93 loss: 6.78140395e-07
Iter: 94 loss: 6.78110496e-07
Iter: 95 loss: 6.77594528e-07
Iter: 96 loss: 6.80598191e-07
Iter: 97 loss: 6.77531375e-07
Iter: 98 loss: 6.76790819e-07
Iter: 99 loss: 6.77015805e-07
Iter: 100 loss: 6.76257173e-07
Iter: 101 loss: 6.75587785e-07
Iter: 102 loss: 6.75261447e-07
Iter: 103 loss: 6.74962337e-07
Iter: 104 loss: 6.74019248e-07
Iter: 105 loss: 6.72461852e-07
Iter: 106 loss: 6.72444457e-07
Iter: 107 loss: 6.72573947e-07
Iter: 108 loss: 6.71845e-07
Iter: 109 loss: 6.7143219e-07
Iter: 110 loss: 6.76759328e-07
Iter: 111 loss: 6.71411271e-07
Iter: 112 loss: 6.71147291e-07
Iter: 113 loss: 6.70788e-07
Iter: 114 loss: 6.70774625e-07
Iter: 115 loss: 6.70702548e-07
Iter: 116 loss: 6.70607392e-07
Iter: 117 loss: 6.70501e-07
Iter: 118 loss: 6.70116663e-07
Iter: 119 loss: 6.71189468e-07
Iter: 120 loss: 6.69912652e-07
Iter: 121 loss: 6.69586143e-07
Iter: 122 loss: 6.69541e-07
Iter: 123 loss: 6.69256451e-07
Iter: 124 loss: 6.69443352e-07
Iter: 125 loss: 6.69057044e-07
Iter: 126 loss: 6.68730763e-07
Iter: 127 loss: 6.68306711e-07
Iter: 128 loss: 6.6829466e-07
Iter: 129 loss: 6.6804472e-07
Iter: 130 loss: 6.67918414e-07
Iter: 131 loss: 6.67733e-07
Iter: 132 loss: 6.67400172e-07
Iter: 133 loss: 6.74932721e-07
Iter: 134 loss: 6.67399888e-07
Iter: 135 loss: 6.66991355e-07
Iter: 136 loss: 6.66238748e-07
Iter: 137 loss: 6.82534051e-07
Iter: 138 loss: 6.66251935e-07
Iter: 139 loss: 6.65529456e-07
Iter: 140 loss: 6.72920351e-07
Iter: 141 loss: 6.65479263e-07
Iter: 142 loss: 6.65091648e-07
Iter: 143 loss: 6.65054756e-07
Iter: 144 loss: 6.64658103e-07
Iter: 145 loss: 6.64126219e-07
Iter: 146 loss: 6.64111326e-07
Iter: 147 loss: 6.63889523e-07
Iter: 148 loss: 6.6383609e-07
Iter: 149 loss: 6.63600417e-07
Iter: 150 loss: 6.63113951e-07
Iter: 151 loss: 6.74103944e-07
Iter: 152 loss: 6.63126173e-07
Iter: 153 loss: 6.62935179e-07
Iter: 154 loss: 6.62906814e-07
Iter: 155 loss: 6.62821094e-07
Iter: 156 loss: 6.62778803e-07
Iter: 157 loss: 6.62734749e-07
Iter: 158 loss: 6.62601565e-07
Iter: 159 loss: 6.6249163e-07
Iter: 160 loss: 6.62444677e-07
Iter: 161 loss: 6.62279717e-07
Iter: 162 loss: 6.62258344e-07
Iter: 163 loss: 6.62131e-07
Iter: 164 loss: 6.61836168e-07
Iter: 165 loss: 6.61843615e-07
Iter: 166 loss: 6.61490844e-07
Iter: 167 loss: 6.60591922e-07
Iter: 168 loss: 6.70911732e-07
Iter: 169 loss: 6.60556907e-07
Iter: 170 loss: 6.59590285e-07
Iter: 171 loss: 6.63664707e-07
Iter: 172 loss: 6.59402531e-07
Iter: 173 loss: 6.59312093e-07
Iter: 174 loss: 6.58949716e-07
Iter: 175 loss: 6.58591148e-07
Iter: 176 loss: 6.59571242e-07
Iter: 177 loss: 6.58490762e-07
Iter: 178 loss: 6.58326712e-07
Iter: 179 loss: 6.58393162e-07
Iter: 180 loss: 6.58224508e-07
Iter: 181 loss: 6.57901182e-07
Iter: 182 loss: 6.58458248e-07
Iter: 183 loss: 6.57792384e-07
Iter: 184 loss: 6.57576095e-07
Iter: 185 loss: 6.58477e-07
Iter: 186 loss: 6.57574105e-07
Iter: 187 loss: 6.57350938e-07
Iter: 188 loss: 6.57354121e-07
Iter: 189 loss: 6.57178532e-07
Iter: 190 loss: 6.56913e-07
Iter: 191 loss: 6.56973953e-07
Iter: 192 loss: 6.56697921e-07
Iter: 193 loss: 6.56497264e-07
Iter: 194 loss: 6.56524549e-07
Iter: 195 loss: 6.56301665e-07
Iter: 196 loss: 6.56466341e-07
Iter: 197 loss: 6.56206225e-07
Iter: 198 loss: 6.56022394e-07
Iter: 199 loss: 6.55690371e-07
Iter: 200 loss: 6.55704184e-07
Iter: 201 loss: 6.5539939e-07
Iter: 202 loss: 6.55068163e-07
Iter: 203 loss: 6.55021609e-07
Iter: 204 loss: 6.54404857e-07
Iter: 205 loss: 6.59651789e-07
Iter: 206 loss: 6.54378937e-07
Iter: 207 loss: 6.53929703e-07
Iter: 208 loss: 6.53903498e-07
Iter: 209 loss: 6.53604786e-07
Iter: 210 loss: 6.52751623e-07
Iter: 211 loss: 6.59333068e-07
Iter: 212 loss: 6.52583935e-07
Iter: 213 loss: 6.53233428e-07
Iter: 214 loss: 6.52273513e-07
Iter: 215 loss: 6.52162214e-07
Iter: 216 loss: 6.51855544e-07
Iter: 217 loss: 6.54856649e-07
Iter: 218 loss: 6.51832465e-07
Iter: 219 loss: 6.51508572e-07
Iter: 220 loss: 6.56097484e-07
Iter: 221 loss: 6.51494474e-07
Iter: 222 loss: 6.51356402e-07
Iter: 223 loss: 6.51414894e-07
Iter: 224 loss: 6.51263576e-07
Iter: 225 loss: 6.51140681e-07
Iter: 226 loss: 6.51685241e-07
Iter: 227 loss: 6.51124878e-07
Iter: 228 loss: 6.5096765e-07
Iter: 229 loss: 6.5124118e-07
Iter: 230 loss: 6.50884203e-07
Iter: 231 loss: 6.50642278e-07
Iter: 232 loss: 6.50145637e-07
Iter: 233 loss: 6.58760655e-07
Iter: 234 loss: 6.50154448e-07
Iter: 235 loss: 6.49672074e-07
Iter: 236 loss: 6.5024733e-07
Iter: 237 loss: 6.49409685e-07
Iter: 238 loss: 6.48845798e-07
Iter: 239 loss: 6.52558413e-07
Iter: 240 loss: 6.48781793e-07
Iter: 241 loss: 6.48493653e-07
Iter: 242 loss: 6.52131178e-07
Iter: 243 loss: 6.48477567e-07
Iter: 244 loss: 6.48103935e-07
Iter: 245 loss: 6.48546e-07
Iter: 246 loss: 6.4792448e-07
Iter: 247 loss: 6.47712397e-07
Iter: 248 loss: 6.47572108e-07
Iter: 249 loss: 6.47471097e-07
Iter: 250 loss: 6.46961098e-07
Iter: 251 loss: 6.49178e-07
Iter: 252 loss: 6.46821604e-07
Iter: 253 loss: 6.46501803e-07
Iter: 254 loss: 6.46317e-07
Iter: 255 loss: 6.46172566e-07
Iter: 256 loss: 6.46022102e-07
Iter: 257 loss: 6.45962359e-07
Iter: 258 loss: 6.45809223e-07
Iter: 259 loss: 6.45567411e-07
Iter: 260 loss: 6.45553e-07
Iter: 261 loss: 6.45437922e-07
Iter: 262 loss: 6.45399496e-07
Iter: 263 loss: 6.4529695e-07
Iter: 264 loss: 6.45228624e-07
Iter: 265 loss: 6.4520566e-07
Iter: 266 loss: 6.45056332e-07
Iter: 267 loss: 6.44794568e-07
Iter: 268 loss: 6.50807635e-07
Iter: 269 loss: 6.44779107e-07
Iter: 270 loss: 6.44505e-07
Iter: 271 loss: 6.44895067e-07
Iter: 272 loss: 6.4437188e-07
Iter: 273 loss: 6.43928331e-07
Iter: 274 loss: 6.42867292e-07
Iter: 275 loss: 6.57227361e-07
Iter: 276 loss: 6.42829036e-07
Iter: 277 loss: 6.4395573e-07
Iter: 278 loss: 6.42554937e-07
Iter: 279 loss: 6.42332111e-07
Iter: 280 loss: 6.42359e-07
Iter: 281 loss: 6.42167379e-07
Iter: 282 loss: 6.41927386e-07
Iter: 283 loss: 6.42964721e-07
Iter: 284 loss: 6.41877e-07
Iter: 285 loss: 6.41652036e-07
Iter: 286 loss: 6.41598547e-07
Iter: 287 loss: 6.41478209e-07
Iter: 288 loss: 6.41387e-07
Iter: 289 loss: 6.41369354e-07
Iter: 290 loss: 6.41258225e-07
Iter: 291 loss: 6.41033807e-07
Iter: 292 loss: 6.41020165e-07
Iter: 293 loss: 6.40822e-07
Iter: 294 loss: 6.41882309e-07
Iter: 295 loss: 6.40768349e-07
Iter: 296 loss: 6.40533699e-07
Iter: 297 loss: 6.41350653e-07
Iter: 298 loss: 6.40476401e-07
Iter: 299 loss: 6.40288306e-07
Iter: 300 loss: 6.39978168e-07
Iter: 301 loss: 6.39981067e-07
Iter: 302 loss: 6.39589871e-07
Iter: 303 loss: 6.40504368e-07
Iter: 304 loss: 6.39455436e-07
Iter: 305 loss: 6.39017799e-07
Iter: 306 loss: 6.40496523e-07
Iter: 307 loss: 6.38919801e-07
Iter: 308 loss: 6.38579309e-07
Iter: 309 loss: 6.39193843e-07
Iter: 310 loss: 6.38423444e-07
Iter: 311 loss: 6.37938456e-07
Iter: 312 loss: 6.41205e-07
Iter: 313 loss: 6.3787e-07
Iter: 314 loss: 6.37617632e-07
Iter: 315 loss: 6.38334598e-07
Iter: 316 loss: 6.37575e-07
Iter: 317 loss: 6.37253095e-07
Iter: 318 loss: 6.38021731e-07
Iter: 319 loss: 6.37132189e-07
Iter: 320 loss: 6.36903e-07
Iter: 321 loss: 6.36632819e-07
Iter: 322 loss: 6.36624691e-07
Iter: 323 loss: 6.36704158e-07
Iter: 324 loss: 6.36510151e-07
Iter: 325 loss: 6.36470759e-07
Iter: 326 loss: 6.36289656e-07
Iter: 327 loss: 6.37814196e-07
Iter: 328 loss: 6.36259301e-07
Iter: 329 loss: 6.36095081e-07
Iter: 330 loss: 6.36116397e-07
Iter: 331 loss: 6.35994184e-07
Iter: 332 loss: 6.35847e-07
Iter: 333 loss: 6.35817628e-07
Iter: 334 loss: 6.35622087e-07
Iter: 335 loss: 6.3533804e-07
Iter: 336 loss: 6.35369929e-07
Iter: 337 loss: 6.34917058e-07
Iter: 338 loss: 6.38019e-07
Iter: 339 loss: 6.34899948e-07
Iter: 340 loss: 6.34620733e-07
Iter: 341 loss: 6.34624143e-07
Iter: 342 loss: 6.34515118e-07
Iter: 343 loss: 6.3448681e-07
Iter: 344 loss: 6.34399044e-07
Iter: 345 loss: 6.34236812e-07
Iter: 346 loss: 6.34225898e-07
Iter: 347 loss: 6.3408595e-07
Iter: 348 loss: 6.33948616e-07
Iter: 349 loss: 6.33917068e-07
Iter: 350 loss: 6.33819639e-07
Iter: 351 loss: 6.33545369e-07
Iter: 352 loss: 6.36331549e-07
Iter: 353 loss: 6.33548552e-07
Iter: 354 loss: 6.33333912e-07
Iter: 355 loss: 6.33328341e-07
Iter: 356 loss: 6.33195896e-07
Iter: 357 loss: 6.32933165e-07
Iter: 358 loss: 6.32891158e-07
Iter: 359 loss: 6.32685442e-07
Iter: 360 loss: 6.33200784e-07
Iter: 361 loss: 6.32574427e-07
Iter: 362 loss: 6.32455283e-07
Iter: 363 loss: 6.3240509e-07
Iter: 364 loss: 6.32368824e-07
Iter: 365 loss: 6.32219098e-07
Iter: 366 loss: 6.33909849e-07
Iter: 367 loss: 6.32208867e-07
Iter: 368 loss: 6.3200838e-07
Iter: 369 loss: 6.32091428e-07
Iter: 370 loss: 6.31896683e-07
Iter: 371 loss: 6.31632815e-07
Iter: 372 loss: 6.32134117e-07
Iter: 373 loss: 6.31509295e-07
Iter: 374 loss: 6.31330352e-07
Iter: 375 loss: 6.34625792e-07
Iter: 376 loss: 6.31296189e-07
Iter: 377 loss: 6.31041701e-07
Iter: 378 loss: 6.3102874e-07
Iter: 379 loss: 6.3082166e-07
Iter: 380 loss: 6.30538693e-07
Iter: 381 loss: 6.30409772e-07
Iter: 382 loss: 6.30274371e-07
Iter: 383 loss: 6.30042166e-07
Iter: 384 loss: 6.33389845e-07
Iter: 385 loss: 6.30033e-07
Iter: 386 loss: 6.29856686e-07
Iter: 387 loss: 6.32035324e-07
Iter: 388 loss: 6.29871124e-07
Iter: 389 loss: 6.2981087e-07
Iter: 390 loss: 6.29651481e-07
Iter: 391 loss: 6.31827675e-07
Iter: 392 loss: 6.29649719e-07
Iter: 393 loss: 6.29514545e-07
Iter: 394 loss: 6.29840656e-07
Iter: 395 loss: 6.29414103e-07
Iter: 396 loss: 6.29152282e-07
Iter: 397 loss: 6.31037494e-07
Iter: 398 loss: 6.29113231e-07
Iter: 399 loss: 6.29010458e-07
Iter: 400 loss: 6.28770749e-07
Iter: 401 loss: 6.32482454e-07
Iter: 402 loss: 6.28773478e-07
Iter: 403 loss: 6.28706971e-07
Iter: 404 loss: 6.28637622e-07
Iter: 405 loss: 6.28541613e-07
Iter: 406 loss: 6.2839149e-07
Iter: 407 loss: 6.28364546e-07
Iter: 408 loss: 6.28221301e-07
Iter: 409 loss: 6.28766543e-07
Iter: 410 loss: 6.28174575e-07
Iter: 411 loss: 6.28180487e-07
Iter: 412 loss: 6.28084194e-07
Iter: 413 loss: 6.27988811e-07
Iter: 414 loss: 6.27837892e-07
Iter: 415 loss: 6.28394332e-07
Iter: 416 loss: 6.27732732e-07
Iter: 417 loss: 6.27405257e-07
Iter: 418 loss: 6.29016483e-07
Iter: 419 loss: 6.27361771e-07
Iter: 420 loss: 6.27141048e-07
Iter: 421 loss: 6.29649321e-07
Iter: 422 loss: 6.27141617e-07
Iter: 423 loss: 6.26915323e-07
Iter: 424 loss: 6.26469046e-07
Iter: 425 loss: 6.34894434e-07
Iter: 426 loss: 6.26475298e-07
Iter: 427 loss: 6.26185852e-07
Iter: 428 loss: 6.28834755e-07
Iter: 429 loss: 6.26136796e-07
Iter: 430 loss: 6.26091094e-07
Iter: 431 loss: 6.26028793e-07
Iter: 432 loss: 6.25969278e-07
Iter: 433 loss: 6.25760435e-07
Iter: 434 loss: 6.2651668e-07
Iter: 435 loss: 6.25643963e-07
Iter: 436 loss: 6.25443306e-07
Iter: 437 loss: 6.27080112e-07
Iter: 438 loss: 6.25408063e-07
Iter: 439 loss: 6.25266239e-07
Iter: 440 loss: 6.25268058e-07
Iter: 441 loss: 6.25150903e-07
Iter: 442 loss: 6.24837639e-07
Iter: 443 loss: 6.24737254e-07
Iter: 444 loss: 6.24472136e-07
Iter: 445 loss: 6.23895858e-07
Iter: 446 loss: 6.29387159e-07
Iter: 447 loss: 6.2388483e-07
Iter: 448 loss: 6.23551159e-07
Iter: 449 loss: 6.23531264e-07
Iter: 450 loss: 6.23354367e-07
Iter: 451 loss: 6.23110054e-07
Iter: 452 loss: 6.23079586e-07
Iter: 453 loss: 6.22950438e-07
Iter: 454 loss: 6.24601796e-07
Iter: 455 loss: 6.22969196e-07
Iter: 456 loss: 6.22809182e-07
Iter: 457 loss: 6.22913092e-07
Iter: 458 loss: 6.22711e-07
Iter: 459 loss: 6.22549692e-07
Iter: 460 loss: 6.22450557e-07
Iter: 461 loss: 6.22422647e-07
Iter: 462 loss: 6.22233529e-07
Iter: 463 loss: 6.23899552e-07
Iter: 464 loss: 6.22228072e-07
Iter: 465 loss: 6.22018945e-07
Iter: 466 loss: 6.22778373e-07
Iter: 467 loss: 6.21986715e-07
Iter: 468 loss: 6.21866207e-07
Iter: 469 loss: 6.215962e-07
Iter: 470 loss: 6.26685164e-07
Iter: 471 loss: 6.21575509e-07
Iter: 472 loss: 6.21494792e-07
Iter: 473 loss: 6.21416234e-07
Iter: 474 loss: 6.21289132e-07
Iter: 475 loss: 6.21415097e-07
Iter: 476 loss: 6.2119625e-07
Iter: 477 loss: 6.21096831e-07
Iter: 478 loss: 6.20881451e-07
Iter: 479 loss: 6.22823677e-07
Iter: 480 loss: 6.20855076e-07
Iter: 481 loss: 6.20695744e-07
Iter: 482 loss: 6.20676587e-07
Iter: 483 loss: 6.20527146e-07
Iter: 484 loss: 6.21029415e-07
Iter: 485 loss: 6.20465471e-07
Iter: 486 loss: 6.20341325e-07
Iter: 487 loss: 6.19939101e-07
Iter: 488 loss: 6.21807203e-07
Iter: 489 loss: 6.19787954e-07
Iter: 490 loss: 6.19422906e-07
Iter: 491 loss: 6.1934611e-07
Iter: 492 loss: 6.19196214e-07
Iter: 493 loss: 6.18723902e-07
Iter: 494 loss: 6.232749e-07
Iter: 495 loss: 6.18718445e-07
Iter: 496 loss: 6.18364311e-07
Iter: 497 loss: 6.1945417e-07
Iter: 498 loss: 6.18297e-07
Iter: 499 loss: 6.18195372e-07
Iter: 500 loss: 6.18200204e-07
Iter: 501 loss: 6.18120225e-07
Iter: 502 loss: 6.17969135e-07
Iter: 503 loss: 6.21095637e-07
Iter: 504 loss: 6.1798238e-07
Iter: 505 loss: 6.17790533e-07
Iter: 506 loss: 6.18250851e-07
Iter: 507 loss: 6.17735e-07
Iter: 508 loss: 6.17595106e-07
Iter: 509 loss: 6.17958619e-07
Iter: 510 loss: 6.17512285e-07
Iter: 511 loss: 6.17374894e-07
Iter: 512 loss: 6.17239039e-07
Iter: 513 loss: 6.17209821e-07
Iter: 514 loss: 6.16891953e-07
Iter: 515 loss: 6.18151091e-07
Iter: 516 loss: 6.16824707e-07
Iter: 517 loss: 6.16866828e-07
Iter: 518 loss: 6.16711418e-07
Iter: 519 loss: 6.1664025e-07
Iter: 520 loss: 6.16471482e-07
Iter: 521 loss: 6.18040076e-07
Iter: 522 loss: 6.16451302e-07
Iter: 523 loss: 6.16325394e-07
Iter: 524 loss: 6.16301065e-07
Iter: 525 loss: 6.16167767e-07
Iter: 526 loss: 6.15989734e-07
Iter: 527 loss: 6.15974727e-07
Iter: 528 loss: 6.15777481e-07
Iter: 529 loss: 6.15795216e-07
Iter: 530 loss: 6.15588249e-07
Iter: 531 loss: 6.15400154e-07
Iter: 532 loss: 6.15399472e-07
Iter: 533 loss: 6.15241788e-07
Iter: 534 loss: 6.15376962e-07
Iter: 535 loss: 6.15127647e-07
Iter: 536 loss: 6.1493688e-07
Iter: 537 loss: 6.15698696e-07
Iter: 538 loss: 6.1486918e-07
Iter: 539 loss: 6.1471178e-07
Iter: 540 loss: 6.15393674e-07
Iter: 541 loss: 6.14651185e-07
Iter: 542 loss: 6.14545229e-07
Iter: 543 loss: 6.14639418e-07
Iter: 544 loss: 6.14487362e-07
Iter: 545 loss: 6.14360602e-07
Iter: 546 loss: 6.14186717e-07
Iter: 547 loss: 6.1417154e-07
Iter: 548 loss: 6.14051316e-07
Iter: 549 loss: 6.1405035e-07
Iter: 550 loss: 6.13936095e-07
Iter: 551 loss: 6.14026135e-07
Iter: 552 loss: 6.13858447e-07
Iter: 553 loss: 6.13703492e-07
Iter: 554 loss: 6.1348976e-07
Iter: 555 loss: 6.13489e-07
Iter: 556 loss: 6.13422458e-07
Iter: 557 loss: 6.13321333e-07
Iter: 558 loss: 6.13268526e-07
Iter: 559 loss: 6.13082875e-07
Iter: 560 loss: 6.14264763e-07
Iter: 561 loss: 6.13017846e-07
Iter: 562 loss: 6.12739e-07
Iter: 563 loss: 6.13517e-07
Iter: 564 loss: 6.12682356e-07
Iter: 565 loss: 6.12706799e-07
Iter: 566 loss: 6.12619601e-07
Iter: 567 loss: 6.12548206e-07
Iter: 568 loss: 6.12409508e-07
Iter: 569 loss: 6.14029e-07
Iter: 570 loss: 6.12394e-07
Iter: 571 loss: 6.1232754e-07
Iter: 572 loss: 6.12286215e-07
Iter: 573 loss: 6.12248641e-07
Iter: 574 loss: 6.12210613e-07
Iter: 575 loss: 6.12209817e-07
Iter: 576 loss: 6.12106874e-07
Iter: 577 loss: 6.1196431e-07
Iter: 578 loss: 6.15363149e-07
Iter: 579 loss: 6.11977271e-07
Iter: 580 loss: 6.11779797e-07
Iter: 581 loss: 6.12983854e-07
Iter: 582 loss: 6.11765188e-07
Iter: 583 loss: 6.11718178e-07
Iter: 584 loss: 6.11718349e-07
Iter: 585 loss: 6.11640303e-07
Iter: 586 loss: 6.11435155e-07
Iter: 587 loss: 6.12006033e-07
Iter: 588 loss: 6.11392466e-07
Iter: 589 loss: 6.11404289e-07
Iter: 590 loss: 6.11264682e-07
Iter: 591 loss: 6.11174357e-07
Iter: 592 loss: 6.1105527e-07
Iter: 593 loss: 6.14148689e-07
Iter: 594 loss: 6.11077e-07
Iter: 595 loss: 6.10858365e-07
Iter: 596 loss: 6.1061985e-07
Iter: 597 loss: 6.10605639e-07
Iter: 598 loss: 6.10428856e-07
Iter: 599 loss: 6.10421239e-07
Iter: 600 loss: 6.10296411e-07
Iter: 601 loss: 6.10964776e-07
Iter: 602 loss: 6.1028652e-07
Iter: 603 loss: 6.10178859e-07
Iter: 604 loss: 6.09934091e-07
Iter: 605 loss: 6.14345481e-07
Iter: 606 loss: 6.0995535e-07
Iter: 607 loss: 6.09865197e-07
Iter: 608 loss: 6.09860308e-07
Iter: 609 loss: 6.09732e-07
Iter: 610 loss: 6.09868721e-07
Iter: 611 loss: 6.09675567e-07
Iter: 612 loss: 6.0962816e-07
Iter: 613 loss: 6.09587914e-07
Iter: 614 loss: 6.09560743e-07
Iter: 615 loss: 6.09440235e-07
Iter: 616 loss: 6.0980949e-07
Iter: 617 loss: 6.09419089e-07
Iter: 618 loss: 6.09237247e-07
Iter: 619 loss: 6.09270899e-07
Iter: 620 loss: 6.09123731e-07
Iter: 621 loss: 6.09030167e-07
Iter: 622 loss: 6.10011398e-07
Iter: 623 loss: 6.09031076e-07
Iter: 624 loss: 6.08936375e-07
Iter: 625 loss: 6.0876107e-07
Iter: 626 loss: 6.08776759e-07
Iter: 627 loss: 6.0859287e-07
Iter: 628 loss: 6.08699224e-07
Iter: 629 loss: 6.08435471e-07
Iter: 630 loss: 6.08251412e-07
Iter: 631 loss: 6.09348831e-07
Iter: 632 loss: 6.08230039e-07
Iter: 633 loss: 6.08089124e-07
Iter: 634 loss: 6.08775508e-07
Iter: 635 loss: 6.08046832e-07
Iter: 636 loss: 6.07881816e-07
Iter: 637 loss: 6.07854702e-07
Iter: 638 loss: 6.07751758e-07
Iter: 639 loss: 6.07573952e-07
Iter: 640 loss: 6.07577704e-07
Iter: 641 loss: 6.07446168e-07
Iter: 642 loss: 6.0732134e-07
Iter: 643 loss: 6.07285358e-07
Iter: 644 loss: 6.07177299e-07
Iter: 645 loss: 6.07045934e-07
Iter: 646 loss: 6.07002562e-07
Iter: 647 loss: 6.06923265e-07
Iter: 648 loss: 6.06963567e-07
Iter: 649 loss: 6.0681657e-07
Iter: 650 loss: 6.06770072e-07
Iter: 651 loss: 6.06723688e-07
Iter: 652 loss: 6.06678555e-07
Iter: 653 loss: 6.06559638e-07
Iter: 654 loss: 6.07246761e-07
Iter: 655 loss: 6.06528545e-07
Iter: 656 loss: 6.06379785e-07
Iter: 657 loss: 6.06361539e-07
Iter: 658 loss: 6.06228468e-07
Iter: 659 loss: 6.06108472e-07
Iter: 660 loss: 6.06061235e-07
Iter: 661 loss: 6.05881837e-07
Iter: 662 loss: 6.0568982e-07
Iter: 663 loss: 6.05677258e-07
Iter: 664 loss: 6.05585797e-07
Iter: 665 loss: 6.0546256e-07
Iter: 666 loss: 6.05266564e-07
Iter: 667 loss: 6.05665548e-07
Iter: 668 loss: 6.05183857e-07
Iter: 669 loss: 6.05080231e-07
Iter: 670 loss: 6.05036348e-07
Iter: 671 loss: 6.04984791e-07
Iter: 672 loss: 6.04842057e-07
Iter: 673 loss: 6.05618652e-07
Iter: 674 loss: 6.04828415e-07
Iter: 675 loss: 6.04698243e-07
Iter: 676 loss: 6.04918512e-07
Iter: 677 loss: 6.04656407e-07
Iter: 678 loss: 6.04522711e-07
Iter: 679 loss: 6.04490083e-07
Iter: 680 loss: 6.04434717e-07
Iter: 681 loss: 6.04345132e-07
Iter: 682 loss: 6.05785033e-07
Iter: 683 loss: 6.04331831e-07
Iter: 684 loss: 6.04229854e-07
Iter: 685 loss: 6.04401123e-07
Iter: 686 loss: 6.04180229e-07
Iter: 687 loss: 6.04085471e-07
Iter: 688 loss: 6.04029e-07
Iter: 689 loss: 6.04003787e-07
Iter: 690 loss: 6.03962292e-07
Iter: 691 loss: 6.0392324e-07
Iter: 692 loss: 6.03888907e-07
Iter: 693 loss: 6.03763056e-07
Iter: 694 loss: 6.04634693e-07
Iter: 695 loss: 6.03707463e-07
Iter: 696 loss: 6.03584e-07
Iter: 697 loss: 6.03946091e-07
Iter: 698 loss: 6.03568765e-07
Iter: 699 loss: 6.03391413e-07
Iter: 700 loss: 6.05077389e-07
Iter: 701 loss: 6.03418869e-07
Iter: 702 loss: 6.03245439e-07
Iter: 703 loss: 6.03092417e-07
Iter: 704 loss: 6.0305e-07
Iter: 705 loss: 6.02904663e-07
Iter: 706 loss: 6.04137654e-07
Iter: 707 loss: 6.02918135e-07
Iter: 708 loss: 6.02771365e-07
Iter: 709 loss: 6.02882665e-07
Iter: 710 loss: 6.02659441e-07
Iter: 711 loss: 6.02529e-07
Iter: 712 loss: 6.02679847e-07
Iter: 713 loss: 6.02450882e-07
Iter: 714 loss: 6.02329919e-07
Iter: 715 loss: 6.02721343e-07
Iter: 716 loss: 6.02296211e-07
Iter: 717 loss: 6.02195769e-07
Iter: 718 loss: 6.03417107e-07
Iter: 719 loss: 6.02203613e-07
Iter: 720 loss: 6.02115904e-07
Iter: 721 loss: 6.0199875e-07
Iter: 722 loss: 6.04103661e-07
Iter: 723 loss: 6.02019554e-07
Iter: 724 loss: 6.01922807e-07
Iter: 725 loss: 6.0193247e-07
Iter: 726 loss: 6.01842e-07
Iter: 727 loss: 6.01740851e-07
Iter: 728 loss: 6.01691909e-07
Iter: 729 loss: 6.01612e-07
Iter: 730 loss: 6.01634042e-07
Iter: 731 loss: 6.01548265e-07
Iter: 732 loss: 6.01424802e-07
Iter: 733 loss: 6.02050932e-07
Iter: 734 loss: 6.01397062e-07
Iter: 735 loss: 6.01350621e-07
Iter: 736 loss: 6.01324643e-07
Iter: 737 loss: 6.01281158e-07
Iter: 738 loss: 6.01236877e-07
Iter: 739 loss: 6.02486807e-07
Iter: 740 loss: 6.01227498e-07
Iter: 741 loss: 6.01101419e-07
Iter: 742 loss: 6.01595104e-07
Iter: 743 loss: 6.01089141e-07
Iter: 744 loss: 6.01002625e-07
Iter: 745 loss: 6.00927365e-07
Iter: 746 loss: 6.00904059e-07
Iter: 747 loss: 6.0077e-07
Iter: 748 loss: 6.00434532e-07
Iter: 749 loss: 6.07444122e-07
Iter: 750 loss: 6.0045204e-07
Iter: 751 loss: 6.00579256e-07
Iter: 752 loss: 6.00343526e-07
Iter: 753 loss: 6.00255476e-07
Iter: 754 loss: 6.00171e-07
Iter: 755 loss: 6.00130306e-07
Iter: 756 loss: 6.00063913e-07
Iter: 757 loss: 5.99846373e-07
Iter: 758 loss: 5.99846601e-07
Iter: 759 loss: 5.99896396e-07
Iter: 760 loss: 5.99793168e-07
Iter: 761 loss: 5.99727628e-07
Iter: 762 loss: 5.99718078e-07
Iter: 763 loss: 5.99654072e-07
Iter: 764 loss: 5.99597797e-07
Iter: 765 loss: 5.99521172e-07
Iter: 766 loss: 5.99503608e-07
Iter: 767 loss: 5.9937679e-07
Iter: 768 loss: 6.00083411e-07
Iter: 769 loss: 5.99354735e-07
Iter: 770 loss: 5.99203304e-07
Iter: 771 loss: 6.00212388e-07
Iter: 772 loss: 5.99202394e-07
Iter: 773 loss: 5.99125087e-07
Iter: 774 loss: 5.99111274e-07
Iter: 775 loss: 5.99032091e-07
Iter: 776 loss: 5.98945121e-07
Iter: 777 loss: 5.98964562e-07
Iter: 778 loss: 5.98925e-07
Iter: 779 loss: 5.98778115e-07
Iter: 780 loss: 5.98968313e-07
Iter: 781 loss: 5.9871e-07
Iter: 782 loss: 5.98570637e-07
Iter: 783 loss: 6.00646104e-07
Iter: 784 loss: 5.98578424e-07
Iter: 785 loss: 5.98486054e-07
Iter: 786 loss: 5.99213763e-07
Iter: 787 loss: 5.98462691e-07
Iter: 788 loss: 5.9836168e-07
Iter: 789 loss: 5.98226279e-07
Iter: 790 loss: 5.98204338e-07
Iter: 791 loss: 5.98110091e-07
Iter: 792 loss: 5.98420115e-07
Iter: 793 loss: 5.98065412e-07
Iter: 794 loss: 5.97984808e-07
Iter: 795 loss: 5.98457291e-07
Iter: 796 loss: 5.97978101e-07
Iter: 797 loss: 5.97931262e-07
Iter: 798 loss: 5.97882433e-07
Iter: 799 loss: 5.97842359e-07
Iter: 800 loss: 5.97805467e-07
Iter: 801 loss: 5.97705593e-07
Iter: 802 loss: 5.97710141e-07
Iter: 803 loss: 5.97623796e-07
Iter: 804 loss: 5.97620669e-07
Iter: 805 loss: 5.97543249e-07
Iter: 806 loss: 5.97920803e-07
Iter: 807 loss: 5.97525911e-07
Iter: 808 loss: 5.97472081e-07
Iter: 809 loss: 5.97380108e-07
Iter: 810 loss: 5.97372832e-07
Iter: 811 loss: 5.9714597e-07
Iter: 812 loss: 5.97497319e-07
Iter: 813 loss: 5.97078383e-07
Iter: 814 loss: 5.96993e-07
Iter: 815 loss: 5.96894949e-07
Iter: 816 loss: 5.96876419e-07
Iter: 817 loss: 5.96745508e-07
Iter: 818 loss: 5.97248743e-07
Iter: 819 loss: 5.96744655e-07
Iter: 820 loss: 5.96639438e-07
Iter: 821 loss: 5.96658708e-07
Iter: 822 loss: 5.96612381e-07
Iter: 823 loss: 5.96585323e-07
Iter: 824 loss: 5.96540644e-07
Iter: 825 loss: 5.964813e-07
Iter: 826 loss: 5.96454811e-07
Iter: 827 loss: 5.96418374e-07
Iter: 828 loss: 5.96307416e-07
Iter: 829 loss: 5.97743906e-07
Iter: 830 loss: 5.96304517e-07
Iter: 831 loss: 5.9620919e-07
Iter: 832 loss: 5.95989775e-07
Iter: 833 loss: 5.97561609e-07
Iter: 834 loss: 5.95966185e-07
Iter: 835 loss: 5.95803954e-07
Iter: 836 loss: 5.9700244e-07
Iter: 837 loss: 5.9577394e-07
Iter: 838 loss: 5.9566753e-07
Iter: 839 loss: 5.95663607e-07
Iter: 840 loss: 5.95581241e-07
Iter: 841 loss: 5.95602273e-07
Iter: 842 loss: 5.95545941e-07
Iter: 843 loss: 5.95442202e-07
Iter: 844 loss: 5.95462723e-07
Iter: 845 loss: 5.95412246e-07
Iter: 846 loss: 5.95236e-07
Iter: 847 loss: 5.96627274e-07
Iter: 848 loss: 5.95235235e-07
Iter: 849 loss: 5.95070787e-07
Iter: 850 loss: 5.95296569e-07
Iter: 851 loss: 5.95003939e-07
Iter: 852 loss: 5.94825565e-07
Iter: 853 loss: 5.94978928e-07
Iter: 854 loss: 5.94708581e-07
Iter: 855 loss: 5.94871381e-07
Iter: 856 loss: 5.94616722e-07
Iter: 857 loss: 5.94570906e-07
Iter: 858 loss: 5.94474557e-07
Iter: 859 loss: 5.94708e-07
Iter: 860 loss: 5.94424876e-07
Iter: 861 loss: 5.94305789e-07
Iter: 862 loss: 5.94300275e-07
Iter: 863 loss: 5.94179824e-07
Iter: 864 loss: 5.94883886e-07
Iter: 865 loss: 5.94168228e-07
Iter: 866 loss: 5.94107917e-07
Iter: 867 loss: 5.93980076e-07
Iter: 868 loss: 5.94265316e-07
Iter: 869 loss: 5.9387628e-07
Iter: 870 loss: 5.93872926e-07
Iter: 871 loss: 5.93748609e-07
Iter: 872 loss: 5.93641346e-07
Iter: 873 loss: 5.9401583e-07
Iter: 874 loss: 5.93614743e-07
Iter: 875 loss: 5.93487471e-07
Iter: 876 loss: 5.93448931e-07
Iter: 877 loss: 5.93428581e-07
Iter: 878 loss: 5.93234574e-07
Iter: 879 loss: 5.93865536e-07
Iter: 880 loss: 5.93178584e-07
Iter: 881 loss: 5.93111224e-07
Iter: 882 loss: 5.93082746e-07
Iter: 883 loss: 5.93026641e-07
Iter: 884 loss: 5.92888114e-07
Iter: 885 loss: 5.92726963e-07
Iter: 886 loss: 5.92702804e-07
Iter: 887 loss: 5.92639196e-07
Iter: 888 loss: 5.92609751e-07
Iter: 889 loss: 5.92482763e-07
Iter: 890 loss: 5.92613674e-07
Iter: 891 loss: 5.92394031e-07
Iter: 892 loss: 5.92269657e-07
Iter: 893 loss: 5.92139145e-07
Iter: 894 loss: 5.92105039e-07
Iter: 895 loss: 5.92098615e-07
Iter: 896 loss: 5.92049787e-07
Iter: 897 loss: 5.91986236e-07
Iter: 898 loss: 5.91915693e-07
Iter: 899 loss: 5.91891308e-07
Iter: 900 loss: 5.91865899e-07
Iter: 901 loss: 5.91900175e-07
Iter: 902 loss: 5.91806156e-07
Iter: 903 loss: 5.91721459e-07
Iter: 904 loss: 5.91492096e-07
Iter: 905 loss: 5.9531e-07
Iter: 906 loss: 5.91519154e-07
Iter: 907 loss: 5.91374032e-07
Iter: 908 loss: 5.91339585e-07
Iter: 909 loss: 5.91218509e-07
Iter: 910 loss: 5.91250853e-07
Iter: 911 loss: 5.91118351e-07
Iter: 912 loss: 5.9099284e-07
Iter: 913 loss: 5.90883701e-07
Iter: 914 loss: 5.90848913e-07
Iter: 915 loss: 5.90785703e-07
Iter: 916 loss: 5.90785476e-07
Iter: 917 loss: 5.90685147e-07
Iter: 918 loss: 5.90755803e-07
Iter: 919 loss: 5.90639161e-07
Iter: 920 loss: 5.90574132e-07
Iter: 921 loss: 5.90619265e-07
Iter: 922 loss: 5.90531e-07
Iter: 923 loss: 5.9041929e-07
Iter: 924 loss: 5.90736079e-07
Iter: 925 loss: 5.90432421e-07
Iter: 926 loss: 5.90364664e-07
Iter: 927 loss: 5.90424179e-07
Iter: 928 loss: 5.90361196e-07
Iter: 929 loss: 5.90270474e-07
Iter: 930 loss: 5.90697596e-07
Iter: 931 loss: 5.90280479e-07
Iter: 932 loss: 5.90226136e-07
Iter: 933 loss: 5.90129503e-07
Iter: 934 loss: 5.91233345e-07
Iter: 935 loss: 5.90105401e-07
Iter: 936 loss: 5.89973865e-07
Iter: 937 loss: 5.90317597e-07
Iter: 938 loss: 5.89931858e-07
Iter: 939 loss: 5.89903379e-07
Iter: 940 loss: 5.89906335e-07
Iter: 941 loss: 5.89829426e-07
Iter: 942 loss: 5.89941806e-07
Iter: 943 loss: 5.89783781e-07
Iter: 944 loss: 5.89757178e-07
Iter: 945 loss: 5.89648835e-07
Iter: 946 loss: 5.91085268e-07
Iter: 947 loss: 5.89643946e-07
Iter: 948 loss: 5.89515196e-07
Iter: 949 loss: 5.90789909e-07
Iter: 950 loss: 5.89528099e-07
Iter: 951 loss: 5.8938258e-07
Iter: 952 loss: 5.90069817e-07
Iter: 953 loss: 5.89377521e-07
Iter: 954 loss: 5.89305841e-07
Iter: 955 loss: 5.89126046e-07
Iter: 956 loss: 5.91331116e-07
Iter: 957 loss: 5.89103934e-07
Iter: 958 loss: 5.8903845e-07
Iter: 959 loss: 5.8895273e-07
Iter: 960 loss: 5.88955686e-07
Iter: 961 loss: 5.88984165e-07
Iter: 962 loss: 5.88984335e-07
Iter: 963 loss: 5.88950684e-07
Iter: 964 loss: 5.88967396e-07
Iter: 965 loss: 5.88970636e-07
Iter: 966 loss: 5.88964099e-07
Iter: 967 loss: 5.88968078e-07
Iter: 968 loss: 5.88963417e-07
Iter: 969 loss: 5.88965349e-07
Iter: 970 loss: 5.88956766e-07
Iter: 971 loss: 5.88962394e-07
Iter: 972 loss: 5.88952105e-07
Iter: 973 loss: 5.88953583e-07
Iter: 974 loss: 5.88954663e-07
Iter: 975 loss: 5.8895273e-07
Iter: 976 loss: 5.889558e-07
Iter: 977 loss: 5.88952048e-07
Iter: 978 loss: 5.88953299e-07
Iter: 979 loss: 5.88955572e-07
Iter: 980 loss: 5.88953071e-07
Iter: 981 loss: 5.88955459e-07
Iter: 982 loss: 5.88954947e-07
Iter: 983 loss: 5.88954492e-07
Iter: 984 loss: 5.88953071e-07
Iter: 985 loss: 5.88953e-07
Iter: 986 loss: 5.88954492e-07
Iter: 987 loss: 5.88953e-07
Iter: 988 loss: 5.88861326e-07
Iter: 989 loss: 5.88863372e-07
Iter: 990 loss: 5.88854448e-07
Iter: 991 loss: 5.88822559e-07
Iter: 992 loss: 5.88773673e-07
Iter: 993 loss: 5.88746161e-07
Iter: 994 loss: 5.88751675e-07
Iter: 995 loss: 5.88716034e-07
Iter: 996 loss: 5.88667319e-07
Iter: 997 loss: 5.8864606e-07
Iter: 998 loss: 5.88583362e-07
Iter: 999 loss: 5.8865885e-07
Iter: 1000 loss: 5.88568128e-07
Iter: 1001 loss: 5.88459443e-07
Iter: 1002 loss: 5.88860757e-07
Iter: 1003 loss: 5.88437047e-07
Iter: 1004 loss: 5.88397143e-07
Iter: 1005 loss: 5.88218029e-07
Iter: 1006 loss: 5.89869558e-07
Iter: 1007 loss: 5.88208536e-07
Iter: 1008 loss: 5.88122e-07
Iter: 1009 loss: 5.88115313e-07
Iter: 1010 loss: 5.88037608e-07
Iter: 1011 loss: 5.88199327e-07
Iter: 1012 loss: 5.87990144e-07
Iter: 1013 loss: 5.87975137e-07
Iter: 1014 loss: 5.88123271e-07
Iter: 1015 loss: 5.87952854e-07
Iter: 1016 loss: 5.87896636e-07
Iter: 1017 loss: 5.87832631e-07
Iter: 1018 loss: 5.87810405e-07
Iter: 1019 loss: 5.87723264e-07
Iter: 1020 loss: 5.8763078e-07
Iter: 1021 loss: 5.87613499e-07
Iter: 1022 loss: 5.87529485e-07
Iter: 1023 loss: 5.87540853e-07
Iter: 1024 loss: 5.87445e-07
Iter: 1025 loss: 5.88228829e-07
Iter: 1026 loss: 5.87424381e-07
Iter: 1027 loss: 5.8741449e-07
Iter: 1028 loss: 5.8731041e-07
Iter: 1029 loss: 5.87875661e-07
Iter: 1030 loss: 5.87254362e-07
Iter: 1031 loss: 5.8716472e-07
Iter: 1032 loss: 5.88244916e-07
Iter: 1033 loss: 5.87187174e-07
Iter: 1034 loss: 5.87161708e-07
Iter: 1035 loss: 5.87170405e-07
Iter: 1036 loss: 5.8711953e-07
Iter: 1037 loss: 5.87048e-07
Iter: 1038 loss: 5.87348495e-07
Iter: 1039 loss: 5.86995213e-07
Iter: 1040 loss: 5.86891588e-07
Iter: 1041 loss: 5.8772838e-07
Iter: 1042 loss: 5.86903468e-07
Iter: 1043 loss: 5.86807573e-07
Iter: 1044 loss: 5.87385614e-07
Iter: 1045 loss: 5.86759825e-07
Iter: 1046 loss: 5.86725378e-07
Iter: 1047 loss: 5.86946669e-07
Iter: 1048 loss: 5.86694227e-07
Iter: 1049 loss: 5.86640738e-07
Iter: 1050 loss: 5.86755277e-07
Iter: 1051 loss: 5.86585543e-07
Iter: 1052 loss: 5.86526653e-07
Iter: 1053 loss: 5.86459407e-07
Iter: 1054 loss: 5.86448891e-07
Iter: 1055 loss: 5.86329804e-07
Iter: 1056 loss: 5.86683882e-07
Iter: 1057 loss: 5.86307522e-07
Iter: 1058 loss: 5.86324575e-07
Iter: 1059 loss: 5.86270744e-07
Iter: 1060 loss: 5.862222e-07
Iter: 1061 loss: 5.86144324e-07
Iter: 1062 loss: 5.86774661e-07
Iter: 1063 loss: 5.86158649e-07
Iter: 1064 loss: 5.86034275e-07
Iter: 1065 loss: 5.86245108e-07
Iter: 1066 loss: 5.86028136e-07
Iter: 1067 loss: 5.85890916e-07
Iter: 1068 loss: 5.86084184e-07
Iter: 1069 loss: 5.85835323e-07
Iter: 1070 loss: 5.85834186e-07
Iter: 1071 loss: 5.85790076e-07
Iter: 1072 loss: 5.85727889e-07
Iter: 1073 loss: 5.85774046e-07
Iter: 1074 loss: 5.8571419e-07
Iter: 1075 loss: 5.85685427e-07
Iter: 1076 loss: 5.85691964e-07
Iter: 1077 loss: 5.85661724e-07
Iter: 1078 loss: 5.85569751e-07
Iter: 1079 loss: 5.85634211e-07
Iter: 1080 loss: 5.85520752e-07
Iter: 1081 loss: 5.85480905e-07
Iter: 1082 loss: 5.85474e-07
Iter: 1083 loss: 5.85443217e-07
Iter: 1084 loss: 5.85327598e-07
Iter: 1085 loss: 5.86507213e-07
Iter: 1086 loss: 5.85349085e-07
Iter: 1087 loss: 5.85216753e-07
Iter: 1088 loss: 5.85116766e-07
Iter: 1089 loss: 5.85104544e-07
Iter: 1090 loss: 5.84967665e-07
Iter: 1091 loss: 5.86571275e-07
Iter: 1092 loss: 5.84980853e-07
Iter: 1093 loss: 5.84892859e-07
Iter: 1094 loss: 5.85634439e-07
Iter: 1095 loss: 5.84887744e-07
Iter: 1096 loss: 5.84818906e-07
Iter: 1097 loss: 5.84741258e-07
Iter: 1098 loss: 5.84732561e-07
Iter: 1099 loss: 5.84649229e-07
Iter: 1100 loss: 5.84456586e-07
Iter: 1101 loss: 5.87368959e-07
Iter: 1102 loss: 5.84429358e-07
Iter: 1103 loss: 5.84339205e-07
Iter: 1104 loss: 5.84303621e-07
Iter: 1105 loss: 5.84242855e-07
Iter: 1106 loss: 5.85072712e-07
Iter: 1107 loss: 5.84230179e-07
Iter: 1108 loss: 5.84165775e-07
Iter: 1109 loss: 5.84047655e-07
Iter: 1110 loss: 5.84052e-07
Iter: 1111 loss: 5.84010479e-07
Iter: 1112 loss: 5.83997235e-07
Iter: 1113 loss: 5.83949827e-07
Iter: 1114 loss: 5.83885878e-07
Iter: 1115 loss: 5.83876727e-07
Iter: 1116 loss: 5.83837732e-07
Iter: 1117 loss: 5.84461645e-07
Iter: 1118 loss: 5.83824203e-07
Iter: 1119 loss: 5.8377509e-07
Iter: 1120 loss: 5.83717565e-07
Iter: 1121 loss: 5.85511202e-07
Iter: 1122 loss: 5.8370091e-07
Iter: 1123 loss: 5.83616099e-07
Iter: 1124 loss: 5.83816472e-07
Iter: 1125 loss: 5.83588189e-07
Iter: 1126 loss: 5.83505141e-07
Iter: 1127 loss: 5.84098814e-07
Iter: 1128 loss: 5.83523502e-07
Iter: 1129 loss: 5.83403448e-07
Iter: 1130 loss: 5.8343835e-07
Iter: 1131 loss: 5.83322958e-07
Iter: 1132 loss: 5.83295218e-07
Iter: 1133 loss: 5.83198471e-07
Iter: 1134 loss: 5.83216661e-07
Iter: 1135 loss: 5.83129577e-07
Iter: 1136 loss: 5.84118538e-07
Iter: 1137 loss: 5.83124915e-07
Iter: 1138 loss: 5.83086489e-07
Iter: 1139 loss: 5.83082965e-07
Iter: 1140 loss: 5.83045789e-07
Iter: 1141 loss: 5.82997359e-07
Iter: 1142 loss: 5.82984057e-07
Iter: 1143 loss: 5.82942789e-07
Iter: 1144 loss: 5.83200631e-07
Iter: 1145 loss: 5.82951e-07
Iter: 1146 loss: 5.82890891e-07
Iter: 1147 loss: 5.83003725e-07
Iter: 1148 loss: 5.82878727e-07
Iter: 1149 loss: 5.82789653e-07
Iter: 1150 loss: 5.82752136e-07
Iter: 1151 loss: 5.8273389e-07
Iter: 1152 loss: 5.82583652e-07
Iter: 1153 loss: 5.83061e-07
Iter: 1154 loss: 5.8253238e-07
Iter: 1155 loss: 5.82466498e-07
Iter: 1156 loss: 5.82420682e-07
Iter: 1157 loss: 5.82416192e-07
Iter: 1158 loss: 5.82370831e-07
Iter: 1159 loss: 5.82397718e-07
Iter: 1160 loss: 5.82347411e-07
Iter: 1161 loss: 5.82605367e-07
Iter: 1162 loss: 5.82340817e-07
Iter: 1163 loss: 5.82304835e-07
Iter: 1164 loss: 5.82266637e-07
Iter: 1165 loss: 5.83154474e-07
Iter: 1166 loss: 5.82309e-07
Iter: 1167 loss: 5.82237e-07
Iter: 1168 loss: 5.8237373e-07
Iter: 1169 loss: 5.82209623e-07
Iter: 1170 loss: 5.82162784e-07
Iter: 1171 loss: 5.82336156e-07
Iter: 1172 loss: 5.82167786e-07
Iter: 1173 loss: 5.82121459e-07
Iter: 1174 loss: 5.82146413e-07
Iter: 1175 loss: 5.8208127e-07
Iter: 1176 loss: 5.81987933e-07
Iter: 1177 loss: 5.82080531e-07
Iter: 1178 loss: 5.81956783e-07
Iter: 1179 loss: 5.81902157e-07
Iter: 1180 loss: 5.81885445e-07
Iter: 1181 loss: 5.81877543e-07
Iter: 1182 loss: 5.81796371e-07
Iter: 1183 loss: 5.82873668e-07
Iter: 1184 loss: 5.81772326e-07
Iter: 1185 loss: 5.81734753e-07
Iter: 1186 loss: 5.81736515e-07
Iter: 1187 loss: 5.81722645e-07
Iter: 1188 loss: 5.8163323e-07
Iter: 1189 loss: 5.81634254e-07
Iter: 1190 loss: 5.81594691e-07
Iter: 1191 loss: 5.81459517e-07
Iter: 1192 loss: 5.81459346e-07
Iter: 1193 loss: 5.81399718e-07
Iter: 1194 loss: 5.82008852e-07
Iter: 1195 loss: 5.81393465e-07
Iter: 1196 loss: 5.8132116e-07
Iter: 1197 loss: 5.81826953e-07
Iter: 1198 loss: 5.81323036e-07
Iter: 1199 loss: 5.81253062e-07
Iter: 1200 loss: 5.81220775e-07
Iter: 1201 loss: 5.81202187e-07
Iter: 1202 loss: 5.81144263e-07
Iter: 1203 loss: 5.81138522e-07
Iter: 1204 loss: 5.81129257e-07
Iter: 1205 loss: 5.81084691e-07
Iter: 1206 loss: 5.81051324e-07
Iter: 1207 loss: 5.81033305e-07
Iter: 1208 loss: 5.80993628e-07
Iter: 1209 loss: 5.80990957e-07
Iter: 1210 loss: 5.8091257e-07
Iter: 1211 loss: 5.80925303e-07
Iter: 1212 loss: 5.80875735e-07
Iter: 1213 loss: 5.80695428e-07
Iter: 1214 loss: 5.81134373e-07
Iter: 1215 loss: 5.80687e-07
Iter: 1216 loss: 5.80616529e-07
Iter: 1217 loss: 5.8095651e-07
Iter: 1218 loss: 5.80596634e-07
Iter: 1219 loss: 5.80497158e-07
Iter: 1220 loss: 5.80591177e-07
Iter: 1221 loss: 5.80471919e-07
Iter: 1222 loss: 5.80381084e-07
Iter: 1223 loss: 5.80274332e-07
Iter: 1224 loss: 5.80247729e-07
Iter: 1225 loss: 5.80171331e-07
Iter: 1226 loss: 5.81088329e-07
Iter: 1227 loss: 5.80199583e-07
Iter: 1228 loss: 5.80171218e-07
Iter: 1229 loss: 5.80562414e-07
Iter: 1230 loss: 5.80149162e-07
Iter: 1231 loss: 5.80132223e-07
Iter: 1232 loss: 5.80005121e-07
Iter: 1233 loss: 5.81410347e-07
Iter: 1234 loss: 5.80035589e-07
Iter: 1235 loss: 5.79958964e-07
Iter: 1236 loss: 5.80044912e-07
Iter: 1237 loss: 5.79888251e-07
Iter: 1238 loss: 5.79881487e-07
Iter: 1239 loss: 5.79878417e-07
Iter: 1240 loss: 5.79814127e-07
Iter: 1241 loss: 5.79756374e-07
Iter: 1242 loss: 5.79755238e-07
Iter: 1243 loss: 5.79694301e-07
Iter: 1244 loss: 5.79753305e-07
Iter: 1245 loss: 5.79632967e-07
Iter: 1246 loss: 5.79568109e-07
Iter: 1247 loss: 5.80504832e-07
Iter: 1248 loss: 5.79562823e-07
Iter: 1249 loss: 5.79557593e-07
Iter: 1250 loss: 5.79525874e-07
Iter: 1251 loss: 5.79490347e-07
Iter: 1252 loss: 5.79458799e-07
Iter: 1253 loss: 5.79471703e-07
Iter: 1254 loss: 5.79433333e-07
Iter: 1255 loss: 5.79361256e-07
Iter: 1256 loss: 5.79840275e-07
Iter: 1257 loss: 5.79320158e-07
Iter: 1258 loss: 5.79243533e-07
Iter: 1259 loss: 5.79606763e-07
Iter: 1260 loss: 5.79196e-07
Iter: 1261 loss: 5.79157245e-07
Iter: 1262 loss: 5.80143478e-07
Iter: 1263 loss: 5.79147127e-07
Iter: 1264 loss: 5.7904748e-07
Iter: 1265 loss: 5.79127686e-07
Iter: 1266 loss: 5.7904532e-07
Iter: 1267 loss: 5.78996378e-07
Iter: 1268 loss: 5.78937204e-07
Iter: 1269 loss: 5.78944e-07
Iter: 1270 loss: 5.78900085e-07
Iter: 1271 loss: 5.79200218e-07
Iter: 1272 loss: 5.78870811e-07
Iter: 1273 loss: 5.78814593e-07
Iter: 1274 loss: 5.79204197e-07
Iter: 1275 loss: 5.78834772e-07
Iter: 1276 loss: 5.78807317e-07
Iter: 1277 loss: 5.78720801e-07
Iter: 1278 loss: 5.79185553e-07
Iter: 1279 loss: 5.78727054e-07
Iter: 1280 loss: 5.78680101e-07
Iter: 1281 loss: 5.78676e-07
Iter: 1282 loss: 5.78634683e-07
Iter: 1283 loss: 5.78583411e-07
Iter: 1284 loss: 5.78544359e-07
Iter: 1285 loss: 5.78464778e-07
Iter: 1286 loss: 5.78908725e-07
Iter: 1287 loss: 5.78446e-07
Iter: 1288 loss: 5.784226e-07
Iter: 1289 loss: 5.78355753e-07
Iter: 1290 loss: 5.78301069e-07
Iter: 1291 loss: 5.78262359e-07
Iter: 1292 loss: 5.78305958e-07
Iter: 1293 loss: 5.78206311e-07
Iter: 1294 loss: 5.78137e-07
Iter: 1295 loss: 5.77989e-07
Iter: 1296 loss: 5.77994683e-07
Iter: 1297 loss: 5.78110757e-07
Iter: 1298 loss: 5.77968819e-07
Iter: 1299 loss: 5.77897879e-07
Iter: 1300 loss: 5.77805e-07
Iter: 1301 loss: 5.79414859e-07
Iter: 1302 loss: 5.77802e-07
Iter: 1303 loss: 5.77684602e-07
Iter: 1304 loss: 5.77978767e-07
Iter: 1305 loss: 5.77676474e-07
Iter: 1306 loss: 5.77535445e-07
Iter: 1307 loss: 5.77748779e-07
Iter: 1308 loss: 5.77515266e-07
Iter: 1309 loss: 5.77412607e-07
Iter: 1310 loss: 5.77763558e-07
Iter: 1311 loss: 5.77422952e-07
Iter: 1312 loss: 5.77379922e-07
Iter: 1313 loss: 5.77379069e-07
Iter: 1314 loss: 5.77346555e-07
Iter: 1315 loss: 5.77274477e-07
Iter: 1316 loss: 5.77263791e-07
Iter: 1317 loss: 5.77234573e-07
Iter: 1318 loss: 5.77220362e-07
Iter: 1319 loss: 5.77214166e-07
Iter: 1320 loss: 5.77113724e-07
Iter: 1321 loss: 5.77491903e-07
Iter: 1322 loss: 5.77101957e-07
Iter: 1323 loss: 5.77025446e-07
Iter: 1324 loss: 5.76968773e-07
Iter: 1325 loss: 5.76956495e-07
Iter: 1326 loss: 5.76814273e-07
Iter: 1327 loss: 5.76937282e-07
Iter: 1328 loss: 5.76738387e-07
Iter: 1329 loss: 5.76667958e-07
Iter: 1330 loss: 5.7794125e-07
Iter: 1331 loss: 5.76668413e-07
Iter: 1332 loss: 5.76609409e-07
Iter: 1333 loss: 5.7660759e-07
Iter: 1334 loss: 5.76564446e-07
Iter: 1335 loss: 5.76565071e-07
Iter: 1336 loss: 5.77020273e-07
Iter: 1337 loss: 5.76521302e-07
Iter: 1338 loss: 5.76534489e-07
Iter: 1339 loss: 5.76522098e-07
Iter: 1340 loss: 5.76518346e-07
Iter: 1341 loss: 5.76497087e-07
Iter: 1342 loss: 5.76454113e-07
Iter: 1343 loss: 5.77074104e-07
Iter: 1344 loss: 5.76473326e-07
Iter: 1345 loss: 5.76445359e-07
Iter: 1346 loss: 5.76439618e-07
Iter: 1347 loss: 5.76399088e-07
Iter: 1348 loss: 5.76356172e-07
Iter: 1349 loss: 5.76787386e-07
Iter: 1350 loss: 5.76365949e-07
Iter: 1351 loss: 5.76345258e-07
Iter: 1352 loss: 5.76303421e-07
Iter: 1353 loss: 5.76287221e-07
Iter: 1354 loss: 5.76235891e-07
Iter: 1355 loss: 5.76841899e-07
Iter: 1356 loss: 5.76259424e-07
Iter: 1357 loss: 5.76225773e-07
Iter: 1358 loss: 5.76292337e-07
Iter: 1359 loss: 5.76158584e-07
Iter: 1360 loss: 5.7614136e-07
Iter: 1361 loss: 5.76117486e-07
Iter: 1362 loss: 5.76082186e-07
Iter: 1363 loss: 5.76001639e-07
Iter: 1364 loss: 5.7605871e-07
Iter: 1365 loss: 5.75991464e-07
Iter: 1366 loss: 5.75897502e-07
Iter: 1367 loss: 5.75902618e-07
Iter: 1368 loss: 5.75831791e-07
Iter: 1369 loss: 5.75713273e-07
Iter: 1370 loss: 5.77424544e-07
Iter: 1371 loss: 5.75666377e-07
Iter: 1372 loss: 5.75560932e-07
Iter: 1373 loss: 5.76540799e-07
Iter: 1374 loss: 5.75593219e-07
Iter: 1375 loss: 5.75501076e-07
Iter: 1376 loss: 5.76394825e-07
Iter: 1377 loss: 5.75508e-07
Iter: 1378 loss: 5.75478e-07
Iter: 1379 loss: 5.75411036e-07
Iter: 1380 loss: 5.75412287e-07
Iter: 1381 loss: 5.75393415e-07
Iter: 1382 loss: 5.75357262e-07
Iter: 1383 loss: 5.75352601e-07
Iter: 1384 loss: 5.75301783e-07
Iter: 1385 loss: 5.75314914e-07
Iter: 1386 loss: 5.75293598e-07
Iter: 1387 loss: 5.75251931e-07
Iter: 1388 loss: 5.75240506e-07
Iter: 1389 loss: 5.75227261e-07
Iter: 1390 loss: 5.75228341e-07
Iter: 1391 loss: 5.75197475e-07
Iter: 1392 loss: 5.75154729e-07
Iter: 1393 loss: 5.75595323e-07
Iter: 1394 loss: 5.75156662e-07
Iter: 1395 loss: 5.75088734e-07
Iter: 1396 loss: 5.75007675e-07
Iter: 1397 loss: 5.75017e-07
Iter: 1398 loss: 5.74945773e-07
Iter: 1399 loss: 5.75552804e-07
Iter: 1400 loss: 5.74928606e-07
Iter: 1401 loss: 5.74877959e-07
Iter: 1402 loss: 5.75154e-07
Iter: 1403 loss: 5.74881767e-07
Iter: 1404 loss: 5.74819296e-07
Iter: 1405 loss: 5.74812816e-07
Iter: 1406 loss: 5.74803209e-07
Iter: 1407 loss: 5.74759042e-07
Iter: 1408 loss: 5.75115223e-07
Iter: 1409 loss: 5.74756029e-07
Iter: 1410 loss: 5.74709702e-07
Iter: 1411 loss: 5.74685316e-07
Iter: 1412 loss: 5.74663886e-07
Iter: 1413 loss: 5.74622163e-07
Iter: 1414 loss: 5.74824867e-07
Iter: 1415 loss: 5.74591695e-07
Iter: 1416 loss: 5.74553383e-07
Iter: 1417 loss: 5.74707542e-07
Iter: 1418 loss: 5.74528485e-07
Iter: 1419 loss: 5.74499666e-07
Iter: 1420 loss: 5.74526609e-07
Iter: 1421 loss: 5.74466526e-07
Iter: 1422 loss: 5.74443447e-07
Iter: 1423 loss: 5.74868295e-07
Iter: 1424 loss: 5.74446517e-07
Iter: 1425 loss: 5.74382625e-07
Iter: 1426 loss: 5.74445266e-07
Iter: 1427 loss: 5.74382284e-07
Iter: 1428 loss: 5.74358751e-07
Iter: 1429 loss: 5.74423098e-07
Iter: 1430 loss: 5.74367277e-07
Iter: 1431 loss: 5.74331068e-07
Iter: 1432 loss: 5.74357102e-07
Iter: 1433 loss: 5.74322e-07
Iter: 1434 loss: 5.74280307e-07
Iter: 1435 loss: 5.74308501e-07
Iter: 1436 loss: 5.74245405e-07
Iter: 1437 loss: 5.74192313e-07
Iter: 1438 loss: 5.74357102e-07
Iter: 1439 loss: 5.74192029e-07
Iter: 1440 loss: 5.74150874e-07
Iter: 1441 loss: 5.74267119e-07
Iter: 1442 loss: 5.74098294e-07
Iter: 1443 loss: 5.74071692e-07
Iter: 1444 loss: 5.74178e-07
Iter: 1445 loss: 5.74029968e-07
Iter: 1446 loss: 5.73983357e-07
Iter: 1447 loss: 5.74031674e-07
Iter: 1448 loss: 5.73972443e-07
Iter: 1449 loss: 5.73888883e-07
Iter: 1450 loss: 5.73910825e-07
Iter: 1451 loss: 5.73890247e-07
Iter: 1452 loss: 5.73844204e-07
Iter: 1453 loss: 5.74572368e-07
Iter: 1454 loss: 5.73848695e-07
Iter: 1455 loss: 5.7380646e-07
Iter: 1456 loss: 5.7381817e-07
Iter: 1457 loss: 5.73812258e-07
Iter: 1458 loss: 5.73869e-07
Iter: 1459 loss: 5.7378503e-07
Iter: 1460 loss: 5.73755415e-07
Iter: 1461 loss: 5.73716079e-07
Iter: 1462 loss: 5.74565092e-07
Iter: 1463 loss: 5.73723923e-07
Iter: 1464 loss: 5.73681859e-07
Iter: 1465 loss: 5.74084652e-07
Iter: 1466 loss: 5.73674072e-07
Iter: 1467 loss: 5.73646332e-07
Iter: 1468 loss: 5.73655086e-07
Iter: 1469 loss: 5.73616433e-07
Iter: 1470 loss: 5.73577097e-07
Iter: 1471 loss: 5.73686407e-07
Iter: 1472 loss: 5.73556065e-07
Iter: 1473 loss: 5.7347313e-07
Iter: 1474 loss: 5.73677369e-07
Iter: 1475 loss: 5.73495527e-07
Iter: 1476 loss: 5.7342487e-07
Iter: 1477 loss: 5.73654e-07
Iter: 1478 loss: 5.73430611e-07
Iter: 1479 loss: 5.73405373e-07
Iter: 1480 loss: 5.73421232e-07
Iter: 1481 loss: 5.7338e-07
Iter: 1482 loss: 5.73344153e-07
Iter: 1483 loss: 5.733595e-07
Iter: 1484 loss: 5.73352395e-07
Iter: 1485 loss: 5.73301577e-07
Iter: 1486 loss: 5.73300895e-07
Iter: 1487 loss: 5.73280886e-07
Iter: 1488 loss: 5.73556463e-07
Iter: 1489 loss: 5.73253828e-07
Iter: 1490 loss: 5.73259626e-07
Iter: 1491 loss: 5.73244051e-07
Iter: 1492 loss: 5.73240186e-07
Iter: 1493 loss: 5.73244847e-07
Iter: 1494 loss: 5.73253317e-07
Iter: 1495 loss: 5.73260593e-07
Iter: 1496 loss: 5.73248e-07
Iter: 1497 loss: 5.73261218e-07
Iter: 1498 loss: 5.73256273e-07
Iter: 1499 loss: 5.73237742e-07
Iter: 1500 loss: 5.73248371e-07
Iter: 1501 loss: 5.73238708e-07
Iter: 1502 loss: 5.73249281e-07
Iter: 1503 loss: 5.73250816e-07
Iter: 1504 loss: 5.73251896e-07
Iter: 1505 loss: 5.73245416e-07
Iter: 1506 loss: 5.73251782e-07
Iter: 1507 loss: 5.73255875e-07
Iter: 1508 loss: 5.7325127e-07
Iter: 1509 loss: 5.73254113e-07
Iter: 1510 loss: 5.73254624e-07
Iter: 1511 loss: 5.73253942e-07
Iter: 1512 loss: 5.73253885e-07
Iter: 1513 loss: 5.73254169e-07
Iter: 1514 loss: 5.73254169e-07
Iter: 1515 loss: 5.73254624e-07
Iter: 1516 loss: 5.73187208e-07
Iter: 1517 loss: 5.73300895e-07
Iter: 1518 loss: 5.73171178e-07
Iter: 1519 loss: 5.7312019e-07
Iter: 1520 loss: 5.73085458e-07
Iter: 1521 loss: 5.73088926e-07
Iter: 1522 loss: 5.73015484e-07
Iter: 1523 loss: 5.73024863e-07
Iter: 1524 loss: 5.73006901e-07
Iter: 1525 loss: 5.72959266e-07
Iter: 1526 loss: 5.72963586e-07
Iter: 1527 loss: 5.72914246e-07
Iter: 1528 loss: 5.7321364e-07
Iter: 1529 loss: 5.72899751e-07
Iter: 1530 loss: 5.72898557e-07
Iter: 1531 loss: 5.73055e-07
Iter: 1532 loss: 5.72873944e-07
Iter: 1533 loss: 5.72862518e-07
Iter: 1534 loss: 5.72841941e-07
Iter: 1535 loss: 5.72812951e-07
Iter: 1536 loss: 5.72788622e-07
Iter: 1537 loss: 5.72966428e-07
Iter: 1538 loss: 5.72786178e-07
Iter: 1539 loss: 5.72729277e-07
Iter: 1540 loss: 5.7273553e-07
Iter: 1541 loss: 5.72689942e-07
Iter: 1542 loss: 5.72645149e-07
Iter: 1543 loss: 5.72707449e-07
Iter: 1544 loss: 5.72613658e-07
Iter: 1545 loss: 5.72541808e-07
Iter: 1546 loss: 5.72508043e-07
Iter: 1547 loss: 5.72457907e-07
Iter: 1548 loss: 5.72398051e-07
Iter: 1549 loss: 5.72854447e-07
Iter: 1550 loss: 5.72388217e-07
Iter: 1551 loss: 5.7234206e-07
Iter: 1552 loss: 5.72552892e-07
Iter: 1553 loss: 5.72339445e-07
Iter: 1554 loss: 5.72278054e-07
Iter: 1555 loss: 5.72506565e-07
Iter: 1556 loss: 5.72256113e-07
Iter: 1557 loss: 5.72237241e-07
Iter: 1558 loss: 5.72232807e-07
Iter: 1559 loss: 5.72219108e-07
Iter: 1560 loss: 5.72158e-07
Iter: 1561 loss: 5.72357408e-07
Iter: 1562 loss: 5.72142255e-07
Iter: 1563 loss: 5.72084332e-07
Iter: 1564 loss: 5.72752e-07
Iter: 1565 loss: 5.72077965e-07
Iter: 1566 loss: 5.72000147e-07
Iter: 1567 loss: 5.72451256e-07
Iter: 1568 loss: 5.7198173e-07
Iter: 1569 loss: 5.71952739e-07
Iter: 1570 loss: 5.71836495e-07
Iter: 1571 loss: 5.73140255e-07
Iter: 1572 loss: 5.71828707e-07
Iter: 1573 loss: 5.71805231e-07
Iter: 1574 loss: 5.71755152e-07
Iter: 1575 loss: 5.71726332e-07
Iter: 1576 loss: 5.71719738e-07
Iter: 1577 loss: 5.71687337e-07
Iter: 1578 loss: 5.71676082e-07
Iter: 1579 loss: 5.71647831e-07
Iter: 1580 loss: 5.71647433e-07
Iter: 1581 loss: 5.71597354e-07
Iter: 1582 loss: 5.71614635e-07
Iter: 1583 loss: 5.7156177e-07
Iter: 1584 loss: 5.7148236e-07
Iter: 1585 loss: 5.71453086e-07
Iter: 1586 loss: 5.71425062e-07
Iter: 1587 loss: 5.71316036e-07
Iter: 1588 loss: 5.71862188e-07
Iter: 1589 loss: 5.71311546e-07
Iter: 1590 loss: 5.71233272e-07
Iter: 1591 loss: 5.71601277e-07
Iter: 1592 loss: 5.71213661e-07
Iter: 1593 loss: 5.71169835e-07
Iter: 1594 loss: 5.71502142e-07
Iter: 1595 loss: 5.71126066e-07
Iter: 1596 loss: 5.7110833e-07
Iter: 1597 loss: 5.71077521e-07
Iter: 1598 loss: 5.71066664e-07
Iter: 1599 loss: 5.71081841e-07
Iter: 1600 loss: 5.71029886e-07
Iter: 1601 loss: 5.71017665e-07
Iter: 1602 loss: 5.70958946e-07
Iter: 1603 loss: 5.71212126e-07
Iter: 1604 loss: 5.7098066e-07
Iter: 1605 loss: 5.70938369e-07
Iter: 1606 loss: 5.70932912e-07
Iter: 1607 loss: 5.70937686e-07
Iter: 1608 loss: 5.70912789e-07
Iter: 1609 loss: 5.70912221e-07
Iter: 1610 loss: 5.70907446e-07
Iter: 1611 loss: 5.70930411e-07
Iter: 1612 loss: 5.70922111e-07
Iter: 1613 loss: 5.70942e-07
Iter: 1614 loss: 5.70918587e-07
Iter: 1615 loss: 5.70938369e-07
Iter: 1616 loss: 5.70923305e-07
Iter: 1617 loss: 5.70937175e-07
Iter: 1618 loss: 5.70925636e-07
Iter: 1619 loss: 5.70933e-07
Iter: 1620 loss: 5.70938766e-07
Iter: 1621 loss: 5.70936038e-07
Iter: 1622 loss: 5.70934844e-07
Iter: 1623 loss: 5.70935526e-07
Iter: 1624 loss: 5.70932798e-07
Iter: 1625 loss: 5.70934844e-07
Iter: 1626 loss: 5.70934958e-07
Iter: 1627 loss: 5.70933366e-07
Iter: 1628 loss: 5.70933594e-07
Iter: 1629 loss: 5.70933594e-07
Iter: 1630 loss: 5.70933537e-07
Iter: 1631 loss: 5.70933366e-07
Iter: 1632 loss: 5.70933537e-07
Iter: 1633 loss: 5.7084344e-07
Iter: 1634 loss: 5.71293867e-07
Iter: 1635 loss: 5.70813313e-07
Iter: 1636 loss: 5.70755162e-07
Iter: 1637 loss: 5.70813e-07
Iter: 1638 loss: 5.7073845e-07
Iter: 1639 loss: 5.7064608e-07
Iter: 1640 loss: 5.71330247e-07
Iter: 1641 loss: 5.70648751e-07
Iter: 1642 loss: 5.70589634e-07
Iter: 1643 loss: 5.70544955e-07
Iter: 1644 loss: 5.71279486e-07
Iter: 1645 loss: 5.70524151e-07
Iter: 1646 loss: 5.70492489e-07
Iter: 1647 loss: 5.70715656e-07
Iter: 1648 loss: 5.70450936e-07
Iter: 1649 loss: 5.70464067e-07
Iter: 1650 loss: 5.70471457e-07
Iter: 1651 loss: 5.70451789e-07
Iter: 1652 loss: 5.7048328e-07
Iter: 1653 loss: 5.70458667e-07
Iter: 1654 loss: 5.70456677e-07
Iter: 1655 loss: 5.70457814e-07
Iter: 1656 loss: 5.70462532e-07
Iter: 1657 loss: 5.70465318e-07
Iter: 1658 loss: 5.70459576e-07
Iter: 1659 loss: 5.70471514e-07
Iter: 1660 loss: 5.70468842e-07
Iter: 1661 loss: 5.70458042e-07
Iter: 1662 loss: 5.7045213e-07
Iter: 1663 loss: 5.70452585e-07
Iter: 1664 loss: 5.70452471e-07
Iter: 1665 loss: 5.70450823e-07
Iter: 1666 loss: 5.70450823e-07
Iter: 1667 loss: 5.70451562e-07
Iter: 1668 loss: 5.70451277e-07
Iter: 1669 loss: 5.70452301e-07
Iter: 1670 loss: 5.70452528e-07
Iter: 1671 loss: 5.70452187e-07
Iter: 1672 loss: 5.70451277e-07
Iter: 1673 loss: 5.70451277e-07
Iter: 1674 loss: 5.70451391e-07
Iter: 1675 loss: 5.70451391e-07
Iter: 1676 loss: 5.70451334e-07
Iter: 1677 loss: 5.70451334e-07
Iter: 1678 loss: 5.70452187e-07
Iter: 1679 loss: 5.70452187e-07
Iter: 1680 loss: 5.70451334e-07
Iter: 1681 loss: 5.70452187e-07
Iter: 1682 loss: 5.70451334e-07
Iter: 1683 loss: 5.70452187e-07
Iter: 1684 loss: 5.70451334e-07
Iter: 1685 loss: 5.70452187e-07
Iter: 1686 loss: 5.70451334e-07
Iter: 1687 loss: 5.70452187e-07
Iter: 1688 loss: 5.70452187e-07
Iter: 1689 loss: 5.70451334e-07
Iter: 1690 loss: 5.71466444e-07
Iter: 1691 loss: 5.70481234e-07
Iter: 1692 loss: 5.70478733e-07
Iter: 1693 loss: 5.70461964e-07
Iter: 1694 loss: 5.70455313e-07
Iter: 1695 loss: 5.70477e-07
Iter: 1696 loss: 5.70466227e-07
Iter: 1697 loss: 5.70458269e-07
Iter: 1698 loss: 5.70468046e-07
Iter: 1699 loss: 5.7046941e-07
Iter: 1700 loss: 5.7045321e-07
Iter: 1701 loss: 5.70455768e-07
Iter: 1702 loss: 5.704552e-07
Iter: 1703 loss: 5.7045645e-07
Iter: 1704 loss: 5.70451903e-07
Iter: 1705 loss: 5.70454517e-07
Iter: 1706 loss: 5.70452642e-07
Iter: 1707 loss: 5.7045213e-07
Iter: 1708 loss: 5.70452e-07
Iter: 1709 loss: 5.7045213e-07
Iter: 1710 loss: 5.70452244e-07
Iter: 1711 loss: 5.70452e-07
Iter: 1712 loss: 5.70451903e-07
Iter: 1713 loss: 5.70451903e-07
Iter: 1714 loss: 5.70451959e-07
Iter: 1715 loss: 5.70451903e-07
Iter: 1716 loss: 5.70451903e-07
Iter: 1717 loss: 5.70451903e-07
Iter: 1718 loss: 5.70451903e-07
Iter: 1719 loss: 5.70451903e-07
Iter: 1720 loss: 5.70451959e-07
Iter: 1721 loss: 5.70451903e-07
Iter: 1722 loss: 5.70451959e-07
Iter: 1723 loss: 5.70451903e-07
Iter: 1724 loss: 5.70451903e-07
Iter: 1725 loss: 5.70451903e-07
Iter: 1726 loss: 5.70451903e-07
Iter: 1727 loss: 5.70451959e-07
Iter: 1728 loss: 5.70451903e-07
Iter: 1729 loss: 5.70451959e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 0 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0_8000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd568c0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd5697f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd56963d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd65b1a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd568cf268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd568d8c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd56872730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd5684e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd56875bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd568256a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd567ee158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd567dbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd567a0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd567b80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd567b7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd5676d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd56739048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd567299d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd56701488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd566dcea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd566ad950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd566bc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd56653e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd566298c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd56628378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd56615d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd565ca840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd565ad2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd565a2d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd565547b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd5656d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd5653dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd5653f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd564f01e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd564e1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd564c66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.66112829e-06
Iter: 2 loss: 1.99949932e-06
Iter: 3 loss: 1.4909956e-06
Iter: 4 loss: 1.28215743e-06
Iter: 5 loss: 1.15080366e-06
Iter: 6 loss: 1.06790571e-06
Iter: 7 loss: 9.5239011e-07
Iter: 8 loss: 1.01649186e-06
Iter: 9 loss: 8.76853051e-07
Iter: 10 loss: 8.6364247e-07
Iter: 11 loss: 8.14232067e-07
Iter: 12 loss: 7.98575684e-07
Iter: 13 loss: 7.96084123e-07
Iter: 14 loss: 7.85264206e-07
Iter: 15 loss: 7.77884452e-07
Iter: 16 loss: 8.22242782e-07
Iter: 17 loss: 7.76961656e-07
Iter: 18 loss: 7.69392841e-07
Iter: 19 loss: 8.18241745e-07
Iter: 20 loss: 7.68576683e-07
Iter: 21 loss: 7.66920721e-07
Iter: 22 loss: 7.625747e-07
Iter: 23 loss: 7.93556922e-07
Iter: 24 loss: 7.61630815e-07
Iter: 25 loss: 7.5691031e-07
Iter: 26 loss: 7.5690167e-07
Iter: 27 loss: 7.53559107e-07
Iter: 28 loss: 7.55886049e-07
Iter: 29 loss: 7.51480911e-07
Iter: 30 loss: 7.48214e-07
Iter: 31 loss: 7.46064757e-07
Iter: 32 loss: 7.44815736e-07
Iter: 33 loss: 7.40309e-07
Iter: 34 loss: 7.30305e-07
Iter: 35 loss: 8.72097075e-07
Iter: 36 loss: 7.29788553e-07
Iter: 37 loss: 7.23976314e-07
Iter: 38 loss: 8.03259354e-07
Iter: 39 loss: 7.23957214e-07
Iter: 40 loss: 7.20487151e-07
Iter: 41 loss: 7.39915e-07
Iter: 42 loss: 7.19991533e-07
Iter: 43 loss: 7.18894455e-07
Iter: 44 loss: 7.18808e-07
Iter: 45 loss: 7.17377588e-07
Iter: 46 loss: 7.14585e-07
Iter: 47 loss: 7.71357463e-07
Iter: 48 loss: 7.14566e-07
Iter: 49 loss: 7.12292433e-07
Iter: 50 loss: 7.24913775e-07
Iter: 51 loss: 7.11964958e-07
Iter: 52 loss: 7.11473149e-07
Iter: 53 loss: 7.11238044e-07
Iter: 54 loss: 7.10519032e-07
Iter: 55 loss: 7.08398034e-07
Iter: 56 loss: 7.16172849e-07
Iter: 57 loss: 7.07474953e-07
Iter: 58 loss: 7.07304309e-07
Iter: 59 loss: 7.06753212e-07
Iter: 60 loss: 7.05984235e-07
Iter: 61 loss: 7.06216497e-07
Iter: 62 loss: 7.05462469e-07
Iter: 63 loss: 7.04666604e-07
Iter: 64 loss: 7.08866082e-07
Iter: 65 loss: 7.0454422e-07
Iter: 66 loss: 7.03533033e-07
Iter: 67 loss: 7.02469265e-07
Iter: 68 loss: 7.02306181e-07
Iter: 69 loss: 7.00815121e-07
Iter: 70 loss: 6.97551798e-07
Iter: 71 loss: 7.45005195e-07
Iter: 72 loss: 6.97409575e-07
Iter: 73 loss: 6.95967572e-07
Iter: 74 loss: 6.957236e-07
Iter: 75 loss: 6.94757489e-07
Iter: 76 loss: 6.97182941e-07
Iter: 77 loss: 6.94420351e-07
Iter: 78 loss: 6.9349187e-07
Iter: 79 loss: 7.0850092e-07
Iter: 80 loss: 6.93468905e-07
Iter: 81 loss: 6.93249831e-07
Iter: 82 loss: 6.92679919e-07
Iter: 83 loss: 7.00185808e-07
Iter: 84 loss: 6.92662866e-07
Iter: 85 loss: 6.91872458e-07
Iter: 86 loss: 6.94007326e-07
Iter: 87 loss: 6.9162212e-07
Iter: 88 loss: 6.91111097e-07
Iter: 89 loss: 6.91037542e-07
Iter: 90 loss: 6.90751449e-07
Iter: 91 loss: 6.89936e-07
Iter: 92 loss: 6.92070898e-07
Iter: 93 loss: 6.89439275e-07
Iter: 94 loss: 6.89147669e-07
Iter: 95 loss: 6.88972e-07
Iter: 96 loss: 6.88552234e-07
Iter: 97 loss: 6.91152763e-07
Iter: 98 loss: 6.88540297e-07
Iter: 99 loss: 6.8825625e-07
Iter: 100 loss: 6.87541501e-07
Iter: 101 loss: 6.9257419e-07
Iter: 102 loss: 6.87379838e-07
Iter: 103 loss: 6.8719e-07
Iter: 104 loss: 6.86867736e-07
Iter: 105 loss: 6.86687372e-07
Iter: 106 loss: 6.86114277e-07
Iter: 107 loss: 6.87274451e-07
Iter: 108 loss: 6.85766395e-07
Iter: 109 loss: 6.84590646e-07
Iter: 110 loss: 6.86676799e-07
Iter: 111 loss: 6.84069846e-07
Iter: 112 loss: 6.8343229e-07
Iter: 113 loss: 6.88441e-07
Iter: 114 loss: 6.83417056e-07
Iter: 115 loss: 6.83087535e-07
Iter: 116 loss: 6.83057294e-07
Iter: 117 loss: 6.82876816e-07
Iter: 118 loss: 6.82621135e-07
Iter: 119 loss: 6.82620112e-07
Iter: 120 loss: 6.82324071e-07
Iter: 121 loss: 6.82302755e-07
Iter: 122 loss: 6.82084192e-07
Iter: 123 loss: 6.81664403e-07
Iter: 124 loss: 6.81657809e-07
Iter: 125 loss: 6.81473807e-07
Iter: 126 loss: 6.81222218e-07
Iter: 127 loss: 6.81216306e-07
Iter: 128 loss: 6.80697212e-07
Iter: 129 loss: 6.80983874e-07
Iter: 130 loss: 6.80330572e-07
Iter: 131 loss: 6.7999008e-07
Iter: 132 loss: 6.79970185e-07
Iter: 133 loss: 6.79488494e-07
Iter: 134 loss: 6.79804032e-07
Iter: 135 loss: 6.79203652e-07
Iter: 136 loss: 6.78899823e-07
Iter: 137 loss: 6.78865206e-07
Iter: 138 loss: 6.78621404e-07
Iter: 139 loss: 6.78314677e-07
Iter: 140 loss: 6.78324739e-07
Iter: 141 loss: 6.77970775e-07
Iter: 142 loss: 6.77269497e-07
Iter: 143 loss: 6.89284263e-07
Iter: 144 loss: 6.77243634e-07
Iter: 145 loss: 6.76858406e-07
Iter: 146 loss: 6.78396418e-07
Iter: 147 loss: 6.7673767e-07
Iter: 148 loss: 6.76354659e-07
Iter: 149 loss: 6.7770867e-07
Iter: 150 loss: 6.76258765e-07
Iter: 151 loss: 6.75940271e-07
Iter: 152 loss: 6.75964e-07
Iter: 153 loss: 6.75884735e-07
Iter: 154 loss: 6.75739784e-07
Iter: 155 loss: 6.76644845e-07
Iter: 156 loss: 6.75723811e-07
Iter: 157 loss: 6.7545966e-07
Iter: 158 loss: 6.7596045e-07
Iter: 159 loss: 6.75368938e-07
Iter: 160 loss: 6.75385536e-07
Iter: 161 loss: 6.75269689e-07
Iter: 162 loss: 6.75168394e-07
Iter: 163 loss: 6.74852345e-07
Iter: 164 loss: 6.7502333e-07
Iter: 165 loss: 6.74591661e-07
Iter: 166 loss: 6.74215812e-07
Iter: 167 loss: 6.74223543e-07
Iter: 168 loss: 6.73971442e-07
Iter: 169 loss: 6.73970476e-07
Iter: 170 loss: 6.73793e-07
Iter: 171 loss: 6.73244358e-07
Iter: 172 loss: 6.75477622e-07
Iter: 173 loss: 6.73052e-07
Iter: 174 loss: 6.72699741e-07
Iter: 175 loss: 6.77848107e-07
Iter: 176 loss: 6.72706562e-07
Iter: 177 loss: 6.72311899e-07
Iter: 178 loss: 6.7366841e-07
Iter: 179 loss: 6.72217197e-07
Iter: 180 loss: 6.71945031e-07
Iter: 181 loss: 6.71788882e-07
Iter: 182 loss: 6.71644443e-07
Iter: 183 loss: 6.71469252e-07
Iter: 184 loss: 6.72009946e-07
Iter: 185 loss: 6.71393309e-07
Iter: 186 loss: 6.7128974e-07
Iter: 187 loss: 6.7125967e-07
Iter: 188 loss: 6.71201633e-07
Iter: 189 loss: 6.71102839e-07
Iter: 190 loss: 6.71103862e-07
Iter: 191 loss: 6.70957149e-07
Iter: 192 loss: 6.70704765e-07
Iter: 193 loss: 6.70711358e-07
Iter: 194 loss: 6.70572661e-07
Iter: 195 loss: 6.70499787e-07
Iter: 196 loss: 6.70389909e-07
Iter: 197 loss: 6.7006124e-07
Iter: 198 loss: 6.71272e-07
Iter: 199 loss: 6.69917199e-07
Iter: 200 loss: 6.69231667e-07
Iter: 201 loss: 6.6887452e-07
Iter: 202 loss: 6.68544885e-07
Iter: 203 loss: 6.69490419e-07
Iter: 204 loss: 6.68366283e-07
Iter: 205 loss: 6.68228324e-07
Iter: 206 loss: 6.67833717e-07
Iter: 207 loss: 6.72268357e-07
Iter: 208 loss: 6.677991e-07
Iter: 209 loss: 6.67484528e-07
Iter: 210 loss: 6.68639814e-07
Iter: 211 loss: 6.67379709e-07
Iter: 212 loss: 6.67257723e-07
Iter: 213 loss: 6.67244421e-07
Iter: 214 loss: 6.67065e-07
Iter: 215 loss: 6.66670303e-07
Iter: 216 loss: 6.70836585e-07
Iter: 217 loss: 6.66639266e-07
Iter: 218 loss: 6.66356868e-07
Iter: 219 loss: 6.66989536e-07
Iter: 220 loss: 6.6628138e-07
Iter: 221 loss: 6.66053438e-07
Iter: 222 loss: 6.66041387e-07
Iter: 223 loss: 6.6580867e-07
Iter: 224 loss: 6.66040592e-07
Iter: 225 loss: 6.65678328e-07
Iter: 226 loss: 6.65593575e-07
Iter: 227 loss: 6.65614607e-07
Iter: 228 loss: 6.65536675e-07
Iter: 229 loss: 6.65407242e-07
Iter: 230 loss: 6.66711628e-07
Iter: 231 loss: 6.65403149e-07
Iter: 232 loss: 6.65276673e-07
Iter: 233 loss: 6.65008656e-07
Iter: 234 loss: 6.6928925e-07
Iter: 235 loss: 6.65008e-07
Iter: 236 loss: 6.64744277e-07
Iter: 237 loss: 6.64284357e-07
Iter: 238 loss: 6.64269578e-07
Iter: 239 loss: 6.63876733e-07
Iter: 240 loss: 6.70204372e-07
Iter: 241 loss: 6.63868036e-07
Iter: 242 loss: 6.63651747e-07
Iter: 243 loss: 6.63637593e-07
Iter: 244 loss: 6.63509695e-07
Iter: 245 loss: 6.63213882e-07
Iter: 246 loss: 6.67677568e-07
Iter: 247 loss: 6.63200694e-07
Iter: 248 loss: 6.63193077e-07
Iter: 249 loss: 6.63132084e-07
Iter: 250 loss: 6.63082915e-07
Iter: 251 loss: 6.62878335e-07
Iter: 252 loss: 6.63926471e-07
Iter: 253 loss: 6.6279739e-07
Iter: 254 loss: 6.62526645e-07
Iter: 255 loss: 6.63408343e-07
Iter: 256 loss: 6.62452067e-07
Iter: 257 loss: 6.62455136e-07
Iter: 258 loss: 6.62342586e-07
Iter: 259 loss: 6.62271134e-07
Iter: 260 loss: 6.6208554e-07
Iter: 261 loss: 6.64112349e-07
Iter: 262 loss: 6.62073262e-07
Iter: 263 loss: 6.61882609e-07
Iter: 264 loss: 6.6384672e-07
Iter: 265 loss: 6.61867148e-07
Iter: 266 loss: 6.61751528e-07
Iter: 267 loss: 6.62629702e-07
Iter: 268 loss: 6.61755791e-07
Iter: 269 loss: 6.61675188e-07
Iter: 270 loss: 6.615046e-07
Iter: 271 loss: 6.63332514e-07
Iter: 272 loss: 6.61480954e-07
Iter: 273 loss: 6.61236641e-07
Iter: 274 loss: 6.62401533e-07
Iter: 275 loss: 6.61203217e-07
Iter: 276 loss: 6.61003526e-07
Iter: 277 loss: 6.61380398e-07
Iter: 278 loss: 6.60932301e-07
Iter: 279 loss: 6.60568389e-07
Iter: 280 loss: 6.60931846e-07
Iter: 281 loss: 6.6036921e-07
Iter: 282 loss: 6.60089199e-07
Iter: 283 loss: 6.60426736e-07
Iter: 284 loss: 6.59929128e-07
Iter: 285 loss: 6.59844659e-07
Iter: 286 loss: 6.59782359e-07
Iter: 287 loss: 6.59692375e-07
Iter: 288 loss: 6.59428338e-07
Iter: 289 loss: 6.60690318e-07
Iter: 290 loss: 6.59366606e-07
Iter: 291 loss: 6.59200396e-07
Iter: 292 loss: 6.60392402e-07
Iter: 293 loss: 6.59185389e-07
Iter: 294 loss: 6.59090517e-07
Iter: 295 loss: 6.59084776e-07
Iter: 296 loss: 6.58986608e-07
Iter: 297 loss: 6.58948636e-07
Iter: 298 loss: 6.58911404e-07
Iter: 299 loss: 6.58831198e-07
Iter: 300 loss: 6.59851e-07
Iter: 301 loss: 6.58802946e-07
Iter: 302 loss: 6.58706313e-07
Iter: 303 loss: 6.5842346e-07
Iter: 304 loss: 6.59650425e-07
Iter: 305 loss: 6.58299257e-07
Iter: 306 loss: 6.58055853e-07
Iter: 307 loss: 6.59551688e-07
Iter: 308 loss: 6.58017939e-07
Iter: 309 loss: 6.57744295e-07
Iter: 310 loss: 6.58416411e-07
Iter: 311 loss: 6.57664032e-07
Iter: 312 loss: 6.57431e-07
Iter: 313 loss: 6.57440637e-07
Iter: 314 loss: 6.57316207e-07
Iter: 315 loss: 6.57059388e-07
Iter: 316 loss: 6.57050464e-07
Iter: 317 loss: 6.56860777e-07
Iter: 318 loss: 6.60220906e-07
Iter: 319 loss: 6.56855264e-07
Iter: 320 loss: 6.56609473e-07
Iter: 321 loss: 6.56542397e-07
Iter: 322 loss: 6.56400459e-07
Iter: 323 loss: 6.56254542e-07
Iter: 324 loss: 6.56191162e-07
Iter: 325 loss: 6.56127e-07
Iter: 326 loss: 6.55937299e-07
Iter: 327 loss: 6.58132763e-07
Iter: 328 loss: 6.55942245e-07
Iter: 329 loss: 6.55863118e-07
Iter: 330 loss: 6.5585732e-07
Iter: 331 loss: 6.5580025e-07
Iter: 332 loss: 6.55682e-07
Iter: 333 loss: 6.55680253e-07
Iter: 334 loss: 6.55594135e-07
Iter: 335 loss: 6.55586177e-07
Iter: 336 loss: 6.55492613e-07
Iter: 337 loss: 6.55241195e-07
Iter: 338 loss: 6.5640063e-07
Iter: 339 loss: 6.55097949e-07
Iter: 340 loss: 6.54890755e-07
Iter: 341 loss: 6.58134411e-07
Iter: 342 loss: 6.54863697e-07
Iter: 343 loss: 6.5466304e-07
Iter: 344 loss: 6.55274334e-07
Iter: 345 loss: 6.54619839e-07
Iter: 346 loss: 6.5436052e-07
Iter: 347 loss: 6.54452947e-07
Iter: 348 loss: 6.54152473e-07
Iter: 349 loss: 6.54036739e-07
Iter: 350 loss: 6.54866085e-07
Iter: 351 loss: 6.54019686e-07
Iter: 352 loss: 6.53902703e-07
Iter: 353 loss: 6.55267854e-07
Iter: 354 loss: 6.53906341e-07
Iter: 355 loss: 6.53834832e-07
Iter: 356 loss: 6.5361121e-07
Iter: 357 loss: 6.54406676e-07
Iter: 358 loss: 6.53506959e-07
Iter: 359 loss: 6.53245934e-07
Iter: 360 loss: 6.53704944e-07
Iter: 361 loss: 6.53151233e-07
Iter: 362 loss: 6.53098937e-07
Iter: 363 loss: 6.53020777e-07
Iter: 364 loss: 6.52943584e-07
Iter: 365 loss: 6.53695565e-07
Iter: 366 loss: 6.52934773e-07
Iter: 367 loss: 6.52878896e-07
Iter: 368 loss: 6.52821711e-07
Iter: 369 loss: 6.52837457e-07
Iter: 370 loss: 6.52700066e-07
Iter: 371 loss: 6.5294762e-07
Iter: 372 loss: 6.52630206e-07
Iter: 373 loss: 6.52555968e-07
Iter: 374 loss: 6.5245348e-07
Iter: 375 loss: 6.5245888e-07
Iter: 376 loss: 6.52284541e-07
Iter: 377 loss: 6.53394068e-07
Iter: 378 loss: 6.5225413e-07
Iter: 379 loss: 6.52074561e-07
Iter: 380 loss: 6.52743779e-07
Iter: 381 loss: 6.52038693e-07
Iter: 382 loss: 6.51899938e-07
Iter: 383 loss: 6.51687515e-07
Iter: 384 loss: 6.51692403e-07
Iter: 385 loss: 6.51482424e-07
Iter: 386 loss: 6.51482537e-07
Iter: 387 loss: 6.51344294e-07
Iter: 388 loss: 6.51329174e-07
Iter: 389 loss: 6.51208666e-07
Iter: 390 loss: 6.5112954e-07
Iter: 391 loss: 6.50918594e-07
Iter: 392 loss: 6.54468295e-07
Iter: 393 loss: 6.50908419e-07
Iter: 394 loss: 6.50680875e-07
Iter: 395 loss: 6.52397205e-07
Iter: 396 loss: 6.50627953e-07
Iter: 397 loss: 6.504e-07
Iter: 398 loss: 6.50571963e-07
Iter: 399 loss: 6.50265918e-07
Iter: 400 loss: 6.50283255e-07
Iter: 401 loss: 6.50140862e-07
Iter: 402 loss: 6.5005645e-07
Iter: 403 loss: 6.49919571e-07
Iter: 404 loss: 6.51156256e-07
Iter: 405 loss: 6.4987745e-07
Iter: 406 loss: 6.49877734e-07
Iter: 407 loss: 6.49812137e-07
Iter: 408 loss: 6.49758078e-07
Iter: 409 loss: 6.4966332e-07
Iter: 410 loss: 6.49667527e-07
Iter: 411 loss: 6.49581921e-07
Iter: 412 loss: 6.49894e-07
Iter: 413 loss: 6.49592437e-07
Iter: 414 loss: 6.49445553e-07
Iter: 415 loss: 6.49332549e-07
Iter: 416 loss: 6.49287472e-07
Iter: 417 loss: 6.49191747e-07
Iter: 418 loss: 6.49187655e-07
Iter: 419 loss: 6.49087e-07
Iter: 420 loss: 6.48882349e-07
Iter: 421 loss: 6.50488801e-07
Iter: 422 loss: 6.48833691e-07
Iter: 423 loss: 6.48441528e-07
Iter: 424 loss: 6.48948514e-07
Iter: 425 loss: 6.48259572e-07
Iter: 426 loss: 6.48025889e-07
Iter: 427 loss: 6.51099356e-07
Iter: 428 loss: 6.48019238e-07
Iter: 429 loss: 6.47923798e-07
Iter: 430 loss: 6.48488822e-07
Iter: 431 loss: 6.47894069e-07
Iter: 432 loss: 6.47819718e-07
Iter: 433 loss: 6.48033733e-07
Iter: 434 loss: 6.47796e-07
Iter: 435 loss: 6.47695344e-07
Iter: 436 loss: 6.47696879e-07
Iter: 437 loss: 6.47653621e-07
Iter: 438 loss: 6.47538684e-07
Iter: 439 loss: 6.4986466e-07
Iter: 440 loss: 6.4755e-07
Iter: 441 loss: 6.4748582e-07
Iter: 442 loss: 6.47492868e-07
Iter: 443 loss: 6.47418403e-07
Iter: 444 loss: 6.47336265e-07
Iter: 445 loss: 6.47307445e-07
Iter: 446 loss: 6.47237243e-07
Iter: 447 loss: 6.47691593e-07
Iter: 448 loss: 6.47232071e-07
Iter: 449 loss: 6.47132765e-07
Iter: 450 loss: 6.47406466e-07
Iter: 451 loss: 6.47129241e-07
Iter: 452 loss: 6.47058528e-07
Iter: 453 loss: 6.4696917e-07
Iter: 454 loss: 6.46938304e-07
Iter: 455 loss: 6.46869e-07
Iter: 456 loss: 6.48040896e-07
Iter: 457 loss: 6.46879414e-07
Iter: 458 loss: 6.46760896e-07
Iter: 459 loss: 6.46527155e-07
Iter: 460 loss: 6.4966e-07
Iter: 461 loss: 6.46535227e-07
Iter: 462 loss: 6.46287162e-07
Iter: 463 loss: 6.46916476e-07
Iter: 464 loss: 6.46208036e-07
Iter: 465 loss: 6.45931e-07
Iter: 466 loss: 6.46032561e-07
Iter: 467 loss: 6.45755165e-07
Iter: 468 loss: 6.45772843e-07
Iter: 469 loss: 6.45639432e-07
Iter: 470 loss: 6.45532396e-07
Iter: 471 loss: 6.45602e-07
Iter: 472 loss: 6.45472596e-07
Iter: 473 loss: 6.45379032e-07
Iter: 474 loss: 6.45233797e-07
Iter: 475 loss: 6.4523266e-07
Iter: 476 loss: 6.45101409e-07
Iter: 477 loss: 6.46122771e-07
Iter: 478 loss: 6.45088903e-07
Iter: 479 loss: 6.44913371e-07
Iter: 480 loss: 6.45039052e-07
Iter: 481 loss: 6.44788827e-07
Iter: 482 loss: 6.44679233e-07
Iter: 483 loss: 6.44865963e-07
Iter: 484 loss: 6.44595957e-07
Iter: 485 loss: 6.44533429e-07
Iter: 486 loss: 6.44512511e-07
Iter: 487 loss: 6.44464194e-07
Iter: 488 loss: 6.44315264e-07
Iter: 489 loss: 6.44695376e-07
Iter: 490 loss: 6.44236707e-07
Iter: 491 loss: 6.44307761e-07
Iter: 492 loss: 6.44171223e-07
Iter: 493 loss: 6.44105512e-07
Iter: 494 loss: 6.43982276e-07
Iter: 495 loss: 6.45974296e-07
Iter: 496 loss: 6.43968519e-07
Iter: 497 loss: 6.43831868e-07
Iter: 498 loss: 6.43874444e-07
Iter: 499 loss: 6.43717499e-07
Iter: 500 loss: 6.43563794e-07
Iter: 501 loss: 6.4373711e-07
Iter: 502 loss: 6.43470514e-07
Iter: 503 loss: 6.43410658e-07
Iter: 504 loss: 6.43357e-07
Iter: 505 loss: 6.43290775e-07
Iter: 506 loss: 6.43167e-07
Iter: 507 loss: 6.43171e-07
Iter: 508 loss: 6.43082103e-07
Iter: 509 loss: 6.43289695e-07
Iter: 510 loss: 6.43019291e-07
Iter: 511 loss: 6.42948805e-07
Iter: 512 loss: 6.42992177e-07
Iter: 513 loss: 6.42887812e-07
Iter: 514 loss: 6.42789132e-07
Iter: 515 loss: 6.42789132e-07
Iter: 516 loss: 6.42738655e-07
Iter: 517 loss: 6.42538453e-07
Iter: 518 loss: 6.42803286e-07
Iter: 519 loss: 6.42434543e-07
Iter: 520 loss: 6.42367411e-07
Iter: 521 loss: 6.42364171e-07
Iter: 522 loss: 6.42230134e-07
Iter: 523 loss: 6.42139355e-07
Iter: 524 loss: 6.42118607e-07
Iter: 525 loss: 6.41950464e-07
Iter: 526 loss: 6.42062e-07
Iter: 527 loss: 6.41853092e-07
Iter: 528 loss: 6.41843314e-07
Iter: 529 loss: 6.41802387e-07
Iter: 530 loss: 6.41775046e-07
Iter: 531 loss: 6.41657437e-07
Iter: 532 loss: 6.42516966e-07
Iter: 533 loss: 6.41637371e-07
Iter: 534 loss: 6.41545853e-07
Iter: 535 loss: 6.41935912e-07
Iter: 536 loss: 6.4150646e-07
Iter: 537 loss: 6.41459337e-07
Iter: 538 loss: 6.42077566e-07
Iter: 539 loss: 6.41443194e-07
Iter: 540 loss: 6.41396e-07
Iter: 541 loss: 6.41431029e-07
Iter: 542 loss: 6.41344513e-07
Iter: 543 loss: 6.41303e-07
Iter: 544 loss: 6.41480312e-07
Iter: 545 loss: 6.41293639e-07
Iter: 546 loss: 6.41231281e-07
Iter: 547 loss: 6.41263398e-07
Iter: 548 loss: 6.41217071e-07
Iter: 549 loss: 6.41146642e-07
Iter: 550 loss: 6.41081044e-07
Iter: 551 loss: 6.41056943e-07
Iter: 552 loss: 6.40985604e-07
Iter: 553 loss: 6.40896246e-07
Iter: 554 loss: 6.40872202e-07
Iter: 555 loss: 6.40756127e-07
Iter: 556 loss: 6.40740041e-07
Iter: 557 loss: 6.40648466e-07
Iter: 558 loss: 6.40870098e-07
Iter: 559 loss: 6.40609471e-07
Iter: 560 loss: 6.40524547e-07
Iter: 561 loss: 6.40344297e-07
Iter: 562 loss: 6.42535952e-07
Iter: 563 loss: 6.40330882e-07
Iter: 564 loss: 6.40390681e-07
Iter: 565 loss: 6.40261078e-07
Iter: 566 loss: 6.40203439e-07
Iter: 567 loss: 6.4012869e-07
Iter: 568 loss: 6.40137159e-07
Iter: 569 loss: 6.40036546e-07
Iter: 570 loss: 6.39902737e-07
Iter: 571 loss: 6.3987909e-07
Iter: 572 loss: 6.39917062e-07
Iter: 573 loss: 6.39838447e-07
Iter: 574 loss: 6.39786e-07
Iter: 575 loss: 6.39767e-07
Iter: 576 loss: 6.39759492e-07
Iter: 577 loss: 6.39694e-07
Iter: 578 loss: 6.39919165e-07
Iter: 579 loss: 6.39671157e-07
Iter: 580 loss: 6.39632162e-07
Iter: 581 loss: 6.39830773e-07
Iter: 582 loss: 6.39598284e-07
Iter: 583 loss: 6.39560426e-07
Iter: 584 loss: 6.39486757e-07
Iter: 585 loss: 6.40634539e-07
Iter: 586 loss: 6.39467544e-07
Iter: 587 loss: 6.39391487e-07
Iter: 588 loss: 6.40491294e-07
Iter: 589 loss: 6.3938694e-07
Iter: 590 loss: 6.39314919e-07
Iter: 591 loss: 6.39314806e-07
Iter: 592 loss: 6.39297753e-07
Iter: 593 loss: 6.39172185e-07
Iter: 594 loss: 6.39995619e-07
Iter: 595 loss: 6.39152745e-07
Iter: 596 loss: 6.39083623e-07
Iter: 597 loss: 6.40369194e-07
Iter: 598 loss: 6.39079587e-07
Iter: 599 loss: 6.3901274e-07
Iter: 600 loss: 6.39669565e-07
Iter: 601 loss: 6.39004384e-07
Iter: 602 loss: 6.38978804e-07
Iter: 603 loss: 6.38873701e-07
Iter: 604 loss: 6.39276664e-07
Iter: 605 loss: 6.38836752e-07
Iter: 606 loss: 6.38631832e-07
Iter: 607 loss: 6.39269103e-07
Iter: 608 loss: 6.38571805e-07
Iter: 609 loss: 6.38555662e-07
Iter: 610 loss: 6.38473523e-07
Iter: 611 loss: 6.38460619e-07
Iter: 612 loss: 6.38400195e-07
Iter: 613 loss: 6.3838911e-07
Iter: 614 loss: 6.38293955e-07
Iter: 615 loss: 6.390095e-07
Iter: 616 loss: 6.38284519e-07
Iter: 617 loss: 6.38238589e-07
Iter: 618 loss: 6.38110578e-07
Iter: 619 loss: 6.38118763e-07
Iter: 620 loss: 6.38040547e-07
Iter: 621 loss: 6.37992457e-07
Iter: 622 loss: 6.37954258e-07
Iter: 623 loss: 6.38033271e-07
Iter: 624 loss: 6.37917424e-07
Iter: 625 loss: 6.37869675e-07
Iter: 626 loss: 6.37887069e-07
Iter: 627 loss: 6.3786365e-07
Iter: 628 loss: 6.37812036e-07
Iter: 629 loss: 6.3778964e-07
Iter: 630 loss: 6.37777362e-07
Iter: 631 loss: 6.37765254e-07
Iter: 632 loss: 6.37724611e-07
Iter: 633 loss: 6.37725066e-07
Iter: 634 loss: 6.37683684e-07
Iter: 635 loss: 6.37693e-07
Iter: 636 loss: 6.37648213e-07
Iter: 637 loss: 6.37538733e-07
Iter: 638 loss: 6.38033271e-07
Iter: 639 loss: 6.37518383e-07
Iter: 640 loss: 6.37376274e-07
Iter: 641 loss: 6.37384346e-07
Iter: 642 loss: 6.3729874e-07
Iter: 643 loss: 6.37300047e-07
Iter: 644 loss: 6.37233484e-07
Iter: 645 loss: 6.37135031e-07
Iter: 646 loss: 6.37104108e-07
Iter: 647 loss: 6.37049368e-07
Iter: 648 loss: 6.36891286e-07
Iter: 649 loss: 6.38751771e-07
Iter: 650 loss: 6.36899642e-07
Iter: 651 loss: 6.36843424e-07
Iter: 652 loss: 6.36811819e-07
Iter: 653 loss: 6.36786e-07
Iter: 654 loss: 6.36714617e-07
Iter: 655 loss: 6.36868208e-07
Iter: 656 loss: 6.36693244e-07
Iter: 657 loss: 6.3661389e-07
Iter: 658 loss: 6.36731556e-07
Iter: 659 loss: 6.36593597e-07
Iter: 660 loss: 6.36542154e-07
Iter: 661 loss: 6.36518848e-07
Iter: 662 loss: 6.36487925e-07
Iter: 663 loss: 6.36415393e-07
Iter: 664 loss: 6.36327741e-07
Iter: 665 loss: 6.36310915e-07
Iter: 666 loss: 6.36193931e-07
Iter: 667 loss: 6.36261e-07
Iter: 668 loss: 6.36130892e-07
Iter: 669 loss: 6.36051368e-07
Iter: 670 loss: 6.3658706e-07
Iter: 671 loss: 6.36033747e-07
Iter: 672 loss: 6.35999413e-07
Iter: 673 loss: 6.35984e-07
Iter: 674 loss: 6.35927563e-07
Iter: 675 loss: 6.35870492e-07
Iter: 676 loss: 6.35885044e-07
Iter: 677 loss: 6.35777781e-07
Iter: 678 loss: 6.3609059e-07
Iter: 679 loss: 6.35771244e-07
Iter: 680 loss: 6.35751519e-07
Iter: 681 loss: 6.35743618e-07
Iter: 682 loss: 6.35724177e-07
Iter: 683 loss: 6.35646757e-07
Iter: 684 loss: 6.36462971e-07
Iter: 685 loss: 6.35658239e-07
Iter: 686 loss: 6.35552283e-07
Iter: 687 loss: 6.35907e-07
Iter: 688 loss: 6.35553e-07
Iter: 689 loss: 6.35475658e-07
Iter: 690 loss: 6.3587413e-07
Iter: 691 loss: 6.35474862e-07
Iter: 692 loss: 6.3542268e-07
Iter: 693 loss: 6.35553761e-07
Iter: 694 loss: 6.35409549e-07
Iter: 695 loss: 6.35386868e-07
Iter: 696 loss: 6.35526703e-07
Iter: 697 loss: 6.35367769e-07
Iter: 698 loss: 6.35322067e-07
Iter: 699 loss: 6.35313029e-07
Iter: 700 loss: 6.35300466e-07
Iter: 701 loss: 6.35246579e-07
Iter: 702 loss: 6.35282277e-07
Iter: 703 loss: 6.35233164e-07
Iter: 704 loss: 6.35188258e-07
Iter: 705 loss: 6.35180754e-07
Iter: 706 loss: 6.35160745e-07
Iter: 707 loss: 6.35126639e-07
Iter: 708 loss: 6.35108677e-07
Iter: 709 loss: 6.35059791e-07
Iter: 710 loss: 6.35112656e-07
Iter: 711 loss: 6.35032791e-07
Iter: 712 loss: 6.35021365e-07
Iter: 713 loss: 6.35026652e-07
Iter: 714 loss: 6.34967705e-07
Iter: 715 loss: 6.34946105e-07
Iter: 716 loss: 6.34956621e-07
Iter: 717 loss: 6.34908474e-07
Iter: 718 loss: 6.35134143e-07
Iter: 719 loss: 6.34913e-07
Iter: 720 loss: 6.34884884e-07
Iter: 721 loss: 6.35043193e-07
Iter: 722 loss: 6.34868684e-07
Iter: 723 loss: 6.34862431e-07
Iter: 724 loss: 6.34859816e-07
Iter: 725 loss: 6.34861465e-07
Iter: 726 loss: 6.34836169e-07
Iter: 727 loss: 6.34991238e-07
Iter: 728 loss: 6.34843445e-07
Iter: 729 loss: 6.34821e-07
Iter: 730 loss: 6.3477961e-07
Iter: 731 loss: 6.35105948e-07
Iter: 732 loss: 6.34769265e-07
Iter: 733 loss: 6.34730554e-07
Iter: 734 loss: 6.34813205e-07
Iter: 735 loss: 6.34727144e-07
Iter: 736 loss: 6.34700029e-07
Iter: 737 loss: 6.34701678e-07
Iter: 738 loss: 6.34663309e-07
Iter: 739 loss: 6.34707078e-07
Iter: 740 loss: 6.34649439e-07
Iter: 741 loss: 6.34647108e-07
Iter: 742 loss: 6.34618459e-07
Iter: 743 loss: 6.34623916e-07
Iter: 744 loss: 6.34608909e-07
Iter: 745 loss: 6.34622324e-07
Iter: 746 loss: 6.34587877e-07
Iter: 747 loss: 6.34592084e-07
Iter: 748 loss: 6.34566334e-07
Iter: 749 loss: 6.3455127e-07
Iter: 750 loss: 6.34644e-07
Iter: 751 loss: 6.34555363e-07
Iter: 752 loss: 6.34558546e-07
Iter: 753 loss: 6.34551213e-07
Iter: 754 loss: 6.34550588e-07
Iter: 755 loss: 6.34563037e-07
Iter: 756 loss: 6.3455542e-07
Iter: 757 loss: 6.34564685e-07
Iter: 758 loss: 6.34567073e-07
Iter: 759 loss: 6.34563889e-07
Iter: 760 loss: 6.34564e-07
Iter: 761 loss: 6.34555079e-07
Iter: 762 loss: 6.34553658e-07
Iter: 763 loss: 6.34552237e-07
Iter: 764 loss: 6.3455343e-07
Iter: 765 loss: 6.34563207e-07
Iter: 766 loss: 6.34557807e-07
Iter: 767 loss: 6.34556443e-07
Iter: 768 loss: 6.34555533e-07
Iter: 769 loss: 6.34556386e-07
Iter: 770 loss: 6.34555647e-07
Iter: 771 loss: 6.34556386e-07
Iter: 772 loss: 6.34556386e-07
Iter: 773 loss: 6.34556443e-07
Iter: 774 loss: 6.34555931e-07
Iter: 775 loss: 6.34555931e-07
Iter: 776 loss: 6.34556443e-07
Iter: 777 loss: 6.34555931e-07
Iter: 778 loss: 6.34533649e-07
Iter: 779 loss: 6.34632215e-07
Iter: 780 loss: 6.34544563e-07
Iter: 781 loss: 6.34514777e-07
Iter: 782 loss: 6.34579351e-07
Iter: 783 loss: 6.34515914e-07
Iter: 784 loss: 6.34498122e-07
Iter: 785 loss: 6.34632443e-07
Iter: 786 loss: 6.34481353e-07
Iter: 787 loss: 6.34465209e-07
Iter: 788 loss: 6.34454636e-07
Iter: 789 loss: 6.34611069e-07
Iter: 790 loss: 6.34463959e-07
Iter: 791 loss: 6.34421554e-07
Iter: 792 loss: 6.34565538e-07
Iter: 793 loss: 6.34415244e-07
Iter: 794 loss: 6.34399044e-07
Iter: 795 loss: 6.34683829e-07
Iter: 796 loss: 6.34416665e-07
Iter: 797 loss: 6.34417461e-07
Iter: 798 loss: 6.34390233e-07
Iter: 799 loss: 6.34393587e-07
Iter: 800 loss: 6.34396656e-07
Iter: 801 loss: 6.34412174e-07
Iter: 802 loss: 6.34408934e-07
Iter: 803 loss: 6.34412061e-07
Iter: 804 loss: 6.34412402e-07
Iter: 805 loss: 6.34415358e-07
Iter: 806 loss: 6.3441496e-07
Iter: 807 loss: 6.34419678e-07
Iter: 808 loss: 6.34417916e-07
Iter: 809 loss: 6.3441712e-07
Iter: 810 loss: 6.34415187e-07
Iter: 811 loss: 6.34417688e-07
Iter: 812 loss: 6.34416608e-07
Iter: 813 loss: 6.34415869e-07
Iter: 814 loss: 6.34415869e-07
Iter: 815 loss: 6.34415869e-07
Iter: 816 loss: 6.34415869e-07
Iter: 817 loss: 6.34415869e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.4
+ date
Mon Nov  9 03:15:02 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.4/500_500_500_500_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_1000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_1000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d215f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d2d47b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d2cf6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d1e6b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d2d4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d1a4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d1a4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d0fbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d0fbea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d0ba6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d0edc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d07f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d0421e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d05c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d010a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d036a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cfe82f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564d036b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cfa56a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cf5da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cf5d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cf0e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cf0ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cee8048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564ce94f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564ce947b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564ce942f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564ce7dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564ce01620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564ce1b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564ce287b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cde5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cded598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cd959d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f564cd48268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f563f770f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.7428398e-06
Iter: 2 loss: 1.90027026e-06
Iter: 3 loss: 1.7648199e-06
Iter: 4 loss: 1.42440945e-06
Iter: 5 loss: 1.57459488e-06
Iter: 6 loss: 1.19224012e-06
Iter: 7 loss: 1.07201231e-06
Iter: 8 loss: 2.1377225e-06
Iter: 9 loss: 1.06608661e-06
Iter: 10 loss: 9.57740781e-07
Iter: 11 loss: 1.21229891e-06
Iter: 12 loss: 9.18002399e-07
Iter: 13 loss: 8.77985258e-07
Iter: 14 loss: 9.68041832e-07
Iter: 15 loss: 8.62902311e-07
Iter: 16 loss: 8.46240141e-07
Iter: 17 loss: 8.4325734e-07
Iter: 18 loss: 8.32408432e-07
Iter: 19 loss: 8.10119161e-07
Iter: 20 loss: 1.20203106e-06
Iter: 21 loss: 8.09646792e-07
Iter: 22 loss: 7.91922901e-07
Iter: 23 loss: 8.87065e-07
Iter: 24 loss: 7.89195326e-07
Iter: 25 loss: 7.78367621e-07
Iter: 26 loss: 7.78284743e-07
Iter: 27 loss: 7.69263295e-07
Iter: 28 loss: 7.45119564e-07
Iter: 29 loss: 9.11588927e-07
Iter: 30 loss: 7.39737288e-07
Iter: 31 loss: 7.20894263e-07
Iter: 32 loss: 9.11965117e-07
Iter: 33 loss: 7.20257958e-07
Iter: 34 loss: 7.07886159e-07
Iter: 35 loss: 7.14311454e-07
Iter: 36 loss: 6.9950886e-07
Iter: 37 loss: 7.03213345e-07
Iter: 38 loss: 6.95795393e-07
Iter: 39 loss: 6.92631147e-07
Iter: 40 loss: 6.96162545e-07
Iter: 41 loss: 6.90937611e-07
Iter: 42 loss: 6.88437808e-07
Iter: 43 loss: 6.8360373e-07
Iter: 44 loss: 7.83041855e-07
Iter: 45 loss: 6.83544954e-07
Iter: 46 loss: 6.83950702e-07
Iter: 47 loss: 6.81118479e-07
Iter: 48 loss: 6.79482696e-07
Iter: 49 loss: 6.75818683e-07
Iter: 50 loss: 7.25503185e-07
Iter: 51 loss: 6.75690103e-07
Iter: 52 loss: 6.71876137e-07
Iter: 53 loss: 7.20430137e-07
Iter: 54 loss: 6.71796e-07
Iter: 55 loss: 6.67633174e-07
Iter: 56 loss: 6.60347553e-07
Iter: 57 loss: 6.60325611e-07
Iter: 58 loss: 6.55488577e-07
Iter: 59 loss: 6.92047365e-07
Iter: 60 loss: 6.55172073e-07
Iter: 61 loss: 6.50461629e-07
Iter: 62 loss: 6.77288199e-07
Iter: 63 loss: 6.49853291e-07
Iter: 64 loss: 6.46395051e-07
Iter: 65 loss: 6.42355246e-07
Iter: 66 loss: 6.41897032e-07
Iter: 67 loss: 6.38494157e-07
Iter: 68 loss: 6.53816755e-07
Iter: 69 loss: 6.37826531e-07
Iter: 70 loss: 6.34493858e-07
Iter: 71 loss: 6.34560536e-07
Iter: 72 loss: 6.31866953e-07
Iter: 73 loss: 6.28614828e-07
Iter: 74 loss: 6.68320411e-07
Iter: 75 loss: 6.28527232e-07
Iter: 76 loss: 6.26702501e-07
Iter: 77 loss: 6.26654128e-07
Iter: 78 loss: 6.25083715e-07
Iter: 79 loss: 6.21315621e-07
Iter: 80 loss: 6.62983553e-07
Iter: 81 loss: 6.20855417e-07
Iter: 82 loss: 6.19157447e-07
Iter: 83 loss: 6.18999081e-07
Iter: 84 loss: 6.16934415e-07
Iter: 85 loss: 6.17830494e-07
Iter: 86 loss: 6.15554654e-07
Iter: 87 loss: 6.13559337e-07
Iter: 88 loss: 6.13261932e-07
Iter: 89 loss: 6.11885639e-07
Iter: 90 loss: 6.1090492e-07
Iter: 91 loss: 6.10378379e-07
Iter: 92 loss: 6.09691e-07
Iter: 93 loss: 6.07410868e-07
Iter: 94 loss: 6.13873055e-07
Iter: 95 loss: 6.0626229e-07
Iter: 96 loss: 6.04389072e-07
Iter: 97 loss: 6.04329045e-07
Iter: 98 loss: 6.02850605e-07
Iter: 99 loss: 6.16636555e-07
Iter: 100 loss: 6.02805699e-07
Iter: 101 loss: 6.02098964e-07
Iter: 102 loss: 6.00020314e-07
Iter: 103 loss: 6.09443589e-07
Iter: 104 loss: 5.99384521e-07
Iter: 105 loss: 5.97176211e-07
Iter: 106 loss: 6.21921117e-07
Iter: 107 loss: 5.97141536e-07
Iter: 108 loss: 5.95532242e-07
Iter: 109 loss: 5.94952667e-07
Iter: 110 loss: 5.94085122e-07
Iter: 111 loss: 5.92837864e-07
Iter: 112 loss: 5.92407957e-07
Iter: 113 loss: 5.9122317e-07
Iter: 114 loss: 5.89654633e-07
Iter: 115 loss: 5.89569311e-07
Iter: 116 loss: 5.87910222e-07
Iter: 117 loss: 6.06946571e-07
Iter: 118 loss: 5.87940406e-07
Iter: 119 loss: 5.86173e-07
Iter: 120 loss: 5.83610472e-07
Iter: 121 loss: 5.83563406e-07
Iter: 122 loss: 5.8182809e-07
Iter: 123 loss: 5.81724748e-07
Iter: 124 loss: 5.80332653e-07
Iter: 125 loss: 5.81535403e-07
Iter: 126 loss: 5.79513312e-07
Iter: 127 loss: 5.78359732e-07
Iter: 128 loss: 5.77612639e-07
Iter: 129 loss: 5.7710804e-07
Iter: 130 loss: 5.77432957e-07
Iter: 131 loss: 5.76580078e-07
Iter: 132 loss: 5.75936838e-07
Iter: 133 loss: 5.7562238e-07
Iter: 134 loss: 5.75389834e-07
Iter: 135 loss: 5.74587034e-07
Iter: 136 loss: 5.73126044e-07
Iter: 137 loss: 6.04701199e-07
Iter: 138 loss: 5.7312468e-07
Iter: 139 loss: 5.71234125e-07
Iter: 140 loss: 5.76783862e-07
Iter: 141 loss: 5.70681948e-07
Iter: 142 loss: 5.68474775e-07
Iter: 143 loss: 5.75560421e-07
Iter: 144 loss: 5.67752181e-07
Iter: 145 loss: 5.65907385e-07
Iter: 146 loss: 5.65890275e-07
Iter: 147 loss: 5.65160349e-07
Iter: 148 loss: 5.64455206e-07
Iter: 149 loss: 5.64365e-07
Iter: 150 loss: 5.6321926e-07
Iter: 151 loss: 5.76825641e-07
Iter: 152 loss: 5.63221192e-07
Iter: 153 loss: 5.62430273e-07
Iter: 154 loss: 5.61458307e-07
Iter: 155 loss: 5.61407717e-07
Iter: 156 loss: 5.61076945e-07
Iter: 157 loss: 5.60885212e-07
Iter: 158 loss: 5.60437115e-07
Iter: 159 loss: 5.59577586e-07
Iter: 160 loss: 5.72528961e-07
Iter: 161 loss: 5.59466514e-07
Iter: 162 loss: 5.58296335e-07
Iter: 163 loss: 5.59986859e-07
Iter: 164 loss: 5.57652754e-07
Iter: 165 loss: 5.57266503e-07
Iter: 166 loss: 5.569226e-07
Iter: 167 loss: 5.56526686e-07
Iter: 168 loss: 5.55308816e-07
Iter: 169 loss: 5.64743061e-07
Iter: 170 loss: 5.55087126e-07
Iter: 171 loss: 5.53310713e-07
Iter: 172 loss: 5.53351413e-07
Iter: 173 loss: 5.51943572e-07
Iter: 174 loss: 5.50238724e-07
Iter: 175 loss: 5.63204196e-07
Iter: 176 loss: 5.50155278e-07
Iter: 177 loss: 5.48803e-07
Iter: 178 loss: 5.60791136e-07
Iter: 179 loss: 5.48730441e-07
Iter: 180 loss: 5.47541902e-07
Iter: 181 loss: 5.54308201e-07
Iter: 182 loss: 5.47292473e-07
Iter: 183 loss: 5.46713693e-07
Iter: 184 loss: 5.45802607e-07
Iter: 185 loss: 5.45764465e-07
Iter: 186 loss: 5.44398517e-07
Iter: 187 loss: 5.58397915e-07
Iter: 188 loss: 5.44404202e-07
Iter: 189 loss: 5.43455e-07
Iter: 190 loss: 5.42842599e-07
Iter: 191 loss: 5.4255014e-07
Iter: 192 loss: 5.41996314e-07
Iter: 193 loss: 5.4193606e-07
Iter: 194 loss: 5.41470058e-07
Iter: 195 loss: 5.40325914e-07
Iter: 196 loss: 5.53978566e-07
Iter: 197 loss: 5.40250085e-07
Iter: 198 loss: 5.39251971e-07
Iter: 199 loss: 5.43099588e-07
Iter: 200 loss: 5.38970198e-07
Iter: 201 loss: 5.38028644e-07
Iter: 202 loss: 5.39906353e-07
Iter: 203 loss: 5.37635231e-07
Iter: 204 loss: 5.36745e-07
Iter: 205 loss: 5.36743244e-07
Iter: 206 loss: 5.3599166e-07
Iter: 207 loss: 5.34424942e-07
Iter: 208 loss: 5.62473531e-07
Iter: 209 loss: 5.34442506e-07
Iter: 210 loss: 5.33044215e-07
Iter: 211 loss: 5.36297875e-07
Iter: 212 loss: 5.325129e-07
Iter: 213 loss: 5.33315074e-07
Iter: 214 loss: 5.31970613e-07
Iter: 215 loss: 5.31607043e-07
Iter: 216 loss: 5.3083852e-07
Iter: 217 loss: 5.46002411e-07
Iter: 218 loss: 5.30841646e-07
Iter: 219 loss: 5.30230068e-07
Iter: 220 loss: 5.36089e-07
Iter: 221 loss: 5.30168791e-07
Iter: 222 loss: 5.29423517e-07
Iter: 223 loss: 5.30255761e-07
Iter: 224 loss: 5.29097122e-07
Iter: 225 loss: 5.28641351e-07
Iter: 226 loss: 5.29398392e-07
Iter: 227 loss: 5.28464398e-07
Iter: 228 loss: 5.27793475e-07
Iter: 229 loss: 5.29529814e-07
Iter: 230 loss: 5.27499139e-07
Iter: 231 loss: 5.26898134e-07
Iter: 232 loss: 5.25667701e-07
Iter: 233 loss: 5.53572818e-07
Iter: 234 loss: 5.25672931e-07
Iter: 235 loss: 5.24393e-07
Iter: 236 loss: 5.26705833e-07
Iter: 237 loss: 5.23855647e-07
Iter: 238 loss: 5.22579569e-07
Iter: 239 loss: 5.34031187e-07
Iter: 240 loss: 5.2243945e-07
Iter: 241 loss: 5.21500795e-07
Iter: 242 loss: 5.34999629e-07
Iter: 243 loss: 5.21544905e-07
Iter: 244 loss: 5.21070206e-07
Iter: 245 loss: 5.19788784e-07
Iter: 246 loss: 5.29382078e-07
Iter: 247 loss: 5.19547143e-07
Iter: 248 loss: 5.17948877e-07
Iter: 249 loss: 5.24722623e-07
Iter: 250 loss: 5.17562285e-07
Iter: 251 loss: 5.1651142e-07
Iter: 252 loss: 5.20949186e-07
Iter: 253 loss: 5.1627876e-07
Iter: 254 loss: 5.15489887e-07
Iter: 255 loss: 5.15465047e-07
Iter: 256 loss: 5.14900421e-07
Iter: 257 loss: 5.14007183e-07
Iter: 258 loss: 5.13984332e-07
Iter: 259 loss: 5.1356983e-07
Iter: 260 loss: 5.13529699e-07
Iter: 261 loss: 5.13058183e-07
Iter: 262 loss: 5.12459337e-07
Iter: 263 loss: 5.12440522e-07
Iter: 264 loss: 5.11866347e-07
Iter: 265 loss: 5.18588308e-07
Iter: 266 loss: 5.11803137e-07
Iter: 267 loss: 5.11251471e-07
Iter: 268 loss: 5.10917403e-07
Iter: 269 loss: 5.10653e-07
Iter: 270 loss: 5.0991963e-07
Iter: 271 loss: 5.08506787e-07
Iter: 272 loss: 5.40642588e-07
Iter: 273 loss: 5.08484504e-07
Iter: 274 loss: 5.08195797e-07
Iter: 275 loss: 5.07835e-07
Iter: 276 loss: 5.07224627e-07
Iter: 277 loss: 5.06618676e-07
Iter: 278 loss: 5.06511867e-07
Iter: 279 loss: 5.05536946e-07
Iter: 280 loss: 5.05630339e-07
Iter: 281 loss: 5.0481674e-07
Iter: 282 loss: 5.03704e-07
Iter: 283 loss: 5.10344705e-07
Iter: 284 loss: 5.03566923e-07
Iter: 285 loss: 5.02995363e-07
Iter: 286 loss: 5.03066474e-07
Iter: 287 loss: 5.02424427e-07
Iter: 288 loss: 5.02511284e-07
Iter: 289 loss: 5.01948762e-07
Iter: 290 loss: 5.01373904e-07
Iter: 291 loss: 5.00638293e-07
Iter: 292 loss: 5.00556837e-07
Iter: 293 loss: 4.99411271e-07
Iter: 294 loss: 5.09101596e-07
Iter: 295 loss: 4.99368866e-07
Iter: 296 loss: 4.97959718e-07
Iter: 297 loss: 4.98875693e-07
Iter: 298 loss: 4.96991845e-07
Iter: 299 loss: 4.96308871e-07
Iter: 300 loss: 5.04104946e-07
Iter: 301 loss: 4.9628278e-07
Iter: 302 loss: 4.95548932e-07
Iter: 303 loss: 4.94966343e-07
Iter: 304 loss: 4.94736582e-07
Iter: 305 loss: 4.93813786e-07
Iter: 306 loss: 4.94184e-07
Iter: 307 loss: 4.9310546e-07
Iter: 308 loss: 4.92965114e-07
Iter: 309 loss: 4.92723075e-07
Iter: 310 loss: 4.92307208e-07
Iter: 311 loss: 4.91367302e-07
Iter: 312 loss: 5.01366571e-07
Iter: 313 loss: 4.91253672e-07
Iter: 314 loss: 4.90236403e-07
Iter: 315 loss: 4.92130141e-07
Iter: 316 loss: 4.89905915e-07
Iter: 317 loss: 4.88877788e-07
Iter: 318 loss: 4.88900582e-07
Iter: 319 loss: 4.88047192e-07
Iter: 320 loss: 4.88504384e-07
Iter: 321 loss: 4.87614443e-07
Iter: 322 loss: 4.87158673e-07
Iter: 323 loss: 4.86532201e-07
Iter: 324 loss: 4.86547719e-07
Iter: 325 loss: 4.8586935e-07
Iter: 326 loss: 4.85871624e-07
Iter: 327 loss: 4.85315525e-07
Iter: 328 loss: 4.8551658e-07
Iter: 329 loss: 4.84952579e-07
Iter: 330 loss: 4.84736461e-07
Iter: 331 loss: 4.83999656e-07
Iter: 332 loss: 4.9139328e-07
Iter: 333 loss: 4.8391405e-07
Iter: 334 loss: 4.83168321e-07
Iter: 335 loss: 4.87973637e-07
Iter: 336 loss: 4.83035e-07
Iter: 337 loss: 4.82156793e-07
Iter: 338 loss: 4.84347254e-07
Iter: 339 loss: 4.81775714e-07
Iter: 340 loss: 4.81188295e-07
Iter: 341 loss: 4.81194888e-07
Iter: 342 loss: 4.80729568e-07
Iter: 343 loss: 4.80200924e-07
Iter: 344 loss: 4.8019308e-07
Iter: 345 loss: 4.79764878e-07
Iter: 346 loss: 4.79084065e-07
Iter: 347 loss: 4.79111e-07
Iter: 348 loss: 4.78592483e-07
Iter: 349 loss: 4.79381697e-07
Iter: 350 loss: 4.78339643e-07
Iter: 351 loss: 4.77667299e-07
Iter: 352 loss: 4.78227321e-07
Iter: 353 loss: 4.77308561e-07
Iter: 354 loss: 4.77357503e-07
Iter: 355 loss: 4.76982564e-07
Iter: 356 loss: 4.76720913e-07
Iter: 357 loss: 4.76114053e-07
Iter: 358 loss: 4.78203901e-07
Iter: 359 loss: 4.75797663e-07
Iter: 360 loss: 4.74892772e-07
Iter: 361 loss: 4.83398878e-07
Iter: 362 loss: 4.74892687e-07
Iter: 363 loss: 4.73801236e-07
Iter: 364 loss: 4.76368086e-07
Iter: 365 loss: 4.73468617e-07
Iter: 366 loss: 4.72804203e-07
Iter: 367 loss: 4.73386848e-07
Iter: 368 loss: 4.72364519e-07
Iter: 369 loss: 4.71550976e-07
Iter: 370 loss: 4.77674234e-07
Iter: 371 loss: 4.71485521e-07
Iter: 372 loss: 4.71025828e-07
Iter: 373 loss: 4.71453632e-07
Iter: 374 loss: 4.70702787e-07
Iter: 375 loss: 4.70381849e-07
Iter: 376 loss: 4.74236856e-07
Iter: 377 loss: 4.70405439e-07
Iter: 378 loss: 4.70068755e-07
Iter: 379 loss: 4.69831321e-07
Iter: 380 loss: 4.6978937e-07
Iter: 381 loss: 4.69293894e-07
Iter: 382 loss: 4.69153349e-07
Iter: 383 loss: 4.68833036e-07
Iter: 384 loss: 4.68215973e-07
Iter: 385 loss: 4.69250608e-07
Iter: 386 loss: 4.67821678e-07
Iter: 387 loss: 4.67227181e-07
Iter: 388 loss: 4.67246679e-07
Iter: 389 loss: 4.66544293e-07
Iter: 390 loss: 4.66583572e-07
Iter: 391 loss: 4.65945959e-07
Iter: 392 loss: 4.65451024e-07
Iter: 393 loss: 4.65171411e-07
Iter: 394 loss: 4.64985249e-07
Iter: 395 loss: 4.64545309e-07
Iter: 396 loss: 4.644711e-07
Iter: 397 loss: 4.64053869e-07
Iter: 398 loss: 4.63912812e-07
Iter: 399 loss: 4.63640362e-07
Iter: 400 loss: 4.63416114e-07
Iter: 401 loss: 4.63395622e-07
Iter: 402 loss: 4.63193118e-07
Iter: 403 loss: 4.62782225e-07
Iter: 404 loss: 4.62831338e-07
Iter: 405 loss: 4.62388812e-07
Iter: 406 loss: 4.65322842e-07
Iter: 407 loss: 4.62333503e-07
Iter: 408 loss: 4.61935031e-07
Iter: 409 loss: 4.63459116e-07
Iter: 410 loss: 4.61928494e-07
Iter: 411 loss: 4.61615741e-07
Iter: 412 loss: 4.60969943e-07
Iter: 413 loss: 4.70970235e-07
Iter: 414 loss: 4.60889964e-07
Iter: 415 loss: 4.60046351e-07
Iter: 416 loss: 4.62127048e-07
Iter: 417 loss: 4.5974582e-07
Iter: 418 loss: 4.58959619e-07
Iter: 419 loss: 4.59858313e-07
Iter: 420 loss: 4.58583315e-07
Iter: 421 loss: 4.5827926e-07
Iter: 422 loss: 4.5810728e-07
Iter: 423 loss: 4.57641363e-07
Iter: 424 loss: 4.57755874e-07
Iter: 425 loss: 4.5729152e-07
Iter: 426 loss: 4.56928632e-07
Iter: 427 loss: 4.56171279e-07
Iter: 428 loss: 4.70997861e-07
Iter: 429 loss: 4.56164855e-07
Iter: 430 loss: 4.55955188e-07
Iter: 431 loss: 4.55739439e-07
Iter: 432 loss: 4.55290206e-07
Iter: 433 loss: 4.55277814e-07
Iter: 434 loss: 4.54971911e-07
Iter: 435 loss: 4.54605527e-07
Iter: 436 loss: 4.54982683e-07
Iter: 437 loss: 4.54381791e-07
Iter: 438 loss: 4.5378647e-07
Iter: 439 loss: 4.56130749e-07
Iter: 440 loss: 4.53673408e-07
Iter: 441 loss: 4.53349e-07
Iter: 442 loss: 4.53406443e-07
Iter: 443 loss: 4.53137773e-07
Iter: 444 loss: 4.52748907e-07
Iter: 445 loss: 4.5273805e-07
Iter: 446 loss: 4.52496e-07
Iter: 447 loss: 4.51808319e-07
Iter: 448 loss: 4.60333467e-07
Iter: 449 loss: 4.51771882e-07
Iter: 450 loss: 4.51112015e-07
Iter: 451 loss: 4.51539e-07
Iter: 452 loss: 4.5073233e-07
Iter: 453 loss: 4.5002966e-07
Iter: 454 loss: 4.50612617e-07
Iter: 455 loss: 4.49707557e-07
Iter: 456 loss: 4.48986555e-07
Iter: 457 loss: 4.48967739e-07
Iter: 458 loss: 4.48669709e-07
Iter: 459 loss: 4.48228235e-07
Iter: 460 loss: 4.48167356e-07
Iter: 461 loss: 4.47622028e-07
Iter: 462 loss: 4.48756907e-07
Iter: 463 loss: 4.4740051e-07
Iter: 464 loss: 4.47397724e-07
Iter: 465 loss: 4.47176831e-07
Iter: 466 loss: 4.47014969e-07
Iter: 467 loss: 4.46592509e-07
Iter: 468 loss: 4.48314836e-07
Iter: 469 loss: 4.46460632e-07
Iter: 470 loss: 4.45911212e-07
Iter: 471 loss: 4.45889214e-07
Iter: 472 loss: 4.45508419e-07
Iter: 473 loss: 4.44828686e-07
Iter: 474 loss: 4.44852844e-07
Iter: 475 loss: 4.44358875e-07
Iter: 476 loss: 4.474538e-07
Iter: 477 loss: 4.44334802e-07
Iter: 478 loss: 4.43715436e-07
Iter: 479 loss: 4.4396765e-07
Iter: 480 loss: 4.43254891e-07
Iter: 481 loss: 4.42553301e-07
Iter: 482 loss: 4.42972834e-07
Iter: 483 loss: 4.42136923e-07
Iter: 484 loss: 4.41630505e-07
Iter: 485 loss: 4.43970123e-07
Iter: 486 loss: 4.41584945e-07
Iter: 487 loss: 4.41154356e-07
Iter: 488 loss: 4.43748547e-07
Iter: 489 loss: 4.41155692e-07
Iter: 490 loss: 4.40678178e-07
Iter: 491 loss: 4.40439891e-07
Iter: 492 loss: 4.40292297e-07
Iter: 493 loss: 4.39697658e-07
Iter: 494 loss: 4.40948696e-07
Iter: 495 loss: 4.39546284e-07
Iter: 496 loss: 4.39198345e-07
Iter: 497 loss: 4.39221765e-07
Iter: 498 loss: 4.38803681e-07
Iter: 499 loss: 4.38079951e-07
Iter: 500 loss: 4.53005697e-07
Iter: 501 loss: 4.38074153e-07
Iter: 502 loss: 4.3761986e-07
Iter: 503 loss: 4.37628984e-07
Iter: 504 loss: 4.37298e-07
Iter: 505 loss: 4.37189556e-07
Iter: 506 loss: 4.3686606e-07
Iter: 507 loss: 4.36417508e-07
Iter: 508 loss: 4.36505502e-07
Iter: 509 loss: 4.36040978e-07
Iter: 510 loss: 4.35774922e-07
Iter: 511 loss: 4.35725639e-07
Iter: 512 loss: 4.35488801e-07
Iter: 513 loss: 4.35019416e-07
Iter: 514 loss: 4.41522502e-07
Iter: 515 loss: 4.34976982e-07
Iter: 516 loss: 4.34432195e-07
Iter: 517 loss: 4.36356146e-07
Iter: 518 loss: 4.34320697e-07
Iter: 519 loss: 4.3390844e-07
Iter: 520 loss: 4.36942798e-07
Iter: 521 loss: 4.33887152e-07
Iter: 522 loss: 4.33619e-07
Iter: 523 loss: 4.33256957e-07
Iter: 524 loss: 4.33183402e-07
Iter: 525 loss: 4.32604963e-07
Iter: 526 loss: 4.32579498e-07
Iter: 527 loss: 4.32089649e-07
Iter: 528 loss: 4.31725255e-07
Iter: 529 loss: 4.31659828e-07
Iter: 530 loss: 4.31276646e-07
Iter: 531 loss: 4.31964622e-07
Iter: 532 loss: 4.3113107e-07
Iter: 533 loss: 4.30817323e-07
Iter: 534 loss: 4.30519208e-07
Iter: 535 loss: 4.30455202e-07
Iter: 536 loss: 4.29977291e-07
Iter: 537 loss: 4.2999406e-07
Iter: 538 loss: 4.29790418e-07
Iter: 539 loss: 4.29416531e-07
Iter: 540 loss: 4.37532236e-07
Iter: 541 loss: 4.29385921e-07
Iter: 542 loss: 4.29004274e-07
Iter: 543 loss: 4.33806861e-07
Iter: 544 loss: 4.29029598e-07
Iter: 545 loss: 4.28590283e-07
Iter: 546 loss: 4.2839298e-07
Iter: 547 loss: 4.28129027e-07
Iter: 548 loss: 4.27712877e-07
Iter: 549 loss: 4.28998931e-07
Iter: 550 loss: 4.27617408e-07
Iter: 551 loss: 4.27326313e-07
Iter: 552 loss: 4.27287631e-07
Iter: 553 loss: 4.27009752e-07
Iter: 554 loss: 4.26507484e-07
Iter: 555 loss: 4.26513282e-07
Iter: 556 loss: 4.26037786e-07
Iter: 557 loss: 4.27612775e-07
Iter: 558 loss: 4.25957182e-07
Iter: 559 loss: 4.25560557e-07
Iter: 560 loss: 4.26579e-07
Iter: 561 loss: 4.25481886e-07
Iter: 562 loss: 4.25098307e-07
Iter: 563 loss: 4.28742112e-07
Iter: 564 loss: 4.25061273e-07
Iter: 565 loss: 4.24796639e-07
Iter: 566 loss: 4.24459984e-07
Iter: 567 loss: 4.24484085e-07
Iter: 568 loss: 4.24167354e-07
Iter: 569 loss: 4.24175226e-07
Iter: 570 loss: 4.23911956e-07
Iter: 571 loss: 4.23454708e-07
Iter: 572 loss: 4.29748695e-07
Iter: 573 loss: 4.23459454e-07
Iter: 574 loss: 4.23162362e-07
Iter: 575 loss: 4.23137863e-07
Iter: 576 loss: 4.2291262e-07
Iter: 577 loss: 4.2344584e-07
Iter: 578 loss: 4.22839747e-07
Iter: 579 loss: 4.2262505e-07
Iter: 580 loss: 4.22341031e-07
Iter: 581 loss: 4.29617671e-07
Iter: 582 loss: 4.22345551e-07
Iter: 583 loss: 4.21959726e-07
Iter: 584 loss: 4.22572441e-07
Iter: 585 loss: 4.21789423e-07
Iter: 586 loss: 4.21281015e-07
Iter: 587 loss: 4.21928178e-07
Iter: 588 loss: 4.21052761e-07
Iter: 589 loss: 4.20535514e-07
Iter: 590 loss: 4.20304957e-07
Iter: 591 loss: 4.20022417e-07
Iter: 592 loss: 4.19641538e-07
Iter: 593 loss: 4.19634659e-07
Iter: 594 loss: 4.19491812e-07
Iter: 595 loss: 4.21176111e-07
Iter: 596 loss: 4.19412828e-07
Iter: 597 loss: 4.19208334e-07
Iter: 598 loss: 4.18909281e-07
Iter: 599 loss: 4.18913771e-07
Iter: 600 loss: 4.18578935e-07
Iter: 601 loss: 4.22279186e-07
Iter: 602 loss: 4.18607556e-07
Iter: 603 loss: 4.18274624e-07
Iter: 604 loss: 4.18806053e-07
Iter: 605 loss: 4.18164404e-07
Iter: 606 loss: 4.17926287e-07
Iter: 607 loss: 4.17858644e-07
Iter: 608 loss: 4.17734327e-07
Iter: 609 loss: 4.17221059e-07
Iter: 610 loss: 4.18221532e-07
Iter: 611 loss: 4.17015741e-07
Iter: 612 loss: 4.16492e-07
Iter: 613 loss: 4.1760552e-07
Iter: 614 loss: 4.16290931e-07
Iter: 615 loss: 4.15841214e-07
Iter: 616 loss: 4.19342086e-07
Iter: 617 loss: 4.15798382e-07
Iter: 618 loss: 4.15482049e-07
Iter: 619 loss: 4.14969179e-07
Iter: 620 loss: 4.26749637e-07
Iter: 621 loss: 4.14990694e-07
Iter: 622 loss: 4.14329747e-07
Iter: 623 loss: 4.1636298e-07
Iter: 624 loss: 4.14190708e-07
Iter: 625 loss: 4.13733545e-07
Iter: 626 loss: 4.16687556e-07
Iter: 627 loss: 4.13692931e-07
Iter: 628 loss: 4.13395696e-07
Iter: 629 loss: 4.17023472e-07
Iter: 630 loss: 4.13424289e-07
Iter: 631 loss: 4.13099372e-07
Iter: 632 loss: 4.1278895e-07
Iter: 633 loss: 4.12770873e-07
Iter: 634 loss: 4.12318599e-07
Iter: 635 loss: 4.14031604e-07
Iter: 636 loss: 4.1223214e-07
Iter: 637 loss: 4.11694714e-07
Iter: 638 loss: 4.1308806e-07
Iter: 639 loss: 4.11492152e-07
Iter: 640 loss: 4.10997586e-07
Iter: 641 loss: 4.10564667e-07
Iter: 642 loss: 4.10423468e-07
Iter: 643 loss: 4.09884535e-07
Iter: 644 loss: 4.09892749e-07
Iter: 645 loss: 4.0954933e-07
Iter: 646 loss: 4.09348132e-07
Iter: 647 loss: 4.09247889e-07
Iter: 648 loss: 4.08825088e-07
Iter: 649 loss: 4.1352132e-07
Iter: 650 loss: 4.08768926e-07
Iter: 651 loss: 4.08473625e-07
Iter: 652 loss: 4.0833703e-07
Iter: 653 loss: 4.08178664e-07
Iter: 654 loss: 4.07840645e-07
Iter: 655 loss: 4.07905816e-07
Iter: 656 loss: 4.07613754e-07
Iter: 657 loss: 4.07144029e-07
Iter: 658 loss: 4.08342714e-07
Iter: 659 loss: 4.06975346e-07
Iter: 660 loss: 4.06744704e-07
Iter: 661 loss: 4.06728759e-07
Iter: 662 loss: 4.06465347e-07
Iter: 663 loss: 4.06634e-07
Iter: 664 loss: 4.06248859e-07
Iter: 665 loss: 4.05962822e-07
Iter: 666 loss: 4.06148558e-07
Iter: 667 loss: 4.05789194e-07
Iter: 668 loss: 4.05443728e-07
Iter: 669 loss: 4.0862426e-07
Iter: 670 loss: 4.05437277e-07
Iter: 671 loss: 4.05215786e-07
Iter: 672 loss: 4.05127537e-07
Iter: 673 loss: 4.04990089e-07
Iter: 674 loss: 4.04836101e-07
Iter: 675 loss: 4.07863979e-07
Iter: 676 loss: 4.04826778e-07
Iter: 677 loss: 4.04582323e-07
Iter: 678 loss: 4.04256696e-07
Iter: 679 loss: 4.04222e-07
Iter: 680 loss: 4.03959774e-07
Iter: 681 loss: 4.08235735e-07
Iter: 682 loss: 4.03915664e-07
Iter: 683 loss: 4.03667656e-07
Iter: 684 loss: 4.0385973e-07
Iter: 685 loss: 4.03475156e-07
Iter: 686 loss: 4.03184345e-07
Iter: 687 loss: 4.02683128e-07
Iter: 688 loss: 4.02700607e-07
Iter: 689 loss: 4.02039404e-07
Iter: 690 loss: 4.03275152e-07
Iter: 691 loss: 4.01813054e-07
Iter: 692 loss: 4.01564023e-07
Iter: 693 loss: 4.01473102e-07
Iter: 694 loss: 4.01176152e-07
Iter: 695 loss: 4.01554985e-07
Iter: 696 loss: 4.01079092e-07
Iter: 697 loss: 4.00713503e-07
Iter: 698 loss: 4.00696337e-07
Iter: 699 loss: 4.00495821e-07
Iter: 700 loss: 4.00062049e-07
Iter: 701 loss: 4.05854621e-07
Iter: 702 loss: 4.00101499e-07
Iter: 703 loss: 3.99871283e-07
Iter: 704 loss: 3.99520275e-07
Iter: 705 loss: 3.99489522e-07
Iter: 706 loss: 3.99018347e-07
Iter: 707 loss: 4.01678022e-07
Iter: 708 loss: 3.99005813e-07
Iter: 709 loss: 3.98494166e-07
Iter: 710 loss: 3.98645398e-07
Iter: 711 loss: 3.98126e-07
Iter: 712 loss: 3.97750085e-07
Iter: 713 loss: 4.00534532e-07
Iter: 714 loss: 3.97716462e-07
Iter: 715 loss: 3.97286669e-07
Iter: 716 loss: 3.9831616e-07
Iter: 717 loss: 3.97138137e-07
Iter: 718 loss: 3.96845905e-07
Iter: 719 loss: 3.96586842e-07
Iter: 720 loss: 3.96465623e-07
Iter: 721 loss: 3.96035404e-07
Iter: 722 loss: 3.97102724e-07
Iter: 723 loss: 3.95905715e-07
Iter: 724 loss: 3.95573323e-07
Iter: 725 loss: 3.97356331e-07
Iter: 726 loss: 3.95496926e-07
Iter: 727 loss: 3.95219985e-07
Iter: 728 loss: 3.98968041e-07
Iter: 729 loss: 3.9525878e-07
Iter: 730 loss: 3.95021345e-07
Iter: 731 loss: 3.94737e-07
Iter: 732 loss: 3.94728602e-07
Iter: 733 loss: 3.94442367e-07
Iter: 734 loss: 3.94457459e-07
Iter: 735 loss: 3.94232018e-07
Iter: 736 loss: 3.94029144e-07
Iter: 737 loss: 3.93926086e-07
Iter: 738 loss: 3.9357252e-07
Iter: 739 loss: 3.94030849e-07
Iter: 740 loss: 3.93372744e-07
Iter: 741 loss: 3.93001159e-07
Iter: 742 loss: 3.97801955e-07
Iter: 743 loss: 3.92961169e-07
Iter: 744 loss: 3.9277549e-07
Iter: 745 loss: 3.92691788e-07
Iter: 746 loss: 3.92642676e-07
Iter: 747 loss: 3.92342287e-07
Iter: 748 loss: 3.94905e-07
Iter: 749 loss: 3.92319464e-07
Iter: 750 loss: 3.92129209e-07
Iter: 751 loss: 3.91801763e-07
Iter: 752 loss: 3.91799261e-07
Iter: 753 loss: 3.913635e-07
Iter: 754 loss: 3.91729827e-07
Iter: 755 loss: 3.91179327e-07
Iter: 756 loss: 3.90659437e-07
Iter: 757 loss: 3.91270135e-07
Iter: 758 loss: 3.90412396e-07
Iter: 759 loss: 3.90043027e-07
Iter: 760 loss: 3.94177732e-07
Iter: 761 loss: 3.89984791e-07
Iter: 762 loss: 3.89723823e-07
Iter: 763 loss: 3.93873279e-07
Iter: 764 loss: 3.89723652e-07
Iter: 765 loss: 3.89551218e-07
Iter: 766 loss: 3.89256e-07
Iter: 767 loss: 3.95920694e-07
Iter: 768 loss: 3.89222151e-07
Iter: 769 loss: 3.89114291e-07
Iter: 770 loss: 3.89069896e-07
Iter: 771 loss: 3.88920682e-07
Iter: 772 loss: 3.8867222e-07
Iter: 773 loss: 3.94883443e-07
Iter: 774 loss: 3.88662158e-07
Iter: 775 loss: 3.88455305e-07
Iter: 776 loss: 3.88428759e-07
Iter: 777 loss: 3.88267694e-07
Iter: 778 loss: 3.88103672e-07
Iter: 779 loss: 3.88103331e-07
Iter: 780 loss: 3.8772373e-07
Iter: 781 loss: 3.88086818e-07
Iter: 782 loss: 3.87616581e-07
Iter: 783 loss: 3.87488569e-07
Iter: 784 loss: 3.87363031e-07
Iter: 785 loss: 3.87313946e-07
Iter: 786 loss: 3.86961347e-07
Iter: 787 loss: 3.91336584e-07
Iter: 788 loss: 3.8698164e-07
Iter: 789 loss: 3.86752447e-07
Iter: 790 loss: 3.86920334e-07
Iter: 791 loss: 3.86496197e-07
Iter: 792 loss: 3.86241965e-07
Iter: 793 loss: 3.88020794e-07
Iter: 794 loss: 3.86214026e-07
Iter: 795 loss: 3.8606089e-07
Iter: 796 loss: 3.87906397e-07
Iter: 797 loss: 3.86056485e-07
Iter: 798 loss: 3.85867367e-07
Iter: 799 loss: 3.85849376e-07
Iter: 800 loss: 3.85729322e-07
Iter: 801 loss: 3.85438227e-07
Iter: 802 loss: 3.85280089e-07
Iter: 803 loss: 3.85187576e-07
Iter: 804 loss: 3.85011447e-07
Iter: 805 loss: 3.84953466e-07
Iter: 806 loss: 3.84781629e-07
Iter: 807 loss: 3.84326739e-07
Iter: 808 loss: 3.88690353e-07
Iter: 809 loss: 3.8424713e-07
Iter: 810 loss: 3.83969279e-07
Iter: 811 loss: 3.83971212e-07
Iter: 812 loss: 3.83688899e-07
Iter: 813 loss: 3.84647933e-07
Iter: 814 loss: 3.8365917e-07
Iter: 815 loss: 3.8345911e-07
Iter: 816 loss: 3.83127912e-07
Iter: 817 loss: 3.83168015e-07
Iter: 818 loss: 3.83006807e-07
Iter: 819 loss: 3.82975827e-07
Iter: 820 loss: 3.82835196e-07
Iter: 821 loss: 3.82664609e-07
Iter: 822 loss: 3.82619817e-07
Iter: 823 loss: 3.82341909e-07
Iter: 824 loss: 3.82111153e-07
Iter: 825 loss: 3.82091855e-07
Iter: 826 loss: 3.81713846e-07
Iter: 827 loss: 3.82058914e-07
Iter: 828 loss: 3.81423291e-07
Iter: 829 loss: 3.81010267e-07
Iter: 830 loss: 3.82733504e-07
Iter: 831 loss: 3.80824758e-07
Iter: 832 loss: 3.80492793e-07
Iter: 833 loss: 3.8177248e-07
Iter: 834 loss: 3.8040065e-07
Iter: 835 loss: 3.80115182e-07
Iter: 836 loss: 3.80130217e-07
Iter: 837 loss: 3.79839491e-07
Iter: 838 loss: 3.79440024e-07
Iter: 839 loss: 3.79462961e-07
Iter: 840 loss: 3.79118774e-07
Iter: 841 loss: 3.79631814e-07
Iter: 842 loss: 3.78866758e-07
Iter: 843 loss: 3.78501738e-07
Iter: 844 loss: 3.7849702e-07
Iter: 845 loss: 3.78324444e-07
Iter: 846 loss: 3.7800163e-07
Iter: 847 loss: 3.7802252e-07
Iter: 848 loss: 3.77649798e-07
Iter: 849 loss: 3.7814894e-07
Iter: 850 loss: 3.77470116e-07
Iter: 851 loss: 3.77013e-07
Iter: 852 loss: 3.81252e-07
Iter: 853 loss: 3.77006643e-07
Iter: 854 loss: 3.76750506e-07
Iter: 855 loss: 3.7634544e-07
Iter: 856 loss: 3.76358116e-07
Iter: 857 loss: 3.75888902e-07
Iter: 858 loss: 3.76446849e-07
Iter: 859 loss: 3.75672641e-07
Iter: 860 loss: 3.7560568e-07
Iter: 861 loss: 3.75441914e-07
Iter: 862 loss: 3.75199221e-07
Iter: 863 loss: 3.74843495e-07
Iter: 864 loss: 3.81220218e-07
Iter: 865 loss: 3.74806945e-07
Iter: 866 loss: 3.74408444e-07
Iter: 867 loss: 3.74508858e-07
Iter: 868 loss: 3.74111238e-07
Iter: 869 loss: 3.73691819e-07
Iter: 870 loss: 3.76923026e-07
Iter: 871 loss: 3.73610021e-07
Iter: 872 loss: 3.73425479e-07
Iter: 873 loss: 3.73397086e-07
Iter: 874 loss: 3.73193245e-07
Iter: 875 loss: 3.72858068e-07
Iter: 876 loss: 3.77879559e-07
Iter: 877 loss: 3.7282075e-07
Iter: 878 loss: 3.72618047e-07
Iter: 879 loss: 3.72575329e-07
Iter: 880 loss: 3.72370323e-07
Iter: 881 loss: 3.72089119e-07
Iter: 882 loss: 3.72077494e-07
Iter: 883 loss: 3.71757892e-07
Iter: 884 loss: 3.72510897e-07
Iter: 885 loss: 3.71568859e-07
Iter: 886 loss: 3.71275348e-07
Iter: 887 loss: 3.71294504e-07
Iter: 888 loss: 3.71137077e-07
Iter: 889 loss: 3.70707056e-07
Iter: 890 loss: 3.73214618e-07
Iter: 891 loss: 3.70634268e-07
Iter: 892 loss: 3.70395611e-07
Iter: 893 loss: 3.70330952e-07
Iter: 894 loss: 3.70153543e-07
Iter: 895 loss: 3.73521459e-07
Iter: 896 loss: 3.70177645e-07
Iter: 897 loss: 3.699964e-07
Iter: 898 loss: 3.69606823e-07
Iter: 899 loss: 3.72269881e-07
Iter: 900 loss: 3.6954475e-07
Iter: 901 loss: 3.69101059e-07
Iter: 902 loss: 3.70595558e-07
Iter: 903 loss: 3.68959e-07
Iter: 904 loss: 3.68473792e-07
Iter: 905 loss: 3.69349152e-07
Iter: 906 loss: 3.68226267e-07
Iter: 907 loss: 3.68234907e-07
Iter: 908 loss: 3.6803408e-07
Iter: 909 loss: 3.67873639e-07
Iter: 910 loss: 3.67514701e-07
Iter: 911 loss: 3.71907106e-07
Iter: 912 loss: 3.67477668e-07
Iter: 913 loss: 3.67160425e-07
Iter: 914 loss: 3.69441381e-07
Iter: 915 loss: 3.67086926e-07
Iter: 916 loss: 3.66851111e-07
Iter: 917 loss: 3.68883434e-07
Iter: 918 loss: 3.66811037e-07
Iter: 919 loss: 3.66702523e-07
Iter: 920 loss: 3.66640705e-07
Iter: 921 loss: 3.66587301e-07
Iter: 922 loss: 3.66394772e-07
Iter: 923 loss: 3.67412724e-07
Iter: 924 loss: 3.66384398e-07
Iter: 925 loss: 3.66232399e-07
Iter: 926 loss: 3.66049164e-07
Iter: 927 loss: 3.66015456e-07
Iter: 928 loss: 3.65776174e-07
Iter: 929 loss: 3.68295218e-07
Iter: 930 loss: 3.65739311e-07
Iter: 931 loss: 3.65437415e-07
Iter: 932 loss: 3.65606581e-07
Iter: 933 loss: 3.65279561e-07
Iter: 934 loss: 3.65048834e-07
Iter: 935 loss: 3.65001569e-07
Iter: 936 loss: 3.64870573e-07
Iter: 937 loss: 3.64624299e-07
Iter: 938 loss: 3.64837604e-07
Iter: 939 loss: 3.64472157e-07
Iter: 940 loss: 3.64293669e-07
Iter: 941 loss: 3.64282897e-07
Iter: 942 loss: 3.64085565e-07
Iter: 943 loss: 3.64464597e-07
Iter: 944 loss: 3.64081757e-07
Iter: 945 loss: 3.63945787e-07
Iter: 946 loss: 3.63724098e-07
Iter: 947 loss: 3.63738366e-07
Iter: 948 loss: 3.63381133e-07
Iter: 949 loss: 3.66646134e-07
Iter: 950 loss: 3.63427091e-07
Iter: 951 loss: 3.63150548e-07
Iter: 952 loss: 3.63122382e-07
Iter: 953 loss: 3.63024327e-07
Iter: 954 loss: 3.62723426e-07
Iter: 955 loss: 3.66006276e-07
Iter: 956 loss: 3.62704526e-07
Iter: 957 loss: 3.62549571e-07
Iter: 958 loss: 3.62187933e-07
Iter: 959 loss: 3.68137307e-07
Iter: 960 loss: 3.62151894e-07
Iter: 961 loss: 3.61875351e-07
Iter: 962 loss: 3.6606977e-07
Iter: 963 loss: 3.61859605e-07
Iter: 964 loss: 3.616355e-07
Iter: 965 loss: 3.62448532e-07
Iter: 966 loss: 3.61586018e-07
Iter: 967 loss: 3.61345684e-07
Iter: 968 loss: 3.61203888e-07
Iter: 969 loss: 3.61163018e-07
Iter: 970 loss: 3.6092672e-07
Iter: 971 loss: 3.61037678e-07
Iter: 972 loss: 3.60733651e-07
Iter: 973 loss: 3.60474985e-07
Iter: 974 loss: 3.61297566e-07
Iter: 975 loss: 3.60368659e-07
Iter: 976 loss: 3.60243064e-07
Iter: 977 loss: 3.60198385e-07
Iter: 978 loss: 3.59996363e-07
Iter: 979 loss: 3.59742444e-07
Iter: 980 loss: 3.65080666e-07
Iter: 981 loss: 3.5974216e-07
Iter: 982 loss: 3.59395187e-07
Iter: 983 loss: 3.59335274e-07
Iter: 984 loss: 3.59164119e-07
Iter: 985 loss: 3.59027212e-07
Iter: 986 loss: 3.58961159e-07
Iter: 987 loss: 3.58735747e-07
Iter: 988 loss: 3.58647128e-07
Iter: 989 loss: 3.58581389e-07
Iter: 990 loss: 3.58341367e-07
Iter: 991 loss: 3.60011086e-07
Iter: 992 loss: 3.58341083e-07
Iter: 993 loss: 3.58104728e-07
Iter: 994 loss: 3.58271166e-07
Iter: 995 loss: 3.57963927e-07
Iter: 996 loss: 3.57767533e-07
Iter: 997 loss: 3.57663794e-07
Iter: 998 loss: 3.57589101e-07
Iter: 999 loss: 3.5730659e-07
Iter: 1000 loss: 3.57317589e-07
Iter: 1001 loss: 3.57058639e-07
Iter: 1002 loss: 3.56911357e-07
Iter: 1003 loss: 3.5689547e-07
Iter: 1004 loss: 3.56619068e-07
Iter: 1005 loss: 3.57161412e-07
Iter: 1006 loss: 3.56502312e-07
Iter: 1007 loss: 3.56224461e-07
Iter: 1008 loss: 3.57036299e-07
Iter: 1009 loss: 3.56121689e-07
Iter: 1010 loss: 3.5588792e-07
Iter: 1011 loss: 3.59642172e-07
Iter: 1012 loss: 3.55881667e-07
Iter: 1013 loss: 3.55755191e-07
Iter: 1014 loss: 3.555636e-07
Iter: 1015 loss: 3.60679223e-07
Iter: 1016 loss: 3.55539498e-07
Iter: 1017 loss: 3.5532e-07
Iter: 1018 loss: 3.56092016e-07
Iter: 1019 loss: 3.55266366e-07
Iter: 1020 loss: 3.54989737e-07
Iter: 1021 loss: 3.57554654e-07
Iter: 1022 loss: 3.54995109e-07
Iter: 1023 loss: 3.54805479e-07
Iter: 1024 loss: 3.54709414e-07
Iter: 1025 loss: 3.54618237e-07
Iter: 1026 loss: 3.54409394e-07
Iter: 1027 loss: 3.57559259e-07
Iter: 1028 loss: 3.5440587e-07
Iter: 1029 loss: 3.54240626e-07
Iter: 1030 loss: 3.53876203e-07
Iter: 1031 loss: 3.53909513e-07
Iter: 1032 loss: 3.5357732e-07
Iter: 1033 loss: 3.53841472e-07
Iter: 1034 loss: 3.53358359e-07
Iter: 1035 loss: 3.53233048e-07
Iter: 1036 loss: 3.53147755e-07
Iter: 1037 loss: 3.52966879e-07
Iter: 1038 loss: 3.52729046e-07
Iter: 1039 loss: 3.52720036e-07
Iter: 1040 loss: 3.52445369e-07
Iter: 1041 loss: 3.52143104e-07
Iter: 1042 loss: 3.5208825e-07
Iter: 1043 loss: 3.51728772e-07
Iter: 1044 loss: 3.53035091e-07
Iter: 1045 loss: 3.51535e-07
Iter: 1046 loss: 3.51251117e-07
Iter: 1047 loss: 3.51268e-07
Iter: 1048 loss: 3.50957805e-07
Iter: 1049 loss: 3.50858357e-07
Iter: 1050 loss: 3.50712924e-07
Iter: 1051 loss: 3.50409636e-07
Iter: 1052 loss: 3.50652215e-07
Iter: 1053 loss: 3.50276338e-07
Iter: 1054 loss: 3.50054876e-07
Iter: 1055 loss: 3.50037965e-07
Iter: 1056 loss: 3.49900972e-07
Iter: 1057 loss: 3.49713474e-07
Iter: 1058 loss: 3.49685223e-07
Iter: 1059 loss: 3.49425562e-07
Iter: 1060 loss: 3.49597883e-07
Iter: 1061 loss: 3.49260034e-07
Iter: 1062 loss: 3.49098968e-07
Iter: 1063 loss: 3.49068046e-07
Iter: 1064 loss: 3.48917723e-07
Iter: 1065 loss: 3.48544489e-07
Iter: 1066 loss: 3.53537814e-07
Iter: 1067 loss: 3.48524395e-07
Iter: 1068 loss: 3.48238785e-07
Iter: 1069 loss: 3.49282857e-07
Iter: 1070 loss: 3.48111769e-07
Iter: 1071 loss: 3.47960309e-07
Iter: 1072 loss: 3.47936378e-07
Iter: 1073 loss: 3.47817434e-07
Iter: 1074 loss: 3.47573945e-07
Iter: 1075 loss: 3.47576588e-07
Iter: 1076 loss: 3.47353705e-07
Iter: 1077 loss: 3.47488253e-07
Iter: 1078 loss: 3.47230753e-07
Iter: 1079 loss: 3.47069573e-07
Iter: 1080 loss: 3.4708512e-07
Iter: 1081 loss: 3.46910923e-07
Iter: 1082 loss: 3.47115531e-07
Iter: 1083 loss: 3.4679681e-07
Iter: 1084 loss: 3.46644384e-07
Iter: 1085 loss: 3.46401549e-07
Iter: 1086 loss: 3.52333103e-07
Iter: 1087 loss: 3.4633581e-07
Iter: 1088 loss: 3.46221839e-07
Iter: 1089 loss: 3.46181793e-07
Iter: 1090 loss: 3.45994238e-07
Iter: 1091 loss: 3.45707491e-07
Iter: 1092 loss: 3.45727017e-07
Iter: 1093 loss: 3.4540659e-07
Iter: 1094 loss: 3.46943409e-07
Iter: 1095 loss: 3.4538391e-07
Iter: 1096 loss: 3.4510083e-07
Iter: 1097 loss: 3.47456762e-07
Iter: 1098 loss: 3.45032333e-07
Iter: 1099 loss: 3.44884768e-07
Iter: 1100 loss: 3.44633747e-07
Iter: 1101 loss: 3.44633463e-07
Iter: 1102 loss: 3.44362803e-07
Iter: 1103 loss: 3.45188823e-07
Iter: 1104 loss: 3.44317584e-07
Iter: 1105 loss: 3.44198128e-07
Iter: 1106 loss: 3.4415234e-07
Iter: 1107 loss: 3.4398991e-07
Iter: 1108 loss: 3.43845841e-07
Iter: 1109 loss: 3.43876252e-07
Iter: 1110 loss: 3.43556025e-07
Iter: 1111 loss: 3.4339223e-07
Iter: 1112 loss: 3.43295e-07
Iter: 1113 loss: 3.42913523e-07
Iter: 1114 loss: 3.44324349e-07
Iter: 1115 loss: 3.42822119e-07
Iter: 1116 loss: 3.42598554e-07
Iter: 1117 loss: 3.42570218e-07
Iter: 1118 loss: 3.42364e-07
Iter: 1119 loss: 3.4246429e-07
Iter: 1120 loss: 3.42192095e-07
Iter: 1121 loss: 3.42017358e-07
Iter: 1122 loss: 3.42342076e-07
Iter: 1123 loss: 3.41947612e-07
Iter: 1124 loss: 3.41721147e-07
Iter: 1125 loss: 3.43009276e-07
Iter: 1126 loss: 3.41641282e-07
Iter: 1127 loss: 3.41500368e-07
Iter: 1128 loss: 3.41317445e-07
Iter: 1129 loss: 3.41267565e-07
Iter: 1130 loss: 3.41212058e-07
Iter: 1131 loss: 3.41159677e-07
Iter: 1132 loss: 3.41010946e-07
Iter: 1133 loss: 3.40781099e-07
Iter: 1134 loss: 3.45939611e-07
Iter: 1135 loss: 3.40802643e-07
Iter: 1136 loss: 3.4055023e-07
Iter: 1137 loss: 3.42426631e-07
Iter: 1138 loss: 3.40556539e-07
Iter: 1139 loss: 3.40380495e-07
Iter: 1140 loss: 3.40462918e-07
Iter: 1141 loss: 3.40252257e-07
Iter: 1142 loss: 3.40042732e-07
Iter: 1143 loss: 3.3987493e-07
Iter: 1144 loss: 3.39790859e-07
Iter: 1145 loss: 3.39566668e-07
Iter: 1146 loss: 3.42758142e-07
Iter: 1147 loss: 3.39563144e-07
Iter: 1148 loss: 3.39261874e-07
Iter: 1149 loss: 3.39128519e-07
Iter: 1150 loss: 3.39011592e-07
Iter: 1151 loss: 3.38897905e-07
Iter: 1152 loss: 3.38760685e-07
Iter: 1153 loss: 3.38601382e-07
Iter: 1154 loss: 3.39117832e-07
Iter: 1155 loss: 3.38566338e-07
Iter: 1156 loss: 3.38430539e-07
Iter: 1157 loss: 3.38387906e-07
Iter: 1158 loss: 3.38355733e-07
Iter: 1159 loss: 3.38130917e-07
Iter: 1160 loss: 3.39964487e-07
Iter: 1161 loss: 3.38122391e-07
Iter: 1162 loss: 3.37999893e-07
Iter: 1163 loss: 3.37958966e-07
Iter: 1164 loss: 3.37891947e-07
Iter: 1165 loss: 3.37715051e-07
Iter: 1166 loss: 3.39128661e-07
Iter: 1167 loss: 3.37731365e-07
Iter: 1168 loss: 3.37569503e-07
Iter: 1169 loss: 3.37362053e-07
Iter: 1170 loss: 3.37354635e-07
Iter: 1171 loss: 3.37325162e-07
Iter: 1172 loss: 3.37255301e-07
Iter: 1173 loss: 3.37187771e-07
Iter: 1174 loss: 3.36989245e-07
Iter: 1175 loss: 3.39304535e-07
Iter: 1176 loss: 3.36961705e-07
Iter: 1177 loss: 3.36742403e-07
Iter: 1178 loss: 3.37251265e-07
Iter: 1179 loss: 3.36623032e-07
Iter: 1180 loss: 3.3642e-07
Iter: 1181 loss: 3.36677743e-07
Iter: 1182 loss: 3.36259717e-07
Iter: 1183 loss: 3.35958703e-07
Iter: 1184 loss: 3.37072834e-07
Iter: 1185 loss: 3.35932583e-07
Iter: 1186 loss: 3.35750741e-07
Iter: 1187 loss: 3.35733915e-07
Iter: 1188 loss: 3.35629238e-07
Iter: 1189 loss: 3.35369776e-07
Iter: 1190 loss: 3.35362017e-07
Iter: 1191 loss: 3.35153345e-07
Iter: 1192 loss: 3.35161758e-07
Iter: 1193 loss: 3.35002085e-07
Iter: 1194 loss: 3.35019251e-07
Iter: 1195 loss: 3.34849176e-07
Iter: 1196 loss: 3.34667476e-07
Iter: 1197 loss: 3.35357441e-07
Iter: 1198 loss: 3.34674581e-07
Iter: 1199 loss: 3.34431604e-07
Iter: 1200 loss: 3.34445673e-07
Iter: 1201 loss: 3.34240838e-07
Iter: 1202 loss: 3.33961225e-07
Iter: 1203 loss: 3.34196756e-07
Iter: 1204 loss: 3.33803314e-07
Iter: 1205 loss: 3.33646767e-07
Iter: 1206 loss: 3.34837864e-07
Iter: 1207 loss: 3.33633949e-07
Iter: 1208 loss: 3.33434684e-07
Iter: 1209 loss: 3.33687638e-07
Iter: 1210 loss: 3.33380484e-07
Iter: 1211 loss: 3.33234937e-07
Iter: 1212 loss: 3.3325702e-07
Iter: 1213 loss: 3.3309658e-07
Iter: 1214 loss: 3.32920507e-07
Iter: 1215 loss: 3.32773851e-07
Iter: 1216 loss: 3.32734288e-07
Iter: 1217 loss: 3.32398713e-07
Iter: 1218 loss: 3.34008746e-07
Iter: 1219 loss: 3.32322145e-07
Iter: 1220 loss: 3.32171339e-07
Iter: 1221 loss: 3.32161392e-07
Iter: 1222 loss: 3.32041338e-07
Iter: 1223 loss: 3.31750613e-07
Iter: 1224 loss: 3.35581205e-07
Iter: 1225 loss: 3.3174021e-07
Iter: 1226 loss: 3.31300441e-07
Iter: 1227 loss: 3.35197939e-07
Iter: 1228 loss: 3.31300924e-07
Iter: 1229 loss: 3.31125051e-07
Iter: 1230 loss: 3.3137087e-07
Iter: 1231 loss: 3.3102765e-07
Iter: 1232 loss: 3.30793569e-07
Iter: 1233 loss: 3.32745373e-07
Iter: 1234 loss: 3.30799878e-07
Iter: 1235 loss: 3.3065939e-07
Iter: 1236 loss: 3.30441878e-07
Iter: 1237 loss: 3.35475193e-07
Iter: 1238 loss: 3.30410074e-07
Iter: 1239 loss: 3.30076091e-07
Iter: 1240 loss: 3.31120958e-07
Iter: 1241 loss: 3.30020299e-07
Iter: 1242 loss: 3.29827486e-07
Iter: 1243 loss: 3.29850167e-07
Iter: 1244 loss: 3.29715817e-07
Iter: 1245 loss: 3.2951931e-07
Iter: 1246 loss: 3.34339489e-07
Iter: 1247 loss: 3.2949859e-07
Iter: 1248 loss: 3.2926016e-07
Iter: 1249 loss: 3.29747508e-07
Iter: 1250 loss: 3.29078773e-07
Iter: 1251 loss: 3.28849922e-07
Iter: 1252 loss: 3.30696253e-07
Iter: 1253 loss: 3.2883824e-07
Iter: 1254 loss: 3.28707415e-07
Iter: 1255 loss: 3.30323871e-07
Iter: 1256 loss: 3.28629227e-07
Iter: 1257 loss: 3.28511305e-07
Iter: 1258 loss: 3.2839074e-07
Iter: 1259 loss: 3.28351575e-07
Iter: 1260 loss: 3.28219301e-07
Iter: 1261 loss: 3.28221063e-07
Iter: 1262 loss: 3.28085775e-07
Iter: 1263 loss: 3.27941507e-07
Iter: 1264 loss: 3.27900921e-07
Iter: 1265 loss: 3.27768589e-07
Iter: 1266 loss: 3.29021219e-07
Iter: 1267 loss: 3.27737467e-07
Iter: 1268 loss: 3.27529222e-07
Iter: 1269 loss: 3.27886141e-07
Iter: 1270 loss: 3.27430769e-07
Iter: 1271 loss: 3.27316513e-07
Iter: 1272 loss: 3.27375e-07
Iter: 1273 loss: 3.27220789e-07
Iter: 1274 loss: 3.27065948e-07
Iter: 1275 loss: 3.29286195e-07
Iter: 1276 loss: 3.27015755e-07
Iter: 1277 loss: 3.26864722e-07
Iter: 1278 loss: 3.26757799e-07
Iter: 1279 loss: 3.26703969e-07
Iter: 1280 loss: 3.26510019e-07
Iter: 1281 loss: 3.26674382e-07
Iter: 1282 loss: 3.26448657e-07
Iter: 1283 loss: 3.26154577e-07
Iter: 1284 loss: 3.2621648e-07
Iter: 1285 loss: 3.26053026e-07
Iter: 1286 loss: 3.25792911e-07
Iter: 1287 loss: 3.25810163e-07
Iter: 1288 loss: 3.25583528e-07
Iter: 1289 loss: 3.26316751e-07
Iter: 1290 loss: 3.2554874e-07
Iter: 1291 loss: 3.25441448e-07
Iter: 1292 loss: 3.25258725e-07
Iter: 1293 loss: 3.25225955e-07
Iter: 1294 loss: 3.24945091e-07
Iter: 1295 loss: 3.27616192e-07
Iter: 1296 loss: 3.2495e-07
Iter: 1297 loss: 3.24772429e-07
Iter: 1298 loss: 3.24886855e-07
Iter: 1299 loss: 3.24712744e-07
Iter: 1300 loss: 3.24539201e-07
Iter: 1301 loss: 3.25776682e-07
Iter: 1302 loss: 3.24531e-07
Iter: 1303 loss: 3.24455755e-07
Iter: 1304 loss: 3.24142405e-07
Iter: 1305 loss: 3.28080858e-07
Iter: 1306 loss: 3.24152523e-07
Iter: 1307 loss: 3.24042958e-07
Iter: 1308 loss: 3.24022039e-07
Iter: 1309 loss: 3.23902754e-07
Iter: 1310 loss: 3.24010529e-07
Iter: 1311 loss: 3.23848042e-07
Iter: 1312 loss: 3.23724464e-07
Iter: 1313 loss: 3.23540263e-07
Iter: 1314 loss: 3.23529321e-07
Iter: 1315 loss: 3.23347848e-07
Iter: 1316 loss: 3.24251687e-07
Iter: 1317 loss: 3.23305272e-07
Iter: 1318 loss: 3.23168877e-07
Iter: 1319 loss: 3.23446073e-07
Iter: 1320 loss: 3.23102597e-07
Iter: 1321 loss: 3.22991269e-07
Iter: 1322 loss: 3.23011022e-07
Iter: 1323 loss: 3.22903816e-07
Iter: 1324 loss: 3.22870477e-07
Iter: 1325 loss: 3.22845864e-07
Iter: 1326 loss: 3.22735559e-07
Iter: 1327 loss: 3.23599835e-07
Iter: 1328 loss: 3.22748122e-07
Iter: 1329 loss: 3.2259149e-07
Iter: 1330 loss: 3.22460039e-07
Iter: 1331 loss: 3.22429287e-07
Iter: 1332 loss: 3.22326457e-07
Iter: 1333 loss: 3.23939389e-07
Iter: 1334 loss: 3.2228715e-07
Iter: 1335 loss: 3.22133928e-07
Iter: 1336 loss: 3.22335666e-07
Iter: 1337 loss: 3.22099169e-07
Iter: 1338 loss: 3.21924119e-07
Iter: 1339 loss: 3.21626914e-07
Iter: 1340 loss: 3.21632399e-07
Iter: 1341 loss: 3.21611623e-07
Iter: 1342 loss: 3.21482759e-07
Iter: 1343 loss: 3.21355259e-07
Iter: 1344 loss: 3.21333715e-07
Iter: 1345 loss: 3.21218408e-07
Iter: 1346 loss: 3.21128937e-07
Iter: 1347 loss: 3.20919355e-07
Iter: 1348 loss: 3.208973e-07
Iter: 1349 loss: 3.20635422e-07
Iter: 1350 loss: 3.23920375e-07
Iter: 1351 loss: 3.20638378e-07
Iter: 1352 loss: 3.20521536e-07
Iter: 1353 loss: 3.20521053e-07
Iter: 1354 loss: 3.20445366e-07
Iter: 1355 loss: 3.2029169e-07
Iter: 1356 loss: 3.23074403e-07
Iter: 1357 loss: 3.20296749e-07
Iter: 1358 loss: 3.20085348e-07
Iter: 1359 loss: 3.20870754e-07
Iter: 1360 loss: 3.20036236e-07
Iter: 1361 loss: 3.19865933e-07
Iter: 1362 loss: 3.20704657e-07
Iter: 1363 loss: 3.19844958e-07
Iter: 1364 loss: 3.19712967e-07
Iter: 1365 loss: 3.19459474e-07
Iter: 1366 loss: 3.23632463e-07
Iter: 1367 loss: 3.19398339e-07
Iter: 1368 loss: 3.19159824e-07
Iter: 1369 loss: 3.19130265e-07
Iter: 1370 loss: 3.18972e-07
Iter: 1371 loss: 3.1888095e-07
Iter: 1372 loss: 3.18861964e-07
Iter: 1373 loss: 3.18678445e-07
Iter: 1374 loss: 3.19691452e-07
Iter: 1375 loss: 3.18669464e-07
Iter: 1376 loss: 3.18530454e-07
Iter: 1377 loss: 3.18769196e-07
Iter: 1378 loss: 3.18441607e-07
Iter: 1379 loss: 3.18307315e-07
Iter: 1380 loss: 3.18325476e-07
Iter: 1381 loss: 3.18198261e-07
Iter: 1382 loss: 3.18070789e-07
Iter: 1383 loss: 3.18090173e-07
Iter: 1384 loss: 3.1802395e-07
Iter: 1385 loss: 3.17819286e-07
Iter: 1386 loss: 3.18033585e-07
Iter: 1387 loss: 3.17754797e-07
Iter: 1388 loss: 3.17584664e-07
Iter: 1389 loss: 3.20011594e-07
Iter: 1390 loss: 3.17567952e-07
Iter: 1391 loss: 3.17505794e-07
Iter: 1392 loss: 3.17317529e-07
Iter: 1393 loss: 3.17304256e-07
Iter: 1394 loss: 3.17067446e-07
Iter: 1395 loss: 3.19039088e-07
Iter: 1396 loss: 3.17056362e-07
Iter: 1397 loss: 3.1679474e-07
Iter: 1398 loss: 3.16866789e-07
Iter: 1399 loss: 3.16642513e-07
Iter: 1400 loss: 3.16429379e-07
Iter: 1401 loss: 3.17918762e-07
Iter: 1402 loss: 3.16441714e-07
Iter: 1403 loss: 3.16237163e-07
Iter: 1404 loss: 3.16617673e-07
Iter: 1405 loss: 3.16191205e-07
Iter: 1406 loss: 3.15979804e-07
Iter: 1407 loss: 3.16286162e-07
Iter: 1408 loss: 3.15914519e-07
Iter: 1409 loss: 3.15775964e-07
Iter: 1410 loss: 3.17525803e-07
Iter: 1411 loss: 3.15759024e-07
Iter: 1412 loss: 3.15673589e-07
Iter: 1413 loss: 3.15693029e-07
Iter: 1414 loss: 3.15630103e-07
Iter: 1415 loss: 3.154816e-07
Iter: 1416 loss: 3.15502092e-07
Iter: 1417 loss: 3.15397955e-07
Iter: 1418 loss: 3.15241522e-07
Iter: 1419 loss: 3.16117905e-07
Iter: 1420 loss: 3.15211906e-07
Iter: 1421 loss: 3.15087902e-07
Iter: 1422 loss: 3.16325071e-07
Iter: 1423 loss: 3.15095321e-07
Iter: 1424 loss: 3.14995845e-07
Iter: 1425 loss: 3.1480738e-07
Iter: 1426 loss: 3.14822103e-07
Iter: 1427 loss: 3.14666352e-07
Iter: 1428 loss: 3.1541029e-07
Iter: 1429 loss: 3.14632445e-07
Iter: 1430 loss: 3.14440058e-07
Iter: 1431 loss: 3.15984721e-07
Iter: 1432 loss: 3.14457111e-07
Iter: 1433 loss: 3.14356612e-07
Iter: 1434 loss: 3.14296699e-07
Iter: 1435 loss: 3.14261456e-07
Iter: 1436 loss: 3.14093143e-07
Iter: 1437 loss: 3.15313741e-07
Iter: 1438 loss: 3.14135633e-07
Iter: 1439 loss: 3.14001397e-07
Iter: 1440 loss: 3.13917e-07
Iter: 1441 loss: 3.13848773e-07
Iter: 1442 loss: 3.13789087e-07
Iter: 1443 loss: 3.13804662e-07
Iter: 1444 loss: 3.13703623e-07
Iter: 1445 loss: 3.13553358e-07
Iter: 1446 loss: 3.13549691e-07
Iter: 1447 loss: 3.13338091e-07
Iter: 1448 loss: 3.13671649e-07
Iter: 1449 loss: 3.13197717e-07
Iter: 1450 loss: 3.130626e-07
Iter: 1451 loss: 3.14538795e-07
Iter: 1452 loss: 3.13090197e-07
Iter: 1453 loss: 3.12959855e-07
Iter: 1454 loss: 3.13538095e-07
Iter: 1455 loss: 3.12965739e-07
Iter: 1456 loss: 3.12857082e-07
Iter: 1457 loss: 3.12903978e-07
Iter: 1458 loss: 3.12757351e-07
Iter: 1459 loss: 3.1272279e-07
Iter: 1460 loss: 3.13024543e-07
Iter: 1461 loss: 3.12692777e-07
Iter: 1462 loss: 3.1266535e-07
Iter: 1463 loss: 3.13149513e-07
Iter: 1464 loss: 3.12616066e-07
Iter: 1465 loss: 3.12543619e-07
Iter: 1466 loss: 3.12325596e-07
Iter: 1467 loss: 3.15444e-07
Iter: 1468 loss: 3.12308089e-07
Iter: 1469 loss: 3.12235528e-07
Iter: 1470 loss: 3.12200314e-07
Iter: 1471 loss: 3.12121699e-07
Iter: 1472 loss: 3.12013412e-07
Iter: 1473 loss: 3.11988458e-07
Iter: 1474 loss: 3.11885856e-07
Iter: 1475 loss: 3.12236381e-07
Iter: 1476 loss: 3.11827591e-07
Iter: 1477 loss: 3.11744429e-07
Iter: 1478 loss: 3.11730247e-07
Iter: 1479 loss: 3.11666582e-07
Iter: 1480 loss: 3.11593311e-07
Iter: 1481 loss: 3.11590412e-07
Iter: 1482 loss: 3.11477834e-07
Iter: 1483 loss: 3.11715496e-07
Iter: 1484 loss: 3.11470899e-07
Iter: 1485 loss: 3.11355222e-07
Iter: 1486 loss: 3.11384582e-07
Iter: 1487 loss: 3.11323362e-07
Iter: 1488 loss: 3.11307616e-07
Iter: 1489 loss: 3.11235937e-07
Iter: 1490 loss: 3.11149734e-07
Iter: 1491 loss: 3.11065349e-07
Iter: 1492 loss: 3.11117077e-07
Iter: 1493 loss: 3.10908547e-07
Iter: 1494 loss: 3.12931263e-07
Iter: 1495 loss: 3.10903573e-07
Iter: 1496 loss: 3.10820809e-07
Iter: 1497 loss: 3.10881973e-07
Iter: 1498 loss: 3.10790028e-07
Iter: 1499 loss: 3.1069402e-07
Iter: 1500 loss: 3.10659573e-07
Iter: 1501 loss: 3.10547222e-07
Iter: 1502 loss: 3.10333576e-07
Iter: 1503 loss: 3.11900351e-07
Iter: 1504 loss: 3.10376322e-07
Iter: 1505 loss: 3.10270536e-07
Iter: 1506 loss: 3.10188398e-07
Iter: 1507 loss: 3.10111318e-07
Iter: 1508 loss: 3.1005672e-07
Iter: 1509 loss: 3.10064678e-07
Iter: 1510 loss: 3.09936155e-07
Iter: 1511 loss: 3.09768893e-07
Iter: 1512 loss: 3.09748202e-07
Iter: 1513 loss: 3.09632213e-07
Iter: 1514 loss: 3.09856631e-07
Iter: 1515 loss: 3.09541349e-07
Iter: 1516 loss: 3.0944642e-07
Iter: 1517 loss: 3.0965515e-07
Iter: 1518 loss: 3.0941834e-07
Iter: 1519 loss: 3.09285156e-07
Iter: 1520 loss: 3.1007491e-07
Iter: 1521 loss: 3.09229392e-07
Iter: 1522 loss: 3.09124715e-07
Iter: 1523 loss: 3.09214215e-07
Iter: 1524 loss: 3.09066678e-07
Iter: 1525 loss: 3.08962086e-07
Iter: 1526 loss: 3.09368033e-07
Iter: 1527 loss: 3.08942447e-07
Iter: 1528 loss: 3.08805767e-07
Iter: 1529 loss: 3.09216858e-07
Iter: 1530 loss: 3.08845699e-07
Iter: 1531 loss: 3.0875222e-07
Iter: 1532 loss: 3.08812844e-07
Iter: 1533 loss: 3.08709616e-07
Iter: 1534 loss: 3.08654563e-07
Iter: 1535 loss: 3.09040217e-07
Iter: 1536 loss: 3.08617444e-07
Iter: 1537 loss: 3.08526097e-07
Iter: 1538 loss: 3.08427957e-07
Iter: 1539 loss: 3.08414229e-07
Iter: 1540 loss: 3.08283916e-07
Iter: 1541 loss: 3.08609657e-07
Iter: 1542 loss: 3.08234377e-07
Iter: 1543 loss: 3.08156046e-07
Iter: 1544 loss: 3.08137146e-07
Iter: 1545 loss: 3.0810304e-07
Iter: 1546 loss: 3.07948881e-07
Iter: 1547 loss: 3.09046328e-07
Iter: 1548 loss: 3.07928701e-07
Iter: 1549 loss: 3.07826269e-07
Iter: 1550 loss: 3.09334666e-07
Iter: 1551 loss: 3.07837581e-07
Iter: 1552 loss: 3.07791169e-07
Iter: 1553 loss: 3.08325667e-07
Iter: 1554 loss: 3.07780965e-07
Iter: 1555 loss: 3.0773046e-07
Iter: 1556 loss: 3.07659292e-07
Iter: 1557 loss: 3.07643347e-07
Iter: 1558 loss: 3.0755362e-07
Iter: 1559 loss: 3.07641699e-07
Iter: 1560 loss: 3.07433254e-07
Iter: 1561 loss: 3.07377206e-07
Iter: 1562 loss: 3.07360182e-07
Iter: 1563 loss: 3.07253231e-07
Iter: 1564 loss: 3.07173565e-07
Iter: 1565 loss: 3.0717851e-07
Iter: 1566 loss: 3.07065335e-07
Iter: 1567 loss: 3.07403297e-07
Iter: 1568 loss: 3.07025914e-07
Iter: 1569 loss: 3.06919532e-07
Iter: 1570 loss: 3.08383562e-07
Iter: 1571 loss: 3.06893867e-07
Iter: 1572 loss: 3.06833783e-07
Iter: 1573 loss: 3.06714725e-07
Iter: 1574 loss: 3.09417828e-07
Iter: 1575 loss: 3.06709921e-07
Iter: 1576 loss: 3.06595666e-07
Iter: 1577 loss: 3.08022038e-07
Iter: 1578 loss: 3.0656858e-07
Iter: 1579 loss: 3.06478483e-07
Iter: 1580 loss: 3.06714e-07
Iter: 1581 loss: 3.06426813e-07
Iter: 1582 loss: 3.06369458e-07
Iter: 1583 loss: 3.063e-07
Iter: 1584 loss: 3.06287973e-07
Iter: 1585 loss: 3.06132677e-07
Iter: 1586 loss: 3.073107e-07
Iter: 1587 loss: 3.06108859e-07
Iter: 1588 loss: 3.05989829e-07
Iter: 1589 loss: 3.06002619e-07
Iter: 1590 loss: 3.05934293e-07
Iter: 1591 loss: 3.05753389e-07
Iter: 1592 loss: 3.05805202e-07
Iter: 1593 loss: 3.05636433e-07
Iter: 1594 loss: 3.05509388e-07
Iter: 1595 loss: 3.05902489e-07
Iter: 1596 loss: 3.05454648e-07
Iter: 1597 loss: 3.05291962e-07
Iter: 1598 loss: 3.05287898e-07
Iter: 1599 loss: 3.05245806e-07
Iter: 1600 loss: 3.0513624e-07
Iter: 1601 loss: 3.07121837e-07
Iter: 1602 loss: 3.0513354e-07
Iter: 1603 loss: 3.05040885e-07
Iter: 1604 loss: 3.05718885e-07
Iter: 1605 loss: 3.05004846e-07
Iter: 1606 loss: 3.0491492e-07
Iter: 1607 loss: 3.05066834e-07
Iter: 1608 loss: 3.04867029e-07
Iter: 1609 loss: 3.04750841e-07
Iter: 1610 loss: 3.04730776e-07
Iter: 1611 loss: 3.04686921e-07
Iter: 1612 loss: 3.04545722e-07
Iter: 1613 loss: 3.04680299e-07
Iter: 1614 loss: 3.04478e-07
Iter: 1615 loss: 3.04236977e-07
Iter: 1616 loss: 3.04888545e-07
Iter: 1617 loss: 3.04111637e-07
Iter: 1618 loss: 3.04068379e-07
Iter: 1619 loss: 3.03968278e-07
Iter: 1620 loss: 3.03917744e-07
Iter: 1621 loss: 3.03803176e-07
Iter: 1622 loss: 3.03805848e-07
Iter: 1623 loss: 3.03691053e-07
Iter: 1624 loss: 3.03855643e-07
Iter: 1625 loss: 3.03613717e-07
Iter: 1626 loss: 3.03573927e-07
Iter: 1627 loss: 3.03388759e-07
Iter: 1628 loss: 3.03401521e-07
Iter: 1629 loss: 3.03268763e-07
Iter: 1630 loss: 3.05204082e-07
Iter: 1631 loss: 3.03284253e-07
Iter: 1632 loss: 3.0317895e-07
Iter: 1633 loss: 3.04199773e-07
Iter: 1634 loss: 3.03151154e-07
Iter: 1635 loss: 3.03109488e-07
Iter: 1636 loss: 3.02929038e-07
Iter: 1637 loss: 3.04230326e-07
Iter: 1638 loss: 3.02884274e-07
Iter: 1639 loss: 3.02718036e-07
Iter: 1640 loss: 3.02726619e-07
Iter: 1641 loss: 3.02581157e-07
Iter: 1642 loss: 3.02927248e-07
Iter: 1643 loss: 3.02546425e-07
Iter: 1644 loss: 3.02421711e-07
Iter: 1645 loss: 3.02381295e-07
Iter: 1646 loss: 3.02370779e-07
Iter: 1647 loss: 3.02211959e-07
Iter: 1648 loss: 3.0348474e-07
Iter: 1649 loss: 3.02214744e-07
Iter: 1650 loss: 3.02081276e-07
Iter: 1651 loss: 3.02186265e-07
Iter: 1652 loss: 3.02009255e-07
Iter: 1653 loss: 3.0195028e-07
Iter: 1654 loss: 3.0198774e-07
Iter: 1655 loss: 3.01913332e-07
Iter: 1656 loss: 3.01791403e-07
Iter: 1657 loss: 3.02783121e-07
Iter: 1658 loss: 3.01800299e-07
Iter: 1659 loss: 3.016996e-07
Iter: 1660 loss: 3.01577671e-07
Iter: 1661 loss: 3.05516608e-07
Iter: 1662 loss: 3.01554905e-07
Iter: 1663 loss: 3.01432863e-07
Iter: 1664 loss: 3.02222503e-07
Iter: 1665 loss: 3.01411433e-07
Iter: 1666 loss: 3.01343107e-07
Iter: 1667 loss: 3.01981657e-07
Iter: 1668 loss: 3.01297575e-07
Iter: 1669 loss: 3.01183462e-07
Iter: 1670 loss: 3.01178119e-07
Iter: 1671 loss: 3.01107661e-07
Iter: 1672 loss: 3.01010459e-07
Iter: 1673 loss: 3.01394493e-07
Iter: 1674 loss: 3.01016826e-07
Iter: 1675 loss: 3.00879748e-07
Iter: 1676 loss: 3.01678e-07
Iter: 1677 loss: 3.00854111e-07
Iter: 1678 loss: 3.00796927e-07
Iter: 1679 loss: 3.00690687e-07
Iter: 1680 loss: 3.00661895e-07
Iter: 1681 loss: 3.0059411e-07
Iter: 1682 loss: 3.01961279e-07
Iter: 1683 loss: 3.00598543e-07
Iter: 1684 loss: 3.00522174e-07
Iter: 1685 loss: 3.00639499e-07
Iter: 1686 loss: 3.00422755e-07
Iter: 1687 loss: 3.00383107e-07
Iter: 1688 loss: 3.00179067e-07
Iter: 1689 loss: 3.00194273e-07
Iter: 1690 loss: 3.00093262e-07
Iter: 1691 loss: 3.00107075e-07
Iter: 1692 loss: 3.00007144e-07
Iter: 1693 loss: 2.99986681e-07
Iter: 1694 loss: 2.99966445e-07
Iter: 1695 loss: 2.99821949e-07
Iter: 1696 loss: 2.99700361e-07
Iter: 1697 loss: 2.99679755e-07
Iter: 1698 loss: 2.99548191e-07
Iter: 1699 loss: 2.99550322e-07
Iter: 1700 loss: 2.9949959e-07
Iter: 1701 loss: 2.99457724e-07
Iter: 1702 loss: 2.99404348e-07
Iter: 1703 loss: 2.9932059e-07
Iter: 1704 loss: 2.99132637e-07
Iter: 1705 loss: 2.99099753e-07
Iter: 1706 loss: 2.99009173e-07
Iter: 1707 loss: 2.9898905e-07
Iter: 1708 loss: 2.98870305e-07
Iter: 1709 loss: 2.98851063e-07
Iter: 1710 loss: 2.9876017e-07
Iter: 1711 loss: 2.98653219e-07
Iter: 1712 loss: 2.98542659e-07
Iter: 1713 loss: 2.98520263e-07
Iter: 1714 loss: 2.98345782e-07
Iter: 1715 loss: 2.9909458e-07
Iter: 1716 loss: 2.98307242e-07
Iter: 1717 loss: 2.98195857e-07
Iter: 1718 loss: 2.98220868e-07
Iter: 1719 loss: 2.98127134e-07
Iter: 1720 loss: 2.97949413e-07
Iter: 1721 loss: 3.0077689e-07
Iter: 1722 loss: 2.97897259e-07
Iter: 1723 loss: 2.9782791e-07
Iter: 1724 loss: 2.97813017e-07
Iter: 1725 loss: 2.9770689e-07
Iter: 1726 loss: 2.97571773e-07
Iter: 1727 loss: 2.97528857e-07
Iter: 1728 loss: 2.97369269e-07
Iter: 1729 loss: 2.97913942e-07
Iter: 1730 loss: 2.97292502e-07
Iter: 1731 loss: 2.97122426e-07
Iter: 1732 loss: 2.99040551e-07
Iter: 1733 loss: 2.97140161e-07
Iter: 1734 loss: 2.97000895e-07
Iter: 1735 loss: 2.96940868e-07
Iter: 1736 loss: 2.96926885e-07
Iter: 1737 loss: 2.96800636e-07
Iter: 1738 loss: 2.96964771e-07
Iter: 1739 loss: 2.96729326e-07
Iter: 1740 loss: 2.9665739e-07
Iter: 1741 loss: 2.96647727e-07
Iter: 1742 loss: 2.96561524e-07
Iter: 1743 loss: 2.96627121e-07
Iter: 1744 loss: 2.96545778e-07
Iter: 1745 loss: 2.96420097e-07
Iter: 1746 loss: 2.96299618e-07
Iter: 1747 loss: 2.96316671e-07
Iter: 1748 loss: 2.9619062e-07
Iter: 1749 loss: 2.9619946e-07
Iter: 1750 loss: 2.96091059e-07
Iter: 1751 loss: 2.96128349e-07
Iter: 1752 loss: 2.95968903e-07
Iter: 1753 loss: 2.95834212e-07
Iter: 1754 loss: 2.96085176e-07
Iter: 1755 loss: 2.95742325e-07
Iter: 1756 loss: 2.95645151e-07
Iter: 1757 loss: 2.95638557e-07
Iter: 1758 loss: 2.95629434e-07
Iter: 1759 loss: 2.95492612e-07
Iter: 1760 loss: 2.978e-07
Iter: 1761 loss: 2.95512109e-07
Iter: 1762 loss: 2.95400326e-07
Iter: 1763 loss: 2.95425821e-07
Iter: 1764 loss: 2.95331176e-07
Iter: 1765 loss: 2.95233e-07
Iter: 1766 loss: 2.95252619e-07
Iter: 1767 loss: 2.95145242e-07
Iter: 1768 loss: 2.95332484e-07
Iter: 1769 loss: 2.95083282e-07
Iter: 1770 loss: 2.94957772e-07
Iter: 1771 loss: 2.94823622e-07
Iter: 1772 loss: 2.94800714e-07
Iter: 1773 loss: 2.94703824e-07
Iter: 1774 loss: 2.94647236e-07
Iter: 1775 loss: 2.94554e-07
Iter: 1776 loss: 2.94368505e-07
Iter: 1777 loss: 2.9438354e-07
Iter: 1778 loss: 2.94203147e-07
Iter: 1779 loss: 2.94603382e-07
Iter: 1780 loss: 2.94147156e-07
Iter: 1781 loss: 2.93992457e-07
Iter: 1782 loss: 2.93868311e-07
Iter: 1783 loss: 2.93768466e-07
Iter: 1784 loss: 2.93622918e-07
Iter: 1785 loss: 2.94719484e-07
Iter: 1786 loss: 2.93586766e-07
Iter: 1787 loss: 2.93474443e-07
Iter: 1788 loss: 2.93560646e-07
Iter: 1789 loss: 2.93414161e-07
Iter: 1790 loss: 2.93211372e-07
Iter: 1791 loss: 2.93570395e-07
Iter: 1792 loss: 2.93163765e-07
Iter: 1793 loss: 2.93038283e-07
Iter: 1794 loss: 2.93625902e-07
Iter: 1795 loss: 2.93011425e-07
Iter: 1796 loss: 2.92881907e-07
Iter: 1797 loss: 2.93403758e-07
Iter: 1798 loss: 2.92835153e-07
Iter: 1799 loss: 2.92708535e-07
Iter: 1800 loss: 2.9250026e-07
Iter: 1801 loss: 2.95941447e-07
Iter: 1802 loss: 2.92501738e-07
Iter: 1803 loss: 2.92259983e-07
Iter: 1804 loss: 2.93594582e-07
Iter: 1805 loss: 2.92180658e-07
Iter: 1806 loss: 2.9192725e-07
Iter: 1807 loss: 2.92033434e-07
Iter: 1808 loss: 2.91773205e-07
Iter: 1809 loss: 2.91911789e-07
Iter: 1810 loss: 2.91646131e-07
Iter: 1811 loss: 2.91610036e-07
Iter: 1812 loss: 2.91514056e-07
Iter: 1813 loss: 2.91477875e-07
Iter: 1814 loss: 2.91355377e-07
Iter: 1815 loss: 2.91740491e-07
Iter: 1816 loss: 2.91312858e-07
Iter: 1817 loss: 2.91115e-07
Iter: 1818 loss: 2.91263888e-07
Iter: 1819 loss: 2.90981603e-07
Iter: 1820 loss: 2.90863937e-07
Iter: 1821 loss: 2.90702161e-07
Iter: 1822 loss: 2.90656146e-07
Iter: 1823 loss: 2.90487435e-07
Iter: 1824 loss: 2.9045745e-07
Iter: 1825 loss: 2.90352773e-07
Iter: 1826 loss: 2.90155754e-07
Iter: 1827 loss: 2.90123666e-07
Iter: 1828 loss: 2.89998155e-07
Iter: 1829 loss: 2.90902079e-07
Iter: 1830 loss: 2.89974082e-07
Iter: 1831 loss: 2.89860679e-07
Iter: 1832 loss: 2.89943e-07
Iter: 1833 loss: 2.89791302e-07
Iter: 1834 loss: 2.8961631e-07
Iter: 1835 loss: 2.91317036e-07
Iter: 1836 loss: 2.89662438e-07
Iter: 1837 loss: 2.89511689e-07
Iter: 1838 loss: 2.89921218e-07
Iter: 1839 loss: 2.89479573e-07
Iter: 1840 loss: 2.8937751e-07
Iter: 1841 loss: 2.89209879e-07
Iter: 1842 loss: 2.91142555e-07
Iter: 1843 loss: 2.89198084e-07
Iter: 1844 loss: 2.88993647e-07
Iter: 1845 loss: 2.91216168e-07
Iter: 1846 loss: 2.88989128e-07
Iter: 1847 loss: 2.88926827e-07
Iter: 1848 loss: 2.88896047e-07
Iter: 1849 loss: 2.8886069e-07
Iter: 1850 loss: 2.8871537e-07
Iter: 1851 loss: 2.90525946e-07
Iter: 1852 loss: 2.88702097e-07
Iter: 1853 loss: 2.8852395e-07
Iter: 1854 loss: 2.90187188e-07
Iter: 1855 loss: 2.88547795e-07
Iter: 1856 loss: 2.88447751e-07
Iter: 1857 loss: 2.88859695e-07
Iter: 1858 loss: 2.88451389e-07
Iter: 1859 loss: 2.88367232e-07
Iter: 1860 loss: 2.88281058e-07
Iter: 1861 loss: 2.88279296e-07
Iter: 1862 loss: 2.88141621e-07
Iter: 1863 loss: 2.88168025e-07
Iter: 1864 loss: 2.88102427e-07
Iter: 1865 loss: 2.87952361e-07
Iter: 1866 loss: 2.90308208e-07
Iter: 1867 loss: 2.87938349e-07
Iter: 1868 loss: 2.87779443e-07
Iter: 1869 loss: 2.88338924e-07
Iter: 1870 loss: 2.87748975e-07
Iter: 1871 loss: 2.87630257e-07
Iter: 1872 loss: 2.88089808e-07
Iter: 1873 loss: 2.87552325e-07
Iter: 1874 loss: 2.8745535e-07
Iter: 1875 loss: 2.87335837e-07
Iter: 1876 loss: 2.87300708e-07
Iter: 1877 loss: 2.87029224e-07
Iter: 1878 loss: 2.88072499e-07
Iter: 1879 loss: 2.86994094e-07
Iter: 1880 loss: 2.87012199e-07
Iter: 1881 loss: 2.86881914e-07
Iter: 1882 loss: 2.86799207e-07
Iter: 1883 loss: 2.86710105e-07
Iter: 1884 loss: 2.86702857e-07
Iter: 1885 loss: 2.86531844e-07
Iter: 1886 loss: 2.86340082e-07
Iter: 1887 loss: 2.86333801e-07
Iter: 1888 loss: 2.86190385e-07
Iter: 1889 loss: 2.86173076e-07
Iter: 1890 loss: 2.86086276e-07
Iter: 1891 loss: 2.86005417e-07
Iter: 1892 loss: 2.85942974e-07
Iter: 1893 loss: 2.85821955e-07
Iter: 1894 loss: 2.85970827e-07
Iter: 1895 loss: 2.85748115e-07
Iter: 1896 loss: 2.85592279e-07
Iter: 1897 loss: 2.86483186e-07
Iter: 1898 loss: 2.85526227e-07
Iter: 1899 loss: 2.85406401e-07
Iter: 1900 loss: 2.85204607e-07
Iter: 1901 loss: 2.85216146e-07
Iter: 1902 loss: 2.85091829e-07
Iter: 1903 loss: 2.85111327e-07
Iter: 1904 loss: 2.85000937e-07
Iter: 1905 loss: 2.85033252e-07
Iter: 1906 loss: 2.84945457e-07
Iter: 1907 loss: 2.84826797e-07
Iter: 1908 loss: 2.84701372e-07
Iter: 1909 loss: 2.88456022e-07
Iter: 1910 loss: 2.84691396e-07
Iter: 1911 loss: 2.84533826e-07
Iter: 1912 loss: 2.85943855e-07
Iter: 1913 loss: 2.84544683e-07
Iter: 1914 loss: 2.84397714e-07
Iter: 1915 loss: 2.84213201e-07
Iter: 1916 loss: 2.8419322e-07
Iter: 1917 loss: 2.83951806e-07
Iter: 1918 loss: 2.83669124e-07
Iter: 1919 loss: 2.83627259e-07
Iter: 1920 loss: 2.83307287e-07
Iter: 1921 loss: 2.85039533e-07
Iter: 1922 loss: 2.83310811e-07
Iter: 1923 loss: 2.83136046e-07
Iter: 1924 loss: 2.85404553e-07
Iter: 1925 loss: 2.83135591e-07
Iter: 1926 loss: 2.83004738e-07
Iter: 1927 loss: 2.8311004e-07
Iter: 1928 loss: 2.82961224e-07
Iter: 1929 loss: 2.82848589e-07
Iter: 1930 loss: 2.83527811e-07
Iter: 1931 loss: 2.82817524e-07
Iter: 1932 loss: 2.82739336e-07
Iter: 1933 loss: 2.82818235e-07
Iter: 1934 loss: 2.8266831e-07
Iter: 1935 loss: 2.82539276e-07
Iter: 1936 loss: 2.82522933e-07
Iter: 1937 loss: 2.82457052e-07
Iter: 1938 loss: 2.82199522e-07
Iter: 1939 loss: 2.8356186e-07
Iter: 1940 loss: 2.8217147e-07
Iter: 1941 loss: 2.82044937e-07
Iter: 1942 loss: 2.82405352e-07
Iter: 1943 loss: 2.81988264e-07
Iter: 1944 loss: 2.81836435e-07
Iter: 1945 loss: 2.82462025e-07
Iter: 1946 loss: 2.81823532e-07
Iter: 1947 loss: 2.8163916e-07
Iter: 1948 loss: 2.81377766e-07
Iter: 1949 loss: 2.81347582e-07
Iter: 1950 loss: 2.8105552e-07
Iter: 1951 loss: 2.83256e-07
Iter: 1952 loss: 2.81071181e-07
Iter: 1953 loss: 2.80907443e-07
Iter: 1954 loss: 2.81033323e-07
Iter: 1955 loss: 2.80822263e-07
Iter: 1956 loss: 2.80659719e-07
Iter: 1957 loss: 2.81483494e-07
Iter: 1958 loss: 2.80621464e-07
Iter: 1959 loss: 2.8045207e-07
Iter: 1960 loss: 2.81505578e-07
Iter: 1961 loss: 2.80423535e-07
Iter: 1962 loss: 2.80313827e-07
Iter: 1963 loss: 2.8055058e-07
Iter: 1964 loss: 2.80297655e-07
Iter: 1965 loss: 2.8020483e-07
Iter: 1966 loss: 2.80522386e-07
Iter: 1967 loss: 2.80121242e-07
Iter: 1968 loss: 2.8002583e-07
Iter: 1969 loss: 2.79809456e-07
Iter: 1970 loss: 2.79828754e-07
Iter: 1971 loss: 2.79646201e-07
Iter: 1972 loss: 2.79609367e-07
Iter: 1973 loss: 2.79477121e-07
Iter: 1974 loss: 2.79331289e-07
Iter: 1975 loss: 2.79298746e-07
Iter: 1976 loss: 2.79055286e-07
Iter: 1977 loss: 2.80510591e-07
Iter: 1978 loss: 2.79042524e-07
Iter: 1979 loss: 2.78794118e-07
Iter: 1980 loss: 2.7993292e-07
Iter: 1981 loss: 2.78791731e-07
Iter: 1982 loss: 2.78646951e-07
Iter: 1983 loss: 2.78666079e-07
Iter: 1984 loss: 2.78582519e-07
Iter: 1985 loss: 2.78408152e-07
Iter: 1986 loss: 2.78367622e-07
Iter: 1987 loss: 2.78222871e-07
Iter: 1988 loss: 2.7802281e-07
Iter: 1989 loss: 2.79699094e-07
Iter: 1990 loss: 2.77997373e-07
Iter: 1991 loss: 2.7788596e-07
Iter: 1992 loss: 2.77869134e-07
Iter: 1993 loss: 2.77775655e-07
Iter: 1994 loss: 2.77635877e-07
Iter: 1995 loss: 2.8096585e-07
Iter: 1996 loss: 2.77607171e-07
Iter: 1997 loss: 2.77512811e-07
Iter: 1998 loss: 2.79824519e-07
Iter: 1999 loss: 2.77518495e-07
Iter: 2000 loss: 2.77357628e-07
Iter: 2001 loss: 2.77404439e-07
Iter: 2002 loss: 2.77296806e-07
Iter: 2003 loss: 2.77179936e-07
Iter: 2004 loss: 2.77846425e-07
Iter: 2005 loss: 2.7718562e-07
Iter: 2006 loss: 2.77071962e-07
Iter: 2007 loss: 2.76925334e-07
Iter: 2008 loss: 2.76926187e-07
Iter: 2009 loss: 2.76782941e-07
Iter: 2010 loss: 2.76755856e-07
Iter: 2011 loss: 2.76683409e-07
Iter: 2012 loss: 2.76546871e-07
Iter: 2013 loss: 2.76529306e-07
Iter: 2014 loss: 2.76431336e-07
Iter: 2015 loss: 2.76173836e-07
Iter: 2016 loss: 2.80534607e-07
Iter: 2017 loss: 2.7617935e-07
Iter: 2018 loss: 2.7591966e-07
Iter: 2019 loss: 2.77767725e-07
Iter: 2020 loss: 2.75908207e-07
Iter: 2021 loss: 2.75771072e-07
Iter: 2022 loss: 2.76194555e-07
Iter: 2023 loss: 2.75699705e-07
Iter: 2024 loss: 2.75548672e-07
Iter: 2025 loss: 2.7647323e-07
Iter: 2026 loss: 2.75541709e-07
Iter: 2027 loss: 2.7539491e-07
Iter: 2028 loss: 2.75707094e-07
Iter: 2029 loss: 2.75368478e-07
Iter: 2030 loss: 2.75284265e-07
Iter: 2031 loss: 2.75566947e-07
Iter: 2032 loss: 2.75274544e-07
Iter: 2033 loss: 2.75230065e-07
Iter: 2034 loss: 2.75327807e-07
Iter: 2035 loss: 2.75166769e-07
Iter: 2036 loss: 2.75072665e-07
Iter: 2037 loss: 2.75032846e-07
Iter: 2038 loss: 2.74972592e-07
Iter: 2039 loss: 2.74840517e-07
Iter: 2040 loss: 2.7637978e-07
Iter: 2041 loss: 2.74869365e-07
Iter: 2042 loss: 2.7478913e-07
Iter: 2043 loss: 2.74586e-07
Iter: 2044 loss: 2.7701293e-07
Iter: 2045 loss: 2.74559369e-07
Iter: 2046 loss: 2.74345638e-07
Iter: 2047 loss: 2.75244673e-07
Iter: 2048 loss: 2.7433137e-07
Iter: 2049 loss: 2.74218962e-07
Iter: 2050 loss: 2.74150409e-07
Iter: 2051 loss: 2.7412554e-07
Iter: 2052 loss: 2.73963821e-07
Iter: 2053 loss: 2.76138707e-07
Iter: 2054 loss: 2.73965583e-07
Iter: 2055 loss: 2.73751084e-07
Iter: 2056 loss: 2.74563831e-07
Iter: 2057 loss: 2.73714249e-07
Iter: 2058 loss: 2.7360943e-07
Iter: 2059 loss: 2.74139609e-07
Iter: 2060 loss: 2.73583e-07
Iter: 2061 loss: 2.73467833e-07
Iter: 2062 loss: 2.74404897e-07
Iter: 2063 loss: 2.73464309e-07
Iter: 2064 loss: 2.7332743e-07
Iter: 2065 loss: 2.7317094e-07
Iter: 2066 loss: 2.73165597e-07
Iter: 2067 loss: 2.73017605e-07
Iter: 2068 loss: 2.73589649e-07
Iter: 2069 loss: 2.72945215e-07
Iter: 2070 loss: 2.72812144e-07
Iter: 2071 loss: 2.73522772e-07
Iter: 2072 loss: 2.72795859e-07
Iter: 2073 loss: 2.72645735e-07
Iter: 2074 loss: 2.73492645e-07
Iter: 2075 loss: 2.72613931e-07
Iter: 2076 loss: 2.7254103e-07
Iter: 2077 loss: 2.72507407e-07
Iter: 2078 loss: 2.72418959e-07
Iter: 2079 loss: 2.72308966e-07
Iter: 2080 loss: 2.73421819e-07
Iter: 2081 loss: 2.72339804e-07
Iter: 2082 loss: 2.72189084e-07
Iter: 2083 loss: 2.72018269e-07
Iter: 2084 loss: 2.76363636e-07
Iter: 2085 loss: 2.72001415e-07
Iter: 2086 loss: 2.71858653e-07
Iter: 2087 loss: 2.74292944e-07
Iter: 2088 loss: 2.7185024e-07
Iter: 2089 loss: 2.71722115e-07
Iter: 2090 loss: 2.72230409e-07
Iter: 2091 loss: 2.71658649e-07
Iter: 2092 loss: 2.71534532e-07
Iter: 2093 loss: 2.71327508e-07
Iter: 2094 loss: 2.75176461e-07
Iter: 2095 loss: 2.71256056e-07
Iter: 2096 loss: 2.71177498e-07
Iter: 2097 loss: 2.71138873e-07
Iter: 2098 loss: 2.70972322e-07
Iter: 2099 loss: 2.71265179e-07
Iter: 2100 loss: 2.70921447e-07
Iter: 2101 loss: 2.70828821e-07
Iter: 2102 loss: 2.70622365e-07
Iter: 2103 loss: 2.74999707e-07
Iter: 2104 loss: 2.70616e-07
Iter: 2105 loss: 2.70385414e-07
Iter: 2106 loss: 2.71795216e-07
Iter: 2107 loss: 2.70327234e-07
Iter: 2108 loss: 2.70245152e-07
Iter: 2109 loss: 2.70213746e-07
Iter: 2110 loss: 2.70134791e-07
Iter: 2111 loss: 2.69919525e-07
Iter: 2112 loss: 2.71769892e-07
Iter: 2113 loss: 2.69835652e-07
Iter: 2114 loss: 2.69401284e-07
Iter: 2115 loss: 2.69157113e-07
Iter: 2116 loss: 2.69024042e-07
Iter: 2117 loss: 2.68852318e-07
Iter: 2118 loss: 2.68744031e-07
Iter: 2119 loss: 2.6852743e-07
Iter: 2120 loss: 2.68531949e-07
Iter: 2121 loss: 2.68299516e-07
Iter: 2122 loss: 2.68032835e-07
Iter: 2123 loss: 2.68279905e-07
Iter: 2124 loss: 2.67794832e-07
Iter: 2125 loss: 2.67690893e-07
Iter: 2126 loss: 2.67703939e-07
Iter: 2127 loss: 2.675377e-07
Iter: 2128 loss: 2.67631e-07
Iter: 2129 loss: 2.67463719e-07
Iter: 2130 loss: 2.67316551e-07
Iter: 2131 loss: 2.67444136e-07
Iter: 2132 loss: 2.67256553e-07
Iter: 2133 loss: 2.6710714e-07
Iter: 2134 loss: 2.68772055e-07
Iter: 2135 loss: 2.67098159e-07
Iter: 2136 loss: 2.67038843e-07
Iter: 2137 loss: 2.66780091e-07
Iter: 2138 loss: 2.6822056e-07
Iter: 2139 loss: 2.6670557e-07
Iter: 2140 loss: 2.66297263e-07
Iter: 2141 loss: 2.68893018e-07
Iter: 2142 loss: 2.6628814e-07
Iter: 2143 loss: 2.66126733e-07
Iter: 2144 loss: 2.66101182e-07
Iter: 2145 loss: 2.65958903e-07
Iter: 2146 loss: 2.6598434e-07
Iter: 2147 loss: 2.65837201e-07
Iter: 2148 loss: 2.6564453e-07
Iter: 2149 loss: 2.6566741e-07
Iter: 2150 loss: 2.6553937e-07
Iter: 2151 loss: 2.65418521e-07
Iter: 2152 loss: 2.65770865e-07
Iter: 2153 loss: 2.65350053e-07
Iter: 2154 loss: 2.6525e-07
Iter: 2155 loss: 2.67094549e-07
Iter: 2156 loss: 2.65230142e-07
Iter: 2157 loss: 2.65131121e-07
Iter: 2158 loss: 2.64950046e-07
Iter: 2159 loss: 2.6495178e-07
Iter: 2160 loss: 2.64849717e-07
Iter: 2161 loss: 2.6483778e-07
Iter: 2162 loss: 2.64738389e-07
Iter: 2163 loss: 2.64574538e-07
Iter: 2164 loss: 2.66898269e-07
Iter: 2165 loss: 2.64507747e-07
Iter: 2166 loss: 2.64407e-07
Iter: 2167 loss: 2.6438272e-07
Iter: 2168 loss: 2.64274746e-07
Iter: 2169 loss: 2.64353503e-07
Iter: 2170 loss: 2.64246978e-07
Iter: 2171 loss: 2.64103733e-07
Iter: 2172 loss: 2.64089067e-07
Iter: 2173 loss: 2.64041944e-07
Iter: 2174 loss: 2.63900262e-07
Iter: 2175 loss: 2.64343385e-07
Iter: 2176 loss: 2.63836228e-07
Iter: 2177 loss: 2.6374488e-07
Iter: 2178 loss: 2.63730357e-07
Iter: 2179 loss: 2.63679709e-07
Iter: 2180 loss: 2.63505285e-07
Iter: 2181 loss: 2.63699803e-07
Iter: 2182 loss: 2.63351296e-07
Iter: 2183 loss: 2.62949726e-07
Iter: 2184 loss: 2.63611611e-07
Iter: 2185 loss: 2.6277894e-07
Iter: 2186 loss: 2.62779167e-07
Iter: 2187 loss: 2.62616567e-07
Iter: 2188 loss: 2.62477556e-07
Iter: 2189 loss: 2.62380922e-07
Iter: 2190 loss: 2.62269339e-07
Iter: 2191 loss: 2.62104095e-07
Iter: 2192 loss: 2.62570154e-07
Iter: 2193 loss: 2.62040032e-07
Iter: 2194 loss: 2.61863875e-07
Iter: 2195 loss: 2.61847049e-07
Iter: 2196 loss: 2.61774886e-07
Iter: 2197 loss: 2.61720629e-07
Iter: 2198 loss: 2.61683141e-07
Iter: 2199 loss: 2.61511758e-07
Iter: 2200 loss: 2.62479887e-07
Iter: 2201 loss: 2.61525372e-07
Iter: 2202 loss: 2.61440135e-07
Iter: 2203 loss: 2.61386305e-07
Iter: 2204 loss: 2.61372492e-07
Iter: 2205 loss: 2.6127708e-07
Iter: 2206 loss: 2.61141849e-07
Iter: 2207 loss: 2.61135114e-07
Iter: 2208 loss: 2.60896201e-07
Iter: 2209 loss: 2.61824169e-07
Iter: 2210 loss: 2.60861071e-07
Iter: 2211 loss: 2.60722032e-07
Iter: 2212 loss: 2.60739114e-07
Iter: 2213 loss: 2.60658908e-07
Iter: 2214 loss: 2.60487411e-07
Iter: 2215 loss: 2.61864386e-07
Iter: 2216 loss: 2.60439663e-07
Iter: 2217 loss: 2.60206804e-07
Iter: 2218 loss: 2.60938265e-07
Iter: 2219 loss: 2.60167695e-07
Iter: 2220 loss: 2.60142571e-07
Iter: 2221 loss: 2.60055089e-07
Iter: 2222 loss: 2.60026e-07
Iter: 2223 loss: 2.59877766e-07
Iter: 2224 loss: 2.60842398e-07
Iter: 2225 loss: 2.59880494e-07
Iter: 2226 loss: 2.59800572e-07
Iter: 2227 loss: 2.59815863e-07
Iter: 2228 loss: 2.59714056e-07
Iter: 2229 loss: 2.60357098e-07
Iter: 2230 loss: 2.59701523e-07
Iter: 2231 loss: 2.59645446e-07
Iter: 2232 loss: 2.59599517e-07
Iter: 2233 loss: 2.59608896e-07
Iter: 2234 loss: 2.59454794e-07
Iter: 2235 loss: 2.5971795e-07
Iter: 2236 loss: 2.59375867e-07
Iter: 2237 loss: 2.59254819e-07
Iter: 2238 loss: 2.59216876e-07
Iter: 2239 loss: 2.59165887e-07
Iter: 2240 loss: 2.59036142e-07
Iter: 2241 loss: 2.59349378e-07
Iter: 2242 loss: 2.58960057e-07
Iter: 2243 loss: 2.588163e-07
Iter: 2244 loss: 2.59508539e-07
Iter: 2245 loss: 2.58767358e-07
Iter: 2246 loss: 2.5877074e-07
Iter: 2247 loss: 2.58700652e-07
Iter: 2248 loss: 2.58682405e-07
Iter: 2249 loss: 2.58581622e-07
Iter: 2250 loss: 2.60294854e-07
Iter: 2251 loss: 2.58562579e-07
Iter: 2252 loss: 2.58451394e-07
Iter: 2253 loss: 2.58544105e-07
Iter: 2254 loss: 2.58385796e-07
Iter: 2255 loss: 2.58308859e-07
Iter: 2256 loss: 2.59626944e-07
Iter: 2257 loss: 2.58314685e-07
Iter: 2258 loss: 2.5821123e-07
Iter: 2259 loss: 2.58134861e-07
Iter: 2260 loss: 2.58069633e-07
Iter: 2261 loss: 2.57971863e-07
Iter: 2262 loss: 2.57942503e-07
Iter: 2263 loss: 2.57896147e-07
Iter: 2264 loss: 2.57714362e-07
Iter: 2265 loss: 2.59089632e-07
Iter: 2266 loss: 2.57715556e-07
Iter: 2267 loss: 2.57550198e-07
Iter: 2268 loss: 2.57642228e-07
Iter: 2269 loss: 2.57429804e-07
Iter: 2270 loss: 2.57291362e-07
Iter: 2271 loss: 2.57843851e-07
Iter: 2272 loss: 2.57289201e-07
Iter: 2273 loss: 2.57162156e-07
Iter: 2274 loss: 2.57437961e-07
Iter: 2275 loss: 2.57083855e-07
Iter: 2276 loss: 2.56955758e-07
Iter: 2277 loss: 2.56723865e-07
Iter: 2278 loss: 2.56753367e-07
Iter: 2279 loss: 2.56545775e-07
Iter: 2280 loss: 2.5779218e-07
Iter: 2281 loss: 2.56562231e-07
Iter: 2282 loss: 2.56480689e-07
Iter: 2283 loss: 2.56474038e-07
Iter: 2284 loss: 2.56389029e-07
Iter: 2285 loss: 2.56322153e-07
Iter: 2286 loss: 2.56258176e-07
Iter: 2287 loss: 2.56196131e-07
Iter: 2288 loss: 2.56287592e-07
Iter: 2289 loss: 2.56158387e-07
Iter: 2290 loss: 2.56078152e-07
Iter: 2291 loss: 2.56023441e-07
Iter: 2292 loss: 2.55985668e-07
Iter: 2293 loss: 2.55963613e-07
Iter: 2294 loss: 2.55918764e-07
Iter: 2295 loss: 2.55858509e-07
Iter: 2296 loss: 2.55796692e-07
Iter: 2297 loss: 2.55765599e-07
Iter: 2298 loss: 2.55667828e-07
Iter: 2299 loss: 2.56112855e-07
Iter: 2300 loss: 2.55580261e-07
Iter: 2301 loss: 2.55482945e-07
Iter: 2302 loss: 2.55629089e-07
Iter: 2303 loss: 2.55383185e-07
Iter: 2304 loss: 2.55263785e-07
Iter: 2305 loss: 2.5549221e-07
Iter: 2306 loss: 2.55247926e-07
Iter: 2307 loss: 2.55128157e-07
Iter: 2308 loss: 2.56131642e-07
Iter: 2309 loss: 2.55122416e-07
Iter: 2310 loss: 2.55069949e-07
Iter: 2311 loss: 2.54959559e-07
Iter: 2312 loss: 2.5493668e-07
Iter: 2313 loss: 2.54843542e-07
Iter: 2314 loss: 2.56248427e-07
Iter: 2315 loss: 2.54829331e-07
Iter: 2316 loss: 2.54710443e-07
Iter: 2317 loss: 2.55242838e-07
Iter: 2318 loss: 2.54694442e-07
Iter: 2319 loss: 2.54584506e-07
Iter: 2320 loss: 2.54382655e-07
Iter: 2321 loss: 2.57964075e-07
Iter: 2322 loss: 2.54390358e-07
Iter: 2323 loss: 2.54217298e-07
Iter: 2324 loss: 2.54819099e-07
Iter: 2325 loss: 2.54163524e-07
Iter: 2326 loss: 2.54013713e-07
Iter: 2327 loss: 2.56413045e-07
Iter: 2328 loss: 2.53994159e-07
Iter: 2329 loss: 2.53831786e-07
Iter: 2330 loss: 2.53921797e-07
Iter: 2331 loss: 2.5373879e-07
Iter: 2332 loss: 2.53583465e-07
Iter: 2333 loss: 2.53714745e-07
Iter: 2334 loss: 2.53472365e-07
Iter: 2335 loss: 2.53365556e-07
Iter: 2336 loss: 2.53361378e-07
Iter: 2337 loss: 2.53263153e-07
Iter: 2338 loss: 2.53182691e-07
Iter: 2339 loss: 2.53139604e-07
Iter: 2340 loss: 2.53068663e-07
Iter: 2341 loss: 2.5420627e-07
Iter: 2342 loss: 2.53058261e-07
Iter: 2343 loss: 2.52956738e-07
Iter: 2344 loss: 2.52871189e-07
Iter: 2345 loss: 2.52844131e-07
Iter: 2346 loss: 2.52710407e-07
Iter: 2347 loss: 2.52741e-07
Iter: 2348 loss: 2.52596493e-07
Iter: 2349 loss: 2.5251677e-07
Iter: 2350 loss: 2.52507476e-07
Iter: 2351 loss: 2.52419625e-07
Iter: 2352 loss: 2.52179234e-07
Iter: 2353 loss: 2.55640543e-07
Iter: 2354 loss: 2.52190489e-07
Iter: 2355 loss: 2.5204119e-07
Iter: 2356 loss: 2.52506624e-07
Iter: 2357 loss: 2.52002451e-07
Iter: 2358 loss: 2.5188487e-07
Iter: 2359 loss: 2.52037864e-07
Iter: 2360 loss: 2.51805091e-07
Iter: 2361 loss: 2.51726021e-07
Iter: 2362 loss: 2.51698197e-07
Iter: 2363 loss: 2.51596333e-07
Iter: 2364 loss: 2.51515388e-07
Iter: 2365 loss: 2.51509704e-07
Iter: 2366 loss: 2.51413439e-07
Iter: 2367 loss: 2.5114818e-07
Iter: 2368 loss: 2.51172196e-07
Iter: 2369 loss: 2.51065444e-07
Iter: 2370 loss: 2.50984812e-07
Iter: 2371 loss: 2.50851599e-07
Iter: 2372 loss: 2.50770512e-07
Iter: 2373 loss: 2.5075542e-07
Iter: 2374 loss: 2.50594439e-07
Iter: 2375 loss: 2.50638294e-07
Iter: 2376 loss: 2.50439285e-07
Iter: 2377 loss: 2.5029e-07
Iter: 2378 loss: 2.52350503e-07
Iter: 2379 loss: 2.50280948e-07
Iter: 2380 loss: 2.50146314e-07
Iter: 2381 loss: 2.50796234e-07
Iter: 2382 loss: 2.50109139e-07
Iter: 2383 loss: 2.49979763e-07
Iter: 2384 loss: 2.4982549e-07
Iter: 2385 loss: 2.54736051e-07
Iter: 2386 loss: 2.49820062e-07
Iter: 2387 loss: 2.49624463e-07
Iter: 2388 loss: 2.50902559e-07
Iter: 2389 loss: 2.4962722e-07
Iter: 2390 loss: 2.49415848e-07
Iter: 2391 loss: 2.51073061e-07
Iter: 2392 loss: 2.49395498e-07
Iter: 2393 loss: 2.49307845e-07
Iter: 2394 loss: 2.49161644e-07
Iter: 2395 loss: 2.49137855e-07
Iter: 2396 loss: 2.48886806e-07
Iter: 2397 loss: 2.50644e-07
Iter: 2398 loss: 2.48853837e-07
Iter: 2399 loss: 2.48688934e-07
Iter: 2400 loss: 2.48900363e-07
Iter: 2401 loss: 2.48610661e-07
Iter: 2402 loss: 2.48478955e-07
Iter: 2403 loss: 2.48713604e-07
Iter: 2404 loss: 2.48431718e-07
Iter: 2405 loss: 2.48296317e-07
Iter: 2406 loss: 2.50157512e-07
Iter: 2407 loss: 2.48284238e-07
Iter: 2408 loss: 2.48226399e-07
Iter: 2409 loss: 2.4815813e-07
Iter: 2410 loss: 2.48129254e-07
Iter: 2411 loss: 2.48056608e-07
Iter: 2412 loss: 2.48002209e-07
Iter: 2413 loss: 2.47959207e-07
Iter: 2414 loss: 2.47852313e-07
Iter: 2415 loss: 2.47857429e-07
Iter: 2416 loss: 2.4775386e-07
Iter: 2417 loss: 2.48238308e-07
Iter: 2418 loss: 2.47762273e-07
Iter: 2419 loss: 2.47657567e-07
Iter: 2420 loss: 2.47549053e-07
Iter: 2421 loss: 2.48644142e-07
Iter: 2422 loss: 2.4745222e-07
Iter: 2423 loss: 2.47447616e-07
Iter: 2424 loss: 2.47384605e-07
Iter: 2425 loss: 2.47304058e-07
Iter: 2426 loss: 2.47476351e-07
Iter: 2427 loss: 2.4724639e-07
Iter: 2428 loss: 2.47201797e-07
Iter: 2429 loss: 2.47324522e-07
Iter: 2430 loss: 2.47130743e-07
Iter: 2431 loss: 2.47007137e-07
Iter: 2432 loss: 2.47308861e-07
Iter: 2433 loss: 2.46958649e-07
Iter: 2434 loss: 2.46885207e-07
Iter: 2435 loss: 2.46930142e-07
Iter: 2436 loss: 2.46815432e-07
Iter: 2437 loss: 2.46731e-07
Iter: 2438 loss: 2.47611041e-07
Iter: 2439 loss: 2.46726984e-07
Iter: 2440 loss: 2.46631402e-07
Iter: 2441 loss: 2.46517544e-07
Iter: 2442 loss: 2.46522745e-07
Iter: 2443 loss: 2.46393967e-07
Iter: 2444 loss: 2.46459592e-07
Iter: 2445 loss: 2.46322799e-07
Iter: 2446 loss: 2.46192371e-07
Iter: 2447 loss: 2.46125495e-07
Iter: 2448 loss: 2.46041452e-07
Iter: 2449 loss: 2.4591094e-07
Iter: 2450 loss: 2.47262449e-07
Iter: 2451 loss: 2.45923161e-07
Iter: 2452 loss: 2.4580379e-07
Iter: 2453 loss: 2.45821241e-07
Iter: 2454 loss: 2.45715512e-07
Iter: 2455 loss: 2.45605918e-07
Iter: 2456 loss: 2.45594634e-07
Iter: 2457 loss: 2.45497603e-07
Iter: 2458 loss: 2.45395654e-07
Iter: 2459 loss: 2.45382182e-07
Iter: 2460 loss: 2.4526409e-07
Iter: 2461 loss: 2.45270115e-07
Iter: 2462 loss: 2.45184708e-07
Iter: 2463 loss: 2.45032368e-07
Iter: 2464 loss: 2.48609695e-07
Iter: 2465 loss: 2.4499e-07
Iter: 2466 loss: 2.44917658e-07
Iter: 2467 loss: 2.44895261e-07
Iter: 2468 loss: 2.44835235e-07
Iter: 2469 loss: 2.44736242e-07
Iter: 2470 loss: 2.44753835e-07
Iter: 2471 loss: 2.44621305e-07
Iter: 2472 loss: 2.44615052e-07
Iter: 2473 loss: 2.44500768e-07
Iter: 2474 loss: 2.445056e-07
Iter: 2475 loss: 2.44448444e-07
Iter: 2476 loss: 2.44385149e-07
Iter: 2477 loss: 2.44417294e-07
Iter: 2478 loss: 2.44370312e-07
Iter: 2479 loss: 2.44308239e-07
Iter: 2480 loss: 2.44127506e-07
Iter: 2481 loss: 2.4638689e-07
Iter: 2482 loss: 2.44147742e-07
Iter: 2483 loss: 2.4390161e-07
Iter: 2484 loss: 2.44505912e-07
Iter: 2485 loss: 2.43836041e-07
Iter: 2486 loss: 2.43640812e-07
Iter: 2487 loss: 2.44887019e-07
Iter: 2488 loss: 2.43635554e-07
Iter: 2489 loss: 2.43398631e-07
Iter: 2490 loss: 2.44495482e-07
Iter: 2491 loss: 2.43390446e-07
Iter: 2492 loss: 2.43271188e-07
Iter: 2493 loss: 2.4348617e-07
Iter: 2494 loss: 2.43252146e-07
Iter: 2495 loss: 2.43104694e-07
Iter: 2496 loss: 2.43580274e-07
Iter: 2497 loss: 2.43111032e-07
Iter: 2498 loss: 2.43000386e-07
Iter: 2499 loss: 2.43091051e-07
Iter: 2500 loss: 2.42973613e-07
Iter: 2501 loss: 2.42907277e-07
Iter: 2502 loss: 2.43560208e-07
Iter: 2503 loss: 2.42870897e-07
Iter: 2504 loss: 2.42785973e-07
Iter: 2505 loss: 2.42759569e-07
Iter: 2506 loss: 2.42759825e-07
Iter: 2507 loss: 2.42639146e-07
Iter: 2508 loss: 2.4291495e-07
Iter: 2509 loss: 2.4259e-07
Iter: 2510 loss: 2.42470378e-07
Iter: 2511 loss: 2.4346744e-07
Iter: 2512 loss: 2.42472026e-07
Iter: 2513 loss: 2.42351973e-07
Iter: 2514 loss: 2.42273813e-07
Iter: 2515 loss: 2.42274211e-07
Iter: 2516 loss: 2.42106978e-07
Iter: 2517 loss: 2.42336654e-07
Iter: 2518 loss: 2.42042034e-07
Iter: 2519 loss: 2.41881793e-07
Iter: 2520 loss: 2.42903781e-07
Iter: 2521 loss: 2.41841519e-07
Iter: 2522 loss: 2.41772739e-07
Iter: 2523 loss: 2.41797522e-07
Iter: 2524 loss: 2.41731016e-07
Iter: 2525 loss: 2.4163171e-07
Iter: 2526 loss: 2.41617585e-07
Iter: 2527 loss: 2.41521604e-07
Iter: 2528 loss: 2.41534565e-07
Iter: 2529 loss: 2.41489488e-07
Iter: 2530 loss: 2.41418746e-07
Iter: 2531 loss: 2.4141184e-07
Iter: 2532 loss: 2.41354826e-07
Iter: 2533 loss: 2.42364507e-07
Iter: 2534 loss: 2.41324642e-07
Iter: 2535 loss: 2.41239775e-07
Iter: 2536 loss: 2.41122649e-07
Iter: 2537 loss: 2.44059351e-07
Iter: 2538 loss: 2.41126202e-07
Iter: 2539 loss: 2.4096525e-07
Iter: 2540 loss: 2.4156094e-07
Iter: 2541 loss: 2.40934e-07
Iter: 2542 loss: 2.40885669e-07
Iter: 2543 loss: 2.40863784e-07
Iter: 2544 loss: 2.40774284e-07
Iter: 2545 loss: 2.40615464e-07
Iter: 2546 loss: 2.41422697e-07
Iter: 2547 loss: 2.40546058e-07
Iter: 2548 loss: 2.4038286e-07
Iter: 2549 loss: 2.42349245e-07
Iter: 2550 loss: 2.40382462e-07
Iter: 2551 loss: 2.40250927e-07
Iter: 2552 loss: 2.40320048e-07
Iter: 2553 loss: 2.40138093e-07
Iter: 2554 loss: 2.40010422e-07
Iter: 2555 loss: 2.40003544e-07
Iter: 2556 loss: 2.39868484e-07
Iter: 2557 loss: 2.39837135e-07
Iter: 2558 loss: 2.39755934e-07
Iter: 2559 loss: 2.39614423e-07
Iter: 2560 loss: 2.40856224e-07
Iter: 2561 loss: 2.39609705e-07
Iter: 2562 loss: 2.3947382e-07
Iter: 2563 loss: 2.39403334e-07
Iter: 2564 loss: 2.39377e-07
Iter: 2565 loss: 2.39250738e-07
Iter: 2566 loss: 2.40638087e-07
Iter: 2567 loss: 2.39249971e-07
Iter: 2568 loss: 2.39151746e-07
Iter: 2569 loss: 2.39201199e-07
Iter: 2570 loss: 2.39083789e-07
Iter: 2571 loss: 2.38992811e-07
Iter: 2572 loss: 2.38825066e-07
Iter: 2573 loss: 2.41117561e-07
Iter: 2574 loss: 2.38824327e-07
Iter: 2575 loss: 2.38720844e-07
Iter: 2576 loss: 2.38703024e-07
Iter: 2577 loss: 2.38589053e-07
Iter: 2578 loss: 2.38624892e-07
Iter: 2579 loss: 2.38491282e-07
Iter: 2580 loss: 2.38394136e-07
Iter: 2581 loss: 2.38478208e-07
Iter: 2582 loss: 2.38376231e-07
Iter: 2583 loss: 2.38202858e-07
Iter: 2584 loss: 2.38284073e-07
Iter: 2585 loss: 2.38127043e-07
Iter: 2586 loss: 2.37990122e-07
Iter: 2587 loss: 2.39530664e-07
Iter: 2588 loss: 2.37989326e-07
Iter: 2589 loss: 2.37813396e-07
Iter: 2590 loss: 2.38535335e-07
Iter: 2591 loss: 2.37815527e-07
Iter: 2592 loss: 2.37770635e-07
Iter: 2593 loss: 2.38021983e-07
Iter: 2594 loss: 2.37752147e-07
Iter: 2595 loss: 2.3766215e-07
Iter: 2596 loss: 2.37893047e-07
Iter: 2597 loss: 2.37648777e-07
Iter: 2598 loss: 2.3756462e-07
Iter: 2599 loss: 2.37566354e-07
Iter: 2600 loss: 2.37524731e-07
Iter: 2601 loss: 2.37387709e-07
Iter: 2602 loss: 2.38242052e-07
Iter: 2603 loss: 2.37400968e-07
Iter: 2604 loss: 2.37345603e-07
Iter: 2605 loss: 2.37209051e-07
Iter: 2606 loss: 2.39881643e-07
Iter: 2607 loss: 2.37215431e-07
Iter: 2608 loss: 2.37061e-07
Iter: 2609 loss: 2.38240077e-07
Iter: 2610 loss: 2.37051097e-07
Iter: 2611 loss: 2.36933033e-07
Iter: 2612 loss: 2.37185418e-07
Iter: 2613 loss: 2.36860927e-07
Iter: 2614 loss: 2.36727487e-07
Iter: 2615 loss: 2.36581968e-07
Iter: 2616 loss: 2.36540302e-07
Iter: 2617 loss: 2.36382334e-07
Iter: 2618 loss: 2.37083526e-07
Iter: 2619 loss: 2.36297325e-07
Iter: 2620 loss: 2.36163416e-07
Iter: 2621 loss: 2.36674921e-07
Iter: 2622 loss: 2.36129694e-07
Iter: 2623 loss: 2.35984e-07
Iter: 2624 loss: 2.36540643e-07
Iter: 2625 loss: 2.35952172e-07
Iter: 2626 loss: 2.35804862e-07
Iter: 2627 loss: 2.35972919e-07
Iter: 2628 loss: 2.35719824e-07
Iter: 2629 loss: 2.35539034e-07
Iter: 2630 loss: 2.37162084e-07
Iter: 2631 loss: 2.35538906e-07
Iter: 2632 loss: 2.35426555e-07
Iter: 2633 loss: 2.35391155e-07
Iter: 2634 loss: 2.35310978e-07
Iter: 2635 loss: 2.35195841e-07
Iter: 2636 loss: 2.35828892e-07
Iter: 2637 loss: 2.35176984e-07
Iter: 2638 loss: 2.35014141e-07
Iter: 2639 loss: 2.34862767e-07
Iter: 2640 loss: 2.34802386e-07
Iter: 2641 loss: 2.34691086e-07
Iter: 2642 loss: 2.36398279e-07
Iter: 2643 loss: 2.34664512e-07
Iter: 2644 loss: 2.34567921e-07
Iter: 2645 loss: 2.34885064e-07
Iter: 2646 loss: 2.34523128e-07
Iter: 2647 loss: 2.34454888e-07
Iter: 2648 loss: 2.34365942e-07
Iter: 2649 loss: 2.34297119e-07
Iter: 2650 loss: 2.34178231e-07
Iter: 2651 loss: 2.35640812e-07
Iter: 2652 loss: 2.34179524e-07
Iter: 2653 loss: 2.34072303e-07
Iter: 2654 loss: 2.34475806e-07
Iter: 2655 loss: 2.33981524e-07
Iter: 2656 loss: 2.33904544e-07
Iter: 2657 loss: 2.3412845e-07
Iter: 2658 loss: 2.33869855e-07
Iter: 2659 loss: 2.33770763e-07
Iter: 2660 loss: 2.33842428e-07
Iter: 2661 loss: 2.3366178e-07
Iter: 2662 loss: 2.33577325e-07
Iter: 2663 loss: 2.33586988e-07
Iter: 2664 loss: 2.33524261e-07
Iter: 2665 loss: 2.33350704e-07
Iter: 2666 loss: 2.36308409e-07
Iter: 2667 loss: 2.33320065e-07
Iter: 2668 loss: 2.33156754e-07
Iter: 2669 loss: 2.34622533e-07
Iter: 2670 loss: 2.33177758e-07
Iter: 2671 loss: 2.33010269e-07
Iter: 2672 loss: 2.33512409e-07
Iter: 2673 loss: 2.32960147e-07
Iter: 2674 loss: 2.32923711e-07
Iter: 2675 loss: 2.3307868e-07
Iter: 2676 loss: 2.32862362e-07
Iter: 2677 loss: 2.3275463e-07
Iter: 2678 loss: 2.33315546e-07
Iter: 2679 loss: 2.32767661e-07
Iter: 2680 loss: 2.32694035e-07
Iter: 2681 loss: 2.32649427e-07
Iter: 2682 loss: 2.32599547e-07
Iter: 2683 loss: 2.32480389e-07
Iter: 2684 loss: 2.32608812e-07
Iter: 2685 loss: 2.32466817e-07
Iter: 2686 loss: 2.32339147e-07
Iter: 2687 loss: 2.33519231e-07
Iter: 2688 loss: 2.32315557e-07
Iter: 2689 loss: 2.32218852e-07
Iter: 2690 loss: 2.32527583e-07
Iter: 2691 loss: 2.32217616e-07
Iter: 2692 loss: 2.32101542e-07
Iter: 2693 loss: 2.32050553e-07
Iter: 2694 loss: 2.32005746e-07
Iter: 2695 loss: 2.31854798e-07
Iter: 2696 loss: 2.32663737e-07
Iter: 2697 loss: 2.31814028e-07
Iter: 2698 loss: 2.31661261e-07
Iter: 2699 loss: 2.32002748e-07
Iter: 2700 loss: 2.31580387e-07
Iter: 2701 loss: 2.31471688e-07
Iter: 2702 loss: 2.31905403e-07
Iter: 2703 loss: 2.3142475e-07
Iter: 2704 loss: 2.31327419e-07
Iter: 2705 loss: 2.31697257e-07
Iter: 2706 loss: 2.31315084e-07
Iter: 2707 loss: 2.31222941e-07
Iter: 2708 loss: 2.31165217e-07
Iter: 2709 loss: 2.31117298e-07
Iter: 2710 loss: 2.3103398e-07
Iter: 2711 loss: 2.32605828e-07
Iter: 2712 loss: 2.31015918e-07
Iter: 2713 loss: 2.30911439e-07
Iter: 2714 loss: 2.31018959e-07
Iter: 2715 loss: 2.30888205e-07
Iter: 2716 loss: 2.30852e-07
Iter: 2717 loss: 2.30686183e-07
Iter: 2718 loss: 2.33667308e-07
Iter: 2719 loss: 2.30669059e-07
Iter: 2720 loss: 2.30511048e-07
Iter: 2721 loss: 2.31980465e-07
Iter: 2722 loss: 2.30517898e-07
Iter: 2723 loss: 2.3040603e-07
Iter: 2724 loss: 2.31374571e-07
Iter: 2725 loss: 2.30395116e-07
Iter: 2726 loss: 2.30311372e-07
Iter: 2727 loss: 2.30384785e-07
Iter: 2728 loss: 2.30281756e-07
Iter: 2729 loss: 2.30206069e-07
Iter: 2730 loss: 2.30227045e-07
Iter: 2731 loss: 2.30109478e-07
Iter: 2732 loss: 2.30061488e-07
Iter: 2733 loss: 2.30013185e-07
Iter: 2734 loss: 2.29977388e-07
Iter: 2735 loss: 2.29879277e-07
Iter: 2736 loss: 2.31350711e-07
Iter: 2737 loss: 2.2987507e-07
Iter: 2738 loss: 2.29737651e-07
Iter: 2739 loss: 2.31324606e-07
Iter: 2740 loss: 2.29722389e-07
Iter: 2741 loss: 2.29666213e-07
Iter: 2742 loss: 2.29721991e-07
Iter: 2743 loss: 2.2962206e-07
Iter: 2744 loss: 2.29503357e-07
Iter: 2745 loss: 2.29502604e-07
Iter: 2746 loss: 2.29430526e-07
Iter: 2747 loss: 2.29375928e-07
Iter: 2748 loss: 2.29373484e-07
Iter: 2749 loss: 2.29308711e-07
Iter: 2750 loss: 2.29220191e-07
Iter: 2751 loss: 2.29222081e-07
Iter: 2752 loss: 2.29130436e-07
Iter: 2753 loss: 2.29183357e-07
Iter: 2754 loss: 2.29098333e-07
Iter: 2755 loss: 2.289636e-07
Iter: 2756 loss: 2.29670519e-07
Iter: 2757 loss: 2.28963415e-07
Iter: 2758 loss: 2.28872125e-07
Iter: 2759 loss: 2.2940128e-07
Iter: 2760 loss: 2.28867208e-07
Iter: 2761 loss: 2.28799806e-07
Iter: 2762 loss: 2.28792373e-07
Iter: 2763 loss: 2.28753663e-07
Iter: 2764 loss: 2.28669649e-07
Iter: 2765 loss: 2.29118797e-07
Iter: 2766 loss: 2.28668327e-07
Iter: 2767 loss: 2.28569249e-07
Iter: 2768 loss: 2.28625538e-07
Iter: 2769 loss: 2.28495736e-07
Iter: 2770 loss: 2.28441337e-07
Iter: 2771 loss: 2.28715606e-07
Iter: 2772 loss: 2.28419225e-07
Iter: 2773 loss: 2.28349123e-07
Iter: 2774 loss: 2.2872743e-07
Iter: 2775 loss: 2.28384096e-07
Iter: 2776 loss: 2.28313183e-07
Iter: 2777 loss: 2.2820862e-07
Iter: 2778 loss: 2.2956857e-07
Iter: 2779 loss: 2.28187702e-07
Iter: 2780 loss: 2.28109741e-07
Iter: 2781 loss: 2.28581911e-07
Iter: 2782 loss: 2.2808851e-07
Iter: 2783 loss: 2.28054191e-07
Iter: 2784 loss: 2.28028057e-07
Iter: 2785 loss: 2.2799972e-07
Iter: 2786 loss: 2.27886872e-07
Iter: 2787 loss: 2.28753322e-07
Iter: 2788 loss: 2.27832373e-07
Iter: 2789 loss: 2.27706153e-07
Iter: 2790 loss: 2.28233631e-07
Iter: 2791 loss: 2.27672018e-07
Iter: 2792 loss: 2.27572599e-07
Iter: 2793 loss: 2.28278509e-07
Iter: 2794 loss: 2.27551823e-07
Iter: 2795 loss: 2.27418781e-07
Iter: 2796 loss: 2.27905403e-07
Iter: 2797 loss: 2.27439415e-07
Iter: 2798 loss: 2.27352984e-07
Iter: 2799 loss: 2.27328755e-07
Iter: 2800 loss: 2.27300731e-07
Iter: 2801 loss: 2.27274299e-07
Iter: 2802 loss: 2.27279344e-07
Iter: 2803 loss: 2.27201824e-07
Iter: 2804 loss: 2.27164065e-07
Iter: 2805 loss: 2.27122825e-07
Iter: 2806 loss: 2.27098866e-07
Iter: 2807 loss: 2.27570879e-07
Iter: 2808 loss: 2.27084286e-07
Iter: 2809 loss: 2.27056347e-07
Iter: 2810 loss: 2.27072405e-07
Iter: 2811 loss: 2.27023349e-07
Iter: 2812 loss: 2.26976283e-07
Iter: 2813 loss: 2.26881411e-07
Iter: 2814 loss: 2.26875443e-07
Iter: 2815 loss: 2.26821626e-07
Iter: 2816 loss: 2.27616155e-07
Iter: 2817 loss: 2.26788416e-07
Iter: 2818 loss: 2.26750132e-07
Iter: 2819 loss: 2.26743765e-07
Iter: 2820 loss: 2.26708963e-07
Iter: 2821 loss: 2.26609771e-07
Iter: 2822 loss: 2.26447199e-07
Iter: 2823 loss: 2.26476459e-07
Iter: 2824 loss: 2.26362488e-07
Iter: 2825 loss: 2.26934958e-07
Iter: 2826 loss: 2.26306796e-07
Iter: 2827 loss: 2.26197784e-07
Iter: 2828 loss: 2.2666201e-07
Iter: 2829 loss: 2.26173711e-07
Iter: 2830 loss: 2.26110814e-07
Iter: 2831 loss: 2.26106749e-07
Iter: 2832 loss: 2.26081696e-07
Iter: 2833 loss: 2.2601877e-07
Iter: 2834 loss: 2.26579203e-07
Iter: 2835 loss: 2.25954921e-07
Iter: 2836 loss: 2.25881408e-07
Iter: 2837 loss: 2.25890261e-07
Iter: 2838 loss: 2.25792931e-07
Iter: 2839 loss: 2.25869485e-07
Iter: 2840 loss: 2.25775295e-07
Iter: 2841 loss: 2.25684943e-07
Iter: 2842 loss: 2.25658013e-07
Iter: 2843 loss: 2.25622443e-07
Iter: 2844 loss: 2.25510092e-07
Iter: 2845 loss: 2.26256063e-07
Iter: 2846 loss: 2.25478672e-07
Iter: 2847 loss: 2.25380262e-07
Iter: 2848 loss: 2.25655526e-07
Iter: 2849 loss: 2.25349851e-07
Iter: 2850 loss: 2.25274221e-07
Iter: 2851 loss: 2.25731227e-07
Iter: 2852 loss: 2.25255519e-07
Iter: 2853 loss: 2.25176066e-07
Iter: 2854 loss: 2.25127792e-07
Iter: 2855 loss: 2.25067964e-07
Iter: 2856 loss: 2.24965476e-07
Iter: 2857 loss: 2.25023086e-07
Iter: 2858 loss: 2.24903644e-07
Iter: 2859 loss: 2.24807849e-07
Iter: 2860 loss: 2.24990174e-07
Iter: 2861 loss: 2.24746927e-07
Iter: 2862 loss: 2.24638285e-07
Iter: 2863 loss: 2.24685976e-07
Iter: 2864 loss: 2.24582124e-07
Iter: 2865 loss: 2.24528691e-07
Iter: 2866 loss: 2.24477986e-07
Iter: 2867 loss: 2.24389211e-07
Iter: 2868 loss: 2.24425264e-07
Iter: 2869 loss: 2.24320772e-07
Iter: 2870 loss: 2.2423626e-07
Iter: 2871 loss: 2.24252233e-07
Iter: 2872 loss: 2.24171927e-07
Iter: 2873 loss: 2.24134936e-07
Iter: 2874 loss: 2.24091934e-07
Iter: 2875 loss: 2.24021136e-07
Iter: 2876 loss: 2.24102365e-07
Iter: 2877 loss: 2.23990128e-07
Iter: 2878 loss: 2.23890964e-07
Iter: 2879 loss: 2.24752114e-07
Iter: 2880 loss: 2.23889359e-07
Iter: 2881 loss: 2.23810645e-07
Iter: 2882 loss: 2.24109556e-07
Iter: 2883 loss: 2.23798452e-07
Iter: 2884 loss: 2.23745019e-07
Iter: 2885 loss: 2.23776e-07
Iter: 2886 loss: 2.23712306e-07
Iter: 2887 loss: 2.23638608e-07
Iter: 2888 loss: 2.23946714e-07
Iter: 2889 loss: 2.23608055e-07
Iter: 2890 loss: 2.23542557e-07
Iter: 2891 loss: 2.23364211e-07
Iter: 2892 loss: 2.2708052e-07
Iter: 2893 loss: 2.23369781e-07
Iter: 2894 loss: 2.23273702e-07
Iter: 2895 loss: 2.23260258e-07
Iter: 2896 loss: 2.23205504e-07
Iter: 2897 loss: 2.23220766e-07
Iter: 2898 loss: 2.23140376e-07
Iter: 2899 loss: 2.23052126e-07
Iter: 2900 loss: 2.23091462e-07
Iter: 2901 loss: 2.22982507e-07
Iter: 2902 loss: 2.22968808e-07
Iter: 2903 loss: 2.22935782e-07
Iter: 2904 loss: 2.22896745e-07
Iter: 2905 loss: 2.22835808e-07
Iter: 2906 loss: 2.22831602e-07
Iter: 2907 loss: 2.22760235e-07
Iter: 2908 loss: 2.2294671e-07
Iter: 2909 loss: 2.22721098e-07
Iter: 2910 loss: 2.226882e-07
Iter: 2911 loss: 2.22833023e-07
Iter: 2912 loss: 2.22661299e-07
Iter: 2913 loss: 2.22606246e-07
Iter: 2914 loss: 2.2306979e-07
Iter: 2915 loss: 2.22584703e-07
Iter: 2916 loss: 2.22505122e-07
Iter: 2917 loss: 2.22665562e-07
Iter: 2918 loss: 2.22474029e-07
Iter: 2919 loss: 2.22426436e-07
Iter: 2920 loss: 2.22703079e-07
Iter: 2921 loss: 2.2243168e-07
Iter: 2922 loss: 2.22329462e-07
Iter: 2923 loss: 2.22260752e-07
Iter: 2924 loss: 2.22252083e-07
Iter: 2925 loss: 2.22186685e-07
Iter: 2926 loss: 2.22616166e-07
Iter: 2927 loss: 2.22154171e-07
Iter: 2928 loss: 2.22087749e-07
Iter: 2929 loss: 2.22621537e-07
Iter: 2930 loss: 2.22100255e-07
Iter: 2931 loss: 2.22029982e-07
Iter: 2932 loss: 2.21959141e-07
Iter: 2933 loss: 2.21957137e-07
Iter: 2934 loss: 2.21929668e-07
Iter: 2935 loss: 2.22748938e-07
Iter: 2936 loss: 2.21929469e-07
Iter: 2937 loss: 2.21879404e-07
Iter: 2938 loss: 2.21890843e-07
Iter: 2939 loss: 2.21859281e-07
Iter: 2940 loss: 2.2182283e-07
Iter: 2941 loss: 2.21719503e-07
Iter: 2942 loss: 2.23517731e-07
Iter: 2943 loss: 2.21732904e-07
Iter: 2944 loss: 2.21661594e-07
Iter: 2945 loss: 2.22454545e-07
Iter: 2946 loss: 2.21660613e-07
Iter: 2947 loss: 2.21603855e-07
Iter: 2948 loss: 2.21889962e-07
Iter: 2949 loss: 2.21550124e-07
Iter: 2950 loss: 2.21471055e-07
Iter: 2951 loss: 2.2199886e-07
Iter: 2952 loss: 2.21474721e-07
Iter: 2953 loss: 2.21429701e-07
Iter: 2954 loss: 2.2152841e-07
Iter: 2955 loss: 2.21432273e-07
Iter: 2956 loss: 2.213838e-07
Iter: 2957 loss: 2.21549499e-07
Iter: 2958 loss: 2.21382606e-07
Iter: 2959 loss: 2.21347534e-07
Iter: 2960 loss: 2.212889e-07
Iter: 2961 loss: 2.22580752e-07
Iter: 2962 loss: 2.21261814e-07
Iter: 2963 loss: 2.21226912e-07
Iter: 2964 loss: 2.21254965e-07
Iter: 2965 loss: 2.21189822e-07
Iter: 2966 loss: 2.2123011e-07
Iter: 2967 loss: 2.21193289e-07
Iter: 2968 loss: 2.21121439e-07
Iter: 2969 loss: 2.2119147e-07
Iter: 2970 loss: 2.2110116e-07
Iter: 2971 loss: 2.2104939e-07
Iter: 2972 loss: 2.21234842e-07
Iter: 2973 loss: 2.21025402e-07
Iter: 2974 loss: 2.20998146e-07
Iter: 2975 loss: 2.21031769e-07
Iter: 2976 loss: 2.20952131e-07
Iter: 2977 loss: 2.20914458e-07
Iter: 2978 loss: 2.2093198e-07
Iter: 2979 loss: 2.2087761e-07
Iter: 2980 loss: 2.20794689e-07
Iter: 2981 loss: 2.21251526e-07
Iter: 2982 loss: 2.20792728e-07
Iter: 2983 loss: 2.20751872e-07
Iter: 2984 loss: 2.21286172e-07
Iter: 2985 loss: 2.20751971e-07
Iter: 2986 loss: 2.20720267e-07
Iter: 2987 loss: 2.20680562e-07
Iter: 2988 loss: 2.20637816e-07
Iter: 2989 loss: 2.20618261e-07
Iter: 2990 loss: 2.21505701e-07
Iter: 2991 loss: 2.20631662e-07
Iter: 2992 loss: 2.20556302e-07
Iter: 2993 loss: 2.20571337e-07
Iter: 2994 loss: 2.20519325e-07
Iter: 2995 loss: 2.20440484e-07
Iter: 2996 loss: 2.2043271e-07
Iter: 2997 loss: 2.20382319e-07
Iter: 2998 loss: 2.2032502e-07
Iter: 2999 loss: 2.20328701e-07
Iter: 3000 loss: 2.20263473e-07
Iter: 3001 loss: 2.20629431e-07
Iter: 3002 loss: 2.20294737e-07
Iter: 3003 loss: 2.20239201e-07
Iter: 3004 loss: 2.2020626e-07
Iter: 3005 loss: 2.2060739e-07
Iter: 3006 loss: 2.20209344e-07
Iter: 3007 loss: 2.2016475e-07
Iter: 3008 loss: 2.20138077e-07
Iter: 3009 loss: 2.20116718e-07
Iter: 3010 loss: 2.20117428e-07
Iter: 3011 loss: 2.20108632e-07
Iter: 3012 loss: 2.20036299e-07
Iter: 3013 loss: 2.19983662e-07
Iter: 3014 loss: 2.19982866e-07
Iter: 3015 loss: 2.19894957e-07
Iter: 3016 loss: 2.20412872e-07
Iter: 3017 loss: 2.19862144e-07
Iter: 3018 loss: 2.19848545e-07
Iter: 3019 loss: 2.19858208e-07
Iter: 3020 loss: 2.19838199e-07
Iter: 3021 loss: 2.19792042e-07
Iter: 3022 loss: 2.19785392e-07
Iter: 3023 loss: 2.19784596e-07
Iter: 3024 loss: 2.20033527e-07
Iter: 3025 loss: 2.19761858e-07
Iter: 3026 loss: 2.19719553e-07
Iter: 3027 loss: 2.19707232e-07
Iter: 3028 loss: 2.19690477e-07
Iter: 3029 loss: 2.19634e-07
Iter: 3030 loss: 2.19629726e-07
Iter: 3031 loss: 2.19616339e-07
Iter: 3032 loss: 2.19538251e-07
Iter: 3033 loss: 2.19783985e-07
Iter: 3034 loss: 2.19507257e-07
Iter: 3035 loss: 2.19438661e-07
Iter: 3036 loss: 2.1971664e-07
Iter: 3037 loss: 2.19386664e-07
Iter: 3038 loss: 2.19334709e-07
Iter: 3039 loss: 2.1920485e-07
Iter: 3040 loss: 2.1920529e-07
Iter: 3041 loss: 2.19134506e-07
Iter: 3042 loss: 2.19139864e-07
Iter: 3043 loss: 2.19088776e-07
Iter: 3044 loss: 2.19379757e-07
Iter: 3045 loss: 2.19057682e-07
Iter: 3046 loss: 2.19017465e-07
Iter: 3047 loss: 2.1893797e-07
Iter: 3048 loss: 2.1894023e-07
Iter: 3049 loss: 2.18861828e-07
Iter: 3050 loss: 2.19445241e-07
Iter: 3051 loss: 2.18845202e-07
Iter: 3052 loss: 2.18779888e-07
Iter: 3053 loss: 2.19409088e-07
Iter: 3054 loss: 2.18788486e-07
Iter: 3055 loss: 2.18739331e-07
Iter: 3056 loss: 2.18718924e-07
Iter: 3057 loss: 2.18694993e-07
Iter: 3058 loss: 2.18614232e-07
Iter: 3059 loss: 2.19119158e-07
Iter: 3060 loss: 2.18582599e-07
Iter: 3061 loss: 2.18537e-07
Iter: 3062 loss: 2.18499181e-07
Iter: 3063 loss: 2.18473076e-07
Iter: 3064 loss: 2.18406143e-07
Iter: 3065 loss: 2.18906081e-07
Iter: 3066 loss: 2.18398426e-07
Iter: 3067 loss: 2.1832281e-07
Iter: 3068 loss: 2.1875e-07
Iter: 3069 loss: 2.18305374e-07
Iter: 3070 loss: 2.18266507e-07
Iter: 3071 loss: 2.18232401e-07
Iter: 3072 loss: 2.1824448e-07
Iter: 3073 loss: 2.18162313e-07
Iter: 3074 loss: 2.1808178e-07
Iter: 3075 loss: 2.18101732e-07
Iter: 3076 loss: 2.18016524e-07
Iter: 3077 loss: 2.18027921e-07
Iter: 3078 loss: 2.17929667e-07
Iter: 3079 loss: 2.18409355e-07
Iter: 3080 loss: 2.17918569e-07
Iter: 3081 loss: 2.17858684e-07
Iter: 3082 loss: 2.17779274e-07
Iter: 3083 loss: 2.18409667e-07
Iter: 3084 loss: 2.17715339e-07
Iter: 3085 loss: 2.17646502e-07
Iter: 3086 loss: 2.17661452e-07
Iter: 3087 loss: 2.17591918e-07
Iter: 3088 loss: 2.17593239e-07
Iter: 3089 loss: 2.17552568e-07
Iter: 3090 loss: 2.17489145e-07
Iter: 3091 loss: 2.18211625e-07
Iter: 3092 loss: 2.1753074e-07
Iter: 3093 loss: 2.17478032e-07
Iter: 3094 loss: 2.17485692e-07
Iter: 3095 loss: 2.17462741e-07
Iter: 3096 loss: 2.17408626e-07
Iter: 3097 loss: 2.17422937e-07
Iter: 3098 loss: 2.1734887e-07
Iter: 3099 loss: 2.17186212e-07
Iter: 3100 loss: 2.18928022e-07
Iter: 3101 loss: 2.1721533e-07
Iter: 3102 loss: 2.17086892e-07
Iter: 3103 loss: 2.1749338e-07
Iter: 3104 loss: 2.17029196e-07
Iter: 3105 loss: 2.17045198e-07
Iter: 3106 loss: 2.16980283e-07
Iter: 3107 loss: 2.16974e-07
Iter: 3108 loss: 2.16907864e-07
Iter: 3109 loss: 2.17145868e-07
Iter: 3110 loss: 2.16891635e-07
Iter: 3111 loss: 2.16839595e-07
Iter: 3112 loss: 2.1680404e-07
Iter: 3113 loss: 2.16783633e-07
Iter: 3114 loss: 2.17010594e-07
Iter: 3115 loss: 2.16781132e-07
Iter: 3116 loss: 2.16751403e-07
Iter: 3117 loss: 2.16703967e-07
Iter: 3118 loss: 2.17176137e-07
Iter: 3119 loss: 2.16685009e-07
Iter: 3120 loss: 2.16654882e-07
Iter: 3121 loss: 2.16923624e-07
Iter: 3122 loss: 2.16629019e-07
Iter: 3123 loss: 2.16568395e-07
Iter: 3124 loss: 2.1691946e-07
Iter: 3125 loss: 2.16522452e-07
Iter: 3126 loss: 2.1644388e-07
Iter: 3127 loss: 2.16425207e-07
Iter: 3128 loss: 2.16374644e-07
Iter: 3129 loss: 2.16329013e-07
Iter: 3130 loss: 2.16885411e-07
Iter: 3131 loss: 2.1628162e-07
Iter: 3132 loss: 2.16253511e-07
Iter: 3133 loss: 2.16257391e-07
Iter: 3134 loss: 2.16162974e-07
Iter: 3135 loss: 2.16102023e-07
Iter: 3136 loss: 2.16164494e-07
Iter: 3137 loss: 2.16081588e-07
Iter: 3138 loss: 2.15967432e-07
Iter: 3139 loss: 2.16347331e-07
Iter: 3140 loss: 2.15999293e-07
Iter: 3141 loss: 2.15921716e-07
Iter: 3142 loss: 2.15923592e-07
Iter: 3143 loss: 2.15917908e-07
Iter: 3144 loss: 2.15853717e-07
Iter: 3145 loss: 2.15828294e-07
Iter: 3146 loss: 2.15812832e-07
Iter: 3147 loss: 2.16434429e-07
Iter: 3148 loss: 2.15807589e-07
Iter: 3149 loss: 2.15776282e-07
Iter: 3150 loss: 2.15717648e-07
Iter: 3151 loss: 2.15724512e-07
Iter: 3152 loss: 2.15649791e-07
Iter: 3153 loss: 2.16077495e-07
Iter: 3154 loss: 2.15626471e-07
Iter: 3155 loss: 2.155668e-07
Iter: 3156 loss: 2.15562977e-07
Iter: 3157 loss: 2.1550693e-07
Iter: 3158 loss: 2.15465931e-07
Iter: 3159 loss: 2.16535483e-07
Iter: 3160 loss: 2.15445283e-07
Iter: 3161 loss: 2.15421196e-07
Iter: 3162 loss: 2.15399893e-07
Iter: 3163 loss: 2.15380652e-07
Iter: 3164 loss: 2.15304084e-07
Iter: 3165 loss: 2.15526256e-07
Iter: 3166 loss: 2.15295643e-07
Iter: 3167 loss: 2.15244128e-07
Iter: 3168 loss: 2.15361283e-07
Iter: 3169 loss: 2.15226024e-07
Iter: 3170 loss: 2.15184514e-07
Iter: 3171 loss: 2.15295969e-07
Iter: 3172 loss: 2.151762e-07
Iter: 3173 loss: 2.15076483e-07
Iter: 3174 loss: 2.15197559e-07
Iter: 3175 loss: 2.150733e-07
Iter: 3176 loss: 2.14968097e-07
Iter: 3177 loss: 2.15154103e-07
Iter: 3178 loss: 2.14923801e-07
Iter: 3179 loss: 2.14866361e-07
Iter: 3180 loss: 2.15336172e-07
Iter: 3181 loss: 2.14847049e-07
Iter: 3182 loss: 2.14762338e-07
Iter: 3183 loss: 2.14748638e-07
Iter: 3184 loss: 2.14676902e-07
Iter: 3185 loss: 2.14621721e-07
Iter: 3186 loss: 2.14604228e-07
Iter: 3187 loss: 2.14521549e-07
Iter: 3188 loss: 2.14485013e-07
Iter: 3189 loss: 2.14472635e-07
Iter: 3190 loss: 2.14410406e-07
Iter: 3191 loss: 2.14360142e-07
Iter: 3192 loss: 2.14361449e-07
Iter: 3193 loss: 2.14221657e-07
Iter: 3194 loss: 2.14614175e-07
Iter: 3195 loss: 2.1421215e-07
Iter: 3196 loss: 2.14155165e-07
Iter: 3197 loss: 2.14093106e-07
Iter: 3198 loss: 2.14094968e-07
Iter: 3199 loss: 2.14006945e-07
Iter: 3200 loss: 2.14219355e-07
Iter: 3201 loss: 2.13962778e-07
Iter: 3202 loss: 2.13843364e-07
Iter: 3203 loss: 2.14087478e-07
Iter: 3204 loss: 2.13831399e-07
Iter: 3205 loss: 2.137607e-07
Iter: 3206 loss: 2.1375817e-07
Iter: 3207 loss: 2.13699934e-07
Iter: 3208 loss: 2.13805237e-07
Iter: 3209 loss: 2.13694e-07
Iter: 3210 loss: 2.13625782e-07
Iter: 3211 loss: 2.13738076e-07
Iter: 3212 loss: 2.13601481e-07
Iter: 3213 loss: 2.13553463e-07
Iter: 3214 loss: 2.13935721e-07
Iter: 3215 loss: 2.1356783e-07
Iter: 3216 loss: 2.13515762e-07
Iter: 3217 loss: 2.13481854e-07
Iter: 3218 loss: 2.13487937e-07
Iter: 3219 loss: 2.13398806e-07
Iter: 3220 loss: 2.13592187e-07
Iter: 3221 loss: 2.13412221e-07
Iter: 3222 loss: 2.13356202e-07
Iter: 3223 loss: 2.13339746e-07
Iter: 3224 loss: 2.13263434e-07
Iter: 3225 loss: 2.13183114e-07
Iter: 3226 loss: 2.13200479e-07
Iter: 3227 loss: 2.13166473e-07
Iter: 3228 loss: 2.13090544e-07
Iter: 3229 loss: 2.13076603e-07
Iter: 3230 loss: 2.12992205e-07
Iter: 3231 loss: 2.12911445e-07
Iter: 3232 loss: 2.1289874e-07
Iter: 3233 loss: 2.12807436e-07
Iter: 3234 loss: 2.13170381e-07
Iter: 3235 loss: 2.12778204e-07
Iter: 3236 loss: 2.12713189e-07
Iter: 3237 loss: 2.13056779e-07
Iter: 3238 loss: 2.12708443e-07
Iter: 3239 loss: 2.12626276e-07
Iter: 3240 loss: 2.12882156e-07
Iter: 3241 loss: 2.12630681e-07
Iter: 3242 loss: 2.12556415e-07
Iter: 3243 loss: 2.12854388e-07
Iter: 3244 loss: 2.12549139e-07
Iter: 3245 loss: 2.12532171e-07
Iter: 3246 loss: 2.1252157e-07
Iter: 3247 loss: 2.12487606e-07
Iter: 3248 loss: 2.12410214e-07
Iter: 3249 loss: 2.12630368e-07
Iter: 3250 loss: 2.12386936e-07
Iter: 3251 loss: 2.1234996e-07
Iter: 3252 loss: 2.12314305e-07
Iter: 3253 loss: 2.12296797e-07
Iter: 3254 loss: 2.12215724e-07
Iter: 3255 loss: 2.12840632e-07
Iter: 3256 loss: 2.12229679e-07
Iter: 3257 loss: 2.1214251e-07
Iter: 3258 loss: 2.12048064e-07
Iter: 3259 loss: 2.12070745e-07
Iter: 3260 loss: 2.11994774e-07
Iter: 3261 loss: 2.11990766e-07
Iter: 3262 loss: 2.11940772e-07
Iter: 3263 loss: 2.11894047e-07
Iter: 3264 loss: 2.11885549e-07
Iter: 3265 loss: 2.11847066e-07
Iter: 3266 loss: 2.11740911e-07
Iter: 3267 loss: 2.11744464e-07
Iter: 3268 loss: 2.11656328e-07
Iter: 3269 loss: 2.11895241e-07
Iter: 3270 loss: 2.11633363e-07
Iter: 3271 loss: 2.1154321e-07
Iter: 3272 loss: 2.11595307e-07
Iter: 3273 loss: 2.11492917e-07
Iter: 3274 loss: 2.1149026e-07
Iter: 3275 loss: 2.11447741e-07
Iter: 3276 loss: 2.11438419e-07
Iter: 3277 loss: 2.11407965e-07
Iter: 3278 loss: 2.11406558e-07
Iter: 3279 loss: 2.11374882e-07
Iter: 3280 loss: 2.11709335e-07
Iter: 3281 loss: 2.1135007e-07
Iter: 3282 loss: 2.11330146e-07
Iter: 3283 loss: 2.11336683e-07
Iter: 3284 loss: 2.11272564e-07
Iter: 3285 loss: 2.11214498e-07
Iter: 3286 loss: 2.11322202e-07
Iter: 3287 loss: 2.11225938e-07
Iter: 3288 loss: 2.11190383e-07
Iter: 3289 loss: 2.11441545e-07
Iter: 3290 loss: 2.11168057e-07
Iter: 3291 loss: 2.11116713e-07
Iter: 3292 loss: 2.11093038e-07
Iter: 3293 loss: 2.11093663e-07
Iter: 3294 loss: 2.11002686e-07
Iter: 3295 loss: 2.11365801e-07
Iter: 3296 loss: 2.11004775e-07
Iter: 3297 loss: 2.10957552e-07
Iter: 3298 loss: 2.11418097e-07
Iter: 3299 loss: 2.10950788e-07
Iter: 3300 loss: 2.10962185e-07
Iter: 3301 loss: 2.10947547e-07
Iter: 3302 loss: 2.10943767e-07
Iter: 3303 loss: 2.10959598e-07
Iter: 3304 loss: 2.10957012e-07
Iter: 3305 loss: 2.10951015e-07
Iter: 3306 loss: 2.10951868e-07
Iter: 3307 loss: 2.10960181e-07
Iter: 3308 loss: 2.1094597e-07
Iter: 3309 loss: 2.10946524e-07
Iter: 3310 loss: 2.10943568e-07
Iter: 3311 loss: 2.1094931e-07
Iter: 3312 loss: 2.10957e-07
Iter: 3313 loss: 2.10953388e-07
Iter: 3314 loss: 2.10958135e-07
Iter: 3315 loss: 2.10956145e-07
Iter: 3316 loss: 2.1095218e-07
Iter: 3317 loss: 2.10952322e-07
Iter: 3318 loss: 2.10953687e-07
Iter: 3319 loss: 2.10952948e-07
Iter: 3320 loss: 2.10952862e-07
Iter: 3321 loss: 2.10951626e-07
Iter: 3322 loss: 2.10950631e-07
Iter: 3323 loss: 2.10950631e-07
Iter: 3324 loss: 2.10950631e-07
Iter: 3325 loss: 2.10951626e-07
Iter: 3326 loss: 2.10825476e-07
Iter: 3327 loss: 2.12273179e-07
Iter: 3328 loss: 2.1081236e-07
Iter: 3329 loss: 2.10758031e-07
Iter: 3330 loss: 2.11191306e-07
Iter: 3331 loss: 2.10712898e-07
Iter: 3332 loss: 2.10677257e-07
Iter: 3333 loss: 2.106907e-07
Iter: 3334 loss: 2.10631526e-07
Iter: 3335 loss: 2.10624336e-07
Iter: 3336 loss: 2.10615127e-07
Iter: 3337 loss: 2.10574569e-07
Iter: 3338 loss: 2.1100891e-07
Iter: 3339 loss: 2.10583011e-07
Iter: 3340 loss: 2.10568075e-07
Iter: 3341 loss: 2.10526593e-07
Iter: 3342 loss: 2.1053205e-07
Iter: 3343 loss: 2.10452185e-07
Iter: 3344 loss: 2.10662563e-07
Iter: 3345 loss: 2.10431381e-07
Iter: 3346 loss: 2.10346712e-07
Iter: 3347 loss: 2.10826059e-07
Iter: 3348 loss: 2.10320565e-07
Iter: 3349 loss: 2.10303725e-07
Iter: 3350 loss: 2.10405403e-07
Iter: 3351 loss: 2.10269548e-07
Iter: 3352 loss: 2.10211084e-07
Iter: 3353 loss: 2.10678223e-07
Iter: 3354 loss: 2.10204121e-07
Iter: 3355 loss: 2.10172345e-07
Iter: 3356 loss: 2.10115218e-07
Iter: 3357 loss: 2.10103366e-07
Iter: 3358 loss: 2.10064499e-07
Iter: 3359 loss: 2.10130665e-07
Iter: 3360 loss: 2.1003342e-07
Iter: 3361 loss: 2.10007528e-07
Iter: 3362 loss: 2.10045911e-07
Iter: 3363 loss: 2.10007087e-07
Iter: 3364 loss: 2.09904954e-07
Iter: 3365 loss: 2.10040582e-07
Iter: 3366 loss: 2.09862748e-07
Iter: 3367 loss: 2.09861156e-07
Iter: 3368 loss: 2.09840323e-07
Iter: 3369 loss: 2.09803474e-07
Iter: 3370 loss: 2.0976276e-07
Iter: 3371 loss: 2.09702733e-07
Iter: 3372 loss: 2.09692871e-07
Iter: 3373 loss: 2.09707622e-07
Iter: 3374 loss: 2.09718635e-07
Iter: 3375 loss: 2.09723225e-07
Iter: 3376 loss: 2.09706769e-07
Iter: 3377 loss: 2.09701e-07
Iter: 3378 loss: 2.09708674e-07
Iter: 3379 loss: 2.09715438e-07
Iter: 3380 loss: 2.09719104e-07
Iter: 3381 loss: 2.09722572e-07
Iter: 3382 loss: 2.09729791e-07
Iter: 3383 loss: 2.09722572e-07
Iter: 3384 loss: 2.09721094e-07
Iter: 3385 loss: 2.0972567e-07
Iter: 3386 loss: 2.09707935e-07
Iter: 3387 loss: 2.09703686e-07
Iter: 3388 loss: 2.09714656e-07
Iter: 3389 loss: 2.09699294e-07
Iter: 3390 loss: 2.09712951e-07
Iter: 3391 loss: 2.09707196e-07
Iter: 3392 loss: 2.09705192e-07
Iter: 3393 loss: 2.09701213e-07
Iter: 3394 loss: 2.09700971e-07
Iter: 3395 loss: 2.09701369e-07
Iter: 3396 loss: 2.09704979e-07
Iter: 3397 loss: 2.09701369e-07
Iter: 3398 loss: 2.09701369e-07
Iter: 3399 loss: 2.09704979e-07
Iter: 3400 loss: 2.09701369e-07
Iter: 3401 loss: 2.09701369e-07
Iter: 3402 loss: 2.09704979e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_4000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_4000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db77e37b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db77ea510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db7892840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db78149d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db7775f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db78922f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db7775e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db7726840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db7726620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db767f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db767f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db767f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db765ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db76101e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db75ca158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db75e3d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db7624d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db7624b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1db75589d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6a85aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6a87d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6a81b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6a8306a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6a7efe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6a7efd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6a7ef268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6a75df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6a7efa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d44013400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d44038158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d44044598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d307e3268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d307fb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d307a5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d307552f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d30766c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.78645643e-06
Iter: 2 loss: 1.92163452e-06
Iter: 3 loss: 1.80945938e-06
Iter: 4 loss: 1.48577203e-06
Iter: 5 loss: 1.62363403e-06
Iter: 6 loss: 1.26381622e-06
Iter: 7 loss: 1.12796806e-06
Iter: 8 loss: 1.34883726e-06
Iter: 9 loss: 1.06566063e-06
Iter: 10 loss: 9.96717063e-07
Iter: 11 loss: 9.81628091e-07
Iter: 12 loss: 9.52475546e-07
Iter: 13 loss: 9.39401161e-07
Iter: 14 loss: 9.24680307e-07
Iter: 15 loss: 9.1107438e-07
Iter: 16 loss: 9.10892936e-07
Iter: 17 loss: 8.97005407e-07
Iter: 18 loss: 8.81641597e-07
Iter: 19 loss: 8.79468701e-07
Iter: 20 loss: 8.67054723e-07
Iter: 21 loss: 9.10355482e-07
Iter: 22 loss: 8.63813625e-07
Iter: 23 loss: 8.51058701e-07
Iter: 24 loss: 9.73721853e-07
Iter: 25 loss: 8.50587128e-07
Iter: 26 loss: 8.40172106e-07
Iter: 27 loss: 8.15737508e-07
Iter: 28 loss: 1.1065672e-06
Iter: 29 loss: 8.13703082e-07
Iter: 30 loss: 7.96231348e-07
Iter: 31 loss: 8.53160429e-07
Iter: 32 loss: 7.91381922e-07
Iter: 33 loss: 7.7837052e-07
Iter: 34 loss: 8.33044624e-07
Iter: 35 loss: 7.75696833e-07
Iter: 36 loss: 7.70834163e-07
Iter: 37 loss: 7.97324901e-07
Iter: 38 loss: 7.70070187e-07
Iter: 39 loss: 7.66172207e-07
Iter: 40 loss: 7.93052038e-07
Iter: 41 loss: 7.65789139e-07
Iter: 42 loss: 7.62675256e-07
Iter: 43 loss: 8.06845264e-07
Iter: 44 loss: 7.62693901e-07
Iter: 45 loss: 7.61141223e-07
Iter: 46 loss: 7.56910254e-07
Iter: 47 loss: 7.78210335e-07
Iter: 48 loss: 7.55507472e-07
Iter: 49 loss: 7.53052632e-07
Iter: 50 loss: 7.5188882e-07
Iter: 51 loss: 7.49398737e-07
Iter: 52 loss: 7.4510433e-07
Iter: 53 loss: 7.45116495e-07
Iter: 54 loss: 7.41142e-07
Iter: 55 loss: 7.52263077e-07
Iter: 56 loss: 7.39843244e-07
Iter: 57 loss: 7.35093238e-07
Iter: 58 loss: 7.77067385e-07
Iter: 59 loss: 7.34839773e-07
Iter: 60 loss: 7.32569333e-07
Iter: 61 loss: 7.32313424e-07
Iter: 62 loss: 7.3065371e-07
Iter: 63 loss: 7.29329713e-07
Iter: 64 loss: 7.29299757e-07
Iter: 65 loss: 7.278353e-07
Iter: 66 loss: 7.24753477e-07
Iter: 67 loss: 7.73763077e-07
Iter: 68 loss: 7.24611652e-07
Iter: 69 loss: 7.21820811e-07
Iter: 70 loss: 7.29687429e-07
Iter: 71 loss: 7.20978505e-07
Iter: 72 loss: 7.18331307e-07
Iter: 73 loss: 7.22139305e-07
Iter: 74 loss: 7.17043861e-07
Iter: 75 loss: 7.16604632e-07
Iter: 76 loss: 7.15814053e-07
Iter: 77 loss: 7.1474085e-07
Iter: 78 loss: 7.13853296e-07
Iter: 79 loss: 7.13536792e-07
Iter: 80 loss: 7.12097346e-07
Iter: 81 loss: 7.1254658e-07
Iter: 82 loss: 7.11044891e-07
Iter: 83 loss: 7.09294e-07
Iter: 84 loss: 7.09299684e-07
Iter: 85 loss: 7.0864246e-07
Iter: 86 loss: 7.07208585e-07
Iter: 87 loss: 7.28535952e-07
Iter: 88 loss: 7.07146228e-07
Iter: 89 loss: 7.05907212e-07
Iter: 90 loss: 7.05899822e-07
Iter: 91 loss: 7.04601575e-07
Iter: 92 loss: 7.04267109e-07
Iter: 93 loss: 7.03457943e-07
Iter: 94 loss: 7.0235e-07
Iter: 95 loss: 7.02282136e-07
Iter: 96 loss: 7.0144506e-07
Iter: 97 loss: 7.00145677e-07
Iter: 98 loss: 7.00093e-07
Iter: 99 loss: 6.99323948e-07
Iter: 100 loss: 6.98584131e-07
Iter: 101 loss: 6.98403085e-07
Iter: 102 loss: 6.97678502e-07
Iter: 103 loss: 6.97915425e-07
Iter: 104 loss: 6.9720727e-07
Iter: 105 loss: 6.96076938e-07
Iter: 106 loss: 6.99277052e-07
Iter: 107 loss: 6.95774247e-07
Iter: 108 loss: 6.94776645e-07
Iter: 109 loss: 6.94792675e-07
Iter: 110 loss: 6.94283472e-07
Iter: 111 loss: 6.92822198e-07
Iter: 112 loss: 6.98826398e-07
Iter: 113 loss: 6.92218805e-07
Iter: 114 loss: 6.91416631e-07
Iter: 115 loss: 6.91068351e-07
Iter: 116 loss: 6.89955755e-07
Iter: 117 loss: 6.89042508e-07
Iter: 118 loss: 6.88757609e-07
Iter: 119 loss: 6.87689237e-07
Iter: 120 loss: 6.91952096e-07
Iter: 121 loss: 6.87464194e-07
Iter: 122 loss: 6.8612718e-07
Iter: 123 loss: 6.90362413e-07
Iter: 124 loss: 6.85746045e-07
Iter: 125 loss: 6.8509803e-07
Iter: 126 loss: 6.85704322e-07
Iter: 127 loss: 6.84735255e-07
Iter: 128 loss: 6.84347526e-07
Iter: 129 loss: 6.84329279e-07
Iter: 130 loss: 6.83870667e-07
Iter: 131 loss: 6.83605265e-07
Iter: 132 loss: 6.83400458e-07
Iter: 133 loss: 6.82974246e-07
Iter: 134 loss: 6.83109192e-07
Iter: 135 loss: 6.8264535e-07
Iter: 136 loss: 6.82024051e-07
Iter: 137 loss: 6.81955498e-07
Iter: 138 loss: 6.81483129e-07
Iter: 139 loss: 6.81053052e-07
Iter: 140 loss: 6.80923279e-07
Iter: 141 loss: 6.80526682e-07
Iter: 142 loss: 6.80085293e-07
Iter: 143 loss: 6.80064e-07
Iter: 144 loss: 6.79416814e-07
Iter: 145 loss: 6.81277356e-07
Iter: 146 loss: 6.79273967e-07
Iter: 147 loss: 6.78534434e-07
Iter: 148 loss: 6.83116355e-07
Iter: 149 loss: 6.78439108e-07
Iter: 150 loss: 6.78133517e-07
Iter: 151 loss: 6.77797345e-07
Iter: 152 loss: 6.77764888e-07
Iter: 153 loss: 6.77290927e-07
Iter: 154 loss: 6.77273761e-07
Iter: 155 loss: 6.76926e-07
Iter: 156 loss: 6.76117338e-07
Iter: 157 loss: 6.873953e-07
Iter: 158 loss: 6.7608039e-07
Iter: 159 loss: 6.75572551e-07
Iter: 160 loss: 6.82873633e-07
Iter: 161 loss: 6.75578235e-07
Iter: 162 loss: 6.75045e-07
Iter: 163 loss: 6.77703554e-07
Iter: 164 loss: 6.74978878e-07
Iter: 165 loss: 6.74520493e-07
Iter: 166 loss: 6.73647378e-07
Iter: 167 loss: 6.88115222e-07
Iter: 168 loss: 6.73622651e-07
Iter: 169 loss: 6.73023237e-07
Iter: 170 loss: 6.78721392e-07
Iter: 171 loss: 6.72989302e-07
Iter: 172 loss: 6.72643523e-07
Iter: 173 loss: 6.77245339e-07
Iter: 174 loss: 6.72623059e-07
Iter: 175 loss: 6.72299564e-07
Iter: 176 loss: 6.72124e-07
Iter: 177 loss: 6.71919565e-07
Iter: 178 loss: 6.71548548e-07
Iter: 179 loss: 6.71952876e-07
Iter: 180 loss: 6.71254497e-07
Iter: 181 loss: 6.70775876e-07
Iter: 182 loss: 6.76848401e-07
Iter: 183 loss: 6.7078679e-07
Iter: 184 loss: 6.70391273e-07
Iter: 185 loss: 6.69540213e-07
Iter: 186 loss: 6.83086114e-07
Iter: 187 loss: 6.69493488e-07
Iter: 188 loss: 6.69484052e-07
Iter: 189 loss: 6.69222118e-07
Iter: 190 loss: 6.68953703e-07
Iter: 191 loss: 6.68399366e-07
Iter: 192 loss: 6.76425145e-07
Iter: 193 loss: 6.68413293e-07
Iter: 194 loss: 6.67892095e-07
Iter: 195 loss: 6.70551628e-07
Iter: 196 loss: 6.67810525e-07
Iter: 197 loss: 6.67539325e-07
Iter: 198 loss: 6.67513405e-07
Iter: 199 loss: 6.67326617e-07
Iter: 200 loss: 6.66903247e-07
Iter: 201 loss: 6.745733e-07
Iter: 202 loss: 6.66908647e-07
Iter: 203 loss: 6.66346409e-07
Iter: 204 loss: 6.66815822e-07
Iter: 205 loss: 6.66023425e-07
Iter: 206 loss: 6.65611879e-07
Iter: 207 loss: 6.65585901e-07
Iter: 208 loss: 6.65165089e-07
Iter: 209 loss: 6.65237508e-07
Iter: 210 loss: 6.6481158e-07
Iter: 211 loss: 6.64209551e-07
Iter: 212 loss: 6.63979904e-07
Iter: 213 loss: 6.6363117e-07
Iter: 214 loss: 6.63504807e-07
Iter: 215 loss: 6.63281071e-07
Iter: 216 loss: 6.62998218e-07
Iter: 217 loss: 6.62525224e-07
Iter: 218 loss: 6.73494355e-07
Iter: 219 loss: 6.62504249e-07
Iter: 220 loss: 6.62107425e-07
Iter: 221 loss: 6.65275422e-07
Iter: 222 loss: 6.6210157e-07
Iter: 223 loss: 6.6171765e-07
Iter: 224 loss: 6.63261631e-07
Iter: 225 loss: 6.61633692e-07
Iter: 226 loss: 6.61411832e-07
Iter: 227 loss: 6.6120964e-07
Iter: 228 loss: 6.61176387e-07
Iter: 229 loss: 6.60952708e-07
Iter: 230 loss: 6.6093753e-07
Iter: 231 loss: 6.60703108e-07
Iter: 232 loss: 6.60262685e-07
Iter: 233 loss: 6.60268483e-07
Iter: 234 loss: 6.59875809e-07
Iter: 235 loss: 6.60348121e-07
Iter: 236 loss: 6.59670945e-07
Iter: 237 loss: 6.59142131e-07
Iter: 238 loss: 6.63119863e-07
Iter: 239 loss: 6.59097282e-07
Iter: 240 loss: 6.58633155e-07
Iter: 241 loss: 6.6150028e-07
Iter: 242 loss: 6.58592285e-07
Iter: 243 loss: 6.58316822e-07
Iter: 244 loss: 6.58169938e-07
Iter: 245 loss: 6.58045906e-07
Iter: 246 loss: 6.57790793e-07
Iter: 247 loss: 6.57789201e-07
Iter: 248 loss: 6.5756592e-07
Iter: 249 loss: 6.57235319e-07
Iter: 250 loss: 6.57208886e-07
Iter: 251 loss: 6.56924954e-07
Iter: 252 loss: 6.57089345e-07
Iter: 253 loss: 6.56742259e-07
Iter: 254 loss: 6.56395741e-07
Iter: 255 loss: 6.56336852e-07
Iter: 256 loss: 6.56127838e-07
Iter: 257 loss: 6.55522854e-07
Iter: 258 loss: 6.61415356e-07
Iter: 259 loss: 6.55446e-07
Iter: 260 loss: 6.55284282e-07
Iter: 261 loss: 6.55179861e-07
Iter: 262 loss: 6.5487427e-07
Iter: 263 loss: 6.54687938e-07
Iter: 264 loss: 6.54608925e-07
Iter: 265 loss: 6.54134055e-07
Iter: 266 loss: 6.53566588e-07
Iter: 267 loss: 6.5352782e-07
Iter: 268 loss: 6.53031748e-07
Iter: 269 loss: 6.59447323e-07
Iter: 270 loss: 6.5303027e-07
Iter: 271 loss: 6.52676249e-07
Iter: 272 loss: 6.55876192e-07
Iter: 273 loss: 6.52661242e-07
Iter: 274 loss: 6.52343317e-07
Iter: 275 loss: 6.51706216e-07
Iter: 276 loss: 6.62254763e-07
Iter: 277 loss: 6.51670575e-07
Iter: 278 loss: 6.51319226e-07
Iter: 279 loss: 6.5129035e-07
Iter: 280 loss: 6.50922175e-07
Iter: 281 loss: 6.51369703e-07
Iter: 282 loss: 6.50747893e-07
Iter: 283 loss: 6.50397453e-07
Iter: 284 loss: 6.49769277e-07
Iter: 285 loss: 6.627929e-07
Iter: 286 loss: 6.49772801e-07
Iter: 287 loss: 6.501229e-07
Iter: 288 loss: 6.49561e-07
Iter: 289 loss: 6.49400477e-07
Iter: 290 loss: 6.49154231e-07
Iter: 291 loss: 6.49182e-07
Iter: 292 loss: 6.48918217e-07
Iter: 293 loss: 6.49764331e-07
Iter: 294 loss: 6.48852279e-07
Iter: 295 loss: 6.48526566e-07
Iter: 296 loss: 6.49535082e-07
Iter: 297 loss: 6.4841538e-07
Iter: 298 loss: 6.48241212e-07
Iter: 299 loss: 6.48028617e-07
Iter: 300 loss: 6.48000196e-07
Iter: 301 loss: 6.47571e-07
Iter: 302 loss: 6.47454442e-07
Iter: 303 loss: 6.472103e-07
Iter: 304 loss: 6.47151e-07
Iter: 305 loss: 6.46881688e-07
Iter: 306 loss: 6.46692911e-07
Iter: 307 loss: 6.46313254e-07
Iter: 308 loss: 6.46319847e-07
Iter: 309 loss: 6.45958e-07
Iter: 310 loss: 6.47700688e-07
Iter: 311 loss: 6.45897e-07
Iter: 312 loss: 6.45545128e-07
Iter: 313 loss: 6.48221146e-07
Iter: 314 loss: 6.45521e-07
Iter: 315 loss: 6.45338446e-07
Iter: 316 loss: 6.4507185e-07
Iter: 317 loss: 6.45059458e-07
Iter: 318 loss: 6.44789907e-07
Iter: 319 loss: 6.46060585e-07
Iter: 320 loss: 6.44773422e-07
Iter: 321 loss: 6.44429861e-07
Iter: 322 loss: 6.46274088e-07
Iter: 323 loss: 6.44377565e-07
Iter: 324 loss: 6.4422e-07
Iter: 325 loss: 6.44063959e-07
Iter: 326 loss: 6.44020872e-07
Iter: 327 loss: 6.43711701e-07
Iter: 328 loss: 6.46661078e-07
Iter: 329 loss: 6.43709313e-07
Iter: 330 loss: 6.43480462e-07
Iter: 331 loss: 6.43149633e-07
Iter: 332 loss: 6.43109558e-07
Iter: 333 loss: 6.4281744e-07
Iter: 334 loss: 6.43773546e-07
Iter: 335 loss: 6.42762586e-07
Iter: 336 loss: 6.42515147e-07
Iter: 337 loss: 6.45327418e-07
Iter: 338 loss: 6.42534133e-07
Iter: 339 loss: 6.42256737e-07
Iter: 340 loss: 6.42870475e-07
Iter: 341 loss: 6.42184773e-07
Iter: 342 loss: 6.42024474e-07
Iter: 343 loss: 6.42071427e-07
Iter: 344 loss: 6.41939891e-07
Iter: 345 loss: 6.41763961e-07
Iter: 346 loss: 6.43965848e-07
Iter: 347 loss: 6.41796191e-07
Iter: 348 loss: 6.41630891e-07
Iter: 349 loss: 6.41317797e-07
Iter: 350 loss: 6.45593786e-07
Iter: 351 loss: 6.41303757e-07
Iter: 352 loss: 6.40970541e-07
Iter: 353 loss: 6.41699785e-07
Iter: 354 loss: 6.40845656e-07
Iter: 355 loss: 6.40547341e-07
Iter: 356 loss: 6.45477826e-07
Iter: 357 loss: 6.40519261e-07
Iter: 358 loss: 6.40306894e-07
Iter: 359 loss: 6.39976065e-07
Iter: 360 loss: 6.39966743e-07
Iter: 361 loss: 6.39888867e-07
Iter: 362 loss: 6.39816449e-07
Iter: 363 loss: 6.39709867e-07
Iter: 364 loss: 6.39430482e-07
Iter: 365 loss: 6.43106262e-07
Iter: 366 loss: 6.39409109e-07
Iter: 367 loss: 6.39069867e-07
Iter: 368 loss: 6.39422183e-07
Iter: 369 loss: 6.38907409e-07
Iter: 370 loss: 6.38648544e-07
Iter: 371 loss: 6.4015461e-07
Iter: 372 loss: 6.3863564e-07
Iter: 373 loss: 6.38385586e-07
Iter: 374 loss: 6.40932967e-07
Iter: 375 loss: 6.38380129e-07
Iter: 376 loss: 6.38192887e-07
Iter: 377 loss: 6.37856942e-07
Iter: 378 loss: 6.37842561e-07
Iter: 379 loss: 6.37752805e-07
Iter: 380 loss: 6.37714948e-07
Iter: 381 loss: 6.37579774e-07
Iter: 382 loss: 6.37417372e-07
Iter: 383 loss: 6.37396397e-07
Iter: 384 loss: 6.37209382e-07
Iter: 385 loss: 6.37164362e-07
Iter: 386 loss: 6.37009634e-07
Iter: 387 loss: 6.36944378e-07
Iter: 388 loss: 6.3691607e-07
Iter: 389 loss: 6.36799825e-07
Iter: 390 loss: 6.3652061e-07
Iter: 391 loss: 6.40645055e-07
Iter: 392 loss: 6.36502705e-07
Iter: 393 loss: 6.36308073e-07
Iter: 394 loss: 6.39767677e-07
Iter: 395 loss: 6.36320124e-07
Iter: 396 loss: 6.3610338e-07
Iter: 397 loss: 6.36376058e-07
Iter: 398 loss: 6.3603e-07
Iter: 399 loss: 6.35825e-07
Iter: 400 loss: 6.35378e-07
Iter: 401 loss: 6.41316092e-07
Iter: 402 loss: 6.35371066e-07
Iter: 403 loss: 6.34946616e-07
Iter: 404 loss: 6.39523364e-07
Iter: 405 loss: 6.34920866e-07
Iter: 406 loss: 6.34869366e-07
Iter: 407 loss: 6.34789842e-07
Iter: 408 loss: 6.34669675e-07
Iter: 409 loss: 6.34499088e-07
Iter: 410 loss: 6.34522337e-07
Iter: 411 loss: 6.34325829e-07
Iter: 412 loss: 6.34303547e-07
Iter: 413 loss: 6.34179742e-07
Iter: 414 loss: 6.34011087e-07
Iter: 415 loss: 6.364005e-07
Iter: 416 loss: 6.34021603e-07
Iter: 417 loss: 6.3380287e-07
Iter: 418 loss: 6.33766831e-07
Iter: 419 loss: 6.33647971e-07
Iter: 420 loss: 6.334879e-07
Iter: 421 loss: 6.33452544e-07
Iter: 422 loss: 6.33387e-07
Iter: 423 loss: 6.33109607e-07
Iter: 424 loss: 6.33280933e-07
Iter: 425 loss: 6.32961246e-07
Iter: 426 loss: 6.32955221e-07
Iter: 427 loss: 6.32846309e-07
Iter: 428 loss: 6.3277912e-07
Iter: 429 loss: 6.32673846e-07
Iter: 430 loss: 6.34349135e-07
Iter: 431 loss: 6.32647925e-07
Iter: 432 loss: 6.32523438e-07
Iter: 433 loss: 6.34024786e-07
Iter: 434 loss: 6.32526792e-07
Iter: 435 loss: 6.32425042e-07
Iter: 436 loss: 6.3243732e-07
Iter: 437 loss: 6.32328e-07
Iter: 438 loss: 6.3222376e-07
Iter: 439 loss: 6.32084095e-07
Iter: 440 loss: 6.32104729e-07
Iter: 441 loss: 6.31984904e-07
Iter: 442 loss: 6.31963417e-07
Iter: 443 loss: 6.31818125e-07
Iter: 444 loss: 6.31812554e-07
Iter: 445 loss: 6.3172115e-07
Iter: 446 loss: 6.31607918e-07
Iter: 447 loss: 6.31479793e-07
Iter: 448 loss: 6.31449097e-07
Iter: 449 loss: 6.31222e-07
Iter: 450 loss: 6.33616764e-07
Iter: 451 loss: 6.31198361e-07
Iter: 452 loss: 6.31031867e-07
Iter: 453 loss: 6.32009233e-07
Iter: 454 loss: 6.30977127e-07
Iter: 455 loss: 6.30885495e-07
Iter: 456 loss: 6.30553e-07
Iter: 457 loss: 6.32357114e-07
Iter: 458 loss: 6.30450472e-07
Iter: 459 loss: 6.30048419e-07
Iter: 460 loss: 6.32829483e-07
Iter: 461 loss: 6.2998015e-07
Iter: 462 loss: 6.29694682e-07
Iter: 463 loss: 6.29980377e-07
Iter: 464 loss: 6.29534952e-07
Iter: 465 loss: 6.29300416e-07
Iter: 466 loss: 6.32300839e-07
Iter: 467 loss: 6.29278134e-07
Iter: 468 loss: 6.29118404e-07
Iter: 469 loss: 6.29117721e-07
Iter: 470 loss: 6.28983173e-07
Iter: 471 loss: 6.28660587e-07
Iter: 472 loss: 6.31069611e-07
Iter: 473 loss: 6.28576799e-07
Iter: 474 loss: 6.28509383e-07
Iter: 475 loss: 6.28469877e-07
Iter: 476 loss: 6.28273938e-07
Iter: 477 loss: 6.28052192e-07
Iter: 478 loss: 6.28071746e-07
Iter: 479 loss: 6.27718e-07
Iter: 480 loss: 6.27403779e-07
Iter: 481 loss: 6.27326926e-07
Iter: 482 loss: 6.27613758e-07
Iter: 483 loss: 6.27147529e-07
Iter: 484 loss: 6.27087616e-07
Iter: 485 loss: 6.26869621e-07
Iter: 486 loss: 6.28311113e-07
Iter: 487 loss: 6.26860356e-07
Iter: 488 loss: 6.26591373e-07
Iter: 489 loss: 6.27565328e-07
Iter: 490 loss: 6.26499912e-07
Iter: 491 loss: 6.26460405e-07
Iter: 492 loss: 6.26389635e-07
Iter: 493 loss: 6.26305564e-07
Iter: 494 loss: 6.26045107e-07
Iter: 495 loss: 6.27370753e-07
Iter: 496 loss: 6.2598474e-07
Iter: 497 loss: 6.25673e-07
Iter: 498 loss: 6.26614906e-07
Iter: 499 loss: 6.25582743e-07
Iter: 500 loss: 6.25310236e-07
Iter: 501 loss: 6.26739393e-07
Iter: 502 loss: 6.25287612e-07
Iter: 503 loss: 6.24923359e-07
Iter: 504 loss: 6.26529868e-07
Iter: 505 loss: 6.24864754e-07
Iter: 506 loss: 6.24698259e-07
Iter: 507 loss: 6.24890731e-07
Iter: 508 loss: 6.24616064e-07
Iter: 509 loss: 6.24441157e-07
Iter: 510 loss: 6.26337965e-07
Iter: 511 loss: 6.2442632e-07
Iter: 512 loss: 6.24340032e-07
Iter: 513 loss: 6.23948495e-07
Iter: 514 loss: 6.25829216e-07
Iter: 515 loss: 6.23795302e-07
Iter: 516 loss: 6.23722201e-07
Iter: 517 loss: 6.23606411e-07
Iter: 518 loss: 6.23413712e-07
Iter: 519 loss: 6.23584242e-07
Iter: 520 loss: 6.23312644e-07
Iter: 521 loss: 6.23077881e-07
Iter: 522 loss: 6.22777065e-07
Iter: 523 loss: 6.22761888e-07
Iter: 524 loss: 6.22479e-07
Iter: 525 loss: 6.22470566e-07
Iter: 526 loss: 6.22318623e-07
Iter: 527 loss: 6.22330049e-07
Iter: 528 loss: 6.22191919e-07
Iter: 529 loss: 6.21922368e-07
Iter: 530 loss: 6.24112886e-07
Iter: 531 loss: 6.21835568e-07
Iter: 532 loss: 6.21546519e-07
Iter: 533 loss: 6.23174458e-07
Iter: 534 loss: 6.21479103e-07
Iter: 535 loss: 6.2121353e-07
Iter: 536 loss: 6.2364245e-07
Iter: 537 loss: 6.21215463e-07
Iter: 538 loss: 6.20869969e-07
Iter: 539 loss: 6.20705862e-07
Iter: 540 loss: 6.20538515e-07
Iter: 541 loss: 6.20341552e-07
Iter: 542 loss: 6.20985588e-07
Iter: 543 loss: 6.20288802e-07
Iter: 544 loss: 6.19971388e-07
Iter: 545 loss: 6.20516971e-07
Iter: 546 loss: 6.19820185e-07
Iter: 547 loss: 6.19557227e-07
Iter: 548 loss: 6.19424e-07
Iter: 549 loss: 6.19289438e-07
Iter: 550 loss: 6.19301375e-07
Iter: 551 loss: 6.19181435e-07
Iter: 552 loss: 6.19077696e-07
Iter: 553 loss: 6.18895569e-07
Iter: 554 loss: 6.22318908e-07
Iter: 555 loss: 6.18887952e-07
Iter: 556 loss: 6.1862454e-07
Iter: 557 loss: 6.18818603e-07
Iter: 558 loss: 6.18452873e-07
Iter: 559 loss: 6.18243291e-07
Iter: 560 loss: 6.21710342e-07
Iter: 561 loss: 6.18253e-07
Iter: 562 loss: 6.17957312e-07
Iter: 563 loss: 6.18077479e-07
Iter: 564 loss: 6.17735736e-07
Iter: 565 loss: 6.17477895e-07
Iter: 566 loss: 6.17417527e-07
Iter: 567 loss: 6.17232558e-07
Iter: 568 loss: 6.16946465e-07
Iter: 569 loss: 6.18159675e-07
Iter: 570 loss: 6.1689417e-07
Iter: 571 loss: 6.16561579e-07
Iter: 572 loss: 6.19440186e-07
Iter: 573 loss: 6.16572208e-07
Iter: 574 loss: 6.16376724e-07
Iter: 575 loss: 6.16042712e-07
Iter: 576 loss: 6.16027137e-07
Iter: 577 loss: 6.15853082e-07
Iter: 578 loss: 6.15845579e-07
Iter: 579 loss: 6.1561019e-07
Iter: 580 loss: 6.1542363e-07
Iter: 581 loss: 6.15376052e-07
Iter: 582 loss: 6.15071428e-07
Iter: 583 loss: 6.15544536e-07
Iter: 584 loss: 6.14938699e-07
Iter: 585 loss: 6.14816202e-07
Iter: 586 loss: 6.14765554e-07
Iter: 587 loss: 6.14700866e-07
Iter: 588 loss: 6.14471617e-07
Iter: 589 loss: 6.15280442e-07
Iter: 590 loss: 6.14340252e-07
Iter: 591 loss: 6.14214116e-07
Iter: 592 loss: 6.14187115e-07
Iter: 593 loss: 6.14043415e-07
Iter: 594 loss: 6.14484748e-07
Iter: 595 loss: 6.13975601e-07
Iter: 596 loss: 6.13819566e-07
Iter: 597 loss: 6.13596285e-07
Iter: 598 loss: 6.1356161e-07
Iter: 599 loss: 6.13295128e-07
Iter: 600 loss: 6.13926375e-07
Iter: 601 loss: 6.13135285e-07
Iter: 602 loss: 6.12971803e-07
Iter: 603 loss: 6.12957763e-07
Iter: 604 loss: 6.12752274e-07
Iter: 605 loss: 6.12379097e-07
Iter: 606 loss: 6.21150434e-07
Iter: 607 loss: 6.1237688e-07
Iter: 608 loss: 6.12037297e-07
Iter: 609 loss: 6.1286346e-07
Iter: 610 loss: 6.11898031e-07
Iter: 611 loss: 6.11645191e-07
Iter: 612 loss: 6.13329462e-07
Iter: 613 loss: 6.11621545e-07
Iter: 614 loss: 6.11293558e-07
Iter: 615 loss: 6.11628479e-07
Iter: 616 loss: 6.11091309e-07
Iter: 617 loss: 6.10888264e-07
Iter: 618 loss: 6.10996494e-07
Iter: 619 loss: 6.10793109e-07
Iter: 620 loss: 6.10566588e-07
Iter: 621 loss: 6.10568691e-07
Iter: 622 loss: 6.10429879e-07
Iter: 623 loss: 6.10002473e-07
Iter: 624 loss: 6.14000271e-07
Iter: 625 loss: 6.09957397e-07
Iter: 626 loss: 6.09676135e-07
Iter: 627 loss: 6.12188273e-07
Iter: 628 loss: 6.09715357e-07
Iter: 629 loss: 6.09523681e-07
Iter: 630 loss: 6.09521521e-07
Iter: 631 loss: 6.09388508e-07
Iter: 632 loss: 6.09114522e-07
Iter: 633 loss: 6.13342763e-07
Iter: 634 loss: 6.09082463e-07
Iter: 635 loss: 6.08937739e-07
Iter: 636 loss: 6.10358484e-07
Iter: 637 loss: 6.0894e-07
Iter: 638 loss: 6.08798814e-07
Iter: 639 loss: 6.09709e-07
Iter: 640 loss: 6.08746632e-07
Iter: 641 loss: 6.08640221e-07
Iter: 642 loss: 6.08414666e-07
Iter: 643 loss: 6.08411e-07
Iter: 644 loss: 6.08220148e-07
Iter: 645 loss: 6.0884804e-07
Iter: 646 loss: 6.08179e-07
Iter: 647 loss: 6.0802796e-07
Iter: 648 loss: 6.10234508e-07
Iter: 649 loss: 6.08041319e-07
Iter: 650 loss: 6.07893185e-07
Iter: 651 loss: 6.07849074e-07
Iter: 652 loss: 6.07770176e-07
Iter: 653 loss: 6.0767735e-07
Iter: 654 loss: 6.07801894e-07
Iter: 655 loss: 6.07606864e-07
Iter: 656 loss: 6.07453558e-07
Iter: 657 loss: 6.08064113e-07
Iter: 658 loss: 6.07389268e-07
Iter: 659 loss: 6.07275865e-07
Iter: 660 loss: 6.07153822e-07
Iter: 661 loss: 6.0713819e-07
Iter: 662 loss: 6.06992444e-07
Iter: 663 loss: 6.07999084e-07
Iter: 664 loss: 6.06981416e-07
Iter: 665 loss: 6.06761034e-07
Iter: 666 loss: 6.06844083e-07
Iter: 667 loss: 6.06590561e-07
Iter: 668 loss: 6.06430433e-07
Iter: 669 loss: 6.06427534e-07
Iter: 670 loss: 6.06311801e-07
Iter: 671 loss: 6.0608545e-07
Iter: 672 loss: 6.06057654e-07
Iter: 673 loss: 6.05947832e-07
Iter: 674 loss: 6.06069193e-07
Iter: 675 loss: 6.05799244e-07
Iter: 676 loss: 6.05744503e-07
Iter: 677 loss: 6.05641844e-07
Iter: 678 loss: 6.06751769e-07
Iter: 679 loss: 6.05619562e-07
Iter: 680 loss: 6.05497462e-07
Iter: 681 loss: 6.06139793e-07
Iter: 682 loss: 6.05440505e-07
Iter: 683 loss: 6.05323748e-07
Iter: 684 loss: 6.06249159e-07
Iter: 685 loss: 6.053e-07
Iter: 686 loss: 6.0522234e-07
Iter: 687 loss: 6.05094783e-07
Iter: 688 loss: 6.05073865e-07
Iter: 689 loss: 6.04959496e-07
Iter: 690 loss: 6.04939032e-07
Iter: 691 loss: 6.04826369e-07
Iter: 692 loss: 6.04683805e-07
Iter: 693 loss: 6.04652882e-07
Iter: 694 loss: 6.04512195e-07
Iter: 695 loss: 6.04497188e-07
Iter: 696 loss: 6.04388333e-07
Iter: 697 loss: 6.04203933e-07
Iter: 698 loss: 6.06583399e-07
Iter: 699 loss: 6.04181878e-07
Iter: 700 loss: 6.04059e-07
Iter: 701 loss: 6.06216304e-07
Iter: 702 loss: 6.04051138e-07
Iter: 703 loss: 6.03985427e-07
Iter: 704 loss: 6.03811145e-07
Iter: 705 loss: 6.05154696e-07
Iter: 706 loss: 6.0381285e-07
Iter: 707 loss: 6.03587182e-07
Iter: 708 loss: 6.04581828e-07
Iter: 709 loss: 6.03570129e-07
Iter: 710 loss: 6.0339238e-07
Iter: 711 loss: 6.03396529e-07
Iter: 712 loss: 6.03327351e-07
Iter: 713 loss: 6.032e-07
Iter: 714 loss: 6.04158231e-07
Iter: 715 loss: 6.03200306e-07
Iter: 716 loss: 6.0307184e-07
Iter: 717 loss: 6.03051e-07
Iter: 718 loss: 6.02971795e-07
Iter: 719 loss: 6.02915179e-07
Iter: 720 loss: 6.02841908e-07
Iter: 721 loss: 6.02720945e-07
Iter: 722 loss: 6.02872262e-07
Iter: 723 loss: 6.02705143e-07
Iter: 724 loss: 6.02520629e-07
Iter: 725 loss: 6.02822865e-07
Iter: 726 loss: 6.02446448e-07
Iter: 727 loss: 6.02299679e-07
Iter: 728 loss: 6.0228956e-07
Iter: 729 loss: 6.02194859e-07
Iter: 730 loss: 6.02063324e-07
Iter: 731 loss: 6.02210662e-07
Iter: 732 loss: 6.01939405e-07
Iter: 733 loss: 6.01838565e-07
Iter: 734 loss: 6.0185846e-07
Iter: 735 loss: 6.01771603e-07
Iter: 736 loss: 6.01870283e-07
Iter: 737 loss: 6.01737099e-07
Iter: 738 loss: 6.01685826e-07
Iter: 739 loss: 6.01581746e-07
Iter: 740 loss: 6.03987473e-07
Iter: 741 loss: 6.01571742e-07
Iter: 742 loss: 6.01535532e-07
Iter: 743 loss: 6.01531269e-07
Iter: 744 loss: 6.01456804e-07
Iter: 745 loss: 6.01355111e-07
Iter: 746 loss: 6.0361117e-07
Iter: 747 loss: 6.01348859e-07
Iter: 748 loss: 6.01255351e-07
Iter: 749 loss: 6.01391946e-07
Iter: 750 loss: 6.01214879e-07
Iter: 751 loss: 6.0103855e-07
Iter: 752 loss: 6.01741e-07
Iter: 753 loss: 6.01023658e-07
Iter: 754 loss: 6.00947487e-07
Iter: 755 loss: 6.00885187e-07
Iter: 756 loss: 6.00823171e-07
Iter: 757 loss: 6.00664578e-07
Iter: 758 loss: 6.01838e-07
Iter: 759 loss: 6.00669523e-07
Iter: 760 loss: 6.00558678e-07
Iter: 761 loss: 6.00441e-07
Iter: 762 loss: 6.00422823e-07
Iter: 763 loss: 6.00332669e-07
Iter: 764 loss: 6.00728299e-07
Iter: 765 loss: 6.00291969e-07
Iter: 766 loss: 6.00237968e-07
Iter: 767 loss: 6.00321187e-07
Iter: 768 loss: 6.00217163e-07
Iter: 769 loss: 6.0013565e-07
Iter: 770 loss: 6.00047656e-07
Iter: 771 loss: 6.00051408e-07
Iter: 772 loss: 5.99948351e-07
Iter: 773 loss: 6.00159353e-07
Iter: 774 loss: 5.99900545e-07
Iter: 775 loss: 5.99799705e-07
Iter: 776 loss: 6.00417479e-07
Iter: 777 loss: 5.99748887e-07
Iter: 778 loss: 5.99622e-07
Iter: 779 loss: 6.00047088e-07
Iter: 780 loss: 5.99562782e-07
Iter: 781 loss: 5.99504119e-07
Iter: 782 loss: 5.99467e-07
Iter: 783 loss: 5.99433861e-07
Iter: 784 loss: 5.99360249e-07
Iter: 785 loss: 6.0067191e-07
Iter: 786 loss: 5.99362068e-07
Iter: 787 loss: 5.99265888e-07
Iter: 788 loss: 5.99209557e-07
Iter: 789 loss: 5.99176e-07
Iter: 790 loss: 5.99109512e-07
Iter: 791 loss: 5.99122075e-07
Iter: 792 loss: 5.99048349e-07
Iter: 793 loss: 5.98926476e-07
Iter: 794 loss: 6.01189072e-07
Iter: 795 loss: 5.98918291e-07
Iter: 796 loss: 5.98779707e-07
Iter: 797 loss: 6.00005819e-07
Iter: 798 loss: 5.98762313e-07
Iter: 799 loss: 5.98665792e-07
Iter: 800 loss: 5.99338421e-07
Iter: 801 loss: 5.9861884e-07
Iter: 802 loss: 5.98556881e-07
Iter: 803 loss: 5.98426141e-07
Iter: 804 loss: 5.9843336e-07
Iter: 805 loss: 5.98248789e-07
Iter: 806 loss: 5.9833377e-07
Iter: 807 loss: 5.98094516e-07
Iter: 808 loss: 5.97992e-07
Iter: 809 loss: 5.9798208e-07
Iter: 810 loss: 5.97925521e-07
Iter: 811 loss: 5.97902613e-07
Iter: 812 loss: 5.97842302e-07
Iter: 813 loss: 5.97706617e-07
Iter: 814 loss: 5.98732868e-07
Iter: 815 loss: 5.97687858e-07
Iter: 816 loss: 5.97613962e-07
Iter: 817 loss: 5.97593385e-07
Iter: 818 loss: 5.97504936e-07
Iter: 819 loss: 5.97448206e-07
Iter: 820 loss: 5.97410917e-07
Iter: 821 loss: 5.97277221e-07
Iter: 822 loss: 5.97810697e-07
Iter: 823 loss: 5.97238454e-07
Iter: 824 loss: 5.97097937e-07
Iter: 825 loss: 5.97111807e-07
Iter: 826 loss: 5.96960433e-07
Iter: 827 loss: 5.96812e-07
Iter: 828 loss: 5.97437065e-07
Iter: 829 loss: 5.96793e-07
Iter: 830 loss: 5.96651375e-07
Iter: 831 loss: 5.97895109e-07
Iter: 832 loss: 5.96626592e-07
Iter: 833 loss: 5.96526206e-07
Iter: 834 loss: 5.96461916e-07
Iter: 835 loss: 5.96413827e-07
Iter: 836 loss: 5.96292693e-07
Iter: 837 loss: 5.96544339e-07
Iter: 838 loss: 5.96237e-07
Iter: 839 loss: 5.96062705e-07
Iter: 840 loss: 5.962101e-07
Iter: 841 loss: 5.96006316e-07
Iter: 842 loss: 5.96000177e-07
Iter: 843 loss: 5.95934807e-07
Iter: 844 loss: 5.95854601e-07
Iter: 845 loss: 5.95746144e-07
Iter: 846 loss: 5.95757115e-07
Iter: 847 loss: 5.95600682e-07
Iter: 848 loss: 5.95344e-07
Iter: 849 loss: 5.95337724e-07
Iter: 850 loss: 5.95458459e-07
Iter: 851 loss: 5.95223696e-07
Iter: 852 loss: 5.95126778e-07
Iter: 853 loss: 5.94956703e-07
Iter: 854 loss: 5.97583323e-07
Iter: 855 loss: 5.94952382e-07
Iter: 856 loss: 5.94776395e-07
Iter: 857 loss: 5.94789867e-07
Iter: 858 loss: 5.94639118e-07
Iter: 859 loss: 5.94708126e-07
Iter: 860 loss: 5.94551409e-07
Iter: 861 loss: 5.94420271e-07
Iter: 862 loss: 5.94507583e-07
Iter: 863 loss: 5.94390144e-07
Iter: 864 loss: 5.94213e-07
Iter: 865 loss: 5.95981703e-07
Iter: 866 loss: 5.94201083e-07
Iter: 867 loss: 5.94097742e-07
Iter: 868 loss: 5.94038283e-07
Iter: 869 loss: 5.94002245e-07
Iter: 870 loss: 5.93873096e-07
Iter: 871 loss: 5.9373059e-07
Iter: 872 loss: 5.93707227e-07
Iter: 873 loss: 5.93587174e-07
Iter: 874 loss: 5.93590755e-07
Iter: 875 loss: 5.93491052e-07
Iter: 876 loss: 5.93757e-07
Iter: 877 loss: 5.93482241e-07
Iter: 878 loss: 5.9339385e-07
Iter: 879 loss: 5.93349569e-07
Iter: 880 loss: 5.93302275e-07
Iter: 881 loss: 5.93231164e-07
Iter: 882 loss: 5.93689265e-07
Iter: 883 loss: 5.93206778e-07
Iter: 884 loss: 5.9309059e-07
Iter: 885 loss: 5.93459333e-07
Iter: 886 loss: 5.93052732e-07
Iter: 887 loss: 5.92957406e-07
Iter: 888 loss: 5.92736342e-07
Iter: 889 loss: 5.92741458e-07
Iter: 890 loss: 5.92653066e-07
Iter: 891 loss: 5.92619131e-07
Iter: 892 loss: 5.9249237e-07
Iter: 893 loss: 5.92219578e-07
Iter: 894 loss: 5.95360461e-07
Iter: 895 loss: 5.92202639e-07
Iter: 896 loss: 5.91965204e-07
Iter: 897 loss: 5.93325694e-07
Iter: 898 loss: 5.91937e-07
Iter: 899 loss: 5.91918763e-07
Iter: 900 loss: 5.91920298e-07
Iter: 901 loss: 5.91848561e-07
Iter: 902 loss: 5.91710545e-07
Iter: 903 loss: 5.91856235e-07
Iter: 904 loss: 5.9161971e-07
Iter: 905 loss: 5.91365847e-07
Iter: 906 loss: 5.92731681e-07
Iter: 907 loss: 5.91342484e-07
Iter: 908 loss: 5.91275807e-07
Iter: 909 loss: 5.91240905e-07
Iter: 910 loss: 5.91167179e-07
Iter: 911 loss: 5.90954869e-07
Iter: 912 loss: 5.93815685e-07
Iter: 913 loss: 5.90974e-07
Iter: 914 loss: 5.90731588e-07
Iter: 915 loss: 5.91196113e-07
Iter: 916 loss: 5.90627792e-07
Iter: 917 loss: 5.90522234e-07
Iter: 918 loss: 5.90499496e-07
Iter: 919 loss: 5.90385127e-07
Iter: 920 loss: 5.90284742e-07
Iter: 921 loss: 5.90273146e-07
Iter: 922 loss: 5.90161e-07
Iter: 923 loss: 5.90794e-07
Iter: 924 loss: 5.90121886e-07
Iter: 925 loss: 5.90040941e-07
Iter: 926 loss: 5.91115167e-07
Iter: 927 loss: 5.9001934e-07
Iter: 928 loss: 5.899401e-07
Iter: 929 loss: 5.89722276e-07
Iter: 930 loss: 5.91542062e-07
Iter: 931 loss: 5.89683168e-07
Iter: 932 loss: 5.89500928e-07
Iter: 933 loss: 5.90095169e-07
Iter: 934 loss: 5.89462388e-07
Iter: 935 loss: 5.89254626e-07
Iter: 936 loss: 5.89816182e-07
Iter: 937 loss: 5.89207e-07
Iter: 938 loss: 5.89224385e-07
Iter: 939 loss: 5.89150375e-07
Iter: 940 loss: 5.89102058e-07
Iter: 941 loss: 5.88955231e-07
Iter: 942 loss: 5.89477793e-07
Iter: 943 loss: 5.88953753e-07
Iter: 944 loss: 5.88876844e-07
Iter: 945 loss: 5.88841374e-07
Iter: 946 loss: 5.88751e-07
Iter: 947 loss: 5.88772878e-07
Iter: 948 loss: 5.88692842e-07
Iter: 949 loss: 5.88589955e-07
Iter: 950 loss: 5.88545504e-07
Iter: 951 loss: 5.88527655e-07
Iter: 952 loss: 5.88355761e-07
Iter: 953 loss: 5.89564081e-07
Iter: 954 loss: 5.88351e-07
Iter: 955 loss: 5.88260036e-07
Iter: 956 loss: 5.88211492e-07
Iter: 957 loss: 5.88150328e-07
Iter: 958 loss: 5.88050568e-07
Iter: 959 loss: 5.88462058e-07
Iter: 960 loss: 5.88018963e-07
Iter: 961 loss: 5.87868669e-07
Iter: 962 loss: 5.89121782e-07
Iter: 963 loss: 5.87891293e-07
Iter: 964 loss: 5.87788691e-07
Iter: 965 loss: 5.87744296e-07
Iter: 966 loss: 5.87739635e-07
Iter: 967 loss: 5.87662271e-07
Iter: 968 loss: 5.87497084e-07
Iter: 969 loss: 5.90594254e-07
Iter: 970 loss: 5.87505497e-07
Iter: 971 loss: 5.87411193e-07
Iter: 972 loss: 5.87407953e-07
Iter: 973 loss: 5.8732337e-07
Iter: 974 loss: 5.87289719e-07
Iter: 975 loss: 5.87239583e-07
Iter: 976 loss: 5.87125214e-07
Iter: 977 loss: 5.87053e-07
Iter: 978 loss: 5.86984697e-07
Iter: 979 loss: 5.86765736e-07
Iter: 980 loss: 5.86765e-07
Iter: 981 loss: 5.86693886e-07
Iter: 982 loss: 5.86605836e-07
Iter: 983 loss: 5.86570479e-07
Iter: 984 loss: 5.86423141e-07
Iter: 985 loss: 5.87757938e-07
Iter: 986 loss: 5.86451392e-07
Iter: 987 loss: 5.8628973e-07
Iter: 988 loss: 5.86076567e-07
Iter: 989 loss: 5.86086912e-07
Iter: 990 loss: 5.85889211e-07
Iter: 991 loss: 5.86632666e-07
Iter: 992 loss: 5.85882731e-07
Iter: 993 loss: 5.85686166e-07
Iter: 994 loss: 5.85741077e-07
Iter: 995 loss: 5.85552584e-07
Iter: 996 loss: 5.85461805e-07
Iter: 997 loss: 5.85402518e-07
Iter: 998 loss: 5.8534448e-07
Iter: 999 loss: 5.85205385e-07
Iter: 1000 loss: 5.88170451e-07
Iter: 1001 loss: 5.8519629e-07
Iter: 1002 loss: 5.85054181e-07
Iter: 1003 loss: 5.86445651e-07
Iter: 1004 loss: 5.85044404e-07
Iter: 1005 loss: 5.84976078e-07
Iter: 1006 loss: 5.851075e-07
Iter: 1007 loss: 5.84928046e-07
Iter: 1008 loss: 5.84852501e-07
Iter: 1009 loss: 5.84839142e-07
Iter: 1010 loss: 5.84764734e-07
Iter: 1011 loss: 5.84695499e-07
Iter: 1012 loss: 5.85106534e-07
Iter: 1013 loss: 5.84720738e-07
Iter: 1014 loss: 5.84565441e-07
Iter: 1015 loss: 5.84646727e-07
Iter: 1016 loss: 5.8445778e-07
Iter: 1017 loss: 5.84366944e-07
Iter: 1018 loss: 5.85103066e-07
Iter: 1019 loss: 5.84372572e-07
Iter: 1020 loss: 5.84265194e-07
Iter: 1021 loss: 5.84388e-07
Iter: 1022 loss: 5.84185102e-07
Iter: 1023 loss: 5.84127e-07
Iter: 1024 loss: 5.84035604e-07
Iter: 1025 loss: 5.84033558e-07
Iter: 1026 loss: 5.83835117e-07
Iter: 1027 loss: 5.84152417e-07
Iter: 1028 loss: 5.83782253e-07
Iter: 1029 loss: 5.83615758e-07
Iter: 1030 loss: 5.84334828e-07
Iter: 1031 loss: 5.83592623e-07
Iter: 1032 loss: 5.83479448e-07
Iter: 1033 loss: 5.84845054e-07
Iter: 1034 loss: 5.83491669e-07
Iter: 1035 loss: 5.83413168e-07
Iter: 1036 loss: 5.83350925e-07
Iter: 1037 loss: 5.83287658e-07
Iter: 1038 loss: 5.83199494e-07
Iter: 1039 loss: 5.83680048e-07
Iter: 1040 loss: 5.83179656e-07
Iter: 1041 loss: 5.83073643e-07
Iter: 1042 loss: 5.83338533e-07
Iter: 1043 loss: 5.83062274e-07
Iter: 1044 loss: 5.8298383e-07
Iter: 1045 loss: 5.82745486e-07
Iter: 1046 loss: 5.84060331e-07
Iter: 1047 loss: 5.82681821e-07
Iter: 1048 loss: 5.82560915e-07
Iter: 1049 loss: 5.82576376e-07
Iter: 1050 loss: 5.82459279e-07
Iter: 1051 loss: 5.82477242e-07
Iter: 1052 loss: 5.82385042e-07
Iter: 1053 loss: 5.82254586e-07
Iter: 1054 loss: 5.84509053e-07
Iter: 1055 loss: 5.82250209e-07
Iter: 1056 loss: 5.82177336e-07
Iter: 1057 loss: 5.82156133e-07
Iter: 1058 loss: 5.82099233e-07
Iter: 1059 loss: 5.81972643e-07
Iter: 1060 loss: 5.83843075e-07
Iter: 1061 loss: 5.81898519e-07
Iter: 1062 loss: 5.81767836e-07
Iter: 1063 loss: 5.82456437e-07
Iter: 1064 loss: 5.8173714e-07
Iter: 1065 loss: 5.8159327e-07
Iter: 1066 loss: 5.81593326e-07
Iter: 1067 loss: 5.81486631e-07
Iter: 1068 loss: 5.81305e-07
Iter: 1069 loss: 5.82477e-07
Iter: 1070 loss: 5.81273525e-07
Iter: 1071 loss: 5.81210884e-07
Iter: 1072 loss: 5.81180927e-07
Iter: 1073 loss: 5.81137215e-07
Iter: 1074 loss: 5.80979531e-07
Iter: 1075 loss: 5.81726454e-07
Iter: 1076 loss: 5.80946e-07
Iter: 1077 loss: 5.80900519e-07
Iter: 1078 loss: 5.8085385e-07
Iter: 1079 loss: 5.80753294e-07
Iter: 1080 loss: 5.80596634e-07
Iter: 1081 loss: 5.82515781e-07
Iter: 1082 loss: 5.80578899e-07
Iter: 1083 loss: 5.80383642e-07
Iter: 1084 loss: 5.80547407e-07
Iter: 1085 loss: 5.80263304e-07
Iter: 1086 loss: 5.80156438e-07
Iter: 1087 loss: 5.81243285e-07
Iter: 1088 loss: 5.80129836e-07
Iter: 1089 loss: 5.80004667e-07
Iter: 1090 loss: 5.81105951e-07
Iter: 1091 loss: 5.80002734e-07
Iter: 1092 loss: 5.79922528e-07
Iter: 1093 loss: 5.79822768e-07
Iter: 1094 loss: 5.798247e-07
Iter: 1095 loss: 5.79746938e-07
Iter: 1096 loss: 5.80689061e-07
Iter: 1097 loss: 5.79741595e-07
Iter: 1098 loss: 5.79654056e-07
Iter: 1099 loss: 5.7960267e-07
Iter: 1100 loss: 5.79574476e-07
Iter: 1101 loss: 5.7945482e-07
Iter: 1102 loss: 5.79461698e-07
Iter: 1103 loss: 5.79367622e-07
Iter: 1104 loss: 5.792092e-07
Iter: 1105 loss: 5.79065841e-07
Iter: 1106 loss: 5.79059758e-07
Iter: 1107 loss: 5.7890162e-07
Iter: 1108 loss: 5.78903496e-07
Iter: 1109 loss: 5.7879447e-07
Iter: 1110 loss: 5.78796403e-07
Iter: 1111 loss: 5.78770823e-07
Iter: 1112 loss: 5.78645086e-07
Iter: 1113 loss: 5.80185144e-07
Iter: 1114 loss: 5.78628146e-07
Iter: 1115 loss: 5.78551862e-07
Iter: 1116 loss: 5.78530603e-07
Iter: 1117 loss: 5.7847376e-07
Iter: 1118 loss: 5.78378945e-07
Iter: 1119 loss: 5.78382526e-07
Iter: 1120 loss: 5.78286063e-07
Iter: 1121 loss: 5.78077447e-07
Iter: 1122 loss: 5.78077e-07
Iter: 1123 loss: 5.77994115e-07
Iter: 1124 loss: 5.77965e-07
Iter: 1125 loss: 5.77848482e-07
Iter: 1126 loss: 5.78047263e-07
Iter: 1127 loss: 5.77807953e-07
Iter: 1128 loss: 5.7770842e-07
Iter: 1129 loss: 5.7763657e-07
Iter: 1130 loss: 5.77627134e-07
Iter: 1131 loss: 5.77633386e-07
Iter: 1132 loss: 5.77582114e-07
Iter: 1133 loss: 5.77531239e-07
Iter: 1134 loss: 5.77445576e-07
Iter: 1135 loss: 5.78600407e-07
Iter: 1136 loss: 5.77411868e-07
Iter: 1137 loss: 5.77315404e-07
Iter: 1138 loss: 5.77389642e-07
Iter: 1139 loss: 5.7724111e-07
Iter: 1140 loss: 5.77133733e-07
Iter: 1141 loss: 5.77137314e-07
Iter: 1142 loss: 5.77018e-07
Iter: 1143 loss: 5.77137143e-07
Iter: 1144 loss: 5.76962066e-07
Iter: 1145 loss: 5.76830303e-07
Iter: 1146 loss: 5.76962805e-07
Iter: 1147 loss: 5.76750722e-07
Iter: 1148 loss: 5.76647949e-07
Iter: 1149 loss: 5.76618049e-07
Iter: 1150 loss: 5.76579055e-07
Iter: 1151 loss: 5.76462071e-07
Iter: 1152 loss: 5.78048969e-07
Iter: 1153 loss: 5.76430807e-07
Iter: 1154 loss: 5.76306547e-07
Iter: 1155 loss: 5.7700845e-07
Iter: 1156 loss: 5.7629245e-07
Iter: 1157 loss: 5.76260277e-07
Iter: 1158 loss: 5.7626886e-07
Iter: 1159 loss: 5.76200819e-07
Iter: 1160 loss: 5.76094806e-07
Iter: 1161 loss: 5.77768844e-07
Iter: 1162 loss: 5.76075479e-07
Iter: 1163 loss: 5.75984e-07
Iter: 1164 loss: 5.76125217e-07
Iter: 1165 loss: 5.75919614e-07
Iter: 1166 loss: 5.75856404e-07
Iter: 1167 loss: 5.75871582e-07
Iter: 1168 loss: 5.75769832e-07
Iter: 1169 loss: 5.7565552e-07
Iter: 1170 loss: 5.78068125e-07
Iter: 1171 loss: 5.75652962e-07
Iter: 1172 loss: 5.75533079e-07
Iter: 1173 loss: 5.76049729e-07
Iter: 1174 loss: 5.75502952e-07
Iter: 1175 loss: 5.75454692e-07
Iter: 1176 loss: 5.75461286e-07
Iter: 1177 loss: 5.75387446e-07
Iter: 1178 loss: 5.75311105e-07
Iter: 1179 loss: 5.77274e-07
Iter: 1180 loss: 5.7530184e-07
Iter: 1181 loss: 5.75284957e-07
Iter: 1182 loss: 5.75261538e-07
Iter: 1183 loss: 5.75211288e-07
Iter: 1184 loss: 5.75111187e-07
Iter: 1185 loss: 5.77186427e-07
Iter: 1186 loss: 5.75114427e-07
Iter: 1187 loss: 5.75006766e-07
Iter: 1188 loss: 5.74841067e-07
Iter: 1189 loss: 5.74812589e-07
Iter: 1190 loss: 5.74665592e-07
Iter: 1191 loss: 5.76149318e-07
Iter: 1192 loss: 5.74629098e-07
Iter: 1193 loss: 5.74491139e-07
Iter: 1194 loss: 5.7625175e-07
Iter: 1195 loss: 5.74516207e-07
Iter: 1196 loss: 5.74344199e-07
Iter: 1197 loss: 5.74136379e-07
Iter: 1198 loss: 5.74121941e-07
Iter: 1199 loss: 5.74003366e-07
Iter: 1200 loss: 5.74201408e-07
Iter: 1201 loss: 5.73981652e-07
Iter: 1202 loss: 5.73844432e-07
Iter: 1203 loss: 5.75106e-07
Iter: 1204 loss: 5.73827e-07
Iter: 1205 loss: 5.73739385e-07
Iter: 1206 loss: 5.74127682e-07
Iter: 1207 loss: 5.73723582e-07
Iter: 1208 loss: 5.73652869e-07
Iter: 1209 loss: 5.73496266e-07
Iter: 1210 loss: 5.75474928e-07
Iter: 1211 loss: 5.73488705e-07
Iter: 1212 loss: 5.73393095e-07
Iter: 1213 loss: 5.73373654e-07
Iter: 1214 loss: 5.73291e-07
Iter: 1215 loss: 5.73228249e-07
Iter: 1216 loss: 5.73202101e-07
Iter: 1217 loss: 5.73123657e-07
Iter: 1218 loss: 5.73115358e-07
Iter: 1219 loss: 5.73038392e-07
Iter: 1220 loss: 5.7283637e-07
Iter: 1221 loss: 5.74871308e-07
Iter: 1222 loss: 5.7284069e-07
Iter: 1223 loss: 5.72696536e-07
Iter: 1224 loss: 5.73677482e-07
Iter: 1225 loss: 5.72673571e-07
Iter: 1226 loss: 5.72582167e-07
Iter: 1227 loss: 5.7298962e-07
Iter: 1228 loss: 5.72578529e-07
Iter: 1229 loss: 5.72449267e-07
Iter: 1230 loss: 5.72842396e-07
Iter: 1231 loss: 5.72407316e-07
Iter: 1232 loss: 5.72352064e-07
Iter: 1233 loss: 5.72279646e-07
Iter: 1234 loss: 5.72252e-07
Iter: 1235 loss: 5.72093882e-07
Iter: 1236 loss: 5.72240879e-07
Iter: 1237 loss: 5.71969906e-07
Iter: 1238 loss: 5.71957116e-07
Iter: 1239 loss: 5.7188447e-07
Iter: 1240 loss: 5.71832629e-07
Iter: 1241 loss: 5.71782607e-07
Iter: 1242 loss: 5.71745716e-07
Iter: 1243 loss: 5.71639248e-07
Iter: 1244 loss: 5.72094962e-07
Iter: 1245 loss: 5.71651697e-07
Iter: 1246 loss: 5.7158843e-07
Iter: 1247 loss: 5.7197559e-07
Iter: 1248 loss: 5.71577971e-07
Iter: 1249 loss: 5.71521298e-07
Iter: 1250 loss: 5.71567512e-07
Iter: 1251 loss: 5.71545627e-07
Iter: 1252 loss: 5.7146525e-07
Iter: 1253 loss: 5.71570524e-07
Iter: 1254 loss: 5.71433475e-07
Iter: 1255 loss: 5.71400449e-07
Iter: 1256 loss: 5.71260557e-07
Iter: 1257 loss: 5.73204716e-07
Iter: 1258 loss: 5.71247e-07
Iter: 1259 loss: 5.71172905e-07
Iter: 1260 loss: 5.72717454e-07
Iter: 1261 loss: 5.71171313e-07
Iter: 1262 loss: 5.71074395e-07
Iter: 1263 loss: 5.71263627e-07
Iter: 1264 loss: 5.71028863e-07
Iter: 1265 loss: 5.70882378e-07
Iter: 1266 loss: 5.7084992e-07
Iter: 1267 loss: 5.70789553e-07
Iter: 1268 loss: 5.70663701e-07
Iter: 1269 loss: 5.70713269e-07
Iter: 1270 loss: 5.70599184e-07
Iter: 1271 loss: 5.70489078e-07
Iter: 1272 loss: 5.70470661e-07
Iter: 1273 loss: 5.7036857e-07
Iter: 1274 loss: 5.70586508e-07
Iter: 1275 loss: 5.70320367e-07
Iter: 1276 loss: 5.70259203e-07
Iter: 1277 loss: 5.70236125e-07
Iter: 1278 loss: 5.70213842e-07
Iter: 1279 loss: 5.70105499e-07
Iter: 1280 loss: 5.70930411e-07
Iter: 1281 loss: 5.70100838e-07
Iter: 1282 loss: 5.70027623e-07
Iter: 1283 loss: 5.69911037e-07
Iter: 1284 loss: 5.69924964e-07
Iter: 1285 loss: 5.69782912e-07
Iter: 1286 loss: 5.69796669e-07
Iter: 1287 loss: 5.69724875e-07
Iter: 1288 loss: 5.69570545e-07
Iter: 1289 loss: 5.70479074e-07
Iter: 1290 loss: 5.69531949e-07
Iter: 1291 loss: 5.69308781e-07
Iter: 1292 loss: 5.70964289e-07
Iter: 1293 loss: 5.69303893e-07
Iter: 1294 loss: 5.69250574e-07
Iter: 1295 loss: 5.69222664e-07
Iter: 1296 loss: 5.69192252e-07
Iter: 1297 loss: 5.69042072e-07
Iter: 1298 loss: 5.71177679e-07
Iter: 1299 loss: 5.69031499e-07
Iter: 1300 loss: 5.68903431e-07
Iter: 1301 loss: 5.6890724e-07
Iter: 1302 loss: 5.68783207e-07
Iter: 1303 loss: 5.68684925e-07
Iter: 1304 loss: 5.68665826e-07
Iter: 1305 loss: 5.68591531e-07
Iter: 1306 loss: 5.69116878e-07
Iter: 1307 loss: 5.68579253e-07
Iter: 1308 loss: 5.68502173e-07
Iter: 1309 loss: 5.68337612e-07
Iter: 1310 loss: 5.71268458e-07
Iter: 1311 loss: 5.68330108e-07
Iter: 1312 loss: 5.68295263e-07
Iter: 1313 loss: 5.6829316e-07
Iter: 1314 loss: 5.68207895e-07
Iter: 1315 loss: 5.68150767e-07
Iter: 1316 loss: 5.68142809e-07
Iter: 1317 loss: 5.68054475e-07
Iter: 1318 loss: 5.69007966e-07
Iter: 1319 loss: 5.68055611e-07
Iter: 1320 loss: 5.67958125e-07
Iter: 1321 loss: 5.67864731e-07
Iter: 1322 loss: 5.67847337e-07
Iter: 1323 loss: 5.67752636e-07
Iter: 1324 loss: 5.67804e-07
Iter: 1325 loss: 5.6770358e-07
Iter: 1326 loss: 5.67609106e-07
Iter: 1327 loss: 5.67622067e-07
Iter: 1328 loss: 5.67512586e-07
Iter: 1329 loss: 5.67443635e-07
Iter: 1330 loss: 5.67425332e-07
Iter: 1331 loss: 5.67320399e-07
Iter: 1332 loss: 5.67398104e-07
Iter: 1333 loss: 5.67224106e-07
Iter: 1334 loss: 5.67064546e-07
Iter: 1335 loss: 5.67227346e-07
Iter: 1336 loss: 5.66978088e-07
Iter: 1337 loss: 5.66855874e-07
Iter: 1338 loss: 5.668727e-07
Iter: 1339 loss: 5.66787605e-07
Iter: 1340 loss: 5.6671638e-07
Iter: 1341 loss: 5.6670541e-07
Iter: 1342 loss: 5.66596839e-07
Iter: 1343 loss: 5.67087397e-07
Iter: 1344 loss: 5.66573192e-07
Iter: 1345 loss: 5.66448307e-07
Iter: 1346 loss: 5.66776691e-07
Iter: 1347 loss: 5.66429e-07
Iter: 1348 loss: 5.66366339e-07
Iter: 1349 loss: 5.66532776e-07
Iter: 1350 loss: 5.6633229e-07
Iter: 1351 loss: 5.66260553e-07
Iter: 1352 loss: 5.66346785e-07
Iter: 1353 loss: 5.66212179e-07
Iter: 1354 loss: 5.66144422e-07
Iter: 1355 loss: 5.6599481e-07
Iter: 1356 loss: 5.65993957e-07
Iter: 1357 loss: 5.65919947e-07
Iter: 1358 loss: 5.658855e-07
Iter: 1359 loss: 5.65805408e-07
Iter: 1360 loss: 5.65948937e-07
Iter: 1361 loss: 5.65761752e-07
Iter: 1362 loss: 5.65666539e-07
Iter: 1363 loss: 5.65619416e-07
Iter: 1364 loss: 5.65550863e-07
Iter: 1365 loss: 5.65469463e-07
Iter: 1366 loss: 5.66175061e-07
Iter: 1367 loss: 5.65456332e-07
Iter: 1368 loss: 5.6537624e-07
Iter: 1369 loss: 5.66244694e-07
Iter: 1370 loss: 5.65362143e-07
Iter: 1371 loss: 5.65295124e-07
Iter: 1372 loss: 5.65219125e-07
Iter: 1373 loss: 5.65207927e-07
Iter: 1374 loss: 5.65105211e-07
Iter: 1375 loss: 5.65514256e-07
Iter: 1376 loss: 5.65079858e-07
Iter: 1377 loss: 5.65014659e-07
Iter: 1378 loss: 5.65874871e-07
Iter: 1379 loss: 5.65012e-07
Iter: 1380 loss: 5.64973334e-07
Iter: 1381 loss: 5.64871129e-07
Iter: 1382 loss: 5.66870881e-07
Iter: 1383 loss: 5.64880793e-07
Iter: 1384 loss: 5.64774041e-07
Iter: 1385 loss: 5.64787172e-07
Iter: 1386 loss: 5.64727145e-07
Iter: 1387 loss: 5.64611582e-07
Iter: 1388 loss: 5.66617473e-07
Iter: 1389 loss: 5.64629147e-07
Iter: 1390 loss: 5.64507673e-07
Iter: 1391 loss: 5.64472e-07
Iter: 1392 loss: 5.64401205e-07
Iter: 1393 loss: 5.64486e-07
Iter: 1394 loss: 5.64356071e-07
Iter: 1395 loss: 5.64334925e-07
Iter: 1396 loss: 5.64272455e-07
Iter: 1397 loss: 5.65028e-07
Iter: 1398 loss: 5.64261882e-07
Iter: 1399 loss: 5.64129209e-07
Iter: 1400 loss: 5.64383413e-07
Iter: 1401 loss: 5.64076686e-07
Iter: 1402 loss: 5.64012055e-07
Iter: 1403 loss: 5.64102834e-07
Iter: 1404 loss: 5.6398676e-07
Iter: 1405 loss: 5.63901494e-07
Iter: 1406 loss: 5.64722825e-07
Iter: 1407 loss: 5.63907292e-07
Iter: 1408 loss: 5.63841922e-07
Iter: 1409 loss: 5.63706294e-07
Iter: 1410 loss: 5.66407664e-07
Iter: 1411 loss: 5.63680942e-07
Iter: 1412 loss: 5.63630351e-07
Iter: 1413 loss: 5.64736069e-07
Iter: 1414 loss: 5.63630465e-07
Iter: 1415 loss: 5.6353241e-07
Iter: 1416 loss: 5.63687706e-07
Iter: 1417 loss: 5.63483184e-07
Iter: 1418 loss: 5.634285e-07
Iter: 1419 loss: 5.63380524e-07
Iter: 1420 loss: 5.63346248e-07
Iter: 1421 loss: 5.63282526e-07
Iter: 1422 loss: 5.63252343e-07
Iter: 1423 loss: 5.6322267e-07
Iter: 1424 loss: 5.63136268e-07
Iter: 1425 loss: 5.63673098e-07
Iter: 1426 loss: 5.63134336e-07
Iter: 1427 loss: 5.6303503e-07
Iter: 1428 loss: 5.64229538e-07
Iter: 1429 loss: 5.63053447e-07
Iter: 1430 loss: 5.62928449e-07
Iter: 1431 loss: 5.63114099e-07
Iter: 1432 loss: 5.62922253e-07
Iter: 1433 loss: 5.62860123e-07
Iter: 1434 loss: 5.62742059e-07
Iter: 1435 loss: 5.65160576e-07
Iter: 1436 loss: 5.62777416e-07
Iter: 1437 loss: 5.62651508e-07
Iter: 1438 loss: 5.63449817e-07
Iter: 1439 loss: 5.62647699e-07
Iter: 1440 loss: 5.62590174e-07
Iter: 1441 loss: 5.62676746e-07
Iter: 1442 loss: 5.62555954e-07
Iter: 1443 loss: 5.62456876e-07
Iter: 1444 loss: 5.62616947e-07
Iter: 1445 loss: 5.62433684e-07
Iter: 1446 loss: 5.62368314e-07
Iter: 1447 loss: 5.62494051e-07
Iter: 1448 loss: 5.62311811e-07
Iter: 1449 loss: 5.62280093e-07
Iter: 1450 loss: 5.6282704e-07
Iter: 1451 loss: 5.62268553e-07
Iter: 1452 loss: 5.62195794e-07
Iter: 1453 loss: 5.62174876e-07
Iter: 1454 loss: 5.62141281e-07
Iter: 1455 loss: 5.6206693e-07
Iter: 1456 loss: 5.62233822e-07
Iter: 1457 loss: 5.6203919e-07
Iter: 1458 loss: 5.61980244e-07
Iter: 1459 loss: 5.62738819e-07
Iter: 1460 loss: 5.61958188e-07
Iter: 1461 loss: 5.61935849e-07
Iter: 1462 loss: 5.61815341e-07
Iter: 1463 loss: 5.62870355e-07
Iter: 1464 loss: 5.61808406e-07
Iter: 1465 loss: 5.61773049e-07
Iter: 1466 loss: 5.61771117e-07
Iter: 1467 loss: 5.6171e-07
Iter: 1468 loss: 5.6163168e-07
Iter: 1469 loss: 5.61638274e-07
Iter: 1470 loss: 5.61548518e-07
Iter: 1471 loss: 5.61457796e-07
Iter: 1472 loss: 5.61447337e-07
Iter: 1473 loss: 5.61378215e-07
Iter: 1474 loss: 5.61362185e-07
Iter: 1475 loss: 5.61309434e-07
Iter: 1476 loss: 5.61425054e-07
Iter: 1477 loss: 5.61285e-07
Iter: 1478 loss: 5.61219679e-07
Iter: 1479 loss: 5.61163461e-07
Iter: 1480 loss: 5.61159482e-07
Iter: 1481 loss: 5.61041134e-07
Iter: 1482 loss: 5.61008676e-07
Iter: 1483 loss: 5.60929607e-07
Iter: 1484 loss: 5.60873275e-07
Iter: 1485 loss: 5.60855085e-07
Iter: 1486 loss: 5.60768399e-07
Iter: 1487 loss: 5.60633339e-07
Iter: 1488 loss: 5.63663775e-07
Iter: 1489 loss: 5.60619e-07
Iter: 1490 loss: 5.60489184e-07
Iter: 1491 loss: 5.60733497e-07
Iter: 1492 loss: 5.60418584e-07
Iter: 1493 loss: 5.60291426e-07
Iter: 1494 loss: 5.60464287e-07
Iter: 1495 loss: 5.60259537e-07
Iter: 1496 loss: 5.60286765e-07
Iter: 1497 loss: 5.60187573e-07
Iter: 1498 loss: 5.6016728e-07
Iter: 1499 loss: 5.60126296e-07
Iter: 1500 loss: 5.6011811e-07
Iter: 1501 loss: 5.6008588e-07
Iter: 1502 loss: 5.60339458e-07
Iter: 1503 loss: 5.60080196e-07
Iter: 1504 loss: 5.60015337e-07
Iter: 1505 loss: 5.60070589e-07
Iter: 1506 loss: 5.59970545e-07
Iter: 1507 loss: 5.59925752e-07
Iter: 1508 loss: 5.60046033e-07
Iter: 1509 loss: 5.5988545e-07
Iter: 1510 loss: 5.59841055e-07
Iter: 1511 loss: 5.60092076e-07
Iter: 1512 loss: 5.59830539e-07
Iter: 1513 loss: 5.59734474e-07
Iter: 1514 loss: 5.59969237e-07
Iter: 1515 loss: 5.59714636e-07
Iter: 1516 loss: 5.59669161e-07
Iter: 1517 loss: 5.59658815e-07
Iter: 1518 loss: 5.59591513e-07
Iter: 1519 loss: 5.5951125e-07
Iter: 1520 loss: 5.60174726e-07
Iter: 1521 loss: 5.59534215e-07
Iter: 1522 loss: 5.59446619e-07
Iter: 1523 loss: 5.59337536e-07
Iter: 1524 loss: 5.5934413e-07
Iter: 1525 loss: 5.59306955e-07
Iter: 1526 loss: 5.59373746e-07
Iter: 1527 loss: 5.5925517e-07
Iter: 1528 loss: 5.59201339e-07
Iter: 1529 loss: 5.59774662e-07
Iter: 1530 loss: 5.59205e-07
Iter: 1531 loss: 5.59152738e-07
Iter: 1532 loss: 5.59408875e-07
Iter: 1533 loss: 5.59140233e-07
Iter: 1534 loss: 5.59074e-07
Iter: 1535 loss: 5.58961574e-07
Iter: 1536 loss: 5.60541594e-07
Iter: 1537 loss: 5.58958163e-07
Iter: 1538 loss: 5.58906e-07
Iter: 1539 loss: 5.58926274e-07
Iter: 1540 loss: 5.58830607e-07
Iter: 1541 loss: 5.58756483e-07
Iter: 1542 loss: 5.58734428e-07
Iter: 1543 loss: 5.58658826e-07
Iter: 1544 loss: 5.59612658e-07
Iter: 1545 loss: 5.58656893e-07
Iter: 1546 loss: 5.58551278e-07
Iter: 1547 loss: 5.58633928e-07
Iter: 1548 loss: 5.58489319e-07
Iter: 1549 loss: 5.58396323e-07
Iter: 1550 loss: 5.58820716e-07
Iter: 1551 loss: 5.58406271e-07
Iter: 1552 loss: 5.58345278e-07
Iter: 1553 loss: 5.58583679e-07
Iter: 1554 loss: 5.5832e-07
Iter: 1555 loss: 5.58253078e-07
Iter: 1556 loss: 5.58258137e-07
Iter: 1557 loss: 5.5823466e-07
Iter: 1558 loss: 5.58164402e-07
Iter: 1559 loss: 5.5815832e-07
Iter: 1560 loss: 5.58110969e-07
Iter: 1561 loss: 5.58046224e-07
Iter: 1562 loss: 5.58254328e-07
Iter: 1563 loss: 5.5801155e-07
Iter: 1564 loss: 5.57969e-07
Iter: 1565 loss: 5.57964313e-07
Iter: 1566 loss: 5.57957435e-07
Iter: 1567 loss: 5.57909573e-07
Iter: 1568 loss: 5.59418709e-07
Iter: 1569 loss: 5.5790656e-07
Iter: 1570 loss: 5.57839087e-07
Iter: 1571 loss: 5.58617785e-07
Iter: 1572 loss: 5.57852161e-07
Iter: 1573 loss: 5.5779168e-07
Iter: 1574 loss: 5.57678e-07
Iter: 1575 loss: 5.59991463e-07
Iter: 1576 loss: 5.5765878e-07
Iter: 1577 loss: 5.57640476e-07
Iter: 1578 loss: 5.57644626e-07
Iter: 1579 loss: 5.57571639e-07
Iter: 1580 loss: 5.57575163e-07
Iter: 1581 loss: 5.57540147e-07
Iter: 1582 loss: 5.57461249e-07
Iter: 1583 loss: 5.57500357e-07
Iter: 1584 loss: 5.57407361e-07
Iter: 1585 loss: 5.57300382e-07
Iter: 1586 loss: 5.57849717e-07
Iter: 1587 loss: 5.57329486e-07
Iter: 1588 loss: 5.57254793e-07
Iter: 1589 loss: 5.57478074e-07
Iter: 1590 loss: 5.5722893e-07
Iter: 1591 loss: 5.57170665e-07
Iter: 1592 loss: 5.57124451e-07
Iter: 1593 loss: 5.57096484e-07
Iter: 1594 loss: 5.57055841e-07
Iter: 1595 loss: 5.57308908e-07
Iter: 1596 loss: 5.57042313e-07
Iter: 1597 loss: 5.56989505e-07
Iter: 1598 loss: 5.57091766e-07
Iter: 1599 loss: 5.5694494e-07
Iter: 1600 loss: 5.5682176e-07
Iter: 1601 loss: 5.57240469e-07
Iter: 1602 loss: 5.56787654e-07
Iter: 1603 loss: 5.56731379e-07
Iter: 1604 loss: 5.56667715e-07
Iter: 1605 loss: 5.56643158e-07
Iter: 1606 loss: 5.56494342e-07
Iter: 1607 loss: 5.57678788e-07
Iter: 1608 loss: 5.56520774e-07
Iter: 1609 loss: 5.56439602e-07
Iter: 1610 loss: 5.56226041e-07
Iter: 1611 loss: 5.60167848e-07
Iter: 1612 loss: 5.56218765e-07
Iter: 1613 loss: 5.56180225e-07
Iter: 1614 loss: 5.56194323e-07
Iter: 1615 loss: 5.5611406e-07
Iter: 1616 loss: 5.5613458e-07
Iter: 1617 loss: 5.56071427e-07
Iter: 1618 loss: 5.55994632e-07
Iter: 1619 loss: 5.56473481e-07
Iter: 1620 loss: 5.56003783e-07
Iter: 1621 loss: 5.55975419e-07
Iter: 1622 loss: 5.56017596e-07
Iter: 1623 loss: 5.55945121e-07
Iter: 1624 loss: 5.55908116e-07
Iter: 1625 loss: 5.55963879e-07
Iter: 1626 loss: 5.55912152e-07
Iter: 1627 loss: 5.5586986e-07
Iter: 1628 loss: 5.55797158e-07
Iter: 1629 loss: 5.55791132e-07
Iter: 1630 loss: 5.55711722e-07
Iter: 1631 loss: 5.55984968e-07
Iter: 1632 loss: 5.55708766e-07
Iter: 1633 loss: 5.55628958e-07
Iter: 1634 loss: 5.55642885e-07
Iter: 1635 loss: 5.55582233e-07
Iter: 1636 loss: 5.55470081e-07
Iter: 1637 loss: 5.57889848e-07
Iter: 1638 loss: 5.55458769e-07
Iter: 1639 loss: 5.55365773e-07
Iter: 1640 loss: 5.56313694e-07
Iter: 1641 loss: 5.55357e-07
Iter: 1642 loss: 5.5531018e-07
Iter: 1643 loss: 5.55369127e-07
Iter: 1644 loss: 5.55262261e-07
Iter: 1645 loss: 5.55210249e-07
Iter: 1646 loss: 5.55167617e-07
Iter: 1647 loss: 5.5514397e-07
Iter: 1648 loss: 5.55070756e-07
Iter: 1649 loss: 5.55085251e-07
Iter: 1650 loss: 5.55008228e-07
Iter: 1651 loss: 5.54870496e-07
Iter: 1652 loss: 5.57083581e-07
Iter: 1653 loss: 5.5487e-07
Iter: 1654 loss: 5.54805865e-07
Iter: 1655 loss: 5.54795861e-07
Iter: 1656 loss: 5.54742314e-07
Iter: 1657 loss: 5.55274823e-07
Iter: 1658 loss: 5.54744361e-07
Iter: 1659 loss: 5.54709743e-07
Iter: 1660 loss: 5.54612598e-07
Iter: 1661 loss: 5.55430915e-07
Iter: 1662 loss: 5.54617259e-07
Iter: 1663 loss: 5.54531368e-07
Iter: 1664 loss: 5.55460247e-07
Iter: 1665 loss: 5.54515395e-07
Iter: 1666 loss: 5.54509256e-07
Iter: 1667 loss: 5.54439566e-07
Iter: 1668 loss: 5.54436212e-07
Iter: 1669 loss: 5.54331621e-07
Iter: 1670 loss: 5.54337532e-07
Iter: 1671 loss: 5.54293365e-07
Iter: 1672 loss: 5.54213898e-07
Iter: 1673 loss: 5.55942279e-07
Iter: 1674 loss: 5.54221401e-07
Iter: 1675 loss: 5.54117264e-07
Iter: 1676 loss: 5.54018698e-07
Iter: 1677 loss: 5.5397993e-07
Iter: 1678 loss: 5.53900122e-07
Iter: 1679 loss: 5.54750613e-07
Iter: 1680 loss: 5.53905807e-07
Iter: 1681 loss: 5.53855216e-07
Iter: 1682 loss: 5.54325879e-07
Iter: 1683 loss: 5.53834411e-07
Iter: 1684 loss: 5.53801e-07
Iter: 1685 loss: 5.53733912e-07
Iter: 1686 loss: 5.53735617e-07
Iter: 1687 loss: 5.5371487e-07
Iter: 1688 loss: 5.53680763e-07
Iter: 1689 loss: 5.53663654e-07
Iter: 1690 loss: 5.53632844e-07
Iter: 1691 loss: 5.54121868e-07
Iter: 1692 loss: 5.53610619e-07
Iter: 1693 loss: 5.53570089e-07
Iter: 1694 loss: 5.54391818e-07
Iter: 1695 loss: 5.53572931e-07
Iter: 1696 loss: 5.53514326e-07
Iter: 1697 loss: 5.53528309e-07
Iter: 1698 loss: 5.53472319e-07
Iter: 1699 loss: 5.53439463e-07
Iter: 1700 loss: 5.53422296e-07
Iter: 1701 loss: 5.53406267e-07
Iter: 1702 loss: 5.5336e-07
Iter: 1703 loss: 5.533592e-07
Iter: 1704 loss: 5.53283371e-07
Iter: 1705 loss: 5.53204359e-07
Iter: 1706 loss: 5.54064854e-07
Iter: 1707 loss: 5.53215273e-07
Iter: 1708 loss: 5.53208281e-07
Iter: 1709 loss: 5.53155473e-07
Iter: 1710 loss: 5.53146378e-07
Iter: 1711 loss: 5.53113637e-07
Iter: 1712 loss: 5.53132054e-07
Iter: 1713 loss: 5.53077939e-07
Iter: 1714 loss: 5.53018879e-07
Iter: 1715 loss: 5.53023483e-07
Iter: 1716 loss: 5.52983579e-07
Iter: 1717 loss: 5.52936456e-07
Iter: 1718 loss: 5.52909114e-07
Iter: 1719 loss: 5.52875292e-07
Iter: 1720 loss: 5.52797417e-07
Iter: 1721 loss: 5.5281032e-07
Iter: 1722 loss: 5.52749611e-07
Iter: 1723 loss: 5.5269345e-07
Iter: 1724 loss: 5.52660765e-07
Iter: 1725 loss: 5.52536846e-07
Iter: 1726 loss: 5.52656275e-07
Iter: 1727 loss: 5.52528661e-07
Iter: 1728 loss: 5.52491883e-07
Iter: 1729 loss: 5.52483471e-07
Iter: 1730 loss: 5.52419351e-07
Iter: 1731 loss: 5.52391441e-07
Iter: 1732 loss: 5.52381437e-07
Iter: 1733 loss: 5.52285087e-07
Iter: 1734 loss: 5.52435154e-07
Iter: 1735 loss: 5.52254335e-07
Iter: 1736 loss: 5.52157758e-07
Iter: 1737 loss: 5.52172082e-07
Iter: 1738 loss: 5.52050381e-07
Iter: 1739 loss: 5.51928679e-07
Iter: 1740 loss: 5.53221525e-07
Iter: 1741 loss: 5.51921403e-07
Iter: 1742 loss: 5.51822893e-07
Iter: 1743 loss: 5.5193982e-07
Iter: 1744 loss: 5.51826e-07
Iter: 1745 loss: 5.51687776e-07
Iter: 1746 loss: 5.51631274e-07
Iter: 1747 loss: 5.51594894e-07
Iter: 1748 loss: 5.51455798e-07
Iter: 1749 loss: 5.51913331e-07
Iter: 1750 loss: 5.51434653e-07
Iter: 1751 loss: 5.51388666e-07
Iter: 1752 loss: 5.51675157e-07
Iter: 1753 loss: 5.51361211e-07
Iter: 1754 loss: 5.51280607e-07
Iter: 1755 loss: 5.51672429e-07
Iter: 1756 loss: 5.51270603e-07
Iter: 1757 loss: 5.51235416e-07
Iter: 1758 loss: 5.51202106e-07
Iter: 1759 loss: 5.51217795e-07
Iter: 1760 loss: 5.51146456e-07
Iter: 1761 loss: 5.51486437e-07
Iter: 1762 loss: 5.51126391e-07
Iter: 1763 loss: 5.51066762e-07
Iter: 1764 loss: 5.5106932e-07
Iter: 1765 loss: 5.50991103e-07
Iter: 1766 loss: 5.50932327e-07
Iter: 1767 loss: 5.51172548e-07
Iter: 1768 loss: 5.50892878e-07
Iter: 1769 loss: 5.50824097e-07
Iter: 1770 loss: 5.51169251e-07
Iter: 1771 loss: 5.50799029e-07
Iter: 1772 loss: 5.50736218e-07
Iter: 1773 loss: 5.50725474e-07
Iter: 1774 loss: 5.50664822e-07
Iter: 1775 loss: 5.50571031e-07
Iter: 1776 loss: 5.51347739e-07
Iter: 1777 loss: 5.50559491e-07
Iter: 1778 loss: 5.50477296e-07
Iter: 1779 loss: 5.50834102e-07
Iter: 1780 loss: 5.50449158e-07
Iter: 1781 loss: 5.5044228e-07
Iter: 1782 loss: 5.50324501e-07
Iter: 1783 loss: 5.52019685e-07
Iter: 1784 loss: 5.50352411e-07
Iter: 1785 loss: 5.50223717e-07
Iter: 1786 loss: 5.50664424e-07
Iter: 1787 loss: 5.50193477e-07
Iter: 1788 loss: 5.50116965e-07
Iter: 1789 loss: 5.50113157e-07
Iter: 1790 loss: 5.50037726e-07
Iter: 1791 loss: 5.49925403e-07
Iter: 1792 loss: 5.49936885e-07
Iter: 1793 loss: 5.49818253e-07
Iter: 1794 loss: 5.50345646e-07
Iter: 1795 loss: 5.49792617e-07
Iter: 1796 loss: 5.49787444e-07
Iter: 1797 loss: 5.49765332e-07
Iter: 1798 loss: 5.49729123e-07
Iter: 1799 loss: 5.49640788e-07
Iter: 1800 loss: 5.50446202e-07
Iter: 1801 loss: 5.49652384e-07
Iter: 1802 loss: 5.49612935e-07
Iter: 1803 loss: 5.49593494e-07
Iter: 1804 loss: 5.49551942e-07
Iter: 1805 loss: 5.49572462e-07
Iter: 1806 loss: 5.49547622e-07
Iter: 1807 loss: 5.49517949e-07
Iter: 1808 loss: 5.49666879e-07
Iter: 1809 loss: 5.49526249e-07
Iter: 1810 loss: 5.49454512e-07
Iter: 1811 loss: 5.49496576e-07
Iter: 1812 loss: 5.49433935e-07
Iter: 1813 loss: 5.49362539e-07
Iter: 1814 loss: 5.4955342e-07
Iter: 1815 loss: 5.49329457e-07
Iter: 1816 loss: 5.49314791e-07
Iter: 1817 loss: 5.49223785e-07
Iter: 1818 loss: 5.49220772e-07
Iter: 1819 loss: 5.49123229e-07
Iter: 1820 loss: 5.49624758e-07
Iter: 1821 loss: 5.49114361e-07
Iter: 1822 loss: 5.49125161e-07
Iter: 1823 loss: 5.4908088e-07
Iter: 1824 loss: 5.49047343e-07
Iter: 1825 loss: 5.49009314e-07
Iter: 1826 loss: 5.49215542e-07
Iter: 1827 loss: 5.49006245e-07
Iter: 1828 loss: 5.4891774e-07
Iter: 1829 loss: 5.48921832e-07
Iter: 1830 loss: 5.48863341e-07
Iter: 1831 loss: 5.48907963e-07
Iter: 1832 loss: 5.48829121e-07
Iter: 1833 loss: 5.4874954e-07
Iter: 1834 loss: 5.48707249e-07
Iter: 1835 loss: 5.48665753e-07
Iter: 1836 loss: 5.48518301e-07
Iter: 1837 loss: 5.49784204e-07
Iter: 1838 loss: 5.48528533e-07
Iter: 1839 loss: 5.48458559e-07
Iter: 1840 loss: 5.48447247e-07
Iter: 1841 loss: 5.48428261e-07
Iter: 1842 loss: 5.48303206e-07
Iter: 1843 loss: 5.49112599e-07
Iter: 1844 loss: 5.4829718e-07
Iter: 1845 loss: 5.48253638e-07
Iter: 1846 loss: 5.4835283e-07
Iter: 1847 loss: 5.48228854e-07
Iter: 1848 loss: 5.48172579e-07
Iter: 1849 loss: 5.48236699e-07
Iter: 1850 loss: 5.4816303e-07
Iter: 1851 loss: 5.48076e-07
Iter: 1852 loss: 5.48187757e-07
Iter: 1853 loss: 5.48071512e-07
Iter: 1854 loss: 5.48008188e-07
Iter: 1855 loss: 5.48093226e-07
Iter: 1856 loss: 5.47963793e-07
Iter: 1857 loss: 5.47917068e-07
Iter: 1858 loss: 5.47909849e-07
Iter: 1859 loss: 5.4786409e-07
Iter: 1860 loss: 5.47786215e-07
Iter: 1861 loss: 5.49719289e-07
Iter: 1862 loss: 5.47783486e-07
Iter: 1863 loss: 5.47716866e-07
Iter: 1864 loss: 5.48887385e-07
Iter: 1865 loss: 5.47688728e-07
Iter: 1866 loss: 5.4760585e-07
Iter: 1867 loss: 5.47630862e-07
Iter: 1868 loss: 5.47563218e-07
Iter: 1869 loss: 5.47504669e-07
Iter: 1870 loss: 5.4764763e-07
Iter: 1871 loss: 5.47450099e-07
Iter: 1872 loss: 5.47372e-07
Iter: 1873 loss: 5.47716752e-07
Iter: 1874 loss: 5.47358923e-07
Iter: 1875 loss: 5.47297532e-07
Iter: 1876 loss: 5.47474087e-07
Iter: 1877 loss: 5.47301852e-07
Iter: 1878 loss: 5.47256832e-07
Iter: 1879 loss: 5.47484149e-07
Iter: 1880 loss: 5.47228751e-07
Iter: 1881 loss: 5.4721329e-07
Iter: 1882 loss: 5.4715531e-07
Iter: 1883 loss: 5.48335606e-07
Iter: 1884 loss: 5.47152865e-07
Iter: 1885 loss: 5.47051059e-07
Iter: 1886 loss: 5.4805696e-07
Iter: 1887 loss: 5.47043783e-07
Iter: 1888 loss: 5.46961928e-07
Iter: 1889 loss: 5.4695937e-07
Iter: 1890 loss: 5.46926117e-07
Iter: 1891 loss: 5.46854494e-07
Iter: 1892 loss: 5.47669515e-07
Iter: 1893 loss: 5.46871e-07
Iter: 1894 loss: 5.46776164e-07
Iter: 1895 loss: 5.47024342e-07
Iter: 1896 loss: 5.46795036e-07
Iter: 1897 loss: 5.46754279e-07
Iter: 1898 loss: 5.46785088e-07
Iter: 1899 loss: 5.46753085e-07
Iter: 1900 loss: 5.46700392e-07
Iter: 1901 loss: 5.47029742e-07
Iter: 1902 loss: 5.46685214e-07
Iter: 1903 loss: 5.46650881e-07
Iter: 1904 loss: 5.46622118e-07
Iter: 1905 loss: 5.46595686e-07
Iter: 1906 loss: 5.46580736e-07
Iter: 1907 loss: 5.46575393e-07
Iter: 1908 loss: 5.46527247e-07
Iter: 1909 loss: 5.46490696e-07
Iter: 1910 loss: 5.46506612e-07
Iter: 1911 loss: 5.46445904e-07
Iter: 1912 loss: 5.46833576e-07
Iter: 1913 loss: 5.46441242e-07
Iter: 1914 loss: 5.46419585e-07
Iter: 1915 loss: 5.46380818e-07
Iter: 1916 loss: 5.46367119e-07
Iter: 1917 loss: 5.46318e-07
Iter: 1918 loss: 5.46389e-07
Iter: 1919 loss: 5.46275942e-07
Iter: 1920 loss: 5.46220065e-07
Iter: 1921 loss: 5.46832894e-07
Iter: 1922 loss: 5.46240585e-07
Iter: 1923 loss: 5.4620574e-07
Iter: 1924 loss: 5.46250362e-07
Iter: 1925 loss: 5.46164642e-07
Iter: 1926 loss: 5.46144634e-07
Iter: 1927 loss: 5.46219098e-07
Iter: 1928 loss: 5.46127353e-07
Iter: 1929 loss: 5.46085971e-07
Iter: 1930 loss: 5.46025944e-07
Iter: 1931 loss: 5.46022363e-07
Iter: 1932 loss: 5.45979901e-07
Iter: 1933 loss: 5.45966373e-07
Iter: 1934 loss: 5.45959438e-07
Iter: 1935 loss: 5.45874286e-07
Iter: 1936 loss: 5.47077093e-07
Iter: 1937 loss: 5.45883836e-07
Iter: 1938 loss: 5.45821422e-07
Iter: 1939 loss: 5.46172032e-07
Iter: 1940 loss: 5.45813577e-07
Iter: 1941 loss: 5.45767648e-07
Iter: 1942 loss: 5.45695e-07
Iter: 1943 loss: 5.45688295e-07
Iter: 1944 loss: 5.45611726e-07
Iter: 1945 loss: 5.45608657e-07
Iter: 1946 loss: 5.45593139e-07
Iter: 1947 loss: 5.45554599e-07
Iter: 1948 loss: 5.4555403e-07
Iter: 1949 loss: 5.4544e-07
Iter: 1950 loss: 5.45505145e-07
Iter: 1951 loss: 5.45434091e-07
Iter: 1952 loss: 5.4535252e-07
Iter: 1953 loss: 5.45333933e-07
Iter: 1954 loss: 5.45265266e-07
Iter: 1955 loss: 5.45175283e-07
Iter: 1956 loss: 5.46626552e-07
Iter: 1957 loss: 5.45196599e-07
Iter: 1958 loss: 5.45076148e-07
Iter: 1959 loss: 5.45592513e-07
Iter: 1960 loss: 5.45062449e-07
Iter: 1961 loss: 5.45004582e-07
Iter: 1962 loss: 5.45021749e-07
Iter: 1963 loss: 5.44977809e-07
Iter: 1964 loss: 5.44919317e-07
Iter: 1965 loss: 5.44999807e-07
Iter: 1966 loss: 5.4484542e-07
Iter: 1967 loss: 5.44741113e-07
Iter: 1968 loss: 5.45542434e-07
Iter: 1969 loss: 5.44718773e-07
Iter: 1970 loss: 5.4469109e-07
Iter: 1971 loss: 5.44883e-07
Iter: 1972 loss: 5.44661418e-07
Iter: 1973 loss: 5.4463726e-07
Iter: 1974 loss: 5.44657837e-07
Iter: 1975 loss: 5.4458809e-07
Iter: 1976 loss: 5.44526699e-07
Iter: 1977 loss: 5.44510158e-07
Iter: 1978 loss: 5.44482646e-07
Iter: 1979 loss: 5.44426427e-07
Iter: 1980 loss: 5.44434783e-07
Iter: 1981 loss: 5.44410909e-07
Iter: 1982 loss: 5.4432e-07
Iter: 1983 loss: 5.45038915e-07
Iter: 1984 loss: 5.44338491e-07
Iter: 1985 loss: 5.44253226e-07
Iter: 1986 loss: 5.44638567e-07
Iter: 1987 loss: 5.44224179e-07
Iter: 1988 loss: 5.44181944e-07
Iter: 1989 loss: 5.44129534e-07
Iter: 1990 loss: 5.44139198e-07
Iter: 1991 loss: 5.44071554e-07
Iter: 1992 loss: 5.44058935e-07
Iter: 1993 loss: 5.44004138e-07
Iter: 1994 loss: 5.44427166e-07
Iter: 1995 loss: 5.44004e-07
Iter: 1996 loss: 5.43951728e-07
Iter: 1997 loss: 5.4388056e-07
Iter: 1998 loss: 5.44888508e-07
Iter: 1999 loss: 5.43865667e-07
Iter: 2000 loss: 5.43796432e-07
Iter: 2001 loss: 5.45018736e-07
Iter: 2002 loss: 5.43783926e-07
Iter: 2003 loss: 5.4372515e-07
Iter: 2004 loss: 5.43743454e-07
Iter: 2005 loss: 5.43656711e-07
Iter: 2006 loss: 5.43582132e-07
Iter: 2007 loss: 5.44032e-07
Iter: 2008 loss: 5.43583269e-07
Iter: 2009 loss: 5.43481747e-07
Iter: 2010 loss: 5.43392957e-07
Iter: 2011 loss: 5.43420128e-07
Iter: 2012 loss: 5.43362717e-07
Iter: 2013 loss: 5.43353565e-07
Iter: 2014 loss: 5.43310762e-07
Iter: 2015 loss: 5.43293822e-07
Iter: 2016 loss: 5.43227e-07
Iter: 2017 loss: 5.43158706e-07
Iter: 2018 loss: 5.43068495e-07
Iter: 2019 loss: 5.43083274e-07
Iter: 2020 loss: 5.42984935e-07
Iter: 2021 loss: 5.43890053e-07
Iter: 2022 loss: 5.43008582e-07
Iter: 2023 loss: 5.4295333e-07
Iter: 2024 loss: 5.42874432e-07
Iter: 2025 loss: 5.42844305e-07
Iter: 2026 loss: 5.42868065e-07
Iter: 2027 loss: 5.4282151e-07
Iter: 2028 loss: 5.42783141e-07
Iter: 2029 loss: 5.42786609e-07
Iter: 2030 loss: 5.42745227e-07
Iter: 2031 loss: 5.4268105e-07
Iter: 2032 loss: 5.42851581e-07
Iter: 2033 loss: 5.42666669e-07
Iter: 2034 loss: 5.42597661e-07
Iter: 2035 loss: 5.42766259e-07
Iter: 2036 loss: 5.42572593e-07
Iter: 2037 loss: 5.42527289e-07
Iter: 2038 loss: 5.42964358e-07
Iter: 2039 loss: 5.42510634e-07
Iter: 2040 loss: 5.42452199e-07
Iter: 2041 loss: 5.42427756e-07
Iter: 2042 loss: 5.42402518e-07
Iter: 2043 loss: 5.42305884e-07
Iter: 2044 loss: 5.42348516e-07
Iter: 2045 loss: 5.4223915e-07
Iter: 2046 loss: 5.42197e-07
Iter: 2047 loss: 5.42186399e-07
Iter: 2048 loss: 5.42141095e-07
Iter: 2049 loss: 5.42113867e-07
Iter: 2050 loss: 5.43701447e-07
Iter: 2051 loss: 5.42082489e-07
Iter: 2052 loss: 5.41985514e-07
Iter: 2053 loss: 5.41900476e-07
Iter: 2054 loss: 5.41853694e-07
Iter: 2055 loss: 5.41774625e-07
Iter: 2056 loss: 5.43016768e-07
Iter: 2057 loss: 5.41760585e-07
Iter: 2058 loss: 5.41704537e-07
Iter: 2059 loss: 5.42300427e-07
Iter: 2060 loss: 5.4167549e-07
Iter: 2061 loss: 5.41596364e-07
Iter: 2062 loss: 5.41910254e-07
Iter: 2063 loss: 5.41567545e-07
Iter: 2064 loss: 5.4152548e-07
Iter: 2065 loss: 5.41601935e-07
Iter: 2066 loss: 5.41509905e-07
Iter: 2067 loss: 5.4146949e-07
Iter: 2068 loss: 5.4200018e-07
Iter: 2069 loss: 5.41461873e-07
Iter: 2070 loss: 5.41429245e-07
Iter: 2071 loss: 5.41402414e-07
Iter: 2072 loss: 5.41391671e-07
Iter: 2073 loss: 5.4132073e-07
Iter: 2074 loss: 5.42082489e-07
Iter: 2075 loss: 5.41330792e-07
Iter: 2076 loss: 5.4130885e-07
Iter: 2077 loss: 5.4124564e-07
Iter: 2078 loss: 5.41981e-07
Iter: 2079 loss: 5.41235408e-07
Iter: 2080 loss: 5.41130589e-07
Iter: 2081 loss: 5.41982274e-07
Iter: 2082 loss: 5.41130476e-07
Iter: 2083 loss: 5.4106e-07
Iter: 2084 loss: 5.41275654e-07
Iter: 2085 loss: 5.41013378e-07
Iter: 2086 loss: 5.40925271e-07
Iter: 2087 loss: 5.40888209e-07
Iter: 2088 loss: 5.40893723e-07
Iter: 2089 loss: 5.40757867e-07
Iter: 2090 loss: 5.40660835e-07
Iter: 2091 loss: 5.40632698e-07
Iter: 2092 loss: 5.4044358e-07
Iter: 2093 loss: 5.41217673e-07
Iter: 2094 loss: 5.40435053e-07
Iter: 2095 loss: 5.40313295e-07
Iter: 2096 loss: 5.40307155e-07
Iter: 2097 loss: 5.40202109e-07
Iter: 2098 loss: 5.40038911e-07
Iter: 2099 loss: 5.40065e-07
Iter: 2100 loss: 5.39932159e-07
Iter: 2101 loss: 5.40311589e-07
Iter: 2102 loss: 5.398864e-07
Iter: 2103 loss: 5.3973838e-07
Iter: 2104 loss: 5.41025e-07
Iter: 2105 loss: 5.39712062e-07
Iter: 2106 loss: 5.39640041e-07
Iter: 2107 loss: 5.3976953e-07
Iter: 2108 loss: 5.39594566e-07
Iter: 2109 loss: 5.39482187e-07
Iter: 2110 loss: 5.40150324e-07
Iter: 2111 loss: 5.39498e-07
Iter: 2112 loss: 5.39432222e-07
Iter: 2113 loss: 5.39373e-07
Iter: 2114 loss: 5.41112058e-07
Iter: 2115 loss: 5.39368784e-07
Iter: 2116 loss: 5.39254359e-07
Iter: 2117 loss: 5.39257769e-07
Iter: 2118 loss: 5.39191888e-07
Iter: 2119 loss: 5.39346161e-07
Iter: 2120 loss: 5.39157782e-07
Iter: 2121 loss: 5.39119e-07
Iter: 2122 loss: 5.39049267e-07
Iter: 2123 loss: 5.40846543e-07
Iter: 2124 loss: 5.39061318e-07
Iter: 2125 loss: 5.38976792e-07
Iter: 2126 loss: 5.3918393e-07
Iter: 2127 loss: 5.38952804e-07
Iter: 2128 loss: 5.3881331e-07
Iter: 2129 loss: 5.38710424e-07
Iter: 2130 loss: 5.38697805e-07
Iter: 2131 loss: 5.38760901e-07
Iter: 2132 loss: 5.38625329e-07
Iter: 2133 loss: 5.3857741e-07
Iter: 2134 loss: 5.38598954e-07
Iter: 2135 loss: 5.38541258e-07
Iter: 2136 loss: 5.38486916e-07
Iter: 2137 loss: 5.38722531e-07
Iter: 2138 loss: 5.38469919e-07
Iter: 2139 loss: 5.3840995e-07
Iter: 2140 loss: 5.38283757e-07
Iter: 2141 loss: 5.38293477e-07
Iter: 2142 loss: 5.38189624e-07
Iter: 2143 loss: 5.38208269e-07
Iter: 2144 loss: 5.38146651e-07
Iter: 2145 loss: 5.38613449e-07
Iter: 2146 loss: 5.38132781e-07
Iter: 2147 loss: 5.38124652e-07
Iter: 2148 loss: 5.38003405e-07
Iter: 2149 loss: 5.38580707e-07
Iter: 2150 loss: 5.37979815e-07
Iter: 2151 loss: 5.37966685e-07
Iter: 2152 loss: 5.37947926e-07
Iter: 2153 loss: 5.37920243e-07
Iter: 2154 loss: 5.37977598e-07
Iter: 2155 loss: 5.37860615e-07
Iter: 2156 loss: 5.3782162e-07
Iter: 2157 loss: 5.37748235e-07
Iter: 2158 loss: 5.392464e-07
Iter: 2159 loss: 5.37746e-07
Iter: 2160 loss: 5.37689857e-07
Iter: 2161 loss: 5.37896653e-07
Iter: 2162 loss: 5.37673145e-07
Iter: 2163 loss: 5.37579695e-07
Iter: 2164 loss: 5.38093e-07
Iter: 2165 loss: 5.37555934e-07
Iter: 2166 loss: 5.37496476e-07
Iter: 2167 loss: 5.38175811e-07
Iter: 2168 loss: 5.37494e-07
Iter: 2169 loss: 5.37482151e-07
Iter: 2170 loss: 5.37467372e-07
Iter: 2171 loss: 5.37446567e-07
Iter: 2172 loss: 5.37392566e-07
Iter: 2173 loss: 5.37529615e-07
Iter: 2174 loss: 5.37365963e-07
Iter: 2175 loss: 5.37334131e-07
Iter: 2176 loss: 5.37235337e-07
Iter: 2177 loss: 5.37240169e-07
Iter: 2178 loss: 5.37231358e-07
Iter: 2179 loss: 5.37200322e-07
Iter: 2180 loss: 5.37178835e-07
Iter: 2181 loss: 5.37139783e-07
Iter: 2182 loss: 5.37141545e-07
Iter: 2183 loss: 5.37074072e-07
Iter: 2184 loss: 5.37218966e-07
Iter: 2185 loss: 5.37051221e-07
Iter: 2186 loss: 5.370145e-07
Iter: 2187 loss: 5.36975563e-07
Iter: 2188 loss: 5.36952825e-07
Iter: 2189 loss: 5.36870857e-07
Iter: 2190 loss: 5.37042865e-07
Iter: 2191 loss: 5.3687711e-07
Iter: 2192 loss: 5.36771495e-07
Iter: 2193 loss: 5.3696624e-07
Iter: 2194 loss: 5.36755238e-07
Iter: 2195 loss: 5.36711809e-07
Iter: 2196 loss: 5.36859034e-07
Iter: 2197 loss: 5.36655421e-07
Iter: 2198 loss: 5.36613e-07
Iter: 2199 loss: 5.3732083e-07
Iter: 2200 loss: 5.36617506e-07
Iter: 2201 loss: 5.36537755e-07
Iter: 2202 loss: 5.36490859e-07
Iter: 2203 loss: 5.36495122e-07
Iter: 2204 loss: 5.36463062e-07
Iter: 2205 loss: 5.36446692e-07
Iter: 2206 loss: 5.36441917e-07
Iter: 2207 loss: 5.36412642e-07
Iter: 2208 loss: 5.36446748e-07
Iter: 2209 loss: 5.36380128e-07
Iter: 2210 loss: 5.36534628e-07
Iter: 2211 loss: 5.36374671e-07
Iter: 2212 loss: 5.36303219e-07
Iter: 2213 loss: 5.36854714e-07
Iter: 2214 loss: 5.3632084e-07
Iter: 2215 loss: 5.36314133e-07
Iter: 2216 loss: 5.36308164e-07
Iter: 2217 loss: 5.36304697e-07
Iter: 2218 loss: 5.36269e-07
Iter: 2219 loss: 5.36473408e-07
Iter: 2220 loss: 5.36251207e-07
Iter: 2221 loss: 5.36245352e-07
Iter: 2222 loss: 5.36208e-07
Iter: 2223 loss: 5.36193738e-07
Iter: 2224 loss: 5.36137691e-07
Iter: 2225 loss: 5.36169182e-07
Iter: 2226 loss: 5.3610529e-07
Iter: 2227 loss: 5.36013772e-07
Iter: 2228 loss: 5.36064647e-07
Iter: 2229 loss: 5.35961703e-07
Iter: 2230 loss: 5.35927597e-07
Iter: 2231 loss: 5.35908782e-07
Iter: 2232 loss: 5.35875e-07
Iter: 2233 loss: 5.3584597e-07
Iter: 2234 loss: 5.35826416e-07
Iter: 2235 loss: 5.35791855e-07
Iter: 2236 loss: 5.35789582e-07
Iter: 2237 loss: 5.35768834e-07
Iter: 2238 loss: 5.35696472e-07
Iter: 2239 loss: 5.35702668e-07
Iter: 2240 loss: 5.35715628e-07
Iter: 2241 loss: 5.35721256e-07
Iter: 2242 loss: 5.35721e-07
Iter: 2243 loss: 5.35718641e-07
Iter: 2244 loss: 5.35720574e-07
Iter: 2245 loss: 5.35701e-07
Iter: 2246 loss: 5.35702839e-07
Iter: 2247 loss: 5.35691697e-07
Iter: 2248 loss: 5.35711479e-07
Iter: 2249 loss: 5.35705112e-07
Iter: 2250 loss: 5.35702327e-07
Iter: 2251 loss: 5.35701702e-07
Iter: 2252 loss: 5.35700565e-07
Iter: 2253 loss: 5.35702952e-07
Iter: 2254 loss: 5.35701e-07
Iter: 2255 loss: 5.35700678e-07
Iter: 2256 loss: 5.35705453e-07
Iter: 2257 loss: 5.35702725e-07
Iter: 2258 loss: 5.35703521e-07
Iter: 2259 loss: 5.35703748e-07
Iter: 2260 loss: 5.35704544e-07
Iter: 2261 loss: 5.35702782e-07
Iter: 2262 loss: 5.35704089e-07
Iter: 2263 loss: 5.35702782e-07
Iter: 2264 loss: 5.35704089e-07
Iter: 2265 loss: 5.35703521e-07
Iter: 2266 loss: 5.35703521e-07
Iter: 2267 loss: 5.35703521e-07
Iter: 2268 loss: 5.35702782e-07
Iter: 2269 loss: 5.35703521e-07
Iter: 2270 loss: 5.35642528e-07
Iter: 2271 loss: 5.35625645e-07
Iter: 2272 loss: 5.35600861e-07
Iter: 2273 loss: 5.35759e-07
Iter: 2274 loss: 5.35544473e-07
Iter: 2275 loss: 5.35537e-07
Iter: 2276 loss: 5.35536515e-07
Iter: 2277 loss: 5.35493541e-07
Iter: 2278 loss: 5.35407821e-07
Iter: 2279 loss: 5.36473806e-07
Iter: 2280 loss: 5.35426921e-07
Iter: 2281 loss: 5.35346658e-07
Iter: 2282 loss: 5.35576874e-07
Iter: 2283 loss: 5.35330798e-07
Iter: 2284 loss: 5.35297715e-07
Iter: 2285 loss: 5.35261222e-07
Iter: 2286 loss: 5.35231038e-07
Iter: 2287 loss: 5.35181186e-07
Iter: 2288 loss: 5.35694198e-07
Iter: 2289 loss: 5.35181528e-07
Iter: 2290 loss: 5.35142931e-07
Iter: 2291 loss: 5.35128379e-07
Iter: 2292 loss: 5.35109507e-07
Iter: 2293 loss: 5.35059087e-07
Iter: 2294 loss: 5.36301741e-07
Iter: 2295 loss: 5.35047263e-07
Iter: 2296 loss: 5.35007246e-07
Iter: 2297 loss: 5.35521e-07
Iter: 2298 loss: 5.34972742e-07
Iter: 2299 loss: 5.34929313e-07
Iter: 2300 loss: 5.34911e-07
Iter: 2301 loss: 5.34877358e-07
Iter: 2302 loss: 5.34816877e-07
Iter: 2303 loss: 5.35266622e-07
Iter: 2304 loss: 5.3484888e-07
Iter: 2305 loss: 5.34800847e-07
Iter: 2306 loss: 5.34780895e-07
Iter: 2307 loss: 5.34738319e-07
Iter: 2308 loss: 5.34695801e-07
Iter: 2309 loss: 5.34811875e-07
Iter: 2310 loss: 5.34672836e-07
Iter: 2311 loss: 5.34646574e-07
Iter: 2312 loss: 5.34659591e-07
Iter: 2313 loss: 5.34633e-07
Iter: 2314 loss: 5.34605761e-07
Iter: 2315 loss: 5.35171637e-07
Iter: 2316 loss: 5.34598598e-07
Iter: 2317 loss: 5.34508786e-07
Iter: 2318 loss: 5.34627247e-07
Iter: 2319 loss: 5.344736e-07
Iter: 2320 loss: 5.34444325e-07
Iter: 2321 loss: 5.3454653e-07
Iter: 2322 loss: 5.34404421e-07
Iter: 2323 loss: 5.34329615e-07
Iter: 2324 loss: 5.34501169e-07
Iter: 2325 loss: 5.34297214e-07
Iter: 2326 loss: 5.34299943e-07
Iter: 2327 loss: 5.3425174e-07
Iter: 2328 loss: 5.34255037e-07
Iter: 2329 loss: 5.34255378e-07
Iter: 2330 loss: 5.34270498e-07
Iter: 2331 loss: 5.34262938e-07
Iter: 2332 loss: 5.34283743e-07
Iter: 2333 loss: 5.34262313e-07
Iter: 2334 loss: 5.34259925e-07
Iter: 2335 loss: 5.34273795e-07
Iter: 2336 loss: 5.34256628e-07
Iter: 2337 loss: 5.34254355e-07
Iter: 2338 loss: 5.34263847e-07
Iter: 2339 loss: 5.34256571e-07
Iter: 2340 loss: 5.34255378e-07
Iter: 2341 loss: 5.3425191e-07
Iter: 2342 loss: 5.34254355e-07
Iter: 2343 loss: 5.34257538e-07
Iter: 2344 loss: 5.34252592e-07
Iter: 2345 loss: 5.34251797e-07
Iter: 2346 loss: 5.34252e-07
Iter: 2347 loss: 5.34252706e-07
Iter: 2348 loss: 5.34252649e-07
Iter: 2349 loss: 5.34252308e-07
Iter: 2350 loss: 5.34252251e-07
Iter: 2351 loss: 5.34252308e-07
Iter: 2352 loss: 5.34252194e-07
Iter: 2353 loss: 5.34252194e-07
Iter: 2354 loss: 5.34252308e-07
Iter: 2355 loss: 5.34252194e-07
Iter: 2356 loss: 5.34252308e-07
Iter: 2357 loss: 5.34252194e-07
Iter: 2358 loss: 5.34252194e-07
Iter: 2359 loss: 5.34252194e-07
Iter: 2360 loss: 5.34252308e-07
Iter: 2361 loss: 5.34252308e-07
Iter: 2362 loss: 5.34252308e-07
Iter: 2363 loss: 5.34252308e-07
Iter: 2364 loss: 5.34252308e-07
Iter: 2365 loss: 5.34252194e-07
Iter: 2366 loss: 5.34314665e-07
Iter: 2367 loss: 5.34270043e-07
Iter: 2368 loss: 5.34258959e-07
Iter: 2369 loss: 5.34260948e-07
Iter: 2370 loss: 5.34277319e-07
Iter: 2371 loss: 5.34266519e-07
Iter: 2372 loss: 5.34277433e-07
Iter: 2373 loss: 5.34283743e-07
Iter: 2374 loss: 5.34267429e-07
Iter: 2375 loss: 5.34268167e-07
Iter: 2376 loss: 5.34263336e-07
Iter: 2377 loss: 5.34263393e-07
Iter: 2378 loss: 5.34258561e-07
Iter: 2379 loss: 5.34261972e-07
Iter: 2380 loss: 5.34258675e-07
Iter: 2381 loss: 5.3425606e-07
Iter: 2382 loss: 5.34252479e-07
Iter: 2383 loss: 5.34256515e-07
Iter: 2384 loss: 5.34256174e-07
Iter: 2385 loss: 5.34253104e-07
Iter: 2386 loss: 5.34253104e-07
Iter: 2387 loss: 5.34253161e-07
Iter: 2388 loss: 5.34253161e-07
Iter: 2389 loss: 5.34252479e-07
Iter: 2390 loss: 5.34253161e-07
Iter: 2391 loss: 5.34252479e-07
Iter: 2392 loss: 5.34252479e-07
Iter: 2393 loss: 5.34253161e-07
Iter: 2394 loss: 5.34252479e-07
Iter: 2395 loss: 5.34252479e-07
Iter: 2396 loss: 5.34253161e-07
Iter: 2397 loss: 5.34253161e-07
Iter: 2398 loss: 5.34252479e-07
Iter: 2399 loss: 5.34253161e-07
Iter: 2400 loss: 5.34253161e-07
Iter: 2401 loss: 5.34253161e-07
Iter: 2402 loss: 5.34252479e-07
Iter: 2403 loss: 5.34252479e-07
Iter: 2404 loss: 5.34253161e-07
Iter: 2405 loss: 5.34252479e-07
Iter: 2406 loss: 5.34253161e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.4_8000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec5420f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec5424c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec541887b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec54253620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec54193f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec54188158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec54146840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec540fca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec540fc730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec540fc510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec540b81e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec5406cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec5408cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec54046268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec5408c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec54053730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4efecc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4eff18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4ef3cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4ef19158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4ef7a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4eecc2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4eec06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4ee85f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4ee99378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4ee13f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4ee55598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec4ee130d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec0e93e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec0e8ea158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec0e8fd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec0e8b21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec0e8db598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec0e8ad9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec0e86d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fec0e82af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.81463144e-06
Iter: 2 loss: 1.92158541e-06
Iter: 3 loss: 1.81902476e-06
Iter: 4 loss: 1.49651237e-06
Iter: 5 loss: 1.66122709e-06
Iter: 6 loss: 1.28189049e-06
Iter: 7 loss: 1.13512579e-06
Iter: 8 loss: 1.15582338e-06
Iter: 9 loss: 1.02378658e-06
Iter: 10 loss: 1.00928901e-06
Iter: 11 loss: 9.73322358e-07
Iter: 12 loss: 9.39329311e-07
Iter: 13 loss: 1.09330267e-06
Iter: 14 loss: 9.32748208e-07
Iter: 15 loss: 9.20002776e-07
Iter: 16 loss: 8.98120902e-07
Iter: 17 loss: 8.98104e-07
Iter: 18 loss: 8.9738279e-07
Iter: 19 loss: 8.88821432e-07
Iter: 20 loss: 8.81162578e-07
Iter: 21 loss: 8.70584586e-07
Iter: 22 loss: 8.70123529e-07
Iter: 23 loss: 8.57006739e-07
Iter: 24 loss: 8.54267569e-07
Iter: 25 loss: 8.45603154e-07
Iter: 26 loss: 8.31125249e-07
Iter: 27 loss: 8.30466206e-07
Iter: 28 loss: 8.2457268e-07
Iter: 29 loss: 8.11900804e-07
Iter: 30 loss: 1.00768693e-06
Iter: 31 loss: 8.11432415e-07
Iter: 32 loss: 8.03196031e-07
Iter: 33 loss: 8.0313589e-07
Iter: 34 loss: 7.96646e-07
Iter: 35 loss: 8.09248434e-07
Iter: 36 loss: 7.9397995e-07
Iter: 37 loss: 7.91038701e-07
Iter: 38 loss: 7.96026598e-07
Iter: 39 loss: 7.89717205e-07
Iter: 40 loss: 7.86368616e-07
Iter: 41 loss: 7.84443728e-07
Iter: 42 loss: 7.83056521e-07
Iter: 43 loss: 7.83874896e-07
Iter: 44 loss: 7.81239692e-07
Iter: 45 loss: 7.79784443e-07
Iter: 46 loss: 7.76467061e-07
Iter: 47 loss: 8.19498268e-07
Iter: 48 loss: 7.76262709e-07
Iter: 49 loss: 7.71836881e-07
Iter: 50 loss: 7.72362341e-07
Iter: 51 loss: 7.68453731e-07
Iter: 52 loss: 7.67486767e-07
Iter: 53 loss: 7.65557274e-07
Iter: 54 loss: 7.64069682e-07
Iter: 55 loss: 7.60280841e-07
Iter: 56 loss: 7.90512217e-07
Iter: 57 loss: 7.59511693e-07
Iter: 58 loss: 7.55874112e-07
Iter: 59 loss: 8.10928668e-07
Iter: 60 loss: 7.55883718e-07
Iter: 61 loss: 7.52637e-07
Iter: 62 loss: 7.65640493e-07
Iter: 63 loss: 7.51888592e-07
Iter: 64 loss: 7.50551862e-07
Iter: 65 loss: 7.48106913e-07
Iter: 66 loss: 8.07760159e-07
Iter: 67 loss: 7.48115383e-07
Iter: 68 loss: 7.45436864e-07
Iter: 69 loss: 7.45410034e-07
Iter: 70 loss: 7.43630437e-07
Iter: 71 loss: 7.41450606e-07
Iter: 72 loss: 7.41269446e-07
Iter: 73 loss: 7.39172378e-07
Iter: 74 loss: 7.45198804e-07
Iter: 75 loss: 7.38530616e-07
Iter: 76 loss: 7.36893298e-07
Iter: 77 loss: 7.4874356e-07
Iter: 78 loss: 7.36730271e-07
Iter: 79 loss: 7.35709705e-07
Iter: 80 loss: 7.35698904e-07
Iter: 81 loss: 7.35198e-07
Iter: 82 loss: 7.33812612e-07
Iter: 83 loss: 7.42383918e-07
Iter: 84 loss: 7.33437901e-07
Iter: 85 loss: 7.31716e-07
Iter: 86 loss: 7.52866e-07
Iter: 87 loss: 7.31714294e-07
Iter: 88 loss: 7.30122e-07
Iter: 89 loss: 7.36061736e-07
Iter: 90 loss: 7.29733358e-07
Iter: 91 loss: 7.28889404e-07
Iter: 92 loss: 7.27084853e-07
Iter: 93 loss: 7.53638858e-07
Iter: 94 loss: 7.26974577e-07
Iter: 95 loss: 7.25611244e-07
Iter: 96 loss: 7.25382165e-07
Iter: 97 loss: 7.24414349e-07
Iter: 98 loss: 7.23013329e-07
Iter: 99 loss: 7.22970128e-07
Iter: 100 loss: 7.21873107e-07
Iter: 101 loss: 7.30551733e-07
Iter: 102 loss: 7.21834112e-07
Iter: 103 loss: 7.2066473e-07
Iter: 104 loss: 7.24999495e-07
Iter: 105 loss: 7.20379489e-07
Iter: 106 loss: 7.19922525e-07
Iter: 107 loss: 7.20059461e-07
Iter: 108 loss: 7.19594198e-07
Iter: 109 loss: 7.19034801e-07
Iter: 110 loss: 7.18946524e-07
Iter: 111 loss: 7.18534523e-07
Iter: 112 loss: 7.17649073e-07
Iter: 113 loss: 7.26350891e-07
Iter: 114 loss: 7.17625198e-07
Iter: 115 loss: 7.1680364e-07
Iter: 116 loss: 7.16547e-07
Iter: 117 loss: 7.16065756e-07
Iter: 118 loss: 7.15200713e-07
Iter: 119 loss: 7.15078841e-07
Iter: 120 loss: 7.14456519e-07
Iter: 121 loss: 7.12987458e-07
Iter: 122 loss: 7.27676479e-07
Iter: 123 loss: 7.1296e-07
Iter: 124 loss: 7.11925907e-07
Iter: 125 loss: 7.11000951e-07
Iter: 126 loss: 7.10747202e-07
Iter: 127 loss: 7.10292682e-07
Iter: 128 loss: 7.10271365e-07
Iter: 129 loss: 7.09732717e-07
Iter: 130 loss: 7.09379947e-07
Iter: 131 loss: 7.09200663e-07
Iter: 132 loss: 7.08730681e-07
Iter: 133 loss: 7.10224413e-07
Iter: 134 loss: 7.08603693e-07
Iter: 135 loss: 7.08342668e-07
Iter: 136 loss: 7.08346192e-07
Iter: 137 loss: 7.08086191e-07
Iter: 138 loss: 7.074309e-07
Iter: 139 loss: 7.12274186e-07
Iter: 140 loss: 7.0731312e-07
Iter: 141 loss: 7.06671472e-07
Iter: 142 loss: 7.12782e-07
Iter: 143 loss: 7.06651463e-07
Iter: 144 loss: 7.06256515e-07
Iter: 145 loss: 7.10193e-07
Iter: 146 loss: 7.06261062e-07
Iter: 147 loss: 7.05802449e-07
Iter: 148 loss: 7.05665173e-07
Iter: 149 loss: 7.05404318e-07
Iter: 150 loss: 7.04871809e-07
Iter: 151 loss: 7.05676939e-07
Iter: 152 loss: 7.0459339e-07
Iter: 153 loss: 7.04434797e-07
Iter: 154 loss: 7.04366926e-07
Iter: 155 loss: 7.041711e-07
Iter: 156 loss: 7.0365104e-07
Iter: 157 loss: 7.09905748e-07
Iter: 158 loss: 7.03603575e-07
Iter: 159 loss: 7.03017349e-07
Iter: 160 loss: 7.04554623e-07
Iter: 161 loss: 7.02809757e-07
Iter: 162 loss: 7.02414127e-07
Iter: 163 loss: 7.02404861e-07
Iter: 164 loss: 7.02166233e-07
Iter: 165 loss: 7.01418401e-07
Iter: 166 loss: 7.03668491e-07
Iter: 167 loss: 7.01051817e-07
Iter: 168 loss: 7.00850705e-07
Iter: 169 loss: 7.00571832e-07
Iter: 170 loss: 7.00227e-07
Iter: 171 loss: 7.00879525e-07
Iter: 172 loss: 7.00061435e-07
Iter: 173 loss: 6.99793645e-07
Iter: 174 loss: 6.9938659e-07
Iter: 175 loss: 6.99403586e-07
Iter: 176 loss: 6.99156317e-07
Iter: 177 loss: 6.99114139e-07
Iter: 178 loss: 6.98913084e-07
Iter: 179 loss: 6.99188377e-07
Iter: 180 loss: 6.98829353e-07
Iter: 181 loss: 6.98567362e-07
Iter: 182 loss: 6.98095505e-07
Iter: 183 loss: 7.06412663e-07
Iter: 184 loss: 6.98099143e-07
Iter: 185 loss: 6.97480061e-07
Iter: 186 loss: 7.02878424e-07
Iter: 187 loss: 6.97442943e-07
Iter: 188 loss: 6.96883831e-07
Iter: 189 loss: 6.99478562e-07
Iter: 190 loss: 6.96744962e-07
Iter: 191 loss: 6.96461598e-07
Iter: 192 loss: 6.96058237e-07
Iter: 193 loss: 6.9604755e-07
Iter: 194 loss: 6.95734343e-07
Iter: 195 loss: 6.95716381e-07
Iter: 196 loss: 6.95393965e-07
Iter: 197 loss: 6.95080303e-07
Iter: 198 loss: 6.95017093e-07
Iter: 199 loss: 6.94762e-07
Iter: 200 loss: 6.95853316e-07
Iter: 201 loss: 6.94723212e-07
Iter: 202 loss: 6.943946e-07
Iter: 203 loss: 6.95464166e-07
Iter: 204 loss: 6.94337587e-07
Iter: 205 loss: 6.9410703e-07
Iter: 206 loss: 6.93887046e-07
Iter: 207 loss: 6.93806328e-07
Iter: 208 loss: 6.93466575e-07
Iter: 209 loss: 6.94823086e-07
Iter: 210 loss: 6.93383299e-07
Iter: 211 loss: 6.92876085e-07
Iter: 212 loss: 6.9327416e-07
Iter: 213 loss: 6.92600565e-07
Iter: 214 loss: 6.91977334e-07
Iter: 215 loss: 6.92785363e-07
Iter: 216 loss: 6.91668e-07
Iter: 217 loss: 6.91299192e-07
Iter: 218 loss: 6.92738695e-07
Iter: 219 loss: 6.91218872e-07
Iter: 220 loss: 6.90788056e-07
Iter: 221 loss: 6.94460141e-07
Iter: 222 loss: 6.90742354e-07
Iter: 223 loss: 6.90504351e-07
Iter: 224 loss: 6.90406694e-07
Iter: 225 loss: 6.90277886e-07
Iter: 226 loss: 6.90144475e-07
Iter: 227 loss: 6.90135607e-07
Iter: 228 loss: 6.9000231e-07
Iter: 229 loss: 6.89837e-07
Iter: 230 loss: 6.89814215e-07
Iter: 231 loss: 6.8959281e-07
Iter: 232 loss: 6.89690353e-07
Iter: 233 loss: 6.89442572e-07
Iter: 234 loss: 6.89266244e-07
Iter: 235 loss: 6.89253511e-07
Iter: 236 loss: 6.89112653e-07
Iter: 237 loss: 6.88811895e-07
Iter: 238 loss: 6.91835396e-07
Iter: 239 loss: 6.88757e-07
Iter: 240 loss: 6.88378748e-07
Iter: 241 loss: 6.92216e-07
Iter: 242 loss: 6.88365958e-07
Iter: 243 loss: 6.88110333e-07
Iter: 244 loss: 6.89662386e-07
Iter: 245 loss: 6.88056844e-07
Iter: 246 loss: 6.87925649e-07
Iter: 247 loss: 6.87832085e-07
Iter: 248 loss: 6.87739657e-07
Iter: 249 loss: 6.87459874e-07
Iter: 250 loss: 6.87551506e-07
Iter: 251 loss: 6.87280703e-07
Iter: 252 loss: 6.8716264e-07
Iter: 253 loss: 6.8709528e-07
Iter: 254 loss: 6.86969884e-07
Iter: 255 loss: 6.86730687e-07
Iter: 256 loss: 6.90415732e-07
Iter: 257 loss: 6.86719432e-07
Iter: 258 loss: 6.86376097e-07
Iter: 259 loss: 6.87597208e-07
Iter: 260 loss: 6.86283386e-07
Iter: 261 loss: 6.85978534e-07
Iter: 262 loss: 6.89766125e-07
Iter: 263 loss: 6.85968416e-07
Iter: 264 loss: 6.8586985e-07
Iter: 265 loss: 6.85619341e-07
Iter: 266 loss: 6.8960378e-07
Iter: 267 loss: 6.85593648e-07
Iter: 268 loss: 6.8538094e-07
Iter: 269 loss: 6.8536832e-07
Iter: 270 loss: 6.85188752e-07
Iter: 271 loss: 6.85197222e-07
Iter: 272 loss: 6.85021178e-07
Iter: 273 loss: 6.84891177e-07
Iter: 274 loss: 6.85477175e-07
Iter: 275 loss: 6.8486122e-07
Iter: 276 loss: 6.84669089e-07
Iter: 277 loss: 6.8503374e-07
Iter: 278 loss: 6.84585871e-07
Iter: 279 loss: 6.8437447e-07
Iter: 280 loss: 6.84334168e-07
Iter: 281 loss: 6.84159033e-07
Iter: 282 loss: 6.83888345e-07
Iter: 283 loss: 6.8444848e-07
Iter: 284 loss: 6.83767723e-07
Iter: 285 loss: 6.83499138e-07
Iter: 286 loss: 6.8580573e-07
Iter: 287 loss: 6.83485553e-07
Iter: 288 loss: 6.83191615e-07
Iter: 289 loss: 6.83103281e-07
Iter: 290 loss: 6.82910127e-07
Iter: 291 loss: 6.8274062e-07
Iter: 292 loss: 6.8361885e-07
Iter: 293 loss: 6.8269776e-07
Iter: 294 loss: 6.82549626e-07
Iter: 295 loss: 6.83938538e-07
Iter: 296 loss: 6.82541838e-07
Iter: 297 loss: 6.82409791e-07
Iter: 298 loss: 6.82142741e-07
Iter: 299 loss: 6.87370857e-07
Iter: 300 loss: 6.82123755e-07
Iter: 301 loss: 6.81994152e-07
Iter: 302 loss: 6.81988467e-07
Iter: 303 loss: 6.81829476e-07
Iter: 304 loss: 6.81589142e-07
Iter: 305 loss: 6.81581184e-07
Iter: 306 loss: 6.81264964e-07
Iter: 307 loss: 6.82125574e-07
Iter: 308 loss: 6.81183337e-07
Iter: 309 loss: 6.80937887e-07
Iter: 310 loss: 6.84147267e-07
Iter: 311 loss: 6.80923449e-07
Iter: 312 loss: 6.8076173e-07
Iter: 313 loss: 6.80587789e-07
Iter: 314 loss: 6.80556923e-07
Iter: 315 loss: 6.80277765e-07
Iter: 316 loss: 6.80649805e-07
Iter: 317 loss: 6.80136964e-07
Iter: 318 loss: 6.79942445e-07
Iter: 319 loss: 6.7992579e-07
Iter: 320 loss: 6.79756852e-07
Iter: 321 loss: 6.80221092e-07
Iter: 322 loss: 6.79736559e-07
Iter: 323 loss: 6.796393e-07
Iter: 324 loss: 6.79392883e-07
Iter: 325 loss: 6.83307235e-07
Iter: 326 loss: 6.79389814e-07
Iter: 327 loss: 6.79265099e-07
Iter: 328 loss: 6.79240088e-07
Iter: 329 loss: 6.7911094e-07
Iter: 330 loss: 6.78969514e-07
Iter: 331 loss: 6.78950812e-07
Iter: 332 loss: 6.78750496e-07
Iter: 333 loss: 6.78854349e-07
Iter: 334 loss: 6.78588208e-07
Iter: 335 loss: 6.78292e-07
Iter: 336 loss: 6.81060669e-07
Iter: 337 loss: 6.78254764e-07
Iter: 338 loss: 6.7813653e-07
Iter: 339 loss: 6.78091283e-07
Iter: 340 loss: 6.78023525e-07
Iter: 341 loss: 6.77819969e-07
Iter: 342 loss: 6.79453251e-07
Iter: 343 loss: 6.77823152e-07
Iter: 344 loss: 6.77632897e-07
Iter: 345 loss: 6.77697642e-07
Iter: 346 loss: 6.77509775e-07
Iter: 347 loss: 6.77344644e-07
Iter: 348 loss: 6.77461401e-07
Iter: 349 loss: 6.77231583e-07
Iter: 350 loss: 6.76985792e-07
Iter: 351 loss: 6.77895514e-07
Iter: 352 loss: 6.76940203e-07
Iter: 353 loss: 6.76658715e-07
Iter: 354 loss: 6.78879417e-07
Iter: 355 loss: 6.76632339e-07
Iter: 356 loss: 6.76481477e-07
Iter: 357 loss: 6.7630242e-07
Iter: 358 loss: 6.76286163e-07
Iter: 359 loss: 6.76153149e-07
Iter: 360 loss: 6.76145646e-07
Iter: 361 loss: 6.75959654e-07
Iter: 362 loss: 6.75839942e-07
Iter: 363 loss: 6.75793331e-07
Iter: 364 loss: 6.75609897e-07
Iter: 365 loss: 6.75944875e-07
Iter: 366 loss: 6.75536739e-07
Iter: 367 loss: 6.75385706e-07
Iter: 368 loss: 6.77881872e-07
Iter: 369 loss: 6.75383887e-07
Iter: 370 loss: 6.75264232e-07
Iter: 371 loss: 6.75072215e-07
Iter: 372 loss: 6.79984055e-07
Iter: 373 loss: 6.75067554e-07
Iter: 374 loss: 6.74963303e-07
Iter: 375 loss: 6.74945625e-07
Iter: 376 loss: 6.74821081e-07
Iter: 377 loss: 6.7468136e-07
Iter: 378 loss: 6.74662601e-07
Iter: 379 loss: 6.74415446e-07
Iter: 380 loss: 6.74251396e-07
Iter: 381 loss: 6.74151693e-07
Iter: 382 loss: 6.7391e-07
Iter: 383 loss: 6.75927936e-07
Iter: 384 loss: 6.73936029e-07
Iter: 385 loss: 6.7367e-07
Iter: 386 loss: 6.75795491e-07
Iter: 387 loss: 6.73678926e-07
Iter: 388 loss: 6.73536476e-07
Iter: 389 loss: 6.73479235e-07
Iter: 390 loss: 6.73410341e-07
Iter: 391 loss: 6.7329546e-07
Iter: 392 loss: 6.73944669e-07
Iter: 393 loss: 6.73302907e-07
Iter: 394 loss: 6.73107309e-07
Iter: 395 loss: 6.73215254e-07
Iter: 396 loss: 6.73030229e-07
Iter: 397 loss: 6.72830879e-07
Iter: 398 loss: 6.72720489e-07
Iter: 399 loss: 6.72669273e-07
Iter: 400 loss: 6.72479871e-07
Iter: 401 loss: 6.7248186e-07
Iter: 402 loss: 6.7225767e-07
Iter: 403 loss: 6.71896203e-07
Iter: 404 loss: 6.71922294e-07
Iter: 405 loss: 6.71706061e-07
Iter: 406 loss: 6.74296643e-07
Iter: 407 loss: 6.71717203e-07
Iter: 408 loss: 6.71527971e-07
Iter: 409 loss: 6.7221788e-07
Iter: 410 loss: 6.71487214e-07
Iter: 411 loss: 6.71302246e-07
Iter: 412 loss: 6.71101e-07
Iter: 413 loss: 6.71096245e-07
Iter: 414 loss: 6.70864949e-07
Iter: 415 loss: 6.71602606e-07
Iter: 416 loss: 6.70807594e-07
Iter: 417 loss: 6.70669863e-07
Iter: 418 loss: 6.72577357e-07
Iter: 419 loss: 6.70671795e-07
Iter: 420 loss: 6.70462612e-07
Iter: 421 loss: 6.70257123e-07
Iter: 422 loss: 6.70243537e-07
Iter: 423 loss: 6.70106772e-07
Iter: 424 loss: 6.71230566e-07
Iter: 425 loss: 6.70099553e-07
Iter: 426 loss: 6.69984388e-07
Iter: 427 loss: 6.70677707e-07
Iter: 428 loss: 6.69971769e-07
Iter: 429 loss: 6.6988224e-07
Iter: 430 loss: 6.69743144e-07
Iter: 431 loss: 6.69733708e-07
Iter: 432 loss: 6.69622e-07
Iter: 433 loss: 6.69780945e-07
Iter: 434 loss: 6.69552833e-07
Iter: 435 loss: 6.69378835e-07
Iter: 436 loss: 6.71123871e-07
Iter: 437 loss: 6.6939549e-07
Iter: 438 loss: 6.69245651e-07
Iter: 439 loss: 6.6906e-07
Iter: 440 loss: 6.69058409e-07
Iter: 441 loss: 6.68971836e-07
Iter: 442 loss: 6.68929147e-07
Iter: 443 loss: 6.68852181e-07
Iter: 444 loss: 6.68663915e-07
Iter: 445 loss: 6.68671532e-07
Iter: 446 loss: 6.68532e-07
Iter: 447 loss: 6.69285328e-07
Iter: 448 loss: 6.68509e-07
Iter: 449 loss: 6.68441203e-07
Iter: 450 loss: 6.68369182e-07
Iter: 451 loss: 6.68351618e-07
Iter: 452 loss: 6.68243729e-07
Iter: 453 loss: 6.68961889e-07
Iter: 454 loss: 6.6820229e-07
Iter: 455 loss: 6.68142889e-07
Iter: 456 loss: 6.68756911e-07
Iter: 457 loss: 6.68140956e-07
Iter: 458 loss: 6.68029088e-07
Iter: 459 loss: 6.67894824e-07
Iter: 460 loss: 6.67913241e-07
Iter: 461 loss: 6.67718041e-07
Iter: 462 loss: 6.67716108e-07
Iter: 463 loss: 6.67571214e-07
Iter: 464 loss: 6.67491918e-07
Iter: 465 loss: 6.67483221e-07
Iter: 466 loss: 6.67371069e-07
Iter: 467 loss: 6.67317863e-07
Iter: 468 loss: 6.67250447e-07
Iter: 469 loss: 6.6717854e-07
Iter: 470 loss: 6.67650738e-07
Iter: 471 loss: 6.67193603e-07
Iter: 472 loss: 6.6710993e-07
Iter: 473 loss: 6.6732747e-07
Iter: 474 loss: 6.67094923e-07
Iter: 475 loss: 6.67030577e-07
Iter: 476 loss: 6.66918254e-07
Iter: 477 loss: 6.66900178e-07
Iter: 478 loss: 6.66877213e-07
Iter: 479 loss: 6.66868175e-07
Iter: 480 loss: 6.66796041e-07
Iter: 481 loss: 6.66647281e-07
Iter: 482 loss: 6.67739812e-07
Iter: 483 loss: 6.66593451e-07
Iter: 484 loss: 6.66342146e-07
Iter: 485 loss: 6.66143592e-07
Iter: 486 loss: 6.66055541e-07
Iter: 487 loss: 6.65710218e-07
Iter: 488 loss: 6.67482425e-07
Iter: 489 loss: 6.65649168e-07
Iter: 490 loss: 6.65494156e-07
Iter: 491 loss: 6.65454252e-07
Iter: 492 loss: 6.65301741e-07
Iter: 493 loss: 6.65334e-07
Iter: 494 loss: 6.65227276e-07
Iter: 495 loss: 6.65117568e-07
Iter: 496 loss: 6.65348807e-07
Iter: 497 loss: 6.65102e-07
Iter: 498 loss: 6.6496915e-07
Iter: 499 loss: 6.65544349e-07
Iter: 500 loss: 6.64932259e-07
Iter: 501 loss: 6.6488326e-07
Iter: 502 loss: 6.64768436e-07
Iter: 503 loss: 6.64771733e-07
Iter: 504 loss: 6.64650486e-07
Iter: 505 loss: 6.6625023e-07
Iter: 506 loss: 6.64648269e-07
Iter: 507 loss: 6.64544075e-07
Iter: 508 loss: 6.64339382e-07
Iter: 509 loss: 6.64332902e-07
Iter: 510 loss: 6.64152367e-07
Iter: 511 loss: 6.6466464e-07
Iter: 512 loss: 6.64098195e-07
Iter: 513 loss: 6.63966318e-07
Iter: 514 loss: 6.6616218e-07
Iter: 515 loss: 6.63952278e-07
Iter: 516 loss: 6.63864284e-07
Iter: 517 loss: 6.63596893e-07
Iter: 518 loss: 6.66630854e-07
Iter: 519 loss: 6.63591379e-07
Iter: 520 loss: 6.6340931e-07
Iter: 521 loss: 6.63890205e-07
Iter: 522 loss: 6.63344622e-07
Iter: 523 loss: 6.63077799e-07
Iter: 524 loss: 6.63472406e-07
Iter: 525 loss: 6.62992193e-07
Iter: 526 loss: 6.62886237e-07
Iter: 527 loss: 6.62819673e-07
Iter: 528 loss: 6.62748505e-07
Iter: 529 loss: 6.62544039e-07
Iter: 530 loss: 6.64142476e-07
Iter: 531 loss: 6.62537332e-07
Iter: 532 loss: 6.62302341e-07
Iter: 533 loss: 6.62297e-07
Iter: 534 loss: 6.62194111e-07
Iter: 535 loss: 6.62142384e-07
Iter: 536 loss: 6.62082698e-07
Iter: 537 loss: 6.62020398e-07
Iter: 538 loss: 6.62486514e-07
Iter: 539 loss: 6.62009654e-07
Iter: 540 loss: 6.6191177e-07
Iter: 541 loss: 6.62066896e-07
Iter: 542 loss: 6.6186908e-07
Iter: 543 loss: 6.61801323e-07
Iter: 544 loss: 6.61870899e-07
Iter: 545 loss: 6.61762272e-07
Iter: 546 loss: 6.61673766e-07
Iter: 547 loss: 6.61719184e-07
Iter: 548 loss: 6.61627666e-07
Iter: 549 loss: 6.61493686e-07
Iter: 550 loss: 6.61397507e-07
Iter: 551 loss: 6.61351919e-07
Iter: 552 loss: 6.61182526e-07
Iter: 553 loss: 6.61120396e-07
Iter: 554 loss: 6.60999e-07
Iter: 555 loss: 6.60627393e-07
Iter: 556 loss: 6.61078957e-07
Iter: 557 loss: 6.60440946e-07
Iter: 558 loss: 6.60475393e-07
Iter: 559 loss: 6.60333114e-07
Iter: 560 loss: 6.60197429e-07
Iter: 561 loss: 6.60069475e-07
Iter: 562 loss: 6.60061289e-07
Iter: 563 loss: 6.59935949e-07
Iter: 564 loss: 6.60175033e-07
Iter: 565 loss: 6.59865e-07
Iter: 566 loss: 6.59773889e-07
Iter: 567 loss: 6.5977548e-07
Iter: 568 loss: 6.59730745e-07
Iter: 569 loss: 6.59625755e-07
Iter: 570 loss: 6.60783314e-07
Iter: 571 loss: 6.59641273e-07
Iter: 572 loss: 6.59471e-07
Iter: 573 loss: 6.60843398e-07
Iter: 574 loss: 6.59460682e-07
Iter: 575 loss: 6.59375587e-07
Iter: 576 loss: 6.59279294e-07
Iter: 577 loss: 6.59252237e-07
Iter: 578 loss: 6.59136163e-07
Iter: 579 loss: 6.60925e-07
Iter: 580 loss: 6.59128318e-07
Iter: 581 loss: 6.58982913e-07
Iter: 582 loss: 6.5878146e-07
Iter: 583 loss: 6.58756221e-07
Iter: 584 loss: 6.58521799e-07
Iter: 585 loss: 6.58972567e-07
Iter: 586 loss: 6.58408908e-07
Iter: 587 loss: 6.58225076e-07
Iter: 588 loss: 6.58288798e-07
Iter: 589 loss: 6.58081603e-07
Iter: 590 loss: 6.57945634e-07
Iter: 591 loss: 6.57938244e-07
Iter: 592 loss: 6.57885607e-07
Iter: 593 loss: 6.57885948e-07
Iter: 594 loss: 6.57828878e-07
Iter: 595 loss: 6.57691658e-07
Iter: 596 loss: 6.58345812e-07
Iter: 597 loss: 6.5764516e-07
Iter: 598 loss: 6.57486908e-07
Iter: 599 loss: 6.58981833e-07
Iter: 600 loss: 6.57492308e-07
Iter: 601 loss: 6.57329e-07
Iter: 602 loss: 6.57816031e-07
Iter: 603 loss: 6.57288638e-07
Iter: 604 loss: 6.57150508e-07
Iter: 605 loss: 6.5712743e-07
Iter: 606 loss: 6.57044779e-07
Iter: 607 loss: 6.56932173e-07
Iter: 608 loss: 6.56936152e-07
Iter: 609 loss: 6.56884197e-07
Iter: 610 loss: 6.56771931e-07
Iter: 611 loss: 6.58424824e-07
Iter: 612 loss: 6.56738735e-07
Iter: 613 loss: 6.56617715e-07
Iter: 614 loss: 6.56621864e-07
Iter: 615 loss: 6.56542625e-07
Iter: 616 loss: 6.56403245e-07
Iter: 617 loss: 6.56418649e-07
Iter: 618 loss: 6.56197699e-07
Iter: 619 loss: 6.56075031e-07
Iter: 620 loss: 6.56022166e-07
Iter: 621 loss: 6.5573937e-07
Iter: 622 loss: 6.58869965e-07
Iter: 623 loss: 6.55715e-07
Iter: 624 loss: 6.55590327e-07
Iter: 625 loss: 6.57442172e-07
Iter: 626 loss: 6.55592089e-07
Iter: 627 loss: 6.55475617e-07
Iter: 628 loss: 6.5554417e-07
Iter: 629 loss: 6.55365113e-07
Iter: 630 loss: 6.55259839e-07
Iter: 631 loss: 6.55162467e-07
Iter: 632 loss: 6.55105e-07
Iter: 633 loss: 6.54973405e-07
Iter: 634 loss: 6.56052578e-07
Iter: 635 loss: 6.54959194e-07
Iter: 636 loss: 6.54770247e-07
Iter: 637 loss: 6.55248073e-07
Iter: 638 loss: 6.54727785e-07
Iter: 639 loss: 6.54557e-07
Iter: 640 loss: 6.54406961e-07
Iter: 641 loss: 6.54424639e-07
Iter: 642 loss: 6.5422887e-07
Iter: 643 loss: 6.54215114e-07
Iter: 644 loss: 6.54031908e-07
Iter: 645 loss: 6.53938059e-07
Iter: 646 loss: 6.53851e-07
Iter: 647 loss: 6.53785605e-07
Iter: 648 loss: 6.53793e-07
Iter: 649 loss: 6.53707048e-07
Iter: 650 loss: 6.53626e-07
Iter: 651 loss: 6.53625762e-07
Iter: 652 loss: 6.53528048e-07
Iter: 653 loss: 6.53494681e-07
Iter: 654 loss: 6.53448353e-07
Iter: 655 loss: 6.53347854e-07
Iter: 656 loss: 6.53483312e-07
Iter: 657 loss: 6.53290044e-07
Iter: 658 loss: 6.53157315e-07
Iter: 659 loss: 6.54177938e-07
Iter: 660 loss: 6.53135714e-07
Iter: 661 loss: 6.53019356e-07
Iter: 662 loss: 6.54319138e-07
Iter: 663 loss: 6.53014865e-07
Iter: 664 loss: 6.52926531e-07
Iter: 665 loss: 6.52711833e-07
Iter: 666 loss: 6.54621147e-07
Iter: 667 loss: 6.52700692e-07
Iter: 668 loss: 6.52490257e-07
Iter: 669 loss: 6.53974496e-07
Iter: 670 loss: 6.52487188e-07
Iter: 671 loss: 6.5236884e-07
Iter: 672 loss: 6.52368499e-07
Iter: 673 loss: 6.52278e-07
Iter: 674 loss: 6.52109065e-07
Iter: 675 loss: 6.53508721e-07
Iter: 676 loss: 6.52052506e-07
Iter: 677 loss: 6.51948653e-07
Iter: 678 loss: 6.5371853e-07
Iter: 679 loss: 6.51963774e-07
Iter: 680 loss: 6.51861e-07
Iter: 681 loss: 6.51854407e-07
Iter: 682 loss: 6.51795858e-07
Iter: 683 loss: 6.51652954e-07
Iter: 684 loss: 6.53072902e-07
Iter: 685 loss: 6.51640448e-07
Iter: 686 loss: 6.51645564e-07
Iter: 687 loss: 6.51600203e-07
Iter: 688 loss: 6.51548589e-07
Iter: 689 loss: 6.51425e-07
Iter: 690 loss: 6.52849849e-07
Iter: 691 loss: 6.51374307e-07
Iter: 692 loss: 6.51262383e-07
Iter: 693 loss: 6.51460141e-07
Iter: 694 loss: 6.5121e-07
Iter: 695 loss: 6.51126925e-07
Iter: 696 loss: 6.52252879e-07
Iter: 697 loss: 6.51126243e-07
Iter: 698 loss: 6.51074856e-07
Iter: 699 loss: 6.51551773e-07
Iter: 700 loss: 6.5104814e-07
Iter: 701 loss: 6.50995446e-07
Iter: 702 loss: 6.50872039e-07
Iter: 703 loss: 6.5300145e-07
Iter: 704 loss: 6.50862376e-07
Iter: 705 loss: 6.50769891e-07
Iter: 706 loss: 6.51421544e-07
Iter: 707 loss: 6.50789502e-07
Iter: 708 loss: 6.50656773e-07
Iter: 709 loss: 6.51240555e-07
Iter: 710 loss: 6.50645461e-07
Iter: 711 loss: 6.50544791e-07
Iter: 712 loss: 6.50399e-07
Iter: 713 loss: 6.50396203e-07
Iter: 714 loss: 6.5027757e-07
Iter: 715 loss: 6.50292122e-07
Iter: 716 loss: 6.50204186e-07
Iter: 717 loss: 6.50372272e-07
Iter: 718 loss: 6.50149218e-07
Iter: 719 loss: 6.50099082e-07
Iter: 720 loss: 6.50142e-07
Iter: 721 loss: 6.50076e-07
Iter: 722 loss: 6.50004267e-07
Iter: 723 loss: 6.50017e-07
Iter: 724 loss: 6.49988579e-07
Iter: 725 loss: 6.49897061e-07
Iter: 726 loss: 6.50278253e-07
Iter: 727 loss: 6.49877791e-07
Iter: 728 loss: 6.49761034e-07
Iter: 729 loss: 6.50083336e-07
Iter: 730 loss: 6.4971988e-07
Iter: 731 loss: 6.49631545e-07
Iter: 732 loss: 6.50549566e-07
Iter: 733 loss: 6.49647518e-07
Iter: 734 loss: 6.49512913e-07
Iter: 735 loss: 6.49457547e-07
Iter: 736 loss: 6.49404797e-07
Iter: 737 loss: 6.49275933e-07
Iter: 738 loss: 6.49418268e-07
Iter: 739 loss: 6.49187086e-07
Iter: 740 loss: 6.49126832e-07
Iter: 741 loss: 6.49107847e-07
Iter: 742 loss: 6.49024514e-07
Iter: 743 loss: 6.49034519e-07
Iter: 744 loss: 6.48981882e-07
Iter: 745 loss: 6.48902073e-07
Iter: 746 loss: 6.4908113e-07
Iter: 747 loss: 6.48864898e-07
Iter: 748 loss: 6.48822947e-07
Iter: 749 loss: 6.48827267e-07
Iter: 750 loss: 6.48776791e-07
Iter: 751 loss: 6.48718355e-07
Iter: 752 loss: 6.4990445e-07
Iter: 753 loss: 6.48703406e-07
Iter: 754 loss: 6.48638547e-07
Iter: 755 loss: 6.49607e-07
Iter: 756 loss: 6.48643493e-07
Iter: 757 loss: 6.48570676e-07
Iter: 758 loss: 6.48505e-07
Iter: 759 loss: 6.48491891e-07
Iter: 760 loss: 6.48379682e-07
Iter: 761 loss: 6.48236664e-07
Iter: 762 loss: 6.48208584e-07
Iter: 763 loss: 6.48088417e-07
Iter: 764 loss: 6.48086939e-07
Iter: 765 loss: 6.47986099e-07
Iter: 766 loss: 6.48597791e-07
Iter: 767 loss: 6.47969728e-07
Iter: 768 loss: 6.47916863e-07
Iter: 769 loss: 6.47850356e-07
Iter: 770 loss: 6.47861441e-07
Iter: 771 loss: 6.47787658e-07
Iter: 772 loss: 6.48181071e-07
Iter: 773 loss: 6.47774186e-07
Iter: 774 loss: 6.47691422e-07
Iter: 775 loss: 6.48550781e-07
Iter: 776 loss: 6.47711545e-07
Iter: 777 loss: 6.4767778e-07
Iter: 778 loss: 6.47587797e-07
Iter: 779 loss: 6.49015e-07
Iter: 780 loss: 6.47599848e-07
Iter: 781 loss: 6.4753533e-07
Iter: 782 loss: 6.4753317e-07
Iter: 783 loss: 6.47473826e-07
Iter: 784 loss: 6.47485e-07
Iter: 785 loss: 6.47433808e-07
Iter: 786 loss: 6.47384297e-07
Iter: 787 loss: 6.47440743e-07
Iter: 788 loss: 6.47349907e-07
Iter: 789 loss: 6.47247077e-07
Iter: 790 loss: 6.4774008e-07
Iter: 791 loss: 6.47255661e-07
Iter: 792 loss: 6.47184947e-07
Iter: 793 loss: 6.47129184e-07
Iter: 794 loss: 6.47136972e-07
Iter: 795 loss: 6.4706154e-07
Iter: 796 loss: 6.47622585e-07
Iter: 797 loss: 6.47060688e-07
Iter: 798 loss: 6.46985e-07
Iter: 799 loss: 6.47201205e-07
Iter: 800 loss: 6.46961212e-07
Iter: 801 loss: 6.46890612e-07
Iter: 802 loss: 6.46709566e-07
Iter: 803 loss: 6.46713e-07
Iter: 804 loss: 6.46563308e-07
Iter: 805 loss: 6.47614115e-07
Iter: 806 loss: 6.46560636e-07
Iter: 807 loss: 6.46492481e-07
Iter: 808 loss: 6.46497824e-07
Iter: 809 loss: 6.46436149e-07
Iter: 810 loss: 6.46339402e-07
Iter: 811 loss: 6.46326725e-07
Iter: 812 loss: 6.46264652e-07
Iter: 813 loss: 6.46281705e-07
Iter: 814 loss: 6.46236458e-07
Iter: 815 loss: 6.46299895e-07
Iter: 816 loss: 6.46195076e-07
Iter: 817 loss: 6.46159947e-07
Iter: 818 loss: 6.46153694e-07
Iter: 819 loss: 6.46096396e-07
Iter: 820 loss: 6.4605149e-07
Iter: 821 loss: 6.46048875e-07
Iter: 822 loss: 6.4600539e-07
Iter: 823 loss: 6.45890111e-07
Iter: 824 loss: 6.46772321e-07
Iter: 825 loss: 6.45876128e-07
Iter: 826 loss: 6.45706507e-07
Iter: 827 loss: 6.45729187e-07
Iter: 828 loss: 6.4557986e-07
Iter: 829 loss: 6.45449177e-07
Iter: 830 loss: 6.45434852e-07
Iter: 831 loss: 6.45327646e-07
Iter: 832 loss: 6.45217142e-07
Iter: 833 loss: 6.45208274e-07
Iter: 834 loss: 6.45071111e-07
Iter: 835 loss: 6.45218734e-07
Iter: 836 loss: 6.45009891e-07
Iter: 837 loss: 6.44958618e-07
Iter: 838 loss: 6.44930083e-07
Iter: 839 loss: 6.44885404e-07
Iter: 840 loss: 6.4486153e-07
Iter: 841 loss: 6.44815714e-07
Iter: 842 loss: 6.44747047e-07
Iter: 843 loss: 6.44765748e-07
Iter: 844 loss: 6.44704755e-07
Iter: 845 loss: 6.44593513e-07
Iter: 846 loss: 6.45651198e-07
Iter: 847 loss: 6.44591523e-07
Iter: 848 loss: 6.44534225e-07
Iter: 849 loss: 6.44484885e-07
Iter: 850 loss: 6.44451234e-07
Iter: 851 loss: 6.44379725e-07
Iter: 852 loss: 6.45092598e-07
Iter: 853 loss: 6.44385466e-07
Iter: 854 loss: 6.44274905e-07
Iter: 855 loss: 6.44163833e-07
Iter: 856 loss: 6.44136946e-07
Iter: 857 loss: 6.44041734e-07
Iter: 858 loss: 6.44224031e-07
Iter: 859 loss: 6.43990347e-07
Iter: 860 loss: 6.43930605e-07
Iter: 861 loss: 6.43936119e-07
Iter: 862 loss: 6.43851649e-07
Iter: 863 loss: 6.43808e-07
Iter: 864 loss: 6.4377906e-07
Iter: 865 loss: 6.43684871e-07
Iter: 866 loss: 6.43746375e-07
Iter: 867 loss: 6.43677595e-07
Iter: 868 loss: 6.43565954e-07
Iter: 869 loss: 6.4371892e-07
Iter: 870 loss: 6.4352696e-07
Iter: 871 loss: 6.43410715e-07
Iter: 872 loss: 6.44298211e-07
Iter: 873 loss: 6.43390592e-07
Iter: 874 loss: 6.43316866e-07
Iter: 875 loss: 6.43287251e-07
Iter: 876 loss: 6.4325252e-07
Iter: 877 loss: 6.43171404e-07
Iter: 878 loss: 6.43164299e-07
Iter: 879 loss: 6.43125759e-07
Iter: 880 loss: 6.43045155e-07
Iter: 881 loss: 6.43037708e-07
Iter: 882 loss: 6.42982172e-07
Iter: 883 loss: 6.43794465e-07
Iter: 884 loss: 6.42998316e-07
Iter: 885 loss: 6.42948294e-07
Iter: 886 loss: 6.42969837e-07
Iter: 887 loss: 6.42902194e-07
Iter: 888 loss: 6.4284643e-07
Iter: 889 loss: 6.42697557e-07
Iter: 890 loss: 6.451952e-07
Iter: 891 loss: 6.42702844e-07
Iter: 892 loss: 6.42578868e-07
Iter: 893 loss: 6.4391611e-07
Iter: 894 loss: 6.42580744e-07
Iter: 895 loss: 6.42482235e-07
Iter: 896 loss: 6.4340361e-07
Iter: 897 loss: 6.42482178e-07
Iter: 898 loss: 6.42410441e-07
Iter: 899 loss: 6.42223597e-07
Iter: 900 loss: 6.4358585e-07
Iter: 901 loss: 6.42173632e-07
Iter: 902 loss: 6.41987299e-07
Iter: 903 loss: 6.43969543e-07
Iter: 904 loss: 6.41972747e-07
Iter: 905 loss: 6.41937731e-07
Iter: 906 loss: 6.4189868e-07
Iter: 907 loss: 6.41850704e-07
Iter: 908 loss: 6.4177749e-07
Iter: 909 loss: 6.43943167e-07
Iter: 910 loss: 6.41784254e-07
Iter: 911 loss: 6.4171428e-07
Iter: 912 loss: 6.4171843e-07
Iter: 913 loss: 6.41695863e-07
Iter: 914 loss: 6.41708141e-07
Iter: 915 loss: 6.41659369e-07
Iter: 916 loss: 6.41598149e-07
Iter: 917 loss: 6.41582119e-07
Iter: 918 loss: 6.41558586e-07
Iter: 919 loss: 6.41473548e-07
Iter: 920 loss: 6.42146631e-07
Iter: 921 loss: 6.41445581e-07
Iter: 922 loss: 6.41390045e-07
Iter: 923 loss: 6.41272948e-07
Iter: 924 loss: 6.4126084e-07
Iter: 925 loss: 6.41156362e-07
Iter: 926 loss: 6.41274482e-07
Iter: 927 loss: 6.41080874e-07
Iter: 928 loss: 6.41040117e-07
Iter: 929 loss: 6.41014253e-07
Iter: 930 loss: 6.40971905e-07
Iter: 931 loss: 6.40863618e-07
Iter: 932 loss: 6.40865039e-07
Iter: 933 loss: 6.40792791e-07
Iter: 934 loss: 6.40862e-07
Iter: 935 loss: 6.40750329e-07
Iter: 936 loss: 6.40672852e-07
Iter: 937 loss: 6.41732072e-07
Iter: 938 loss: 6.40678593e-07
Iter: 939 loss: 6.40606572e-07
Iter: 940 loss: 6.40724352e-07
Iter: 941 loss: 6.40580538e-07
Iter: 942 loss: 6.40519033e-07
Iter: 943 loss: 6.404847e-07
Iter: 944 loss: 6.40456392e-07
Iter: 945 loss: 6.40354529e-07
Iter: 946 loss: 6.41758561e-07
Iter: 947 loss: 6.40359531e-07
Iter: 948 loss: 6.40292683e-07
Iter: 949 loss: 6.40241069e-07
Iter: 950 loss: 6.40237545e-07
Iter: 951 loss: 6.40174e-07
Iter: 952 loss: 6.41166821e-07
Iter: 953 loss: 6.40172345e-07
Iter: 954 loss: 6.4010635e-07
Iter: 955 loss: 6.40006e-07
Iter: 956 loss: 6.39999371e-07
Iter: 957 loss: 6.39948667e-07
Iter: 958 loss: 6.40047574e-07
Iter: 959 loss: 6.39897905e-07
Iter: 960 loss: 6.39852487e-07
Iter: 961 loss: 6.4052648e-07
Iter: 962 loss: 6.39858627e-07
Iter: 963 loss: 6.39807581e-07
Iter: 964 loss: 6.39717712e-07
Iter: 965 loss: 6.39703444e-07
Iter: 966 loss: 6.3961e-07
Iter: 967 loss: 6.39624261e-07
Iter: 968 loss: 6.39538086e-07
Iter: 969 loss: 6.39463281e-07
Iter: 970 loss: 6.39812299e-07
Iter: 971 loss: 6.39417806e-07
Iter: 972 loss: 6.39374207e-07
Iter: 973 loss: 6.39372388e-07
Iter: 974 loss: 6.39324867e-07
Iter: 975 loss: 6.39278369e-07
Iter: 976 loss: 6.39257621e-07
Iter: 977 loss: 6.3922414e-07
Iter: 978 loss: 6.39744599e-07
Iter: 979 loss: 6.39215727e-07
Iter: 980 loss: 6.39166728e-07
Iter: 981 loss: 6.39166899e-07
Iter: 982 loss: 6.39108066e-07
Iter: 983 loss: 6.39078166e-07
Iter: 984 loss: 6.39151608e-07
Iter: 985 loss: 6.3906009e-07
Iter: 986 loss: 6.38991821e-07
Iter: 987 loss: 6.39478458e-07
Iter: 988 loss: 6.38986307e-07
Iter: 989 loss: 6.3895493e-07
Iter: 990 loss: 6.38830443e-07
Iter: 991 loss: 6.40327926e-07
Iter: 992 loss: 6.38818278e-07
Iter: 993 loss: 6.38693848e-07
Iter: 994 loss: 6.38969595e-07
Iter: 995 loss: 6.38660481e-07
Iter: 996 loss: 6.38646156e-07
Iter: 997 loss: 6.38620236e-07
Iter: 998 loss: 6.38564529e-07
Iter: 999 loss: 6.38509675e-07
Iter: 1000 loss: 6.38484835e-07
Iter: 1001 loss: 6.38453e-07
Iter: 1002 loss: 6.38481708e-07
Iter: 1003 loss: 6.38428503e-07
Iter: 1004 loss: 6.38347046e-07
Iter: 1005 loss: 6.38616029e-07
Iter: 1006 loss: 6.3835023e-07
Iter: 1007 loss: 6.38286735e-07
Iter: 1008 loss: 6.39064183e-07
Iter: 1009 loss: 6.38287929e-07
Iter: 1010 loss: 6.38252857e-07
Iter: 1011 loss: 6.3817788e-07
Iter: 1012 loss: 6.39580151e-07
Iter: 1013 loss: 6.38192262e-07
Iter: 1014 loss: 6.38127403e-07
Iter: 1015 loss: 6.38113193e-07
Iter: 1016 loss: 6.38063966e-07
Iter: 1017 loss: 6.37970857e-07
Iter: 1018 loss: 6.3799564e-07
Iter: 1019 loss: 6.37941639e-07
Iter: 1020 loss: 6.38654797e-07
Iter: 1021 loss: 6.37928451e-07
Iter: 1022 loss: 6.37882863e-07
Iter: 1023 loss: 6.37937831e-07
Iter: 1024 loss: 6.37854555e-07
Iter: 1025 loss: 6.37795779e-07
Iter: 1026 loss: 6.3780476e-07
Iter: 1027 loss: 6.37771109e-07
Iter: 1028 loss: 6.37708126e-07
Iter: 1029 loss: 6.37692e-07
Iter: 1030 loss: 6.37645655e-07
Iter: 1031 loss: 6.37621952e-07
Iter: 1032 loss: 6.37601488e-07
Iter: 1033 loss: 6.37562152e-07
Iter: 1034 loss: 6.37481207e-07
Iter: 1035 loss: 6.37490871e-07
Iter: 1036 loss: 6.37401342e-07
Iter: 1037 loss: 6.37325e-07
Iter: 1038 loss: 6.37306e-07
Iter: 1039 loss: 6.37264463e-07
Iter: 1040 loss: 6.37242636e-07
Iter: 1041 loss: 6.37173457e-07
Iter: 1042 loss: 6.37409414e-07
Iter: 1043 loss: 6.37183803e-07
Iter: 1044 loss: 6.37142193e-07
Iter: 1045 loss: 6.37109224e-07
Iter: 1046 loss: 6.37137191e-07
Iter: 1047 loss: 6.37060282e-07
Iter: 1048 loss: 6.37527251e-07
Iter: 1049 loss: 6.37060793e-07
Iter: 1050 loss: 6.37030723e-07
Iter: 1051 loss: 6.37006224e-07
Iter: 1052 loss: 6.3697928e-07
Iter: 1053 loss: 6.36952223e-07
Iter: 1054 loss: 6.37460857e-07
Iter: 1055 loss: 6.36946083e-07
Iter: 1056 loss: 6.36882817e-07
Iter: 1057 loss: 6.36829895e-07
Iter: 1058 loss: 6.36844788e-07
Iter: 1059 loss: 6.36755885e-07
Iter: 1060 loss: 6.36736502e-07
Iter: 1061 loss: 6.36696e-07
Iter: 1062 loss: 6.36608206e-07
Iter: 1063 loss: 6.36868549e-07
Iter: 1064 loss: 6.36596724e-07
Iter: 1065 loss: 6.3660832e-07
Iter: 1066 loss: 6.36564096e-07
Iter: 1067 loss: 6.36550681e-07
Iter: 1068 loss: 6.36493155e-07
Iter: 1069 loss: 6.37036464e-07
Iter: 1070 loss: 6.36482127e-07
Iter: 1071 loss: 6.36441712e-07
Iter: 1072 loss: 6.36544428e-07
Iter: 1073 loss: 6.36391917e-07
Iter: 1074 loss: 6.36355196e-07
Iter: 1075 loss: 6.36856498e-07
Iter: 1076 loss: 6.36362358e-07
Iter: 1077 loss: 6.36303923e-07
Iter: 1078 loss: 6.36225082e-07
Iter: 1079 loss: 6.36204106e-07
Iter: 1080 loss: 6.36133052e-07
Iter: 1081 loss: 6.36212917e-07
Iter: 1082 loss: 6.36099e-07
Iter: 1083 loss: 6.36060633e-07
Iter: 1084 loss: 6.36056257e-07
Iter: 1085 loss: 6.35991967e-07
Iter: 1086 loss: 6.35911306e-07
Iter: 1087 loss: 6.36980076e-07
Iter: 1088 loss: 6.35929609e-07
Iter: 1089 loss: 6.35888398e-07
Iter: 1090 loss: 6.35878735e-07
Iter: 1091 loss: 6.35843946e-07
Iter: 1092 loss: 6.35827746e-07
Iter: 1093 loss: 6.35811489e-07
Iter: 1094 loss: 6.35787444e-07
Iter: 1095 loss: 6.35694846e-07
Iter: 1096 loss: 6.37099902e-07
Iter: 1097 loss: 6.35699848e-07
Iter: 1098 loss: 6.35612764e-07
Iter: 1099 loss: 6.35991e-07
Iter: 1100 loss: 6.35603669e-07
Iter: 1101 loss: 6.35482877e-07
Iter: 1102 loss: 6.35548417e-07
Iter: 1103 loss: 6.35414949e-07
Iter: 1104 loss: 6.35492313e-07
Iter: 1105 loss: 6.3541188e-07
Iter: 1106 loss: 6.35375613e-07
Iter: 1107 loss: 6.35324398e-07
Iter: 1108 loss: 6.36311597e-07
Iter: 1109 loss: 6.35330878e-07
Iter: 1110 loss: 6.35271419e-07
Iter: 1111 loss: 6.3527358e-07
Iter: 1112 loss: 6.35239644e-07
Iter: 1113 loss: 6.35367428e-07
Iter: 1114 loss: 6.35217589e-07
Iter: 1115 loss: 6.35196386e-07
Iter: 1116 loss: 6.35116521e-07
Iter: 1117 loss: 6.35555125e-07
Iter: 1118 loss: 6.35110155e-07
Iter: 1119 loss: 6.35022104e-07
Iter: 1120 loss: 6.35850142e-07
Iter: 1121 loss: 6.35013294e-07
Iter: 1122 loss: 6.34954688e-07
Iter: 1123 loss: 6.34959633e-07
Iter: 1124 loss: 6.34927233e-07
Iter: 1125 loss: 6.3484481e-07
Iter: 1126 loss: 6.35787273e-07
Iter: 1127 loss: 6.34833555e-07
Iter: 1128 loss: 6.34785749e-07
Iter: 1129 loss: 6.34791263e-07
Iter: 1130 loss: 6.34779155e-07
Iter: 1131 loss: 6.34794333e-07
Iter: 1132 loss: 6.34765115e-07
Iter: 1133 loss: 6.34722426e-07
Iter: 1134 loss: 6.34670755e-07
Iter: 1135 loss: 6.34674052e-07
Iter: 1136 loss: 6.34644607e-07
Iter: 1137 loss: 6.35117374e-07
Iter: 1138 loss: 6.34628236e-07
Iter: 1139 loss: 6.34609705e-07
Iter: 1140 loss: 6.35050469e-07
Iter: 1141 loss: 6.34608682e-07
Iter: 1142 loss: 6.34565254e-07
Iter: 1143 loss: 6.34482547e-07
Iter: 1144 loss: 6.34888579e-07
Iter: 1145 loss: 6.34453215e-07
Iter: 1146 loss: 6.343829e-07
Iter: 1147 loss: 6.34397e-07
Iter: 1148 loss: 6.3433265e-07
Iter: 1149 loss: 6.34802518e-07
Iter: 1150 loss: 6.34336629e-07
Iter: 1151 loss: 6.34304456e-07
Iter: 1152 loss: 6.34219077e-07
Iter: 1153 loss: 6.34868798e-07
Iter: 1154 loss: 6.34211403e-07
Iter: 1155 loss: 6.34182811e-07
Iter: 1156 loss: 6.34185881e-07
Iter: 1157 loss: 6.34148591e-07
Iter: 1158 loss: 6.34478e-07
Iter: 1159 loss: 6.34150524e-07
Iter: 1160 loss: 6.34136711e-07
Iter: 1161 loss: 6.34067874e-07
Iter: 1162 loss: 6.34639889e-07
Iter: 1163 loss: 6.3407e-07
Iter: 1164 loss: 6.34045819e-07
Iter: 1165 loss: 6.34027231e-07
Iter: 1166 loss: 6.33994205e-07
Iter: 1167 loss: 6.33962259e-07
Iter: 1168 loss: 6.33956859e-07
Iter: 1169 loss: 6.33875061e-07
Iter: 1170 loss: 6.33938384e-07
Iter: 1171 loss: 6.33861362e-07
Iter: 1172 loss: 6.33820207e-07
Iter: 1173 loss: 6.33994716e-07
Iter: 1174 loss: 6.33790933e-07
Iter: 1175 loss: 6.33753189e-07
Iter: 1176 loss: 6.33763761e-07
Iter: 1177 loss: 6.33734373e-07
Iter: 1178 loss: 6.33705099e-07
Iter: 1179 loss: 6.3369464e-07
Iter: 1180 loss: 6.33664683e-07
Iter: 1181 loss: 6.33712261e-07
Iter: 1182 loss: 6.33644333e-07
Iter: 1183 loss: 6.33564923e-07
Iter: 1184 loss: 6.33806167e-07
Iter: 1185 loss: 6.33518425e-07
Iter: 1186 loss: 6.33474201e-07
Iter: 1187 loss: 6.33428044e-07
Iter: 1188 loss: 6.33398713e-07
Iter: 1189 loss: 6.33360798e-07
Iter: 1190 loss: 6.33362049e-07
Iter: 1191 loss: 6.33305604e-07
Iter: 1192 loss: 6.33239e-07
Iter: 1193 loss: 6.34174e-07
Iter: 1194 loss: 6.33241768e-07
Iter: 1195 loss: 6.33184754e-07
Iter: 1196 loss: 6.33642685e-07
Iter: 1197 loss: 6.33177933e-07
Iter: 1198 loss: 6.33128479e-07
Iter: 1199 loss: 6.33172704e-07
Iter: 1200 loss: 6.33118304e-07
Iter: 1201 loss: 6.33033892e-07
Iter: 1202 loss: 6.333795e-07
Iter: 1203 loss: 6.33029288e-07
Iter: 1204 loss: 6.32985461e-07
Iter: 1205 loss: 6.3295e-07
Iter: 1206 loss: 6.32930323e-07
Iter: 1207 loss: 6.32894626e-07
Iter: 1208 loss: 6.33271725e-07
Iter: 1209 loss: 6.32890533e-07
Iter: 1210 loss: 6.32812487e-07
Iter: 1211 loss: 6.32709771e-07
Iter: 1212 loss: 6.32725801e-07
Iter: 1213 loss: 6.3265793e-07
Iter: 1214 loss: 6.33264619e-07
Iter: 1215 loss: 6.32651506e-07
Iter: 1216 loss: 6.32592e-07
Iter: 1217 loss: 6.32611034e-07
Iter: 1218 loss: 6.32583522e-07
Iter: 1219 loss: 6.32527303e-07
Iter: 1220 loss: 6.32547483e-07
Iter: 1221 loss: 6.32506556e-07
Iter: 1222 loss: 6.32899059e-07
Iter: 1223 loss: 6.32506158e-07
Iter: 1224 loss: 6.32505362e-07
Iter: 1225 loss: 6.32484443e-07
Iter: 1226 loss: 6.32447268e-07
Iter: 1227 loss: 6.32415549e-07
Iter: 1228 loss: 6.32355352e-07
Iter: 1229 loss: 6.32362458e-07
Iter: 1230 loss: 6.3226139e-07
Iter: 1231 loss: 6.32386786e-07
Iter: 1232 loss: 6.32236151e-07
Iter: 1233 loss: 6.32213357e-07
Iter: 1234 loss: 6.32194428e-07
Iter: 1235 loss: 6.32153842e-07
Iter: 1236 loss: 6.32097e-07
Iter: 1237 loss: 6.32085346e-07
Iter: 1238 loss: 6.32050501e-07
Iter: 1239 loss: 6.32423166e-07
Iter: 1240 loss: 6.32045726e-07
Iter: 1241 loss: 6.31977855e-07
Iter: 1242 loss: 6.31965122e-07
Iter: 1243 loss: 6.31951764e-07
Iter: 1244 loss: 6.31876617e-07
Iter: 1245 loss: 6.31951366e-07
Iter: 1246 loss: 6.3181983e-07
Iter: 1247 loss: 6.31784701e-07
Iter: 1248 loss: 6.31783792e-07
Iter: 1249 loss: 6.31732291e-07
Iter: 1250 loss: 6.31705632e-07
Iter: 1251 loss: 6.31696082e-07
Iter: 1252 loss: 6.31627245e-07
Iter: 1253 loss: 6.3197831e-07
Iter: 1254 loss: 6.31627699e-07
Iter: 1255 loss: 6.31582793e-07
Iter: 1256 loss: 6.3182523e-07
Iter: 1257 loss: 6.31580065e-07
Iter: 1258 loss: 6.31556702e-07
Iter: 1259 loss: 6.31497e-07
Iter: 1260 loss: 6.32771162e-07
Iter: 1261 loss: 6.3148326e-07
Iter: 1262 loss: 6.3142511e-07
Iter: 1263 loss: 6.31683406e-07
Iter: 1264 loss: 6.31423745e-07
Iter: 1265 loss: 6.31362923e-07
Iter: 1266 loss: 6.31826424e-07
Iter: 1267 loss: 6.31360251e-07
Iter: 1268 loss: 6.31308069e-07
Iter: 1269 loss: 6.31223145e-07
Iter: 1270 loss: 6.31224907e-07
Iter: 1271 loss: 6.31137482e-07
Iter: 1272 loss: 6.31433693e-07
Iter: 1273 loss: 6.31116563e-07
Iter: 1274 loss: 6.31044941e-07
Iter: 1275 loss: 6.31680962e-07
Iter: 1276 loss: 6.31043349e-07
Iter: 1277 loss: 6.31007595e-07
Iter: 1278 loss: 6.30905106e-07
Iter: 1279 loss: 6.32115e-07
Iter: 1280 loss: 6.30882e-07
Iter: 1281 loss: 6.30781e-07
Iter: 1282 loss: 6.31641569e-07
Iter: 1283 loss: 6.30785337e-07
Iter: 1284 loss: 6.30763907e-07
Iter: 1285 loss: 6.30775446e-07
Iter: 1286 loss: 6.30725822e-07
Iter: 1287 loss: 6.30654824e-07
Iter: 1288 loss: 6.31564319e-07
Iter: 1289 loss: 6.30665113e-07
Iter: 1290 loss: 6.30646127e-07
Iter: 1291 loss: 6.30637146e-07
Iter: 1292 loss: 6.30602869e-07
Iter: 1293 loss: 6.30562113e-07
Iter: 1294 loss: 6.31451883e-07
Iter: 1295 loss: 6.30582861e-07
Iter: 1296 loss: 6.30491968e-07
Iter: 1297 loss: 6.30400393e-07
Iter: 1298 loss: 6.30375837e-07
Iter: 1299 loss: 6.30349518e-07
Iter: 1300 loss: 6.30338832e-07
Iter: 1301 loss: 6.30287389e-07
Iter: 1302 loss: 6.30498789e-07
Iter: 1303 loss: 6.3026522e-07
Iter: 1304 loss: 6.30202237e-07
Iter: 1305 loss: 6.30142495e-07
Iter: 1306 loss: 6.3013033e-07
Iter: 1307 loss: 6.3011646e-07
Iter: 1308 loss: 6.30083036e-07
Iter: 1309 loss: 6.30062459e-07
Iter: 1310 loss: 6.30024601e-07
Iter: 1311 loss: 6.30015506e-07
Iter: 1312 loss: 6.29964347e-07
Iter: 1313 loss: 6.29901592e-07
Iter: 1314 loss: 6.31807097e-07
Iter: 1315 loss: 6.29882038e-07
Iter: 1316 loss: 6.29788474e-07
Iter: 1317 loss: 6.30556258e-07
Iter: 1318 loss: 6.29808e-07
Iter: 1319 loss: 6.2972822e-07
Iter: 1320 loss: 6.30230375e-07
Iter: 1321 loss: 6.29701276e-07
Iter: 1322 loss: 6.29657848e-07
Iter: 1323 loss: 6.29663475e-07
Iter: 1324 loss: 6.29636304e-07
Iter: 1325 loss: 6.29579802e-07
Iter: 1326 loss: 6.29590147e-07
Iter: 1327 loss: 6.29545752e-07
Iter: 1328 loss: 6.29471174e-07
Iter: 1329 loss: 6.29858107e-07
Iter: 1330 loss: 6.29411602e-07
Iter: 1331 loss: 6.29297631e-07
Iter: 1332 loss: 6.30424097e-07
Iter: 1333 loss: 6.29307e-07
Iter: 1334 loss: 6.29271767e-07
Iter: 1335 loss: 6.29253293e-07
Iter: 1336 loss: 6.2921464e-07
Iter: 1337 loss: 6.29103624e-07
Iter: 1338 loss: 6.30161e-07
Iter: 1339 loss: 6.2912045e-07
Iter: 1340 loss: 6.29049964e-07
Iter: 1341 loss: 6.29029046e-07
Iter: 1342 loss: 6.28969246e-07
Iter: 1343 loss: 6.29007559e-07
Iter: 1344 loss: 6.28925875e-07
Iter: 1345 loss: 6.2886636e-07
Iter: 1346 loss: 6.28811335e-07
Iter: 1347 loss: 6.28787234e-07
Iter: 1348 loss: 6.28712769e-07
Iter: 1349 loss: 6.29098281e-07
Iter: 1350 loss: 6.28703333e-07
Iter: 1351 loss: 6.28628527e-07
Iter: 1352 loss: 6.2872374e-07
Iter: 1353 loss: 6.28644216e-07
Iter: 1354 loss: 6.28537862e-07
Iter: 1355 loss: 6.28987607e-07
Iter: 1356 loss: 6.28542466e-07
Iter: 1357 loss: 6.28514499e-07
Iter: 1358 loss: 6.2847414e-07
Iter: 1359 loss: 6.28467433e-07
Iter: 1360 loss: 6.28403143e-07
Iter: 1361 loss: 6.28958901e-07
Iter: 1362 loss: 6.28403029e-07
Iter: 1363 loss: 6.28369435e-07
Iter: 1364 loss: 6.28267401e-07
Iter: 1365 loss: 6.29982537e-07
Iter: 1366 loss: 6.28270357e-07
Iter: 1367 loss: 6.28192765e-07
Iter: 1368 loss: 6.28205385e-07
Iter: 1369 loss: 6.28174121e-07
Iter: 1370 loss: 6.2809454e-07
Iter: 1371 loss: 6.28091e-07
Iter: 1372 loss: 6.28042358e-07
Iter: 1373 loss: 6.28449754e-07
Iter: 1374 loss: 6.28025532e-07
Iter: 1375 loss: 6.27982331e-07
Iter: 1376 loss: 6.27992904e-07
Iter: 1377 loss: 6.2795084e-07
Iter: 1378 loss: 6.27933218e-07
Iter: 1379 loss: 6.27911049e-07
Iter: 1380 loss: 6.27865347e-07
Iter: 1381 loss: 6.27887971e-07
Iter: 1382 loss: 6.27838233e-07
Iter: 1383 loss: 6.27776387e-07
Iter: 1384 loss: 6.27856821e-07
Iter: 1385 loss: 6.27732106e-07
Iter: 1386 loss: 6.27684358e-07
Iter: 1387 loss: 6.28426221e-07
Iter: 1388 loss: 6.27685495e-07
Iter: 1389 loss: 6.27601935e-07
Iter: 1390 loss: 6.27607619e-07
Iter: 1391 loss: 6.27550946e-07
Iter: 1392 loss: 6.27499958e-07
Iter: 1393 loss: 6.27504733e-07
Iter: 1394 loss: 6.2746e-07
Iter: 1395 loss: 6.27385134e-07
Iter: 1396 loss: 6.27388886e-07
Iter: 1397 loss: 6.27339659e-07
Iter: 1398 loss: 6.27295094e-07
Iter: 1399 loss: 6.27288046e-07
Iter: 1400 loss: 6.27249619e-07
Iter: 1401 loss: 6.27486202e-07
Iter: 1402 loss: 6.27229269e-07
Iter: 1403 loss: 6.27197096e-07
Iter: 1404 loss: 6.2732073e-07
Iter: 1405 loss: 6.27210284e-07
Iter: 1406 loss: 6.27163672e-07
Iter: 1407 loss: 6.27140935e-07
Iter: 1408 loss: 6.27143322e-07
Iter: 1409 loss: 6.27100917e-07
Iter: 1410 loss: 6.27095346e-07
Iter: 1411 loss: 6.27062263e-07
Iter: 1412 loss: 6.27001157e-07
Iter: 1413 loss: 6.27000304e-07
Iter: 1414 loss: 6.26924e-07
Iter: 1415 loss: 6.26953806e-07
Iter: 1416 loss: 6.2687036e-07
Iter: 1417 loss: 6.26756162e-07
Iter: 1418 loss: 6.26848532e-07
Iter: 1419 loss: 6.26718304e-07
Iter: 1420 loss: 6.26647079e-07
Iter: 1421 loss: 6.27753934e-07
Iter: 1422 loss: 6.26651e-07
Iter: 1423 loss: 6.26626388e-07
Iter: 1424 loss: 6.26686813e-07
Iter: 1425 loss: 6.26595806e-07
Iter: 1426 loss: 6.26555902e-07
Iter: 1427 loss: 6.26759117e-07
Iter: 1428 loss: 6.26537826e-07
Iter: 1429 loss: 6.26512e-07
Iter: 1430 loss: 6.26412884e-07
Iter: 1431 loss: 6.26417034e-07
Iter: 1432 loss: 6.26350129e-07
Iter: 1433 loss: 6.26587507e-07
Iter: 1434 loss: 6.26317672e-07
Iter: 1435 loss: 6.26195401e-07
Iter: 1436 loss: 6.26673568e-07
Iter: 1437 loss: 6.26179258e-07
Iter: 1438 loss: 6.26133897e-07
Iter: 1439 loss: 6.26086262e-07
Iter: 1440 loss: 6.26097574e-07
Iter: 1441 loss: 6.26017481e-07
Iter: 1442 loss: 6.26042493e-07
Iter: 1443 loss: 6.25975645e-07
Iter: 1444 loss: 6.25900725e-07
Iter: 1445 loss: 6.25901464e-07
Iter: 1446 loss: 6.25834275e-07
Iter: 1447 loss: 6.26038116e-07
Iter: 1448 loss: 6.25799771e-07
Iter: 1449 loss: 6.25773794e-07
Iter: 1450 loss: 6.26318183e-07
Iter: 1451 loss: 6.25755831e-07
Iter: 1452 loss: 6.25712e-07
Iter: 1453 loss: 6.25699045e-07
Iter: 1454 loss: 6.25651751e-07
Iter: 1455 loss: 6.25616735e-07
Iter: 1456 loss: 6.25574671e-07
Iter: 1457 loss: 6.2556245e-07
Iter: 1458 loss: 6.25472921e-07
Iter: 1459 loss: 6.25616906e-07
Iter: 1460 loss: 6.25436428e-07
Iter: 1461 loss: 6.25440805e-07
Iter: 1462 loss: 6.25385724e-07
Iter: 1463 loss: 6.25362077e-07
Iter: 1464 loss: 6.25310804e-07
Iter: 1465 loss: 6.25585869e-07
Iter: 1466 loss: 6.25278687e-07
Iter: 1467 loss: 6.25165399e-07
Iter: 1468 loss: 6.25486621e-07
Iter: 1469 loss: 6.25143457e-07
Iter: 1470 loss: 6.25096277e-07
Iter: 1471 loss: 6.25052394e-07
Iter: 1472 loss: 6.25012262e-07
Iter: 1473 loss: 6.24915174e-07
Iter: 1474 loss: 6.25341443e-07
Iter: 1475 loss: 6.24868107e-07
Iter: 1476 loss: 6.2478e-07
Iter: 1477 loss: 6.2477e-07
Iter: 1478 loss: 6.24688425e-07
Iter: 1479 loss: 6.24645168e-07
Iter: 1480 loss: 6.24632605e-07
Iter: 1481 loss: 6.24565644e-07
Iter: 1482 loss: 6.24452582e-07
Iter: 1483 loss: 6.24442293e-07
Iter: 1484 loss: 6.24480151e-07
Iter: 1485 loss: 6.24416828e-07
Iter: 1486 loss: 6.24395796e-07
Iter: 1487 loss: 6.24419727e-07
Iter: 1488 loss: 6.24345944e-07
Iter: 1489 loss: 6.24326219e-07
Iter: 1490 loss: 6.24256131e-07
Iter: 1491 loss: 6.25171197e-07
Iter: 1492 loss: 6.2426e-07
Iter: 1493 loss: 6.2418593e-07
Iter: 1494 loss: 6.24727591e-07
Iter: 1495 loss: 6.24188829e-07
Iter: 1496 loss: 6.24093332e-07
Iter: 1497 loss: 6.24215318e-07
Iter: 1498 loss: 6.24024437e-07
Iter: 1499 loss: 6.23938945e-07
Iter: 1500 loss: 6.23878407e-07
Iter: 1501 loss: 6.23854078e-07
Iter: 1502 loss: 6.23805818e-07
Iter: 1503 loss: 6.23777225e-07
Iter: 1504 loss: 6.23738174e-07
Iter: 1505 loss: 6.24057861e-07
Iter: 1506 loss: 6.23728113e-07
Iter: 1507 loss: 6.23697247e-07
Iter: 1508 loss: 6.23618689e-07
Iter: 1509 loss: 6.2472111e-07
Iter: 1510 loss: 6.23624942e-07
Iter: 1511 loss: 6.23609139e-07
Iter: 1512 loss: 6.23571452e-07
Iter: 1513 loss: 6.23552e-07
Iter: 1514 loss: 6.23476581e-07
Iter: 1515 loss: 6.23995618e-07
Iter: 1516 loss: 6.23461e-07
Iter: 1517 loss: 6.23375399e-07
Iter: 1518 loss: 6.23648134e-07
Iter: 1519 loss: 6.23352662e-07
Iter: 1520 loss: 6.2326535e-07
Iter: 1521 loss: 6.23289225e-07
Iter: 1522 loss: 6.23228232e-07
Iter: 1523 loss: 6.23150697e-07
Iter: 1524 loss: 6.23147912e-07
Iter: 1525 loss: 6.23066228e-07
Iter: 1526 loss: 6.23757614e-07
Iter: 1527 loss: 6.23053e-07
Iter: 1528 loss: 6.22994776e-07
Iter: 1529 loss: 6.23054348e-07
Iter: 1530 loss: 6.22946231e-07
Iter: 1531 loss: 6.22910363e-07
Iter: 1532 loss: 6.23001e-07
Iter: 1533 loss: 6.2286e-07
Iter: 1534 loss: 6.22827201e-07
Iter: 1535 loss: 6.22798837e-07
Iter: 1536 loss: 6.22762286e-07
Iter: 1537 loss: 6.22686457e-07
Iter: 1538 loss: 6.22703283e-07
Iter: 1539 loss: 6.22660309e-07
Iter: 1540 loss: 6.22610855e-07
Iter: 1541 loss: 6.22597e-07
Iter: 1542 loss: 6.22529e-07
Iter: 1543 loss: 6.22979371e-07
Iter: 1544 loss: 6.22519678e-07
Iter: 1545 loss: 6.22420373e-07
Iter: 1546 loss: 6.22566233e-07
Iter: 1547 loss: 6.22388654e-07
Iter: 1548 loss: 6.2235074e-07
Iter: 1549 loss: 6.22345965e-07
Iter: 1550 loss: 6.22319533e-07
Iter: 1551 loss: 6.22272239e-07
Iter: 1552 loss: 6.22792413e-07
Iter: 1553 loss: 6.22259108e-07
Iter: 1554 loss: 6.22205334e-07
Iter: 1555 loss: 6.22322261e-07
Iter: 1556 loss: 6.22185553e-07
Iter: 1557 loss: 6.22165e-07
Iter: 1558 loss: 6.22221705e-07
Iter: 1559 loss: 6.22142295e-07
Iter: 1560 loss: 6.22095513e-07
Iter: 1561 loss: 6.22114214e-07
Iter: 1562 loss: 6.22070274e-07
Iter: 1563 loss: 6.22016785e-07
Iter: 1564 loss: 6.219895e-07
Iter: 1565 loss: 6.21965341e-07
Iter: 1566 loss: 6.21917e-07
Iter: 1567 loss: 6.22468747e-07
Iter: 1568 loss: 6.21893719e-07
Iter: 1569 loss: 6.21848926e-07
Iter: 1570 loss: 6.22315383e-07
Iter: 1571 loss: 6.21819595e-07
Iter: 1572 loss: 6.21747063e-07
Iter: 1573 loss: 6.2171938e-07
Iter: 1574 loss: 6.21702895e-07
Iter: 1575 loss: 6.2163889e-07
Iter: 1576 loss: 6.21951244e-07
Iter: 1577 loss: 6.21620075e-07
Iter: 1578 loss: 6.21582444e-07
Iter: 1579 loss: 6.22119614e-07
Iter: 1580 loss: 6.21584093e-07
Iter: 1581 loss: 6.21560218e-07
Iter: 1582 loss: 6.2147592e-07
Iter: 1583 loss: 6.22232278e-07
Iter: 1584 loss: 6.21488311e-07
Iter: 1585 loss: 6.21401398e-07
Iter: 1586 loss: 6.22175548e-07
Iter: 1587 loss: 6.21381048e-07
Iter: 1588 loss: 6.21342906e-07
Iter: 1589 loss: 6.21528329e-07
Iter: 1590 loss: 6.21327331e-07
Iter: 1591 loss: 6.2129277e-07
Iter: 1592 loss: 6.21268669e-07
Iter: 1593 loss: 6.21227855e-07
Iter: 1594 loss: 6.21201821e-07
Iter: 1595 loss: 6.21185052e-07
Iter: 1596 loss: 6.21172603e-07
Iter: 1597 loss: 6.21104846e-07
Iter: 1598 loss: 6.22042933e-07
Iter: 1599 loss: 6.21095637e-07
Iter: 1600 loss: 6.20998208e-07
Iter: 1601 loss: 6.21372124e-07
Iter: 1602 loss: 6.20972628e-07
Iter: 1603 loss: 6.20944377e-07
Iter: 1604 loss: 6.21292315e-07
Iter: 1605 loss: 6.2095944e-07
Iter: 1606 loss: 6.20903052e-07
Iter: 1607 loss: 6.2086e-07
Iter: 1608 loss: 6.20835863e-07
Iter: 1609 loss: 6.20762819e-07
Iter: 1610 loss: 6.20871219e-07
Iter: 1611 loss: 6.20717287e-07
Iter: 1612 loss: 6.2073218e-07
Iter: 1613 loss: 6.20699325e-07
Iter: 1614 loss: 6.20674541e-07
Iter: 1615 loss: 6.20597575e-07
Iter: 1616 loss: 6.2105596e-07
Iter: 1617 loss: 6.20560968e-07
Iter: 1618 loss: 6.20491676e-07
Iter: 1619 loss: 6.20497815e-07
Iter: 1620 loss: 6.2045757e-07
Iter: 1621 loss: 6.20447395e-07
Iter: 1622 loss: 6.2043938e-07
Iter: 1623 loss: 6.20393962e-07
Iter: 1624 loss: 6.20896e-07
Iter: 1625 loss: 6.20382139e-07
Iter: 1626 loss: 6.20319e-07
Iter: 1627 loss: 6.20324045e-07
Iter: 1628 loss: 6.20287892e-07
Iter: 1629 loss: 6.20256742e-07
Iter: 1630 loss: 6.20270555e-07
Iter: 1631 loss: 6.20180856e-07
Iter: 1632 loss: 6.20103322e-07
Iter: 1633 loss: 6.20108096e-07
Iter: 1634 loss: 6.2000754e-07
Iter: 1635 loss: 6.20000662e-07
Iter: 1636 loss: 6.19922844e-07
Iter: 1637 loss: 6.20256174e-07
Iter: 1638 loss: 6.19908519e-07
Iter: 1639 loss: 6.19873276e-07
Iter: 1640 loss: 6.19777666e-07
Iter: 1641 loss: 6.19781133e-07
Iter: 1642 loss: 6.19748789e-07
Iter: 1643 loss: 6.19728837e-07
Iter: 1644 loss: 6.19697062e-07
Iter: 1645 loss: 6.19723608e-07
Iter: 1646 loss: 6.19673585e-07
Iter: 1647 loss: 6.19627087e-07
Iter: 1648 loss: 6.19567e-07
Iter: 1649 loss: 6.2056813e-07
Iter: 1650 loss: 6.1958292e-07
Iter: 1651 loss: 6.19557795e-07
Iter: 1652 loss: 6.1952403e-07
Iter: 1653 loss: 6.19489924e-07
Iter: 1654 loss: 6.19437344e-07
Iter: 1655 loss: 6.19419211e-07
Iter: 1656 loss: 6.19353045e-07
Iter: 1657 loss: 6.19318257e-07
Iter: 1658 loss: 6.1927517e-07
Iter: 1659 loss: 6.19185585e-07
Iter: 1660 loss: 6.19170635e-07
Iter: 1661 loss: 6.19150796e-07
Iter: 1662 loss: 6.19070136e-07
Iter: 1663 loss: 6.19080083e-07
Iter: 1664 loss: 6.19009256e-07
Iter: 1665 loss: 6.19108164e-07
Iter: 1666 loss: 6.18959689e-07
Iter: 1667 loss: 6.18930926e-07
Iter: 1668 loss: 6.18907222e-07
Iter: 1669 loss: 6.18872491e-07
Iter: 1670 loss: 6.18808258e-07
Iter: 1671 loss: 6.19838602e-07
Iter: 1672 loss: 6.18830313e-07
Iter: 1673 loss: 6.18753688e-07
Iter: 1674 loss: 6.1881849e-07
Iter: 1675 loss: 6.18724698e-07
Iter: 1676 loss: 6.18691956e-07
Iter: 1677 loss: 6.18659e-07
Iter: 1678 loss: 6.1863409e-07
Iter: 1679 loss: 6.1858043e-07
Iter: 1680 loss: 6.19063712e-07
Iter: 1681 loss: 6.18580202e-07
Iter: 1682 loss: 6.18491526e-07
Iter: 1683 loss: 6.19316779e-07
Iter: 1684 loss: 6.18495164e-07
Iter: 1685 loss: 6.18414e-07
Iter: 1686 loss: 6.18978447e-07
Iter: 1687 loss: 6.18410581e-07
Iter: 1688 loss: 6.18388071e-07
Iter: 1689 loss: 6.18332e-07
Iter: 1690 loss: 6.18882495e-07
Iter: 1691 loss: 6.18299964e-07
Iter: 1692 loss: 6.18285753e-07
Iter: 1693 loss: 6.18255797e-07
Iter: 1694 loss: 6.1823323e-07
Iter: 1695 loss: 6.18183e-07
Iter: 1696 loss: 6.18159333e-07
Iter: 1697 loss: 6.1811204e-07
Iter: 1698 loss: 6.1799426e-07
Iter: 1699 loss: 6.1800489e-07
Iter: 1700 loss: 6.17929118e-07
Iter: 1701 loss: 6.17921614e-07
Iter: 1702 loss: 6.17863066e-07
Iter: 1703 loss: 6.18154047e-07
Iter: 1704 loss: 6.17846467e-07
Iter: 1705 loss: 6.17787293e-07
Iter: 1706 loss: 6.17665819e-07
Iter: 1707 loss: 6.20181595e-07
Iter: 1708 loss: 6.1765769e-07
Iter: 1709 loss: 6.17585e-07
Iter: 1710 loss: 6.18480271e-07
Iter: 1711 loss: 6.17577143e-07
Iter: 1712 loss: 6.17549233e-07
Iter: 1713 loss: 6.17540422e-07
Iter: 1714 loss: 6.17495175e-07
Iter: 1715 loss: 6.17417186e-07
Iter: 1716 loss: 6.17901776e-07
Iter: 1717 loss: 6.17391834e-07
Iter: 1718 loss: 6.17339879e-07
Iter: 1719 loss: 6.17331466e-07
Iter: 1720 loss: 6.17319529e-07
Iter: 1721 loss: 6.17515298e-07
Iter: 1722 loss: 6.17288492e-07
Iter: 1723 loss: 6.1724e-07
Iter: 1724 loss: 6.17135925e-07
Iter: 1725 loss: 6.17680541e-07
Iter: 1726 loss: 6.17123135e-07
Iter: 1727 loss: 6.17203568e-07
Iter: 1728 loss: 6.17064757e-07
Iter: 1729 loss: 6.17047419e-07
Iter: 1730 loss: 6.16967498e-07
Iter: 1731 loss: 6.17593628e-07
Iter: 1732 loss: 6.16955901e-07
Iter: 1733 loss: 6.16839543e-07
Iter: 1734 loss: 6.16905595e-07
Iter: 1735 loss: 6.16787872e-07
Iter: 1736 loss: 6.16715738e-07
Iter: 1737 loss: 6.16718694e-07
Iter: 1738 loss: 6.16631382e-07
Iter: 1739 loss: 6.16692319e-07
Iter: 1740 loss: 6.16570901e-07
Iter: 1741 loss: 6.16484897e-07
Iter: 1742 loss: 6.16527927e-07
Iter: 1743 loss: 6.16443572e-07
Iter: 1744 loss: 6.16397756e-07
Iter: 1745 loss: 6.16391105e-07
Iter: 1746 loss: 6.16352168e-07
Iter: 1747 loss: 6.1630783e-07
Iter: 1748 loss: 6.16285206e-07
Iter: 1749 loss: 6.1623922e-07
Iter: 1750 loss: 6.16256102e-07
Iter: 1751 loss: 6.16206762e-07
Iter: 1752 loss: 6.16182547e-07
Iter: 1753 loss: 6.16169586e-07
Iter: 1754 loss: 6.16154352e-07
Iter: 1755 loss: 6.16069e-07
Iter: 1756 loss: 6.16722787e-07
Iter: 1757 loss: 6.16025773e-07
Iter: 1758 loss: 6.15983367e-07
Iter: 1759 loss: 6.15980071e-07
Iter: 1760 loss: 6.15928911e-07
Iter: 1761 loss: 6.1600872e-07
Iter: 1762 loss: 6.15884971e-07
Iter: 1763 loss: 6.15830459e-07
Iter: 1764 loss: 6.1573013e-07
Iter: 1765 loss: 6.17964247e-07
Iter: 1766 loss: 6.15727174e-07
Iter: 1767 loss: 6.15627641e-07
Iter: 1768 loss: 6.15630654e-07
Iter: 1769 loss: 6.1556716e-07
Iter: 1770 loss: 6.15550562e-07
Iter: 1771 loss: 6.1552106e-07
Iter: 1772 loss: 6.1544813e-07
Iter: 1773 loss: 6.15905662e-07
Iter: 1774 loss: 6.15437443e-07
Iter: 1775 loss: 6.15321653e-07
Iter: 1776 loss: 6.15750196e-07
Iter: 1777 loss: 6.15305964e-07
Iter: 1778 loss: 6.1528408e-07
Iter: 1779 loss: 6.15263332e-07
Iter: 1780 loss: 6.15231386e-07
Iter: 1781 loss: 6.15109911e-07
Iter: 1782 loss: 6.15485419e-07
Iter: 1783 loss: 6.15042723e-07
Iter: 1784 loss: 6.14935516e-07
Iter: 1785 loss: 6.16343414e-07
Iter: 1786 loss: 6.14951944e-07
Iter: 1787 loss: 6.1485747e-07
Iter: 1788 loss: 6.15473709e-07
Iter: 1789 loss: 6.14828878e-07
Iter: 1790 loss: 6.14780333e-07
Iter: 1791 loss: 6.1461003e-07
Iter: 1792 loss: 6.17070896e-07
Iter: 1793 loss: 6.14611963e-07
Iter: 1794 loss: 6.14528176e-07
Iter: 1795 loss: 6.14500436e-07
Iter: 1796 loss: 6.14438704e-07
Iter: 1797 loss: 6.14274597e-07
Iter: 1798 loss: 6.15691818e-07
Iter: 1799 loss: 6.14220937e-07
Iter: 1800 loss: 6.13997088e-07
Iter: 1801 loss: 6.15716317e-07
Iter: 1802 loss: 6.13968041e-07
Iter: 1803 loss: 6.13923191e-07
Iter: 1804 loss: 6.13926488e-07
Iter: 1805 loss: 6.13867371e-07
Iter: 1806 loss: 6.13807231e-07
Iter: 1807 loss: 6.13797681e-07
Iter: 1808 loss: 6.13712075e-07
Iter: 1809 loss: 6.13875727e-07
Iter: 1810 loss: 6.13633915e-07
Iter: 1811 loss: 6.13595034e-07
Iter: 1812 loss: 6.13641191e-07
Iter: 1813 loss: 6.13536372e-07
Iter: 1814 loss: 6.13513862e-07
Iter: 1815 loss: 6.13474242e-07
Iter: 1816 loss: 6.13468956e-07
Iter: 1817 loss: 6.13352825e-07
Iter: 1818 loss: 6.15117756e-07
Iter: 1819 loss: 6.13343047e-07
Iter: 1820 loss: 6.13276598e-07
Iter: 1821 loss: 6.13423936e-07
Iter: 1822 loss: 6.13267275e-07
Iter: 1823 loss: 6.13134e-07
Iter: 1824 loss: 6.13850489e-07
Iter: 1825 loss: 6.13134262e-07
Iter: 1826 loss: 6.13106181e-07
Iter: 1827 loss: 6.13050645e-07
Iter: 1828 loss: 6.13042801e-07
Iter: 1829 loss: 6.12959923e-07
Iter: 1830 loss: 6.12917859e-07
Iter: 1831 loss: 6.1288182e-07
Iter: 1832 loss: 6.12788085e-07
Iter: 1833 loss: 6.1380905e-07
Iter: 1834 loss: 6.12819122e-07
Iter: 1835 loss: 6.12743406e-07
Iter: 1836 loss: 6.12751194e-07
Iter: 1837 loss: 6.12687472e-07
Iter: 1838 loss: 6.12599081e-07
Iter: 1839 loss: 6.12586518e-07
Iter: 1840 loss: 6.1253013e-07
Iter: 1841 loss: 6.1260323e-07
Iter: 1842 loss: 6.12473059e-07
Iter: 1843 loss: 6.12407575e-07
Iter: 1844 loss: 6.12426106e-07
Iter: 1845 loss: 6.12379722e-07
Iter: 1846 loss: 6.12342546e-07
Iter: 1847 loss: 6.12343797e-07
Iter: 1848 loss: 6.12301278e-07
Iter: 1849 loss: 6.12385e-07
Iter: 1850 loss: 6.12270583e-07
Iter: 1851 loss: 6.12206236e-07
Iter: 1852 loss: 6.12641e-07
Iter: 1853 loss: 6.12205611e-07
Iter: 1854 loss: 6.12154906e-07
Iter: 1855 loss: 6.12089821e-07
Iter: 1856 loss: 6.12080271e-07
Iter: 1857 loss: 6.12064582e-07
Iter: 1858 loss: 6.1205094e-07
Iter: 1859 loss: 6.12028089e-07
Iter: 1860 loss: 6.11904909e-07
Iter: 1861 loss: 6.12429858e-07
Iter: 1862 loss: 6.11871201e-07
Iter: 1863 loss: 6.11743246e-07
Iter: 1864 loss: 6.12322424e-07
Iter: 1865 loss: 6.11729604e-07
Iter: 1866 loss: 6.11648943e-07
Iter: 1867 loss: 6.11924349e-07
Iter: 1868 loss: 6.11626206e-07
Iter: 1869 loss: 6.11541509e-07
Iter: 1870 loss: 6.11533437e-07
Iter: 1871 loss: 6.11518e-07
Iter: 1872 loss: 6.11454311e-07
Iter: 1873 loss: 6.12930194e-07
Iter: 1874 loss: 6.11447717e-07
Iter: 1875 loss: 6.11367113e-07
Iter: 1876 loss: 6.11410258e-07
Iter: 1877 loss: 6.11317091e-07
Iter: 1878 loss: 6.11262749e-07
Iter: 1879 loss: 6.11248538e-07
Iter: 1880 loss: 6.11229893e-07
Iter: 1881 loss: 6.11185e-07
Iter: 1882 loss: 6.11177825e-07
Iter: 1883 loss: 6.11117628e-07
Iter: 1884 loss: 6.11229666e-07
Iter: 1885 loss: 6.11076587e-07
Iter: 1886 loss: 6.10991947e-07
Iter: 1887 loss: 6.11746543e-07
Iter: 1888 loss: 6.10974212e-07
Iter: 1889 loss: 6.109438e-07
Iter: 1890 loss: 6.10939594e-07
Iter: 1891 loss: 6.10914185e-07
Iter: 1892 loss: 6.1085791e-07
Iter: 1893 loss: 6.11366204e-07
Iter: 1894 loss: 6.10861093e-07
Iter: 1895 loss: 6.1082585e-07
Iter: 1896 loss: 6.10783786e-07
Iter: 1897 loss: 6.11751943e-07
Iter: 1898 loss: 6.10760708e-07
Iter: 1899 loss: 6.10664642e-07
Iter: 1900 loss: 6.10793677e-07
Iter: 1901 loss: 6.10659356e-07
Iter: 1902 loss: 6.10522477e-07
Iter: 1903 loss: 6.10999223e-07
Iter: 1904 loss: 6.10530151e-07
Iter: 1905 loss: 6.10479674e-07
Iter: 1906 loss: 6.10450343e-07
Iter: 1907 loss: 6.10427719e-07
Iter: 1908 loss: 6.1037457e-07
Iter: 1909 loss: 6.10757183e-07
Iter: 1910 loss: 6.10347797e-07
Iter: 1911 loss: 6.10291181e-07
Iter: 1912 loss: 6.10282086e-07
Iter: 1913 loss: 6.10242182e-07
Iter: 1914 loss: 6.10434938e-07
Iter: 1915 loss: 6.1025662e-07
Iter: 1916 loss: 6.10245e-07
Iter: 1917 loss: 6.10196537e-07
Iter: 1918 loss: 6.10198299e-07
Iter: 1919 loss: 6.10154359e-07
Iter: 1920 loss: 6.10373149e-07
Iter: 1921 loss: 6.10135601e-07
Iter: 1922 loss: 6.10077791e-07
Iter: 1923 loss: 6.10147936e-07
Iter: 1924 loss: 6.10087e-07
Iter: 1925 loss: 6.10042548e-07
Iter: 1926 loss: 6.10167433e-07
Iter: 1927 loss: 6.10030725e-07
Iter: 1928 loss: 6.09992412e-07
Iter: 1929 loss: 6.09938695e-07
Iter: 1930 loss: 6.0993716e-07
Iter: 1931 loss: 6.0987287e-07
Iter: 1932 loss: 6.10019924e-07
Iter: 1933 loss: 6.09855931e-07
Iter: 1934 loss: 6.09787321e-07
Iter: 1935 loss: 6.09686822e-07
Iter: 1936 loss: 6.09686481e-07
Iter: 1937 loss: 6.09735366e-07
Iter: 1938 loss: 6.09651238e-07
Iter: 1939 loss: 6.09592519e-07
Iter: 1940 loss: 6.09585868e-07
Iter: 1941 loss: 6.09556196e-07
Iter: 1942 loss: 6.09503218e-07
Iter: 1943 loss: 6.09397432e-07
Iter: 1944 loss: 6.11414e-07
Iter: 1945 loss: 6.09396807e-07
Iter: 1946 loss: 6.09374069e-07
Iter: 1947 loss: 6.09338031e-07
Iter: 1948 loss: 6.09314782e-07
Iter: 1949 loss: 6.09509186e-07
Iter: 1950 loss: 6.09281187e-07
Iter: 1951 loss: 6.09277549e-07
Iter: 1952 loss: 6.09257711e-07
Iter: 1953 loss: 6.0924441e-07
Iter: 1954 loss: 6.09258962e-07
Iter: 1955 loss: 6.09250662e-07
Iter: 1956 loss: 6.09241965e-07
Iter: 1957 loss: 6.09228323e-07
Iter: 1958 loss: 6.09236508e-07
Iter: 1959 loss: 6.09221217e-07
Iter: 1960 loss: 6.09253163e-07
Iter: 1961 loss: 6.09237077e-07
Iter: 1962 loss: 6.09231961e-07
Iter: 1963 loss: 6.0922514e-07
Iter: 1964 loss: 6.09231563e-07
Iter: 1965 loss: 6.09225708e-07
Iter: 1966 loss: 6.09231392e-07
Iter: 1967 loss: 6.09246342e-07
Iter: 1968 loss: 6.0923594e-07
Iter: 1969 loss: 6.09231961e-07
Iter: 1970 loss: 6.09237e-07
Iter: 1971 loss: 6.09237759e-07
Iter: 1972 loss: 6.09236622e-07
Iter: 1973 loss: 6.0924117e-07
Iter: 1974 loss: 6.09244751e-07
Iter: 1975 loss: 6.09245944e-07
Iter: 1976 loss: 6.09244921e-07
Iter: 1977 loss: 6.09244807e-07
Iter: 1978 loss: 6.09246172e-07
Iter: 1979 loss: 6.09244807e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.8
+ date
Mon Nov  9 04:13:09 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.8/500_500_500_500_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_1000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_1000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf44cdd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf44cf950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf44659d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf44651e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf45808c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf44488c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf4448d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf43d96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf435f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf43d9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf435f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf4341488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf435f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf4302e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf43162f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf42d5488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf42d5e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf4283b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf42498c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf41fb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf41fb510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf41ae6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf41c0bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf416d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf418d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf418d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf414f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9cf40f49d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ce0b22a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ce0b22e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ce0b00a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ce0aaa8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ce0aaab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ce0aaa0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ce0a6e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ce0ad4d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.59824935e-06
Iter: 2 loss: 2.77234858e-06
Iter: 3 loss: 1.86502916e-06
Iter: 4 loss: 1.61916944e-06
Iter: 5 loss: 1.50875621e-06
Iter: 6 loss: 1.38481687e-06
Iter: 7 loss: 1.22156564e-06
Iter: 8 loss: 3.77355582e-06
Iter: 9 loss: 1.22156143e-06
Iter: 10 loss: 1.09277812e-06
Iter: 11 loss: 1.04264836e-06
Iter: 12 loss: 9.73040642e-07
Iter: 13 loss: 8.97850384e-07
Iter: 14 loss: 1.82378153e-06
Iter: 15 loss: 8.9699779e-07
Iter: 16 loss: 8.65331856e-07
Iter: 17 loss: 8.65299398e-07
Iter: 18 loss: 8.5202322e-07
Iter: 19 loss: 8.33040644e-07
Iter: 20 loss: 8.32450041e-07
Iter: 21 loss: 8.15651958e-07
Iter: 22 loss: 8.15049e-07
Iter: 23 loss: 8.07037509e-07
Iter: 24 loss: 7.9323695e-07
Iter: 25 loss: 7.93153276e-07
Iter: 26 loss: 7.78018489e-07
Iter: 27 loss: 7.89453168e-07
Iter: 28 loss: 7.68756081e-07
Iter: 29 loss: 7.51530365e-07
Iter: 30 loss: 8.20497576e-07
Iter: 31 loss: 7.47508579e-07
Iter: 32 loss: 7.34849664e-07
Iter: 33 loss: 8.01737031e-07
Iter: 34 loss: 7.3289749e-07
Iter: 35 loss: 7.29032763e-07
Iter: 36 loss: 7.2755131e-07
Iter: 37 loss: 7.23080461e-07
Iter: 38 loss: 7.16098953e-07
Iter: 39 loss: 7.16065756e-07
Iter: 40 loss: 7.11755433e-07
Iter: 41 loss: 7.11741393e-07
Iter: 42 loss: 7.07161917e-07
Iter: 43 loss: 7.02224952e-07
Iter: 44 loss: 7.01415047e-07
Iter: 45 loss: 6.96062784e-07
Iter: 46 loss: 7.16005502e-07
Iter: 47 loss: 6.94732933e-07
Iter: 48 loss: 6.89059675e-07
Iter: 49 loss: 7.30314355e-07
Iter: 50 loss: 6.88633406e-07
Iter: 51 loss: 6.84109636e-07
Iter: 52 loss: 6.76197374e-07
Iter: 53 loss: 6.76230684e-07
Iter: 54 loss: 6.66452195e-07
Iter: 55 loss: 7.77199148e-07
Iter: 56 loss: 6.66320716e-07
Iter: 57 loss: 6.58441252e-07
Iter: 58 loss: 6.54026962e-07
Iter: 59 loss: 6.50688662e-07
Iter: 60 loss: 6.43344151e-07
Iter: 61 loss: 6.5236685e-07
Iter: 62 loss: 6.39489713e-07
Iter: 63 loss: 6.31068474e-07
Iter: 64 loss: 6.48411e-07
Iter: 65 loss: 6.27656789e-07
Iter: 66 loss: 6.23018934e-07
Iter: 67 loss: 6.54979601e-07
Iter: 68 loss: 6.22577488e-07
Iter: 69 loss: 6.20435742e-07
Iter: 70 loss: 6.20347464e-07
Iter: 71 loss: 6.18085494e-07
Iter: 72 loss: 6.17610908e-07
Iter: 73 loss: 6.16136504e-07
Iter: 74 loss: 6.13826444e-07
Iter: 75 loss: 6.18264494e-07
Iter: 76 loss: 6.1287642e-07
Iter: 77 loss: 6.10203585e-07
Iter: 78 loss: 6.32447893e-07
Iter: 79 loss: 6.09920846e-07
Iter: 80 loss: 6.07826962e-07
Iter: 81 loss: 6.02943146e-07
Iter: 82 loss: 6.64776223e-07
Iter: 83 loss: 6.02601403e-07
Iter: 84 loss: 6.01441457e-07
Iter: 85 loss: 6.00091767e-07
Iter: 86 loss: 5.97953147e-07
Iter: 87 loss: 5.93410959e-07
Iter: 88 loss: 6.73856562e-07
Iter: 89 loss: 5.9335116e-07
Iter: 90 loss: 5.9051473e-07
Iter: 91 loss: 5.90488639e-07
Iter: 92 loss: 5.88067167e-07
Iter: 93 loss: 5.89623539e-07
Iter: 94 loss: 5.86426609e-07
Iter: 95 loss: 5.84182089e-07
Iter: 96 loss: 5.82132827e-07
Iter: 97 loss: 5.81528298e-07
Iter: 98 loss: 5.77900323e-07
Iter: 99 loss: 5.87570241e-07
Iter: 100 loss: 5.7662254e-07
Iter: 101 loss: 5.73085913e-07
Iter: 102 loss: 5.89798162e-07
Iter: 103 loss: 5.72396516e-07
Iter: 104 loss: 5.7072458e-07
Iter: 105 loss: 5.7057656e-07
Iter: 106 loss: 5.68984092e-07
Iter: 107 loss: 5.66327287e-07
Iter: 108 loss: 5.66256347e-07
Iter: 109 loss: 5.64949971e-07
Iter: 110 loss: 5.64848278e-07
Iter: 111 loss: 5.63571234e-07
Iter: 112 loss: 5.62298226e-07
Iter: 113 loss: 5.62053401e-07
Iter: 114 loss: 5.60473381e-07
Iter: 115 loss: 5.62839148e-07
Iter: 116 loss: 5.59652904e-07
Iter: 117 loss: 5.58867725e-07
Iter: 118 loss: 5.58716181e-07
Iter: 119 loss: 5.57948852e-07
Iter: 120 loss: 5.56257476e-07
Iter: 121 loss: 5.79030598e-07
Iter: 122 loss: 5.56145551e-07
Iter: 123 loss: 5.54600604e-07
Iter: 124 loss: 5.71568421e-07
Iter: 125 loss: 5.54606e-07
Iter: 126 loss: 5.53050086e-07
Iter: 127 loss: 5.56226041e-07
Iter: 128 loss: 5.52468293e-07
Iter: 129 loss: 5.51474841e-07
Iter: 130 loss: 5.49895219e-07
Iter: 131 loss: 5.49870492e-07
Iter: 132 loss: 5.47977379e-07
Iter: 133 loss: 5.60442231e-07
Iter: 134 loss: 5.47788886e-07
Iter: 135 loss: 5.46469948e-07
Iter: 136 loss: 5.49798642e-07
Iter: 137 loss: 5.46010313e-07
Iter: 138 loss: 5.45029252e-07
Iter: 139 loss: 5.59414389e-07
Iter: 140 loss: 5.44953195e-07
Iter: 141 loss: 5.43792055e-07
Iter: 142 loss: 5.43719523e-07
Iter: 143 loss: 5.42788e-07
Iter: 144 loss: 5.41636041e-07
Iter: 145 loss: 5.44921591e-07
Iter: 146 loss: 5.41143891e-07
Iter: 147 loss: 5.3963231e-07
Iter: 148 loss: 5.46929755e-07
Iter: 149 loss: 5.39429266e-07
Iter: 150 loss: 5.38280744e-07
Iter: 151 loss: 5.3606044e-07
Iter: 152 loss: 5.85540306e-07
Iter: 153 loss: 5.36060497e-07
Iter: 154 loss: 5.35508832e-07
Iter: 155 loss: 5.34954324e-07
Iter: 156 loss: 5.34077515e-07
Iter: 157 loss: 5.32657793e-07
Iter: 158 loss: 5.32623346e-07
Iter: 159 loss: 5.31370915e-07
Iter: 160 loss: 5.39966209e-07
Iter: 161 loss: 5.31211356e-07
Iter: 162 loss: 5.29921635e-07
Iter: 163 loss: 5.33919604e-07
Iter: 164 loss: 5.29496731e-07
Iter: 165 loss: 5.28797386e-07
Iter: 166 loss: 5.28224462e-07
Iter: 167 loss: 5.27929842e-07
Iter: 168 loss: 5.269697e-07
Iter: 169 loss: 5.26048211e-07
Iter: 170 loss: 5.25789858e-07
Iter: 171 loss: 5.2429823e-07
Iter: 172 loss: 5.31952935e-07
Iter: 173 loss: 5.24010431e-07
Iter: 174 loss: 5.22621292e-07
Iter: 175 loss: 5.25799521e-07
Iter: 176 loss: 5.22056894e-07
Iter: 177 loss: 5.20747903e-07
Iter: 178 loss: 5.29567046e-07
Iter: 179 loss: 5.20498759e-07
Iter: 180 loss: 5.19363482e-07
Iter: 181 loss: 5.32084186e-07
Iter: 182 loss: 5.19282e-07
Iter: 183 loss: 5.18684431e-07
Iter: 184 loss: 5.18233833e-07
Iter: 185 loss: 5.18026354e-07
Iter: 186 loss: 5.17068372e-07
Iter: 187 loss: 5.26926215e-07
Iter: 188 loss: 5.1699692e-07
Iter: 189 loss: 5.16339696e-07
Iter: 190 loss: 5.15474198e-07
Iter: 191 loss: 5.15381942e-07
Iter: 192 loss: 5.14654516e-07
Iter: 193 loss: 5.14698741e-07
Iter: 194 loss: 5.13797488e-07
Iter: 195 loss: 5.12764e-07
Iter: 196 loss: 5.12666475e-07
Iter: 197 loss: 5.11684107e-07
Iter: 198 loss: 5.17167166e-07
Iter: 199 loss: 5.11514372e-07
Iter: 200 loss: 5.10383245e-07
Iter: 201 loss: 5.14003318e-07
Iter: 202 loss: 5.10019049e-07
Iter: 203 loss: 5.09181461e-07
Iter: 204 loss: 5.08727226e-07
Iter: 205 loss: 5.0828794e-07
Iter: 206 loss: 5.07243271e-07
Iter: 207 loss: 5.11145117e-07
Iter: 208 loss: 5.07010895e-07
Iter: 209 loss: 5.06190418e-07
Iter: 210 loss: 5.09900303e-07
Iter: 211 loss: 5.06013e-07
Iter: 212 loss: 5.05331911e-07
Iter: 213 loss: 5.13616499e-07
Iter: 214 loss: 5.05345952e-07
Iter: 215 loss: 5.04797413e-07
Iter: 216 loss: 5.05137223e-07
Iter: 217 loss: 5.04516152e-07
Iter: 218 loss: 5.03919807e-07
Iter: 219 loss: 5.06212416e-07
Iter: 220 loss: 5.03832894e-07
Iter: 221 loss: 5.03109447e-07
Iter: 222 loss: 5.02856722e-07
Iter: 223 loss: 5.02473483e-07
Iter: 224 loss: 5.01535112e-07
Iter: 225 loss: 5.02078706e-07
Iter: 226 loss: 5.00939677e-07
Iter: 227 loss: 5.00194574e-07
Iter: 228 loss: 5.00118517e-07
Iter: 229 loss: 4.99742612e-07
Iter: 230 loss: 4.98625e-07
Iter: 231 loss: 5.12591612e-07
Iter: 232 loss: 4.98504505e-07
Iter: 233 loss: 4.97906285e-07
Iter: 234 loss: 4.97865926e-07
Iter: 235 loss: 4.9725395e-07
Iter: 236 loss: 4.96883331e-07
Iter: 237 loss: 4.96654081e-07
Iter: 238 loss: 4.95971449e-07
Iter: 239 loss: 4.95482823e-07
Iter: 240 loss: 4.95248287e-07
Iter: 241 loss: 4.94229766e-07
Iter: 242 loss: 5.01408181e-07
Iter: 243 loss: 4.9409465e-07
Iter: 244 loss: 4.9327997e-07
Iter: 245 loss: 5.02592286e-07
Iter: 246 loss: 4.93278833e-07
Iter: 247 loss: 4.925501e-07
Iter: 248 loss: 4.93359266e-07
Iter: 249 loss: 4.92151059e-07
Iter: 250 loss: 4.91329047e-07
Iter: 251 loss: 4.92015602e-07
Iter: 252 loss: 4.90866285e-07
Iter: 253 loss: 4.89758918e-07
Iter: 254 loss: 4.98139229e-07
Iter: 255 loss: 4.89724641e-07
Iter: 256 loss: 4.89013246e-07
Iter: 257 loss: 4.88619548e-07
Iter: 258 loss: 4.88337264e-07
Iter: 259 loss: 4.87597333e-07
Iter: 260 loss: 4.95094753e-07
Iter: 261 loss: 4.875684e-07
Iter: 262 loss: 4.86785041e-07
Iter: 263 loss: 4.86858369e-07
Iter: 264 loss: 4.86199156e-07
Iter: 265 loss: 4.85646524e-07
Iter: 266 loss: 4.87977445e-07
Iter: 267 loss: 4.85551652e-07
Iter: 268 loss: 4.84893349e-07
Iter: 269 loss: 4.86217573e-07
Iter: 270 loss: 4.84671659e-07
Iter: 271 loss: 4.84044222e-07
Iter: 272 loss: 4.83304461e-07
Iter: 273 loss: 4.83216752e-07
Iter: 274 loss: 4.82285714e-07
Iter: 275 loss: 4.87010652e-07
Iter: 276 loss: 4.82113705e-07
Iter: 277 loss: 4.81362235e-07
Iter: 278 loss: 4.88012176e-07
Iter: 279 loss: 4.81381221e-07
Iter: 280 loss: 4.80619178e-07
Iter: 281 loss: 4.83692531e-07
Iter: 282 loss: 4.8050191e-07
Iter: 283 loss: 4.7997122e-07
Iter: 284 loss: 4.805147e-07
Iter: 285 loss: 4.79584855e-07
Iter: 286 loss: 4.79204573e-07
Iter: 287 loss: 4.85042733e-07
Iter: 288 loss: 4.79237826e-07
Iter: 289 loss: 4.78878746e-07
Iter: 290 loss: 4.78232209e-07
Iter: 291 loss: 4.78268873e-07
Iter: 292 loss: 4.77626656e-07
Iter: 293 loss: 4.82427e-07
Iter: 294 loss: 4.77570495e-07
Iter: 295 loss: 4.76981768e-07
Iter: 296 loss: 4.79290861e-07
Iter: 297 loss: 4.76837727e-07
Iter: 298 loss: 4.76398583e-07
Iter: 299 loss: 4.75598483e-07
Iter: 300 loss: 4.75568982e-07
Iter: 301 loss: 4.74771269e-07
Iter: 302 loss: 4.74757371e-07
Iter: 303 loss: 4.74220798e-07
Iter: 304 loss: 4.73098453e-07
Iter: 305 loss: 4.98107795e-07
Iter: 306 loss: 4.73076909e-07
Iter: 307 loss: 4.71896982e-07
Iter: 308 loss: 4.74127489e-07
Iter: 309 loss: 4.71437488e-07
Iter: 310 loss: 4.70527681e-07
Iter: 311 loss: 4.78738457e-07
Iter: 312 loss: 4.70482831e-07
Iter: 313 loss: 4.69776126e-07
Iter: 314 loss: 4.77619778e-07
Iter: 315 loss: 4.69783799e-07
Iter: 316 loss: 4.69319417e-07
Iter: 317 loss: 4.68816239e-07
Iter: 318 loss: 4.68706304e-07
Iter: 319 loss: 4.68197925e-07
Iter: 320 loss: 4.68211738e-07
Iter: 321 loss: 4.67805961e-07
Iter: 322 loss: 4.67567304e-07
Iter: 323 loss: 4.67427896e-07
Iter: 324 loss: 4.66864179e-07
Iter: 325 loss: 4.67194269e-07
Iter: 326 loss: 4.66438394e-07
Iter: 327 loss: 4.65947409e-07
Iter: 328 loss: 4.65911654e-07
Iter: 329 loss: 4.6556184e-07
Iter: 330 loss: 4.64846693e-07
Iter: 331 loss: 4.78902564e-07
Iter: 332 loss: 4.6481307e-07
Iter: 333 loss: 4.64295908e-07
Iter: 334 loss: 4.71030546e-07
Iter: 335 loss: 4.64284739e-07
Iter: 336 loss: 4.63645165e-07
Iter: 337 loss: 4.63337244e-07
Iter: 338 loss: 4.63086309e-07
Iter: 339 loss: 4.6234851e-07
Iter: 340 loss: 4.6329265e-07
Iter: 341 loss: 4.61978971e-07
Iter: 342 loss: 4.61401953e-07
Iter: 343 loss: 4.62329353e-07
Iter: 344 loss: 4.61042873e-07
Iter: 345 loss: 4.60533727e-07
Iter: 346 loss: 4.60476173e-07
Iter: 347 loss: 4.60034e-07
Iter: 348 loss: 4.60006788e-07
Iter: 349 loss: 4.596194e-07
Iter: 350 loss: 4.59125204e-07
Iter: 351 loss: 4.6182376e-07
Iter: 352 loss: 4.59063585e-07
Iter: 353 loss: 4.58473835e-07
Iter: 354 loss: 4.58472357e-07
Iter: 355 loss: 4.58049499e-07
Iter: 356 loss: 4.57127157e-07
Iter: 357 loss: 4.56431451e-07
Iter: 358 loss: 4.56251882e-07
Iter: 359 loss: 4.55461e-07
Iter: 360 loss: 4.55423731e-07
Iter: 361 loss: 4.54629571e-07
Iter: 362 loss: 4.55152559e-07
Iter: 363 loss: 4.54146345e-07
Iter: 364 loss: 4.53493612e-07
Iter: 365 loss: 4.53422103e-07
Iter: 366 loss: 4.52934074e-07
Iter: 367 loss: 4.52281142e-07
Iter: 368 loss: 4.52275e-07
Iter: 369 loss: 4.51921693e-07
Iter: 370 loss: 4.51252333e-07
Iter: 371 loss: 4.64735962e-07
Iter: 372 loss: 4.51229852e-07
Iter: 373 loss: 4.50604773e-07
Iter: 374 loss: 4.52181837e-07
Iter: 375 loss: 4.50361028e-07
Iter: 376 loss: 4.49858078e-07
Iter: 377 loss: 4.55676428e-07
Iter: 378 loss: 4.49907276e-07
Iter: 379 loss: 4.4936894e-07
Iter: 380 loss: 4.51926184e-07
Iter: 381 loss: 4.49253548e-07
Iter: 382 loss: 4.4891658e-07
Iter: 383 loss: 4.48680964e-07
Iter: 384 loss: 4.48513219e-07
Iter: 385 loss: 4.4809542e-07
Iter: 386 loss: 4.55286454e-07
Iter: 387 loss: 4.48097751e-07
Iter: 388 loss: 4.47879984e-07
Iter: 389 loss: 4.4721412e-07
Iter: 390 loss: 4.54399469e-07
Iter: 391 loss: 4.47177314e-07
Iter: 392 loss: 4.46602513e-07
Iter: 393 loss: 4.52132525e-07
Iter: 394 loss: 4.46570596e-07
Iter: 395 loss: 4.46190825e-07
Iter: 396 loss: 4.46152171e-07
Iter: 397 loss: 4.45915134e-07
Iter: 398 loss: 4.45327601e-07
Iter: 399 loss: 4.52394403e-07
Iter: 400 loss: 4.452599e-07
Iter: 401 loss: 4.44701072e-07
Iter: 402 loss: 4.5178524e-07
Iter: 403 loss: 4.44727618e-07
Iter: 404 loss: 4.44189482e-07
Iter: 405 loss: 4.44446073e-07
Iter: 406 loss: 4.43807124e-07
Iter: 407 loss: 4.43204101e-07
Iter: 408 loss: 4.42656528e-07
Iter: 409 loss: 4.42539772e-07
Iter: 410 loss: 4.41476487e-07
Iter: 411 loss: 4.43547606e-07
Iter: 412 loss: 4.41040015e-07
Iter: 413 loss: 4.40790188e-07
Iter: 414 loss: 4.40563383e-07
Iter: 415 loss: 4.40137569e-07
Iter: 416 loss: 4.39791108e-07
Iter: 417 loss: 4.39623534e-07
Iter: 418 loss: 4.3919124e-07
Iter: 419 loss: 4.42831606e-07
Iter: 420 loss: 4.39188483e-07
Iter: 421 loss: 4.3873905e-07
Iter: 422 loss: 4.39737363e-07
Iter: 423 loss: 4.38578297e-07
Iter: 424 loss: 4.38233315e-07
Iter: 425 loss: 4.37826316e-07
Iter: 426 loss: 4.37843312e-07
Iter: 427 loss: 4.37413036e-07
Iter: 428 loss: 4.43672349e-07
Iter: 429 loss: 4.37457857e-07
Iter: 430 loss: 4.37038125e-07
Iter: 431 loss: 4.37878e-07
Iter: 432 loss: 4.36902212e-07
Iter: 433 loss: 4.36607536e-07
Iter: 434 loss: 4.36401e-07
Iter: 435 loss: 4.36279777e-07
Iter: 436 loss: 4.35917627e-07
Iter: 437 loss: 4.40704582e-07
Iter: 438 loss: 4.35905463e-07
Iter: 439 loss: 4.35549566e-07
Iter: 440 loss: 4.35369145e-07
Iter: 441 loss: 4.35177128e-07
Iter: 442 loss: 4.34694641e-07
Iter: 443 loss: 4.34756771e-07
Iter: 444 loss: 4.34403148e-07
Iter: 445 loss: 4.33809134e-07
Iter: 446 loss: 4.34947481e-07
Iter: 447 loss: 4.33520654e-07
Iter: 448 loss: 4.33255195e-07
Iter: 449 loss: 4.33187893e-07
Iter: 450 loss: 4.32870223e-07
Iter: 451 loss: 4.3240567e-07
Iter: 452 loss: 4.32383246e-07
Iter: 453 loss: 4.31979402e-07
Iter: 454 loss: 4.35301047e-07
Iter: 455 loss: 4.31912099e-07
Iter: 456 loss: 4.31368875e-07
Iter: 457 loss: 4.31608385e-07
Iter: 458 loss: 4.31029406e-07
Iter: 459 loss: 4.30565308e-07
Iter: 460 loss: 4.3021214e-07
Iter: 461 loss: 4.30096691e-07
Iter: 462 loss: 4.29832625e-07
Iter: 463 loss: 4.29707825e-07
Iter: 464 loss: 4.29444412e-07
Iter: 465 loss: 4.28890928e-07
Iter: 466 loss: 4.40940255e-07
Iter: 467 loss: 4.28866599e-07
Iter: 468 loss: 4.28411539e-07
Iter: 469 loss: 4.30678028e-07
Iter: 470 loss: 4.28391843e-07
Iter: 471 loss: 4.28003034e-07
Iter: 472 loss: 4.3037204e-07
Iter: 473 loss: 4.27930047e-07
Iter: 474 loss: 4.27586741e-07
Iter: 475 loss: 4.2981867e-07
Iter: 476 loss: 4.27538453e-07
Iter: 477 loss: 4.27381622e-07
Iter: 478 loss: 4.27032802e-07
Iter: 479 loss: 4.27000487e-07
Iter: 480 loss: 4.26585387e-07
Iter: 481 loss: 4.28744926e-07
Iter: 482 loss: 4.26529255e-07
Iter: 483 loss: 4.26047563e-07
Iter: 484 loss: 4.29397744e-07
Iter: 485 loss: 4.26095085e-07
Iter: 486 loss: 4.25822805e-07
Iter: 487 loss: 4.25692235e-07
Iter: 488 loss: 4.25545409e-07
Iter: 489 loss: 4.25244536e-07
Iter: 490 loss: 4.29131148e-07
Iter: 491 loss: 4.2522521e-07
Iter: 492 loss: 4.24990361e-07
Iter: 493 loss: 4.2451444e-07
Iter: 494 loss: 4.2453334e-07
Iter: 495 loss: 4.24127336e-07
Iter: 496 loss: 4.27837676e-07
Iter: 497 loss: 4.24112756e-07
Iter: 498 loss: 4.23634447e-07
Iter: 499 loss: 4.24490594e-07
Iter: 500 loss: 4.23425575e-07
Iter: 501 loss: 4.23128199e-07
Iter: 502 loss: 4.22425444e-07
Iter: 503 loss: 4.38451849e-07
Iter: 504 loss: 4.22407652e-07
Iter: 505 loss: 4.21602294e-07
Iter: 506 loss: 4.22807148e-07
Iter: 507 loss: 4.21228435e-07
Iter: 508 loss: 4.20503625e-07
Iter: 509 loss: 4.26163467e-07
Iter: 510 loss: 4.20417848e-07
Iter: 511 loss: 4.19974413e-07
Iter: 512 loss: 4.19981831e-07
Iter: 513 loss: 4.19617493e-07
Iter: 514 loss: 4.20136672e-07
Iter: 515 loss: 4.1940865e-07
Iter: 516 loss: 4.1920697e-07
Iter: 517 loss: 4.19385515e-07
Iter: 518 loss: 4.19079498e-07
Iter: 519 loss: 4.1884698e-07
Iter: 520 loss: 4.18829671e-07
Iter: 521 loss: 4.18652832e-07
Iter: 522 loss: 4.18418892e-07
Iter: 523 loss: 4.18360202e-07
Iter: 524 loss: 4.18107334e-07
Iter: 525 loss: 4.1798873e-07
Iter: 526 loss: 4.17860036e-07
Iter: 527 loss: 4.17606486e-07
Iter: 528 loss: 4.17615155e-07
Iter: 529 loss: 4.17299589e-07
Iter: 530 loss: 4.17176096e-07
Iter: 531 loss: 4.17012473e-07
Iter: 532 loss: 4.16661663e-07
Iter: 533 loss: 4.17478532e-07
Iter: 534 loss: 4.16509863e-07
Iter: 535 loss: 4.16170337e-07
Iter: 536 loss: 4.19389494e-07
Iter: 537 loss: 4.16109742e-07
Iter: 538 loss: 4.15812451e-07
Iter: 539 loss: 4.15323882e-07
Iter: 540 loss: 4.2733069e-07
Iter: 541 loss: 4.15353213e-07
Iter: 542 loss: 4.14914041e-07
Iter: 543 loss: 4.15030883e-07
Iter: 544 loss: 4.14554052e-07
Iter: 545 loss: 4.14297119e-07
Iter: 546 loss: 4.14166038e-07
Iter: 547 loss: 4.13869827e-07
Iter: 548 loss: 4.13561e-07
Iter: 549 loss: 4.13566454e-07
Iter: 550 loss: 4.13083569e-07
Iter: 551 loss: 4.13367e-07
Iter: 552 loss: 4.12763598e-07
Iter: 553 loss: 4.1247921e-07
Iter: 554 loss: 4.12441636e-07
Iter: 555 loss: 4.12180412e-07
Iter: 556 loss: 4.11690394e-07
Iter: 557 loss: 4.11629e-07
Iter: 558 loss: 4.11288084e-07
Iter: 559 loss: 4.11942182e-07
Iter: 560 loss: 4.11108374e-07
Iter: 561 loss: 4.10906893e-07
Iter: 562 loss: 4.10857183e-07
Iter: 563 loss: 4.10628445e-07
Iter: 564 loss: 4.10433302e-07
Iter: 565 loss: 4.10423667e-07
Iter: 566 loss: 4.10213119e-07
Iter: 567 loss: 4.122615e-07
Iter: 568 loss: 4.10258508e-07
Iter: 569 loss: 4.10027184e-07
Iter: 570 loss: 4.10178473e-07
Iter: 571 loss: 4.09833063e-07
Iter: 572 loss: 4.09630331e-07
Iter: 573 loss: 4.0936e-07
Iter: 574 loss: 4.18590787e-07
Iter: 575 loss: 4.09321103e-07
Iter: 576 loss: 4.08789674e-07
Iter: 577 loss: 4.10888873e-07
Iter: 578 loss: 4.08713333e-07
Iter: 579 loss: 4.08361615e-07
Iter: 580 loss: 4.08300536e-07
Iter: 581 loss: 4.0801342e-07
Iter: 582 loss: 4.07561629e-07
Iter: 583 loss: 4.07537783e-07
Iter: 584 loss: 4.07171683e-07
Iter: 585 loss: 4.09578348e-07
Iter: 586 loss: 4.07093694e-07
Iter: 587 loss: 4.06690276e-07
Iter: 588 loss: 4.11360247e-07
Iter: 589 loss: 4.06720176e-07
Iter: 590 loss: 4.06494962e-07
Iter: 591 loss: 4.06183773e-07
Iter: 592 loss: 4.06188036e-07
Iter: 593 loss: 4.05792775e-07
Iter: 594 loss: 4.06813058e-07
Iter: 595 loss: 4.05643135e-07
Iter: 596 loss: 4.05258902e-07
Iter: 597 loss: 4.11103713e-07
Iter: 598 loss: 4.05265098e-07
Iter: 599 loss: 4.04990971e-07
Iter: 600 loss: 4.04552765e-07
Iter: 601 loss: 4.14217851e-07
Iter: 602 loss: 4.04539577e-07
Iter: 603 loss: 4.04071102e-07
Iter: 604 loss: 4.0411004e-07
Iter: 605 loss: 4.03724471e-07
Iter: 606 loss: 4.03695907e-07
Iter: 607 loss: 4.03431756e-07
Iter: 608 loss: 4.03098426e-07
Iter: 609 loss: 4.02691427e-07
Iter: 610 loss: 4.02659566e-07
Iter: 611 loss: 4.02310832e-07
Iter: 612 loss: 4.02345449e-07
Iter: 613 loss: 4.01975115e-07
Iter: 614 loss: 4.03731633e-07
Iter: 615 loss: 4.01915486e-07
Iter: 616 loss: 4.01688396e-07
Iter: 617 loss: 4.01440502e-07
Iter: 618 loss: 4.01411569e-07
Iter: 619 loss: 4.0104473e-07
Iter: 620 loss: 4.03388128e-07
Iter: 621 loss: 4.0104436e-07
Iter: 622 loss: 4.0062389e-07
Iter: 623 loss: 4.01583179e-07
Iter: 624 loss: 4.00492524e-07
Iter: 625 loss: 4.00184859e-07
Iter: 626 loss: 3.9970314e-07
Iter: 627 loss: 3.99716782e-07
Iter: 628 loss: 3.99262603e-07
Iter: 629 loss: 4.04906672e-07
Iter: 630 loss: 3.99280054e-07
Iter: 631 loss: 3.98844492e-07
Iter: 632 loss: 4.00615448e-07
Iter: 633 loss: 3.98741577e-07
Iter: 634 loss: 3.9845122e-07
Iter: 635 loss: 3.98296294e-07
Iter: 636 loss: 3.98157624e-07
Iter: 637 loss: 3.97960406e-07
Iter: 638 loss: 3.97930307e-07
Iter: 639 loss: 3.97781236e-07
Iter: 640 loss: 3.9741775e-07
Iter: 641 loss: 4.0258405e-07
Iter: 642 loss: 3.97391631e-07
Iter: 643 loss: 3.96992675e-07
Iter: 644 loss: 3.97577935e-07
Iter: 645 loss: 3.96804609e-07
Iter: 646 loss: 3.96336873e-07
Iter: 647 loss: 3.97063843e-07
Iter: 648 loss: 3.96098784e-07
Iter: 649 loss: 3.95864447e-07
Iter: 650 loss: 3.95835798e-07
Iter: 651 loss: 3.95586596e-07
Iter: 652 loss: 3.9507e-07
Iter: 653 loss: 4.05121199e-07
Iter: 654 loss: 3.9504198e-07
Iter: 655 loss: 3.94735451e-07
Iter: 656 loss: 3.94725532e-07
Iter: 657 loss: 3.9435065e-07
Iter: 658 loss: 3.94526097e-07
Iter: 659 loss: 3.94117e-07
Iter: 660 loss: 3.93774229e-07
Iter: 661 loss: 3.94725703e-07
Iter: 662 loss: 3.93717585e-07
Iter: 663 loss: 3.93521645e-07
Iter: 664 loss: 3.94509414e-07
Iter: 665 loss: 3.93465058e-07
Iter: 666 loss: 3.93217874e-07
Iter: 667 loss: 3.93614044e-07
Iter: 668 loss: 3.93171916e-07
Iter: 669 loss: 3.92954121e-07
Iter: 670 loss: 3.93603955e-07
Iter: 671 loss: 3.92850097e-07
Iter: 672 loss: 3.92562413e-07
Iter: 673 loss: 3.93756807e-07
Iter: 674 loss: 3.92487891e-07
Iter: 675 loss: 3.92334016e-07
Iter: 676 loss: 3.91856787e-07
Iter: 677 loss: 3.97840608e-07
Iter: 678 loss: 3.91820947e-07
Iter: 679 loss: 3.9123438e-07
Iter: 680 loss: 3.92525891e-07
Iter: 681 loss: 3.90964686e-07
Iter: 682 loss: 3.90473019e-07
Iter: 683 loss: 3.97601355e-07
Iter: 684 loss: 3.90488793e-07
Iter: 685 loss: 3.90082278e-07
Iter: 686 loss: 3.92014897e-07
Iter: 687 loss: 3.89954636e-07
Iter: 688 loss: 3.89620482e-07
Iter: 689 loss: 3.89256e-07
Iter: 690 loss: 3.89205809e-07
Iter: 691 loss: 3.89096556e-07
Iter: 692 loss: 3.88944414e-07
Iter: 693 loss: 3.888278e-07
Iter: 694 loss: 3.88470198e-07
Iter: 695 loss: 3.9478266e-07
Iter: 696 loss: 3.8849322e-07
Iter: 697 loss: 3.88221224e-07
Iter: 698 loss: 3.9134369e-07
Iter: 699 loss: 3.88211333e-07
Iter: 700 loss: 3.87919e-07
Iter: 701 loss: 3.88028468e-07
Iter: 702 loss: 3.87709548e-07
Iter: 703 loss: 3.87449887e-07
Iter: 704 loss: 3.87461e-07
Iter: 705 loss: 3.87179227e-07
Iter: 706 loss: 3.86912e-07
Iter: 707 loss: 3.86860108e-07
Iter: 708 loss: 3.86657177e-07
Iter: 709 loss: 3.86353804e-07
Iter: 710 loss: 3.86313445e-07
Iter: 711 loss: 3.85979092e-07
Iter: 712 loss: 3.85994156e-07
Iter: 713 loss: 3.85720739e-07
Iter: 714 loss: 3.85180698e-07
Iter: 715 loss: 3.86322824e-07
Iter: 716 loss: 3.85015369e-07
Iter: 717 loss: 3.84878604e-07
Iter: 718 loss: 3.8477728e-07
Iter: 719 loss: 3.84537856e-07
Iter: 720 loss: 3.8419563e-07
Iter: 721 loss: 3.92930218e-07
Iter: 722 loss: 3.84189747e-07
Iter: 723 loss: 3.83814779e-07
Iter: 724 loss: 3.84396685e-07
Iter: 725 loss: 3.83637939e-07
Iter: 726 loss: 3.83178218e-07
Iter: 727 loss: 3.83164092e-07
Iter: 728 loss: 3.83009706e-07
Iter: 729 loss: 3.82692349e-07
Iter: 730 loss: 3.82687e-07
Iter: 731 loss: 3.82330199e-07
Iter: 732 loss: 3.87352486e-07
Iter: 733 loss: 3.82357342e-07
Iter: 734 loss: 3.82037371e-07
Iter: 735 loss: 3.81753921e-07
Iter: 736 loss: 3.81668571e-07
Iter: 737 loss: 3.81280131e-07
Iter: 738 loss: 3.81878351e-07
Iter: 739 loss: 3.81076489e-07
Iter: 740 loss: 3.80863071e-07
Iter: 741 loss: 3.80869096e-07
Iter: 742 loss: 3.80638852e-07
Iter: 743 loss: 3.80677278e-07
Iter: 744 loss: 3.80513285e-07
Iter: 745 loss: 3.80305494e-07
Iter: 746 loss: 3.80205222e-07
Iter: 747 loss: 3.80089489e-07
Iter: 748 loss: 3.79763065e-07
Iter: 749 loss: 3.80490917e-07
Iter: 750 loss: 3.79614e-07
Iter: 751 loss: 3.79296125e-07
Iter: 752 loss: 3.83482444e-07
Iter: 753 loss: 3.79277765e-07
Iter: 754 loss: 3.78940484e-07
Iter: 755 loss: 3.78996276e-07
Iter: 756 loss: 3.78742641e-07
Iter: 757 loss: 3.7850134e-07
Iter: 758 loss: 3.7985393e-07
Iter: 759 loss: 3.7846587e-07
Iter: 760 loss: 3.78241509e-07
Iter: 761 loss: 3.78922948e-07
Iter: 762 loss: 3.7813777e-07
Iter: 763 loss: 3.7794851e-07
Iter: 764 loss: 3.77684643e-07
Iter: 765 loss: 3.77737365e-07
Iter: 766 loss: 3.77570871e-07
Iter: 767 loss: 3.77536622e-07
Iter: 768 loss: 3.77338722e-07
Iter: 769 loss: 3.7708935e-07
Iter: 770 loss: 3.77108051e-07
Iter: 771 loss: 3.76864278e-07
Iter: 772 loss: 3.7862759e-07
Iter: 773 loss: 3.76849329e-07
Iter: 774 loss: 3.76603964e-07
Iter: 775 loss: 3.76682067e-07
Iter: 776 loss: 3.76455944e-07
Iter: 777 loss: 3.76244969e-07
Iter: 778 loss: 3.76256622e-07
Iter: 779 loss: 3.76063099e-07
Iter: 780 loss: 3.75692849e-07
Iter: 781 loss: 3.7613e-07
Iter: 782 loss: 3.7551402e-07
Iter: 783 loss: 3.75154485e-07
Iter: 784 loss: 3.76468449e-07
Iter: 785 loss: 3.75106566e-07
Iter: 786 loss: 3.74853471e-07
Iter: 787 loss: 3.74843097e-07
Iter: 788 loss: 3.74664978e-07
Iter: 789 loss: 3.74483534e-07
Iter: 790 loss: 3.74460768e-07
Iter: 791 loss: 3.74263891e-07
Iter: 792 loss: 3.77296658e-07
Iter: 793 loss: 3.74256501e-07
Iter: 794 loss: 3.740615e-07
Iter: 795 loss: 3.73844e-07
Iter: 796 loss: 3.73779471e-07
Iter: 797 loss: 3.73538796e-07
Iter: 798 loss: 3.73826026e-07
Iter: 799 loss: 3.7340709e-07
Iter: 800 loss: 3.73197167e-07
Iter: 801 loss: 3.73174089e-07
Iter: 802 loss: 3.73034311e-07
Iter: 803 loss: 3.72651215e-07
Iter: 804 loss: 3.78569581e-07
Iter: 805 loss: 3.72673327e-07
Iter: 806 loss: 3.72340423e-07
Iter: 807 loss: 3.76447133e-07
Iter: 808 loss: 3.72364411e-07
Iter: 809 loss: 3.72033554e-07
Iter: 810 loss: 3.72629472e-07
Iter: 811 loss: 3.7185697e-07
Iter: 812 loss: 3.71679619e-07
Iter: 813 loss: 3.71500818e-07
Iter: 814 loss: 3.71485385e-07
Iter: 815 loss: 3.71255453e-07
Iter: 816 loss: 3.72331328e-07
Iter: 817 loss: 3.71206625e-07
Iter: 818 loss: 3.71046184e-07
Iter: 819 loss: 3.71672854e-07
Iter: 820 loss: 3.70975982e-07
Iter: 821 loss: 3.70837938e-07
Iter: 822 loss: 3.71085406e-07
Iter: 823 loss: 3.70736132e-07
Iter: 824 loss: 3.70538714e-07
Iter: 825 loss: 3.70405473e-07
Iter: 826 loss: 3.70343912e-07
Iter: 827 loss: 3.70096473e-07
Iter: 828 loss: 3.70103038e-07
Iter: 829 loss: 3.69888539e-07
Iter: 830 loss: 3.69749955e-07
Iter: 831 loss: 3.69706413e-07
Iter: 832 loss: 3.69418132e-07
Iter: 833 loss: 3.698309e-07
Iter: 834 loss: 3.69247317e-07
Iter: 835 loss: 3.6911743e-07
Iter: 836 loss: 3.69078805e-07
Iter: 837 loss: 3.68992886e-07
Iter: 838 loss: 3.68751671e-07
Iter: 839 loss: 3.71447584e-07
Iter: 840 loss: 3.6873746e-07
Iter: 841 loss: 3.68484478e-07
Iter: 842 loss: 3.70552129e-07
Iter: 843 loss: 3.68471916e-07
Iter: 844 loss: 3.68198357e-07
Iter: 845 loss: 3.69600116e-07
Iter: 846 loss: 3.68204979e-07
Iter: 847 loss: 3.68061848e-07
Iter: 848 loss: 3.67824811e-07
Iter: 849 loss: 3.67850078e-07
Iter: 850 loss: 3.67631628e-07
Iter: 851 loss: 3.6860078e-07
Iter: 852 loss: 3.67525615e-07
Iter: 853 loss: 3.67334e-07
Iter: 854 loss: 3.69595625e-07
Iter: 855 loss: 3.67300657e-07
Iter: 856 loss: 3.67106509e-07
Iter: 857 loss: 3.67419744e-07
Iter: 858 loss: 3.67031902e-07
Iter: 859 loss: 3.668803e-07
Iter: 860 loss: 3.67122766e-07
Iter: 861 loss: 3.66802453e-07
Iter: 862 loss: 3.66609555e-07
Iter: 863 loss: 3.68317956e-07
Iter: 864 loss: 3.66594662e-07
Iter: 865 loss: 3.66427827e-07
Iter: 866 loss: 3.66253943e-07
Iter: 867 loss: 3.71632609e-07
Iter: 868 loss: 3.66245104e-07
Iter: 869 loss: 3.66031912e-07
Iter: 870 loss: 3.66052518e-07
Iter: 871 loss: 3.65886848e-07
Iter: 872 loss: 3.6601952e-07
Iter: 873 loss: 3.65774554e-07
Iter: 874 loss: 3.65619172e-07
Iter: 875 loss: 3.65478854e-07
Iter: 876 loss: 3.65451399e-07
Iter: 877 loss: 3.65313667e-07
Iter: 878 loss: 3.65273252e-07
Iter: 879 loss: 3.65112726e-07
Iter: 880 loss: 3.6484397e-07
Iter: 881 loss: 3.64873642e-07
Iter: 882 loss: 3.6459096e-07
Iter: 883 loss: 3.65068047e-07
Iter: 884 loss: 3.64447601e-07
Iter: 885 loss: 3.64244983e-07
Iter: 886 loss: 3.64224775e-07
Iter: 887 loss: 3.63969406e-07
Iter: 888 loss: 3.64353866e-07
Iter: 889 loss: 3.63910772e-07
Iter: 890 loss: 3.63715657e-07
Iter: 891 loss: 3.64173161e-07
Iter: 892 loss: 3.63614902e-07
Iter: 893 loss: 3.63462391e-07
Iter: 894 loss: 3.64744267e-07
Iter: 895 loss: 3.63469155e-07
Iter: 896 loss: 3.63315962e-07
Iter: 897 loss: 3.63202531e-07
Iter: 898 loss: 3.63180277e-07
Iter: 899 loss: 3.62975584e-07
Iter: 900 loss: 3.63569683e-07
Iter: 901 loss: 3.62945229e-07
Iter: 902 loss: 3.62712512e-07
Iter: 903 loss: 3.64214372e-07
Iter: 904 loss: 3.62663627e-07
Iter: 905 loss: 3.62546871e-07
Iter: 906 loss: 3.62503556e-07
Iter: 907 loss: 3.62436936e-07
Iter: 908 loss: 3.62224654e-07
Iter: 909 loss: 3.63891814e-07
Iter: 910 loss: 3.62224085e-07
Iter: 911 loss: 3.61969654e-07
Iter: 912 loss: 3.62142146e-07
Iter: 913 loss: 3.618525e-07
Iter: 914 loss: 3.61666508e-07
Iter: 915 loss: 3.61695186e-07
Iter: 916 loss: 3.61463378e-07
Iter: 917 loss: 3.61364016e-07
Iter: 918 loss: 3.62761313e-07
Iter: 919 loss: 3.61289381e-07
Iter: 920 loss: 3.61197124e-07
Iter: 921 loss: 3.6237833e-07
Iter: 922 loss: 3.61142838e-07
Iter: 923 loss: 3.61039952e-07
Iter: 924 loss: 3.61009171e-07
Iter: 925 loss: 3.60958069e-07
Iter: 926 loss: 3.6073277e-07
Iter: 927 loss: 3.61944444e-07
Iter: 928 loss: 3.60767359e-07
Iter: 929 loss: 3.60584949e-07
Iter: 930 loss: 3.60528929e-07
Iter: 931 loss: 3.60462565e-07
Iter: 932 loss: 3.60310167e-07
Iter: 933 loss: 3.60447757e-07
Iter: 934 loss: 3.60148363e-07
Iter: 935 loss: 3.59991617e-07
Iter: 936 loss: 3.62465329e-07
Iter: 937 loss: 3.59971182e-07
Iter: 938 loss: 3.59815573e-07
Iter: 939 loss: 3.59460103e-07
Iter: 940 loss: 3.65273735e-07
Iter: 941 loss: 3.59496823e-07
Iter: 942 loss: 3.59171054e-07
Iter: 943 loss: 3.61749983e-07
Iter: 944 loss: 3.59194985e-07
Iter: 945 loss: 3.58945726e-07
Iter: 946 loss: 3.60600353e-07
Iter: 947 loss: 3.58880413e-07
Iter: 948 loss: 3.58749674e-07
Iter: 949 loss: 3.58380532e-07
Iter: 950 loss: 3.63989727e-07
Iter: 951 loss: 3.58370187e-07
Iter: 952 loss: 3.5801429e-07
Iter: 953 loss: 3.60755791e-07
Iter: 954 loss: 3.58011505e-07
Iter: 955 loss: 3.57775491e-07
Iter: 956 loss: 3.61214632e-07
Iter: 957 loss: 3.57817953e-07
Iter: 958 loss: 3.57619768e-07
Iter: 959 loss: 3.57392508e-07
Iter: 960 loss: 3.57359397e-07
Iter: 961 loss: 3.57083309e-07
Iter: 962 loss: 3.59961518e-07
Iter: 963 loss: 3.57088425e-07
Iter: 964 loss: 3.56808982e-07
Iter: 965 loss: 3.56978944e-07
Iter: 966 loss: 3.56693903e-07
Iter: 967 loss: 3.56408094e-07
Iter: 968 loss: 3.56815832e-07
Iter: 969 loss: 3.56362563e-07
Iter: 970 loss: 3.5613661e-07
Iter: 971 loss: 3.5825002e-07
Iter: 972 loss: 3.56091533e-07
Iter: 973 loss: 3.55958917e-07
Iter: 974 loss: 3.55880616e-07
Iter: 975 loss: 3.55757294e-07
Iter: 976 loss: 3.55562577e-07
Iter: 977 loss: 3.56319532e-07
Iter: 978 loss: 3.55505847e-07
Iter: 979 loss: 3.55398811e-07
Iter: 980 loss: 3.57565938e-07
Iter: 981 loss: 3.55386277e-07
Iter: 982 loss: 3.55292229e-07
Iter: 983 loss: 3.55061815e-07
Iter: 984 loss: 3.58290833e-07
Iter: 985 loss: 3.55040868e-07
Iter: 986 loss: 3.5481159e-07
Iter: 987 loss: 3.55335601e-07
Iter: 988 loss: 3.54699466e-07
Iter: 989 loss: 3.54442136e-07
Iter: 990 loss: 3.54455494e-07
Iter: 991 loss: 3.54248414e-07
Iter: 992 loss: 3.54053896e-07
Iter: 993 loss: 3.53980482e-07
Iter: 994 loss: 3.53637489e-07
Iter: 995 loss: 3.55642527e-07
Iter: 996 loss: 3.53611483e-07
Iter: 997 loss: 3.5333224e-07
Iter: 998 loss: 3.54218741e-07
Iter: 999 loss: 3.53235151e-07
Iter: 1000 loss: 3.53038189e-07
Iter: 1001 loss: 3.53009142e-07
Iter: 1002 loss: 3.5288565e-07
Iter: 1003 loss: 3.52654268e-07
Iter: 1004 loss: 3.54756651e-07
Iter: 1005 loss: 3.52607827e-07
Iter: 1006 loss: 3.52364822e-07
Iter: 1007 loss: 3.52779466e-07
Iter: 1008 loss: 3.52257274e-07
Iter: 1009 loss: 3.52025523e-07
Iter: 1010 loss: 3.51852435e-07
Iter: 1011 loss: 3.51765152e-07
Iter: 1012 loss: 3.51584021e-07
Iter: 1013 loss: 3.51564182e-07
Iter: 1014 loss: 3.51383477e-07
Iter: 1015 loss: 3.51215647e-07
Iter: 1016 loss: 3.51113101e-07
Iter: 1017 loss: 3.50918299e-07
Iter: 1018 loss: 3.50806943e-07
Iter: 1019 loss: 3.50629648e-07
Iter: 1020 loss: 3.50356032e-07
Iter: 1021 loss: 3.54231162e-07
Iter: 1022 loss: 3.50374307e-07
Iter: 1023 loss: 3.50114078e-07
Iter: 1024 loss: 3.51236025e-07
Iter: 1025 loss: 3.50103846e-07
Iter: 1026 loss: 3.49942468e-07
Iter: 1027 loss: 3.50192551e-07
Iter: 1028 loss: 3.49900688e-07
Iter: 1029 loss: 3.49668852e-07
Iter: 1030 loss: 3.50567404e-07
Iter: 1031 loss: 3.49668454e-07
Iter: 1032 loss: 3.4949764e-07
Iter: 1033 loss: 3.49480331e-07
Iter: 1034 loss: 3.49408566e-07
Iter: 1035 loss: 3.49252645e-07
Iter: 1036 loss: 3.50410573e-07
Iter: 1037 loss: 3.49197705e-07
Iter: 1038 loss: 3.49029165e-07
Iter: 1039 loss: 3.49557666e-07
Iter: 1040 loss: 3.48990739e-07
Iter: 1041 loss: 3.48842434e-07
Iter: 1042 loss: 3.48624724e-07
Iter: 1043 loss: 3.48615117e-07
Iter: 1044 loss: 3.4838817e-07
Iter: 1045 loss: 3.48365205e-07
Iter: 1046 loss: 3.48166566e-07
Iter: 1047 loss: 3.4827454e-07
Iter: 1048 loss: 3.4804259e-07
Iter: 1049 loss: 3.47842132e-07
Iter: 1050 loss: 3.47654463e-07
Iter: 1051 loss: 3.4760123e-07
Iter: 1052 loss: 3.47310817e-07
Iter: 1053 loss: 3.49338336e-07
Iter: 1054 loss: 3.47358622e-07
Iter: 1055 loss: 3.47152138e-07
Iter: 1056 loss: 3.49278281e-07
Iter: 1057 loss: 3.47117918e-07
Iter: 1058 loss: 3.4699292e-07
Iter: 1059 loss: 3.46908962e-07
Iter: 1060 loss: 3.46889493e-07
Iter: 1061 loss: 3.46735646e-07
Iter: 1062 loss: 3.48745658e-07
Iter: 1063 loss: 3.46731071e-07
Iter: 1064 loss: 3.46590582e-07
Iter: 1065 loss: 3.46594732e-07
Iter: 1066 loss: 3.46499121e-07
Iter: 1067 loss: 3.46300368e-07
Iter: 1068 loss: 3.46499604e-07
Iter: 1069 loss: 3.46251284e-07
Iter: 1070 loss: 3.45984716e-07
Iter: 1071 loss: 3.47083216e-07
Iter: 1072 loss: 3.45931852e-07
Iter: 1073 loss: 3.45709282e-07
Iter: 1074 loss: 3.45635186e-07
Iter: 1075 loss: 3.45494868e-07
Iter: 1076 loss: 3.45297082e-07
Iter: 1077 loss: 3.46558608e-07
Iter: 1078 loss: 3.45248111e-07
Iter: 1079 loss: 3.45003969e-07
Iter: 1080 loss: 3.46775863e-07
Iter: 1081 loss: 3.45023e-07
Iter: 1082 loss: 3.44836366e-07
Iter: 1083 loss: 3.44653245e-07
Iter: 1084 loss: 3.44664699e-07
Iter: 1085 loss: 3.44495618e-07
Iter: 1086 loss: 3.45102791e-07
Iter: 1087 loss: 3.44390145e-07
Iter: 1088 loss: 3.44234508e-07
Iter: 1089 loss: 3.46281468e-07
Iter: 1090 loss: 3.44239112e-07
Iter: 1091 loss: 3.44068297e-07
Iter: 1092 loss: 3.44151118e-07
Iter: 1093 loss: 3.43975643e-07
Iter: 1094 loss: 3.43838565e-07
Iter: 1095 loss: 3.44924416e-07
Iter: 1096 loss: 3.43831516e-07
Iter: 1097 loss: 3.4371763e-07
Iter: 1098 loss: 3.43661043e-07
Iter: 1099 loss: 3.43604029e-07
Iter: 1100 loss: 3.43404793e-07
Iter: 1101 loss: 3.4374483e-07
Iter: 1102 loss: 3.43329816e-07
Iter: 1103 loss: 3.43144166e-07
Iter: 1104 loss: 3.452096e-07
Iter: 1105 loss: 3.43114777e-07
Iter: 1106 loss: 3.42998135e-07
Iter: 1107 loss: 3.4290386e-07
Iter: 1108 loss: 3.42842213e-07
Iter: 1109 loss: 3.42665373e-07
Iter: 1110 loss: 3.4307385e-07
Iter: 1111 loss: 3.42583803e-07
Iter: 1112 loss: 3.42527102e-07
Iter: 1113 loss: 3.42530825e-07
Iter: 1114 loss: 3.42429132e-07
Iter: 1115 loss: 3.42303395e-07
Iter: 1116 loss: 3.42269402e-07
Iter: 1117 loss: 3.42174133e-07
Iter: 1118 loss: 3.42296431e-07
Iter: 1119 loss: 3.42087702e-07
Iter: 1120 loss: 3.41995275e-07
Iter: 1121 loss: 3.42066983e-07
Iter: 1122 loss: 3.41896452e-07
Iter: 1123 loss: 3.41814456e-07
Iter: 1124 loss: 3.41766707e-07
Iter: 1125 loss: 3.41639605e-07
Iter: 1126 loss: 3.42382151e-07
Iter: 1127 loss: 3.41609166e-07
Iter: 1128 loss: 3.41481e-07
Iter: 1129 loss: 3.41584723e-07
Iter: 1130 loss: 3.41352973e-07
Iter: 1131 loss: 3.41175109e-07
Iter: 1132 loss: 3.41418911e-07
Iter: 1133 loss: 3.41154021e-07
Iter: 1134 loss: 3.40970729e-07
Iter: 1135 loss: 3.42613333e-07
Iter: 1136 loss: 3.4095612e-07
Iter: 1137 loss: 3.4079531e-07
Iter: 1138 loss: 3.40866052e-07
Iter: 1139 loss: 3.40729741e-07
Iter: 1140 loss: 3.40517886e-07
Iter: 1141 loss: 3.40733294e-07
Iter: 1142 loss: 3.40459906e-07
Iter: 1143 loss: 3.40326835e-07
Iter: 1144 loss: 3.40319929e-07
Iter: 1145 loss: 3.4024788e-07
Iter: 1146 loss: 3.40173585e-07
Iter: 1147 loss: 3.40133397e-07
Iter: 1148 loss: 3.39992198e-07
Iter: 1149 loss: 3.39953147e-07
Iter: 1150 loss: 3.39901305e-07
Iter: 1151 loss: 3.39699938e-07
Iter: 1152 loss: 3.41535895e-07
Iter: 1153 loss: 3.39707924e-07
Iter: 1154 loss: 3.39516305e-07
Iter: 1155 loss: 3.39741575e-07
Iter: 1156 loss: 3.39442437e-07
Iter: 1157 loss: 3.39283503e-07
Iter: 1158 loss: 3.40168185e-07
Iter: 1159 loss: 3.39267189e-07
Iter: 1160 loss: 3.39114251e-07
Iter: 1161 loss: 3.39637438e-07
Iter: 1162 loss: 3.39083954e-07
Iter: 1163 loss: 3.3903504e-07
Iter: 1164 loss: 3.38888441e-07
Iter: 1165 loss: 3.38861298e-07
Iter: 1166 loss: 3.38715893e-07
Iter: 1167 loss: 3.40156618e-07
Iter: 1168 loss: 3.38726295e-07
Iter: 1169 loss: 3.38599762e-07
Iter: 1170 loss: 3.38715921e-07
Iter: 1171 loss: 3.38563751e-07
Iter: 1172 loss: 3.38436763e-07
Iter: 1173 loss: 3.38502986e-07
Iter: 1174 loss: 3.38406551e-07
Iter: 1175 loss: 3.3826845e-07
Iter: 1176 loss: 3.39097738e-07
Iter: 1177 loss: 3.382373e-07
Iter: 1178 loss: 3.38109572e-07
Iter: 1179 loss: 3.38202199e-07
Iter: 1180 loss: 3.3805091e-07
Iter: 1181 loss: 3.37866283e-07
Iter: 1182 loss: 3.37718888e-07
Iter: 1183 loss: 3.37677307e-07
Iter: 1184 loss: 3.37463973e-07
Iter: 1185 loss: 3.38172413e-07
Iter: 1186 loss: 3.37363531e-07
Iter: 1187 loss: 3.37160685e-07
Iter: 1188 loss: 3.37143859e-07
Iter: 1189 loss: 3.36989615e-07
Iter: 1190 loss: 3.36923165e-07
Iter: 1191 loss: 3.36870244e-07
Iter: 1192 loss: 3.36691414e-07
Iter: 1193 loss: 3.38318728e-07
Iter: 1194 loss: 3.36672059e-07
Iter: 1195 loss: 3.36562778e-07
Iter: 1196 loss: 3.36451109e-07
Iter: 1197 loss: 3.36437552e-07
Iter: 1198 loss: 3.36316901e-07
Iter: 1199 loss: 3.37827203e-07
Iter: 1200 loss: 3.3631531e-07
Iter: 1201 loss: 3.36220808e-07
Iter: 1202 loss: 3.36236894e-07
Iter: 1203 loss: 3.36114113e-07
Iter: 1204 loss: 3.35937131e-07
Iter: 1205 loss: 3.35946112e-07
Iter: 1206 loss: 3.35838422e-07
Iter: 1207 loss: 3.35629863e-07
Iter: 1208 loss: 3.36115477e-07
Iter: 1209 loss: 3.35554063e-07
Iter: 1210 loss: 3.35390752e-07
Iter: 1211 loss: 3.37656189e-07
Iter: 1212 loss: 3.353735e-07
Iter: 1213 loss: 3.3522025e-07
Iter: 1214 loss: 3.35014192e-07
Iter: 1215 loss: 3.40715474e-07
Iter: 1216 loss: 3.34967467e-07
Iter: 1217 loss: 3.34714457e-07
Iter: 1218 loss: 3.35731215e-07
Iter: 1219 loss: 3.346874e-07
Iter: 1220 loss: 3.34518461e-07
Iter: 1221 loss: 3.34506325e-07
Iter: 1222 loss: 3.34382747e-07
Iter: 1223 loss: 3.3430527e-07
Iter: 1224 loss: 3.3425215e-07
Iter: 1225 loss: 3.34129e-07
Iter: 1226 loss: 3.35897681e-07
Iter: 1227 loss: 3.34102367e-07
Iter: 1228 loss: 3.33952244e-07
Iter: 1229 loss: 3.33983337e-07
Iter: 1230 loss: 3.33845634e-07
Iter: 1231 loss: 3.33767105e-07
Iter: 1232 loss: 3.34172313e-07
Iter: 1233 loss: 3.33715775e-07
Iter: 1234 loss: 3.33525435e-07
Iter: 1235 loss: 3.33807122e-07
Iter: 1236 loss: 3.33489766e-07
Iter: 1237 loss: 3.33314404e-07
Iter: 1238 loss: 3.33267138e-07
Iter: 1239 loss: 3.33180367e-07
Iter: 1240 loss: 3.32968796e-07
Iter: 1241 loss: 3.3356244e-07
Iter: 1242 loss: 3.32861532e-07
Iter: 1243 loss: 3.3276217e-07
Iter: 1244 loss: 3.32755e-07
Iter: 1245 loss: 3.32605396e-07
Iter: 1246 loss: 3.32477015e-07
Iter: 1247 loss: 3.3246863e-07
Iter: 1248 loss: 3.32287897e-07
Iter: 1249 loss: 3.32401243e-07
Iter: 1250 loss: 3.32188137e-07
Iter: 1251 loss: 3.32022381e-07
Iter: 1252 loss: 3.33260971e-07
Iter: 1253 loss: 3.31989327e-07
Iter: 1254 loss: 3.31822491e-07
Iter: 1255 loss: 3.33171357e-07
Iter: 1256 loss: 3.31802369e-07
Iter: 1257 loss: 3.31740694e-07
Iter: 1258 loss: 3.31750556e-07
Iter: 1259 loss: 3.31605492e-07
Iter: 1260 loss: 3.31476713e-07
Iter: 1261 loss: 3.31934615e-07
Iter: 1262 loss: 3.31373855e-07
Iter: 1263 loss: 3.31233679e-07
Iter: 1264 loss: 3.31256416e-07
Iter: 1265 loss: 3.3108978e-07
Iter: 1266 loss: 3.30927207e-07
Iter: 1267 loss: 3.33196141e-07
Iter: 1268 loss: 3.30923115e-07
Iter: 1269 loss: 3.30818267e-07
Iter: 1270 loss: 3.30694974e-07
Iter: 1271 loss: 3.30641711e-07
Iter: 1272 loss: 3.30360223e-07
Iter: 1273 loss: 3.30567701e-07
Iter: 1274 loss: 3.3022576e-07
Iter: 1275 loss: 3.30037352e-07
Iter: 1276 loss: 3.30026751e-07
Iter: 1277 loss: 3.29829902e-07
Iter: 1278 loss: 3.29947142e-07
Iter: 1279 loss: 3.29719796e-07
Iter: 1280 loss: 3.29501148e-07
Iter: 1281 loss: 3.29204255e-07
Iter: 1282 loss: 3.29192972e-07
Iter: 1283 loss: 3.28815815e-07
Iter: 1284 loss: 3.30806614e-07
Iter: 1285 loss: 3.28794414e-07
Iter: 1286 loss: 3.28604074e-07
Iter: 1287 loss: 3.28596741e-07
Iter: 1288 loss: 3.28468616e-07
Iter: 1289 loss: 3.28237661e-07
Iter: 1290 loss: 3.33856093e-07
Iter: 1291 loss: 3.28260626e-07
Iter: 1292 loss: 3.27965182e-07
Iter: 1293 loss: 3.32056374e-07
Iter: 1294 loss: 3.27947248e-07
Iter: 1295 loss: 3.27785557e-07
Iter: 1296 loss: 3.27731129e-07
Iter: 1297 loss: 3.27615709e-07
Iter: 1298 loss: 3.27454131e-07
Iter: 1299 loss: 3.28997771e-07
Iter: 1300 loss: 3.27447424e-07
Iter: 1301 loss: 3.27257226e-07
Iter: 1302 loss: 3.27138338e-07
Iter: 1303 loss: 3.27037327e-07
Iter: 1304 loss: 3.26832065e-07
Iter: 1305 loss: 3.27473913e-07
Iter: 1306 loss: 3.26783692e-07
Iter: 1307 loss: 3.2661967e-07
Iter: 1308 loss: 3.27633529e-07
Iter: 1309 loss: 3.26566351e-07
Iter: 1310 loss: 3.26393916e-07
Iter: 1311 loss: 3.27282777e-07
Iter: 1312 loss: 3.26413584e-07
Iter: 1313 loss: 3.26201103e-07
Iter: 1314 loss: 3.25908161e-07
Iter: 1315 loss: 3.25922599e-07
Iter: 1316 loss: 3.25648188e-07
Iter: 1317 loss: 3.26281452e-07
Iter: 1318 loss: 3.25516055e-07
Iter: 1319 loss: 3.25203956e-07
Iter: 1320 loss: 3.27779645e-07
Iter: 1321 loss: 3.25169225e-07
Iter: 1322 loss: 3.24931165e-07
Iter: 1323 loss: 3.25563775e-07
Iter: 1324 loss: 3.24805853e-07
Iter: 1325 loss: 3.24627365e-07
Iter: 1326 loss: 3.25770287e-07
Iter: 1327 loss: 3.24550939e-07
Iter: 1328 loss: 3.24383279e-07
Iter: 1329 loss: 3.2450879e-07
Iter: 1330 loss: 3.24280279e-07
Iter: 1331 loss: 3.24068594e-07
Iter: 1332 loss: 3.25016089e-07
Iter: 1333 loss: 3.24051342e-07
Iter: 1334 loss: 3.23831216e-07
Iter: 1335 loss: 3.24177392e-07
Iter: 1336 loss: 3.23766699e-07
Iter: 1337 loss: 3.23530571e-07
Iter: 1338 loss: 3.23462302e-07
Iter: 1339 loss: 3.23382039e-07
Iter: 1340 loss: 3.2306076e-07
Iter: 1341 loss: 3.24404965e-07
Iter: 1342 loss: 3.23042343e-07
Iter: 1343 loss: 3.22855215e-07
Iter: 1344 loss: 3.25603281e-07
Iter: 1345 loss: 3.22844357e-07
Iter: 1346 loss: 3.22704437e-07
Iter: 1347 loss: 3.22441167e-07
Iter: 1348 loss: 3.22459897e-07
Iter: 1349 loss: 3.22158513e-07
Iter: 1350 loss: 3.22398591e-07
Iter: 1351 loss: 3.21923721e-07
Iter: 1352 loss: 3.21650049e-07
Iter: 1353 loss: 3.24968482e-07
Iter: 1354 loss: 3.21638169e-07
Iter: 1355 loss: 3.2143285e-07
Iter: 1356 loss: 3.23068861e-07
Iter: 1357 loss: 3.21405764e-07
Iter: 1358 loss: 3.21278804e-07
Iter: 1359 loss: 3.211739e-07
Iter: 1360 loss: 3.21119359e-07
Iter: 1361 loss: 3.20858931e-07
Iter: 1362 loss: 3.22981123e-07
Iter: 1363 loss: 3.20886897e-07
Iter: 1364 loss: 3.20748512e-07
Iter: 1365 loss: 3.2081806e-07
Iter: 1366 loss: 3.20657335e-07
Iter: 1367 loss: 3.20496042e-07
Iter: 1368 loss: 3.21455644e-07
Iter: 1369 loss: 3.20460231e-07
Iter: 1370 loss: 3.20329775e-07
Iter: 1371 loss: 3.20024753e-07
Iter: 1372 loss: 3.20061275e-07
Iter: 1373 loss: 3.19793287e-07
Iter: 1374 loss: 3.21105375e-07
Iter: 1375 loss: 3.19742611e-07
Iter: 1376 loss: 3.19505489e-07
Iter: 1377 loss: 3.21869436e-07
Iter: 1378 loss: 3.19479966e-07
Iter: 1379 loss: 3.19275841e-07
Iter: 1380 loss: 3.19194612e-07
Iter: 1381 loss: 3.19116793e-07
Iter: 1382 loss: 3.18841984e-07
Iter: 1383 loss: 3.18906189e-07
Iter: 1384 loss: 3.18668754e-07
Iter: 1385 loss: 3.18442716e-07
Iter: 1386 loss: 3.19959298e-07
Iter: 1387 loss: 3.18386185e-07
Iter: 1388 loss: 3.1819971e-07
Iter: 1389 loss: 3.18247572e-07
Iter: 1390 loss: 3.18076957e-07
Iter: 1391 loss: 3.17922911e-07
Iter: 1392 loss: 3.17941215e-07
Iter: 1393 loss: 3.1777671e-07
Iter: 1394 loss: 3.17797884e-07
Iter: 1395 loss: 3.17641025e-07
Iter: 1396 loss: 3.17488372e-07
Iter: 1397 loss: 3.1745526e-07
Iter: 1398 loss: 3.17281263e-07
Iter: 1399 loss: 3.18662842e-07
Iter: 1400 loss: 3.17228626e-07
Iter: 1401 loss: 3.17023392e-07
Iter: 1402 loss: 3.1686568e-07
Iter: 1403 loss: 3.16835212e-07
Iter: 1404 loss: 3.16510807e-07
Iter: 1405 loss: 3.16967515e-07
Iter: 1406 loss: 3.16429663e-07
Iter: 1407 loss: 3.16173e-07
Iter: 1408 loss: 3.18493591e-07
Iter: 1409 loss: 3.16150192e-07
Iter: 1410 loss: 3.15938848e-07
Iter: 1411 loss: 3.17091974e-07
Iter: 1412 loss: 3.15836559e-07
Iter: 1413 loss: 3.15625527e-07
Iter: 1414 loss: 3.15651647e-07
Iter: 1415 loss: 3.1551312e-07
Iter: 1416 loss: 3.15280204e-07
Iter: 1417 loss: 3.15069258e-07
Iter: 1418 loss: 3.14972795e-07
Iter: 1419 loss: 3.14685707e-07
Iter: 1420 loss: 3.19719334e-07
Iter: 1421 loss: 3.14693466e-07
Iter: 1422 loss: 3.14360477e-07
Iter: 1423 loss: 3.15658724e-07
Iter: 1424 loss: 3.14275269e-07
Iter: 1425 loss: 3.14159649e-07
Iter: 1426 loss: 3.14548515e-07
Iter: 1427 loss: 3.14085e-07
Iter: 1428 loss: 3.13910277e-07
Iter: 1429 loss: 3.14063527e-07
Iter: 1430 loss: 3.13823648e-07
Iter: 1431 loss: 3.13602442e-07
Iter: 1432 loss: 3.14662543e-07
Iter: 1433 loss: 3.13561372e-07
Iter: 1434 loss: 3.13401756e-07
Iter: 1435 loss: 3.14039909e-07
Iter: 1436 loss: 3.13356708e-07
Iter: 1437 loss: 3.13310579e-07
Iter: 1438 loss: 3.13104835e-07
Iter: 1439 loss: 3.13085479e-07
Iter: 1440 loss: 3.12853018e-07
Iter: 1441 loss: 3.13478523e-07
Iter: 1442 loss: 3.12845771e-07
Iter: 1443 loss: 3.12708835e-07
Iter: 1444 loss: 3.12676235e-07
Iter: 1445 loss: 3.12570933e-07
Iter: 1446 loss: 3.12457075e-07
Iter: 1447 loss: 3.12441443e-07
Iter: 1448 loss: 3.12262955e-07
Iter: 1449 loss: 3.12044875e-07
Iter: 1450 loss: 3.12011281e-07
Iter: 1451 loss: 3.1169526e-07
Iter: 1452 loss: 3.13212837e-07
Iter: 1453 loss: 3.11664365e-07
Iter: 1454 loss: 3.11543772e-07
Iter: 1455 loss: 3.13510355e-07
Iter: 1456 loss: 3.11524303e-07
Iter: 1457 loss: 3.11303381e-07
Iter: 1458 loss: 3.11440886e-07
Iter: 1459 loss: 3.1114871e-07
Iter: 1460 loss: 3.11054038e-07
Iter: 1461 loss: 3.11812045e-07
Iter: 1462 loss: 3.1101797e-07
Iter: 1463 loss: 3.1085446e-07
Iter: 1464 loss: 3.11354967e-07
Iter: 1465 loss: 3.10836867e-07
Iter: 1466 loss: 3.1071221e-07
Iter: 1467 loss: 3.10716075e-07
Iter: 1468 loss: 3.10594487e-07
Iter: 1469 loss: 3.10473951e-07
Iter: 1470 loss: 3.11150671e-07
Iter: 1471 loss: 3.10392949e-07
Iter: 1472 loss: 3.10275738e-07
Iter: 1473 loss: 3.10084545e-07
Iter: 1474 loss: 3.10086904e-07
Iter: 1475 loss: 3.09824543e-07
Iter: 1476 loss: 3.10202068e-07
Iter: 1477 loss: 3.09713869e-07
Iter: 1478 loss: 3.09555e-07
Iter: 1479 loss: 3.09533476e-07
Iter: 1480 loss: 3.09374144e-07
Iter: 1481 loss: 3.09283109e-07
Iter: 1482 loss: 3.09196821e-07
Iter: 1483 loss: 3.0908123e-07
Iter: 1484 loss: 3.09158224e-07
Iter: 1485 loss: 3.08931135e-07
Iter: 1486 loss: 3.0874051e-07
Iter: 1487 loss: 3.09627183e-07
Iter: 1488 loss: 3.0868128e-07
Iter: 1489 loss: 3.08527348e-07
Iter: 1490 loss: 3.08611959e-07
Iter: 1491 loss: 3.08439439e-07
Iter: 1492 loss: 3.08387513e-07
Iter: 1493 loss: 3.0836253e-07
Iter: 1494 loss: 3.08238725e-07
Iter: 1495 loss: 3.0801877e-07
Iter: 1496 loss: 3.1096161e-07
Iter: 1497 loss: 3.08025619e-07
Iter: 1498 loss: 3.07865776e-07
Iter: 1499 loss: 3.07858983e-07
Iter: 1500 loss: 3.07775252e-07
Iter: 1501 loss: 3.07558395e-07
Iter: 1502 loss: 3.1217445e-07
Iter: 1503 loss: 3.0757738e-07
Iter: 1504 loss: 3.07339917e-07
Iter: 1505 loss: 3.07624305e-07
Iter: 1506 loss: 3.07171831e-07
Iter: 1507 loss: 3.07084207e-07
Iter: 1508 loss: 3.06987488e-07
Iter: 1509 loss: 3.06925358e-07
Iter: 1510 loss: 3.06708046e-07
Iter: 1511 loss: 3.1005851e-07
Iter: 1512 loss: 3.06704749e-07
Iter: 1513 loss: 3.06426699e-07
Iter: 1514 loss: 3.07089635e-07
Iter: 1515 loss: 3.06343537e-07
Iter: 1516 loss: 3.06196824e-07
Iter: 1517 loss: 3.06196966e-07
Iter: 1518 loss: 3.06048889e-07
Iter: 1519 loss: 3.05839251e-07
Iter: 1520 loss: 3.09902219e-07
Iter: 1521 loss: 3.05850108e-07
Iter: 1522 loss: 3.05546649e-07
Iter: 1523 loss: 3.05649735e-07
Iter: 1524 loss: 3.05326125e-07
Iter: 1525 loss: 3.04938084e-07
Iter: 1526 loss: 3.06915e-07
Iter: 1527 loss: 3.04894883e-07
Iter: 1528 loss: 3.04626582e-07
Iter: 1529 loss: 3.04634796e-07
Iter: 1530 loss: 3.04404153e-07
Iter: 1531 loss: 3.04337448e-07
Iter: 1532 loss: 3.04230866e-07
Iter: 1533 loss: 3.04070454e-07
Iter: 1534 loss: 3.05588031e-07
Iter: 1535 loss: 3.04016538e-07
Iter: 1536 loss: 3.03922207e-07
Iter: 1537 loss: 3.04219526e-07
Iter: 1538 loss: 3.03857178e-07
Iter: 1539 loss: 3.03732463e-07
Iter: 1540 loss: 3.03637506e-07
Iter: 1541 loss: 3.03592856e-07
Iter: 1542 loss: 3.03508614e-07
Iter: 1543 loss: 3.03469051e-07
Iter: 1544 loss: 3.03424827e-07
Iter: 1545 loss: 3.03254239e-07
Iter: 1546 loss: 3.05120864e-07
Iter: 1547 loss: 3.03231303e-07
Iter: 1548 loss: 3.02938332e-07
Iter: 1549 loss: 3.02956948e-07
Iter: 1550 loss: 3.02762317e-07
Iter: 1551 loss: 3.02456186e-07
Iter: 1552 loss: 3.05786443e-07
Iter: 1553 loss: 3.02498051e-07
Iter: 1554 loss: 3.02234838e-07
Iter: 1555 loss: 3.03036131e-07
Iter: 1556 loss: 3.0217177e-07
Iter: 1557 loss: 3.01988649e-07
Iter: 1558 loss: 3.01891447e-07
Iter: 1559 loss: 3.01855408e-07
Iter: 1560 loss: 3.01650857e-07
Iter: 1561 loss: 3.02756945e-07
Iter: 1562 loss: 3.0166791e-07
Iter: 1563 loss: 3.0153987e-07
Iter: 1564 loss: 3.01528786e-07
Iter: 1565 loss: 3.01439059e-07
Iter: 1566 loss: 3.01319801e-07
Iter: 1567 loss: 3.03741217e-07
Iter: 1568 loss: 3.01275065e-07
Iter: 1569 loss: 3.01239538e-07
Iter: 1570 loss: 3.01208672e-07
Iter: 1571 loss: 3.01156575e-07
Iter: 1572 loss: 3.00989029e-07
Iter: 1573 loss: 3.04672199e-07
Iter: 1574 loss: 3.00957851e-07
Iter: 1575 loss: 3.00794682e-07
Iter: 1576 loss: 3.01428969e-07
Iter: 1577 loss: 3.00754e-07
Iter: 1578 loss: 3.00554433e-07
Iter: 1579 loss: 3.0068523e-07
Iter: 1580 loss: 3.00397744e-07
Iter: 1581 loss: 3.00239861e-07
Iter: 1582 loss: 3.00413035e-07
Iter: 1583 loss: 3.00112333e-07
Iter: 1584 loss: 2.99900876e-07
Iter: 1585 loss: 2.99920458e-07
Iter: 1586 loss: 2.99795431e-07
Iter: 1587 loss: 2.99600742e-07
Iter: 1588 loss: 2.99617142e-07
Iter: 1589 loss: 2.99480178e-07
Iter: 1590 loss: 3.00035595e-07
Iter: 1591 loss: 2.99434106e-07
Iter: 1592 loss: 2.99333749e-07
Iter: 1593 loss: 2.99196302e-07
Iter: 1594 loss: 3.02048136e-07
Iter: 1595 loss: 2.99145256e-07
Iter: 1596 loss: 2.99022275e-07
Iter: 1597 loss: 3.01090807e-07
Iter: 1598 loss: 2.99007e-07
Iter: 1599 loss: 2.98780321e-07
Iter: 1600 loss: 2.99894367e-07
Iter: 1601 loss: 2.98775092e-07
Iter: 1602 loss: 2.98631363e-07
Iter: 1603 loss: 2.9844864e-07
Iter: 1604 loss: 3.0397382e-07
Iter: 1605 loss: 2.98433861e-07
Iter: 1606 loss: 2.98277911e-07
Iter: 1607 loss: 2.98307384e-07
Iter: 1608 loss: 2.98159e-07
Iter: 1609 loss: 2.98056875e-07
Iter: 1610 loss: 2.98035815e-07
Iter: 1611 loss: 2.97923179e-07
Iter: 1612 loss: 2.99622513e-07
Iter: 1613 loss: 2.97893564e-07
Iter: 1614 loss: 2.97815831e-07
Iter: 1615 loss: 2.97650871e-07
Iter: 1616 loss: 2.97663149e-07
Iter: 1617 loss: 2.97547359e-07
Iter: 1618 loss: 2.98021348e-07
Iter: 1619 loss: 2.97502595e-07
Iter: 1620 loss: 2.97374356e-07
Iter: 1621 loss: 2.97574275e-07
Iter: 1622 loss: 2.97336328e-07
Iter: 1623 loss: 2.9724194e-07
Iter: 1624 loss: 2.98164537e-07
Iter: 1625 loss: 2.97213319e-07
Iter: 1626 loss: 2.97091816e-07
Iter: 1627 loss: 2.96985974e-07
Iter: 1628 loss: 2.96989668e-07
Iter: 1629 loss: 2.96827523e-07
Iter: 1630 loss: 2.97694271e-07
Iter: 1631 loss: 2.96799556e-07
Iter: 1632 loss: 2.96710368e-07
Iter: 1633 loss: 2.97930626e-07
Iter: 1634 loss: 2.96687887e-07
Iter: 1635 loss: 2.96639e-07
Iter: 1636 loss: 2.9641933e-07
Iter: 1637 loss: 3.00493468e-07
Iter: 1638 loss: 2.96402447e-07
Iter: 1639 loss: 2.96304449e-07
Iter: 1640 loss: 2.96311669e-07
Iter: 1641 loss: 2.96193832e-07
Iter: 1642 loss: 2.96306837e-07
Iter: 1643 loss: 2.96104361e-07
Iter: 1644 loss: 2.96042572e-07
Iter: 1645 loss: 2.96272901e-07
Iter: 1646 loss: 2.96012786e-07
Iter: 1647 loss: 2.95879516e-07
Iter: 1648 loss: 2.96090633e-07
Iter: 1649 loss: 2.95813948e-07
Iter: 1650 loss: 2.95714017e-07
Iter: 1651 loss: 2.95606355e-07
Iter: 1652 loss: 2.95583249e-07
Iter: 1653 loss: 2.95382051e-07
Iter: 1654 loss: 2.96441868e-07
Iter: 1655 loss: 2.95351782e-07
Iter: 1656 loss: 2.95286071e-07
Iter: 1657 loss: 2.96339437e-07
Iter: 1658 loss: 2.95230478e-07
Iter: 1659 loss: 2.95115342e-07
Iter: 1660 loss: 2.95058442e-07
Iter: 1661 loss: 2.95042355e-07
Iter: 1662 loss: 2.94861422e-07
Iter: 1663 loss: 2.94935745e-07
Iter: 1664 loss: 2.94761549e-07
Iter: 1665 loss: 2.9468373e-07
Iter: 1666 loss: 2.9461566e-07
Iter: 1667 loss: 2.94545373e-07
Iter: 1668 loss: 2.94630297e-07
Iter: 1669 loss: 2.94508368e-07
Iter: 1670 loss: 2.94417077e-07
Iter: 1671 loss: 2.94455333e-07
Iter: 1672 loss: 2.94367e-07
Iter: 1673 loss: 2.9423768e-07
Iter: 1674 loss: 2.9537847e-07
Iter: 1675 loss: 2.94271587e-07
Iter: 1676 loss: 2.94164664e-07
Iter: 1677 loss: 2.94065899e-07
Iter: 1678 loss: 2.94036198e-07
Iter: 1679 loss: 2.9395909e-07
Iter: 1680 loss: 2.95045737e-07
Iter: 1681 loss: 2.93944368e-07
Iter: 1682 loss: 2.93883204e-07
Iter: 1683 loss: 2.93723872e-07
Iter: 1684 loss: 2.97252257e-07
Iter: 1685 loss: 2.9370139e-07
Iter: 1686 loss: 2.93498545e-07
Iter: 1687 loss: 2.94129109e-07
Iter: 1688 loss: 2.93406828e-07
Iter: 1689 loss: 2.93267192e-07
Iter: 1690 loss: 2.93276543e-07
Iter: 1691 loss: 2.93147e-07
Iter: 1692 loss: 2.93156e-07
Iter: 1693 loss: 2.93023732e-07
Iter: 1694 loss: 2.92889553e-07
Iter: 1695 loss: 2.92978939e-07
Iter: 1696 loss: 2.92782943e-07
Iter: 1697 loss: 2.92643733e-07
Iter: 1698 loss: 2.93840486e-07
Iter: 1699 loss: 2.92634496e-07
Iter: 1700 loss: 2.92509071e-07
Iter: 1701 loss: 2.93589125e-07
Iter: 1702 loss: 2.92471e-07
Iter: 1703 loss: 2.92447169e-07
Iter: 1704 loss: 2.92344225e-07
Iter: 1705 loss: 2.92362529e-07
Iter: 1706 loss: 2.92242646e-07
Iter: 1707 loss: 2.92255777e-07
Iter: 1708 loss: 2.92139333e-07
Iter: 1709 loss: 2.92088515e-07
Iter: 1710 loss: 2.92050288e-07
Iter: 1711 loss: 2.91951238e-07
Iter: 1712 loss: 2.93051329e-07
Iter: 1713 loss: 2.91918553e-07
Iter: 1714 loss: 2.91846902e-07
Iter: 1715 loss: 2.91846362e-07
Iter: 1716 loss: 2.91732903e-07
Iter: 1717 loss: 2.9169567e-07
Iter: 1718 loss: 2.91756805e-07
Iter: 1719 loss: 2.916141e-07
Iter: 1720 loss: 2.91540601e-07
Iter: 1721 loss: 2.91803104e-07
Iter: 1722 loss: 2.9148805e-07
Iter: 1723 loss: 2.91348556e-07
Iter: 1724 loss: 2.92071604e-07
Iter: 1725 loss: 2.91380275e-07
Iter: 1726 loss: 2.91307657e-07
Iter: 1727 loss: 2.91224666e-07
Iter: 1728 loss: 2.91257408e-07
Iter: 1729 loss: 2.91114191e-07
Iter: 1730 loss: 2.91165406e-07
Iter: 1731 loss: 2.91049503e-07
Iter: 1732 loss: 2.90895144e-07
Iter: 1733 loss: 2.92256402e-07
Iter: 1734 loss: 2.90876898e-07
Iter: 1735 loss: 2.90806952e-07
Iter: 1736 loss: 2.90652252e-07
Iter: 1737 loss: 2.90680134e-07
Iter: 1738 loss: 2.90535439e-07
Iter: 1739 loss: 2.91791736e-07
Iter: 1740 loss: 2.90526856e-07
Iter: 1741 loss: 2.90459951e-07
Iter: 1742 loss: 2.90496956e-07
Iter: 1743 loss: 2.90426442e-07
Iter: 1744 loss: 2.90299738e-07
Iter: 1745 loss: 2.9061e-07
Iter: 1746 loss: 2.90263074e-07
Iter: 1747 loss: 2.90168771e-07
Iter: 1748 loss: 2.90504886e-07
Iter: 1749 loss: 2.90157175e-07
Iter: 1750 loss: 2.90067021e-07
Iter: 1751 loss: 2.89940715e-07
Iter: 1752 loss: 2.89919484e-07
Iter: 1753 loss: 2.89860282e-07
Iter: 1754 loss: 2.908196e-07
Iter: 1755 loss: 2.89826033e-07
Iter: 1756 loss: 2.89748897e-07
Iter: 1757 loss: 2.90336857e-07
Iter: 1758 loss: 2.89725136e-07
Iter: 1759 loss: 2.89654e-07
Iter: 1760 loss: 2.89506545e-07
Iter: 1761 loss: 2.89462577e-07
Iter: 1762 loss: 2.89339027e-07
Iter: 1763 loss: 2.89590361e-07
Iter: 1764 loss: 2.89336981e-07
Iter: 1765 loss: 2.8922571e-07
Iter: 1766 loss: 2.9035283e-07
Iter: 1767 loss: 2.89234492e-07
Iter: 1768 loss: 2.8911748e-07
Iter: 1769 loss: 2.89363015e-07
Iter: 1770 loss: 2.89026104e-07
Iter: 1771 loss: 2.88981028e-07
Iter: 1772 loss: 2.89080106e-07
Iter: 1773 loss: 2.88926373e-07
Iter: 1774 loss: 2.88897411e-07
Iter: 1775 loss: 2.89554919e-07
Iter: 1776 loss: 2.88924355e-07
Iter: 1777 loss: 2.88855176e-07
Iter: 1778 loss: 2.88738903e-07
Iter: 1779 loss: 2.8877048e-07
Iter: 1780 loss: 2.88643548e-07
Iter: 1781 loss: 2.89698221e-07
Iter: 1782 loss: 2.8861291e-07
Iter: 1783 loss: 2.88581873e-07
Iter: 1784 loss: 2.88450025e-07
Iter: 1785 loss: 2.88432034e-07
Iter: 1786 loss: 2.88279523e-07
Iter: 1787 loss: 2.88592503e-07
Iter: 1788 loss: 2.88198805e-07
Iter: 1789 loss: 2.88046721e-07
Iter: 1790 loss: 2.89007687e-07
Iter: 1791 loss: 2.88026371e-07
Iter: 1792 loss: 2.87883751e-07
Iter: 1793 loss: 2.88213954e-07
Iter: 1794 loss: 2.87852714e-07
Iter: 1795 loss: 2.87771115e-07
Iter: 1796 loss: 2.87628154e-07
Iter: 1797 loss: 2.87604422e-07
Iter: 1798 loss: 2.87432073e-07
Iter: 1799 loss: 2.87629121e-07
Iter: 1800 loss: 2.8731742e-07
Iter: 1801 loss: 2.87165562e-07
Iter: 1802 loss: 2.8825e-07
Iter: 1803 loss: 2.87114773e-07
Iter: 1804 loss: 2.87018253e-07
Iter: 1805 loss: 2.87197452e-07
Iter: 1806 loss: 2.86960301e-07
Iter: 1807 loss: 2.8693006e-07
Iter: 1808 loss: 2.86918123e-07
Iter: 1809 loss: 2.86846131e-07
Iter: 1810 loss: 2.8680779e-07
Iter: 1811 loss: 2.86758564e-07
Iter: 1812 loss: 2.86672105e-07
Iter: 1813 loss: 2.8656126e-07
Iter: 1814 loss: 2.86564443e-07
Iter: 1815 loss: 2.86529797e-07
Iter: 1816 loss: 2.86549465e-07
Iter: 1817 loss: 2.86462864e-07
Iter: 1818 loss: 2.864534e-07
Iter: 1819 loss: 2.8641287e-07
Iter: 1820 loss: 2.86394084e-07
Iter: 1821 loss: 2.8663365e-07
Iter: 1822 loss: 2.86341447e-07
Iter: 1823 loss: 2.86273263e-07
Iter: 1824 loss: 2.86209513e-07
Iter: 1825 loss: 2.86213975e-07
Iter: 1826 loss: 2.86099123e-07
Iter: 1827 loss: 2.86408209e-07
Iter: 1828 loss: 2.86055922e-07
Iter: 1829 loss: 2.85952893e-07
Iter: 1830 loss: 2.86868129e-07
Iter: 1831 loss: 2.85953405e-07
Iter: 1832 loss: 2.85907674e-07
Iter: 1833 loss: 2.85803338e-07
Iter: 1834 loss: 2.85799729e-07
Iter: 1835 loss: 2.85672229e-07
Iter: 1836 loss: 2.85836933e-07
Iter: 1837 loss: 2.85605751e-07
Iter: 1838 loss: 2.85425727e-07
Iter: 1839 loss: 2.85626982e-07
Iter: 1840 loss: 2.85390939e-07
Iter: 1841 loss: 2.85308204e-07
Iter: 1842 loss: 2.85300871e-07
Iter: 1843 loss: 2.85222541e-07
Iter: 1844 loss: 2.8511954e-07
Iter: 1845 loss: 2.85094018e-07
Iter: 1846 loss: 2.85056785e-07
Iter: 1847 loss: 2.85454632e-07
Iter: 1848 loss: 2.85047321e-07
Iter: 1849 loss: 2.84945628e-07
Iter: 1850 loss: 2.85148332e-07
Iter: 1851 loss: 2.84914847e-07
Iter: 1852 loss: 2.84804685e-07
Iter: 1853 loss: 2.84893133e-07
Iter: 1854 loss: 2.84766742e-07
Iter: 1855 loss: 2.84704015e-07
Iter: 1856 loss: 2.85888632e-07
Iter: 1857 loss: 2.84703532e-07
Iter: 1858 loss: 2.84662065e-07
Iter: 1859 loss: 2.8454042e-07
Iter: 1860 loss: 2.8699688e-07
Iter: 1861 loss: 2.84513476e-07
Iter: 1862 loss: 2.84419627e-07
Iter: 1863 loss: 2.85728589e-07
Iter: 1864 loss: 2.84431593e-07
Iter: 1865 loss: 2.84323306e-07
Iter: 1866 loss: 2.84278684e-07
Iter: 1867 loss: 2.8419484e-07
Iter: 1868 loss: 2.8409724e-07
Iter: 1869 loss: 2.84485708e-07
Iter: 1870 loss: 2.84083e-07
Iter: 1871 loss: 2.83965278e-07
Iter: 1872 loss: 2.8413811e-07
Iter: 1873 loss: 2.83886436e-07
Iter: 1874 loss: 2.83789575e-07
Iter: 1875 loss: 2.83820299e-07
Iter: 1876 loss: 2.83780423e-07
Iter: 1877 loss: 2.8386026e-07
Iter: 1878 loss: 2.83712779e-07
Iter: 1879 loss: 2.83651275e-07
Iter: 1880 loss: 2.83563082e-07
Iter: 1881 loss: 2.83534746e-07
Iter: 1882 loss: 2.83435497e-07
Iter: 1883 loss: 2.83447918e-07
Iter: 1884 loss: 2.83351312e-07
Iter: 1885 loss: 2.83227479e-07
Iter: 1886 loss: 2.83206305e-07
Iter: 1887 loss: 2.83053794e-07
Iter: 1888 loss: 2.83470371e-07
Iter: 1889 loss: 2.82996098e-07
Iter: 1890 loss: 2.828167e-07
Iter: 1891 loss: 2.82819371e-07
Iter: 1892 loss: 2.82627639e-07
Iter: 1893 loss: 2.8257648e-07
Iter: 1894 loss: 2.8257503e-07
Iter: 1895 loss: 2.82442301e-07
Iter: 1896 loss: 2.82430562e-07
Iter: 1897 loss: 2.82405e-07
Iter: 1898 loss: 2.82208759e-07
Iter: 1899 loss: 2.84587458e-07
Iter: 1900 loss: 2.82231809e-07
Iter: 1901 loss: 2.82047608e-07
Iter: 1902 loss: 2.83005136e-07
Iter: 1903 loss: 2.8200526e-07
Iter: 1904 loss: 2.8193017e-07
Iter: 1905 loss: 2.81987496e-07
Iter: 1906 loss: 2.81866619e-07
Iter: 1907 loss: 2.81753842e-07
Iter: 1908 loss: 2.8274124e-07
Iter: 1909 loss: 2.81772031e-07
Iter: 1910 loss: 2.81601785e-07
Iter: 1911 loss: 2.81666928e-07
Iter: 1912 loss: 2.81531243e-07
Iter: 1913 loss: 2.8144467e-07
Iter: 1914 loss: 2.81480226e-07
Iter: 1915 loss: 2.81339624e-07
Iter: 1916 loss: 2.81200812e-07
Iter: 1917 loss: 2.83086337e-07
Iter: 1918 loss: 2.81203711e-07
Iter: 1919 loss: 2.81081469e-07
Iter: 1920 loss: 2.80889878e-07
Iter: 1921 loss: 2.85851712e-07
Iter: 1922 loss: 2.80911649e-07
Iter: 1923 loss: 2.80702324e-07
Iter: 1924 loss: 2.8185994e-07
Iter: 1925 loss: 2.80674755e-07
Iter: 1926 loss: 2.80550267e-07
Iter: 1927 loss: 2.81602496e-07
Iter: 1928 loss: 2.80507408e-07
Iter: 1929 loss: 2.80411854e-07
Iter: 1930 loss: 2.80253232e-07
Iter: 1931 loss: 2.80240613e-07
Iter: 1932 loss: 2.80089523e-07
Iter: 1933 loss: 2.80315135e-07
Iter: 1934 loss: 2.80038137e-07
Iter: 1935 loss: 2.79856835e-07
Iter: 1936 loss: 2.81226363e-07
Iter: 1937 loss: 2.7985979e-07
Iter: 1938 loss: 2.79659332e-07
Iter: 1939 loss: 2.79693978e-07
Iter: 1940 loss: 2.79506594e-07
Iter: 1941 loss: 2.79383244e-07
Iter: 1942 loss: 2.80043139e-07
Iter: 1943 loss: 2.79346892e-07
Iter: 1944 loss: 2.7925995e-07
Iter: 1945 loss: 2.79230107e-07
Iter: 1946 loss: 2.79192847e-07
Iter: 1947 loss: 2.79076517e-07
Iter: 1948 loss: 2.79091893e-07
Iter: 1949 loss: 2.7891258e-07
Iter: 1950 loss: 2.78944555e-07
Iter: 1951 loss: 2.78806283e-07
Iter: 1952 loss: 2.78696689e-07
Iter: 1953 loss: 2.78682649e-07
Iter: 1954 loss: 2.78654909e-07
Iter: 1955 loss: 2.79240425e-07
Iter: 1956 loss: 2.78580217e-07
Iter: 1957 loss: 2.78515927e-07
Iter: 1958 loss: 2.78422931e-07
Iter: 1959 loss: 2.78446e-07
Iter: 1960 loss: 2.78313792e-07
Iter: 1961 loss: 2.78291111e-07
Iter: 1962 loss: 2.78252116e-07
Iter: 1963 loss: 2.781494e-07
Iter: 1964 loss: 2.80754023e-07
Iter: 1965 loss: 2.78099861e-07
Iter: 1966 loss: 2.77951415e-07
Iter: 1967 loss: 2.78490234e-07
Iter: 1968 loss: 2.77902785e-07
Iter: 1969 loss: 2.77773466e-07
Iter: 1970 loss: 2.79012454e-07
Iter: 1971 loss: 2.77774916e-07
Iter: 1972 loss: 2.77609104e-07
Iter: 1973 loss: 2.7775144e-07
Iter: 1974 loss: 2.77496099e-07
Iter: 1975 loss: 2.77373772e-07
Iter: 1976 loss: 2.77634626e-07
Iter: 1977 loss: 2.77315422e-07
Iter: 1978 loss: 2.77239877e-07
Iter: 1979 loss: 2.77252383e-07
Iter: 1980 loss: 2.77152083e-07
Iter: 1981 loss: 2.77020206e-07
Iter: 1982 loss: 2.80195394e-07
Iter: 1983 loss: 2.77026771e-07
Iter: 1984 loss: 2.76911578e-07
Iter: 1985 loss: 2.77413022e-07
Iter: 1986 loss: 2.76813779e-07
Iter: 1987 loss: 2.7670967e-07
Iter: 1988 loss: 2.77930098e-07
Iter: 1989 loss: 2.7672e-07
Iter: 1990 loss: 2.76595301e-07
Iter: 1991 loss: 2.76743094e-07
Iter: 1992 loss: 2.76559263e-07
Iter: 1993 loss: 2.76449015e-07
Iter: 1994 loss: 2.76694777e-07
Iter: 1995 loss: 2.76401835e-07
Iter: 1996 loss: 2.76259584e-07
Iter: 1997 loss: 2.76317735e-07
Iter: 1998 loss: 2.76164286e-07
Iter: 1999 loss: 2.76032949e-07
Iter: 2000 loss: 2.76122393e-07
Iter: 2001 loss: 2.75950697e-07
Iter: 2002 loss: 2.7579506e-07
Iter: 2003 loss: 2.76327086e-07
Iter: 2004 loss: 2.75750494e-07
Iter: 2005 loss: 2.75685125e-07
Iter: 2006 loss: 2.75696635e-07
Iter: 2007 loss: 2.75586046e-07
Iter: 2008 loss: 2.75532216e-07
Iter: 2009 loss: 2.75492283e-07
Iter: 2010 loss: 2.75371974e-07
Iter: 2011 loss: 2.7637617e-07
Iter: 2012 loss: 2.75405114e-07
Iter: 2013 loss: 2.75284322e-07
Iter: 2014 loss: 2.75544892e-07
Iter: 2015 loss: 2.75278836e-07
Iter: 2016 loss: 2.75202439e-07
Iter: 2017 loss: 2.75129736e-07
Iter: 2018 loss: 2.75061723e-07
Iter: 2019 loss: 2.7500036e-07
Iter: 2020 loss: 2.75810265e-07
Iter: 2021 loss: 2.74970773e-07
Iter: 2022 loss: 2.74851658e-07
Iter: 2023 loss: 2.75210084e-07
Iter: 2024 loss: 2.74766933e-07
Iter: 2025 loss: 2.74688205e-07
Iter: 2026 loss: 2.7502324e-07
Iter: 2027 loss: 2.74647704e-07
Iter: 2028 loss: 2.74555219e-07
Iter: 2029 loss: 2.75510672e-07
Iter: 2030 loss: 2.74530919e-07
Iter: 2031 loss: 2.74471233e-07
Iter: 2032 loss: 2.74407256e-07
Iter: 2033 loss: 2.76537e-07
Iter: 2034 loss: 2.74382927e-07
Iter: 2035 loss: 2.74256848e-07
Iter: 2036 loss: 2.74549706e-07
Iter: 2037 loss: 2.74209157e-07
Iter: 2038 loss: 2.74133299e-07
Iter: 2039 loss: 2.7411906e-07
Iter: 2040 loss: 2.74059715e-07
Iter: 2041 loss: 2.74119259e-07
Iter: 2042 loss: 2.74046243e-07
Iter: 2043 loss: 2.7393861e-07
Iter: 2044 loss: 2.73808979e-07
Iter: 2045 loss: 2.73808155e-07
Iter: 2046 loss: 2.73784707e-07
Iter: 2047 loss: 2.73764044e-07
Iter: 2048 loss: 2.73700266e-07
Iter: 2049 loss: 2.73613665e-07
Iter: 2050 loss: 2.73607213e-07
Iter: 2051 loss: 2.73548551e-07
Iter: 2052 loss: 2.73462518e-07
Iter: 2053 loss: 2.73404282e-07
Iter: 2054 loss: 2.73364066e-07
Iter: 2055 loss: 2.73395386e-07
Iter: 2056 loss: 2.73246485e-07
Iter: 2057 loss: 2.7347582e-07
Iter: 2058 loss: 2.73267176e-07
Iter: 2059 loss: 2.7323037e-07
Iter: 2060 loss: 2.73180262e-07
Iter: 2061 loss: 2.73122509e-07
Iter: 2062 loss: 2.73009846e-07
Iter: 2063 loss: 2.74265716e-07
Iter: 2064 loss: 2.73045032e-07
Iter: 2065 loss: 2.73008169e-07
Iter: 2066 loss: 2.72901701e-07
Iter: 2067 loss: 2.74619083e-07
Iter: 2068 loss: 2.72855431e-07
Iter: 2069 loss: 2.72775935e-07
Iter: 2070 loss: 2.72843721e-07
Iter: 2071 loss: 2.72667364e-07
Iter: 2072 loss: 2.72588323e-07
Iter: 2073 loss: 2.73260497e-07
Iter: 2074 loss: 2.72577779e-07
Iter: 2075 loss: 2.72451075e-07
Iter: 2076 loss: 2.72675209e-07
Iter: 2077 loss: 2.72409721e-07
Iter: 2078 loss: 2.72331675e-07
Iter: 2079 loss: 2.72288077e-07
Iter: 2080 loss: 2.72251441e-07
Iter: 2081 loss: 2.72185218e-07
Iter: 2082 loss: 2.72129512e-07
Iter: 2083 loss: 2.72073663e-07
Iter: 2084 loss: 2.72138664e-07
Iter: 2085 loss: 2.72023215e-07
Iter: 2086 loss: 2.71985243e-07
Iter: 2087 loss: 2.71787314e-07
Iter: 2088 loss: 2.73573505e-07
Iter: 2089 loss: 2.71805163e-07
Iter: 2090 loss: 2.716464e-07
Iter: 2091 loss: 2.73276669e-07
Iter: 2092 loss: 2.71633496e-07
Iter: 2093 loss: 2.71533651e-07
Iter: 2094 loss: 2.72283557e-07
Iter: 2095 loss: 2.71502472e-07
Iter: 2096 loss: 2.71395862e-07
Iter: 2097 loss: 2.71979303e-07
Iter: 2098 loss: 2.71401348e-07
Iter: 2099 loss: 2.71319635e-07
Iter: 2100 loss: 2.71355134e-07
Iter: 2101 loss: 2.71304742e-07
Iter: 2102 loss: 2.71190061e-07
Iter: 2103 loss: 2.71911119e-07
Iter: 2104 loss: 2.71184945e-07
Iter: 2105 loss: 2.71133274e-07
Iter: 2106 loss: 2.71066881e-07
Iter: 2107 loss: 2.73030338e-07
Iter: 2108 loss: 2.71043518e-07
Iter: 2109 loss: 2.70963568e-07
Iter: 2110 loss: 2.71980355e-07
Iter: 2111 loss: 2.7096155e-07
Iter: 2112 loss: 2.70865115e-07
Iter: 2113 loss: 2.71034e-07
Iter: 2114 loss: 2.70848147e-07
Iter: 2115 loss: 2.70816116e-07
Iter: 2116 loss: 2.70955297e-07
Iter: 2117 loss: 2.70795226e-07
Iter: 2118 loss: 2.70728492e-07
Iter: 2119 loss: 2.70592636e-07
Iter: 2120 loss: 2.72709315e-07
Iter: 2121 loss: 2.70648229e-07
Iter: 2122 loss: 2.70468746e-07
Iter: 2123 loss: 2.70984856e-07
Iter: 2124 loss: 2.70438079e-07
Iter: 2125 loss: 2.70321323e-07
Iter: 2126 loss: 2.7035685e-07
Iter: 2127 loss: 2.70225627e-07
Iter: 2128 loss: 2.70106199e-07
Iter: 2129 loss: 2.70830895e-07
Iter: 2130 loss: 2.70052567e-07
Iter: 2131 loss: 2.69977733e-07
Iter: 2132 loss: 2.70981502e-07
Iter: 2133 loss: 2.69953063e-07
Iter: 2134 loss: 2.69829115e-07
Iter: 2135 loss: 2.69816866e-07
Iter: 2136 loss: 2.69678566e-07
Iter: 2137 loss: 2.69593386e-07
Iter: 2138 loss: 2.70017e-07
Iter: 2139 loss: 2.69567721e-07
Iter: 2140 loss: 2.69438885e-07
Iter: 2141 loss: 2.70574589e-07
Iter: 2142 loss: 2.69415864e-07
Iter: 2143 loss: 2.69331224e-07
Iter: 2144 loss: 2.69188718e-07
Iter: 2145 loss: 2.6917337e-07
Iter: 2146 loss: 2.690565e-07
Iter: 2147 loss: 2.69789581e-07
Iter: 2148 loss: 2.69027566e-07
Iter: 2149 loss: 2.68898532e-07
Iter: 2150 loss: 2.69195908e-07
Iter: 2151 loss: 2.68874828e-07
Iter: 2152 loss: 2.68795645e-07
Iter: 2153 loss: 2.69113372e-07
Iter: 2154 loss: 2.68764751e-07
Iter: 2155 loss: 2.68645636e-07
Iter: 2156 loss: 2.68989851e-07
Iter: 2157 loss: 2.68607494e-07
Iter: 2158 loss: 2.68560314e-07
Iter: 2159 loss: 2.68455494e-07
Iter: 2160 loss: 2.68472604e-07
Iter: 2161 loss: 2.68330837e-07
Iter: 2162 loss: 2.6885e-07
Iter: 2163 loss: 2.68299743e-07
Iter: 2164 loss: 2.68196857e-07
Iter: 2165 loss: 2.68315091e-07
Iter: 2166 loss: 2.68120885e-07
Iter: 2167 loss: 2.68140838e-07
Iter: 2168 loss: 2.6805256e-07
Iter: 2169 loss: 2.68014162e-07
Iter: 2170 loss: 2.67954221e-07
Iter: 2171 loss: 2.67963429e-07
Iter: 2172 loss: 2.67855114e-07
Iter: 2173 loss: 2.68707282e-07
Iter: 2174 loss: 2.67840647e-07
Iter: 2175 loss: 2.6776658e-07
Iter: 2176 loss: 2.67676313e-07
Iter: 2177 loss: 2.67650648e-07
Iter: 2178 loss: 2.67555265e-07
Iter: 2179 loss: 2.68950942e-07
Iter: 2180 loss: 2.67534631e-07
Iter: 2181 loss: 2.67447035e-07
Iter: 2182 loss: 2.67844314e-07
Iter: 2183 loss: 2.67447916e-07
Iter: 2184 loss: 2.67371036e-07
Iter: 2185 loss: 2.6740662e-07
Iter: 2186 loss: 2.67328716e-07
Iter: 2187 loss: 2.67250016e-07
Iter: 2188 loss: 2.67932506e-07
Iter: 2189 loss: 2.67235151e-07
Iter: 2190 loss: 2.67172311e-07
Iter: 2191 loss: 2.67109613e-07
Iter: 2192 loss: 2.67111318e-07
Iter: 2193 loss: 2.66977054e-07
Iter: 2194 loss: 2.67012e-07
Iter: 2195 loss: 2.66910916e-07
Iter: 2196 loss: 2.66751243e-07
Iter: 2197 loss: 2.67892176e-07
Iter: 2198 loss: 2.66775146e-07
Iter: 2199 loss: 2.66698493e-07
Iter: 2200 loss: 2.67200733e-07
Iter: 2201 loss: 2.66624028e-07
Iter: 2202 loss: 2.66531714e-07
Iter: 2203 loss: 2.66554594e-07
Iter: 2204 loss: 2.6645003e-07
Iter: 2205 loss: 2.66279102e-07
Iter: 2206 loss: 2.66902589e-07
Iter: 2207 loss: 2.66244399e-07
Iter: 2208 loss: 2.66088705e-07
Iter: 2209 loss: 2.66756189e-07
Iter: 2210 loss: 2.66093593e-07
Iter: 2211 loss: 2.65992639e-07
Iter: 2212 loss: 2.65917521e-07
Iter: 2213 loss: 2.65901235e-07
Iter: 2214 loss: 2.65815117e-07
Iter: 2215 loss: 2.67323344e-07
Iter: 2216 loss: 2.65812872e-07
Iter: 2217 loss: 2.65707712e-07
Iter: 2218 loss: 2.65731813e-07
Iter: 2219 loss: 2.65650414e-07
Iter: 2220 loss: 2.65556821e-07
Iter: 2221 loss: 2.66315624e-07
Iter: 2222 loss: 2.65550682e-07
Iter: 2223 loss: 2.65444243e-07
Iter: 2224 loss: 2.65398342e-07
Iter: 2225 loss: 2.6538828e-07
Iter: 2226 loss: 2.65269819e-07
Iter: 2227 loss: 2.65229914e-07
Iter: 2228 loss: 2.65114608e-07
Iter: 2229 loss: 2.6491665e-07
Iter: 2230 loss: 2.65246712e-07
Iter: 2231 loss: 2.64894766e-07
Iter: 2232 loss: 2.64635787e-07
Iter: 2233 loss: 2.64937626e-07
Iter: 2234 loss: 2.64529348e-07
Iter: 2235 loss: 2.64329913e-07
Iter: 2236 loss: 2.64334943e-07
Iter: 2237 loss: 2.64241436e-07
Iter: 2238 loss: 2.64257096e-07
Iter: 2239 loss: 2.64133519e-07
Iter: 2240 loss: 2.640638e-07
Iter: 2241 loss: 2.64052062e-07
Iter: 2242 loss: 2.63994224e-07
Iter: 2243 loss: 2.63961624e-07
Iter: 2244 loss: 2.6392064e-07
Iter: 2245 loss: 2.63847568e-07
Iter: 2246 loss: 2.6413187e-07
Iter: 2247 loss: 2.63768783e-07
Iter: 2248 loss: 2.63691163e-07
Iter: 2249 loss: 2.64636782e-07
Iter: 2250 loss: 2.6365305e-07
Iter: 2251 loss: 2.63580262e-07
Iter: 2252 loss: 2.63601578e-07
Iter: 2253 loss: 2.63544507e-07
Iter: 2254 loss: 2.63435965e-07
Iter: 2255 loss: 2.64751833e-07
Iter: 2256 loss: 2.6344776e-07
Iter: 2257 loss: 2.63346379e-07
Iter: 2258 loss: 2.6328712e-07
Iter: 2259 loss: 2.63255629e-07
Iter: 2260 loss: 2.63188525e-07
Iter: 2261 loss: 2.63239201e-07
Iter: 2262 loss: 2.63115595e-07
Iter: 2263 loss: 2.63035759e-07
Iter: 2264 loss: 2.63598224e-07
Iter: 2265 loss: 2.6297198e-07
Iter: 2266 loss: 2.6293452e-07
Iter: 2267 loss: 2.6398763e-07
Iter: 2268 loss: 2.62899505e-07
Iter: 2269 loss: 2.62837375e-07
Iter: 2270 loss: 2.62885976e-07
Iter: 2271 loss: 2.62795311e-07
Iter: 2272 loss: 2.62752707e-07
Iter: 2273 loss: 2.62987868e-07
Iter: 2274 loss: 2.62710671e-07
Iter: 2275 loss: 2.62632113e-07
Iter: 2276 loss: 2.6263919e-07
Iter: 2277 loss: 2.62589083e-07
Iter: 2278 loss: 2.62477613e-07
Iter: 2279 loss: 2.62491255e-07
Iter: 2280 loss: 2.62377455e-07
Iter: 2281 loss: 2.6230407e-07
Iter: 2282 loss: 2.638441e-07
Iter: 2283 loss: 2.62277808e-07
Iter: 2284 loss: 2.62169607e-07
Iter: 2285 loss: 2.6206834e-07
Iter: 2286 loss: 2.62077663e-07
Iter: 2287 loss: 2.61937117e-07
Iter: 2288 loss: 2.63268817e-07
Iter: 2289 loss: 2.61955506e-07
Iter: 2290 loss: 2.61864358e-07
Iter: 2291 loss: 2.61857338e-07
Iter: 2292 loss: 2.61777018e-07
Iter: 2293 loss: 2.61677371e-07
Iter: 2294 loss: 2.6163994e-07
Iter: 2295 loss: 2.6160069e-07
Iter: 2296 loss: 2.61508831e-07
Iter: 2297 loss: 2.61664525e-07
Iter: 2298 loss: 2.61438231e-07
Iter: 2299 loss: 2.61383775e-07
Iter: 2300 loss: 2.61967699e-07
Iter: 2301 loss: 2.61363937e-07
Iter: 2302 loss: 2.61267928e-07
Iter: 2303 loss: 2.61536485e-07
Iter: 2304 loss: 2.6126034e-07
Iter: 2305 loss: 2.61153502e-07
Iter: 2306 loss: 2.613302e-07
Iter: 2307 loss: 2.61139036e-07
Iter: 2308 loss: 2.61043226e-07
Iter: 2309 loss: 2.61492e-07
Iter: 2310 loss: 2.61069516e-07
Iter: 2311 loss: 2.60982432e-07
Iter: 2312 loss: 2.6092755e-07
Iter: 2313 loss: 2.60908536e-07
Iter: 2314 loss: 2.60783224e-07
Iter: 2315 loss: 2.61225921e-07
Iter: 2316 loss: 2.60729678e-07
Iter: 2317 loss: 2.60710522e-07
Iter: 2318 loss: 2.60704525e-07
Iter: 2319 loss: 2.60651632e-07
Iter: 2320 loss: 2.60610022e-07
Iter: 2321 loss: 2.60606242e-07
Iter: 2322 loss: 2.6052993e-07
Iter: 2323 loss: 2.61424844e-07
Iter: 2324 loss: 2.60533909e-07
Iter: 2325 loss: 2.60474849e-07
Iter: 2326 loss: 2.60424542e-07
Iter: 2327 loss: 2.60394614e-07
Iter: 2328 loss: 2.60357126e-07
Iter: 2329 loss: 2.60378272e-07
Iter: 2330 loss: 2.60304432e-07
Iter: 2331 loss: 2.60174431e-07
Iter: 2332 loss: 2.60427839e-07
Iter: 2333 loss: 2.60148539e-07
Iter: 2334 loss: 2.60030703e-07
Iter: 2335 loss: 2.61003805e-07
Iter: 2336 loss: 2.60023e-07
Iter: 2337 loss: 2.59922786e-07
Iter: 2338 loss: 2.59911928e-07
Iter: 2339 loss: 2.59834621e-07
Iter: 2340 loss: 2.59746173e-07
Iter: 2341 loss: 2.60418346e-07
Iter: 2342 loss: 2.59711726e-07
Iter: 2343 loss: 2.59615433e-07
Iter: 2344 loss: 2.59685976e-07
Iter: 2345 loss: 2.59541196e-07
Iter: 2346 loss: 2.59415515e-07
Iter: 2347 loss: 2.59625921e-07
Iter: 2348 loss: 2.59383171e-07
Iter: 2349 loss: 2.59293671e-07
Iter: 2350 loss: 2.60103491e-07
Iter: 2351 loss: 2.59239698e-07
Iter: 2352 loss: 2.59165688e-07
Iter: 2353 loss: 2.59178023e-07
Iter: 2354 loss: 2.59080537e-07
Iter: 2355 loss: 2.5897009e-07
Iter: 2356 loss: 2.59886349e-07
Iter: 2357 loss: 2.58970829e-07
Iter: 2358 loss: 2.58896307e-07
Iter: 2359 loss: 2.58986631e-07
Iter: 2360 loss: 2.58837247e-07
Iter: 2361 loss: 2.58722793e-07
Iter: 2362 loss: 2.58722025e-07
Iter: 2363 loss: 2.58652392e-07
Iter: 2364 loss: 2.58566644e-07
Iter: 2365 loss: 2.59084e-07
Iter: 2366 loss: 2.58512387e-07
Iter: 2367 loss: 2.58432351e-07
Iter: 2368 loss: 2.58890054e-07
Iter: 2369 loss: 2.58469868e-07
Iter: 2370 loss: 2.58376701e-07
Iter: 2371 loss: 2.58402423e-07
Iter: 2372 loss: 2.58320171e-07
Iter: 2373 loss: 2.58237208e-07
Iter: 2374 loss: 2.5848675e-07
Iter: 2375 loss: 2.58200174e-07
Iter: 2376 loss: 2.58118462e-07
Iter: 2377 loss: 2.58564853e-07
Iter: 2378 loss: 2.58075858e-07
Iter: 2379 loss: 2.57996135e-07
Iter: 2380 loss: 2.57940201e-07
Iter: 2381 loss: 2.57892282e-07
Iter: 2382 loss: 2.57779305e-07
Iter: 2383 loss: 2.57699469e-07
Iter: 2384 loss: 2.57657376e-07
Iter: 2385 loss: 2.57474483e-07
Iter: 2386 loss: 2.59366573e-07
Iter: 2387 loss: 2.57469111e-07
Iter: 2388 loss: 2.57315463e-07
Iter: 2389 loss: 2.58346347e-07
Iter: 2390 loss: 2.57278316e-07
Iter: 2391 loss: 2.5718208e-07
Iter: 2392 loss: 2.57087805e-07
Iter: 2393 loss: 2.57065e-07
Iter: 2394 loss: 2.56990575e-07
Iter: 2395 loss: 2.56990091e-07
Iter: 2396 loss: 2.56871374e-07
Iter: 2397 loss: 2.56993303e-07
Iter: 2398 loss: 2.56859693e-07
Iter: 2399 loss: 2.56794237e-07
Iter: 2400 loss: 2.56792191e-07
Iter: 2401 loss: 2.56702918e-07
Iter: 2402 loss: 2.56587e-07
Iter: 2403 loss: 2.57137089e-07
Iter: 2404 loss: 2.56583462e-07
Iter: 2405 loss: 2.5647455e-07
Iter: 2406 loss: 2.56802139e-07
Iter: 2407 loss: 2.56431434e-07
Iter: 2408 loss: 2.56321442e-07
Iter: 2409 loss: 2.56263434e-07
Iter: 2410 loss: 2.56252406e-07
Iter: 2411 loss: 2.56110894e-07
Iter: 2412 loss: 2.56071843e-07
Iter: 2413 loss: 2.56008633e-07
Iter: 2414 loss: 2.55805304e-07
Iter: 2415 loss: 2.55834181e-07
Iter: 2416 loss: 2.55678287e-07
Iter: 2417 loss: 2.56032564e-07
Iter: 2418 loss: 2.5558694e-07
Iter: 2419 loss: 2.55501419e-07
Iter: 2420 loss: 2.5549798e-07
Iter: 2421 loss: 2.55410839e-07
Iter: 2422 loss: 2.55274131e-07
Iter: 2423 loss: 2.55290331e-07
Iter: 2424 loss: 2.5515709e-07
Iter: 2425 loss: 2.55346094e-07
Iter: 2426 loss: 2.55099678e-07
Iter: 2427 loss: 2.54946428e-07
Iter: 2428 loss: 2.54952482e-07
Iter: 2429 loss: 2.54896406e-07
Iter: 2430 loss: 2.54766235e-07
Iter: 2431 loss: 2.54738495e-07
Iter: 2432 loss: 2.54629015e-07
Iter: 2433 loss: 2.55019188e-07
Iter: 2434 loss: 2.54590759e-07
Iter: 2435 loss: 2.54423583e-07
Iter: 2436 loss: 2.55288739e-07
Iter: 2437 loss: 2.54391466e-07
Iter: 2438 loss: 2.5425075e-07
Iter: 2439 loss: 2.54114894e-07
Iter: 2440 loss: 2.5407985e-07
Iter: 2441 loss: 2.53938254e-07
Iter: 2442 loss: 2.53897213e-07
Iter: 2443 loss: 2.53782673e-07
Iter: 2444 loss: 2.53755303e-07
Iter: 2445 loss: 2.53643066e-07
Iter: 2446 loss: 2.53533926e-07
Iter: 2447 loss: 2.53489958e-07
Iter: 2448 loss: 2.53393921e-07
Iter: 2449 loss: 2.53222879e-07
Iter: 2450 loss: 2.54720248e-07
Iter: 2451 loss: 2.53202046e-07
Iter: 2452 loss: 2.53081879e-07
Iter: 2453 loss: 2.54295401e-07
Iter: 2454 loss: 2.53069203e-07
Iter: 2455 loss: 2.52936786e-07
Iter: 2456 loss: 2.52795104e-07
Iter: 2457 loss: 2.55790837e-07
Iter: 2458 loss: 2.52769809e-07
Iter: 2459 loss: 2.52554713e-07
Iter: 2460 loss: 2.54287841e-07
Iter: 2461 loss: 2.52568952e-07
Iter: 2462 loss: 2.52403623e-07
Iter: 2463 loss: 2.53855063e-07
Iter: 2464 loss: 2.52380602e-07
Iter: 2465 loss: 2.52322593e-07
Iter: 2466 loss: 2.5204659e-07
Iter: 2467 loss: 2.55793964e-07
Iter: 2468 loss: 2.52064268e-07
Iter: 2469 loss: 2.51828538e-07
Iter: 2470 loss: 2.51823735e-07
Iter: 2471 loss: 2.5170587e-07
Iter: 2472 loss: 2.51981021e-07
Iter: 2473 loss: 2.51642689e-07
Iter: 2474 loss: 2.51559e-07
Iter: 2475 loss: 2.51649766e-07
Iter: 2476 loss: 2.51511267e-07
Iter: 2477 loss: 2.51353612e-07
Iter: 2478 loss: 2.52500087e-07
Iter: 2479 loss: 2.51328402e-07
Iter: 2480 loss: 2.51275111e-07
Iter: 2481 loss: 2.51172054e-07
Iter: 2482 loss: 2.51125243e-07
Iter: 2483 loss: 2.51021646e-07
Iter: 2484 loss: 2.51045236e-07
Iter: 2485 loss: 2.50914496e-07
Iter: 2486 loss: 2.5083645e-07
Iter: 2487 loss: 2.5081772e-07
Iter: 2488 loss: 2.5076281e-07
Iter: 2489 loss: 2.50602398e-07
Iter: 2490 loss: 2.50607684e-07
Iter: 2491 loss: 2.50426751e-07
Iter: 2492 loss: 2.50474557e-07
Iter: 2493 loss: 2.50294022e-07
Iter: 2494 loss: 2.50137759e-07
Iter: 2495 loss: 2.5014316e-07
Iter: 2496 loss: 2.50018473e-07
Iter: 2497 loss: 2.50108286e-07
Iter: 2498 loss: 2.49921356e-07
Iter: 2499 loss: 2.49796415e-07
Iter: 2500 loss: 2.49694608e-07
Iter: 2501 loss: 2.49689407e-07
Iter: 2502 loss: 2.49572736e-07
Iter: 2503 loss: 2.49543547e-07
Iter: 2504 loss: 2.49469963e-07
Iter: 2505 loss: 2.49429206e-07
Iter: 2506 loss: 2.49385835e-07
Iter: 2507 loss: 2.49288917e-07
Iter: 2508 loss: 2.50411119e-07
Iter: 2509 loss: 2.49260125e-07
Iter: 2510 loss: 2.49241594e-07
Iter: 2511 loss: 2.49200326e-07
Iter: 2512 loss: 2.49141181e-07
Iter: 2513 loss: 2.49030052e-07
Iter: 2514 loss: 2.489449e-07
Iter: 2515 loss: 2.48898e-07
Iter: 2516 loss: 2.4875871e-07
Iter: 2517 loss: 2.49592887e-07
Iter: 2518 loss: 2.48793867e-07
Iter: 2519 loss: 2.48627714e-07
Iter: 2520 loss: 2.48636553e-07
Iter: 2521 loss: 2.48586304e-07
Iter: 2522 loss: 2.48421742e-07
Iter: 2523 loss: 2.50020065e-07
Iter: 2524 loss: 2.48328291e-07
Iter: 2525 loss: 2.48186581e-07
Iter: 2526 loss: 2.49218317e-07
Iter: 2527 loss: 2.48152787e-07
Iter: 2528 loss: 2.48109473e-07
Iter: 2529 loss: 2.48110695e-07
Iter: 2530 loss: 2.4801642e-07
Iter: 2531 loss: 2.47849272e-07
Iter: 2532 loss: 2.47840489e-07
Iter: 2533 loss: 2.47752524e-07
Iter: 2534 loss: 2.48039299e-07
Iter: 2535 loss: 2.47730668e-07
Iter: 2536 loss: 2.4761016e-07
Iter: 2537 loss: 2.48978267e-07
Iter: 2538 loss: 2.47592425e-07
Iter: 2539 loss: 2.4750878e-07
Iter: 2540 loss: 2.47393928e-07
Iter: 2541 loss: 2.47401232e-07
Iter: 2542 loss: 2.47272425e-07
Iter: 2543 loss: 2.4864795e-07
Iter: 2544 loss: 2.47277512e-07
Iter: 2545 loss: 2.47180196e-07
Iter: 2546 loss: 2.47238972e-07
Iter: 2547 loss: 2.47119118e-07
Iter: 2548 loss: 2.47005715e-07
Iter: 2549 loss: 2.46999292e-07
Iter: 2550 loss: 2.46919683e-07
Iter: 2551 loss: 2.46822651e-07
Iter: 2552 loss: 2.47134125e-07
Iter: 2553 loss: 2.46748073e-07
Iter: 2554 loss: 2.46663177e-07
Iter: 2555 loss: 2.47141315e-07
Iter: 2556 loss: 2.46645953e-07
Iter: 2557 loss: 2.46556652e-07
Iter: 2558 loss: 2.46566401e-07
Iter: 2559 loss: 2.46506858e-07
Iter: 2560 loss: 2.46417585e-07
Iter: 2561 loss: 2.46442227e-07
Iter: 2562 loss: 2.46345451e-07
Iter: 2563 loss: 2.46949895e-07
Iter: 2564 loss: 2.46355e-07
Iter: 2565 loss: 2.46249726e-07
Iter: 2566 loss: 2.46471501e-07
Iter: 2567 loss: 2.4626172e-07
Iter: 2568 loss: 2.46170828e-07
Iter: 2569 loss: 2.46156958e-07
Iter: 2570 loss: 2.46145248e-07
Iter: 2571 loss: 2.46099944e-07
Iter: 2572 loss: 2.4606851e-07
Iter: 2573 loss: 2.46022154e-07
Iter: 2574 loss: 2.45936377e-07
Iter: 2575 loss: 2.45945358e-07
Iter: 2576 loss: 2.45854949e-07
Iter: 2577 loss: 2.46219656e-07
Iter: 2578 loss: 2.45822804e-07
Iter: 2579 loss: 2.45755871e-07
Iter: 2580 loss: 2.46616338e-07
Iter: 2581 loss: 2.45743848e-07
Iter: 2582 loss: 2.45710709e-07
Iter: 2583 loss: 2.45603275e-07
Iter: 2584 loss: 2.46646209e-07
Iter: 2585 loss: 2.45554418e-07
Iter: 2586 loss: 2.45440674e-07
Iter: 2587 loss: 2.45862083e-07
Iter: 2588 loss: 2.45430243e-07
Iter: 2589 loss: 2.45325538e-07
Iter: 2590 loss: 2.4559904e-07
Iter: 2591 loss: 2.45283559e-07
Iter: 2592 loss: 2.45216285e-07
Iter: 2593 loss: 2.4565287e-07
Iter: 2594 loss: 2.45187948e-07
Iter: 2595 loss: 2.45121328e-07
Iter: 2596 loss: 2.46012149e-07
Iter: 2597 loss: 2.45101319e-07
Iter: 2598 loss: 2.45082646e-07
Iter: 2599 loss: 2.44974927e-07
Iter: 2600 loss: 2.44993714e-07
Iter: 2601 loss: 2.44919704e-07
Iter: 2602 loss: 2.45611716e-07
Iter: 2603 loss: 2.44918e-07
Iter: 2604 loss: 2.44894636e-07
Iter: 2605 loss: 2.45010114e-07
Iter: 2606 loss: 2.44876759e-07
Iter: 2607 loss: 2.44802408e-07
Iter: 2608 loss: 2.44735418e-07
Iter: 2609 loss: 2.44730614e-07
Iter: 2610 loss: 2.44634862e-07
Iter: 2611 loss: 2.45286941e-07
Iter: 2612 loss: 2.44608344e-07
Iter: 2613 loss: 2.44564546e-07
Iter: 2614 loss: 2.45039587e-07
Iter: 2615 loss: 2.445517e-07
Iter: 2616 loss: 2.44506083e-07
Iter: 2617 loss: 2.44465099e-07
Iter: 2618 loss: 2.44436563e-07
Iter: 2619 loss: 2.44404276e-07
Iter: 2620 loss: 2.4438782e-07
Iter: 2621 loss: 2.44377134e-07
Iter: 2622 loss: 2.44359228e-07
Iter: 2623 loss: 2.44303124e-07
Iter: 2624 loss: 2.44288401e-07
Iter: 2625 loss: 2.44219365e-07
Iter: 2626 loss: 2.44207484e-07
Iter: 2627 loss: 2.44134725e-07
Iter: 2628 loss: 2.44898132e-07
Iter: 2629 loss: 2.44135379e-07
Iter: 2630 loss: 2.44018082e-07
Iter: 2631 loss: 2.44238919e-07
Iter: 2632 loss: 2.4402047e-07
Iter: 2633 loss: 2.43953366e-07
Iter: 2634 loss: 2.4394302e-07
Iter: 2635 loss: 2.43925967e-07
Iter: 2636 loss: 2.43818533e-07
Iter: 2637 loss: 2.44501337e-07
Iter: 2638 loss: 2.43796052e-07
Iter: 2639 loss: 2.43763935e-07
Iter: 2640 loss: 2.43699731e-07
Iter: 2641 loss: 2.43697855e-07
Iter: 2642 loss: 2.43604518e-07
Iter: 2643 loss: 2.44464218e-07
Iter: 2644 loss: 2.43641551e-07
Iter: 2645 loss: 2.43593661e-07
Iter: 2646 loss: 2.43702971e-07
Iter: 2647 loss: 2.4353767e-07
Iter: 2648 loss: 2.4345789e-07
Iter: 2649 loss: 2.43492423e-07
Iter: 2650 loss: 2.43437029e-07
Iter: 2651 loss: 2.43380555e-07
Iter: 2652 loss: 2.43456e-07
Iter: 2653 loss: 2.43307227e-07
Iter: 2654 loss: 2.43289264e-07
Iter: 2655 loss: 2.44078734e-07
Iter: 2656 loss: 2.43283239e-07
Iter: 2657 loss: 2.43229664e-07
Iter: 2658 loss: 2.43160116e-07
Iter: 2659 loss: 2.43133655e-07
Iter: 2660 loss: 2.43091023e-07
Iter: 2661 loss: 2.43145507e-07
Iter: 2662 loss: 2.43077267e-07
Iter: 2663 loss: 2.43005928e-07
Iter: 2664 loss: 2.43011527e-07
Iter: 2665 loss: 2.42959601e-07
Iter: 2666 loss: 2.42849069e-07
Iter: 2667 loss: 2.44478628e-07
Iter: 2668 loss: 2.4287624e-07
Iter: 2669 loss: 2.4287354e-07
Iter: 2670 loss: 2.42818629e-07
Iter: 2671 loss: 2.42806436e-07
Iter: 2672 loss: 2.42809023e-07
Iter: 2673 loss: 2.4277125e-07
Iter: 2674 loss: 2.42697638e-07
Iter: 2675 loss: 2.42802599e-07
Iter: 2676 loss: 2.4272191e-07
Iter: 2677 loss: 2.42611e-07
Iter: 2678 loss: 2.4337271e-07
Iter: 2679 loss: 2.42629227e-07
Iter: 2680 loss: 2.42605978e-07
Iter: 2681 loss: 2.42557888e-07
Iter: 2682 loss: 2.42543166e-07
Iter: 2683 loss: 2.4247808e-07
Iter: 2684 loss: 2.42462704e-07
Iter: 2685 loss: 2.42431412e-07
Iter: 2686 loss: 2.42321022e-07
Iter: 2687 loss: 2.43065e-07
Iter: 2688 loss: 2.42319658e-07
Iter: 2689 loss: 2.4227478e-07
Iter: 2690 loss: 2.42900427e-07
Iter: 2691 loss: 2.42275092e-07
Iter: 2692 loss: 2.42221518e-07
Iter: 2693 loss: 2.42177293e-07
Iter: 2694 loss: 2.42156062e-07
Iter: 2695 loss: 2.42104335e-07
Iter: 2696 loss: 2.42094956e-07
Iter: 2697 loss: 2.42075345e-07
Iter: 2698 loss: 2.42043228e-07
Iter: 2699 loss: 2.42018103e-07
Iter: 2700 loss: 2.41944122e-07
Iter: 2701 loss: 2.42077476e-07
Iter: 2702 loss: 2.41933833e-07
Iter: 2703 loss: 2.4188725e-07
Iter: 2704 loss: 2.42491524e-07
Iter: 2705 loss: 2.41859738e-07
Iter: 2706 loss: 2.41809175e-07
Iter: 2707 loss: 2.41760205e-07
Iter: 2708 loss: 2.42873739e-07
Iter: 2709 loss: 2.41770465e-07
Iter: 2710 loss: 2.41672694e-07
Iter: 2711 loss: 2.42786143e-07
Iter: 2712 loss: 2.41659961e-07
Iter: 2713 loss: 2.4163117e-07
Iter: 2714 loss: 2.42067841e-07
Iter: 2715 loss: 2.41617016e-07
Iter: 2716 loss: 2.4153573e-07
Iter: 2717 loss: 2.41532661e-07
Iter: 2718 loss: 2.41520866e-07
Iter: 2719 loss: 2.4143236e-07
Iter: 2720 loss: 2.41481757e-07
Iter: 2721 loss: 2.41368866e-07
Iter: 2722 loss: 2.41338824e-07
Iter: 2723 loss: 2.42192186e-07
Iter: 2724 loss: 2.41301819e-07
Iter: 2725 loss: 2.41250973e-07
Iter: 2726 loss: 2.41481303e-07
Iter: 2727 loss: 2.41207943e-07
Iter: 2728 loss: 2.41148115e-07
Iter: 2729 loss: 2.41106051e-07
Iter: 2730 loss: 2.41080045e-07
Iter: 2731 loss: 2.41020075e-07
Iter: 2732 loss: 2.42269607e-07
Iter: 2733 loss: 2.41021553e-07
Iter: 2734 loss: 2.40969257e-07
Iter: 2735 loss: 2.40862022e-07
Iter: 2736 loss: 2.40880382e-07
Iter: 2737 loss: 2.4079452e-07
Iter: 2738 loss: 2.40792019e-07
Iter: 2739 loss: 2.407414e-07
Iter: 2740 loss: 2.40617538e-07
Iter: 2741 loss: 2.40649342e-07
Iter: 2742 loss: 2.40564646e-07
Iter: 2743 loss: 2.40631607e-07
Iter: 2744 loss: 2.40500412e-07
Iter: 2745 loss: 2.40437117e-07
Iter: 2746 loss: 2.4045022e-07
Iter: 2747 loss: 2.40414153e-07
Iter: 2748 loss: 2.40402528e-07
Iter: 2749 loss: 2.40356854e-07
Iter: 2750 loss: 2.40321327e-07
Iter: 2751 loss: 2.40320105e-07
Iter: 2752 loss: 2.40264512e-07
Iter: 2753 loss: 2.40224836e-07
Iter: 2754 loss: 2.40294924e-07
Iter: 2755 loss: 2.40174927e-07
Iter: 2756 loss: 2.40183454e-07
Iter: 2757 loss: 2.40157732e-07
Iter: 2758 loss: 2.4010177e-07
Iter: 2759 loss: 2.40108221e-07
Iter: 2760 loss: 2.40095204e-07
Iter: 2761 loss: 2.40021e-07
Iter: 2762 loss: 2.40279292e-07
Iter: 2763 loss: 2.39998883e-07
Iter: 2764 loss: 2.39984814e-07
Iter: 2765 loss: 2.40180498e-07
Iter: 2766 loss: 2.39966823e-07
Iter: 2767 loss: 2.39933684e-07
Iter: 2768 loss: 2.39926e-07
Iter: 2769 loss: 2.3988062e-07
Iter: 2770 loss: 2.39827955e-07
Iter: 2771 loss: 2.39842819e-07
Iter: 2772 loss: 2.39799931e-07
Iter: 2773 loss: 2.39766706e-07
Iter: 2774 loss: 2.40734892e-07
Iter: 2775 loss: 2.39715177e-07
Iter: 2776 loss: 2.396946e-07
Iter: 2777 loss: 2.39963299e-07
Iter: 2778 loss: 2.39659187e-07
Iter: 2779 loss: 2.39619112e-07
Iter: 2780 loss: 2.39930102e-07
Iter: 2781 loss: 2.39592737e-07
Iter: 2782 loss: 2.39555703e-07
Iter: 2783 loss: 2.39619e-07
Iter: 2784 loss: 2.39528049e-07
Iter: 2785 loss: 2.39473223e-07
Iter: 2786 loss: 2.39457023e-07
Iter: 2787 loss: 2.39403875e-07
Iter: 2788 loss: 2.39321139e-07
Iter: 2789 loss: 2.39676609e-07
Iter: 2790 loss: 2.39351948e-07
Iter: 2791 loss: 2.39300135e-07
Iter: 2792 loss: 2.39659499e-07
Iter: 2793 loss: 2.3927754e-07
Iter: 2794 loss: 2.39216092e-07
Iter: 2795 loss: 2.39459951e-07
Iter: 2796 loss: 2.39208248e-07
Iter: 2797 loss: 2.39158112e-07
Iter: 2798 loss: 2.39114684e-07
Iter: 2799 loss: 2.39121334e-07
Iter: 2800 loss: 2.39077394e-07
Iter: 2801 loss: 2.39565622e-07
Iter: 2802 loss: 2.39073529e-07
Iter: 2803 loss: 2.38969136e-07
Iter: 2804 loss: 2.39194634e-07
Iter: 2805 loss: 2.38958648e-07
Iter: 2806 loss: 2.38946171e-07
Iter: 2807 loss: 2.38938554e-07
Iter: 2808 loss: 2.38882706e-07
Iter: 2809 loss: 2.38855108e-07
Iter: 2810 loss: 2.38856018e-07
Iter: 2811 loss: 2.3884391e-07
Iter: 2812 loss: 2.38779052e-07
Iter: 2813 loss: 2.39992289e-07
Iter: 2814 loss: 2.3879565e-07
Iter: 2815 loss: 2.38725619e-07
Iter: 2816 loss: 2.38767e-07
Iter: 2817 loss: 2.38704615e-07
Iter: 2818 loss: 2.38673977e-07
Iter: 2819 loss: 2.38664313e-07
Iter: 2820 loss: 2.38658373e-07
Iter: 2821 loss: 2.3863663e-07
Iter: 2822 loss: 2.38620146e-07
Iter: 2823 loss: 2.38595305e-07
Iter: 2824 loss: 2.38592236e-07
Iter: 2825 loss: 2.38561398e-07
Iter: 2826 loss: 2.38503361e-07
Iter: 2827 loss: 2.38721498e-07
Iter: 2828 loss: 2.38515184e-07
Iter: 2829 loss: 2.38467919e-07
Iter: 2830 loss: 2.38480879e-07
Iter: 2831 loss: 2.38465532e-07
Iter: 2832 loss: 2.38404027e-07
Iter: 2833 loss: 2.38375918e-07
Iter: 2834 loss: 2.38341542e-07
Iter: 2835 loss: 2.38249896e-07
Iter: 2836 loss: 2.38540281e-07
Iter: 2837 loss: 2.38258508e-07
Iter: 2838 loss: 2.38232673e-07
Iter: 2839 loss: 2.38296295e-07
Iter: 2840 loss: 2.38180633e-07
Iter: 2841 loss: 2.38151216e-07
Iter: 2842 loss: 2.38193735e-07
Iter: 2843 loss: 2.3816466e-07
Iter: 2844 loss: 2.38150619e-07
Iter: 2845 loss: 2.38163764e-07
Iter: 2846 loss: 2.38163366e-07
Iter: 2847 loss: 2.38163508e-07
Iter: 2848 loss: 2.38170315e-07
Iter: 2849 loss: 2.3817266e-07
Iter: 2850 loss: 2.38179354e-07
Iter: 2851 loss: 2.38165825e-07
Iter: 2852 loss: 2.38146384e-07
Iter: 2853 loss: 2.3812882e-07
Iter: 2854 loss: 2.38122013e-07
Iter: 2855 loss: 2.38080219e-07
Iter: 2856 loss: 2.38279483e-07
Iter: 2857 loss: 2.38050063e-07
Iter: 2858 loss: 2.38009363e-07
Iter: 2859 loss: 2.38202929e-07
Iter: 2860 loss: 2.38003992e-07
Iter: 2861 loss: 2.37997199e-07
Iter: 2862 loss: 2.37971975e-07
Iter: 2863 loss: 2.39118634e-07
Iter: 2864 loss: 2.37936973e-07
Iter: 2865 loss: 2.37920574e-07
Iter: 2866 loss: 2.37911735e-07
Iter: 2867 loss: 2.37871973e-07
Iter: 2868 loss: 2.37878183e-07
Iter: 2869 loss: 2.37835337e-07
Iter: 2870 loss: 2.3782205e-07
Iter: 2871 loss: 2.37849918e-07
Iter: 2872 loss: 2.37765718e-07
Iter: 2873 loss: 2.37763601e-07
Iter: 2874 loss: 2.3775e-07
Iter: 2875 loss: 2.37726852e-07
Iter: 2876 loss: 2.37678648e-07
Iter: 2877 loss: 2.37666796e-07
Iter: 2878 loss: 2.37664821e-07
Iter: 2879 loss: 2.3769681e-07
Iter: 2880 loss: 2.37607011e-07
Iter: 2881 loss: 2.37565956e-07
Iter: 2882 loss: 2.37874872e-07
Iter: 2883 loss: 2.37584658e-07
Iter: 2884 loss: 2.37536554e-07
Iter: 2885 loss: 2.3771068e-07
Iter: 2886 loss: 2.37499023e-07
Iter: 2887 loss: 2.37501865e-07
Iter: 2888 loss: 2.37522215e-07
Iter: 2889 loss: 2.3753033e-07
Iter: 2890 loss: 2.37526876e-07
Iter: 2891 loss: 2.37506299e-07
Iter: 2892 loss: 2.37519487e-07
Iter: 2893 loss: 2.37537591e-07
Iter: 2894 loss: 2.37533669e-07
Iter: 2895 loss: 2.37513802e-07
Iter: 2896 loss: 2.37511472e-07
Iter: 2897 loss: 2.3751781e-07
Iter: 2898 loss: 2.37513476e-07
Iter: 2899 loss: 2.37503684e-07
Iter: 2900 loss: 2.37499492e-07
Iter: 2901 loss: 2.37495044e-07
Iter: 2902 loss: 2.37496309e-07
Iter: 2903 loss: 2.37500117e-07
Iter: 2904 loss: 2.37497332e-07
Iter: 2905 loss: 2.37497744e-07
Iter: 2906 loss: 2.37498568e-07
Iter: 2907 loss: 2.37499179e-07
Iter: 2908 loss: 2.37499066e-07
Iter: 2909 loss: 2.37499066e-07
Iter: 2910 loss: 2.37499449e-07
Iter: 2911 loss: 2.37499165e-07
Iter: 2912 loss: 2.37499449e-07
Iter: 2913 loss: 2.37499165e-07
Iter: 2914 loss: 2.37499165e-07
Iter: 2915 loss: 2.37499449e-07
Iter: 2916 loss: 2.37499165e-07
Iter: 2917 loss: 2.37499165e-07
Iter: 2918 loss: 2.37499165e-07
Iter: 2919 loss: 2.37499449e-07
Iter: 2920 loss: 2.37499449e-07
Iter: 2921 loss: 2.37499165e-07
Iter: 2922 loss: 2.37499165e-07
Iter: 2923 loss: 2.37499165e-07
Iter: 2924 loss: 2.37499449e-07
Iter: 2925 loss: 2.37499165e-07
Iter: 2926 loss: 2.3792046e-07
Iter: 2927 loss: 2.3752186e-07
Iter: 2928 loss: 2.3752591e-07
Iter: 2929 loss: 2.37525569e-07
Iter: 2930 loss: 2.37510022e-07
Iter: 2931 loss: 2.37532248e-07
Iter: 2932 loss: 2.37521448e-07
Iter: 2933 loss: 2.37510491e-07
Iter: 2934 loss: 2.37508416e-07
Iter: 2935 loss: 2.37520339e-07
Iter: 2936 loss: 2.37514683e-07
Iter: 2937 loss: 2.3751646e-07
Iter: 2938 loss: 2.37508331e-07
Iter: 2939 loss: 2.37495627e-07
Iter: 2940 loss: 2.37497474e-07
Iter: 2941 loss: 2.37503698e-07
Iter: 2942 loss: 2.37500672e-07
Iter: 2943 loss: 2.37499023e-07
Iter: 2944 loss: 2.3750124e-07
Iter: 2945 loss: 2.37500387e-07
Iter: 2946 loss: 2.37499165e-07
Iter: 2947 loss: 2.37499989e-07
Iter: 2948 loss: 2.37499933e-07
Iter: 2949 loss: 2.37499791e-07
Iter: 2950 loss: 2.3749925e-07
Iter: 2951 loss: 2.3749925e-07
Iter: 2952 loss: 2.3749925e-07
Iter: 2953 loss: 2.3749925e-07
Iter: 2954 loss: 2.3749925e-07
Iter: 2955 loss: 2.37499791e-07
Iter: 2956 loss: 2.3749925e-07
Iter: 2957 loss: 2.37499791e-07
Iter: 2958 loss: 2.3749925e-07
Iter: 2959 loss: 2.37499791e-07
Iter: 2960 loss: 2.37499791e-07
Iter: 2961 loss: 2.3749925e-07
Iter: 2962 loss: 2.37499791e-07
Iter: 2963 loss: 2.3749925e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_4000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_4000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4061fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d40644840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d406e49d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4064d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d405cc7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d405cc8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d405cc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d404fb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d404fb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d404cd048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d404cd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d40485d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4045af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4045a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4046fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4046fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4042aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d40379f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4048b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d40379048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4035e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d402fc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4035ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d402cfc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d402cff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d402a0ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4023dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d402a02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d40203158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d402220d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4021b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d401d2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d401d2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d401cfae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d401471e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0d4016cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.57999556e-06
Iter: 2 loss: 2.71974977e-06
Iter: 3 loss: 1.93285746e-06
Iter: 4 loss: 1.67935218e-06
Iter: 5 loss: 1.58244666e-06
Iter: 6 loss: 1.44417334e-06
Iter: 7 loss: 1.28793e-06
Iter: 8 loss: 3.69355962e-06
Iter: 9 loss: 1.28793363e-06
Iter: 10 loss: 1.16224123e-06
Iter: 11 loss: 1.11588872e-06
Iter: 12 loss: 1.046286e-06
Iter: 13 loss: 9.67112101e-07
Iter: 14 loss: 1.39877397e-06
Iter: 15 loss: 9.55449536e-07
Iter: 16 loss: 9.46012733e-07
Iter: 17 loss: 9.37932441e-07
Iter: 18 loss: 9.25575364e-07
Iter: 19 loss: 9.06537252e-07
Iter: 20 loss: 9.06242e-07
Iter: 21 loss: 8.9132368e-07
Iter: 22 loss: 8.91154571e-07
Iter: 23 loss: 8.80142e-07
Iter: 24 loss: 8.82262441e-07
Iter: 25 loss: 8.71936095e-07
Iter: 26 loss: 8.61426827e-07
Iter: 27 loss: 8.47146111e-07
Iter: 28 loss: 8.46434773e-07
Iter: 29 loss: 8.27495e-07
Iter: 30 loss: 8.69288783e-07
Iter: 31 loss: 8.20242121e-07
Iter: 32 loss: 8.06845264e-07
Iter: 33 loss: 9.4640825e-07
Iter: 34 loss: 8.06454523e-07
Iter: 35 loss: 8.03086607e-07
Iter: 36 loss: 8.01863052e-07
Iter: 37 loss: 7.98158851e-07
Iter: 38 loss: 7.98607289e-07
Iter: 39 loss: 7.95293317e-07
Iter: 40 loss: 7.91762602e-07
Iter: 41 loss: 7.98395718e-07
Iter: 42 loss: 7.90264096e-07
Iter: 43 loss: 7.85056841e-07
Iter: 44 loss: 8.05082607e-07
Iter: 45 loss: 7.83840051e-07
Iter: 46 loss: 7.81057281e-07
Iter: 47 loss: 7.77014861e-07
Iter: 48 loss: 7.76870934e-07
Iter: 49 loss: 7.7257846e-07
Iter: 50 loss: 8.25798224e-07
Iter: 51 loss: 7.7255595e-07
Iter: 52 loss: 7.67139568e-07
Iter: 53 loss: 7.61451133e-07
Iter: 54 loss: 7.60451599e-07
Iter: 55 loss: 7.53075483e-07
Iter: 56 loss: 8.17171895e-07
Iter: 57 loss: 7.52649669e-07
Iter: 58 loss: 7.46254386e-07
Iter: 59 loss: 7.62543152e-07
Iter: 60 loss: 7.44073645e-07
Iter: 61 loss: 7.39954487e-07
Iter: 62 loss: 7.35899448e-07
Iter: 63 loss: 7.35033041e-07
Iter: 64 loss: 7.29850171e-07
Iter: 65 loss: 7.58385738e-07
Iter: 66 loss: 7.29091312e-07
Iter: 67 loss: 7.25636255e-07
Iter: 68 loss: 7.34520256e-07
Iter: 69 loss: 7.24434585e-07
Iter: 70 loss: 7.21003175e-07
Iter: 71 loss: 7.28145665e-07
Iter: 72 loss: 7.19700324e-07
Iter: 73 loss: 7.18125534e-07
Iter: 74 loss: 7.17990304e-07
Iter: 75 loss: 7.15989131e-07
Iter: 76 loss: 7.15212877e-07
Iter: 77 loss: 7.14145131e-07
Iter: 78 loss: 7.12258725e-07
Iter: 79 loss: 7.1768477e-07
Iter: 80 loss: 7.11656526e-07
Iter: 81 loss: 7.09101812e-07
Iter: 82 loss: 7.1742852e-07
Iter: 83 loss: 7.08394623e-07
Iter: 84 loss: 7.06430228e-07
Iter: 85 loss: 7.04362606e-07
Iter: 86 loss: 7.04020408e-07
Iter: 87 loss: 7.02156399e-07
Iter: 88 loss: 7.02115358e-07
Iter: 89 loss: 7.00142664e-07
Iter: 90 loss: 7.01841259e-07
Iter: 91 loss: 6.9901e-07
Iter: 92 loss: 6.9755788e-07
Iter: 93 loss: 7.01093882e-07
Iter: 94 loss: 6.97028781e-07
Iter: 95 loss: 6.94803703e-07
Iter: 96 loss: 6.96192956e-07
Iter: 97 loss: 6.93430138e-07
Iter: 98 loss: 6.91842672e-07
Iter: 99 loss: 6.90009585e-07
Iter: 100 loss: 6.89744866e-07
Iter: 101 loss: 6.86938733e-07
Iter: 102 loss: 6.92876483e-07
Iter: 103 loss: 6.85754799e-07
Iter: 104 loss: 6.83091571e-07
Iter: 105 loss: 7.02160264e-07
Iter: 106 loss: 6.82816e-07
Iter: 107 loss: 6.80884114e-07
Iter: 108 loss: 6.87308045e-07
Iter: 109 loss: 6.80313292e-07
Iter: 110 loss: 6.78459344e-07
Iter: 111 loss: 6.78458719e-07
Iter: 112 loss: 6.78055585e-07
Iter: 113 loss: 6.7742036e-07
Iter: 114 loss: 6.77405126e-07
Iter: 115 loss: 6.7632925e-07
Iter: 116 loss: 6.82800305e-07
Iter: 117 loss: 6.76204593e-07
Iter: 118 loss: 6.75520482e-07
Iter: 119 loss: 6.7519403e-07
Iter: 120 loss: 6.74877697e-07
Iter: 121 loss: 6.74179205e-07
Iter: 122 loss: 6.7700762e-07
Iter: 123 loss: 6.74032e-07
Iter: 124 loss: 6.73087925e-07
Iter: 125 loss: 6.75365e-07
Iter: 126 loss: 6.72721228e-07
Iter: 127 loss: 6.71874261e-07
Iter: 128 loss: 6.71952421e-07
Iter: 129 loss: 6.71244663e-07
Iter: 130 loss: 6.701286e-07
Iter: 131 loss: 6.81555207e-07
Iter: 132 loss: 6.7010825e-07
Iter: 133 loss: 6.69589156e-07
Iter: 134 loss: 6.68578423e-07
Iter: 135 loss: 6.8407536e-07
Iter: 136 loss: 6.68535449e-07
Iter: 137 loss: 6.67105951e-07
Iter: 138 loss: 6.69957217e-07
Iter: 139 loss: 6.66515575e-07
Iter: 140 loss: 6.65108246e-07
Iter: 141 loss: 6.70391046e-07
Iter: 142 loss: 6.64760307e-07
Iter: 143 loss: 6.63320861e-07
Iter: 144 loss: 6.62061211e-07
Iter: 145 loss: 6.61687579e-07
Iter: 146 loss: 6.59301122e-07
Iter: 147 loss: 6.82597943e-07
Iter: 148 loss: 6.59194029e-07
Iter: 149 loss: 6.57919941e-07
Iter: 150 loss: 6.59071e-07
Iter: 151 loss: 6.57207e-07
Iter: 152 loss: 6.57151304e-07
Iter: 153 loss: 6.56467e-07
Iter: 154 loss: 6.56070256e-07
Iter: 155 loss: 6.55479653e-07
Iter: 156 loss: 6.55469876e-07
Iter: 157 loss: 6.55098347e-07
Iter: 158 loss: 6.55101e-07
Iter: 159 loss: 6.54764619e-07
Iter: 160 loss: 6.54197606e-07
Iter: 161 loss: 6.54201472e-07
Iter: 162 loss: 6.53803e-07
Iter: 163 loss: 6.56347254e-07
Iter: 164 loss: 6.53718359e-07
Iter: 165 loss: 6.53412599e-07
Iter: 166 loss: 6.56313546e-07
Iter: 167 loss: 6.53399525e-07
Iter: 168 loss: 6.53111897e-07
Iter: 169 loss: 6.5275151e-07
Iter: 170 loss: 6.52737299e-07
Iter: 171 loss: 6.52252311e-07
Iter: 172 loss: 6.581202e-07
Iter: 173 loss: 6.52254812e-07
Iter: 174 loss: 6.51915229e-07
Iter: 175 loss: 6.51095547e-07
Iter: 176 loss: 6.58117528e-07
Iter: 177 loss: 6.50956281e-07
Iter: 178 loss: 6.50170477e-07
Iter: 179 loss: 6.56182578e-07
Iter: 180 loss: 6.50114146e-07
Iter: 181 loss: 6.495099e-07
Iter: 182 loss: 6.50339871e-07
Iter: 183 loss: 6.49202e-07
Iter: 184 loss: 6.48472565e-07
Iter: 185 loss: 6.50386e-07
Iter: 186 loss: 6.48221601e-07
Iter: 187 loss: 6.48061757e-07
Iter: 188 loss: 6.47879631e-07
Iter: 189 loss: 6.47671641e-07
Iter: 190 loss: 6.47126512e-07
Iter: 191 loss: 6.53683514e-07
Iter: 192 loss: 6.47081833e-07
Iter: 193 loss: 6.46490605e-07
Iter: 194 loss: 6.52025733e-07
Iter: 195 loss: 6.46480089e-07
Iter: 196 loss: 6.45783e-07
Iter: 197 loss: 6.458082e-07
Iter: 198 loss: 6.45308376e-07
Iter: 199 loss: 6.44715158e-07
Iter: 200 loss: 6.45139437e-07
Iter: 201 loss: 6.4435892e-07
Iter: 202 loss: 6.4391287e-07
Iter: 203 loss: 6.43901217e-07
Iter: 204 loss: 6.43532076e-07
Iter: 205 loss: 6.42959776e-07
Iter: 206 loss: 6.42947498e-07
Iter: 207 loss: 6.4279152e-07
Iter: 208 loss: 6.42653504e-07
Iter: 209 loss: 6.42539703e-07
Iter: 210 loss: 6.42220357e-07
Iter: 211 loss: 6.45172122e-07
Iter: 212 loss: 6.42171244e-07
Iter: 213 loss: 6.41733e-07
Iter: 214 loss: 6.42209443e-07
Iter: 215 loss: 6.41512145e-07
Iter: 216 loss: 6.41020222e-07
Iter: 217 loss: 6.43602789e-07
Iter: 218 loss: 6.40955307e-07
Iter: 219 loss: 6.40555e-07
Iter: 220 loss: 6.42732346e-07
Iter: 221 loss: 6.4046003e-07
Iter: 222 loss: 6.40037683e-07
Iter: 223 loss: 6.42353825e-07
Iter: 224 loss: 6.39966117e-07
Iter: 225 loss: 6.39661039e-07
Iter: 226 loss: 6.39156212e-07
Iter: 227 loss: 6.39147913e-07
Iter: 228 loss: 6.38624101e-07
Iter: 229 loss: 6.46546596e-07
Iter: 230 loss: 6.38654342e-07
Iter: 231 loss: 6.38114443e-07
Iter: 232 loss: 6.3812081e-07
Iter: 233 loss: 6.37738708e-07
Iter: 234 loss: 6.37212906e-07
Iter: 235 loss: 6.37497067e-07
Iter: 236 loss: 6.3690976e-07
Iter: 237 loss: 6.36507366e-07
Iter: 238 loss: 6.36474738e-07
Iter: 239 loss: 6.36216782e-07
Iter: 240 loss: 6.35788183e-07
Iter: 241 loss: 6.46515844e-07
Iter: 242 loss: 6.35795914e-07
Iter: 243 loss: 6.35271476e-07
Iter: 244 loss: 6.35259312e-07
Iter: 245 loss: 6.3499823e-07
Iter: 246 loss: 6.34525463e-07
Iter: 247 loss: 6.4472539e-07
Iter: 248 loss: 6.3452444e-07
Iter: 249 loss: 6.34009e-07
Iter: 250 loss: 6.35529432e-07
Iter: 251 loss: 6.33842205e-07
Iter: 252 loss: 6.33450554e-07
Iter: 253 loss: 6.34644493e-07
Iter: 254 loss: 6.33327318e-07
Iter: 255 loss: 6.33115803e-07
Iter: 256 loss: 6.33109607e-07
Iter: 257 loss: 6.32878766e-07
Iter: 258 loss: 6.33227216e-07
Iter: 259 loss: 6.32768774e-07
Iter: 260 loss: 6.32615354e-07
Iter: 261 loss: 6.32489787e-07
Iter: 262 loss: 6.32442493e-07
Iter: 263 loss: 6.32201e-07
Iter: 264 loss: 6.3498635e-07
Iter: 265 loss: 6.32199544e-07
Iter: 266 loss: 6.31910098e-07
Iter: 267 loss: 6.31635146e-07
Iter: 268 loss: 6.31594958e-07
Iter: 269 loss: 6.31292437e-07
Iter: 270 loss: 6.32230467e-07
Iter: 271 loss: 6.31158855e-07
Iter: 272 loss: 6.30752197e-07
Iter: 273 loss: 6.34344588e-07
Iter: 274 loss: 6.30769364e-07
Iter: 275 loss: 6.30487875e-07
Iter: 276 loss: 6.30325644e-07
Iter: 277 loss: 6.30226964e-07
Iter: 278 loss: 6.29912904e-07
Iter: 279 loss: 6.34323953e-07
Iter: 280 loss: 6.29917054e-07
Iter: 281 loss: 6.29704573e-07
Iter: 282 loss: 6.29316844e-07
Iter: 283 loss: 6.29321164e-07
Iter: 284 loss: 6.28888529e-07
Iter: 285 loss: 6.29004489e-07
Iter: 286 loss: 6.28592602e-07
Iter: 287 loss: 6.28040198e-07
Iter: 288 loss: 6.28312876e-07
Iter: 289 loss: 6.27683107e-07
Iter: 290 loss: 6.27236716e-07
Iter: 291 loss: 6.27211648e-07
Iter: 292 loss: 6.26933456e-07
Iter: 293 loss: 6.26912367e-07
Iter: 294 loss: 6.26696533e-07
Iter: 295 loss: 6.26219162e-07
Iter: 296 loss: 6.34406774e-07
Iter: 297 loss: 6.26205178e-07
Iter: 298 loss: 6.26022313e-07
Iter: 299 loss: 6.26021688e-07
Iter: 300 loss: 6.25831376e-07
Iter: 301 loss: 6.26221549e-07
Iter: 302 loss: 6.25750658e-07
Iter: 303 loss: 6.25638222e-07
Iter: 304 loss: 6.25271127e-07
Iter: 305 loss: 6.29600891e-07
Iter: 306 loss: 6.25271753e-07
Iter: 307 loss: 6.25334337e-07
Iter: 308 loss: 6.25155167e-07
Iter: 309 loss: 6.2503841e-07
Iter: 310 loss: 6.24823372e-07
Iter: 311 loss: 6.29284614e-07
Iter: 312 loss: 6.24809616e-07
Iter: 313 loss: 6.24539211e-07
Iter: 314 loss: 6.25975531e-07
Iter: 315 loss: 6.24491747e-07
Iter: 316 loss: 6.2415296e-07
Iter: 317 loss: 6.23859421e-07
Iter: 318 loss: 6.23772166e-07
Iter: 319 loss: 6.23392395e-07
Iter: 320 loss: 6.23439234e-07
Iter: 321 loss: 6.2310562e-07
Iter: 322 loss: 6.22842435e-07
Iter: 323 loss: 6.22549e-07
Iter: 324 loss: 6.22501148e-07
Iter: 325 loss: 6.22153493e-07
Iter: 326 loss: 6.21924244e-07
Iter: 327 loss: 6.21757749e-07
Iter: 328 loss: 6.21387471e-07
Iter: 329 loss: 6.24263e-07
Iter: 330 loss: 6.21352285e-07
Iter: 331 loss: 6.21010145e-07
Iter: 332 loss: 6.20674655e-07
Iter: 333 loss: 6.20615083e-07
Iter: 334 loss: 6.20136689e-07
Iter: 335 loss: 6.26581709e-07
Iter: 336 loss: 6.20134642e-07
Iter: 337 loss: 6.19787272e-07
Iter: 338 loss: 6.23895744e-07
Iter: 339 loss: 6.19809214e-07
Iter: 340 loss: 6.19560922e-07
Iter: 341 loss: 6.19158584e-07
Iter: 342 loss: 6.25921814e-07
Iter: 343 loss: 6.19165064e-07
Iter: 344 loss: 6.18865215e-07
Iter: 345 loss: 6.18815193e-07
Iter: 346 loss: 6.18608055e-07
Iter: 347 loss: 6.19627428e-07
Iter: 348 loss: 6.18523302e-07
Iter: 349 loss: 6.18423883e-07
Iter: 350 loss: 6.18211175e-07
Iter: 351 loss: 6.18218792e-07
Iter: 352 loss: 6.18091462e-07
Iter: 353 loss: 6.18057811e-07
Iter: 354 loss: 6.17954925e-07
Iter: 355 loss: 6.17739033e-07
Iter: 356 loss: 6.2157676e-07
Iter: 357 loss: 6.17741193e-07
Iter: 358 loss: 6.17520584e-07
Iter: 359 loss: 6.19234e-07
Iter: 360 loss: 6.17520413e-07
Iter: 361 loss: 6.17307819e-07
Iter: 362 loss: 6.18211629e-07
Iter: 363 loss: 6.17269109e-07
Iter: 364 loss: 6.17120463e-07
Iter: 365 loss: 6.1674848e-07
Iter: 366 loss: 6.22786729e-07
Iter: 367 loss: 6.16756324e-07
Iter: 368 loss: 6.16327384e-07
Iter: 369 loss: 6.1702184e-07
Iter: 370 loss: 6.16155091e-07
Iter: 371 loss: 6.15781289e-07
Iter: 372 loss: 6.20892763e-07
Iter: 373 loss: 6.15796523e-07
Iter: 374 loss: 6.15548174e-07
Iter: 375 loss: 6.17959358e-07
Iter: 376 loss: 6.15555e-07
Iter: 377 loss: 6.15397198e-07
Iter: 378 loss: 6.15091494e-07
Iter: 379 loss: 6.15105e-07
Iter: 380 loss: 6.14838825e-07
Iter: 381 loss: 6.14863e-07
Iter: 382 loss: 6.14605369e-07
Iter: 383 loss: 6.1486935e-07
Iter: 384 loss: 6.14496741e-07
Iter: 385 loss: 6.14275e-07
Iter: 386 loss: 6.14105033e-07
Iter: 387 loss: 6.14039322e-07
Iter: 388 loss: 6.13784152e-07
Iter: 389 loss: 6.13762154e-07
Iter: 390 loss: 6.13541715e-07
Iter: 391 loss: 6.13453153e-07
Iter: 392 loss: 6.13349471e-07
Iter: 393 loss: 6.13218617e-07
Iter: 394 loss: 6.14849114e-07
Iter: 395 loss: 6.131894e-07
Iter: 396 loss: 6.12976123e-07
Iter: 397 loss: 6.13061786e-07
Iter: 398 loss: 6.12839358e-07
Iter: 399 loss: 6.12719873e-07
Iter: 400 loss: 6.12984763e-07
Iter: 401 loss: 6.1269e-07
Iter: 402 loss: 6.12568897e-07
Iter: 403 loss: 6.12386827e-07
Iter: 404 loss: 6.12385406e-07
Iter: 405 loss: 6.12161443e-07
Iter: 406 loss: 6.1458e-07
Iter: 407 loss: 6.12188217e-07
Iter: 408 loss: 6.11978e-07
Iter: 409 loss: 6.13880502e-07
Iter: 410 loss: 6.11959081e-07
Iter: 411 loss: 6.11855626e-07
Iter: 412 loss: 6.11526843e-07
Iter: 413 loss: 6.143257e-07
Iter: 414 loss: 6.11508426e-07
Iter: 415 loss: 6.11161283e-07
Iter: 416 loss: 6.11174414e-07
Iter: 417 loss: 6.10874e-07
Iter: 418 loss: 6.11048335e-07
Iter: 419 loss: 6.10663278e-07
Iter: 420 loss: 6.10442385e-07
Iter: 421 loss: 6.10411348e-07
Iter: 422 loss: 6.10207962e-07
Iter: 423 loss: 6.09984e-07
Iter: 424 loss: 6.09992185e-07
Iter: 425 loss: 6.09836093e-07
Iter: 426 loss: 6.0964112e-07
Iter: 427 loss: 6.09623442e-07
Iter: 428 loss: 6.09410336e-07
Iter: 429 loss: 6.11178507e-07
Iter: 430 loss: 6.09433812e-07
Iter: 431 loss: 6.09286758e-07
Iter: 432 loss: 6.10321536e-07
Iter: 433 loss: 6.09225253e-07
Iter: 434 loss: 6.09115034e-07
Iter: 435 loss: 6.0884696e-07
Iter: 436 loss: 6.11926907e-07
Iter: 437 loss: 6.08809387e-07
Iter: 438 loss: 6.0846844e-07
Iter: 439 loss: 6.0892944e-07
Iter: 440 loss: 6.08289e-07
Iter: 441 loss: 6.0803734e-07
Iter: 442 loss: 6.08033815e-07
Iter: 443 loss: 6.07846175e-07
Iter: 444 loss: 6.09241624e-07
Iter: 445 loss: 6.0782e-07
Iter: 446 loss: 6.07691959e-07
Iter: 447 loss: 6.07474135e-07
Iter: 448 loss: 6.12259328e-07
Iter: 449 loss: 6.07466461e-07
Iter: 450 loss: 6.07500567e-07
Iter: 451 loss: 6.07393531e-07
Iter: 452 loss: 6.07294339e-07
Iter: 453 loss: 6.07224365e-07
Iter: 454 loss: 6.07200604e-07
Iter: 455 loss: 6.071092e-07
Iter: 456 loss: 6.07296897e-07
Iter: 457 loss: 6.0707589e-07
Iter: 458 loss: 6.06934123e-07
Iter: 459 loss: 6.07721063e-07
Iter: 460 loss: 6.06875631e-07
Iter: 461 loss: 6.06737672e-07
Iter: 462 loss: 6.06582034e-07
Iter: 463 loss: 6.06575554e-07
Iter: 464 loss: 6.06395702e-07
Iter: 465 loss: 6.08713208e-07
Iter: 466 loss: 6.06394224e-07
Iter: 467 loss: 6.06234494e-07
Iter: 468 loss: 6.06123081e-07
Iter: 469 loss: 6.06076526e-07
Iter: 470 loss: 6.05835908e-07
Iter: 471 loss: 6.05666742e-07
Iter: 472 loss: 6.05610126e-07
Iter: 473 loss: 6.05236551e-07
Iter: 474 loss: 6.0615622e-07
Iter: 475 loss: 6.05110358e-07
Iter: 476 loss: 6.04847855e-07
Iter: 477 loss: 6.07862603e-07
Iter: 478 loss: 6.04841944e-07
Iter: 479 loss: 6.04634579e-07
Iter: 480 loss: 6.06086587e-07
Iter: 481 loss: 6.04584443e-07
Iter: 482 loss: 6.0441721e-07
Iter: 483 loss: 6.04085756e-07
Iter: 484 loss: 6.10257132e-07
Iter: 485 loss: 6.04093e-07
Iter: 486 loss: 6.04033971e-07
Iter: 487 loss: 6.03928925e-07
Iter: 488 loss: 6.03845365e-07
Iter: 489 loss: 6.03685635e-07
Iter: 490 loss: 6.03644366e-07
Iter: 491 loss: 6.03523461e-07
Iter: 492 loss: 6.04216893e-07
Iter: 493 loss: 6.0350186e-07
Iter: 494 loss: 6.03337412e-07
Iter: 495 loss: 6.0393495e-07
Iter: 496 loss: 6.03265e-07
Iter: 497 loss: 6.03178705e-07
Iter: 498 loss: 6.03126068e-07
Iter: 499 loss: 6.0305365e-07
Iter: 500 loss: 6.02967816e-07
Iter: 501 loss: 6.02985438e-07
Iter: 502 loss: 6.02895057e-07
Iter: 503 loss: 6.02746e-07
Iter: 504 loss: 6.02752948e-07
Iter: 505 loss: 6.02532737e-07
Iter: 506 loss: 6.02608338e-07
Iter: 507 loss: 6.02440878e-07
Iter: 508 loss: 6.02171895e-07
Iter: 509 loss: 6.01984084e-07
Iter: 510 loss: 6.01932584e-07
Iter: 511 loss: 6.01742727e-07
Iter: 512 loss: 6.0168361e-07
Iter: 513 loss: 6.01507793e-07
Iter: 514 loss: 6.02335945e-07
Iter: 515 loss: 6.01471811e-07
Iter: 516 loss: 6.01324928e-07
Iter: 517 loss: 6.01080387e-07
Iter: 518 loss: 6.01098293e-07
Iter: 519 loss: 6.00985e-07
Iter: 520 loss: 6.0094942e-07
Iter: 521 loss: 6.00875e-07
Iter: 522 loss: 6.00727105e-07
Iter: 523 loss: 6.00736314e-07
Iter: 524 loss: 6.00567716e-07
Iter: 525 loss: 6.01445549e-07
Iter: 526 loss: 6.00500471e-07
Iter: 527 loss: 6.00309704e-07
Iter: 528 loss: 6.00317549e-07
Iter: 529 loss: 6.0014429e-07
Iter: 530 loss: 5.99960742e-07
Iter: 531 loss: 6.00454086e-07
Iter: 532 loss: 5.99913392e-07
Iter: 533 loss: 5.99732459e-07
Iter: 534 loss: 6.02173827e-07
Iter: 535 loss: 5.99729901e-07
Iter: 536 loss: 5.99602629e-07
Iter: 537 loss: 5.99380428e-07
Iter: 538 loss: 5.99375767e-07
Iter: 539 loss: 5.99098939e-07
Iter: 540 loss: 5.99485702e-07
Iter: 541 loss: 5.99002192e-07
Iter: 542 loss: 5.987809e-07
Iter: 543 loss: 5.99380087e-07
Iter: 544 loss: 5.98763734e-07
Iter: 545 loss: 5.9870473e-07
Iter: 546 loss: 5.98612928e-07
Iter: 547 loss: 5.98530107e-07
Iter: 548 loss: 5.98401414e-07
Iter: 549 loss: 5.98402607e-07
Iter: 550 loss: 5.98282e-07
Iter: 551 loss: 5.99240707e-07
Iter: 552 loss: 5.98231395e-07
Iter: 553 loss: 5.98110319e-07
Iter: 554 loss: 5.98584393e-07
Iter: 555 loss: 5.98075871e-07
Iter: 556 loss: 5.97980033e-07
Iter: 557 loss: 5.97784151e-07
Iter: 558 loss: 6.02628234e-07
Iter: 559 loss: 5.97769713e-07
Iter: 560 loss: 5.97608732e-07
Iter: 561 loss: 5.9762192e-07
Iter: 562 loss: 5.97422058e-07
Iter: 563 loss: 5.97149437e-07
Iter: 564 loss: 5.97120447e-07
Iter: 565 loss: 5.96878408e-07
Iter: 566 loss: 5.97164558e-07
Iter: 567 loss: 5.9675142e-07
Iter: 568 loss: 5.96533312e-07
Iter: 569 loss: 5.96528196e-07
Iter: 570 loss: 5.96322536e-07
Iter: 571 loss: 5.96314067e-07
Iter: 572 loss: 5.96164284e-07
Iter: 573 loss: 5.95980225e-07
Iter: 574 loss: 5.95723918e-07
Iter: 575 loss: 5.95743415e-07
Iter: 576 loss: 5.95420488e-07
Iter: 577 loss: 5.9676654e-07
Iter: 578 loss: 5.95341419e-07
Iter: 579 loss: 5.95123822e-07
Iter: 580 loss: 5.9511558e-07
Iter: 581 loss: 5.9497404e-07
Iter: 582 loss: 5.9473382e-07
Iter: 583 loss: 5.94723929e-07
Iter: 584 loss: 5.94500079e-07
Iter: 585 loss: 5.96594589e-07
Iter: 586 loss: 5.94466428e-07
Iter: 587 loss: 5.94204039e-07
Iter: 588 loss: 5.94974608e-07
Iter: 589 loss: 5.94142534e-07
Iter: 590 loss: 5.94046583e-07
Iter: 591 loss: 5.93897653e-07
Iter: 592 loss: 5.93874063e-07
Iter: 593 loss: 5.93764071e-07
Iter: 594 loss: 5.93753271e-07
Iter: 595 loss: 5.9370052e-07
Iter: 596 loss: 5.93528171e-07
Iter: 597 loss: 5.9650273e-07
Iter: 598 loss: 5.93510322e-07
Iter: 599 loss: 5.93451205e-07
Iter: 600 loss: 5.93449272e-07
Iter: 601 loss: 5.93348716e-07
Iter: 602 loss: 5.93325581e-07
Iter: 603 loss: 5.93265327e-07
Iter: 604 loss: 5.93135212e-07
Iter: 605 loss: 5.93200298e-07
Iter: 606 loss: 5.93025447e-07
Iter: 607 loss: 5.92872084e-07
Iter: 608 loss: 5.92836955e-07
Iter: 609 loss: 5.92694164e-07
Iter: 610 loss: 5.92431263e-07
Iter: 611 loss: 5.94020491e-07
Iter: 612 loss: 5.92411709e-07
Iter: 613 loss: 5.92189053e-07
Iter: 614 loss: 5.94257358e-07
Iter: 615 loss: 5.92183198e-07
Iter: 616 loss: 5.9204217e-07
Iter: 617 loss: 5.91809794e-07
Iter: 618 loss: 5.91831963e-07
Iter: 619 loss: 5.91747607e-07
Iter: 620 loss: 5.91675644e-07
Iter: 621 loss: 5.91613684e-07
Iter: 622 loss: 5.91368234e-07
Iter: 623 loss: 5.92605716e-07
Iter: 624 loss: 5.91286721e-07
Iter: 625 loss: 5.91030243e-07
Iter: 626 loss: 5.92908805e-07
Iter: 627 loss: 5.90981301e-07
Iter: 628 loss: 5.90641434e-07
Iter: 629 loss: 5.92208494e-07
Iter: 630 loss: 5.90628645e-07
Iter: 631 loss: 5.90414288e-07
Iter: 632 loss: 5.90218406e-07
Iter: 633 loss: 5.90189e-07
Iter: 634 loss: 5.89889055e-07
Iter: 635 loss: 5.94041865e-07
Iter: 636 loss: 5.89909291e-07
Iter: 637 loss: 5.89645083e-07
Iter: 638 loss: 5.89496551e-07
Iter: 639 loss: 5.89402248e-07
Iter: 640 loss: 5.89225465e-07
Iter: 641 loss: 5.90569471e-07
Iter: 642 loss: 5.89196588e-07
Iter: 643 loss: 5.89055958e-07
Iter: 644 loss: 5.90023035e-07
Iter: 645 loss: 5.89003946e-07
Iter: 646 loss: 5.88901116e-07
Iter: 647 loss: 5.89781621e-07
Iter: 648 loss: 5.88912712e-07
Iter: 649 loss: 5.88816874e-07
Iter: 650 loss: 5.88752243e-07
Iter: 651 loss: 5.88722628e-07
Iter: 652 loss: 5.88599505e-07
Iter: 653 loss: 5.89454146e-07
Iter: 654 loss: 5.88593139e-07
Iter: 655 loss: 5.88488433e-07
Iter: 656 loss: 5.88536182e-07
Iter: 657 loss: 5.88415503e-07
Iter: 658 loss: 5.8830085e-07
Iter: 659 loss: 5.88091268e-07
Iter: 660 loss: 5.8809e-07
Iter: 661 loss: 5.87906754e-07
Iter: 662 loss: 5.87903628e-07
Iter: 663 loss: 5.87739123e-07
Iter: 664 loss: 5.87517604e-07
Iter: 665 loss: 5.87424836e-07
Iter: 666 loss: 5.87232762e-07
Iter: 667 loss: 5.8847877e-07
Iter: 668 loss: 5.87188538e-07
Iter: 669 loss: 5.8697816e-07
Iter: 670 loss: 5.87731449e-07
Iter: 671 loss: 5.8690091e-07
Iter: 672 loss: 5.86703379e-07
Iter: 673 loss: 5.86455712e-07
Iter: 674 loss: 5.86434453e-07
Iter: 675 loss: 5.86224417e-07
Iter: 676 loss: 5.87902775e-07
Iter: 677 loss: 5.86197302e-07
Iter: 678 loss: 5.86040755e-07
Iter: 679 loss: 5.87282329e-07
Iter: 680 loss: 5.86023475e-07
Iter: 681 loss: 5.85869657e-07
Iter: 682 loss: 5.85956514e-07
Iter: 683 loss: 5.85760688e-07
Iter: 684 loss: 5.85617556e-07
Iter: 685 loss: 5.8580963e-07
Iter: 686 loss: 5.85511316e-07
Iter: 687 loss: 5.85364546e-07
Iter: 688 loss: 5.8539041e-07
Iter: 689 loss: 5.85308157e-07
Iter: 690 loss: 5.85085274e-07
Iter: 691 loss: 5.869814e-07
Iter: 692 loss: 5.85003704e-07
Iter: 693 loss: 5.84761437e-07
Iter: 694 loss: 5.85775922e-07
Iter: 695 loss: 5.84734607e-07
Iter: 696 loss: 5.84608813e-07
Iter: 697 loss: 5.84603924e-07
Iter: 698 loss: 5.84514339e-07
Iter: 699 loss: 5.84395821e-07
Iter: 700 loss: 5.84400084e-07
Iter: 701 loss: 5.84300722e-07
Iter: 702 loss: 5.85584246e-07
Iter: 703 loss: 5.84277245e-07
Iter: 704 loss: 5.84197323e-07
Iter: 705 loss: 5.84163558e-07
Iter: 706 loss: 5.8410933e-07
Iter: 707 loss: 5.84013264e-07
Iter: 708 loss: 5.83890255e-07
Iter: 709 loss: 5.83865813e-07
Iter: 710 loss: 5.83720805e-07
Iter: 711 loss: 5.85820203e-07
Iter: 712 loss: 5.83724e-07
Iter: 713 loss: 5.83540725e-07
Iter: 714 loss: 5.84113707e-07
Iter: 715 loss: 5.8350065e-07
Iter: 716 loss: 5.83314659e-07
Iter: 717 loss: 5.83246276e-07
Iter: 718 loss: 5.83127758e-07
Iter: 719 loss: 5.82948076e-07
Iter: 720 loss: 5.82953874e-07
Iter: 721 loss: 5.82795565e-07
Iter: 722 loss: 5.82797441e-07
Iter: 723 loss: 5.82727807e-07
Iter: 724 loss: 5.8256262e-07
Iter: 725 loss: 5.82278403e-07
Iter: 726 loss: 5.82238727e-07
Iter: 727 loss: 5.8216142e-07
Iter: 728 loss: 5.82146527e-07
Iter: 729 loss: 5.82026928e-07
Iter: 730 loss: 5.82373843e-07
Iter: 731 loss: 5.81905852e-07
Iter: 732 loss: 5.81836616e-07
Iter: 733 loss: 5.81748452e-07
Iter: 734 loss: 5.81711163e-07
Iter: 735 loss: 5.81559675e-07
Iter: 736 loss: 5.83615474e-07
Iter: 737 loss: 5.81523238e-07
Iter: 738 loss: 5.81435359e-07
Iter: 739 loss: 5.81328095e-07
Iter: 740 loss: 5.81312463e-07
Iter: 741 loss: 5.81163931e-07
Iter: 742 loss: 5.81296149e-07
Iter: 743 loss: 5.81057407e-07
Iter: 744 loss: 5.80934511e-07
Iter: 745 loss: 5.80922574e-07
Iter: 746 loss: 5.80839753e-07
Iter: 747 loss: 5.80739e-07
Iter: 748 loss: 5.80708502e-07
Iter: 749 loss: 5.80581798e-07
Iter: 750 loss: 5.80587653e-07
Iter: 751 loss: 5.80532969e-07
Iter: 752 loss: 5.80522624e-07
Iter: 753 loss: 5.80442816e-07
Iter: 754 loss: 5.80289338e-07
Iter: 755 loss: 5.80267113e-07
Iter: 756 loss: 5.80225105e-07
Iter: 757 loss: 5.80063386e-07
Iter: 758 loss: 5.80380458e-07
Iter: 759 loss: 5.7997164e-07
Iter: 760 loss: 5.79845221e-07
Iter: 761 loss: 5.79834591e-07
Iter: 762 loss: 5.79698508e-07
Iter: 763 loss: 5.79515927e-07
Iter: 764 loss: 5.79532582e-07
Iter: 765 loss: 5.79370294e-07
Iter: 766 loss: 5.80121309e-07
Iter: 767 loss: 5.79296852e-07
Iter: 768 loss: 5.79132916e-07
Iter: 769 loss: 5.81408472e-07
Iter: 770 loss: 5.79139453e-07
Iter: 771 loss: 5.79083178e-07
Iter: 772 loss: 5.78928507e-07
Iter: 773 loss: 5.8138005e-07
Iter: 774 loss: 5.7894988e-07
Iter: 775 loss: 5.7882221e-07
Iter: 776 loss: 5.79368816e-07
Iter: 777 loss: 5.78750587e-07
Iter: 778 loss: 5.78693061e-07
Iter: 779 loss: 5.78658728e-07
Iter: 780 loss: 5.78584036e-07
Iter: 781 loss: 5.78472736e-07
Iter: 782 loss: 5.81121e-07
Iter: 783 loss: 5.78473646e-07
Iter: 784 loss: 5.78375e-07
Iter: 785 loss: 5.78346544e-07
Iter: 786 loss: 5.78277877e-07
Iter: 787 loss: 5.78111269e-07
Iter: 788 loss: 5.80570884e-07
Iter: 789 loss: 5.78060167e-07
Iter: 790 loss: 5.77919309e-07
Iter: 791 loss: 5.78673962e-07
Iter: 792 loss: 5.77875e-07
Iter: 793 loss: 5.77765377e-07
Iter: 794 loss: 5.77939147e-07
Iter: 795 loss: 5.77694777e-07
Iter: 796 loss: 5.77621165e-07
Iter: 797 loss: 5.77570916e-07
Iter: 798 loss: 5.77527089e-07
Iter: 799 loss: 5.77487185e-07
Iter: 800 loss: 5.77457627e-07
Iter: 801 loss: 5.77369235e-07
Iter: 802 loss: 5.77354683e-07
Iter: 803 loss: 5.77300739e-07
Iter: 804 loss: 5.77196488e-07
Iter: 805 loss: 5.78285778e-07
Iter: 806 loss: 5.77172159e-07
Iter: 807 loss: 5.77064498e-07
Iter: 808 loss: 5.76994807e-07
Iter: 809 loss: 5.76973207e-07
Iter: 810 loss: 5.7682729e-07
Iter: 811 loss: 5.76811601e-07
Iter: 812 loss: 5.76691946e-07
Iter: 813 loss: 5.76622199e-07
Iter: 814 loss: 5.76572688e-07
Iter: 815 loss: 5.76488674e-07
Iter: 816 loss: 5.76475315e-07
Iter: 817 loss: 5.76400225e-07
Iter: 818 loss: 5.76333036e-07
Iter: 819 loss: 5.76339346e-07
Iter: 820 loss: 5.76285856e-07
Iter: 821 loss: 5.76162108e-07
Iter: 822 loss: 5.78915717e-07
Iter: 823 loss: 5.76159891e-07
Iter: 824 loss: 5.76032676e-07
Iter: 825 loss: 5.76092134e-07
Iter: 826 loss: 5.75955482e-07
Iter: 827 loss: 5.75782394e-07
Iter: 828 loss: 5.76074058e-07
Iter: 829 loss: 5.75753859e-07
Iter: 830 loss: 5.75575939e-07
Iter: 831 loss: 5.7621196e-07
Iter: 832 loss: 5.7556025e-07
Iter: 833 loss: 5.75474417e-07
Iter: 834 loss: 5.75486069e-07
Iter: 835 loss: 5.75403533e-07
Iter: 836 loss: 5.75272452e-07
Iter: 837 loss: 5.75267336e-07
Iter: 838 loss: 5.75156e-07
Iter: 839 loss: 5.76154662e-07
Iter: 840 loss: 5.75150807e-07
Iter: 841 loss: 5.75037461e-07
Iter: 842 loss: 5.75464753e-07
Iter: 843 loss: 5.75021659e-07
Iter: 844 loss: 5.74955038e-07
Iter: 845 loss: 5.74797241e-07
Iter: 846 loss: 5.77733829e-07
Iter: 847 loss: 5.7481509e-07
Iter: 848 loss: 5.74689466e-07
Iter: 849 loss: 5.74685032e-07
Iter: 850 loss: 5.74561682e-07
Iter: 851 loss: 5.74695548e-07
Iter: 852 loss: 5.74465787e-07
Iter: 853 loss: 5.74365799e-07
Iter: 854 loss: 5.7510664e-07
Iter: 855 loss: 5.74343574e-07
Iter: 856 loss: 5.74242222e-07
Iter: 857 loss: 5.74159117e-07
Iter: 858 loss: 5.74103467e-07
Iter: 859 loss: 5.73986881e-07
Iter: 860 loss: 5.73923e-07
Iter: 861 loss: 5.73832381e-07
Iter: 862 loss: 5.73639113e-07
Iter: 863 loss: 5.74408318e-07
Iter: 864 loss: 5.73619161e-07
Iter: 865 loss: 5.73494447e-07
Iter: 866 loss: 5.73901787e-07
Iter: 867 loss: 5.73445902e-07
Iter: 868 loss: 5.73381442e-07
Iter: 869 loss: 5.733487e-07
Iter: 870 loss: 5.73275315e-07
Iter: 871 loss: 5.73219722e-07
Iter: 872 loss: 5.73186298e-07
Iter: 873 loss: 5.73074772e-07
Iter: 874 loss: 5.73488194e-07
Iter: 875 loss: 5.73070849e-07
Iter: 876 loss: 5.72973931e-07
Iter: 877 loss: 5.74038552e-07
Iter: 878 loss: 5.72970862e-07
Iter: 879 loss: 5.72880083e-07
Iter: 880 loss: 5.72745364e-07
Iter: 881 loss: 5.75073841e-07
Iter: 882 loss: 5.72745648e-07
Iter: 883 loss: 5.72618376e-07
Iter: 884 loss: 5.73527529e-07
Iter: 885 loss: 5.72567387e-07
Iter: 886 loss: 5.72490762e-07
Iter: 887 loss: 5.73850627e-07
Iter: 888 loss: 5.72488318e-07
Iter: 889 loss: 5.72433692e-07
Iter: 890 loss: 5.72392253e-07
Iter: 891 loss: 5.72380372e-07
Iter: 892 loss: 5.72278509e-07
Iter: 893 loss: 5.73089096e-07
Iter: 894 loss: 5.72283682e-07
Iter: 895 loss: 5.72199497e-07
Iter: 896 loss: 5.72072054e-07
Iter: 897 loss: 5.74641433e-07
Iter: 898 loss: 5.72064437e-07
Iter: 899 loss: 5.71938529e-07
Iter: 900 loss: 5.72045e-07
Iter: 901 loss: 5.71809e-07
Iter: 902 loss: 5.71638793e-07
Iter: 903 loss: 5.71967689e-07
Iter: 904 loss: 5.71546877e-07
Iter: 905 loss: 5.7133434e-07
Iter: 906 loss: 5.72517536e-07
Iter: 907 loss: 5.71333032e-07
Iter: 908 loss: 5.71195301e-07
Iter: 909 loss: 5.71196836e-07
Iter: 910 loss: 5.71076271e-07
Iter: 911 loss: 5.7097833e-07
Iter: 912 loss: 5.70976226e-07
Iter: 913 loss: 5.70815359e-07
Iter: 914 loss: 5.71217413e-07
Iter: 915 loss: 5.70776e-07
Iter: 916 loss: 5.70712132e-07
Iter: 917 loss: 5.70701161e-07
Iter: 918 loss: 5.70663246e-07
Iter: 919 loss: 5.70581619e-07
Iter: 920 loss: 5.72036583e-07
Iter: 921 loss: 5.70547627e-07
Iter: 922 loss: 5.70468046e-07
Iter: 923 loss: 5.70743168e-07
Iter: 924 loss: 5.70445593e-07
Iter: 925 loss: 5.70377438e-07
Iter: 926 loss: 5.71444787e-07
Iter: 927 loss: 5.70373686e-07
Iter: 928 loss: 5.7030752e-07
Iter: 929 loss: 5.70191446e-07
Iter: 930 loss: 5.70173938e-07
Iter: 931 loss: 5.70104362e-07
Iter: 932 loss: 5.70086229e-07
Iter: 933 loss: 5.70011196e-07
Iter: 934 loss: 5.69988913e-07
Iter: 935 loss: 5.69969416e-07
Iter: 936 loss: 5.69867325e-07
Iter: 937 loss: 5.6978962e-07
Iter: 938 loss: 5.69769668e-07
Iter: 939 loss: 5.69646147e-07
Iter: 940 loss: 5.70211796e-07
Iter: 941 loss: 5.69607096e-07
Iter: 942 loss: 5.6952365e-07
Iter: 943 loss: 5.69711062e-07
Iter: 944 loss: 5.69461122e-07
Iter: 945 loss: 5.69367501e-07
Iter: 946 loss: 5.69372901e-07
Iter: 947 loss: 5.69312704e-07
Iter: 948 loss: 5.69188273e-07
Iter: 949 loss: 5.71437795e-07
Iter: 950 loss: 5.6918077e-07
Iter: 951 loss: 5.69128588e-07
Iter: 952 loss: 5.69105396e-07
Iter: 953 loss: 5.69014787e-07
Iter: 954 loss: 5.68919518e-07
Iter: 955 loss: 5.6891713e-07
Iter: 956 loss: 5.68775135e-07
Iter: 957 loss: 5.69345e-07
Iter: 958 loss: 5.68715222e-07
Iter: 959 loss: 5.68625524e-07
Iter: 960 loss: 5.70100724e-07
Iter: 961 loss: 5.68608812e-07
Iter: 962 loss: 5.6858687e-07
Iter: 963 loss: 5.68505811e-07
Iter: 964 loss: 5.68486314e-07
Iter: 965 loss: 5.68406847e-07
Iter: 966 loss: 5.69321912e-07
Iter: 967 loss: 5.68398605e-07
Iter: 968 loss: 5.68345058e-07
Iter: 969 loss: 5.68304358e-07
Iter: 970 loss: 5.68275823e-07
Iter: 971 loss: 5.68214375e-07
Iter: 972 loss: 5.68315613e-07
Iter: 973 loss: 5.68140479e-07
Iter: 974 loss: 5.68047881e-07
Iter: 975 loss: 5.68040548e-07
Iter: 976 loss: 5.68013661e-07
Iter: 977 loss: 5.67873485e-07
Iter: 978 loss: 5.68563792e-07
Iter: 979 loss: 5.67822894e-07
Iter: 980 loss: 5.67682605e-07
Iter: 981 loss: 5.68926055e-07
Iter: 982 loss: 5.67666e-07
Iter: 983 loss: 5.67610641e-07
Iter: 984 loss: 5.67517247e-07
Iter: 985 loss: 5.67497693e-07
Iter: 986 loss: 5.67405777e-07
Iter: 987 loss: 5.68714e-07
Iter: 988 loss: 5.67404811e-07
Iter: 989 loss: 5.67319262e-07
Iter: 990 loss: 5.67548852e-07
Iter: 991 loss: 5.6728868e-07
Iter: 992 loss: 5.6720603e-07
Iter: 993 loss: 5.67112693e-07
Iter: 994 loss: 5.69281156e-07
Iter: 995 loss: 5.67097345e-07
Iter: 996 loss: 5.67013672e-07
Iter: 997 loss: 5.66980248e-07
Iter: 998 loss: 5.66901122e-07
Iter: 999 loss: 5.66827055e-07
Iter: 1000 loss: 5.66782887e-07
Iter: 1001 loss: 5.66644701e-07
Iter: 1002 loss: 5.66991559e-07
Iter: 1003 loss: 5.66632707e-07
Iter: 1004 loss: 5.6649742e-07
Iter: 1005 loss: 5.67521965e-07
Iter: 1006 loss: 5.66505832e-07
Iter: 1007 loss: 5.66404253e-07
Iter: 1008 loss: 5.66278e-07
Iter: 1009 loss: 5.66262258e-07
Iter: 1010 loss: 5.66098777e-07
Iter: 1011 loss: 5.66783797e-07
Iter: 1012 loss: 5.66080246e-07
Iter: 1013 loss: 5.65970709e-07
Iter: 1014 loss: 5.67033908e-07
Iter: 1015 loss: 5.65967468e-07
Iter: 1016 loss: 5.65874302e-07
Iter: 1017 loss: 5.66318363e-07
Iter: 1018 loss: 5.65870323e-07
Iter: 1019 loss: 5.65838377e-07
Iter: 1020 loss: 5.65737423e-07
Iter: 1021 loss: 5.6576323e-07
Iter: 1022 loss: 5.65662276e-07
Iter: 1023 loss: 5.6658422e-07
Iter: 1024 loss: 5.65679727e-07
Iter: 1025 loss: 5.65604864e-07
Iter: 1026 loss: 5.65638743e-07
Iter: 1027 loss: 5.65535629e-07
Iter: 1028 loss: 5.65464291e-07
Iter: 1029 loss: 5.65334801e-07
Iter: 1030 loss: 5.65346568e-07
Iter: 1031 loss: 5.65306e-07
Iter: 1032 loss: 5.65282903e-07
Iter: 1033 loss: 5.6522606e-07
Iter: 1034 loss: 5.65106575e-07
Iter: 1035 loss: 5.66478718e-07
Iter: 1036 loss: 5.65082928e-07
Iter: 1037 loss: 5.65001187e-07
Iter: 1038 loss: 5.66176823e-07
Iter: 1039 loss: 5.64972083e-07
Iter: 1040 loss: 5.64850552e-07
Iter: 1041 loss: 5.65066102e-07
Iter: 1042 loss: 5.64766253e-07
Iter: 1043 loss: 5.64730101e-07
Iter: 1044 loss: 5.6471896e-07
Iter: 1045 loss: 5.64654e-07
Iter: 1046 loss: 5.6459578e-07
Iter: 1047 loss: 5.64736638e-07
Iter: 1048 loss: 5.64529444e-07
Iter: 1049 loss: 5.64432639e-07
Iter: 1050 loss: 5.65549556e-07
Iter: 1051 loss: 5.6446e-07
Iter: 1052 loss: 5.64367667e-07
Iter: 1053 loss: 5.64326228e-07
Iter: 1054 loss: 5.64283937e-07
Iter: 1055 loss: 5.64154732e-07
Iter: 1056 loss: 5.64303548e-07
Iter: 1057 loss: 5.64090442e-07
Iter: 1058 loss: 5.63966353e-07
Iter: 1059 loss: 5.63955837e-07
Iter: 1060 loss: 5.63891035e-07
Iter: 1061 loss: 5.63722892e-07
Iter: 1062 loss: 5.65539892e-07
Iter: 1063 loss: 5.63679578e-07
Iter: 1064 loss: 5.63653e-07
Iter: 1065 loss: 5.63610399e-07
Iter: 1066 loss: 5.63513197e-07
Iter: 1067 loss: 5.63443109e-07
Iter: 1068 loss: 5.63439301e-07
Iter: 1069 loss: 5.63358412e-07
Iter: 1070 loss: 5.63615458e-07
Iter: 1071 loss: 5.63304411e-07
Iter: 1072 loss: 5.63261494e-07
Iter: 1073 loss: 5.63246488e-07
Iter: 1074 loss: 5.63164349e-07
Iter: 1075 loss: 5.63090452e-07
Iter: 1076 loss: 5.64930644e-07
Iter: 1077 loss: 5.63120523e-07
Iter: 1078 loss: 5.63017693e-07
Iter: 1079 loss: 5.63176911e-07
Iter: 1080 loss: 5.62969717e-07
Iter: 1081 loss: 5.62867456e-07
Iter: 1082 loss: 5.63100116e-07
Iter: 1083 loss: 5.62834884e-07
Iter: 1084 loss: 5.62727223e-07
Iter: 1085 loss: 5.6303179e-07
Iter: 1086 loss: 5.62648438e-07
Iter: 1087 loss: 5.62572552e-07
Iter: 1088 loss: 5.62459377e-07
Iter: 1089 loss: 5.62409355e-07
Iter: 1090 loss: 5.62348077e-07
Iter: 1091 loss: 5.62317609e-07
Iter: 1092 loss: 5.62229275e-07
Iter: 1093 loss: 5.62063235e-07
Iter: 1094 loss: 5.62093533e-07
Iter: 1095 loss: 5.61963873e-07
Iter: 1096 loss: 5.62607568e-07
Iter: 1097 loss: 5.61937213e-07
Iter: 1098 loss: 5.61843706e-07
Iter: 1099 loss: 5.62852051e-07
Iter: 1100 loss: 5.61844843e-07
Iter: 1101 loss: 5.61783622e-07
Iter: 1102 loss: 5.61700062e-07
Iter: 1103 loss: 5.63759784e-07
Iter: 1104 loss: 5.61676131e-07
Iter: 1105 loss: 5.61586717e-07
Iter: 1106 loss: 5.61607294e-07
Iter: 1107 loss: 5.61487e-07
Iter: 1108 loss: 5.61421245e-07
Iter: 1109 loss: 5.61380034e-07
Iter: 1110 loss: 5.61271577e-07
Iter: 1111 loss: 5.61467175e-07
Iter: 1112 loss: 5.61203137e-07
Iter: 1113 loss: 5.61083937e-07
Iter: 1114 loss: 5.6259114e-07
Iter: 1115 loss: 5.61066145e-07
Iter: 1116 loss: 5.60952458e-07
Iter: 1117 loss: 5.61104343e-07
Iter: 1118 loss: 5.60907324e-07
Iter: 1119 loss: 5.60765784e-07
Iter: 1120 loss: 5.6106893e-07
Iter: 1121 loss: 5.60735316e-07
Iter: 1122 loss: 5.60650392e-07
Iter: 1123 loss: 5.60959279e-07
Iter: 1124 loss: 5.60626802e-07
Iter: 1125 loss: 5.60501235e-07
Iter: 1126 loss: 5.6146888e-07
Iter: 1127 loss: 5.60517492e-07
Iter: 1128 loss: 5.60461729e-07
Iter: 1129 loss: 5.60327521e-07
Iter: 1130 loss: 5.62244963e-07
Iter: 1131 loss: 5.60336673e-07
Iter: 1132 loss: 5.60281e-07
Iter: 1133 loss: 5.60291369e-07
Iter: 1134 loss: 5.60240551e-07
Iter: 1135 loss: 5.60149942e-07
Iter: 1136 loss: 5.61909474e-07
Iter: 1137 loss: 5.60132605e-07
Iter: 1138 loss: 5.60060926e-07
Iter: 1139 loss: 5.60743104e-07
Iter: 1140 loss: 5.60045407e-07
Iter: 1141 loss: 5.59927685e-07
Iter: 1142 loss: 5.59984642e-07
Iter: 1143 loss: 5.59870614e-07
Iter: 1144 loss: 5.59745899e-07
Iter: 1145 loss: 5.59566331e-07
Iter: 1146 loss: 5.5956275e-07
Iter: 1147 loss: 5.59400121e-07
Iter: 1148 loss: 5.61437673e-07
Iter: 1149 loss: 5.5941149e-07
Iter: 1150 loss: 5.59263412e-07
Iter: 1151 loss: 5.60330477e-07
Iter: 1152 loss: 5.59270234e-07
Iter: 1153 loss: 5.59171099e-07
Iter: 1154 loss: 5.59108059e-07
Iter: 1155 loss: 5.59089528e-07
Iter: 1156 loss: 5.58960551e-07
Iter: 1157 loss: 5.59132e-07
Iter: 1158 loss: 5.58923091e-07
Iter: 1159 loss: 5.58822478e-07
Iter: 1160 loss: 5.58837428e-07
Iter: 1161 loss: 5.58735735e-07
Iter: 1162 loss: 5.58663771e-07
Iter: 1163 loss: 5.58673889e-07
Iter: 1164 loss: 5.58574243e-07
Iter: 1165 loss: 5.59372779e-07
Iter: 1166 loss: 5.58617e-07
Iter: 1167 loss: 5.58508589e-07
Iter: 1168 loss: 5.58786951e-07
Iter: 1169 loss: 5.58450381e-07
Iter: 1170 loss: 5.58427e-07
Iter: 1171 loss: 5.58291049e-07
Iter: 1172 loss: 5.58291845e-07
Iter: 1173 loss: 5.58244892e-07
Iter: 1174 loss: 5.58216698e-07
Iter: 1175 loss: 5.5819396e-07
Iter: 1176 loss: 5.58041393e-07
Iter: 1177 loss: 5.60516071e-07
Iter: 1178 loss: 5.58071747e-07
Iter: 1179 loss: 5.57933163e-07
Iter: 1180 loss: 5.58125066e-07
Iter: 1181 loss: 5.5786569e-07
Iter: 1182 loss: 5.57778321e-07
Iter: 1183 loss: 5.57791054e-07
Iter: 1184 loss: 5.57714884e-07
Iter: 1185 loss: 5.578e-07
Iter: 1186 loss: 5.57684643e-07
Iter: 1187 loss: 5.57574594e-07
Iter: 1188 loss: 5.57508429e-07
Iter: 1189 loss: 5.57496264e-07
Iter: 1190 loss: 5.57376552e-07
Iter: 1191 loss: 5.58678266e-07
Iter: 1192 loss: 5.57375e-07
Iter: 1193 loss: 5.57266048e-07
Iter: 1194 loss: 5.57646956e-07
Iter: 1195 loss: 5.57217277e-07
Iter: 1196 loss: 5.57126725e-07
Iter: 1197 loss: 5.57003148e-07
Iter: 1198 loss: 5.5701355e-07
Iter: 1199 loss: 5.56961822e-07
Iter: 1200 loss: 5.56937835e-07
Iter: 1201 loss: 5.5685922e-07
Iter: 1202 loss: 5.56763382e-07
Iter: 1203 loss: 5.56791292e-07
Iter: 1204 loss: 5.56684427e-07
Iter: 1205 loss: 5.57453859e-07
Iter: 1206 loss: 5.56673399e-07
Iter: 1207 loss: 5.56609905e-07
Iter: 1208 loss: 5.56627185e-07
Iter: 1209 loss: 5.56552777e-07
Iter: 1210 loss: 5.56457621e-07
Iter: 1211 loss: 5.56418627e-07
Iter: 1212 loss: 5.56391399e-07
Iter: 1213 loss: 5.56269811e-07
Iter: 1214 loss: 5.56415102e-07
Iter: 1215 loss: 5.56191367e-07
Iter: 1216 loss: 5.56100133e-07
Iter: 1217 loss: 5.56083137e-07
Iter: 1218 loss: 5.56016175e-07
Iter: 1219 loss: 5.55923066e-07
Iter: 1220 loss: 5.55926817e-07
Iter: 1221 loss: 5.55806196e-07
Iter: 1222 loss: 5.56040789e-07
Iter: 1223 loss: 5.55754752e-07
Iter: 1224 loss: 5.55723886e-07
Iter: 1225 loss: 5.55698477e-07
Iter: 1226 loss: 5.55649478e-07
Iter: 1227 loss: 5.55530391e-07
Iter: 1228 loss: 5.57257465e-07
Iter: 1229 loss: 5.55496399e-07
Iter: 1230 loss: 5.55413123e-07
Iter: 1231 loss: 5.56579721e-07
Iter: 1232 loss: 5.55383622e-07
Iter: 1233 loss: 5.55322401e-07
Iter: 1234 loss: 5.55679662e-07
Iter: 1235 loss: 5.55289091e-07
Iter: 1236 loss: 5.55216559e-07
Iter: 1237 loss: 5.55159e-07
Iter: 1238 loss: 5.55151132e-07
Iter: 1239 loss: 5.55052566e-07
Iter: 1240 loss: 5.55047109e-07
Iter: 1241 loss: 5.54996404e-07
Iter: 1242 loss: 5.5487817e-07
Iter: 1243 loss: 5.54871065e-07
Iter: 1244 loss: 5.54762892e-07
Iter: 1245 loss: 5.54890107e-07
Iter: 1246 loss: 5.54736175e-07
Iter: 1247 loss: 5.54613223e-07
Iter: 1248 loss: 5.5470548e-07
Iter: 1249 loss: 5.54512326e-07
Iter: 1250 loss: 5.54446672e-07
Iter: 1251 loss: 5.54415294e-07
Iter: 1252 loss: 5.5436135e-07
Iter: 1253 loss: 5.5440313e-07
Iter: 1254 loss: 5.54327e-07
Iter: 1255 loss: 5.54237147e-07
Iter: 1256 loss: 5.54167173e-07
Iter: 1257 loss: 5.54129088e-07
Iter: 1258 loss: 5.54072528e-07
Iter: 1259 loss: 5.54077928e-07
Iter: 1260 loss: 5.54007329e-07
Iter: 1261 loss: 5.54012331e-07
Iter: 1262 loss: 5.53950599e-07
Iter: 1263 loss: 5.53891596e-07
Iter: 1264 loss: 5.53899156e-07
Iter: 1265 loss: 5.53848281e-07
Iter: 1266 loss: 5.53792802e-07
Iter: 1267 loss: 5.5485333e-07
Iter: 1268 loss: 5.53788141e-07
Iter: 1269 loss: 5.53707366e-07
Iter: 1270 loss: 5.53670475e-07
Iter: 1271 loss: 5.53639666e-07
Iter: 1272 loss: 5.53578047e-07
Iter: 1273 loss: 5.53606924e-07
Iter: 1274 loss: 5.53554173e-07
Iter: 1275 loss: 5.53501479e-07
Iter: 1276 loss: 5.55012718e-07
Iter: 1277 loss: 5.53490793e-07
Iter: 1278 loss: 5.53386144e-07
Iter: 1279 loss: 5.53440486e-07
Iter: 1280 loss: 5.53315829e-07
Iter: 1281 loss: 5.53233292e-07
Iter: 1282 loss: 5.53367613e-07
Iter: 1283 loss: 5.5317679e-07
Iter: 1284 loss: 5.53068389e-07
Iter: 1285 loss: 5.53913651e-07
Iter: 1286 loss: 5.53035932e-07
Iter: 1287 loss: 5.52971869e-07
Iter: 1288 loss: 5.52971755e-07
Iter: 1289 loss: 5.52883421e-07
Iter: 1290 loss: 5.52778545e-07
Iter: 1291 loss: 5.53431732e-07
Iter: 1292 loss: 5.52767e-07
Iter: 1293 loss: 5.52674749e-07
Iter: 1294 loss: 5.53291e-07
Iter: 1295 loss: 5.52648942e-07
Iter: 1296 loss: 5.52603069e-07
Iter: 1297 loss: 5.52508766e-07
Iter: 1298 loss: 5.52514e-07
Iter: 1299 loss: 5.52473921e-07
Iter: 1300 loss: 5.52481595e-07
Iter: 1301 loss: 5.5242208e-07
Iter: 1302 loss: 5.52330846e-07
Iter: 1303 loss: 5.53297923e-07
Iter: 1304 loss: 5.52355232e-07
Iter: 1305 loss: 5.52289634e-07
Iter: 1306 loss: 5.52321467e-07
Iter: 1307 loss: 5.52220968e-07
Iter: 1308 loss: 5.52145366e-07
Iter: 1309 loss: 5.53989935e-07
Iter: 1310 loss: 5.52123879e-07
Iter: 1311 loss: 5.52051802e-07
Iter: 1312 loss: 5.52363417e-07
Iter: 1313 loss: 5.52043e-07
Iter: 1314 loss: 5.51943231e-07
Iter: 1315 loss: 5.5196756e-07
Iter: 1316 loss: 5.51866663e-07
Iter: 1317 loss: 5.51792368e-07
Iter: 1318 loss: 5.51785433e-07
Iter: 1319 loss: 5.51714834e-07
Iter: 1320 loss: 5.51698179e-07
Iter: 1321 loss: 5.51661856e-07
Iter: 1322 loss: 5.51524522e-07
Iter: 1323 loss: 5.51442099e-07
Iter: 1324 loss: 5.51427547e-07
Iter: 1325 loss: 5.51317953e-07
Iter: 1326 loss: 5.51314884e-07
Iter: 1327 loss: 5.51212281e-07
Iter: 1328 loss: 5.5131818e-07
Iter: 1329 loss: 5.51135656e-07
Iter: 1330 loss: 5.51049823e-07
Iter: 1331 loss: 5.51002643e-07
Iter: 1332 loss: 5.50973255e-07
Iter: 1333 loss: 5.50904247e-07
Iter: 1334 loss: 5.50868663e-07
Iter: 1335 loss: 5.50770039e-07
Iter: 1336 loss: 5.50923914e-07
Iter: 1337 loss: 5.50764071e-07
Iter: 1338 loss: 5.50686593e-07
Iter: 1339 loss: 5.50635207e-07
Iter: 1340 loss: 5.50634809e-07
Iter: 1341 loss: 5.50543405e-07
Iter: 1342 loss: 5.50552386e-07
Iter: 1343 loss: 5.50474851e-07
Iter: 1344 loss: 5.5044228e-07
Iter: 1345 loss: 5.51996209e-07
Iter: 1346 loss: 5.5044211e-07
Iter: 1347 loss: 5.50391746e-07
Iter: 1348 loss: 5.50548634e-07
Iter: 1349 loss: 5.50355821e-07
Iter: 1350 loss: 5.50252707e-07
Iter: 1351 loss: 5.51241442e-07
Iter: 1352 loss: 5.50247819e-07
Iter: 1353 loss: 5.50231334e-07
Iter: 1354 loss: 5.50174946e-07
Iter: 1355 loss: 5.50201435e-07
Iter: 1356 loss: 5.50068307e-07
Iter: 1357 loss: 5.50058189e-07
Iter: 1358 loss: 5.50023969e-07
Iter: 1359 loss: 5.49978779e-07
Iter: 1360 loss: 5.49976846e-07
Iter: 1361 loss: 5.49927108e-07
Iter: 1362 loss: 5.49877313e-07
Iter: 1363 loss: 5.49851109e-07
Iter: 1364 loss: 5.49811148e-07
Iter: 1365 loss: 5.4972611e-07
Iter: 1366 loss: 5.49716106e-07
Iter: 1367 loss: 5.49639424e-07
Iter: 1368 loss: 5.49626805e-07
Iter: 1369 loss: 5.49566494e-07
Iter: 1370 loss: 5.49779884e-07
Iter: 1371 loss: 5.49523463e-07
Iter: 1372 loss: 5.49498168e-07
Iter: 1373 loss: 5.49387153e-07
Iter: 1374 loss: 5.51756443e-07
Iter: 1375 loss: 5.49380729e-07
Iter: 1376 loss: 5.49269885e-07
Iter: 1377 loss: 5.49904769e-07
Iter: 1378 loss: 5.4923413e-07
Iter: 1379 loss: 5.49167737e-07
Iter: 1380 loss: 5.49192066e-07
Iter: 1381 loss: 5.49126355e-07
Iter: 1382 loss: 5.49001811e-07
Iter: 1383 loss: 5.50679658e-07
Iter: 1384 loss: 5.49024776e-07
Iter: 1385 loss: 5.48925755e-07
Iter: 1386 loss: 5.49144602e-07
Iter: 1387 loss: 5.48913761e-07
Iter: 1388 loss: 5.48873231e-07
Iter: 1389 loss: 5.48838273e-07
Iter: 1390 loss: 5.4881383e-07
Iter: 1391 loss: 5.48708613e-07
Iter: 1392 loss: 5.48712649e-07
Iter: 1393 loss: 5.48628122e-07
Iter: 1394 loss: 5.48983621e-07
Iter: 1395 loss: 5.48625394e-07
Iter: 1396 loss: 5.48578726e-07
Iter: 1397 loss: 5.48566788e-07
Iter: 1398 loss: 5.48517505e-07
Iter: 1399 loss: 5.48400408e-07
Iter: 1400 loss: 5.4984389e-07
Iter: 1401 loss: 5.48428034e-07
Iter: 1402 loss: 5.48354876e-07
Iter: 1403 loss: 5.48360617e-07
Iter: 1404 loss: 5.48342e-07
Iter: 1405 loss: 5.48292121e-07
Iter: 1406 loss: 5.48242383e-07
Iter: 1407 loss: 5.48173546e-07
Iter: 1408 loss: 5.48096295e-07
Iter: 1409 loss: 5.48083904e-07
Iter: 1410 loss: 5.47966579e-07
Iter: 1411 loss: 5.49189906e-07
Iter: 1412 loss: 5.47961918e-07
Iter: 1413 loss: 5.47909508e-07
Iter: 1414 loss: 5.4849761e-07
Iter: 1415 loss: 5.47886543e-07
Iter: 1416 loss: 5.47859486e-07
Iter: 1417 loss: 5.47710954e-07
Iter: 1418 loss: 5.49592073e-07
Iter: 1419 loss: 5.47718912e-07
Iter: 1420 loss: 5.47621767e-07
Iter: 1421 loss: 5.48668766e-07
Iter: 1422 loss: 5.47593459e-07
Iter: 1423 loss: 5.47535137e-07
Iter: 1424 loss: 5.48322305e-07
Iter: 1425 loss: 5.47535308e-07
Iter: 1426 loss: 5.47414743e-07
Iter: 1427 loss: 5.47366596e-07
Iter: 1428 loss: 5.47339e-07
Iter: 1429 loss: 5.47241768e-07
Iter: 1430 loss: 5.47616764e-07
Iter: 1431 loss: 5.47237335e-07
Iter: 1432 loss: 5.47166337e-07
Iter: 1433 loss: 5.47176683e-07
Iter: 1434 loss: 5.47148488e-07
Iter: 1435 loss: 5.47000184e-07
Iter: 1436 loss: 5.48036041e-07
Iter: 1437 loss: 5.46933165e-07
Iter: 1438 loss: 5.46911679e-07
Iter: 1439 loss: 5.46917e-07
Iter: 1440 loss: 5.46817546e-07
Iter: 1441 loss: 5.46942431e-07
Iter: 1442 loss: 5.46804529e-07
Iter: 1443 loss: 5.46731769e-07
Iter: 1444 loss: 5.46570959e-07
Iter: 1445 loss: 5.48516084e-07
Iter: 1446 loss: 5.46565e-07
Iter: 1447 loss: 5.46431465e-07
Iter: 1448 loss: 5.47300431e-07
Iter: 1449 loss: 5.46415777e-07
Iter: 1450 loss: 5.46327669e-07
Iter: 1451 loss: 5.46338811e-07
Iter: 1452 loss: 5.4626139e-07
Iter: 1453 loss: 5.46101319e-07
Iter: 1454 loss: 5.46136334e-07
Iter: 1455 loss: 5.46017077e-07
Iter: 1456 loss: 5.46311185e-07
Iter: 1457 loss: 5.45998546e-07
Iter: 1458 loss: 5.45859791e-07
Iter: 1459 loss: 5.45943294e-07
Iter: 1460 loss: 5.45815283e-07
Iter: 1461 loss: 5.45715238e-07
Iter: 1462 loss: 5.46864328e-07
Iter: 1463 loss: 5.45709e-07
Iter: 1464 loss: 5.45630655e-07
Iter: 1465 loss: 5.46040894e-07
Iter: 1466 loss: 5.45618377e-07
Iter: 1467 loss: 5.45550449e-07
Iter: 1468 loss: 5.45453531e-07
Iter: 1469 loss: 5.45434091e-07
Iter: 1470 loss: 5.45333705e-07
Iter: 1471 loss: 5.45902253e-07
Iter: 1472 loss: 5.45314e-07
Iter: 1473 loss: 5.45186708e-07
Iter: 1474 loss: 5.46288902e-07
Iter: 1475 loss: 5.45206e-07
Iter: 1476 loss: 5.45113608e-07
Iter: 1477 loss: 5.45010892e-07
Iter: 1478 loss: 5.47399793e-07
Iter: 1479 loss: 5.45004582e-07
Iter: 1480 loss: 5.45013165e-07
Iter: 1481 loss: 5.44949273e-07
Iter: 1482 loss: 5.44908687e-07
Iter: 1483 loss: 5.44867191e-07
Iter: 1484 loss: 5.46401282e-07
Iter: 1485 loss: 5.44840532e-07
Iter: 1486 loss: 5.44779823e-07
Iter: 1487 loss: 5.44688e-07
Iter: 1488 loss: 5.44666364e-07
Iter: 1489 loss: 5.44609691e-07
Iter: 1490 loss: 5.44616967e-07
Iter: 1491 loss: 5.44527e-07
Iter: 1492 loss: 5.44626801e-07
Iter: 1493 loss: 5.44508111e-07
Iter: 1494 loss: 5.44439e-07
Iter: 1495 loss: 5.44254476e-07
Iter: 1496 loss: 5.46748254e-07
Iter: 1497 loss: 5.44247655e-07
Iter: 1498 loss: 5.44090824e-07
Iter: 1499 loss: 5.45481385e-07
Iter: 1500 loss: 5.44104864e-07
Iter: 1501 loss: 5.43995384e-07
Iter: 1502 loss: 5.44003683e-07
Iter: 1503 loss: 5.43919782e-07
Iter: 1504 loss: 5.43914325e-07
Iter: 1505 loss: 5.43883061e-07
Iter: 1506 loss: 5.43814451e-07
Iter: 1507 loss: 5.43908811e-07
Iter: 1508 loss: 5.43782505e-07
Iter: 1509 loss: 5.4367888e-07
Iter: 1510 loss: 5.44594172e-07
Iter: 1511 loss: 5.43692636e-07
Iter: 1512 loss: 5.43638862e-07
Iter: 1513 loss: 5.43472652e-07
Iter: 1514 loss: 5.44672446e-07
Iter: 1515 loss: 5.43462875e-07
Iter: 1516 loss: 5.43384431e-07
Iter: 1517 loss: 5.43399608e-07
Iter: 1518 loss: 5.43343162e-07
Iter: 1519 loss: 5.43263354e-07
Iter: 1520 loss: 5.43208102e-07
Iter: 1521 loss: 5.43103795e-07
Iter: 1522 loss: 5.43087481e-07
Iter: 1523 loss: 5.43001249e-07
Iter: 1524 loss: 5.42876e-07
Iter: 1525 loss: 5.43726856e-07
Iter: 1526 loss: 5.42838e-07
Iter: 1527 loss: 5.42699e-07
Iter: 1528 loss: 5.43685e-07
Iter: 1529 loss: 5.42699e-07
Iter: 1530 loss: 5.42635803e-07
Iter: 1531 loss: 5.42618409e-07
Iter: 1532 loss: 5.42554517e-07
Iter: 1533 loss: 5.42495172e-07
Iter: 1534 loss: 5.42583166e-07
Iter: 1535 loss: 5.42455723e-07
Iter: 1536 loss: 5.42353e-07
Iter: 1537 loss: 5.42376142e-07
Iter: 1538 loss: 5.42285534e-07
Iter: 1539 loss: 5.42266434e-07
Iter: 1540 loss: 5.42232726e-07
Iter: 1541 loss: 5.42196176e-07
Iter: 1542 loss: 5.42044745e-07
Iter: 1543 loss: 5.42956286e-07
Iter: 1544 loss: 5.42011605e-07
Iter: 1545 loss: 5.41872168e-07
Iter: 1546 loss: 5.42955434e-07
Iter: 1547 loss: 5.41863699e-07
Iter: 1548 loss: 5.41747113e-07
Iter: 1549 loss: 5.42998635e-07
Iter: 1550 loss: 5.4174933e-07
Iter: 1551 loss: 5.41685665e-07
Iter: 1552 loss: 5.41628e-07
Iter: 1553 loss: 5.4161444e-07
Iter: 1554 loss: 5.41550662e-07
Iter: 1555 loss: 5.41598467e-07
Iter: 1556 loss: 5.4149848e-07
Iter: 1557 loss: 5.41428562e-07
Iter: 1558 loss: 5.41440443e-07
Iter: 1559 loss: 5.41374e-07
Iter: 1560 loss: 5.41639395e-07
Iter: 1561 loss: 5.41360578e-07
Iter: 1562 loss: 5.41250927e-07
Iter: 1563 loss: 5.4134739e-07
Iter: 1564 loss: 5.41189593e-07
Iter: 1565 loss: 5.41105862e-07
Iter: 1566 loss: 5.41100349e-07
Iter: 1567 loss: 5.41061411e-07
Iter: 1568 loss: 5.40998144e-07
Iter: 1569 loss: 5.40944768e-07
Iter: 1570 loss: 5.40908275e-07
Iter: 1571 loss: 5.40783276e-07
Iter: 1572 loss: 5.4081454e-07
Iter: 1573 loss: 5.40728252e-07
Iter: 1574 loss: 5.41104441e-07
Iter: 1575 loss: 5.40735186e-07
Iter: 1576 loss: 5.40674876e-07
Iter: 1577 loss: 5.40602457e-07
Iter: 1578 loss: 5.40569886e-07
Iter: 1579 loss: 5.40519807e-07
Iter: 1580 loss: 5.41185727e-07
Iter: 1581 loss: 5.40535893e-07
Iter: 1582 loss: 5.40476094e-07
Iter: 1583 loss: 5.41004965e-07
Iter: 1584 loss: 5.40483256e-07
Iter: 1585 loss: 5.40456824e-07
Iter: 1586 loss: 5.4034615e-07
Iter: 1587 loss: 5.41854e-07
Iter: 1588 loss: 5.40338419e-07
Iter: 1589 loss: 5.40324891e-07
Iter: 1590 loss: 5.40294138e-07
Iter: 1591 loss: 5.40269866e-07
Iter: 1592 loss: 5.40168799e-07
Iter: 1593 loss: 5.40633721e-07
Iter: 1594 loss: 5.40132874e-07
Iter: 1595 loss: 5.40025042e-07
Iter: 1596 loss: 5.40114399e-07
Iter: 1597 loss: 5.39972e-07
Iter: 1598 loss: 5.39960183e-07
Iter: 1599 loss: 5.39912207e-07
Iter: 1600 loss: 5.39847179e-07
Iter: 1601 loss: 5.39780501e-07
Iter: 1602 loss: 5.39797043e-07
Iter: 1603 loss: 5.39673465e-07
Iter: 1604 loss: 5.39643224e-07
Iter: 1605 loss: 5.395882e-07
Iter: 1606 loss: 5.39557504e-07
Iter: 1607 loss: 5.39541247e-07
Iter: 1608 loss: 5.39465361e-07
Iter: 1609 loss: 5.39498956e-07
Iter: 1610 loss: 5.39443874e-07
Iter: 1611 loss: 5.3933303e-07
Iter: 1612 loss: 5.39331268e-07
Iter: 1613 loss: 5.39285224e-07
Iter: 1614 loss: 5.39179155e-07
Iter: 1615 loss: 5.39197458e-07
Iter: 1616 loss: 5.3914323e-07
Iter: 1617 loss: 5.39419148e-07
Iter: 1618 loss: 5.39136863e-07
Iter: 1619 loss: 5.391272e-07
Iter: 1620 loss: 5.3907263e-07
Iter: 1621 loss: 5.39035682e-07
Iter: 1622 loss: 5.39002542e-07
Iter: 1623 loss: 5.39004816e-07
Iter: 1624 loss: 5.39000268e-07
Iter: 1625 loss: 5.38928873e-07
Iter: 1626 loss: 5.39809662e-07
Iter: 1627 loss: 5.38914037e-07
Iter: 1628 loss: 5.38851111e-07
Iter: 1629 loss: 5.38919892e-07
Iter: 1630 loss: 5.38797053e-07
Iter: 1631 loss: 5.38735208e-07
Iter: 1632 loss: 5.38762436e-07
Iter: 1633 loss: 5.38678705e-07
Iter: 1634 loss: 5.38589575e-07
Iter: 1635 loss: 5.38605377e-07
Iter: 1636 loss: 5.38478616e-07
Iter: 1637 loss: 5.3843587e-07
Iter: 1638 loss: 5.38387781e-07
Iter: 1639 loss: 5.38307063e-07
Iter: 1640 loss: 5.38313827e-07
Iter: 1641 loss: 5.38232655e-07
Iter: 1642 loss: 5.38766812e-07
Iter: 1643 loss: 5.38227937e-07
Iter: 1644 loss: 5.38200766e-07
Iter: 1645 loss: 5.38049278e-07
Iter: 1646 loss: 5.38057634e-07
Iter: 1647 loss: 5.38015627e-07
Iter: 1648 loss: 5.38882659e-07
Iter: 1649 loss: 5.37975552e-07
Iter: 1650 loss: 5.37913e-07
Iter: 1651 loss: 5.38102427e-07
Iter: 1652 loss: 5.37894891e-07
Iter: 1653 loss: 5.3782378e-07
Iter: 1654 loss: 5.37835945e-07
Iter: 1655 loss: 5.3780866e-07
Iter: 1656 loss: 5.3769736e-07
Iter: 1657 loss: 5.38331619e-07
Iter: 1658 loss: 5.37663084e-07
Iter: 1659 loss: 5.37621759e-07
Iter: 1660 loss: 5.37540586e-07
Iter: 1661 loss: 5.3753314e-07
Iter: 1662 loss: 5.37431e-07
Iter: 1663 loss: 5.37891424e-07
Iter: 1664 loss: 5.37426899e-07
Iter: 1665 loss: 5.37401831e-07
Iter: 1666 loss: 5.37382448e-07
Iter: 1667 loss: 5.37358119e-07
Iter: 1668 loss: 5.37297467e-07
Iter: 1669 loss: 5.38784434e-07
Iter: 1670 loss: 5.37281039e-07
Iter: 1671 loss: 5.37215556e-07
Iter: 1672 loss: 5.37350672e-07
Iter: 1673 loss: 5.37199298e-07
Iter: 1674 loss: 5.3713859e-07
Iter: 1675 loss: 5.3734334e-07
Iter: 1676 loss: 5.37105166e-07
Iter: 1677 loss: 5.37056223e-07
Iter: 1678 loss: 5.37279277e-07
Iter: 1679 loss: 5.37041501e-07
Iter: 1680 loss: 5.36961238e-07
Iter: 1681 loss: 5.36859147e-07
Iter: 1682 loss: 5.36851189e-07
Iter: 1683 loss: 5.36755067e-07
Iter: 1684 loss: 5.36764446e-07
Iter: 1685 loss: 5.3666156e-07
Iter: 1686 loss: 5.36604261e-07
Iter: 1687 loss: 5.36556342e-07
Iter: 1688 loss: 5.36516552e-07
Iter: 1689 loss: 5.37572134e-07
Iter: 1690 loss: 5.36499329e-07
Iter: 1691 loss: 5.3644294e-07
Iter: 1692 loss: 5.36447374e-07
Iter: 1693 loss: 5.36407697e-07
Iter: 1694 loss: 5.36350171e-07
Iter: 1695 loss: 5.3622216e-07
Iter: 1696 loss: 5.36235802e-07
Iter: 1697 loss: 5.36109496e-07
Iter: 1698 loss: 5.3654469e-07
Iter: 1699 loss: 5.36119785e-07
Iter: 1700 loss: 5.36053051e-07
Iter: 1701 loss: 5.36020593e-07
Iter: 1702 loss: 5.35994161e-07
Iter: 1703 loss: 5.35908271e-07
Iter: 1704 loss: 5.37397796e-07
Iter: 1705 loss: 5.3586848e-07
Iter: 1706 loss: 5.3577827e-07
Iter: 1707 loss: 5.35940671e-07
Iter: 1708 loss: 5.35726826e-07
Iter: 1709 loss: 5.35627635e-07
Iter: 1710 loss: 5.35874733e-07
Iter: 1711 loss: 5.35595404e-07
Iter: 1712 loss: 5.35485526e-07
Iter: 1713 loss: 5.35830225e-07
Iter: 1714 loss: 5.35483082e-07
Iter: 1715 loss: 5.35408844e-07
Iter: 1716 loss: 5.35440222e-07
Iter: 1717 loss: 5.35397135e-07
Iter: 1718 loss: 5.3533995e-07
Iter: 1719 loss: 5.36151504e-07
Iter: 1720 loss: 5.35324432e-07
Iter: 1721 loss: 5.35294248e-07
Iter: 1722 loss: 5.35269237e-07
Iter: 1723 loss: 5.3522632e-07
Iter: 1724 loss: 5.35207221e-07
Iter: 1725 loss: 5.35222171e-07
Iter: 1726 loss: 5.3513935e-07
Iter: 1727 loss: 5.35249342e-07
Iter: 1728 loss: 5.35155e-07
Iter: 1729 loss: 5.35035838e-07
Iter: 1730 loss: 5.35117124e-07
Iter: 1731 loss: 5.34988487e-07
Iter: 1732 loss: 5.34895491e-07
Iter: 1733 loss: 5.34868832e-07
Iter: 1734 loss: 5.34846e-07
Iter: 1735 loss: 5.34715923e-07
Iter: 1736 loss: 5.34982178e-07
Iter: 1737 loss: 5.34685853e-07
Iter: 1738 loss: 5.34546757e-07
Iter: 1739 loss: 5.36156676e-07
Iter: 1740 loss: 5.34537776e-07
Iter: 1741 loss: 5.34498554e-07
Iter: 1742 loss: 5.34408059e-07
Iter: 1743 loss: 5.34396804e-07
Iter: 1744 loss: 5.34276865e-07
Iter: 1745 loss: 5.34408741e-07
Iter: 1746 loss: 5.34204673e-07
Iter: 1747 loss: 5.34102071e-07
Iter: 1748 loss: 5.3432052e-07
Iter: 1749 loss: 5.34064952e-07
Iter: 1750 loss: 5.33908747e-07
Iter: 1751 loss: 5.34386402e-07
Iter: 1752 loss: 5.33859179e-07
Iter: 1753 loss: 5.33762034e-07
Iter: 1754 loss: 5.33756918e-07
Iter: 1755 loss: 5.33686773e-07
Iter: 1756 loss: 5.33632829e-07
Iter: 1757 loss: 5.33622824e-07
Iter: 1758 loss: 5.33554555e-07
Iter: 1759 loss: 5.33573655e-07
Iter: 1760 loss: 5.33542789e-07
Iter: 1761 loss: 5.33426487e-07
Iter: 1762 loss: 5.35606e-07
Iter: 1763 loss: 5.33431717e-07
Iter: 1764 loss: 5.33351908e-07
Iter: 1765 loss: 5.33359298e-07
Iter: 1766 loss: 5.333074e-07
Iter: 1767 loss: 5.33433195e-07
Iter: 1768 loss: 5.33282048e-07
Iter: 1769 loss: 5.3325175e-07
Iter: 1770 loss: 5.33207583e-07
Iter: 1771 loss: 5.34749e-07
Iter: 1772 loss: 5.33191e-07
Iter: 1773 loss: 5.33154662e-07
Iter: 1774 loss: 5.33123284e-07
Iter: 1775 loss: 5.33082186e-07
Iter: 1776 loss: 5.33047626e-07
Iter: 1777 loss: 5.33034779e-07
Iter: 1778 loss: 5.32959575e-07
Iter: 1779 loss: 5.32846911e-07
Iter: 1780 loss: 5.32838669e-07
Iter: 1781 loss: 5.32745503e-07
Iter: 1782 loss: 5.33924663e-07
Iter: 1783 loss: 5.32722652e-07
Iter: 1784 loss: 5.32650859e-07
Iter: 1785 loss: 5.32713784e-07
Iter: 1786 loss: 5.3258907e-07
Iter: 1787 loss: 5.32571e-07
Iter: 1788 loss: 5.33338607e-07
Iter: 1789 loss: 5.32585204e-07
Iter: 1790 loss: 5.32513468e-07
Iter: 1791 loss: 5.32634488e-07
Iter: 1792 loss: 5.32466e-07
Iter: 1793 loss: 5.32418085e-07
Iter: 1794 loss: 5.32397166e-07
Iter: 1795 loss: 5.32370223e-07
Iter: 1796 loss: 5.32330432e-07
Iter: 1797 loss: 5.32327817e-07
Iter: 1798 loss: 5.32255626e-07
Iter: 1799 loss: 5.32227887e-07
Iter: 1800 loss: 5.3221919e-07
Iter: 1801 loss: 5.32186618e-07
Iter: 1802 loss: 5.32166382e-07
Iter: 1803 loss: 5.32138642e-07
Iter: 1804 loss: 5.32005913e-07
Iter: 1805 loss: 5.33877426e-07
Iter: 1806 loss: 5.31991532e-07
Iter: 1807 loss: 5.31927071e-07
Iter: 1808 loss: 5.31947364e-07
Iter: 1809 loss: 5.31872558e-07
Iter: 1810 loss: 5.31834303e-07
Iter: 1811 loss: 5.31797298e-07
Iter: 1812 loss: 5.3175529e-07
Iter: 1813 loss: 5.31827936e-07
Iter: 1814 loss: 5.31697367e-07
Iter: 1815 loss: 5.31636147e-07
Iter: 1816 loss: 5.31824e-07
Iter: 1817 loss: 5.31598175e-07
Iter: 1818 loss: 5.31525416e-07
Iter: 1819 loss: 5.3165769e-07
Iter: 1820 loss: 5.31493413e-07
Iter: 1821 loss: 5.31391834e-07
Iter: 1822 loss: 5.31787805e-07
Iter: 1823 loss: 5.31396154e-07
Iter: 1824 loss: 5.31364435e-07
Iter: 1825 loss: 5.32042577e-07
Iter: 1826 loss: 5.31347837e-07
Iter: 1827 loss: 5.31270757e-07
Iter: 1828 loss: 5.31179694e-07
Iter: 1829 loss: 5.32167292e-07
Iter: 1830 loss: 5.31178614e-07
Iter: 1831 loss: 5.31099e-07
Iter: 1832 loss: 5.31096248e-07
Iter: 1833 loss: 5.31021328e-07
Iter: 1834 loss: 5.31617445e-07
Iter: 1835 loss: 5.31023147e-07
Iter: 1836 loss: 5.30964655e-07
Iter: 1837 loss: 5.3092316e-07
Iter: 1838 loss: 5.3092549e-07
Iter: 1839 loss: 5.30818852e-07
Iter: 1840 loss: 5.31279568e-07
Iter: 1841 loss: 5.30812258e-07
Iter: 1842 loss: 5.30752061e-07
Iter: 1843 loss: 5.30708917e-07
Iter: 1844 loss: 5.30686123e-07
Iter: 1845 loss: 5.30618934e-07
Iter: 1846 loss: 5.30607451e-07
Iter: 1847 loss: 5.30579484e-07
Iter: 1848 loss: 5.30553734e-07
Iter: 1849 loss: 5.30526279e-07
Iter: 1850 loss: 5.30462557e-07
Iter: 1851 loss: 5.30428167e-07
Iter: 1852 loss: 5.30398722e-07
Iter: 1853 loss: 5.30351372e-07
Iter: 1854 loss: 5.30567036e-07
Iter: 1855 loss: 5.30270881e-07
Iter: 1856 loss: 5.30261e-07
Iter: 1857 loss: 5.30267585e-07
Iter: 1858 loss: 5.30201646e-07
Iter: 1859 loss: 5.30558111e-07
Iter: 1860 loss: 5.30232967e-07
Iter: 1861 loss: 5.30191699e-07
Iter: 1862 loss: 5.30109673e-07
Iter: 1863 loss: 5.31329e-07
Iter: 1864 loss: 5.30111151e-07
Iter: 1865 loss: 5.30074658e-07
Iter: 1866 loss: 5.30737e-07
Iter: 1867 loss: 5.30045099e-07
Iter: 1868 loss: 5.30017e-07
Iter: 1869 loss: 5.30075909e-07
Iter: 1870 loss: 5.30007412e-07
Iter: 1871 loss: 5.29925103e-07
Iter: 1872 loss: 5.29862518e-07
Iter: 1873 loss: 5.29864508e-07
Iter: 1874 loss: 5.29882868e-07
Iter: 1875 loss: 5.29854447e-07
Iter: 1876 loss: 5.29821193e-07
Iter: 1877 loss: 5.29774354e-07
Iter: 1878 loss: 5.29779072e-07
Iter: 1879 loss: 5.29735189e-07
Iter: 1880 loss: 5.2964424e-07
Iter: 1881 loss: 5.29642648e-07
Iter: 1882 loss: 5.29606382e-07
Iter: 1883 loss: 5.29613e-07
Iter: 1884 loss: 5.29540443e-07
Iter: 1885 loss: 5.29706369e-07
Iter: 1886 loss: 5.29526801e-07
Iter: 1887 loss: 5.29493661e-07
Iter: 1888 loss: 5.29434374e-07
Iter: 1889 loss: 5.30805892e-07
Iter: 1890 loss: 5.29423687e-07
Iter: 1891 loss: 5.29343424e-07
Iter: 1892 loss: 5.29665158e-07
Iter: 1893 loss: 5.29334613e-07
Iter: 1894 loss: 5.29263957e-07
Iter: 1895 loss: 5.30291572e-07
Iter: 1896 loss: 5.29265151e-07
Iter: 1897 loss: 5.29219506e-07
Iter: 1898 loss: 5.29138902e-07
Iter: 1899 loss: 5.3049223e-07
Iter: 1900 loss: 5.29107297e-07
Iter: 1901 loss: 5.29050453e-07
Iter: 1902 loss: 5.29974386e-07
Iter: 1903 loss: 5.29059434e-07
Iter: 1904 loss: 5.28975079e-07
Iter: 1905 loss: 5.29341378e-07
Iter: 1906 loss: 5.28979399e-07
Iter: 1907 loss: 5.28965529e-07
Iter: 1908 loss: 5.28931764e-07
Iter: 1909 loss: 5.28914939e-07
Iter: 1910 loss: 5.28878786e-07
Iter: 1911 loss: 5.29541126e-07
Iter: 1912 loss: 5.28879e-07
Iter: 1913 loss: 5.28854e-07
Iter: 1914 loss: 5.28829787e-07
Iter: 1915 loss: 5.28773683e-07
Iter: 1916 loss: 5.28764133e-07
Iter: 1917 loss: 5.28675287e-07
Iter: 1918 loss: 5.28695921e-07
Iter: 1919 loss: 5.28624128e-07
Iter: 1920 loss: 5.29055114e-07
Iter: 1921 loss: 5.28623559e-07
Iter: 1922 loss: 5.28560577e-07
Iter: 1923 loss: 5.29205295e-07
Iter: 1924 loss: 5.28546309e-07
Iter: 1925 loss: 5.28499811e-07
Iter: 1926 loss: 5.2838692e-07
Iter: 1927 loss: 5.30663215e-07
Iter: 1928 loss: 5.28396356e-07
Iter: 1929 loss: 5.28320413e-07
Iter: 1930 loss: 5.28558303e-07
Iter: 1931 loss: 5.28310864e-07
Iter: 1932 loss: 5.28222245e-07
Iter: 1933 loss: 5.28228156e-07
Iter: 1934 loss: 5.28158e-07
Iter: 1935 loss: 5.28126634e-07
Iter: 1936 loss: 5.28079909e-07
Iter: 1937 loss: 5.28052738e-07
Iter: 1938 loss: 5.2840835e-07
Iter: 1939 loss: 5.27997656e-07
Iter: 1940 loss: 5.2794735e-07
Iter: 1941 loss: 5.28249529e-07
Iter: 1942 loss: 5.27939505e-07
Iter: 1943 loss: 5.27892553e-07
Iter: 1944 loss: 5.27818088e-07
Iter: 1945 loss: 5.29267e-07
Iter: 1946 loss: 5.27827467e-07
Iter: 1947 loss: 5.27845714e-07
Iter: 1948 loss: 5.27801717e-07
Iter: 1949 loss: 5.27753059e-07
Iter: 1950 loss: 5.27692e-07
Iter: 1951 loss: 5.28599799e-07
Iter: 1952 loss: 5.27683596e-07
Iter: 1953 loss: 5.2765796e-07
Iter: 1954 loss: 5.27644261e-07
Iter: 1955 loss: 5.27600776e-07
Iter: 1956 loss: 5.27481e-07
Iter: 1957 loss: 5.28500436e-07
Iter: 1958 loss: 5.27471173e-07
Iter: 1959 loss: 5.27428938e-07
Iter: 1960 loss: 5.27865723e-07
Iter: 1961 loss: 5.27394775e-07
Iter: 1962 loss: 5.27358509e-07
Iter: 1963 loss: 5.27365046e-07
Iter: 1964 loss: 5.27317297e-07
Iter: 1965 loss: 5.27282737e-07
Iter: 1966 loss: 5.27749705e-07
Iter: 1967 loss: 5.2726466e-07
Iter: 1968 loss: 5.27214e-07
Iter: 1969 loss: 5.27228849e-07
Iter: 1970 loss: 5.27199461e-07
Iter: 1971 loss: 5.2716149e-07
Iter: 1972 loss: 5.2733094e-07
Iter: 1973 loss: 5.27120108e-07
Iter: 1974 loss: 5.27101065e-07
Iter: 1975 loss: 5.27075372e-07
Iter: 1976 loss: 5.27034672e-07
Iter: 1977 loss: 5.26981125e-07
Iter: 1978 loss: 5.26988174e-07
Iter: 1979 loss: 5.26880285e-07
Iter: 1980 loss: 5.27121074e-07
Iter: 1981 loss: 5.26906831e-07
Iter: 1982 loss: 5.26802864e-07
Iter: 1983 loss: 5.27434622e-07
Iter: 1984 loss: 5.26810823e-07
Iter: 1985 loss: 5.26771771e-07
Iter: 1986 loss: 5.26650865e-07
Iter: 1987 loss: 5.28408918e-07
Iter: 1988 loss: 5.26665e-07
Iter: 1989 loss: 5.26541839e-07
Iter: 1990 loss: 5.26915699e-07
Iter: 1991 loss: 5.26510803e-07
Iter: 1992 loss: 5.26441795e-07
Iter: 1993 loss: 5.27563714e-07
Iter: 1994 loss: 5.26446456e-07
Iter: 1995 loss: 5.26404961e-07
Iter: 1996 loss: 5.26629833e-07
Iter: 1997 loss: 5.26371764e-07
Iter: 1998 loss: 5.2632879e-07
Iter: 1999 loss: 5.26343456e-07
Iter: 2000 loss: 5.2630088e-07
Iter: 2001 loss: 5.26209874e-07
Iter: 2002 loss: 5.2656037e-07
Iter: 2003 loss: 5.26227097e-07
Iter: 2004 loss: 5.26184408e-07
Iter: 2005 loss: 5.26139104e-07
Iter: 2006 loss: 5.26107954e-07
Iter: 2007 loss: 5.26054e-07
Iter: 2008 loss: 5.26597262e-07
Iter: 2009 loss: 5.26065321e-07
Iter: 2010 loss: 5.2596863e-07
Iter: 2011 loss: 5.26020756e-07
Iter: 2012 loss: 5.25914345e-07
Iter: 2013 loss: 5.2584744e-07
Iter: 2014 loss: 5.25829364e-07
Iter: 2015 loss: 5.25785083e-07
Iter: 2016 loss: 5.25741257e-07
Iter: 2017 loss: 5.25726875e-07
Iter: 2018 loss: 5.25679354e-07
Iter: 2019 loss: 5.25638939e-07
Iter: 2020 loss: 5.25617736e-07
Iter: 2021 loss: 5.25570499e-07
Iter: 2022 loss: 5.25619214e-07
Iter: 2023 loss: 5.25543157e-07
Iter: 2024 loss: 5.25456358e-07
Iter: 2025 loss: 5.25544749e-07
Iter: 2026 loss: 5.25413498e-07
Iter: 2027 loss: 5.25352e-07
Iter: 2028 loss: 5.26312078e-07
Iter: 2029 loss: 5.25362339e-07
Iter: 2030 loss: 5.25245866e-07
Iter: 2031 loss: 5.25334258e-07
Iter: 2032 loss: 5.25226937e-07
Iter: 2033 loss: 5.25186749e-07
Iter: 2034 loss: 5.25738358e-07
Iter: 2035 loss: 5.25193286e-07
Iter: 2036 loss: 5.25110522e-07
Iter: 2037 loss: 5.25062e-07
Iter: 2038 loss: 5.25010876e-07
Iter: 2039 loss: 5.24961536e-07
Iter: 2040 loss: 5.25148948e-07
Iter: 2041 loss: 5.24913787e-07
Iter: 2042 loss: 5.24814141e-07
Iter: 2043 loss: 5.25987048e-07
Iter: 2044 loss: 5.24839493e-07
Iter: 2045 loss: 5.24771337e-07
Iter: 2046 loss: 5.24685902e-07
Iter: 2047 loss: 5.2685624e-07
Iter: 2048 loss: 5.24675443e-07
Iter: 2049 loss: 5.24564484e-07
Iter: 2050 loss: 5.24995073e-07
Iter: 2051 loss: 5.2453214e-07
Iter: 2052 loss: 5.24464099e-07
Iter: 2053 loss: 5.24475297e-07
Iter: 2054 loss: 5.24440111e-07
Iter: 2055 loss: 5.24346888e-07
Iter: 2056 loss: 5.2551286e-07
Iter: 2057 loss: 5.24350867e-07
Iter: 2058 loss: 5.24220638e-07
Iter: 2059 loss: 5.2423718e-07
Iter: 2060 loss: 5.2416e-07
Iter: 2061 loss: 5.2405278e-07
Iter: 2062 loss: 5.24051075e-07
Iter: 2063 loss: 5.23968652e-07
Iter: 2064 loss: 5.24422774e-07
Iter: 2065 loss: 5.23925e-07
Iter: 2066 loss: 5.23885319e-07
Iter: 2067 loss: 5.2390908e-07
Iter: 2068 loss: 5.23842857e-07
Iter: 2069 loss: 5.23752192e-07
Iter: 2070 loss: 5.24477855e-07
Iter: 2071 loss: 5.23752e-07
Iter: 2072 loss: 5.23674885e-07
Iter: 2073 loss: 5.23653171e-07
Iter: 2074 loss: 5.23638221e-07
Iter: 2075 loss: 5.23532719e-07
Iter: 2076 loss: 5.24514348e-07
Iter: 2077 loss: 5.23534936e-07
Iter: 2078 loss: 5.23436597e-07
Iter: 2079 loss: 5.23486392e-07
Iter: 2080 loss: 5.23440349e-07
Iter: 2081 loss: 5.23349797e-07
Iter: 2082 loss: 5.23384529e-07
Iter: 2083 loss: 5.2329051e-07
Iter: 2084 loss: 5.23250833e-07
Iter: 2085 loss: 5.23225253e-07
Iter: 2086 loss: 5.23179494e-07
Iter: 2087 loss: 5.23075755e-07
Iter: 2088 loss: 5.23077063e-07
Iter: 2089 loss: 5.22987875e-07
Iter: 2090 loss: 5.23118104e-07
Iter: 2091 loss: 5.22905168e-07
Iter: 2092 loss: 5.22830419e-07
Iter: 2093 loss: 5.22874e-07
Iter: 2094 loss: 5.22730659e-07
Iter: 2095 loss: 5.22655114e-07
Iter: 2096 loss: 5.2264005e-07
Iter: 2097 loss: 5.22567632e-07
Iter: 2098 loss: 5.2260134e-07
Iter: 2099 loss: 5.2253165e-07
Iter: 2100 loss: 5.22481514e-07
Iter: 2101 loss: 5.2269462e-07
Iter: 2102 loss: 5.22481287e-07
Iter: 2103 loss: 5.22393862e-07
Iter: 2104 loss: 5.2251778e-07
Iter: 2105 loss: 5.22367486e-07
Iter: 2106 loss: 5.22325081e-07
Iter: 2107 loss: 5.22371863e-07
Iter: 2108 loss: 5.22326957e-07
Iter: 2109 loss: 5.22255903e-07
Iter: 2110 loss: 5.22896698e-07
Iter: 2111 loss: 5.22256187e-07
Iter: 2112 loss: 5.22219864e-07
Iter: 2113 loss: 5.22155574e-07
Iter: 2114 loss: 5.22924779e-07
Iter: 2115 loss: 5.22145513e-07
Iter: 2116 loss: 5.2207622e-07
Iter: 2117 loss: 5.22490666e-07
Iter: 2118 loss: 5.22055e-07
Iter: 2119 loss: 5.21990785e-07
Iter: 2120 loss: 5.22872597e-07
Iter: 2121 loss: 5.2201608e-07
Iter: 2122 loss: 5.2195486e-07
Iter: 2123 loss: 5.21849302e-07
Iter: 2124 loss: 5.21848051e-07
Iter: 2125 loss: 5.21783136e-07
Iter: 2126 loss: 5.21889319e-07
Iter: 2127 loss: 5.21732204e-07
Iter: 2128 loss: 5.21668539e-07
Iter: 2129 loss: 5.221263e-07
Iter: 2130 loss: 5.21650122e-07
Iter: 2131 loss: 5.21590664e-07
Iter: 2132 loss: 5.2225522e-07
Iter: 2133 loss: 5.21601862e-07
Iter: 2134 loss: 5.21558661e-07
Iter: 2135 loss: 5.2147908e-07
Iter: 2136 loss: 5.21492666e-07
Iter: 2137 loss: 5.21440711e-07
Iter: 2138 loss: 5.21424283e-07
Iter: 2139 loss: 5.21392849e-07
Iter: 2140 loss: 5.21354593e-07
Iter: 2141 loss: 5.2135124e-07
Iter: 2142 loss: 5.21272682e-07
Iter: 2143 loss: 5.21568381e-07
Iter: 2144 loss: 5.21268589e-07
Iter: 2145 loss: 5.21205e-07
Iter: 2146 loss: 5.21371476e-07
Iter: 2147 loss: 5.21170477e-07
Iter: 2148 loss: 5.2106509e-07
Iter: 2149 loss: 5.20947708e-07
Iter: 2150 loss: 5.20940489e-07
Iter: 2151 loss: 5.20843912e-07
Iter: 2152 loss: 5.22446953e-07
Iter: 2153 loss: 5.20828962e-07
Iter: 2154 loss: 5.20730907e-07
Iter: 2155 loss: 5.21217487e-07
Iter: 2156 loss: 5.2074e-07
Iter: 2157 loss: 5.2067719e-07
Iter: 2158 loss: 5.20632113e-07
Iter: 2159 loss: 5.2060409e-07
Iter: 2160 loss: 5.2051314e-07
Iter: 2161 loss: 5.2082811e-07
Iter: 2162 loss: 5.20477556e-07
Iter: 2163 loss: 5.20389165e-07
Iter: 2164 loss: 5.20651383e-07
Iter: 2165 loss: 5.20409344e-07
Iter: 2166 loss: 5.20311062e-07
Iter: 2167 loss: 5.20689355e-07
Iter: 2168 loss: 5.20272863e-07
Iter: 2169 loss: 5.20211643e-07
Iter: 2170 loss: 5.20212268e-07
Iter: 2171 loss: 5.20144226e-07
Iter: 2172 loss: 5.20109666e-07
Iter: 2173 loss: 5.2010347e-07
Iter: 2174 loss: 5.2006186e-07
Iter: 2175 loss: 5.19971081e-07
Iter: 2176 loss: 5.21501306e-07
Iter: 2177 loss: 5.19983871e-07
Iter: 2178 loss: 5.19910486e-07
Iter: 2179 loss: 5.20234209e-07
Iter: 2180 loss: 5.19903438e-07
Iter: 2181 loss: 5.19804189e-07
Iter: 2182 loss: 5.20345793e-07
Iter: 2183 loss: 5.1982056e-07
Iter: 2184 loss: 5.1981e-07
Iter: 2185 loss: 5.19703917e-07
Iter: 2186 loss: 5.20734716e-07
Iter: 2187 loss: 5.19664127e-07
Iter: 2188 loss: 5.19602054e-07
Iter: 2189 loss: 5.20369269e-07
Iter: 2190 loss: 5.19614105e-07
Iter: 2191 loss: 5.19516e-07
Iter: 2192 loss: 5.19536911e-07
Iter: 2193 loss: 5.19511332e-07
Iter: 2194 loss: 5.1943141e-07
Iter: 2195 loss: 5.20260414e-07
Iter: 2196 loss: 5.194035e-07
Iter: 2197 loss: 5.19279524e-07
Iter: 2198 loss: 5.20050605e-07
Iter: 2199 loss: 5.19280434e-07
Iter: 2200 loss: 5.19185164e-07
Iter: 2201 loss: 5.20038043e-07
Iter: 2202 loss: 5.19215064e-07
Iter: 2203 loss: 5.19119226e-07
Iter: 2204 loss: 5.19171692e-07
Iter: 2205 loss: 5.19096318e-07
Iter: 2206 loss: 5.19032e-07
Iter: 2207 loss: 5.19085347e-07
Iter: 2208 loss: 5.18954948e-07
Iter: 2209 loss: 5.1885678e-07
Iter: 2210 loss: 5.19428681e-07
Iter: 2211 loss: 5.18824777e-07
Iter: 2212 loss: 5.18770207e-07
Iter: 2213 loss: 5.18726665e-07
Iter: 2214 loss: 5.18717457e-07
Iter: 2215 loss: 5.18677666e-07
Iter: 2216 loss: 5.1865095e-07
Iter: 2217 loss: 5.18612e-07
Iter: 2218 loss: 5.18499746e-07
Iter: 2219 loss: 5.20510241e-07
Iter: 2220 loss: 5.18498041e-07
Iter: 2221 loss: 5.1843142e-07
Iter: 2222 loss: 5.1874423e-07
Iter: 2223 loss: 5.18375543e-07
Iter: 2224 loss: 5.18334389e-07
Iter: 2225 loss: 5.18334275e-07
Iter: 2226 loss: 5.18260435e-07
Iter: 2227 loss: 5.1820814e-07
Iter: 2228 loss: 5.18207514e-07
Iter: 2229 loss: 5.18090246e-07
Iter: 2230 loss: 5.18204899e-07
Iter: 2231 loss: 5.18053298e-07
Iter: 2232 loss: 5.17980766e-07
Iter: 2233 loss: 5.19013724e-07
Iter: 2234 loss: 5.18007482e-07
Iter: 2235 loss: 5.17952117e-07
Iter: 2236 loss: 5.17946376e-07
Iter: 2237 loss: 5.17893e-07
Iter: 2238 loss: 5.17829392e-07
Iter: 2239 loss: 5.1799617e-07
Iter: 2240 loss: 5.17812737e-07
Iter: 2241 loss: 5.17777551e-07
Iter: 2242 loss: 5.18465697e-07
Iter: 2243 loss: 5.17772e-07
Iter: 2244 loss: 5.17726278e-07
Iter: 2245 loss: 5.17624301e-07
Iter: 2246 loss: 5.18735874e-07
Iter: 2247 loss: 5.17659316e-07
Iter: 2248 loss: 5.17599403e-07
Iter: 2249 loss: 5.175404e-07
Iter: 2250 loss: 5.17525e-07
Iter: 2251 loss: 5.17463491e-07
Iter: 2252 loss: 5.17464514e-07
Iter: 2253 loss: 5.17385843e-07
Iter: 2254 loss: 5.17191381e-07
Iter: 2255 loss: 5.17185413e-07
Iter: 2256 loss: 5.17019032e-07
Iter: 2257 loss: 5.18095476e-07
Iter: 2258 loss: 5.16990326e-07
Iter: 2259 loss: 5.16931891e-07
Iter: 2260 loss: 5.16904151e-07
Iter: 2261 loss: 5.16860098e-07
Iter: 2262 loss: 5.16772729e-07
Iter: 2263 loss: 5.16755e-07
Iter: 2264 loss: 5.16679734e-07
Iter: 2265 loss: 5.1712891e-07
Iter: 2266 loss: 5.16653813e-07
Iter: 2267 loss: 5.16617888e-07
Iter: 2268 loss: 5.17126068e-07
Iter: 2269 loss: 5.16632e-07
Iter: 2270 loss: 5.165831e-07
Iter: 2271 loss: 5.16517105e-07
Iter: 2272 loss: 5.18172442e-07
Iter: 2273 loss: 5.16483965e-07
Iter: 2274 loss: 5.16457e-07
Iter: 2275 loss: 5.16467196e-07
Iter: 2276 loss: 5.16423654e-07
Iter: 2277 loss: 5.16435762e-07
Iter: 2278 loss: 5.16384262e-07
Iter: 2279 loss: 5.16342595e-07
Iter: 2280 loss: 5.16290811e-07
Iter: 2281 loss: 5.16266539e-07
Iter: 2282 loss: 5.16218506e-07
Iter: 2283 loss: 5.16231e-07
Iter: 2284 loss: 5.16168086e-07
Iter: 2285 loss: 5.16131536e-07
Iter: 2286 loss: 5.16137277e-07
Iter: 2287 loss: 5.16055763e-07
Iter: 2288 loss: 5.16065029e-07
Iter: 2289 loss: 5.16016655e-07
Iter: 2290 loss: 5.15932584e-07
Iter: 2291 loss: 5.16236582e-07
Iter: 2292 loss: 5.15888246e-07
Iter: 2293 loss: 5.15853401e-07
Iter: 2294 loss: 5.15822592e-07
Iter: 2295 loss: 5.15788429e-07
Iter: 2296 loss: 5.15757733e-07
Iter: 2297 loss: 5.15719876e-07
Iter: 2298 loss: 5.15635634e-07
Iter: 2299 loss: 5.15706802e-07
Iter: 2300 loss: 5.15593911e-07
Iter: 2301 loss: 5.15493355e-07
Iter: 2302 loss: 5.16332307e-07
Iter: 2303 loss: 5.15483578e-07
Iter: 2304 loss: 5.15417241e-07
Iter: 2305 loss: 5.15271722e-07
Iter: 2306 loss: 5.17632543e-07
Iter: 2307 loss: 5.15308159e-07
Iter: 2308 loss: 5.15202601e-07
Iter: 2309 loss: 5.15222212e-07
Iter: 2310 loss: 5.15130637e-07
Iter: 2311 loss: 5.15098691e-07
Iter: 2312 loss: 5.15065324e-07
Iter: 2313 loss: 5.14986596e-07
Iter: 2314 loss: 5.15577426e-07
Iter: 2315 loss: 5.14975909e-07
Iter: 2316 loss: 5.14915598e-07
Iter: 2317 loss: 5.1530543e-07
Iter: 2318 loss: 5.14900478e-07
Iter: 2319 loss: 5.14865746e-07
Iter: 2320 loss: 5.14794237e-07
Iter: 2321 loss: 5.14785597e-07
Iter: 2322 loss: 5.14748479e-07
Iter: 2323 loss: 5.1472415e-07
Iter: 2324 loss: 5.1467083e-07
Iter: 2325 loss: 5.14587043e-07
Iter: 2326 loss: 5.15131887e-07
Iter: 2327 loss: 5.14592841e-07
Iter: 2328 loss: 5.14506553e-07
Iter: 2329 loss: 5.1537512e-07
Iter: 2330 loss: 5.14492285e-07
Iter: 2331 loss: 5.14476142e-07
Iter: 2332 loss: 5.14422254e-07
Iter: 2333 loss: 5.14410885e-07
Iter: 2334 loss: 5.14359954e-07
Iter: 2335 loss: 5.1433608e-07
Iter: 2336 loss: 5.14286228e-07
Iter: 2337 loss: 5.14256385e-07
Iter: 2338 loss: 5.14254566e-07
Iter: 2339 loss: 5.14148041e-07
Iter: 2340 loss: 5.14414353e-07
Iter: 2341 loss: 5.14168164e-07
Iter: 2342 loss: 5.14060389e-07
Iter: 2343 loss: 5.14569138e-07
Iter: 2344 loss: 5.14073463e-07
Iter: 2345 loss: 5.14001101e-07
Iter: 2346 loss: 5.13933117e-07
Iter: 2347 loss: 5.13948862e-07
Iter: 2348 loss: 5.13835062e-07
Iter: 2349 loss: 5.14194255e-07
Iter: 2350 loss: 5.13836198e-07
Iter: 2351 loss: 5.13776683e-07
Iter: 2352 loss: 5.13784187e-07
Iter: 2353 loss: 5.13719613e-07
Iter: 2354 loss: 5.13664304e-07
Iter: 2355 loss: 5.1482283e-07
Iter: 2356 loss: 5.13703128e-07
Iter: 2357 loss: 5.13574605e-07
Iter: 2358 loss: 5.13683517e-07
Iter: 2359 loss: 5.1354931e-07
Iter: 2360 loss: 5.1347007e-07
Iter: 2361 loss: 5.13499e-07
Iter: 2362 loss: 5.13444888e-07
Iter: 2363 loss: 5.13697103e-07
Iter: 2364 loss: 5.13462737e-07
Iter: 2365 loss: 5.13417604e-07
Iter: 2366 loss: 5.13357122e-07
Iter: 2367 loss: 5.14558565e-07
Iter: 2368 loss: 5.13335635e-07
Iter: 2369 loss: 5.13321e-07
Iter: 2370 loss: 5.13301927e-07
Iter: 2371 loss: 5.13266173e-07
Iter: 2372 loss: 5.13181533e-07
Iter: 2373 loss: 5.13205237e-07
Iter: 2374 loss: 5.13141799e-07
Iter: 2375 loss: 5.13112809e-07
Iter: 2376 loss: 5.13038685e-07
Iter: 2377 loss: 5.12982638e-07
Iter: 2378 loss: 5.13005205e-07
Iter: 2379 loss: 5.12923521e-07
Iter: 2380 loss: 5.12925453e-07
Iter: 2381 loss: 5.12866222e-07
Iter: 2382 loss: 5.12806423e-07
Iter: 2383 loss: 5.12861618e-07
Iter: 2384 loss: 5.12784254e-07
Iter: 2385 loss: 5.1274111e-07
Iter: 2386 loss: 5.12732754e-07
Iter: 2387 loss: 5.12710756e-07
Iter: 2388 loss: 5.1264692e-07
Iter: 2389 loss: 5.1334e-07
Iter: 2390 loss: 5.12675683e-07
Iter: 2391 loss: 5.12572456e-07
Iter: 2392 loss: 5.1262748e-07
Iter: 2393 loss: 5.12534939e-07
Iter: 2394 loss: 5.12494e-07
Iter: 2395 loss: 5.12482927e-07
Iter: 2396 loss: 5.12410907e-07
Iter: 2397 loss: 5.12420343e-07
Iter: 2398 loss: 5.12403858e-07
Iter: 2399 loss: 5.12330757e-07
Iter: 2400 loss: 5.12364352e-07
Iter: 2401 loss: 5.12274482e-07
Iter: 2402 loss: 5.12242138e-07
Iter: 2403 loss: 5.12240263e-07
Iter: 2404 loss: 5.12182623e-07
Iter: 2405 loss: 5.12134193e-07
Iter: 2406 loss: 5.12123506e-07
Iter: 2407 loss: 5.12068e-07
Iter: 2408 loss: 5.12129418e-07
Iter: 2409 loss: 5.12049041e-07
Iter: 2410 loss: 5.12004704e-07
Iter: 2411 loss: 5.12004476e-07
Iter: 2412 loss: 5.11942289e-07
Iter: 2413 loss: 5.12007318e-07
Iter: 2414 loss: 5.11911537e-07
Iter: 2415 loss: 5.11865551e-07
Iter: 2416 loss: 5.11792223e-07
Iter: 2417 loss: 5.11813937e-07
Iter: 2418 loss: 5.11728956e-07
Iter: 2419 loss: 5.13058296e-07
Iter: 2420 loss: 5.11727819e-07
Iter: 2421 loss: 5.1168945e-07
Iter: 2422 loss: 5.11613962e-07
Iter: 2423 loss: 5.12650161e-07
Iter: 2424 loss: 5.11626695e-07
Iter: 2425 loss: 5.11525855e-07
Iter: 2426 loss: 5.11887151e-07
Iter: 2427 loss: 5.1149641e-07
Iter: 2428 loss: 5.11478731e-07
Iter: 2429 loss: 5.11479811e-07
Iter: 2430 loss: 5.11456847e-07
Iter: 2431 loss: 5.11384656e-07
Iter: 2432 loss: 5.12510724e-07
Iter: 2433 loss: 5.113763e-07
Iter: 2434 loss: 5.11327528e-07
Iter: 2435 loss: 5.11413589e-07
Iter: 2436 loss: 5.11306666e-07
Iter: 2437 loss: 5.11237204e-07
Iter: 2438 loss: 5.11982e-07
Iter: 2439 loss: 5.11233281e-07
Iter: 2440 loss: 5.11224073e-07
Iter: 2441 loss: 5.11152166e-07
Iter: 2442 loss: 5.12400277e-07
Iter: 2443 loss: 5.111375e-07
Iter: 2444 loss: 5.11028304e-07
Iter: 2445 loss: 5.11490498e-07
Iter: 2446 loss: 5.11037456e-07
Iter: 2447 loss: 5.10951281e-07
Iter: 2448 loss: 5.10923e-07
Iter: 2449 loss: 5.10873178e-07
Iter: 2450 loss: 5.10812697e-07
Iter: 2451 loss: 5.10815539e-07
Iter: 2452 loss: 5.10709867e-07
Iter: 2453 loss: 5.1151568e-07
Iter: 2454 loss: 5.10709128e-07
Iter: 2455 loss: 5.10637335e-07
Iter: 2456 loss: 5.11017788e-07
Iter: 2457 loss: 5.10610903e-07
Iter: 2458 loss: 5.10584528e-07
Iter: 2459 loss: 5.10513587e-07
Iter: 2460 loss: 5.10530128e-07
Iter: 2461 loss: 5.10431107e-07
Iter: 2462 loss: 5.10762447e-07
Iter: 2463 loss: 5.10443442e-07
Iter: 2464 loss: 5.10346524e-07
Iter: 2465 loss: 5.11196959e-07
Iter: 2466 loss: 5.10358632e-07
Iter: 2467 loss: 5.10346e-07
Iter: 2468 loss: 5.1025529e-07
Iter: 2469 loss: 5.109315e-07
Iter: 2470 loss: 5.10236589e-07
Iter: 2471 loss: 5.10208793e-07
Iter: 2472 loss: 5.1107952e-07
Iter: 2473 loss: 5.10179575e-07
Iter: 2474 loss: 5.10063728e-07
Iter: 2475 loss: 5.10276436e-07
Iter: 2476 loss: 5.10048778e-07
Iter: 2477 loss: 5.10007908e-07
Iter: 2478 loss: 5.09933443e-07
Iter: 2479 loss: 5.09939468e-07
Iter: 2480 loss: 5.0985517e-07
Iter: 2481 loss: 5.1059061e-07
Iter: 2482 loss: 5.09845563e-07
Iter: 2483 loss: 5.09750237e-07
Iter: 2484 loss: 5.10111e-07
Iter: 2485 loss: 5.09722327e-07
Iter: 2486 loss: 5.09678e-07
Iter: 2487 loss: 5.09757569e-07
Iter: 2488 loss: 5.09643201e-07
Iter: 2489 loss: 5.09619611e-07
Iter: 2490 loss: 5.10014502e-07
Iter: 2491 loss: 5.09619667e-07
Iter: 2492 loss: 5.09585334e-07
Iter: 2493 loss: 5.09513029e-07
Iter: 2494 loss: 5.0948222e-07
Iter: 2495 loss: 5.09440611e-07
Iter: 2496 loss: 5.09422421e-07
Iter: 2497 loss: 5.09372114e-07
Iter: 2498 loss: 5.09262e-07
Iter: 2499 loss: 5.09301969e-07
Iter: 2500 loss: 5.09211361e-07
Iter: 2501 loss: 5.09243705e-07
Iter: 2502 loss: 5.0915213e-07
Iter: 2503 loss: 5.09098e-07
Iter: 2504 loss: 5.09187089e-07
Iter: 2505 loss: 5.09073402e-07
Iter: 2506 loss: 5.09020083e-07
Iter: 2507 loss: 5.09025426e-07
Iter: 2508 loss: 5.08949938e-07
Iter: 2509 loss: 5.08937433e-07
Iter: 2510 loss: 5.089193e-07
Iter: 2511 loss: 5.08865753e-07
Iter: 2512 loss: 5.08953e-07
Iter: 2513 loss: 5.08847506e-07
Iter: 2514 loss: 5.08841708e-07
Iter: 2515 loss: 5.08796404e-07
Iter: 2516 loss: 5.08807886e-07
Iter: 2517 loss: 5.08808625e-07
Iter: 2518 loss: 5.08802259e-07
Iter: 2519 loss: 5.08781397e-07
Iter: 2520 loss: 5.08807261e-07
Iter: 2521 loss: 5.0879197e-07
Iter: 2522 loss: 5.0879305e-07
Iter: 2523 loss: 5.08792084e-07
Iter: 2524 loss: 5.08795438e-07
Iter: 2525 loss: 5.08801122e-07
Iter: 2526 loss: 5.08787366e-07
Iter: 2527 loss: 5.08801804e-07
Iter: 2528 loss: 5.08799076e-07
Iter: 2529 loss: 5.08794813e-07
Iter: 2530 loss: 5.08799417e-07
Iter: 2531 loss: 5.08795608e-07
Iter: 2532 loss: 5.08799531e-07
Iter: 2533 loss: 5.08798109e-07
Iter: 2534 loss: 5.08797029e-07
Iter: 2535 loss: 5.08794869e-07
Iter: 2536 loss: 5.08795779e-07
Iter: 2537 loss: 5.0879612e-07
Iter: 2538 loss: 5.08796347e-07
Iter: 2539 loss: 5.08796688e-07
Iter: 2540 loss: 5.08797e-07
Iter: 2541 loss: 5.08797e-07
Iter: 2542 loss: 5.08797e-07
Iter: 2543 loss: 5.08796688e-07
Iter: 2544 loss: 5.0864287e-07
Iter: 2545 loss: 5.10227551e-07
Iter: 2546 loss: 5.08675555e-07
Iter: 2547 loss: 5.08612175e-07
Iter: 2548 loss: 5.08620474e-07
Iter: 2549 loss: 5.08556866e-07
Iter: 2550 loss: 5.08501671e-07
Iter: 2551 loss: 5.08502239e-07
Iter: 2552 loss: 5.08398784e-07
Iter: 2553 loss: 5.08451194e-07
Iter: 2554 loss: 5.08350581e-07
Iter: 2555 loss: 5.08277253e-07
Iter: 2556 loss: 5.09051063e-07
Iter: 2557 loss: 5.08260314e-07
Iter: 2558 loss: 5.08200287e-07
Iter: 2559 loss: 5.0828487e-07
Iter: 2560 loss: 5.08163225e-07
Iter: 2561 loss: 5.08095127e-07
Iter: 2562 loss: 5.08221262e-07
Iter: 2563 loss: 5.08084327e-07
Iter: 2564 loss: 5.08035555e-07
Iter: 2565 loss: 5.08282824e-07
Iter: 2566 loss: 5.0801907e-07
Iter: 2567 loss: 5.07946652e-07
Iter: 2568 loss: 5.07897539e-07
Iter: 2569 loss: 5.07896289e-07
Iter: 2570 loss: 5.07763559e-07
Iter: 2571 loss: 5.07888046e-07
Iter: 2572 loss: 5.07719335e-07
Iter: 2573 loss: 5.0762344e-07
Iter: 2574 loss: 5.0764e-07
Iter: 2575 loss: 5.07559776e-07
Iter: 2576 loss: 5.07997811e-07
Iter: 2577 loss: 5.07552159e-07
Iter: 2578 loss: 5.07489119e-07
Iter: 2579 loss: 5.07433413e-07
Iter: 2580 loss: 5.0744751e-07
Iter: 2581 loss: 5.07365769e-07
Iter: 2582 loss: 5.07385835e-07
Iter: 2583 loss: 5.07345703e-07
Iter: 2584 loss: 5.07383e-07
Iter: 2585 loss: 5.07325296e-07
Iter: 2586 loss: 5.07290736e-07
Iter: 2587 loss: 5.07456434e-07
Iter: 2588 loss: 5.07296818e-07
Iter: 2589 loss: 5.07270897e-07
Iter: 2590 loss: 5.0726976e-07
Iter: 2591 loss: 5.0725896e-07
Iter: 2592 loss: 5.07220705e-07
Iter: 2593 loss: 5.07292953e-07
Iter: 2594 loss: 5.07187281e-07
Iter: 2595 loss: 5.07170228e-07
Iter: 2596 loss: 5.07250945e-07
Iter: 2597 loss: 5.07149139e-07
Iter: 2598 loss: 5.07102754e-07
Iter: 2599 loss: 5.07049151e-07
Iter: 2600 loss: 5.0704125e-07
Iter: 2601 loss: 5.06966444e-07
Iter: 2602 loss: 5.06997708e-07
Iter: 2603 loss: 5.06910226e-07
Iter: 2604 loss: 5.06794947e-07
Iter: 2605 loss: 5.07214565e-07
Iter: 2606 loss: 5.06770959e-07
Iter: 2607 loss: 5.06715e-07
Iter: 2608 loss: 5.06705419e-07
Iter: 2609 loss: 5.06673814e-07
Iter: 2610 loss: 5.06617084e-07
Iter: 2611 loss: 5.06576043e-07
Iter: 2612 loss: 5.06497315e-07
Iter: 2613 loss: 5.06662445e-07
Iter: 2614 loss: 5.06485378e-07
Iter: 2615 loss: 5.06380616e-07
Iter: 2616 loss: 5.06958713e-07
Iter: 2617 loss: 5.06349295e-07
Iter: 2618 loss: 5.06304389e-07
Iter: 2619 loss: 5.06244419e-07
Iter: 2620 loss: 5.06236574e-07
Iter: 2621 loss: 5.06130277e-07
Iter: 2622 loss: 5.06161427e-07
Iter: 2623 loss: 5.061097e-07
Iter: 2624 loss: 5.06045922e-07
Iter: 2625 loss: 5.06027902e-07
Iter: 2626 loss: 5.05953039e-07
Iter: 2627 loss: 5.06276137e-07
Iter: 2628 loss: 5.05935304e-07
Iter: 2629 loss: 5.05878461e-07
Iter: 2630 loss: 5.05862317e-07
Iter: 2631 loss: 5.05824573e-07
Iter: 2632 loss: 5.05786943e-07
Iter: 2633 loss: 5.05801e-07
Iter: 2634 loss: 5.05722369e-07
Iter: 2635 loss: 5.05831338e-07
Iter: 2636 loss: 5.05720323e-07
Iter: 2637 loss: 5.05689684e-07
Iter: 2638 loss: 5.05707e-07
Iter: 2639 loss: 5.056595e-07
Iter: 2640 loss: 5.05584865e-07
Iter: 2641 loss: 5.0606883e-07
Iter: 2642 loss: 5.05588559e-07
Iter: 2643 loss: 5.05528874e-07
Iter: 2644 loss: 5.05953381e-07
Iter: 2645 loss: 5.05492039e-07
Iter: 2646 loss: 5.05515573e-07
Iter: 2647 loss: 5.05526543e-07
Iter: 2648 loss: 5.05517676e-07
Iter: 2649 loss: 5.05499031e-07
Iter: 2650 loss: 5.05504204e-07
Iter: 2651 loss: 5.05511e-07
Iter: 2652 loss: 5.05514e-07
Iter: 2653 loss: 5.05519324e-07
Iter: 2654 loss: 5.05515345e-07
Iter: 2655 loss: 5.05519836e-07
Iter: 2656 loss: 5.05493e-07
Iter: 2657 loss: 5.05499543e-07
Iter: 2658 loss: 5.05502214e-07
Iter: 2659 loss: 5.05492039e-07
Iter: 2660 loss: 5.05492153e-07
Iter: 2661 loss: 5.05502783e-07
Iter: 2662 loss: 5.05494768e-07
Iter: 2663 loss: 5.0549329e-07
Iter: 2664 loss: 5.05492e-07
Iter: 2665 loss: 5.05492608e-07
Iter: 2666 loss: 5.05492892e-07
Iter: 2667 loss: 5.0549238e-07
Iter: 2668 loss: 5.05492665e-07
Iter: 2669 loss: 5.05492608e-07
Iter: 2670 loss: 5.05492551e-07
Iter: 2671 loss: 5.05492551e-07
Iter: 2672 loss: 5.05492551e-07
Iter: 2673 loss: 5.05492551e-07
Iter: 2674 loss: 5.05492551e-07
Iter: 2675 loss: 5.05492608e-07
Iter: 2676 loss: 5.05492608e-07
Iter: 2677 loss: 5.05492608e-07
Iter: 2678 loss: 5.05492551e-07
Iter: 2679 loss: 5.05492608e-07
Iter: 2680 loss: 5.05492608e-07
Iter: 2681 loss: 5.05492551e-07
Iter: 2682 loss: 5.05492608e-07
Iter: 2683 loss: 5.05492551e-07
Iter: 2684 loss: 5.05704747e-07
Iter: 2685 loss: 5.05529272e-07
Iter: 2686 loss: 5.05543369e-07
Iter: 2687 loss: 5.05541834e-07
Iter: 2688 loss: 5.05548e-07
Iter: 2689 loss: 5.05518e-07
Iter: 2690 loss: 5.05529499e-07
Iter: 2691 loss: 5.05526373e-07
Iter: 2692 loss: 5.05523758e-07
Iter: 2693 loss: 5.05526e-07
Iter: 2694 loss: 5.05506819e-07
Iter: 2695 loss: 5.05497042e-07
Iter: 2696 loss: 5.05497837e-07
Iter: 2697 loss: 5.05496246e-07
Iter: 2698 loss: 5.05487492e-07
Iter: 2699 loss: 5.05492324e-07
Iter: 2700 loss: 5.05494654e-07
Iter: 2701 loss: 5.05491812e-07
Iter: 2702 loss: 5.05492835e-07
Iter: 2703 loss: 5.05493176e-07
Iter: 2704 loss: 5.05493631e-07
Iter: 2705 loss: 5.05493e-07
Iter: 2706 loss: 5.05493517e-07
Iter: 2707 loss: 5.0549329e-07
Iter: 2708 loss: 5.0549329e-07
Iter: 2709 loss: 5.05493e-07
Iter: 2710 loss: 5.05493e-07
Iter: 2711 loss: 5.0549329e-07
Iter: 2712 loss: 5.0549329e-07
Iter: 2713 loss: 5.0549329e-07
Iter: 2714 loss: 5.05493e-07
Iter: 2715 loss: 5.0549329e-07
Iter: 2716 loss: 5.0549329e-07
Iter: 2717 loss: 5.05493e-07
Iter: 2718 loss: 5.0549329e-07
Iter: 2719 loss: 5.05493e-07
Iter: 2720 loss: 5.05493e-07
Iter: 2721 loss: 5.0549329e-07
Iter: 2722 loss: 5.05493e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi0.8_8000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d9982d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d996d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d9865950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d99528c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d98a3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d9865ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d98658c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d9811a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d9811730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d9811510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d97cf1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d97a0bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d979b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d975d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d979ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d9770730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d970cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d970c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d9699b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d968f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d9645048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d95f72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d95e26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3799125e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3799125d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37990acf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37990aaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37990ac620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37990561e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379902c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3799021510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37740d91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37740f96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37740d79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f377409e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f377408bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.57045974e-06
Iter: 2 loss: 2.76693936e-06
Iter: 3 loss: 1.92238144e-06
Iter: 4 loss: 1.6718609e-06
Iter: 5 loss: 1.55694306e-06
Iter: 6 loss: 1.43220257e-06
Iter: 7 loss: 1.28221541e-06
Iter: 8 loss: 1.28123565e-06
Iter: 9 loss: 1.17051513e-06
Iter: 10 loss: 1.07554035e-06
Iter: 11 loss: 1.04530864e-06
Iter: 12 loss: 9.65596e-07
Iter: 13 loss: 1.42987392e-06
Iter: 14 loss: 9.55064479e-07
Iter: 15 loss: 9.33280717e-07
Iter: 16 loss: 1.25150063e-06
Iter: 17 loss: 9.3325e-07
Iter: 18 loss: 9.12953453e-07
Iter: 19 loss: 9.65197614e-07
Iter: 20 loss: 9.05977515e-07
Iter: 21 loss: 8.91309526e-07
Iter: 22 loss: 9.14755958e-07
Iter: 23 loss: 8.8450355e-07
Iter: 24 loss: 8.76118122e-07
Iter: 25 loss: 8.75651722e-07
Iter: 26 loss: 8.69406676e-07
Iter: 27 loss: 8.5430986e-07
Iter: 28 loss: 1.01326509e-06
Iter: 29 loss: 8.52613312e-07
Iter: 30 loss: 8.36747517e-07
Iter: 31 loss: 8.53123538e-07
Iter: 32 loss: 8.27887561e-07
Iter: 33 loss: 8.14815678e-07
Iter: 34 loss: 9.08365905e-07
Iter: 35 loss: 8.13685688e-07
Iter: 36 loss: 8.04913554e-07
Iter: 37 loss: 8.55938197e-07
Iter: 38 loss: 8.03744115e-07
Iter: 39 loss: 7.99219492e-07
Iter: 40 loss: 8.69673102e-07
Iter: 41 loss: 7.99228587e-07
Iter: 42 loss: 7.94583514e-07
Iter: 43 loss: 8.03647936e-07
Iter: 44 loss: 7.92666583e-07
Iter: 45 loss: 7.89663432e-07
Iter: 46 loss: 7.93186643e-07
Iter: 47 loss: 7.88056468e-07
Iter: 48 loss: 7.84304234e-07
Iter: 49 loss: 8.15622798e-07
Iter: 50 loss: 7.84070153e-07
Iter: 51 loss: 7.81589961e-07
Iter: 52 loss: 7.73723627e-07
Iter: 53 loss: 7.82259747e-07
Iter: 54 loss: 7.67591246e-07
Iter: 55 loss: 7.58300416e-07
Iter: 56 loss: 7.58016938e-07
Iter: 57 loss: 7.54039604e-07
Iter: 58 loss: 7.53854465e-07
Iter: 59 loss: 7.51005e-07
Iter: 60 loss: 7.45887746e-07
Iter: 61 loss: 8.73366844e-07
Iter: 62 loss: 7.45892748e-07
Iter: 63 loss: 7.43895441e-07
Iter: 64 loss: 7.42998282e-07
Iter: 65 loss: 7.41146778e-07
Iter: 66 loss: 7.38632707e-07
Iter: 67 loss: 7.38465644e-07
Iter: 68 loss: 7.36497554e-07
Iter: 69 loss: 7.33806075e-07
Iter: 70 loss: 7.33660158e-07
Iter: 71 loss: 7.31162913e-07
Iter: 72 loss: 7.31146315e-07
Iter: 73 loss: 7.29143949e-07
Iter: 74 loss: 7.28498321e-07
Iter: 75 loss: 7.27318138e-07
Iter: 76 loss: 7.25838618e-07
Iter: 77 loss: 7.25750567e-07
Iter: 78 loss: 7.24103302e-07
Iter: 79 loss: 7.23688231e-07
Iter: 80 loss: 7.2264794e-07
Iter: 81 loss: 7.20858566e-07
Iter: 82 loss: 7.28042153e-07
Iter: 83 loss: 7.20466176e-07
Iter: 84 loss: 7.18371211e-07
Iter: 85 loss: 7.23434084e-07
Iter: 86 loss: 7.17652881e-07
Iter: 87 loss: 7.16061606e-07
Iter: 88 loss: 7.14288376e-07
Iter: 89 loss: 7.14038208e-07
Iter: 90 loss: 7.11452856e-07
Iter: 91 loss: 7.13601196e-07
Iter: 92 loss: 7.09923768e-07
Iter: 93 loss: 7.07284585e-07
Iter: 94 loss: 7.29329884e-07
Iter: 95 loss: 7.07132472e-07
Iter: 96 loss: 7.0573185e-07
Iter: 97 loss: 7.05624643e-07
Iter: 98 loss: 7.04758804e-07
Iter: 99 loss: 7.03044691e-07
Iter: 100 loss: 7.37440587e-07
Iter: 101 loss: 7.02993304e-07
Iter: 102 loss: 7.01482747e-07
Iter: 103 loss: 7.014483e-07
Iter: 104 loss: 7.00495207e-07
Iter: 105 loss: 6.98971348e-07
Iter: 106 loss: 6.9896987e-07
Iter: 107 loss: 6.97201699e-07
Iter: 108 loss: 6.98722943e-07
Iter: 109 loss: 6.9619432e-07
Iter: 110 loss: 6.95854965e-07
Iter: 111 loss: 6.95581775e-07
Iter: 112 loss: 6.94961955e-07
Iter: 113 loss: 6.94981964e-07
Iter: 114 loss: 6.94468895e-07
Iter: 115 loss: 6.93785239e-07
Iter: 116 loss: 6.94101345e-07
Iter: 117 loss: 6.93332197e-07
Iter: 118 loss: 6.92955041e-07
Iter: 119 loss: 6.9292787e-07
Iter: 120 loss: 6.92491369e-07
Iter: 121 loss: 6.91565447e-07
Iter: 122 loss: 7.04455601e-07
Iter: 123 loss: 6.91513947e-07
Iter: 124 loss: 6.90416584e-07
Iter: 125 loss: 6.92630181e-07
Iter: 126 loss: 6.89983665e-07
Iter: 127 loss: 6.89137437e-07
Iter: 128 loss: 6.91496439e-07
Iter: 129 loss: 6.88847138e-07
Iter: 130 loss: 6.87931561e-07
Iter: 131 loss: 6.92564811e-07
Iter: 132 loss: 6.87775128e-07
Iter: 133 loss: 6.86981366e-07
Iter: 134 loss: 6.98613e-07
Iter: 135 loss: 6.87006491e-07
Iter: 136 loss: 6.86551516e-07
Iter: 137 loss: 6.85870134e-07
Iter: 138 loss: 6.85868599e-07
Iter: 139 loss: 6.85174598e-07
Iter: 140 loss: 6.85174712e-07
Iter: 141 loss: 6.8457507e-07
Iter: 142 loss: 6.8293366e-07
Iter: 143 loss: 6.91321418e-07
Iter: 144 loss: 6.82387679e-07
Iter: 145 loss: 6.80567382e-07
Iter: 146 loss: 6.91300443e-07
Iter: 147 loss: 6.8034052e-07
Iter: 148 loss: 6.78865774e-07
Iter: 149 loss: 6.83535347e-07
Iter: 150 loss: 6.78495439e-07
Iter: 151 loss: 6.77776484e-07
Iter: 152 loss: 6.77767275e-07
Iter: 153 loss: 6.77347032e-07
Iter: 154 loss: 6.77358344e-07
Iter: 155 loss: 6.77150297e-07
Iter: 156 loss: 6.76791615e-07
Iter: 157 loss: 6.82727944e-07
Iter: 158 loss: 6.76755917e-07
Iter: 159 loss: 6.76616821e-07
Iter: 160 loss: 6.76580044e-07
Iter: 161 loss: 6.7638905e-07
Iter: 162 loss: 6.76003538e-07
Iter: 163 loss: 6.79996447e-07
Iter: 164 loss: 6.75975e-07
Iter: 165 loss: 6.75501838e-07
Iter: 166 loss: 6.77042e-07
Iter: 167 loss: 6.75392243e-07
Iter: 168 loss: 6.75058857e-07
Iter: 169 loss: 6.75062211e-07
Iter: 170 loss: 6.74751561e-07
Iter: 171 loss: 6.74314492e-07
Iter: 172 loss: 6.74286468e-07
Iter: 173 loss: 6.73781926e-07
Iter: 174 loss: 6.75704655e-07
Iter: 175 loss: 6.73630211e-07
Iter: 176 loss: 6.7320309e-07
Iter: 177 loss: 6.78000561e-07
Iter: 178 loss: 6.73191835e-07
Iter: 179 loss: 6.72980832e-07
Iter: 180 loss: 6.72397277e-07
Iter: 181 loss: 6.78192634e-07
Iter: 182 loss: 6.72321676e-07
Iter: 183 loss: 6.71678038e-07
Iter: 184 loss: 6.75575336e-07
Iter: 185 loss: 6.71588055e-07
Iter: 186 loss: 6.71186854e-07
Iter: 187 loss: 6.73196269e-07
Iter: 188 loss: 6.71116936e-07
Iter: 189 loss: 6.70534348e-07
Iter: 190 loss: 6.7206463e-07
Iter: 191 loss: 6.70330962e-07
Iter: 192 loss: 6.70031056e-07
Iter: 193 loss: 6.69769236e-07
Iter: 194 loss: 6.69712961e-07
Iter: 195 loss: 6.69371843e-07
Iter: 196 loss: 6.693503e-07
Iter: 197 loss: 6.6912753e-07
Iter: 198 loss: 6.68602e-07
Iter: 199 loss: 6.77223227e-07
Iter: 200 loss: 6.68557732e-07
Iter: 201 loss: 6.6821292e-07
Iter: 202 loss: 6.72381475e-07
Iter: 203 loss: 6.68198481e-07
Iter: 204 loss: 6.67895847e-07
Iter: 205 loss: 6.69823521e-07
Iter: 206 loss: 6.6785168e-07
Iter: 207 loss: 6.67651193e-07
Iter: 208 loss: 6.67409267e-07
Iter: 209 loss: 6.67349127e-07
Iter: 210 loss: 6.67201334e-07
Iter: 211 loss: 6.67177687e-07
Iter: 212 loss: 6.66996925e-07
Iter: 213 loss: 6.6680019e-07
Iter: 214 loss: 6.66810479e-07
Iter: 215 loss: 6.66505173e-07
Iter: 216 loss: 6.66656831e-07
Iter: 217 loss: 6.66333165e-07
Iter: 218 loss: 6.65936454e-07
Iter: 219 loss: 6.66363405e-07
Iter: 220 loss: 6.65695438e-07
Iter: 221 loss: 6.65494213e-07
Iter: 222 loss: 6.65481821e-07
Iter: 223 loss: 6.6522955e-07
Iter: 224 loss: 6.64992456e-07
Iter: 225 loss: 6.64930781e-07
Iter: 226 loss: 6.6457369e-07
Iter: 227 loss: 6.64510765e-07
Iter: 228 loss: 6.64314882e-07
Iter: 229 loss: 6.63963647e-07
Iter: 230 loss: 6.6396143e-07
Iter: 231 loss: 6.63627645e-07
Iter: 232 loss: 6.63280616e-07
Iter: 233 loss: 6.63212234e-07
Iter: 234 loss: 6.6281757e-07
Iter: 235 loss: 6.63451942e-07
Iter: 236 loss: 6.62609636e-07
Iter: 237 loss: 6.62364073e-07
Iter: 238 loss: 6.62307e-07
Iter: 239 loss: 6.6211885e-07
Iter: 240 loss: 6.61664e-07
Iter: 241 loss: 6.66133303e-07
Iter: 242 loss: 6.6157952e-07
Iter: 243 loss: 6.6143923e-07
Iter: 244 loss: 6.61339698e-07
Iter: 245 loss: 6.61129e-07
Iter: 246 loss: 6.60882677e-07
Iter: 247 loss: 6.60857779e-07
Iter: 248 loss: 6.60568674e-07
Iter: 249 loss: 6.60790761e-07
Iter: 250 loss: 6.60391436e-07
Iter: 251 loss: 6.60122851e-07
Iter: 252 loss: 6.61316562e-07
Iter: 253 loss: 6.60057708e-07
Iter: 254 loss: 6.59884563e-07
Iter: 255 loss: 6.59862167e-07
Iter: 256 loss: 6.59706814e-07
Iter: 257 loss: 6.59349e-07
Iter: 258 loss: 6.6361963e-07
Iter: 259 loss: 6.59317266e-07
Iter: 260 loss: 6.5889742e-07
Iter: 261 loss: 6.59342504e-07
Iter: 262 loss: 6.58686076e-07
Iter: 263 loss: 6.58438694e-07
Iter: 264 loss: 6.58387648e-07
Iter: 265 loss: 6.58225247e-07
Iter: 266 loss: 6.57870601e-07
Iter: 267 loss: 6.64064714e-07
Iter: 268 loss: 6.57840474e-07
Iter: 269 loss: 6.57464682e-07
Iter: 270 loss: 6.57616624e-07
Iter: 271 loss: 6.57134592e-07
Iter: 272 loss: 6.56718896e-07
Iter: 273 loss: 6.62194452e-07
Iter: 274 loss: 6.5673845e-07
Iter: 275 loss: 6.56618113e-07
Iter: 276 loss: 6.56614873e-07
Iter: 277 loss: 6.56492546e-07
Iter: 278 loss: 6.56211682e-07
Iter: 279 loss: 6.58820795e-07
Iter: 280 loss: 6.56156e-07
Iter: 281 loss: 6.55789393e-07
Iter: 282 loss: 6.58682325e-07
Iter: 283 loss: 6.5578115e-07
Iter: 284 loss: 6.55428835e-07
Iter: 285 loss: 6.56426664e-07
Iter: 286 loss: 6.55316512e-07
Iter: 287 loss: 6.55052418e-07
Iter: 288 loss: 6.54593691e-07
Iter: 289 loss: 6.54593237e-07
Iter: 290 loss: 6.54448968e-07
Iter: 291 loss: 6.54310611e-07
Iter: 292 loss: 6.54082498e-07
Iter: 293 loss: 6.53650204e-07
Iter: 294 loss: 6.59281568e-07
Iter: 295 loss: 6.53609391e-07
Iter: 296 loss: 6.53432608e-07
Iter: 297 loss: 6.5338827e-07
Iter: 298 loss: 6.53193638e-07
Iter: 299 loss: 6.5326924e-07
Iter: 300 loss: 6.53093707e-07
Iter: 301 loss: 6.52892766e-07
Iter: 302 loss: 6.52880885e-07
Iter: 303 loss: 6.52741676e-07
Iter: 304 loss: 6.52537665e-07
Iter: 305 loss: 6.52951599e-07
Iter: 306 loss: 6.52429662e-07
Iter: 307 loss: 6.52214339e-07
Iter: 308 loss: 6.54218354e-07
Iter: 309 loss: 6.52238327e-07
Iter: 310 loss: 6.51985658e-07
Iter: 311 loss: 6.52368612e-07
Iter: 312 loss: 6.51888229e-07
Iter: 313 loss: 6.51654204e-07
Iter: 314 loss: 6.51555e-07
Iter: 315 loss: 6.51441781e-07
Iter: 316 loss: 6.51160349e-07
Iter: 317 loss: 6.55008535e-07
Iter: 318 loss: 6.51172627e-07
Iter: 319 loss: 6.50930247e-07
Iter: 320 loss: 6.50830145e-07
Iter: 321 loss: 6.5073948e-07
Iter: 322 loss: 6.5046595e-07
Iter: 323 loss: 6.5059703e-07
Iter: 324 loss: 6.5026785e-07
Iter: 325 loss: 6.50077652e-07
Iter: 326 loss: 6.50056052e-07
Iter: 327 loss: 6.49940148e-07
Iter: 328 loss: 6.49740059e-07
Iter: 329 loss: 6.53384177e-07
Iter: 330 loss: 6.49727554e-07
Iter: 331 loss: 6.49572598e-07
Iter: 332 loss: 6.52411074e-07
Iter: 333 loss: 6.4956339e-07
Iter: 334 loss: 6.49392916e-07
Iter: 335 loss: 6.49281219e-07
Iter: 336 loss: 6.49187484e-07
Iter: 337 loss: 6.48991886e-07
Iter: 338 loss: 6.48909804e-07
Iter: 339 loss: 6.48800665e-07
Iter: 340 loss: 6.48423907e-07
Iter: 341 loss: 6.48681294e-07
Iter: 342 loss: 6.48214609e-07
Iter: 343 loss: 6.47989282e-07
Iter: 344 loss: 6.4795e-07
Iter: 345 loss: 6.47798402e-07
Iter: 346 loss: 6.49224376e-07
Iter: 347 loss: 6.47792547e-07
Iter: 348 loss: 6.47678348e-07
Iter: 349 loss: 6.47469506e-07
Iter: 350 loss: 6.47481386e-07
Iter: 351 loss: 6.47355193e-07
Iter: 352 loss: 6.47366903e-07
Iter: 353 loss: 6.47250431e-07
Iter: 354 loss: 6.47198419e-07
Iter: 355 loss: 6.47152e-07
Iter: 356 loss: 6.47006573e-07
Iter: 357 loss: 6.46991793e-07
Iter: 358 loss: 6.46899935e-07
Iter: 359 loss: 6.46736908e-07
Iter: 360 loss: 6.48433058e-07
Iter: 361 loss: 6.46752824e-07
Iter: 362 loss: 6.46537899e-07
Iter: 363 loss: 6.47004867e-07
Iter: 364 loss: 6.46497654e-07
Iter: 365 loss: 6.46371177e-07
Iter: 366 loss: 6.46110266e-07
Iter: 367 loss: 6.50938659e-07
Iter: 368 loss: 6.46096396e-07
Iter: 369 loss: 6.45913474e-07
Iter: 370 loss: 6.45905175e-07
Iter: 371 loss: 6.45712362e-07
Iter: 372 loss: 6.45415412e-07
Iter: 373 loss: 6.45416776e-07
Iter: 374 loss: 6.4514893e-07
Iter: 375 loss: 6.45714522e-07
Iter: 376 loss: 6.45041155e-07
Iter: 377 loss: 6.4481776e-07
Iter: 378 loss: 6.45795922e-07
Iter: 379 loss: 6.44783654e-07
Iter: 380 loss: 6.44668148e-07
Iter: 381 loss: 6.44651323e-07
Iter: 382 loss: 6.44521435e-07
Iter: 383 loss: 6.44355282e-07
Iter: 384 loss: 6.44330953e-07
Iter: 385 loss: 6.44212889e-07
Iter: 386 loss: 6.45347086e-07
Iter: 387 loss: 6.44220677e-07
Iter: 388 loss: 6.44066063e-07
Iter: 389 loss: 6.44355168e-07
Iter: 390 loss: 6.44016154e-07
Iter: 391 loss: 6.43879218e-07
Iter: 392 loss: 6.43715225e-07
Iter: 393 loss: 6.43726366e-07
Iter: 394 loss: 6.43552085e-07
Iter: 395 loss: 6.45138e-07
Iter: 396 loss: 6.43552653e-07
Iter: 397 loss: 6.43411397e-07
Iter: 398 loss: 6.44590841e-07
Iter: 399 loss: 6.43427882e-07
Iter: 400 loss: 6.43340513e-07
Iter: 401 loss: 6.43128374e-07
Iter: 402 loss: 6.46661647e-07
Iter: 403 loss: 6.43128374e-07
Iter: 404 loss: 6.42986549e-07
Iter: 405 loss: 6.4472664e-07
Iter: 406 loss: 6.42967905e-07
Iter: 407 loss: 6.4281528e-07
Iter: 408 loss: 6.43035833e-07
Iter: 409 loss: 6.42725524e-07
Iter: 410 loss: 6.4257722e-07
Iter: 411 loss: 6.4241874e-07
Iter: 412 loss: 6.42367e-07
Iter: 413 loss: 6.42108887e-07
Iter: 414 loss: 6.4249474e-07
Iter: 415 loss: 6.41959446e-07
Iter: 416 loss: 6.41975248e-07
Iter: 417 loss: 6.41831662e-07
Iter: 418 loss: 6.41758106e-07
Iter: 419 loss: 6.41637371e-07
Iter: 420 loss: 6.41642487e-07
Iter: 421 loss: 6.41504585e-07
Iter: 422 loss: 6.41824784e-07
Iter: 423 loss: 6.41458087e-07
Iter: 424 loss: 6.41303245e-07
Iter: 425 loss: 6.42293855e-07
Iter: 426 loss: 6.41285283e-07
Iter: 427 loss: 6.41188819e-07
Iter: 428 loss: 6.40974235e-07
Iter: 429 loss: 6.4460454e-07
Iter: 430 loss: 6.40963776e-07
Iter: 431 loss: 6.40796657e-07
Iter: 432 loss: 6.40793e-07
Iter: 433 loss: 6.40626e-07
Iter: 434 loss: 6.40684163e-07
Iter: 435 loss: 6.4050289e-07
Iter: 436 loss: 6.40299788e-07
Iter: 437 loss: 6.40161943e-07
Iter: 438 loss: 6.40087819e-07
Iter: 439 loss: 6.39911207e-07
Iter: 440 loss: 6.39915925e-07
Iter: 441 loss: 6.39774498e-07
Iter: 442 loss: 6.40206963e-07
Iter: 443 loss: 6.39707935e-07
Iter: 444 loss: 6.39605332e-07
Iter: 445 loss: 6.39522227e-07
Iter: 446 loss: 6.39478571e-07
Iter: 447 loss: 6.39385e-07
Iter: 448 loss: 6.40280632e-07
Iter: 449 loss: 6.3937614e-07
Iter: 450 loss: 6.39271e-07
Iter: 451 loss: 6.40426776e-07
Iter: 452 loss: 6.39269217e-07
Iter: 453 loss: 6.3917139e-07
Iter: 454 loss: 6.38960728e-07
Iter: 455 loss: 6.41102133e-07
Iter: 456 loss: 6.38939696e-07
Iter: 457 loss: 6.38778374e-07
Iter: 458 loss: 6.41362419e-07
Iter: 459 loss: 6.38778033e-07
Iter: 460 loss: 6.38584822e-07
Iter: 461 loss: 6.38743302e-07
Iter: 462 loss: 6.38473352e-07
Iter: 463 loss: 6.38328174e-07
Iter: 464 loss: 6.38320387e-07
Iter: 465 loss: 6.38190841e-07
Iter: 466 loss: 6.3807272e-07
Iter: 467 loss: 6.38043389e-07
Iter: 468 loss: 6.37963e-07
Iter: 469 loss: 6.37942605e-07
Iter: 470 loss: 6.37854214e-07
Iter: 471 loss: 6.37755875e-07
Iter: 472 loss: 6.3769221e-07
Iter: 473 loss: 6.37636504e-07
Iter: 474 loss: 6.37513267e-07
Iter: 475 loss: 6.39055202e-07
Iter: 476 loss: 6.37516905e-07
Iter: 477 loss: 6.37338758e-07
Iter: 478 loss: 6.37454377e-07
Iter: 479 loss: 6.37274866e-07
Iter: 480 loss: 6.37134576e-07
Iter: 481 loss: 6.37164419e-07
Iter: 482 loss: 6.3703817e-07
Iter: 483 loss: 6.3688168e-07
Iter: 484 loss: 6.37356663e-07
Iter: 485 loss: 6.36799541e-07
Iter: 486 loss: 6.3664055e-07
Iter: 487 loss: 6.39297639e-07
Iter: 488 loss: 6.36621735e-07
Iter: 489 loss: 6.36554546e-07
Iter: 490 loss: 6.3643904e-07
Iter: 491 loss: 6.36413e-07
Iter: 492 loss: 6.36311313e-07
Iter: 493 loss: 6.37244341e-07
Iter: 494 loss: 6.36287666e-07
Iter: 495 loss: 6.36179266e-07
Iter: 496 loss: 6.36424147e-07
Iter: 497 loss: 6.36142715e-07
Iter: 498 loss: 6.36017944e-07
Iter: 499 loss: 6.3582479e-07
Iter: 500 loss: 6.35828656e-07
Iter: 501 loss: 6.35635956e-07
Iter: 502 loss: 6.37589324e-07
Iter: 503 loss: 6.35648689e-07
Iter: 504 loss: 6.35391189e-07
Iter: 505 loss: 6.35911192e-07
Iter: 506 loss: 6.35343e-07
Iter: 507 loss: 6.35160063e-07
Iter: 508 loss: 6.34955654e-07
Iter: 509 loss: 6.34929677e-07
Iter: 510 loss: 6.34718617e-07
Iter: 511 loss: 6.3604466e-07
Iter: 512 loss: 6.34679282e-07
Iter: 513 loss: 6.34570029e-07
Iter: 514 loss: 6.34556613e-07
Iter: 515 loss: 6.34410867e-07
Iter: 516 loss: 6.34269156e-07
Iter: 517 loss: 6.34251933e-07
Iter: 518 loss: 6.34121875e-07
Iter: 519 loss: 6.34433263e-07
Iter: 520 loss: 6.34073e-07
Iter: 521 loss: 6.33961918e-07
Iter: 522 loss: 6.3441064e-07
Iter: 523 loss: 6.3394134e-07
Iter: 524 loss: 6.33836521e-07
Iter: 525 loss: 6.35054676e-07
Iter: 526 loss: 6.3383e-07
Iter: 527 loss: 6.33764103e-07
Iter: 528 loss: 6.33650643e-07
Iter: 529 loss: 6.33652689e-07
Iter: 530 loss: 6.33503e-07
Iter: 531 loss: 6.33987156e-07
Iter: 532 loss: 6.33505692e-07
Iter: 533 loss: 6.33397406e-07
Iter: 534 loss: 6.34120909e-07
Iter: 535 loss: 6.33384388e-07
Iter: 536 loss: 6.33321747e-07
Iter: 537 loss: 6.33165428e-07
Iter: 538 loss: 6.35283868e-07
Iter: 539 loss: 6.33167247e-07
Iter: 540 loss: 6.32983415e-07
Iter: 541 loss: 6.34213109e-07
Iter: 542 loss: 6.32978754e-07
Iter: 543 loss: 6.32901902e-07
Iter: 544 loss: 6.33872617e-07
Iter: 545 loss: 6.32879846e-07
Iter: 546 loss: 6.32786396e-07
Iter: 547 loss: 6.32853471e-07
Iter: 548 loss: 6.32675e-07
Iter: 549 loss: 6.32624392e-07
Iter: 550 loss: 6.32567378e-07
Iter: 551 loss: 6.32535944e-07
Iter: 552 loss: 6.32398553e-07
Iter: 553 loss: 6.33930426e-07
Iter: 554 loss: 6.32405943e-07
Iter: 555 loss: 6.32286287e-07
Iter: 556 loss: 6.32120418e-07
Iter: 557 loss: 6.32085687e-07
Iter: 558 loss: 6.31886451e-07
Iter: 559 loss: 6.32585284e-07
Iter: 560 loss: 6.31831085e-07
Iter: 561 loss: 6.31750936e-07
Iter: 562 loss: 6.31732746e-07
Iter: 563 loss: 6.31635544e-07
Iter: 564 loss: 6.31505486e-07
Iter: 565 loss: 6.31489343e-07
Iter: 566 loss: 6.3141556e-07
Iter: 567 loss: 6.32734327e-07
Iter: 568 loss: 6.31412661e-07
Iter: 569 loss: 6.31325179e-07
Iter: 570 loss: 6.31300168e-07
Iter: 571 loss: 6.31252874e-07
Iter: 572 loss: 6.31159708e-07
Iter: 573 loss: 6.31184662e-07
Iter: 574 loss: 6.31100647e-07
Iter: 575 loss: 6.3100066e-07
Iter: 576 loss: 6.31338594e-07
Iter: 577 loss: 6.30979173e-07
Iter: 578 loss: 6.30904651e-07
Iter: 579 loss: 6.30905276e-07
Iter: 580 loss: 6.30817e-07
Iter: 581 loss: 6.30620377e-07
Iter: 582 loss: 6.33246202e-07
Iter: 583 loss: 6.30607076e-07
Iter: 584 loss: 6.30405395e-07
Iter: 585 loss: 6.30602358e-07
Iter: 586 loss: 6.30303e-07
Iter: 587 loss: 6.30071781e-07
Iter: 588 loss: 6.31234229e-07
Iter: 589 loss: 6.30008572e-07
Iter: 590 loss: 6.29864644e-07
Iter: 591 loss: 6.31221042e-07
Iter: 592 loss: 6.29857709e-07
Iter: 593 loss: 6.29716567e-07
Iter: 594 loss: 6.31073135e-07
Iter: 595 loss: 6.29709916e-07
Iter: 596 loss: 6.29628744e-07
Iter: 597 loss: 6.29451961e-07
Iter: 598 loss: 6.32080457e-07
Iter: 599 loss: 6.29466172e-07
Iter: 600 loss: 6.29471742e-07
Iter: 601 loss: 6.29374085e-07
Iter: 602 loss: 6.29341116e-07
Iter: 603 loss: 6.29249712e-07
Iter: 604 loss: 6.30777379e-07
Iter: 605 loss: 6.29239082e-07
Iter: 606 loss: 6.29124486e-07
Iter: 607 loss: 6.29774149e-07
Iter: 608 loss: 6.29102203e-07
Iter: 609 loss: 6.28953444e-07
Iter: 610 loss: 6.29384544e-07
Iter: 611 loss: 6.28940938e-07
Iter: 612 loss: 6.28794396e-07
Iter: 613 loss: 6.28595217e-07
Iter: 614 loss: 6.33384275e-07
Iter: 615 loss: 6.28593057e-07
Iter: 616 loss: 6.28468285e-07
Iter: 617 loss: 6.30551483e-07
Iter: 618 loss: 6.28451346e-07
Iter: 619 loss: 6.28391433e-07
Iter: 620 loss: 6.28374778e-07
Iter: 621 loss: 6.2833567e-07
Iter: 622 loss: 6.28221073e-07
Iter: 623 loss: 6.29117039e-07
Iter: 624 loss: 6.28225621e-07
Iter: 625 loss: 6.28101816e-07
Iter: 626 loss: 6.28610451e-07
Iter: 627 loss: 6.2807203e-07
Iter: 628 loss: 6.27950214e-07
Iter: 629 loss: 6.27864324e-07
Iter: 630 loss: 6.27827887e-07
Iter: 631 loss: 6.27646841e-07
Iter: 632 loss: 6.28379723e-07
Iter: 633 loss: 6.27585223e-07
Iter: 634 loss: 6.27517352e-07
Iter: 635 loss: 6.2749541e-07
Iter: 636 loss: 6.27392069e-07
Iter: 637 loss: 6.27170948e-07
Iter: 638 loss: 6.2989227e-07
Iter: 639 loss: 6.27155373e-07
Iter: 640 loss: 6.27067436e-07
Iter: 641 loss: 6.27054135e-07
Iter: 642 loss: 6.26925271e-07
Iter: 643 loss: 6.2681e-07
Iter: 644 loss: 6.26777478e-07
Iter: 645 loss: 6.26613371e-07
Iter: 646 loss: 6.26547489e-07
Iter: 647 loss: 6.26490248e-07
Iter: 648 loss: 6.26274357e-07
Iter: 649 loss: 6.27992677e-07
Iter: 650 loss: 6.26247584e-07
Iter: 651 loss: 6.26104679e-07
Iter: 652 loss: 6.2809147e-07
Iter: 653 loss: 6.26106441e-07
Iter: 654 loss: 6.26033966e-07
Iter: 655 loss: 6.25916414e-07
Iter: 656 loss: 6.28807243e-07
Iter: 657 loss: 6.2593e-07
Iter: 658 loss: 6.25751056e-07
Iter: 659 loss: 6.26495364e-07
Iter: 660 loss: 6.25738267e-07
Iter: 661 loss: 6.25686084e-07
Iter: 662 loss: 6.26651229e-07
Iter: 663 loss: 6.2567e-07
Iter: 664 loss: 6.25595817e-07
Iter: 665 loss: 6.2563231e-07
Iter: 666 loss: 6.25560745e-07
Iter: 667 loss: 6.25493044e-07
Iter: 668 loss: 6.25408461e-07
Iter: 669 loss: 6.25407e-07
Iter: 670 loss: 6.25292671e-07
Iter: 671 loss: 6.25645271e-07
Iter: 672 loss: 6.25271809e-07
Iter: 673 loss: 6.25165399e-07
Iter: 674 loss: 6.25178e-07
Iter: 675 loss: 6.2511964e-07
Iter: 676 loss: 6.2501249e-07
Iter: 677 loss: 6.24985546e-07
Iter: 678 loss: 6.24926884e-07
Iter: 679 loss: 6.24920858e-07
Iter: 680 loss: 6.24817289e-07
Iter: 681 loss: 6.24647953e-07
Iter: 682 loss: 6.28534906e-07
Iter: 683 loss: 6.24648067e-07
Iter: 684 loss: 6.24510676e-07
Iter: 685 loss: 6.24293705e-07
Iter: 686 loss: 6.2427182e-07
Iter: 687 loss: 6.24368681e-07
Iter: 688 loss: 6.24183485e-07
Iter: 689 loss: 6.24110157e-07
Iter: 690 loss: 6.24152676e-07
Iter: 691 loss: 6.24075426e-07
Iter: 692 loss: 6.23979304e-07
Iter: 693 loss: 6.24003405e-07
Iter: 694 loss: 6.23944402e-07
Iter: 695 loss: 6.23828782e-07
Iter: 696 loss: 6.2507786e-07
Iter: 697 loss: 6.23845608e-07
Iter: 698 loss: 6.23752442e-07
Iter: 699 loss: 6.23703613e-07
Iter: 700 loss: 6.23684912e-07
Iter: 701 loss: 6.23586061e-07
Iter: 702 loss: 6.23608798e-07
Iter: 703 loss: 6.23479082e-07
Iter: 704 loss: 6.23357664e-07
Iter: 705 loss: 6.23874143e-07
Iter: 706 loss: 6.23349592e-07
Iter: 707 loss: 6.23308495e-07
Iter: 708 loss: 6.23293829e-07
Iter: 709 loss: 6.2326086e-07
Iter: 710 loss: 6.23197423e-07
Iter: 711 loss: 6.23187475e-07
Iter: 712 loss: 6.23120513e-07
Iter: 713 loss: 6.23314349e-07
Iter: 714 loss: 6.23099083e-07
Iter: 715 loss: 6.23046844e-07
Iter: 716 loss: 6.2359095e-07
Iter: 717 loss: 6.23048038e-07
Iter: 718 loss: 6.23021606e-07
Iter: 719 loss: 6.2291906e-07
Iter: 720 loss: 6.24195422e-07
Iter: 721 loss: 6.22921846e-07
Iter: 722 loss: 6.228193e-07
Iter: 723 loss: 6.22814412e-07
Iter: 724 loss: 6.22730226e-07
Iter: 725 loss: 6.22641892e-07
Iter: 726 loss: 6.22627795e-07
Iter: 727 loss: 6.22556229e-07
Iter: 728 loss: 6.22480684e-07
Iter: 729 loss: 6.22468917e-07
Iter: 730 loss: 6.22359721e-07
Iter: 731 loss: 6.22380639e-07
Iter: 732 loss: 6.22292077e-07
Iter: 733 loss: 6.22185e-07
Iter: 734 loss: 6.22196e-07
Iter: 735 loss: 6.22118364e-07
Iter: 736 loss: 6.22011498e-07
Iter: 737 loss: 6.23816561e-07
Iter: 738 loss: 6.2200894e-07
Iter: 739 loss: 6.21915206e-07
Iter: 740 loss: 6.22288439e-07
Iter: 741 loss: 6.21897584e-07
Iter: 742 loss: 6.21799e-07
Iter: 743 loss: 6.22170091e-07
Iter: 744 loss: 6.21776167e-07
Iter: 745 loss: 6.21630932e-07
Iter: 746 loss: 6.22437824e-07
Iter: 747 loss: 6.21642187e-07
Iter: 748 loss: 6.21560787e-07
Iter: 749 loss: 6.21509969e-07
Iter: 750 loss: 6.21514914e-07
Iter: 751 loss: 6.21398613e-07
Iter: 752 loss: 6.22586185e-07
Iter: 753 loss: 6.2138e-07
Iter: 754 loss: 6.21340632e-07
Iter: 755 loss: 6.21231379e-07
Iter: 756 loss: 6.23275866e-07
Iter: 757 loss: 6.21261279e-07
Iter: 758 loss: 6.21190566e-07
Iter: 759 loss: 6.21188406e-07
Iter: 760 loss: 6.21123831e-07
Iter: 761 loss: 6.21273273e-07
Iter: 762 loss: 6.21115305e-07
Iter: 763 loss: 6.21067e-07
Iter: 764 loss: 6.21003892e-07
Iter: 765 loss: 6.21011736e-07
Iter: 766 loss: 6.20933065e-07
Iter: 767 loss: 6.21753031e-07
Iter: 768 loss: 6.20948072e-07
Iter: 769 loss: 6.20884634e-07
Iter: 770 loss: 6.21054824e-07
Iter: 771 loss: 6.20872811e-07
Iter: 772 loss: 6.20846606e-07
Iter: 773 loss: 6.20743549e-07
Iter: 774 loss: 6.22327093e-07
Iter: 775 loss: 6.207365e-07
Iter: 776 loss: 6.20609399e-07
Iter: 777 loss: 6.20763217e-07
Iter: 778 loss: 6.20519359e-07
Iter: 779 loss: 6.20497133e-07
Iter: 780 loss: 6.20454443e-07
Iter: 781 loss: 6.20405956e-07
Iter: 782 loss: 6.2038464e-07
Iter: 783 loss: 6.20326546e-07
Iter: 784 loss: 6.2024651e-07
Iter: 785 loss: 6.20487185e-07
Iter: 786 loss: 6.20219e-07
Iter: 787 loss: 6.20112644e-07
Iter: 788 loss: 6.20338426e-07
Iter: 789 loss: 6.20070409e-07
Iter: 790 loss: 6.20010269e-07
Iter: 791 loss: 6.19928642e-07
Iter: 792 loss: 6.19909429e-07
Iter: 793 loss: 6.19799e-07
Iter: 794 loss: 6.21073696e-07
Iter: 795 loss: 6.19805462e-07
Iter: 796 loss: 6.1970178e-07
Iter: 797 loss: 6.19636296e-07
Iter: 798 loss: 6.19584171e-07
Iter: 799 loss: 6.19456785e-07
Iter: 800 loss: 6.19888283e-07
Iter: 801 loss: 6.19452749e-07
Iter: 802 loss: 6.19394484e-07
Iter: 803 loss: 6.19380899e-07
Iter: 804 loss: 6.19326329e-07
Iter: 805 loss: 6.19206276e-07
Iter: 806 loss: 6.21634854e-07
Iter: 807 loss: 6.19198204e-07
Iter: 808 loss: 6.19072637e-07
Iter: 809 loss: 6.19533353e-07
Iter: 810 loss: 6.19075e-07
Iter: 811 loss: 6.19006642e-07
Iter: 812 loss: 6.19167736e-07
Iter: 813 loss: 6.18974582e-07
Iter: 814 loss: 6.1892132e-07
Iter: 815 loss: 6.18945251e-07
Iter: 816 loss: 6.18896536e-07
Iter: 817 loss: 6.18818603e-07
Iter: 818 loss: 6.18822583e-07
Iter: 819 loss: 6.18722936e-07
Iter: 820 loss: 6.19452408e-07
Iter: 821 loss: 6.18754086e-07
Iter: 822 loss: 6.18688091e-07
Iter: 823 loss: 6.18589638e-07
Iter: 824 loss: 6.18608738e-07
Iter: 825 loss: 6.18493118e-07
Iter: 826 loss: 6.18794672e-07
Iter: 827 loss: 6.18474e-07
Iter: 828 loss: 6.18389208e-07
Iter: 829 loss: 6.18757781e-07
Iter: 830 loss: 6.18360843e-07
Iter: 831 loss: 6.18276147e-07
Iter: 832 loss: 6.18211971e-07
Iter: 833 loss: 6.18201966e-07
Iter: 834 loss: 6.18092827e-07
Iter: 835 loss: 6.19088439e-07
Iter: 836 loss: 6.18087654e-07
Iter: 837 loss: 6.17999547e-07
Iter: 838 loss: 6.18122158e-07
Iter: 839 loss: 6.17911894e-07
Iter: 840 loss: 6.17840783e-07
Iter: 841 loss: 6.17827368e-07
Iter: 842 loss: 6.17752619e-07
Iter: 843 loss: 6.17667297e-07
Iter: 844 loss: 6.17694297e-07
Iter: 845 loss: 6.1757828e-07
Iter: 846 loss: 6.17418777e-07
Iter: 847 loss: 6.18284162e-07
Iter: 848 loss: 6.1739064e-07
Iter: 849 loss: 6.17305886e-07
Iter: 850 loss: 6.17305545e-07
Iter: 851 loss: 6.17256205e-07
Iter: 852 loss: 6.17167359e-07
Iter: 853 loss: 6.17151045e-07
Iter: 854 loss: 6.17062597e-07
Iter: 855 loss: 6.17072828e-07
Iter: 856 loss: 6.17013541e-07
Iter: 857 loss: 6.1692441e-07
Iter: 858 loss: 6.16918555e-07
Iter: 859 loss: 6.16809928e-07
Iter: 860 loss: 6.17030821e-07
Iter: 861 loss: 6.16779744e-07
Iter: 862 loss: 6.16740465e-07
Iter: 863 loss: 6.17312253e-07
Iter: 864 loss: 6.16751663e-07
Iter: 865 loss: 6.16647526e-07
Iter: 866 loss: 6.1689974e-07
Iter: 867 loss: 6.16625186e-07
Iter: 868 loss: 6.16592615e-07
Iter: 869 loss: 6.16508373e-07
Iter: 870 loss: 6.16528e-07
Iter: 871 loss: 6.16442549e-07
Iter: 872 loss: 6.16447949e-07
Iter: 873 loss: 6.1639912e-07
Iter: 874 loss: 6.16292937e-07
Iter: 875 loss: 6.17762112e-07
Iter: 876 loss: 6.16307489e-07
Iter: 877 loss: 6.16228249e-07
Iter: 878 loss: 6.16429304e-07
Iter: 879 loss: 6.16197781e-07
Iter: 880 loss: 6.1609262e-07
Iter: 881 loss: 6.16658497e-07
Iter: 882 loss: 6.16082673e-07
Iter: 883 loss: 6.16000136e-07
Iter: 884 loss: 6.16906959e-07
Iter: 885 loss: 6.15995418e-07
Iter: 886 loss: 6.15957788e-07
Iter: 887 loss: 6.15947386e-07
Iter: 888 loss: 6.15914928e-07
Iter: 889 loss: 6.1585763e-07
Iter: 890 loss: 6.1589526e-07
Iter: 891 loss: 6.1579459e-07
Iter: 892 loss: 6.15706767e-07
Iter: 893 loss: 6.15696081e-07
Iter: 894 loss: 6.15585577e-07
Iter: 895 loss: 6.15514068e-07
Iter: 896 loss: 6.15674594e-07
Iter: 897 loss: 6.15449039e-07
Iter: 898 loss: 6.15375541e-07
Iter: 899 loss: 6.15374e-07
Iter: 900 loss: 6.15295107e-07
Iter: 901 loss: 6.15334102e-07
Iter: 902 loss: 6.15246336e-07
Iter: 903 loss: 6.1516954e-07
Iter: 904 loss: 6.15426302e-07
Iter: 905 loss: 6.15165e-07
Iter: 906 loss: 6.15108434e-07
Iter: 907 loss: 6.15587339e-07
Iter: 908 loss: 6.15115596e-07
Iter: 909 loss: 6.15071599e-07
Iter: 910 loss: 6.15010435e-07
Iter: 911 loss: 6.16087618e-07
Iter: 912 loss: 6.15001852e-07
Iter: 913 loss: 6.14912096e-07
Iter: 914 loss: 6.15123099e-07
Iter: 915 loss: 6.14915621e-07
Iter: 916 loss: 6.14844794e-07
Iter: 917 loss: 6.14827627e-07
Iter: 918 loss: 6.14808869e-07
Iter: 919 loss: 6.14707687e-07
Iter: 920 loss: 6.15801355e-07
Iter: 921 loss: 6.14694954e-07
Iter: 922 loss: 6.14672558e-07
Iter: 923 loss: 6.14634587e-07
Iter: 924 loss: 6.14597e-07
Iter: 925 loss: 6.14573764e-07
Iter: 926 loss: 6.14549e-07
Iter: 927 loss: 6.14492e-07
Iter: 928 loss: 6.14486e-07
Iter: 929 loss: 6.14409487e-07
Iter: 930 loss: 6.14368446e-07
Iter: 931 loss: 6.14726503e-07
Iter: 932 loss: 6.14335136e-07
Iter: 933 loss: 6.14277496e-07
Iter: 934 loss: 6.15045963e-07
Iter: 935 loss: 6.14272494e-07
Iter: 936 loss: 6.14238331e-07
Iter: 937 loss: 6.14125327e-07
Iter: 938 loss: 6.14113219e-07
Iter: 939 loss: 6.14094517e-07
Iter: 940 loss: 6.14069108e-07
Iter: 941 loss: 6.14023065e-07
Iter: 942 loss: 6.13926261e-07
Iter: 943 loss: 6.16172201e-07
Iter: 944 loss: 6.13923248e-07
Iter: 945 loss: 6.13794214e-07
Iter: 946 loss: 6.13789268e-07
Iter: 947 loss: 6.13719635e-07
Iter: 948 loss: 6.13634313e-07
Iter: 949 loss: 6.13637894e-07
Iter: 950 loss: 6.13597535e-07
Iter: 951 loss: 6.13689167e-07
Iter: 952 loss: 6.1356576e-07
Iter: 953 loss: 6.13521649e-07
Iter: 954 loss: 6.136205e-07
Iter: 955 loss: 6.13492148e-07
Iter: 956 loss: 6.13411544e-07
Iter: 957 loss: 6.13641873e-07
Iter: 958 loss: 6.13418706e-07
Iter: 959 loss: 6.13389261e-07
Iter: 960 loss: 6.1334606e-07
Iter: 961 loss: 6.13320253e-07
Iter: 962 loss: 6.13266593e-07
Iter: 963 loss: 6.13330826e-07
Iter: 964 loss: 6.1323675e-07
Iter: 965 loss: 6.13196278e-07
Iter: 966 loss: 6.13177235e-07
Iter: 967 loss: 6.1315086e-07
Iter: 968 loss: 6.13118459e-07
Iter: 969 loss: 6.130565e-07
Iter: 970 loss: 6.13020802e-07
Iter: 971 loss: 6.13154498e-07
Iter: 972 loss: 6.12997439e-07
Iter: 973 loss: 6.12942472e-07
Iter: 974 loss: 6.13318207e-07
Iter: 975 loss: 6.12908309e-07
Iter: 976 loss: 6.12853341e-07
Iter: 977 loss: 6.127799e-07
Iter: 978 loss: 6.127853e-07
Iter: 979 loss: 6.12698273e-07
Iter: 980 loss: 6.12866415e-07
Iter: 981 loss: 6.12695089e-07
Iter: 982 loss: 6.12588451e-07
Iter: 983 loss: 6.13584916e-07
Iter: 984 loss: 6.12600047e-07
Iter: 985 loss: 6.12503698e-07
Iter: 986 loss: 6.12539111e-07
Iter: 987 loss: 6.12465044e-07
Iter: 988 loss: 6.1240803e-07
Iter: 989 loss: 6.1280906e-07
Iter: 990 loss: 6.12402687e-07
Iter: 991 loss: 6.12321969e-07
Iter: 992 loss: 6.12227211e-07
Iter: 993 loss: 6.14873784e-07
Iter: 994 loss: 6.12217207e-07
Iter: 995 loss: 6.12064412e-07
Iter: 996 loss: 6.12715212e-07
Iter: 997 loss: 6.12032636e-07
Iter: 998 loss: 6.11957546e-07
Iter: 999 loss: 6.12728911e-07
Iter: 1000 loss: 6.11953283e-07
Iter: 1001 loss: 6.1186347e-07
Iter: 1002 loss: 6.12295139e-07
Iter: 1003 loss: 6.1186347e-07
Iter: 1004 loss: 6.1180441e-07
Iter: 1005 loss: 6.11811e-07
Iter: 1006 loss: 6.1176587e-07
Iter: 1007 loss: 6.11754e-07
Iter: 1008 loss: 6.11731821e-07
Iter: 1009 loss: 6.11707719e-07
Iter: 1010 loss: 6.1165747e-07
Iter: 1011 loss: 6.12927465e-07
Iter: 1012 loss: 6.116544e-07
Iter: 1013 loss: 6.11604889e-07
Iter: 1014 loss: 6.11715791e-07
Iter: 1015 loss: 6.11591872e-07
Iter: 1016 loss: 6.1154492e-07
Iter: 1017 loss: 6.11547478e-07
Iter: 1018 loss: 6.11491544e-07
Iter: 1019 loss: 6.1144442e-07
Iter: 1020 loss: 6.11431517e-07
Iter: 1021 loss: 6.11393375e-07
Iter: 1022 loss: 6.11943676e-07
Iter: 1023 loss: 6.11386326e-07
Iter: 1024 loss: 6.11330393e-07
Iter: 1025 loss: 6.11258827e-07
Iter: 1026 loss: 6.11285e-07
Iter: 1027 loss: 6.11171799e-07
Iter: 1028 loss: 6.11187716e-07
Iter: 1029 loss: 6.1112803e-07
Iter: 1030 loss: 6.11020596e-07
Iter: 1031 loss: 6.11840449e-07
Iter: 1032 loss: 6.11006101e-07
Iter: 1033 loss: 6.10953464e-07
Iter: 1034 loss: 6.11868e-07
Iter: 1035 loss: 6.10930499e-07
Iter: 1036 loss: 6.10903896e-07
Iter: 1037 loss: 6.10820734e-07
Iter: 1038 loss: 6.1082369e-07
Iter: 1039 loss: 6.10776112e-07
Iter: 1040 loss: 6.11293672e-07
Iter: 1041 loss: 6.10758946e-07
Iter: 1042 loss: 6.10650147e-07
Iter: 1043 loss: 6.1078191e-07
Iter: 1044 loss: 6.10598931e-07
Iter: 1045 loss: 6.10524239e-07
Iter: 1046 loss: 6.10485301e-07
Iter: 1047 loss: 6.10465634e-07
Iter: 1048 loss: 6.10353595e-07
Iter: 1049 loss: 6.11527412e-07
Iter: 1050 loss: 6.10348877e-07
Iter: 1051 loss: 6.102062e-07
Iter: 1052 loss: 6.10312554e-07
Iter: 1053 loss: 6.1014191e-07
Iter: 1054 loss: 6.10074835e-07
Iter: 1055 loss: 6.10967504e-07
Iter: 1056 loss: 6.1005494e-07
Iter: 1057 loss: 6.1001225e-07
Iter: 1058 loss: 6.09996619e-07
Iter: 1059 loss: 6.09959841e-07
Iter: 1060 loss: 6.0986838e-07
Iter: 1061 loss: 6.09923291e-07
Iter: 1062 loss: 6.09855874e-07
Iter: 1063 loss: 6.09779647e-07
Iter: 1064 loss: 6.10203301e-07
Iter: 1065 loss: 6.09799883e-07
Iter: 1066 loss: 6.09766403e-07
Iter: 1067 loss: 6.10285838e-07
Iter: 1068 loss: 6.09772542e-07
Iter: 1069 loss: 6.09684434e-07
Iter: 1070 loss: 6.0966704e-07
Iter: 1071 loss: 6.09627307e-07
Iter: 1072 loss: 6.09576773e-07
Iter: 1073 loss: 6.09851782e-07
Iter: 1074 loss: 6.09556764e-07
Iter: 1075 loss: 6.09478661e-07
Iter: 1076 loss: 6.09998e-07
Iter: 1077 loss: 6.09465076e-07
Iter: 1078 loss: 6.09391634e-07
Iter: 1079 loss: 6.09259473e-07
Iter: 1080 loss: 6.10985921e-07
Iter: 1081 loss: 6.09239237e-07
Iter: 1082 loss: 6.09124925e-07
Iter: 1083 loss: 6.10582333e-07
Iter: 1084 loss: 6.09148685e-07
Iter: 1085 loss: 6.09038636e-07
Iter: 1086 loss: 6.09832398e-07
Iter: 1087 loss: 6.09041308e-07
Iter: 1088 loss: 6.08988785e-07
Iter: 1089 loss: 6.09016297e-07
Iter: 1090 loss: 6.08957407e-07
Iter: 1091 loss: 6.08852474e-07
Iter: 1092 loss: 6.09121514e-07
Iter: 1093 loss: 6.08836217e-07
Iter: 1094 loss: 6.08804783e-07
Iter: 1095 loss: 6.08733671e-07
Iter: 1096 loss: 6.08723e-07
Iter: 1097 loss: 6.08637151e-07
Iter: 1098 loss: 6.08719802e-07
Iter: 1099 loss: 6.08587129e-07
Iter: 1100 loss: 6.0849311e-07
Iter: 1101 loss: 6.09847518e-07
Iter: 1102 loss: 6.08484243e-07
Iter: 1103 loss: 6.08403184e-07
Iter: 1104 loss: 6.08511584e-07
Iter: 1105 loss: 6.0837e-07
Iter: 1106 loss: 6.0831178e-07
Iter: 1107 loss: 6.0833554e-07
Iter: 1108 loss: 6.08258517e-07
Iter: 1109 loss: 6.08190874e-07
Iter: 1110 loss: 6.08177174e-07
Iter: 1111 loss: 6.08136361e-07
Iter: 1112 loss: 6.0807929e-07
Iter: 1113 loss: 6.0806866e-07
Iter: 1114 loss: 6.08000505e-07
Iter: 1115 loss: 6.08040807e-07
Iter: 1116 loss: 6.07954e-07
Iter: 1117 loss: 6.0793144e-07
Iter: 1118 loss: 6.07882384e-07
Iter: 1119 loss: 6.07878064e-07
Iter: 1120 loss: 6.07831453e-07
Iter: 1121 loss: 6.07824518e-07
Iter: 1122 loss: 6.07776087e-07
Iter: 1123 loss: 6.08126243e-07
Iter: 1124 loss: 6.07772222e-07
Iter: 1125 loss: 6.07737775e-07
Iter: 1126 loss: 6.07661832e-07
Iter: 1127 loss: 6.09154483e-07
Iter: 1128 loss: 6.07667801e-07
Iter: 1129 loss: 6.07608854e-07
Iter: 1130 loss: 6.07864308e-07
Iter: 1131 loss: 6.07578045e-07
Iter: 1132 loss: 6.07517e-07
Iter: 1133 loss: 6.07666607e-07
Iter: 1134 loss: 6.07511538e-07
Iter: 1135 loss: 6.07418428e-07
Iter: 1136 loss: 6.07953325e-07
Iter: 1137 loss: 6.0740922e-07
Iter: 1138 loss: 6.07362722e-07
Iter: 1139 loss: 6.07370112e-07
Iter: 1140 loss: 6.07325433e-07
Iter: 1141 loss: 6.07270124e-07
Iter: 1142 loss: 6.07929e-07
Iter: 1143 loss: 6.07278707e-07
Iter: 1144 loss: 6.07219704e-07
Iter: 1145 loss: 6.07137565e-07
Iter: 1146 loss: 6.07131e-07
Iter: 1147 loss: 6.07033371e-07
Iter: 1148 loss: 6.07049e-07
Iter: 1149 loss: 6.06957087e-07
Iter: 1150 loss: 6.06933781e-07
Iter: 1151 loss: 6.06916899e-07
Iter: 1152 loss: 6.06843173e-07
Iter: 1153 loss: 6.06826632e-07
Iter: 1154 loss: 6.06808783e-07
Iter: 1155 loss: 6.06719141e-07
Iter: 1156 loss: 6.07230561e-07
Iter: 1157 loss: 6.06719937e-07
Iter: 1158 loss: 6.06669289e-07
Iter: 1159 loss: 6.06681397e-07
Iter: 1160 loss: 6.06614663e-07
Iter: 1161 loss: 6.06541903e-07
Iter: 1162 loss: 6.06690605e-07
Iter: 1163 loss: 6.06520757e-07
Iter: 1164 loss: 6.06495632e-07
Iter: 1165 loss: 6.06703168e-07
Iter: 1166 loss: 6.06472e-07
Iter: 1167 loss: 6.06444587e-07
Iter: 1168 loss: 6.06948902e-07
Iter: 1169 loss: 6.0642418e-07
Iter: 1170 loss: 6.06394906e-07
Iter: 1171 loss: 6.06404285e-07
Iter: 1172 loss: 6.06347839e-07
Iter: 1173 loss: 6.06310266e-07
Iter: 1174 loss: 6.06406616e-07
Iter: 1175 loss: 6.06299523e-07
Iter: 1176 loss: 6.06228923e-07
Iter: 1177 loss: 6.06450271e-07
Iter: 1178 loss: 6.06195727e-07
Iter: 1179 loss: 6.06173046e-07
Iter: 1180 loss: 6.06112224e-07
Iter: 1181 loss: 6.06102617e-07
Iter: 1182 loss: 6.06021558e-07
Iter: 1183 loss: 6.06617959e-07
Iter: 1184 loss: 6.05994e-07
Iter: 1185 loss: 6.05921e-07
Iter: 1186 loss: 6.06245635e-07
Iter: 1187 loss: 6.05898606e-07
Iter: 1188 loss: 6.05853529e-07
Iter: 1189 loss: 6.0604134e-07
Iter: 1190 loss: 6.05855178e-07
Iter: 1191 loss: 6.05797e-07
Iter: 1192 loss: 6.05840512e-07
Iter: 1193 loss: 6.05759908e-07
Iter: 1194 loss: 6.05717446e-07
Iter: 1195 loss: 6.05675666e-07
Iter: 1196 loss: 6.0567e-07
Iter: 1197 loss: 6.05578293e-07
Iter: 1198 loss: 6.05935611e-07
Iter: 1199 loss: 6.05565e-07
Iter: 1200 loss: 6.05489333e-07
Iter: 1201 loss: 6.06145875e-07
Iter: 1202 loss: 6.05483137e-07
Iter: 1203 loss: 6.05439254e-07
Iter: 1204 loss: 6.05395599e-07
Iter: 1205 loss: 6.05383832e-07
Iter: 1206 loss: 6.05283276e-07
Iter: 1207 loss: 6.05541572e-07
Iter: 1208 loss: 6.05241e-07
Iter: 1209 loss: 6.05164e-07
Iter: 1210 loss: 6.05162768e-07
Iter: 1211 loss: 6.05137757e-07
Iter: 1212 loss: 6.05055448e-07
Iter: 1213 loss: 6.0626769e-07
Iter: 1214 loss: 6.05048172e-07
Iter: 1215 loss: 6.04958302e-07
Iter: 1216 loss: 6.05457615e-07
Iter: 1217 loss: 6.04952788e-07
Iter: 1218 loss: 6.04920729e-07
Iter: 1219 loss: 6.04919251e-07
Iter: 1220 loss: 6.04881848e-07
Iter: 1221 loss: 6.04839101e-07
Iter: 1222 loss: 6.04871616e-07
Iter: 1223 loss: 6.04814886e-07
Iter: 1224 loss: 6.04966658e-07
Iter: 1225 loss: 6.04799254e-07
Iter: 1226 loss: 6.04757588e-07
Iter: 1227 loss: 6.04720299e-07
Iter: 1228 loss: 6.0470154e-07
Iter: 1229 loss: 6.04644413e-07
Iter: 1230 loss: 6.04698926e-07
Iter: 1231 loss: 6.04602178e-07
Iter: 1232 loss: 6.04530896e-07
Iter: 1233 loss: 6.05332218e-07
Iter: 1234 loss: 6.04523052e-07
Iter: 1235 loss: 6.0444313e-07
Iter: 1236 loss: 6.04559489e-07
Iter: 1237 loss: 6.04387708e-07
Iter: 1238 loss: 6.04343427e-07
Iter: 1239 loss: 6.044354e-07
Iter: 1240 loss: 6.04294144e-07
Iter: 1241 loss: 6.04254069e-07
Iter: 1242 loss: 6.04269417e-07
Iter: 1243 loss: 6.04204843e-07
Iter: 1244 loss: 6.04125034e-07
Iter: 1245 loss: 6.04132765e-07
Iter: 1246 loss: 6.0406478e-07
Iter: 1247 loss: 6.04214506e-07
Iter: 1248 loss: 6.04044203e-07
Iter: 1249 loss: 6.0402823e-07
Iter: 1250 loss: 6.04e-07
Iter: 1251 loss: 6.03985768e-07
Iter: 1252 loss: 6.0389857e-07
Iter: 1253 loss: 6.05227456e-07
Iter: 1254 loss: 6.03908916e-07
Iter: 1255 loss: 6.03831e-07
Iter: 1256 loss: 6.04659249e-07
Iter: 1257 loss: 6.03832063e-07
Iter: 1258 loss: 6.03806427e-07
Iter: 1259 loss: 6.03729688e-07
Iter: 1260 loss: 6.03732474e-07
Iter: 1261 loss: 6.03659146e-07
Iter: 1262 loss: 6.03661931e-07
Iter: 1263 loss: 6.035811e-07
Iter: 1264 loss: 6.03536819e-07
Iter: 1265 loss: 6.03520789e-07
Iter: 1266 loss: 6.03468152e-07
Iter: 1267 loss: 6.03601507e-07
Iter: 1268 loss: 6.03457124e-07
Iter: 1269 loss: 6.0341273e-07
Iter: 1270 loss: 6.03397552e-07
Iter: 1271 loss: 6.0338931e-07
Iter: 1272 loss: 6.033506e-07
Iter: 1273 loss: 6.03346052e-07
Iter: 1274 loss: 6.03318313e-07
Iter: 1275 loss: 6.03260503e-07
Iter: 1276 loss: 6.03258741e-07
Iter: 1277 loss: 6.0320383e-07
Iter: 1278 loss: 6.03154774e-07
Iter: 1279 loss: 6.03156366e-07
Iter: 1280 loss: 6.03055469e-07
Iter: 1281 loss: 6.03065814e-07
Iter: 1282 loss: 6.02985e-07
Iter: 1283 loss: 6.03019316e-07
Iter: 1284 loss: 6.02957471e-07
Iter: 1285 loss: 6.02877321e-07
Iter: 1286 loss: 6.03140961e-07
Iter: 1287 loss: 6.02866294e-07
Iter: 1288 loss: 6.02775117e-07
Iter: 1289 loss: 6.02760451e-07
Iter: 1290 loss: 6.02725777e-07
Iter: 1291 loss: 6.0266558e-07
Iter: 1292 loss: 6.02722309e-07
Iter: 1293 loss: 6.0262721e-07
Iter: 1294 loss: 6.02547289e-07
Iter: 1295 loss: 6.02764885e-07
Iter: 1296 loss: 6.02516309e-07
Iter: 1297 loss: 6.0245759e-07
Iter: 1298 loss: 6.03521585e-07
Iter: 1299 loss: 6.02458783e-07
Iter: 1300 loss: 6.02419334e-07
Iter: 1301 loss: 6.02387331e-07
Iter: 1302 loss: 6.02374939e-07
Iter: 1303 loss: 6.02304908e-07
Iter: 1304 loss: 6.02630848e-07
Iter: 1305 loss: 6.02321279e-07
Iter: 1306 loss: 6.02223849e-07
Iter: 1307 loss: 6.02462762e-07
Iter: 1308 loss: 6.02226862e-07
Iter: 1309 loss: 6.02161151e-07
Iter: 1310 loss: 6.02129148e-07
Iter: 1311 loss: 6.02118348e-07
Iter: 1312 loss: 6.02068212e-07
Iter: 1313 loss: 6.02517787e-07
Iter: 1314 loss: 6.02043258e-07
Iter: 1315 loss: 6.01969305e-07
Iter: 1316 loss: 6.02595605e-07
Iter: 1317 loss: 6.01978741e-07
Iter: 1318 loss: 6.01921727e-07
Iter: 1319 loss: 6.01933721e-07
Iter: 1320 loss: 6.01903423e-07
Iter: 1321 loss: 6.01866532e-07
Iter: 1322 loss: 6.0225068e-07
Iter: 1323 loss: 6.01868805e-07
Iter: 1324 loss: 6.01833733e-07
Iter: 1325 loss: 6.01766487e-07
Iter: 1326 loss: 6.02776254e-07
Iter: 1327 loss: 6.01765578e-07
Iter: 1328 loss: 6.01655699e-07
Iter: 1329 loss: 6.01768875e-07
Iter: 1330 loss: 6.01627e-07
Iter: 1331 loss: 6.01539909e-07
Iter: 1332 loss: 6.0154025e-07
Iter: 1333 loss: 6.01442366e-07
Iter: 1334 loss: 6.01418265e-07
Iter: 1335 loss: 6.01352212e-07
Iter: 1336 loss: 6.01268482e-07
Iter: 1337 loss: 6.01379043e-07
Iter: 1338 loss: 6.01213628e-07
Iter: 1339 loss: 6.01152692e-07
Iter: 1340 loss: 6.01141437e-07
Iter: 1341 loss: 6.01087152e-07
Iter: 1342 loss: 6.00981764e-07
Iter: 1343 loss: 6.00977728e-07
Iter: 1344 loss: 6.00910084e-07
Iter: 1345 loss: 6.01581633e-07
Iter: 1346 loss: 6.00900933e-07
Iter: 1347 loss: 6.00855969e-07
Iter: 1348 loss: 6.01311172e-07
Iter: 1349 loss: 6.00872283e-07
Iter: 1350 loss: 6.00843293e-07
Iter: 1351 loss: 6.00774456e-07
Iter: 1352 loss: 6.00777469e-07
Iter: 1353 loss: 6.00747114e-07
Iter: 1354 loss: 6.01107388e-07
Iter: 1355 loss: 6.00727333e-07
Iter: 1356 loss: 6.00676856e-07
Iter: 1357 loss: 6.00677481e-07
Iter: 1358 loss: 6.00640305e-07
Iter: 1359 loss: 6.00593921e-07
Iter: 1360 loss: 6.0051218e-07
Iter: 1361 loss: 6.00510702e-07
Iter: 1362 loss: 6.00436181e-07
Iter: 1363 loss: 6.01064698e-07
Iter: 1364 loss: 6.00424357e-07
Iter: 1365 loss: 6.00398266e-07
Iter: 1366 loss: 6.00360522e-07
Iter: 1367 loss: 6.00354042e-07
Iter: 1368 loss: 6.00272529e-07
Iter: 1369 loss: 6.01732893e-07
Iter: 1370 loss: 6.00278668e-07
Iter: 1371 loss: 6.00248143e-07
Iter: 1372 loss: 6.00257863e-07
Iter: 1373 loss: 6.00205624e-07
Iter: 1374 loss: 6.00278327e-07
Iter: 1375 loss: 6.00185444e-07
Iter: 1376 loss: 6.00161798e-07
Iter: 1377 loss: 6.00080227e-07
Iter: 1378 loss: 6.01439e-07
Iter: 1379 loss: 6.00077669e-07
Iter: 1380 loss: 6.0000491e-07
Iter: 1381 loss: 5.9999951e-07
Iter: 1382 loss: 5.99949658e-07
Iter: 1383 loss: 6.00168619e-07
Iter: 1384 loss: 5.99927e-07
Iter: 1385 loss: 5.99894861e-07
Iter: 1386 loss: 5.99864507e-07
Iter: 1387 loss: 5.99834834e-07
Iter: 1388 loss: 5.9975e-07
Iter: 1389 loss: 6.00288104e-07
Iter: 1390 loss: 5.99750365e-07
Iter: 1391 loss: 5.99694317e-07
Iter: 1392 loss: 5.99655891e-07
Iter: 1393 loss: 5.99625196e-07
Iter: 1394 loss: 5.99533e-07
Iter: 1395 loss: 5.99657369e-07
Iter: 1396 loss: 5.9952265e-07
Iter: 1397 loss: 5.99455404e-07
Iter: 1398 loss: 6.00224666e-07
Iter: 1399 loss: 5.99458474e-07
Iter: 1400 loss: 5.99384805e-07
Iter: 1401 loss: 5.99765826e-07
Iter: 1402 loss: 5.99374459e-07
Iter: 1403 loss: 5.99341661e-07
Iter: 1404 loss: 5.99313125e-07
Iter: 1405 loss: 5.99313466e-07
Iter: 1406 loss: 5.99264808e-07
Iter: 1407 loss: 5.99268105e-07
Iter: 1408 loss: 5.99215e-07
Iter: 1409 loss: 5.99117129e-07
Iter: 1410 loss: 6.00765702e-07
Iter: 1411 loss: 5.99118266e-07
Iter: 1412 loss: 5.99060058e-07
Iter: 1413 loss: 5.99561531e-07
Iter: 1414 loss: 5.99030045e-07
Iter: 1415 loss: 5.99013788e-07
Iter: 1416 loss: 5.99698296e-07
Iter: 1417 loss: 5.99011855e-07
Iter: 1418 loss: 5.98959e-07
Iter: 1419 loss: 5.98902318e-07
Iter: 1420 loss: 5.98896406e-07
Iter: 1421 loss: 5.98831207e-07
Iter: 1422 loss: 5.99374118e-07
Iter: 1423 loss: 5.98831775e-07
Iter: 1424 loss: 5.98812e-07
Iter: 1425 loss: 5.98755946e-07
Iter: 1426 loss: 5.98751512e-07
Iter: 1427 loss: 5.98661813e-07
Iter: 1428 loss: 5.98633164e-07
Iter: 1429 loss: 5.98599513e-07
Iter: 1430 loss: 5.98506631e-07
Iter: 1431 loss: 5.98906922e-07
Iter: 1432 loss: 5.98508393e-07
Iter: 1433 loss: 5.98461099e-07
Iter: 1434 loss: 5.98456438e-07
Iter: 1435 loss: 5.98388397e-07
Iter: 1436 loss: 5.98332e-07
Iter: 1437 loss: 5.98312567e-07
Iter: 1438 loss: 5.98268684e-07
Iter: 1439 loss: 5.9853005e-07
Iter: 1440 loss: 5.98270162e-07
Iter: 1441 loss: 5.98228439e-07
Iter: 1442 loss: 5.98699785e-07
Iter: 1443 loss: 5.98235772e-07
Iter: 1444 loss: 5.98211159e-07
Iter: 1445 loss: 5.98165116e-07
Iter: 1446 loss: 5.98158408e-07
Iter: 1447 loss: 5.98131805e-07
Iter: 1448 loss: 5.98450811e-07
Iter: 1449 loss: 5.98122483e-07
Iter: 1450 loss: 5.98086501e-07
Iter: 1451 loss: 5.98203087e-07
Iter: 1452 loss: 5.98054896e-07
Iter: 1453 loss: 5.98028123e-07
Iter: 1454 loss: 5.98064503e-07
Iter: 1455 loss: 5.9800152e-07
Iter: 1456 loss: 5.9796497e-07
Iter: 1457 loss: 5.98223096e-07
Iter: 1458 loss: 5.97954624e-07
Iter: 1459 loss: 5.97918358e-07
Iter: 1460 loss: 5.97863504e-07
Iter: 1461 loss: 5.97842472e-07
Iter: 1462 loss: 5.97790915e-07
Iter: 1463 loss: 5.97883286e-07
Iter: 1464 loss: 5.97741064e-07
Iter: 1465 loss: 5.97667963e-07
Iter: 1466 loss: 5.97877943e-07
Iter: 1467 loss: 5.97647897e-07
Iter: 1468 loss: 5.97600604e-07
Iter: 1469 loss: 5.97597875e-07
Iter: 1470 loss: 5.97550752e-07
Iter: 1471 loss: 5.97510848e-07
Iter: 1472 loss: 5.97501639e-07
Iter: 1473 loss: 5.97444739e-07
Iter: 1474 loss: 5.97592134e-07
Iter: 1475 loss: 5.97442408e-07
Iter: 1476 loss: 5.97364703e-07
Iter: 1477 loss: 5.98225597e-07
Iter: 1478 loss: 5.97356859e-07
Iter: 1479 loss: 5.97345434e-07
Iter: 1480 loss: 5.97259827e-07
Iter: 1481 loss: 5.98708e-07
Iter: 1482 loss: 5.97255621e-07
Iter: 1483 loss: 5.97195935e-07
Iter: 1484 loss: 5.97332246e-07
Iter: 1485 loss: 5.97158532e-07
Iter: 1486 loss: 5.97103508e-07
Iter: 1487 loss: 5.97877943e-07
Iter: 1488 loss: 5.97118628e-07
Iter: 1489 loss: 5.97089752e-07
Iter: 1490 loss: 5.9747083e-07
Iter: 1491 loss: 5.97059966e-07
Iter: 1492 loss: 5.97051894e-07
Iter: 1493 loss: 5.9706872e-07
Iter: 1494 loss: 5.97035523e-07
Iter: 1495 loss: 5.96992038e-07
Iter: 1496 loss: 5.97359588e-07
Iter: 1497 loss: 5.96998802e-07
Iter: 1498 loss: 5.96983227e-07
Iter: 1499 loss: 5.96937468e-07
Iter: 1500 loss: 5.96945711e-07
Iter: 1501 loss: 5.96904044e-07
Iter: 1502 loss: 5.96919506e-07
Iter: 1503 loss: 5.96898644e-07
Iter: 1504 loss: 5.96837708e-07
Iter: 1505 loss: 5.97517385e-07
Iter: 1506 loss: 5.96844416e-07
Iter: 1507 loss: 5.9682344e-07
Iter: 1508 loss: 5.96785128e-07
Iter: 1509 loss: 5.96786e-07
Iter: 1510 loss: 5.96732434e-07
Iter: 1511 loss: 5.96939344e-07
Iter: 1512 loss: 5.96733912e-07
Iter: 1513 loss: 5.96683435e-07
Iter: 1514 loss: 5.96782684e-07
Iter: 1515 loss: 5.96665416e-07
Iter: 1516 loss: 5.96652285e-07
Iter: 1517 loss: 5.96610278e-07
Iter: 1518 loss: 5.9659186e-07
Iter: 1519 loss: 5.9655008e-07
Iter: 1520 loss: 5.9659e-07
Iter: 1521 loss: 5.96545362e-07
Iter: 1522 loss: 5.96515406e-07
Iter: 1523 loss: 5.96564519e-07
Iter: 1524 loss: 5.96504321e-07
Iter: 1525 loss: 5.96476525e-07
Iter: 1526 loss: 5.96510858e-07
Iter: 1527 loss: 5.96440373e-07
Iter: 1528 loss: 5.96395807e-07
Iter: 1529 loss: 5.96751534e-07
Iter: 1530 loss: 5.96406721e-07
Iter: 1531 loss: 5.96371365e-07
Iter: 1532 loss: 5.96429345e-07
Iter: 1533 loss: 5.96341351e-07
Iter: 1534 loss: 5.96299174e-07
Iter: 1535 loss: 5.96255518e-07
Iter: 1536 loss: 5.96258928e-07
Iter: 1537 loss: 5.96200437e-07
Iter: 1538 loss: 5.96626876e-07
Iter: 1539 loss: 5.96171276e-07
Iter: 1540 loss: 5.9614581e-07
Iter: 1541 loss: 5.96649556e-07
Iter: 1542 loss: 5.96137e-07
Iter: 1543 loss: 5.96153086e-07
Iter: 1544 loss: 5.96144559e-07
Iter: 1545 loss: 5.96128871e-07
Iter: 1546 loss: 5.96144901e-07
Iter: 1547 loss: 5.96150585e-07
Iter: 1548 loss: 5.96134271e-07
Iter: 1549 loss: 5.96152177e-07
Iter: 1550 loss: 5.96138193e-07
Iter: 1551 loss: 5.96142741e-07
Iter: 1552 loss: 5.96148197e-07
Iter: 1553 loss: 5.96151835e-07
Iter: 1554 loss: 5.96148425e-07
Iter: 1555 loss: 5.96145298e-07
Iter: 1556 loss: 5.96145242e-07
Iter: 1557 loss: 5.96147515e-07
Iter: 1558 loss: 5.96137852e-07
Iter: 1559 loss: 5.96134441e-07
Iter: 1560 loss: 5.96137227e-07
Iter: 1561 loss: 5.96137397e-07
Iter: 1562 loss: 5.96137227e-07
Iter: 1563 loss: 5.96137056e-07
Iter: 1564 loss: 5.96136886e-07
Iter: 1565 loss: 5.96137056e-07
Iter: 1566 loss: 5.96137056e-07
Iter: 1567 loss: 5.96137852e-07
Iter: 1568 loss: 5.96137852e-07
Iter: 1569 loss: 5.96137056e-07
Iter: 1570 loss: 5.96076688e-07
Iter: 1571 loss: 5.96896371e-07
Iter: 1572 loss: 5.96056282e-07
Iter: 1573 loss: 5.96085613e-07
Iter: 1574 loss: 5.9605145e-07
Iter: 1575 loss: 5.96053098e-07
Iter: 1576 loss: 5.96057248e-07
Iter: 1577 loss: 5.96048153e-07
Iter: 1578 loss: 5.96059692e-07
Iter: 1579 loss: 5.96061568e-07
Iter: 1580 loss: 5.96064126e-07
Iter: 1581 loss: 5.96066457e-07
Iter: 1582 loss: 5.96056054e-07
Iter: 1583 loss: 5.96059408e-07
Iter: 1584 loss: 5.9605884e-07
Iter: 1585 loss: 5.96048153e-07
Iter: 1586 loss: 5.96061113e-07
Iter: 1587 loss: 5.9604713e-07
Iter: 1588 loss: 5.96055372e-07
Iter: 1589 loss: 5.96049915e-07
Iter: 1590 loss: 5.96053155e-07
Iter: 1591 loss: 5.96051223e-07
Iter: 1592 loss: 5.96053724e-07
Iter: 1593 loss: 5.96053383e-07
Iter: 1594 loss: 5.96053269e-07
Iter: 1595 loss: 5.96053212e-07
Iter: 1596 loss: 5.96051109e-07
Iter: 1597 loss: 5.96053496e-07
Iter: 1598 loss: 5.96051109e-07
Iter: 1599 loss: 5.96051e-07
Iter: 1600 loss: 5.96051e-07
Iter: 1601 loss: 5.96053496e-07
Iter: 1602 loss: 5.95990969e-07
Iter: 1603 loss: 5.96825e-07
Iter: 1604 loss: 5.95978e-07
Iter: 1605 loss: 5.95958454e-07
Iter: 1606 loss: 5.95955271e-07
Iter: 1607 loss: 5.95936285e-07
Iter: 1608 loss: 5.95864776e-07
Iter: 1609 loss: 5.96324639e-07
Iter: 1610 loss: 5.95845677e-07
Iter: 1611 loss: 5.95774509e-07
Iter: 1612 loss: 5.95993e-07
Iter: 1613 loss: 5.95738697e-07
Iter: 1614 loss: 5.95739266e-07
Iter: 1615 loss: 5.95726192e-07
Iter: 1616 loss: 5.95685265e-07
Iter: 1617 loss: 5.95607958e-07
Iter: 1618 loss: 5.95609e-07
Iter: 1619 loss: 5.95574079e-07
Iter: 1620 loss: 5.95740516e-07
Iter: 1621 loss: 5.95573624e-07
Iter: 1622 loss: 5.95541223e-07
Iter: 1623 loss: 5.960664e-07
Iter: 1624 loss: 5.95514507e-07
Iter: 1625 loss: 5.9551212e-07
Iter: 1626 loss: 5.95424524e-07
Iter: 1627 loss: 5.96430311e-07
Iter: 1628 loss: 5.95424467e-07
Iter: 1629 loss: 5.95373706e-07
Iter: 1630 loss: 5.95690153e-07
Iter: 1631 loss: 5.95390873e-07
Iter: 1632 loss: 5.95298843e-07
Iter: 1633 loss: 5.95670485e-07
Iter: 1634 loss: 5.95297934e-07
Iter: 1635 loss: 5.95260872e-07
Iter: 1636 loss: 5.95210679e-07
Iter: 1637 loss: 5.95225856e-07
Iter: 1638 loss: 5.95151e-07
Iter: 1639 loss: 5.95620918e-07
Iter: 1640 loss: 5.9514457e-07
Iter: 1641 loss: 5.95119332e-07
Iter: 1642 loss: 5.95471647e-07
Iter: 1643 loss: 5.95123367e-07
Iter: 1644 loss: 5.95092274e-07
Iter: 1645 loss: 5.95053621e-07
Iter: 1646 loss: 5.95437143e-07
Iter: 1647 loss: 5.95039523e-07
Iter: 1648 loss: 5.94994162e-07
Iter: 1649 loss: 5.95511267e-07
Iter: 1650 loss: 5.94971709e-07
Iter: 1651 loss: 5.94954145e-07
Iter: 1652 loss: 5.95156678e-07
Iter: 1653 loss: 5.94968583e-07
Iter: 1654 loss: 5.94893834e-07
Iter: 1655 loss: 5.94939706e-07
Iter: 1656 loss: 5.94880817e-07
Iter: 1657 loss: 5.94838411e-07
Iter: 1658 loss: 5.94825337e-07
Iter: 1659 loss: 5.9482295e-07
Iter: 1660 loss: 5.94770881e-07
Iter: 1661 loss: 5.95064705e-07
Iter: 1662 loss: 5.94752464e-07
Iter: 1663 loss: 5.94716084e-07
Iter: 1664 loss: 5.94824e-07
Iter: 1665 loss: 5.94686867e-07
Iter: 1666 loss: 5.94631615e-07
Iter: 1667 loss: 5.94657934e-07
Iter: 1668 loss: 5.94594894e-07
Iter: 1669 loss: 5.94571588e-07
Iter: 1670 loss: 5.94581536e-07
Iter: 1671 loss: 5.94518212e-07
Iter: 1672 loss: 5.94494509e-07
Iter: 1673 loss: 5.9527315e-07
Iter: 1674 loss: 5.94470862e-07
Iter: 1675 loss: 5.94452786e-07
Iter: 1676 loss: 5.9443272e-07
Iter: 1677 loss: 5.94420612e-07
Iter: 1678 loss: 5.94410778e-07
Iter: 1679 loss: 5.94383778e-07
Iter: 1680 loss: 5.94347455e-07
Iter: 1681 loss: 5.94273558e-07
Iter: 1682 loss: 5.95770757e-07
Iter: 1683 loss: 5.94290327e-07
Iter: 1684 loss: 5.94226435e-07
Iter: 1685 loss: 5.94993821e-07
Iter: 1686 loss: 5.94221262e-07
Iter: 1687 loss: 5.9417323e-07
Iter: 1688 loss: 5.94365304e-07
Iter: 1689 loss: 5.94169e-07
Iter: 1690 loss: 5.94123492e-07
Iter: 1691 loss: 5.94091887e-07
Iter: 1692 loss: 5.94077449e-07
Iter: 1693 loss: 5.94017934e-07
Iter: 1694 loss: 5.94219614e-07
Iter: 1695 loss: 5.94021117e-07
Iter: 1696 loss: 5.93961431e-07
Iter: 1697 loss: 5.94014239e-07
Iter: 1698 loss: 5.93955122e-07
Iter: 1699 loss: 5.93941479e-07
Iter: 1700 loss: 5.93950745e-07
Iter: 1701 loss: 5.93918514e-07
Iter: 1702 loss: 5.93884124e-07
Iter: 1703 loss: 5.9389248e-07
Iter: 1704 loss: 5.93860875e-07
Iter: 1705 loss: 5.93842458e-07
Iter: 1706 loss: 5.93816196e-07
Iter: 1707 loss: 5.93759296e-07
Iter: 1708 loss: 5.93999175e-07
Iter: 1709 loss: 5.93759694e-07
Iter: 1710 loss: 5.93708819e-07
Iter: 1711 loss: 5.94243147e-07
Iter: 1712 loss: 5.93721e-07
Iter: 1713 loss: 5.93685741e-07
Iter: 1714 loss: 5.9362884e-07
Iter: 1715 loss: 5.95018491e-07
Iter: 1716 loss: 5.93616619e-07
Iter: 1717 loss: 5.93573191e-07
Iter: 1718 loss: 5.94109e-07
Iter: 1719 loss: 5.93547952e-07
Iter: 1720 loss: 5.93530217e-07
Iter: 1721 loss: 5.93779191e-07
Iter: 1722 loss: 5.93506456e-07
Iter: 1723 loss: 5.9348406e-07
Iter: 1724 loss: 5.93510094e-07
Iter: 1725 loss: 5.9346371e-07
Iter: 1726 loss: 5.93452e-07
Iter: 1727 loss: 5.93529364e-07
Iter: 1728 loss: 5.93419486e-07
Iter: 1729 loss: 5.93403399e-07
Iter: 1730 loss: 5.93656409e-07
Iter: 1731 loss: 5.93398738e-07
Iter: 1732 loss: 5.93378218e-07
Iter: 1733 loss: 5.93334278e-07
Iter: 1734 loss: 5.94017536e-07
Iter: 1735 loss: 5.93351729e-07
Iter: 1736 loss: 5.93271523e-07
Iter: 1737 loss: 5.9327175e-07
Iter: 1738 loss: 5.93226559e-07
Iter: 1739 loss: 5.93204277e-07
Iter: 1740 loss: 5.93196432e-07
Iter: 1741 loss: 5.93168807e-07
Iter: 1742 loss: 5.9315505e-07
Iter: 1743 loss: 5.93119466e-07
Iter: 1744 loss: 5.93089226e-07
Iter: 1745 loss: 5.93029313e-07
Iter: 1746 loss: 5.9303909e-07
Iter: 1747 loss: 5.93019649e-07
Iter: 1748 loss: 5.92983e-07
Iter: 1749 loss: 5.92968604e-07
Iter: 1750 loss: 5.93027721e-07
Iter: 1751 loss: 5.92959623e-07
Iter: 1752 loss: 5.92945639e-07
Iter: 1753 loss: 5.92908577e-07
Iter: 1754 loss: 5.92893571e-07
Iter: 1755 loss: 5.92850711e-07
Iter: 1756 loss: 5.92871231e-07
Iter: 1757 loss: 5.92819447e-07
Iter: 1758 loss: 5.92760102e-07
Iter: 1759 loss: 5.92752713e-07
Iter: 1760 loss: 5.92715423e-07
Iter: 1761 loss: 5.93154482e-07
Iter: 1762 loss: 5.92711444e-07
Iter: 1763 loss: 5.92651475e-07
Iter: 1764 loss: 5.92773802e-07
Iter: 1765 loss: 5.9262743e-07
Iter: 1766 loss: 5.92615379e-07
Iter: 1767 loss: 5.92552965e-07
Iter: 1768 loss: 5.92531876e-07
Iter: 1769 loss: 5.9248822e-07
Iter: 1770 loss: 5.92825586e-07
Iter: 1771 loss: 5.92473612e-07
Iter: 1772 loss: 5.92415176e-07
Iter: 1773 loss: 5.92968263e-07
Iter: 1774 loss: 5.92422e-07
Iter: 1775 loss: 5.92413357e-07
Iter: 1776 loss: 5.92402898e-07
Iter: 1777 loss: 5.92382378e-07
Iter: 1778 loss: 5.92350034e-07
Iter: 1779 loss: 5.92336221e-07
Iter: 1780 loss: 5.92320873e-07
Iter: 1781 loss: 5.92291485e-07
Iter: 1782 loss: 5.92292679e-07
Iter: 1783 loss: 5.92250899e-07
Iter: 1784 loss: 5.92217532e-07
Iter: 1785 loss: 5.92202582e-07
Iter: 1786 loss: 5.92179617e-07
Iter: 1787 loss: 5.92521531e-07
Iter: 1788 loss: 5.92171602e-07
Iter: 1789 loss: 5.92142e-07
Iter: 1790 loss: 5.92207243e-07
Iter: 1791 loss: 5.92117772e-07
Iter: 1792 loss: 5.92113508e-07
Iter: 1793 loss: 5.92135791e-07
Iter: 1794 loss: 5.92094352e-07
Iter: 1795 loss: 5.92058e-07
Iter: 1796 loss: 5.92066385e-07
Iter: 1797 loss: 5.92053084e-07
Iter: 1798 loss: 5.92026197e-07
Iter: 1799 loss: 5.92860943e-07
Iter: 1800 loss: 5.92017329e-07
Iter: 1801 loss: 5.91987941e-07
Iter: 1802 loss: 5.9210663e-07
Iter: 1803 loss: 5.91955e-07
Iter: 1804 loss: 5.91928938e-07
Iter: 1805 loss: 5.92087474e-07
Iter: 1806 loss: 5.91934338e-07
Iter: 1807 loss: 5.91893e-07
Iter: 1808 loss: 5.9190063e-07
Iter: 1809 loss: 5.91878234e-07
Iter: 1810 loss: 5.91838955e-07
Iter: 1811 loss: 5.91826392e-07
Iter: 1812 loss: 5.9177512e-07
Iter: 1813 loss: 5.91720664e-07
Iter: 1814 loss: 5.92049673e-07
Iter: 1815 loss: 5.91743174e-07
Iter: 1816 loss: 5.91649837e-07
Iter: 1817 loss: 5.92163076e-07
Iter: 1818 loss: 5.91639946e-07
Iter: 1819 loss: 5.91618743e-07
Iter: 1820 loss: 5.9159e-07
Iter: 1821 loss: 5.91564913e-07
Iter: 1822 loss: 5.91564117e-07
Iter: 1823 loss: 5.91563207e-07
Iter: 1824 loss: 5.91545074e-07
Iter: 1825 loss: 5.9152012e-07
Iter: 1826 loss: 5.91529727e-07
Iter: 1827 loss: 5.91482944e-07
Iter: 1828 loss: 5.91716116e-07
Iter: 1829 loss: 5.91473395e-07
Iter: 1830 loss: 5.91451e-07
Iter: 1831 loss: 5.91592766e-07
Iter: 1832 loss: 5.91445882e-07
Iter: 1833 loss: 5.91431103e-07
Iter: 1834 loss: 5.91412402e-07
Iter: 1835 loss: 5.91402e-07
Iter: 1836 loss: 5.91357207e-07
Iter: 1837 loss: 5.91542744e-07
Iter: 1838 loss: 5.91352546e-07
Iter: 1839 loss: 5.91303149e-07
Iter: 1840 loss: 5.91535809e-07
Iter: 1841 loss: 5.91315882e-07
Iter: 1842 loss: 5.91288313e-07
Iter: 1843 loss: 5.9128746e-07
Iter: 1844 loss: 5.91262904e-07
Iter: 1845 loss: 5.91227831e-07
Iter: 1846 loss: 5.91203e-07
Iter: 1847 loss: 5.91200205e-07
Iter: 1848 loss: 5.91148762e-07
Iter: 1849 loss: 5.91163371e-07
Iter: 1850 loss: 5.91144726e-07
Iter: 1851 loss: 5.9112574e-07
Iter: 1852 loss: 5.91130402e-07
Iter: 1853 loss: 5.91105959e-07
Iter: 1854 loss: 5.91189519e-07
Iter: 1855 loss: 5.91109938e-07
Iter: 1856 loss: 5.91052356e-07
Iter: 1857 loss: 5.91153196e-07
Iter: 1858 loss: 5.91054913e-07
Iter: 1859 loss: 5.9103877e-07
Iter: 1860 loss: 5.9102689e-07
Iter: 1861 loss: 5.910249e-07
Iter: 1862 loss: 5.90967772e-07
Iter: 1863 loss: 5.91432581e-07
Iter: 1864 loss: 5.90961918e-07
Iter: 1865 loss: 5.90921729e-07
Iter: 1866 loss: 5.9087796e-07
Iter: 1867 loss: 5.90895e-07
Iter: 1868 loss: 5.90844934e-07
Iter: 1869 loss: 5.91053436e-07
Iter: 1870 loss: 5.90831064e-07
Iter: 1871 loss: 5.90796162e-07
Iter: 1872 loss: 5.90818559e-07
Iter: 1873 loss: 5.90790705e-07
Iter: 1874 loss: 5.9075785e-07
Iter: 1875 loss: 5.90743184e-07
Iter: 1876 loss: 5.9070203e-07
Iter: 1877 loss: 5.90834418e-07
Iter: 1878 loss: 5.90707486e-07
Iter: 1879 loss: 5.90707145e-07
Iter: 1880 loss: 5.90875743e-07
Iter: 1881 loss: 5.9068509e-07
Iter: 1882 loss: 5.90654793e-07
Iter: 1883 loss: 5.90698278e-07
Iter: 1884 loss: 5.90654849e-07
Iter: 1885 loss: 5.90631203e-07
Iter: 1886 loss: 5.90640809e-07
Iter: 1887 loss: 5.90609204e-07
Iter: 1888 loss: 5.90577031e-07
Iter: 1889 loss: 5.9059613e-07
Iter: 1890 loss: 5.905747e-07
Iter: 1891 loss: 5.90551679e-07
Iter: 1892 loss: 5.91135e-07
Iter: 1893 loss: 5.90535876e-07
Iter: 1894 loss: 5.90525133e-07
Iter: 1895 loss: 5.90829245e-07
Iter: 1896 loss: 5.90530817e-07
Iter: 1897 loss: 5.90498303e-07
Iter: 1898 loss: 5.90506602e-07
Iter: 1899 loss: 5.90494096e-07
Iter: 1900 loss: 5.90489492e-07
Iter: 1901 loss: 5.90455215e-07
Iter: 1902 loss: 5.90442596e-07
Iter: 1903 loss: 5.90418551e-07
Iter: 1904 loss: 5.90608806e-07
Iter: 1905 loss: 5.90420427e-07
Iter: 1906 loss: 5.90389e-07
Iter: 1907 loss: 5.90536843e-07
Iter: 1908 loss: 5.9040724e-07
Iter: 1909 loss: 5.9036563e-07
Iter: 1910 loss: 5.90352784e-07
Iter: 1911 loss: 5.90320724e-07
Iter: 1912 loss: 5.90316347e-07
Iter: 1913 loss: 5.90424747e-07
Iter: 1914 loss: 5.90293553e-07
Iter: 1915 loss: 5.90259674e-07
Iter: 1916 loss: 5.9068384e-07
Iter: 1917 loss: 5.90273771e-07
Iter: 1918 loss: 5.90244838e-07
Iter: 1919 loss: 5.90227671e-07
Iter: 1920 loss: 5.90228e-07
Iter: 1921 loss: 5.90197601e-07
Iter: 1922 loss: 5.90472609e-07
Iter: 1923 loss: 5.90203854e-07
Iter: 1924 loss: 5.90161221e-07
Iter: 1925 loss: 5.90181685e-07
Iter: 1926 loss: 5.90149511e-07
Iter: 1927 loss: 5.90111199e-07
Iter: 1928 loss: 5.90217e-07
Iter: 1929 loss: 5.90117338e-07
Iter: 1930 loss: 5.90099944e-07
Iter: 1931 loss: 5.90181116e-07
Iter: 1932 loss: 5.90088689e-07
Iter: 1933 loss: 5.90062029e-07
Iter: 1934 loss: 5.90027071e-07
Iter: 1935 loss: 5.90606703e-07
Iter: 1936 loss: 5.90038098e-07
Iter: 1937 loss: 5.89992453e-07
Iter: 1938 loss: 5.90129275e-07
Iter: 1939 loss: 5.89997057e-07
Iter: 1940 loss: 5.89979777e-07
Iter: 1941 loss: 5.89955334e-07
Iter: 1942 loss: 5.8995812e-07
Iter: 1943 loss: 5.89973183e-07
Iter: 1944 loss: 5.89966703e-07
Iter: 1945 loss: 5.89959768e-07
Iter: 1946 loss: 5.89970909e-07
Iter: 1947 loss: 5.89948172e-07
Iter: 1948 loss: 5.89970341e-07
Iter: 1949 loss: 5.8996244e-07
Iter: 1950 loss: 5.89945444e-07
Iter: 1951 loss: 5.89959143e-07
Iter: 1952 loss: 5.89955221e-07
Iter: 1953 loss: 5.89961758e-07
Iter: 1954 loss: 5.89955221e-07
Iter: 1955 loss: 5.89955562e-07
Iter: 1956 loss: 5.8996045e-07
Iter: 1957 loss: 5.89954539e-07
Iter: 1958 loss: 5.89959313e-07
Iter: 1959 loss: 5.89956471e-07
Iter: 1960 loss: 5.89956244e-07
Iter: 1961 loss: 5.89955903e-07
Iter: 1962 loss: 5.8995613e-07
Iter: 1963 loss: 5.8995613e-07
Iter: 1964 loss: 5.89956e-07
Iter: 1965 loss: 5.89955903e-07
Iter: 1966 loss: 5.89956073e-07
Iter: 1967 loss: 5.89955903e-07
Iter: 1968 loss: 5.89956073e-07
Iter: 1969 loss: 5.89955903e-07
Iter: 1970 loss: 5.89956073e-07
Iter: 1971 loss: 5.89955903e-07
Iter: 1972 loss: 5.89928732e-07
Iter: 1973 loss: 5.89891044e-07
Iter: 1974 loss: 5.89869614e-07
Iter: 1975 loss: 5.89868705e-07
Iter: 1976 loss: 5.89850458e-07
Iter: 1977 loss: 5.89891954e-07
Iter: 1978 loss: 5.8982846e-07
Iter: 1979 loss: 5.89830563e-07
Iter: 1980 loss: 5.89826868e-07
Iter: 1981 loss: 5.8983062e-07
Iter: 1982 loss: 5.89832325e-07
Iter: 1983 loss: 5.89837441e-07
Iter: 1984 loss: 5.89837327e-07
Iter: 1985 loss: 5.89821809e-07
Iter: 1986 loss: 5.89839942e-07
Iter: 1987 loss: 5.8984233e-07
Iter: 1988 loss: 5.89829938e-07
Iter: 1989 loss: 5.89828232e-07
Iter: 1990 loss: 5.89828e-07
Iter: 1991 loss: 5.89817773e-07
Iter: 1992 loss: 5.89828346e-07
Iter: 1993 loss: 5.89826698e-07
Iter: 1994 loss: 5.89827e-07
Iter: 1995 loss: 5.89827e-07
Iter: 1996 loss: 5.89827266e-07
Iter: 1997 loss: 5.89827209e-07
Iter: 1998 loss: 5.89828e-07
Iter: 1999 loss: 5.89829824e-07
Iter: 2000 loss: 5.89830222e-07
Iter: 2001 loss: 5.89828119e-07
Iter: 2002 loss: 5.89830165e-07
Iter: 2003 loss: 5.89830279e-07
Iter: 2004 loss: 5.89828119e-07
Iter: 2005 loss: 5.89781166e-07
Iter: 2006 loss: 5.90253762e-07
Iter: 2007 loss: 5.8978452e-07
Iter: 2008 loss: 5.89751608e-07
Iter: 2009 loss: 5.89916567e-07
Iter: 2010 loss: 5.89775425e-07
Iter: 2011 loss: 5.89739102e-07
Iter: 2012 loss: 5.89744559e-07
Iter: 2013 loss: 5.8971591e-07
Iter: 2014 loss: 5.8970943e-07
Iter: 2015 loss: 5.89732849e-07
Iter: 2016 loss: 5.8968169e-07
Iter: 2017 loss: 5.89650654e-07
Iter: 2018 loss: 5.8981459e-07
Iter: 2019 loss: 5.89635533e-07
Iter: 2020 loss: 5.89636102e-07
Iter: 2021 loss: 5.89573915e-07
Iter: 2022 loss: 5.89604838e-07
Iter: 2023 loss: 5.89557885e-07
Iter: 2024 loss: 5.89910087e-07
Iter: 2025 loss: 5.89554702e-07
Iter: 2026 loss: 5.89529122e-07
Iter: 2027 loss: 5.89579599e-07
Iter: 2028 loss: 5.89502861e-07
Iter: 2029 loss: 5.8950593e-07
Iter: 2030 loss: 5.89500814e-07
Iter: 2031 loss: 5.89490469e-07
Iter: 2032 loss: 5.89480578e-07
Iter: 2033 loss: 5.89483193e-07
Iter: 2034 loss: 5.89499905e-07
Iter: 2035 loss: 5.89491947e-07
Iter: 2036 loss: 5.89496494e-07
Iter: 2037 loss: 5.89498939e-07
Iter: 2038 loss: 5.8950053e-07
Iter: 2039 loss: 5.89499336e-07
Iter: 2040 loss: 5.89499336e-07
Iter: 2041 loss: 5.89501269e-07
Iter: 2042 loss: 5.8950377e-07
Iter: 2043 loss: 5.89499905e-07
Iter: 2044 loss: 5.8950161e-07
Iter: 2045 loss: 5.89506271e-07
Iter: 2046 loss: 5.89504e-07
Iter: 2047 loss: 5.8950252e-07
Iter: 2048 loss: 5.89503315e-07
Iter: 2049 loss: 5.89503884e-07
Iter: 2050 loss: 5.89503429e-07
Iter: 2051 loss: 5.89503315e-07
Iter: 2052 loss: 5.89503713e-07
Iter: 2053 loss: 5.89503657e-07
Iter: 2054 loss: 5.89503315e-07
Iter: 2055 loss: 5.89411229e-07
Iter: 2056 loss: 5.90126774e-07
Iter: 2057 loss: 5.89413617e-07
Iter: 2058 loss: 5.89405317e-07
Iter: 2059 loss: 5.89395e-07
Iter: 2060 loss: 5.89363367e-07
Iter: 2061 loss: 5.89339834e-07
Iter: 2062 loss: 5.8935484e-07
Iter: 2063 loss: 5.89306751e-07
Iter: 2064 loss: 5.8942021e-07
Iter: 2065 loss: 5.89307149e-07
Iter: 2066 loss: 5.89293336e-07
Iter: 2067 loss: 5.89299418e-07
Iter: 2068 loss: 5.89275771e-07
Iter: 2069 loss: 5.89293109e-07
Iter: 2070 loss: 5.89238311e-07
Iter: 2071 loss: 5.8923672e-07
Iter: 2072 loss: 5.89219781e-07
Iter: 2073 loss: 5.89228534e-07
Iter: 2074 loss: 5.89199885e-07
Iter: 2075 loss: 5.89199601e-07
Iter: 2076 loss: 5.89193e-07
Iter: 2077 loss: 5.89223703e-07
Iter: 2078 loss: 5.89163506e-07
Iter: 2079 loss: 5.89169645e-07
Iter: 2080 loss: 5.89156912e-07
Iter: 2081 loss: 5.8917e-07
Iter: 2082 loss: 5.891456e-07
Iter: 2083 loss: 5.89166575e-07
Iter: 2084 loss: 5.89166063e-07
Iter: 2085 loss: 5.89161914e-07
Iter: 2086 loss: 5.89155604e-07
Iter: 2087 loss: 5.89167257e-07
Iter: 2088 loss: 5.89152705e-07
Iter: 2089 loss: 5.89159413e-07
Iter: 2090 loss: 5.89147362e-07
Iter: 2091 loss: 5.89162141e-07
Iter: 2092 loss: 5.89163619e-07
Iter: 2093 loss: 5.89161061e-07
Iter: 2094 loss: 5.89168792e-07
Iter: 2095 loss: 5.89168394e-07
Iter: 2096 loss: 5.89165666e-07
Iter: 2097 loss: 5.89161232e-07
Iter: 2098 loss: 5.89162255e-07
Iter: 2099 loss: 5.89166575e-07
Iter: 2100 loss: 5.89166348e-07
Iter: 2101 loss: 5.89162426e-07
Iter: 2102 loss: 5.89162426e-07
Iter: 2103 loss: 5.89166461e-07
Iter: 2104 loss: 5.89162426e-07
Iter: 2105 loss: 5.89117803e-07
Iter: 2106 loss: 5.89116553e-07
Iter: 2107 loss: 5.8908762e-07
Iter: 2108 loss: 5.89107117e-07
Iter: 2109 loss: 5.89077445e-07
Iter: 2110 loss: 5.89031117e-07
Iter: 2111 loss: 5.89488877e-07
Iter: 2112 loss: 5.89024467e-07
Iter: 2113 loss: 5.88989678e-07
Iter: 2114 loss: 5.89206707e-07
Iter: 2115 loss: 5.88963871e-07
Iter: 2116 loss: 5.8895057e-07
Iter: 2117 loss: 5.89345859e-07
Iter: 2118 loss: 5.88945909e-07
Iter: 2119 loss: 5.88954322e-07
Iter: 2120 loss: 5.8893977e-07
Iter: 2121 loss: 5.88957846e-07
Iter: 2122 loss: 5.88945113e-07
Iter: 2123 loss: 5.88944033e-07
Iter: 2124 loss: 5.88940566e-07
Iter: 2125 loss: 5.88953412e-07
Iter: 2126 loss: 5.88949945e-07
Iter: 2127 loss: 5.88943635e-07
Iter: 2128 loss: 5.88951139e-07
Iter: 2129 loss: 5.88947387e-07
Iter: 2130 loss: 5.88948296e-07
Iter: 2131 loss: 5.88944e-07
Iter: 2132 loss: 5.88940679e-07
Iter: 2133 loss: 5.88946364e-07
Iter: 2134 loss: 5.88946193e-07
Iter: 2135 loss: 5.8894517e-07
Iter: 2136 loss: 5.88945227e-07
Iter: 2137 loss: 5.88948296e-07
Iter: 2138 loss: 5.88946477e-07
Iter: 2139 loss: 5.88948069e-07
Iter: 2140 loss: 5.88948183e-07
Iter: 2141 loss: 5.88948126e-07
Iter: 2142 loss: 5.88948183e-07
Iter: 2143 loss: 5.88946477e-07
Iter: 2144 loss: 5.88948183e-07
Iter: 2145 loss: 5.88918056e-07
Iter: 2146 loss: 5.88910154e-07
Iter: 2147 loss: 5.88884234e-07
Iter: 2148 loss: 5.88881278e-07
Iter: 2149 loss: 5.88863486e-07
Iter: 2150 loss: 5.88840521e-07
Iter: 2151 loss: 5.89246724e-07
Iter: 2152 loss: 5.88839498e-07
Iter: 2153 loss: 5.88833757e-07
Iter: 2154 loss: 5.88859393e-07
Iter: 2155 loss: 5.88828129e-07
Iter: 2156 loss: 5.888038e-07
Iter: 2157 loss: 5.88795842e-07
Iter: 2158 loss: 5.8875e-07
Iter: 2159 loss: 5.88728483e-07
Iter: 2160 loss: 5.89113654e-07
Iter: 2161 loss: 5.88733428e-07
Iter: 2162 loss: 5.88697276e-07
Iter: 2163 loss: 5.888283e-07
Iter: 2164 loss: 5.88689602e-07
Iter: 2165 loss: 5.88664307e-07
Iter: 2166 loss: 5.88655269e-07
Iter: 2167 loss: 5.8865794e-07
Iter: 2168 loss: 5.88641e-07
Iter: 2169 loss: 5.88876048e-07
Iter: 2170 loss: 5.88655439e-07
Iter: 2171 loss: 5.88614512e-07
Iter: 2172 loss: 5.88607691e-07
Iter: 2173 loss: 5.89301237e-07
Iter: 2174 loss: 5.88590751e-07
Iter: 2175 loss: 5.88557555e-07
Iter: 2176 loss: 5.88566195e-07
Iter: 2177 loss: 5.88555736e-07
Iter: 2178 loss: 5.88502701e-07
Iter: 2179 loss: 5.88513672e-07
Iter: 2180 loss: 5.88488035e-07
Iter: 2181 loss: 5.88671e-07
Iter: 2182 loss: 5.88486841e-07
Iter: 2183 loss: 5.88448302e-07
Iter: 2184 loss: 5.88786861e-07
Iter: 2185 loss: 5.8845967e-07
Iter: 2186 loss: 5.88432783e-07
Iter: 2187 loss: 5.8838873e-07
Iter: 2188 loss: 5.89095e-07
Iter: 2189 loss: 5.88399132e-07
Iter: 2190 loss: 5.88345472e-07
Iter: 2191 loss: 5.88573471e-07
Iter: 2192 loss: 5.88307671e-07
Iter: 2193 loss: 5.88320404e-07
Iter: 2194 loss: 5.88314037e-07
Iter: 2195 loss: 5.88328e-07
Iter: 2196 loss: 5.8830841e-07
Iter: 2197 loss: 5.88305511e-07
Iter: 2198 loss: 5.88317619e-07
Iter: 2199 loss: 5.88307557e-07
Iter: 2200 loss: 5.88310627e-07
Iter: 2201 loss: 5.88313696e-07
Iter: 2202 loss: 5.88322223e-07
Iter: 2203 loss: 5.8831597e-07
Iter: 2204 loss: 5.88320631e-07
Iter: 2205 loss: 5.88314151e-07
Iter: 2206 loss: 5.88301702e-07
Iter: 2207 loss: 5.88314151e-07
Iter: 2208 loss: 5.88309149e-07
Iter: 2209 loss: 5.88304374e-07
Iter: 2210 loss: 5.88309604e-07
Iter: 2211 loss: 5.88304033e-07
Iter: 2212 loss: 5.88306364e-07
Iter: 2213 loss: 5.88308694e-07
Iter: 2214 loss: 5.88305852e-07
Iter: 2215 loss: 5.88305966e-07
Iter: 2216 loss: 5.8830642e-07
Iter: 2217 loss: 5.88308183e-07
Iter: 2218 loss: 5.88308865e-07
Iter: 2219 loss: 5.88308865e-07
Iter: 2220 loss: 5.88308808e-07
Iter: 2221 loss: 5.88308183e-07
Iter: 2222 loss: 5.88290902e-07
Iter: 2223 loss: 5.88292551e-07
Iter: 2224 loss: 5.88290618e-07
Iter: 2225 loss: 5.88259297e-07
Iter: 2226 loss: 5.88257194e-07
Iter: 2227 loss: 5.88250032e-07
Iter: 2228 loss: 5.88259525e-07
Iter: 2229 loss: 5.88225191e-07
Iter: 2230 loss: 5.8821945e-07
Iter: 2231 loss: 5.88215357e-07
Iter: 2232 loss: 5.88171758e-07
Iter: 2233 loss: 5.88451485e-07
Iter: 2234 loss: 5.88189494e-07
Iter: 2235 loss: 5.88160958e-07
Iter: 2236 loss: 5.88171872e-07
Iter: 2237 loss: 5.88159708e-07
Iter: 2238 loss: 5.88113153e-07
Iter: 2239 loss: 5.88219109e-07
Iter: 2240 loss: 5.88124408e-07
Iter: 2241 loss: 5.8809178e-07
Iter: 2242 loss: 5.88158628e-07
Iter: 2243 loss: 5.88081093e-07
Iter: 2244 loss: 5.88060175e-07
Iter: 2245 loss: 5.88120372e-07
Iter: 2246 loss: 5.8802317e-07
Iter: 2247 loss: 5.88006969e-07
Iter: 2248 loss: 5.87979343e-07
Iter: 2249 loss: 5.87989064e-07
Iter: 2250 loss: 5.87944953e-07
Iter: 2251 loss: 5.88023795e-07
Iter: 2252 loss: 5.87917839e-07
Iter: 2253 loss: 5.87897375e-07
Iter: 2254 loss: 5.88108378e-07
Iter: 2255 loss: 5.87889531e-07
Iter: 2256 loss: 5.87835643e-07
Iter: 2257 loss: 5.87908971e-07
Iter: 2258 loss: 5.87838542e-07
Iter: 2259 loss: 5.87810234e-07
Iter: 2260 loss: 5.88177954e-07
Iter: 2261 loss: 5.8780779e-07
Iter: 2262 loss: 5.87778572e-07
Iter: 2263 loss: 5.87722809e-07
Iter: 2264 loss: 5.87709394e-07
Iter: 2265 loss: 5.87695069e-07
Iter: 2266 loss: 5.87825411e-07
Iter: 2267 loss: 5.87694444e-07
Iter: 2268 loss: 5.87660452e-07
Iter: 2269 loss: 5.87834847e-07
Iter: 2270 loss: 5.87671423e-07
Iter: 2271 loss: 5.8761168e-07
Iter: 2272 loss: 5.87673128e-07
Iter: 2273 loss: 5.87632599e-07
Iter: 2274 loss: 5.87599629e-07
Iter: 2275 loss: 5.87561203e-07
Iter: 2276 loss: 5.87575187e-07
Iter: 2277 loss: 5.87518628e-07
Iter: 2278 loss: 5.87711952e-07
Iter: 2279 loss: 5.87519594e-07
Iter: 2280 loss: 5.87503678e-07
Iter: 2281 loss: 5.87496515e-07
Iter: 2282 loss: 5.87478e-07
Iter: 2283 loss: 5.87456e-07
Iter: 2284 loss: 5.87749128e-07
Iter: 2285 loss: 5.87442514e-07
Iter: 2286 loss: 5.87435693e-07
Iter: 2287 loss: 5.87415684e-07
Iter: 2288 loss: 5.87401075e-07
Iter: 2289 loss: 5.87355544e-07
Iter: 2290 loss: 5.87383965e-07
Iter: 2291 loss: 5.87324735e-07
Iter: 2292 loss: 5.87428758e-07
Iter: 2293 loss: 5.87328486e-07
Iter: 2294 loss: 5.87268801e-07
Iter: 2295 loss: 5.87610316e-07
Iter: 2296 loss: 5.87288127e-07
Iter: 2297 loss: 5.87238389e-07
Iter: 2298 loss: 5.87250838e-07
Iter: 2299 loss: 5.87224235e-07
Iter: 2300 loss: 5.87178e-07
Iter: 2301 loss: 5.87165573e-07
Iter: 2302 loss: 5.8715807e-07
Iter: 2303 loss: 5.87146e-07
Iter: 2304 loss: 5.87147269e-07
Iter: 2305 loss: 5.87104125e-07
Iter: 2306 loss: 5.87105319e-07
Iter: 2307 loss: 5.87091336e-07
Iter: 2308 loss: 5.87065756e-07
Iter: 2309 loss: 5.87001466e-07
Iter: 2310 loss: 5.87005843e-07
Iter: 2311 loss: 5.86988108e-07
Iter: 2312 loss: 5.86981287e-07
Iter: 2313 loss: 5.86964632e-07
Iter: 2314 loss: 5.86996066e-07
Iter: 2315 loss: 5.86931947e-07
Iter: 2316 loss: 5.86907277e-07
Iter: 2317 loss: 5.86912392e-07
Iter: 2318 loss: 5.86896931e-07
Iter: 2319 loss: 5.86869419e-07
Iter: 2320 loss: 5.87165118e-07
Iter: 2321 loss: 5.86861518e-07
Iter: 2322 loss: 5.8684293e-07
Iter: 2323 loss: 5.86848842e-07
Iter: 2324 loss: 5.86841395e-07
Iter: 2325 loss: 5.86822409e-07
Iter: 2326 loss: 5.86793703e-07
Iter: 2327 loss: 5.86785291e-07
Iter: 2328 loss: 5.867455e-07
Iter: 2329 loss: 5.87187856e-07
Iter: 2330 loss: 5.86763917e-07
Iter: 2331 loss: 5.86716851e-07
Iter: 2332 loss: 5.8683861e-07
Iter: 2333 loss: 5.86724241e-07
Iter: 2334 loss: 5.86706051e-07
Iter: 2335 loss: 5.86683541e-07
Iter: 2336 loss: 5.87289151e-07
Iter: 2337 loss: 5.86663873e-07
Iter: 2338 loss: 5.86606234e-07
Iter: 2339 loss: 5.86844124e-07
Iter: 2340 loss: 5.86591455e-07
Iter: 2341 loss: 5.86574401e-07
Iter: 2342 loss: 5.86582473e-07
Iter: 2343 loss: 5.86541944e-07
Iter: 2344 loss: 5.86549845e-07
Iter: 2345 loss: 5.86519946e-07
Iter: 2346 loss: 5.86502e-07
Iter: 2347 loss: 5.86617375e-07
Iter: 2348 loss: 5.86508918e-07
Iter: 2349 loss: 5.86484418e-07
Iter: 2350 loss: 5.86536316e-07
Iter: 2351 loss: 5.86495844e-07
Iter: 2352 loss: 5.86447868e-07
Iter: 2353 loss: 5.86448607e-07
Iter: 2354 loss: 5.86422516e-07
Iter: 2355 loss: 5.8640785e-07
Iter: 2356 loss: 5.86405406e-07
Iter: 2357 loss: 5.86380565e-07
Iter: 2358 loss: 5.86373858e-07
Iter: 2359 loss: 5.86367946e-07
Iter: 2360 loss: 5.86325598e-07
Iter: 2361 loss: 5.86319402e-07
Iter: 2362 loss: 5.86287683e-07
Iter: 2363 loss: 5.8631889e-07
Iter: 2364 loss: 5.86272336e-07
Iter: 2365 loss: 5.86265855e-07
Iter: 2366 loss: 5.86255226e-07
Iter: 2367 loss: 5.86247154e-07
Iter: 2368 loss: 5.86204123e-07
Iter: 2369 loss: 5.86166664e-07
Iter: 2370 loss: 5.8616439e-07
Iter: 2371 loss: 5.86132728e-07
Iter: 2372 loss: 5.862384e-07
Iter: 2373 loss: 5.86101862e-07
Iter: 2374 loss: 5.86085207e-07
Iter: 2375 loss: 5.86077135e-07
Iter: 2376 loss: 5.86041665e-07
Iter: 2377 loss: 5.85985561e-07
Iter: 2378 loss: 5.85998805e-07
Iter: 2379 loss: 5.85938665e-07
Iter: 2380 loss: 5.86167516e-07
Iter: 2381 loss: 5.8594e-07
Iter: 2382 loss: 5.8587932e-07
Iter: 2383 loss: 5.8608515e-07
Iter: 2384 loss: 5.85883868e-07
Iter: 2385 loss: 5.85857322e-07
Iter: 2386 loss: 5.85898533e-07
Iter: 2387 loss: 5.85818896e-07
Iter: 2388 loss: 5.85801388e-07
Iter: 2389 loss: 5.85959583e-07
Iter: 2390 loss: 5.85804173e-07
Iter: 2391 loss: 5.85780299e-07
Iter: 2392 loss: 5.85756425e-07
Iter: 2393 loss: 5.85760176e-07
Iter: 2394 loss: 5.85712655e-07
Iter: 2395 loss: 5.85835096e-07
Iter: 2396 loss: 5.85706402e-07
Iter: 2397 loss: 5.85680709e-07
Iter: 2398 loss: 5.85679118e-07
Iter: 2399 loss: 5.85675e-07
Iter: 2400 loss: 5.85619546e-07
Iter: 2401 loss: 5.86195711e-07
Iter: 2402 loss: 5.85607495e-07
Iter: 2403 loss: 5.85585894e-07
Iter: 2404 loss: 5.85724365e-07
Iter: 2405 loss: 5.85564635e-07
Iter: 2406 loss: 5.85558837e-07
Iter: 2407 loss: 5.85764155e-07
Iter: 2408 loss: 5.85561679e-07
Iter: 2409 loss: 5.8553087e-07
Iter: 2410 loss: 5.85827706e-07
Iter: 2411 loss: 5.85505859e-07
Iter: 2412 loss: 5.85512112e-07
Iter: 2413 loss: 5.85516659e-07
Iter: 2414 loss: 5.85523e-07
Iter: 2415 loss: 5.85523e-07
Iter: 2416 loss: 5.85508133e-07
Iter: 2417 loss: 5.85510122e-07
Iter: 2418 loss: 5.85509042e-07
Iter: 2419 loss: 5.85516432e-07
Iter: 2420 loss: 5.85507337e-07
Iter: 2421 loss: 5.8552132e-07
Iter: 2422 loss: 5.8551791e-07
Iter: 2423 loss: 5.85511657e-07
Iter: 2424 loss: 5.85504e-07
Iter: 2425 loss: 5.85507394e-07
Iter: 2426 loss: 5.85507735e-07
Iter: 2427 loss: 5.85505859e-07
Iter: 2428 loss: 5.85506541e-07
Iter: 2429 loss: 5.8550637e-07
Iter: 2430 loss: 5.85506655e-07
Iter: 2431 loss: 5.85506427e-07
Iter: 2432 loss: 5.85506655e-07
Iter: 2433 loss: 5.85506484e-07
Iter: 2434 loss: 5.85506427e-07
Iter: 2435 loss: 5.85506427e-07
Iter: 2436 loss: 5.8550637e-07
Iter: 2437 loss: 5.8550637e-07
Iter: 2438 loss: 5.85506484e-07
Iter: 2439 loss: 5.8550637e-07
Iter: 2440 loss: 5.8550637e-07
Iter: 2441 loss: 5.8550637e-07
Iter: 2442 loss: 5.85506484e-07
Iter: 2443 loss: 5.85506484e-07
Iter: 2444 loss: 5.8550637e-07
Iter: 2445 loss: 5.85506484e-07
Iter: 2446 loss: 5.85506484e-07
Iter: 2447 loss: 5.8550637e-07
Iter: 2448 loss: 5.85506484e-07
Iter: 2449 loss: 5.87204113e-07
Iter: 2450 loss: 5.8552564e-07
Iter: 2451 loss: 5.85526891e-07
Iter: 2452 loss: 5.85528483e-07
Iter: 2453 loss: 5.85526209e-07
Iter: 2454 loss: 5.8550529e-07
Iter: 2455 loss: 5.85512225e-07
Iter: 2456 loss: 5.85528085e-07
Iter: 2457 loss: 5.85507564e-07
Iter: 2458 loss: 5.85512794e-07
Iter: 2459 loss: 5.8550421e-07
Iter: 2460 loss: 5.85511316e-07
Iter: 2461 loss: 5.85508587e-07
Iter: 2462 loss: 5.85504097e-07
Iter: 2463 loss: 5.85506086e-07
Iter: 2464 loss: 5.85503699e-07
Iter: 2465 loss: 5.85502335e-07
Iter: 2466 loss: 5.85506484e-07
Iter: 2467 loss: 5.85508928e-07
Iter: 2468 loss: 5.85507792e-07
Iter: 2469 loss: 5.85506939e-07
Iter: 2470 loss: 5.85506598e-07
Iter: 2471 loss: 5.85506655e-07
Iter: 2472 loss: 5.85507109e-07
Iter: 2473 loss: 5.85507223e-07
Iter: 2474 loss: 5.85507337e-07
Iter: 2475 loss: 5.85507394e-07
Iter: 2476 loss: 5.85507394e-07
Iter: 2477 loss: 5.85507394e-07
Iter: 2478 loss: 5.85506655e-07
Iter: 2479 loss: 5.85507394e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi0.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.2
+ date
Mon Nov  9 05:16:07 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.2/500_500_500_500_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_1000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_1000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f981290ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98128f79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9812974b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9812974488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9812868620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9812974378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98127e5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98127b5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98127b5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98127d80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f981278ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9812723268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f981273e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98126e06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9812701bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9812701a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98126c1e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98126e00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9812723bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f981262a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97be963598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97be90c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97be9056a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97be9638c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97be8e59d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97be8b5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97be847ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97be8b5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97be847e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f979810dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f979811bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f979811b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9798093488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97980a9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97980a9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f97802446a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.9870962e-06
Iter: 2 loss: 2.14576448e-06
Iter: 3 loss: 1.90654009e-06
Iter: 4 loss: 1.52562279e-06
Iter: 5 loss: 2.19000776e-06
Iter: 6 loss: 1.35667869e-06
Iter: 7 loss: 1.19252638e-06
Iter: 8 loss: 2.97109045e-06
Iter: 9 loss: 1.18869332e-06
Iter: 10 loss: 1.07180745e-06
Iter: 11 loss: 1.15689318e-06
Iter: 12 loss: 9.995249e-07
Iter: 13 loss: 9.2402388e-07
Iter: 14 loss: 1.95436451e-06
Iter: 15 loss: 9.23682933e-07
Iter: 16 loss: 8.71696841e-07
Iter: 17 loss: 8.57305395e-07
Iter: 18 loss: 8.25500138e-07
Iter: 19 loss: 7.98879626e-07
Iter: 20 loss: 1.11918575e-06
Iter: 21 loss: 7.98695112e-07
Iter: 22 loss: 7.84617782e-07
Iter: 23 loss: 8.93480717e-07
Iter: 24 loss: 7.83592782e-07
Iter: 25 loss: 7.73361762e-07
Iter: 26 loss: 7.63473963e-07
Iter: 27 loss: 7.61086426e-07
Iter: 28 loss: 7.46725505e-07
Iter: 29 loss: 7.69038138e-07
Iter: 30 loss: 7.3997893e-07
Iter: 31 loss: 7.25898076e-07
Iter: 32 loss: 7.82362804e-07
Iter: 33 loss: 7.22753157e-07
Iter: 34 loss: 7.10255165e-07
Iter: 35 loss: 7.13242116e-07
Iter: 36 loss: 7.01151748e-07
Iter: 37 loss: 6.85688633e-07
Iter: 38 loss: 7.63613684e-07
Iter: 39 loss: 6.83028645e-07
Iter: 40 loss: 6.78910453e-07
Iter: 41 loss: 6.76674063e-07
Iter: 42 loss: 6.70558848e-07
Iter: 43 loss: 6.66987489e-07
Iter: 44 loss: 6.64414927e-07
Iter: 45 loss: 6.56618e-07
Iter: 46 loss: 6.97877795e-07
Iter: 47 loss: 6.5544009e-07
Iter: 48 loss: 6.47089678e-07
Iter: 49 loss: 6.6611193e-07
Iter: 50 loss: 6.44020645e-07
Iter: 51 loss: 6.3958646e-07
Iter: 52 loss: 6.63617584e-07
Iter: 53 loss: 6.38956124e-07
Iter: 54 loss: 6.33493642e-07
Iter: 55 loss: 6.24012614e-07
Iter: 56 loss: 8.63585342e-07
Iter: 57 loss: 6.24022789e-07
Iter: 58 loss: 6.15079898e-07
Iter: 59 loss: 6.32288e-07
Iter: 60 loss: 6.11270707e-07
Iter: 61 loss: 5.99979e-07
Iter: 62 loss: 7.01719557e-07
Iter: 63 loss: 5.99360249e-07
Iter: 64 loss: 5.93395612e-07
Iter: 65 loss: 5.92860317e-07
Iter: 66 loss: 5.88466094e-07
Iter: 67 loss: 5.80997266e-07
Iter: 68 loss: 5.90762795e-07
Iter: 69 loss: 5.7720797e-07
Iter: 70 loss: 5.71846272e-07
Iter: 71 loss: 6.23043434e-07
Iter: 72 loss: 5.71677617e-07
Iter: 73 loss: 5.67880249e-07
Iter: 74 loss: 5.70038196e-07
Iter: 75 loss: 5.65390962e-07
Iter: 76 loss: 5.61912486e-07
Iter: 77 loss: 5.86218164e-07
Iter: 78 loss: 5.61607123e-07
Iter: 79 loss: 5.59435193e-07
Iter: 80 loss: 5.59460375e-07
Iter: 81 loss: 5.57394856e-07
Iter: 82 loss: 5.5624588e-07
Iter: 83 loss: 5.5537123e-07
Iter: 84 loss: 5.53400355e-07
Iter: 85 loss: 5.69774841e-07
Iter: 86 loss: 5.53294115e-07
Iter: 87 loss: 5.51034645e-07
Iter: 88 loss: 5.49381411e-07
Iter: 89 loss: 5.48703611e-07
Iter: 90 loss: 5.46305841e-07
Iter: 91 loss: 5.61692445e-07
Iter: 92 loss: 5.459965e-07
Iter: 93 loss: 5.43654949e-07
Iter: 94 loss: 5.48438663e-07
Iter: 95 loss: 5.42675366e-07
Iter: 96 loss: 5.41066e-07
Iter: 97 loss: 5.40451538e-07
Iter: 98 loss: 5.39567168e-07
Iter: 99 loss: 5.37437927e-07
Iter: 100 loss: 5.63010644e-07
Iter: 101 loss: 5.37387734e-07
Iter: 102 loss: 5.35405889e-07
Iter: 103 loss: 5.34466778e-07
Iter: 104 loss: 5.33533694e-07
Iter: 105 loss: 5.31156672e-07
Iter: 106 loss: 5.27063719e-07
Iter: 107 loss: 5.27063889e-07
Iter: 108 loss: 5.21630113e-07
Iter: 109 loss: 5.45573414e-07
Iter: 110 loss: 5.20591243e-07
Iter: 111 loss: 5.17055469e-07
Iter: 112 loss: 5.53083908e-07
Iter: 113 loss: 5.17064507e-07
Iter: 114 loss: 5.1421955e-07
Iter: 115 loss: 5.18791865e-07
Iter: 116 loss: 5.12839733e-07
Iter: 117 loss: 5.13008e-07
Iter: 118 loss: 5.11839232e-07
Iter: 119 loss: 5.10981579e-07
Iter: 120 loss: 5.09603183e-07
Iter: 121 loss: 5.09517236e-07
Iter: 122 loss: 5.08904748e-07
Iter: 123 loss: 5.08777759e-07
Iter: 124 loss: 5.0812821e-07
Iter: 125 loss: 5.07170739e-07
Iter: 126 loss: 5.07156585e-07
Iter: 127 loss: 5.05903927e-07
Iter: 128 loss: 5.09049187e-07
Iter: 129 loss: 5.05478511e-07
Iter: 130 loss: 5.04361651e-07
Iter: 131 loss: 5.17734e-07
Iter: 132 loss: 5.0432e-07
Iter: 133 loss: 5.03651165e-07
Iter: 134 loss: 5.02386172e-07
Iter: 135 loss: 5.02365538e-07
Iter: 136 loss: 5.00837643e-07
Iter: 137 loss: 5.03566696e-07
Iter: 138 loss: 5.00146e-07
Iter: 139 loss: 4.98770191e-07
Iter: 140 loss: 4.98702718e-07
Iter: 141 loss: 4.97781969e-07
Iter: 142 loss: 4.97441363e-07
Iter: 143 loss: 4.96919142e-07
Iter: 144 loss: 4.95792278e-07
Iter: 145 loss: 4.94357892e-07
Iter: 146 loss: 4.94183553e-07
Iter: 147 loss: 4.92586139e-07
Iter: 148 loss: 5.14023668e-07
Iter: 149 loss: 4.92598588e-07
Iter: 150 loss: 4.91337232e-07
Iter: 151 loss: 4.92988192e-07
Iter: 152 loss: 4.9081433e-07
Iter: 153 loss: 4.89033425e-07
Iter: 154 loss: 5.05950936e-07
Iter: 155 loss: 4.88979708e-07
Iter: 156 loss: 4.88310889e-07
Iter: 157 loss: 4.86891963e-07
Iter: 158 loss: 5.13762416e-07
Iter: 159 loss: 4.86899808e-07
Iter: 160 loss: 4.85477e-07
Iter: 161 loss: 4.85461214e-07
Iter: 162 loss: 4.84786938e-07
Iter: 163 loss: 4.84376415e-07
Iter: 164 loss: 4.84118118e-07
Iter: 165 loss: 4.83076803e-07
Iter: 166 loss: 4.8829952e-07
Iter: 167 loss: 4.8294396e-07
Iter: 168 loss: 4.81969892e-07
Iter: 169 loss: 4.833189e-07
Iter: 170 loss: 4.81540837e-07
Iter: 171 loss: 4.80837912e-07
Iter: 172 loss: 4.83657459e-07
Iter: 173 loss: 4.8064129e-07
Iter: 174 loss: 4.80003393e-07
Iter: 175 loss: 4.80742415e-07
Iter: 176 loss: 4.79483674e-07
Iter: 177 loss: 4.78716629e-07
Iter: 178 loss: 4.78537913e-07
Iter: 179 loss: 4.78009497e-07
Iter: 180 loss: 4.76863704e-07
Iter: 181 loss: 4.83565941e-07
Iter: 182 loss: 4.7671594e-07
Iter: 183 loss: 4.75859935e-07
Iter: 184 loss: 4.76096034e-07
Iter: 185 loss: 4.75258474e-07
Iter: 186 loss: 4.7492756e-07
Iter: 187 loss: 4.74746344e-07
Iter: 188 loss: 4.74218723e-07
Iter: 189 loss: 4.73533333e-07
Iter: 190 loss: 4.73540865e-07
Iter: 191 loss: 4.72733177e-07
Iter: 192 loss: 4.75127365e-07
Iter: 193 loss: 4.72561254e-07
Iter: 194 loss: 4.71583945e-07
Iter: 195 loss: 4.7638045e-07
Iter: 196 loss: 4.71440302e-07
Iter: 197 loss: 4.70887613e-07
Iter: 198 loss: 4.70790724e-07
Iter: 199 loss: 4.70421753e-07
Iter: 200 loss: 4.69685403e-07
Iter: 201 loss: 4.74788692e-07
Iter: 202 loss: 4.69549462e-07
Iter: 203 loss: 4.69034148e-07
Iter: 204 loss: 4.695342e-07
Iter: 205 loss: 4.68795918e-07
Iter: 206 loss: 4.68065736e-07
Iter: 207 loss: 4.69662e-07
Iter: 208 loss: 4.67857319e-07
Iter: 209 loss: 4.67040678e-07
Iter: 210 loss: 4.66527e-07
Iter: 211 loss: 4.66105e-07
Iter: 212 loss: 4.65040102e-07
Iter: 213 loss: 4.65645911e-07
Iter: 214 loss: 4.64361392e-07
Iter: 215 loss: 4.62822e-07
Iter: 216 loss: 4.69925652e-07
Iter: 217 loss: 4.62598763e-07
Iter: 218 loss: 4.61119328e-07
Iter: 219 loss: 4.65597623e-07
Iter: 220 loss: 4.60693229e-07
Iter: 221 loss: 4.60317494e-07
Iter: 222 loss: 4.59989622e-07
Iter: 223 loss: 4.59606042e-07
Iter: 224 loss: 4.586567e-07
Iter: 225 loss: 4.71482167e-07
Iter: 226 loss: 4.58636748e-07
Iter: 227 loss: 4.57930554e-07
Iter: 228 loss: 4.57923846e-07
Iter: 229 loss: 4.57347824e-07
Iter: 230 loss: 4.58369556e-07
Iter: 231 loss: 4.57078642e-07
Iter: 232 loss: 4.56715156e-07
Iter: 233 loss: 4.57205459e-07
Iter: 234 loss: 4.56476585e-07
Iter: 235 loss: 4.55733129e-07
Iter: 236 loss: 4.56152208e-07
Iter: 237 loss: 4.55300324e-07
Iter: 238 loss: 4.54693293e-07
Iter: 239 loss: 4.60689535e-07
Iter: 240 loss: 4.54697954e-07
Iter: 241 loss: 4.54224676e-07
Iter: 242 loss: 4.54687552e-07
Iter: 243 loss: 4.53897712e-07
Iter: 244 loss: 4.53413804e-07
Iter: 245 loss: 4.52991173e-07
Iter: 246 loss: 4.52742398e-07
Iter: 247 loss: 4.51876673e-07
Iter: 248 loss: 4.53165e-07
Iter: 249 loss: 4.51448102e-07
Iter: 250 loss: 4.50545315e-07
Iter: 251 loss: 4.53965413e-07
Iter: 252 loss: 4.50347471e-07
Iter: 253 loss: 4.49579886e-07
Iter: 254 loss: 4.55480034e-07
Iter: 255 loss: 4.49487e-07
Iter: 256 loss: 4.48782941e-07
Iter: 257 loss: 4.55716133e-07
Iter: 258 loss: 4.4870211e-07
Iter: 259 loss: 4.4834303e-07
Iter: 260 loss: 4.47744327e-07
Iter: 261 loss: 4.4775345e-07
Iter: 262 loss: 4.46950082e-07
Iter: 263 loss: 4.54956847e-07
Iter: 264 loss: 4.46922883e-07
Iter: 265 loss: 4.46410183e-07
Iter: 266 loss: 4.46502241e-07
Iter: 267 loss: 4.45958506e-07
Iter: 268 loss: 4.45352441e-07
Iter: 269 loss: 4.4846135e-07
Iter: 270 loss: 4.45258081e-07
Iter: 271 loss: 4.4475388e-07
Iter: 272 loss: 4.45612613e-07
Iter: 273 loss: 4.44483106e-07
Iter: 274 loss: 4.44053768e-07
Iter: 275 loss: 4.46494965e-07
Iter: 276 loss: 4.43996583e-07
Iter: 277 loss: 4.4350918e-07
Iter: 278 loss: 4.43434942e-07
Iter: 279 loss: 4.43093938e-07
Iter: 280 loss: 4.42532212e-07
Iter: 281 loss: 4.43213082e-07
Iter: 282 loss: 4.42243959e-07
Iter: 283 loss: 4.41570762e-07
Iter: 284 loss: 4.42562e-07
Iter: 285 loss: 4.4132554e-07
Iter: 286 loss: 4.40543772e-07
Iter: 287 loss: 4.4127583e-07
Iter: 288 loss: 4.40242019e-07
Iter: 289 loss: 4.3940787e-07
Iter: 290 loss: 4.45074022e-07
Iter: 291 loss: 4.39349975e-07
Iter: 292 loss: 4.3893624e-07
Iter: 293 loss: 4.38968215e-07
Iter: 294 loss: 4.38546152e-07
Iter: 295 loss: 4.38019356e-07
Iter: 296 loss: 4.37898905e-07
Iter: 297 loss: 4.37475762e-07
Iter: 298 loss: 4.37434153e-07
Iter: 299 loss: 4.37089568e-07
Iter: 300 loss: 4.3653904e-07
Iter: 301 loss: 4.3651761e-07
Iter: 302 loss: 4.36196871e-07
Iter: 303 loss: 4.36025203e-07
Iter: 304 loss: 4.35927319e-07
Iter: 305 loss: 4.35454581e-07
Iter: 306 loss: 4.36812428e-07
Iter: 307 loss: 4.35324807e-07
Iter: 308 loss: 4.34824472e-07
Iter: 309 loss: 4.35686417e-07
Iter: 310 loss: 4.3454537e-07
Iter: 311 loss: 4.34002317e-07
Iter: 312 loss: 4.34602669e-07
Iter: 313 loss: 4.33726626e-07
Iter: 314 loss: 4.33079094e-07
Iter: 315 loss: 4.37528456e-07
Iter: 316 loss: 4.33060336e-07
Iter: 317 loss: 4.32517027e-07
Iter: 318 loss: 4.32924935e-07
Iter: 319 loss: 4.32157464e-07
Iter: 320 loss: 4.31538e-07
Iter: 321 loss: 4.30806722e-07
Iter: 322 loss: 4.30744933e-07
Iter: 323 loss: 4.29553126e-07
Iter: 324 loss: 4.33594607e-07
Iter: 325 loss: 4.29297813e-07
Iter: 326 loss: 4.28438284e-07
Iter: 327 loss: 4.33396451e-07
Iter: 328 loss: 4.28366093e-07
Iter: 329 loss: 4.2772615e-07
Iter: 330 loss: 4.30340748e-07
Iter: 331 loss: 4.27601776e-07
Iter: 332 loss: 4.27269242e-07
Iter: 333 loss: 4.27192788e-07
Iter: 334 loss: 4.26989033e-07
Iter: 335 loss: 4.26701291e-07
Iter: 336 loss: 4.266779e-07
Iter: 337 loss: 4.26296594e-07
Iter: 338 loss: 4.30257955e-07
Iter: 339 loss: 4.26323652e-07
Iter: 340 loss: 4.26025821e-07
Iter: 341 loss: 4.25599779e-07
Iter: 342 loss: 4.25581618e-07
Iter: 343 loss: 4.25116241e-07
Iter: 344 loss: 4.2586376e-07
Iter: 345 loss: 4.24894523e-07
Iter: 346 loss: 4.244867e-07
Iter: 347 loss: 4.29810143e-07
Iter: 348 loss: 4.24424144e-07
Iter: 349 loss: 4.24149022e-07
Iter: 350 loss: 4.23894022e-07
Iter: 351 loss: 4.23805716e-07
Iter: 352 loss: 4.23288867e-07
Iter: 353 loss: 4.2354975e-07
Iter: 354 loss: 4.22893e-07
Iter: 355 loss: 4.22346659e-07
Iter: 356 loss: 4.25406569e-07
Iter: 357 loss: 4.22203811e-07
Iter: 358 loss: 4.21721268e-07
Iter: 359 loss: 4.26045403e-07
Iter: 360 loss: 4.21661582e-07
Iter: 361 loss: 4.21158774e-07
Iter: 362 loss: 4.21164941e-07
Iter: 363 loss: 4.20803275e-07
Iter: 364 loss: 4.20172768e-07
Iter: 365 loss: 4.1970668e-07
Iter: 366 loss: 4.19421951e-07
Iter: 367 loss: 4.19000514e-07
Iter: 368 loss: 4.18927812e-07
Iter: 369 loss: 4.18400703e-07
Iter: 370 loss: 4.19311533e-07
Iter: 371 loss: 4.18115746e-07
Iter: 372 loss: 4.17572039e-07
Iter: 373 loss: 4.17140853e-07
Iter: 374 loss: 4.17003434e-07
Iter: 375 loss: 4.16597118e-07
Iter: 376 loss: 4.16604337e-07
Iter: 377 loss: 4.16200919e-07
Iter: 378 loss: 4.16812e-07
Iter: 379 loss: 4.1601163e-07
Iter: 380 loss: 4.15702459e-07
Iter: 381 loss: 4.15264566e-07
Iter: 382 loss: 4.15269852e-07
Iter: 383 loss: 4.14919555e-07
Iter: 384 loss: 4.14952382e-07
Iter: 385 loss: 4.14702185e-07
Iter: 386 loss: 4.14675611e-07
Iter: 387 loss: 4.1445233e-07
Iter: 388 loss: 4.14168937e-07
Iter: 389 loss: 4.13993575e-07
Iter: 390 loss: 4.13829042e-07
Iter: 391 loss: 4.13546019e-07
Iter: 392 loss: 4.17782871e-07
Iter: 393 loss: 4.13553522e-07
Iter: 394 loss: 4.13157579e-07
Iter: 395 loss: 4.13291616e-07
Iter: 396 loss: 4.1283073e-07
Iter: 397 loss: 4.12276279e-07
Iter: 398 loss: 4.12154407e-07
Iter: 399 loss: 4.11809282e-07
Iter: 400 loss: 4.11229678e-07
Iter: 401 loss: 4.17543276e-07
Iter: 402 loss: 4.11198243e-07
Iter: 403 loss: 4.10599966e-07
Iter: 404 loss: 4.13447083e-07
Iter: 405 loss: 4.10479117e-07
Iter: 406 loss: 4.10113699e-07
Iter: 407 loss: 4.0962513e-07
Iter: 408 loss: 4.09611374e-07
Iter: 409 loss: 4.0920321e-07
Iter: 410 loss: 4.16254693e-07
Iter: 411 loss: 4.09184821e-07
Iter: 412 loss: 4.08747951e-07
Iter: 413 loss: 4.10265386e-07
Iter: 414 loss: 4.08619883e-07
Iter: 415 loss: 4.0844219e-07
Iter: 416 loss: 4.07975477e-07
Iter: 417 loss: 4.08003189e-07
Iter: 418 loss: 4.07725679e-07
Iter: 419 loss: 4.07686883e-07
Iter: 420 loss: 4.07374415e-07
Iter: 421 loss: 4.07454905e-07
Iter: 422 loss: 4.07212099e-07
Iter: 423 loss: 4.06844777e-07
Iter: 424 loss: 4.06904235e-07
Iter: 425 loss: 4.06552459e-07
Iter: 426 loss: 4.06157028e-07
Iter: 427 loss: 4.11385258e-07
Iter: 428 loss: 4.06158705e-07
Iter: 429 loss: 4.05830775e-07
Iter: 430 loss: 4.05626935e-07
Iter: 431 loss: 4.05432047e-07
Iter: 432 loss: 4.04946661e-07
Iter: 433 loss: 4.0600608e-07
Iter: 434 loss: 4.04770446e-07
Iter: 435 loss: 4.04328915e-07
Iter: 436 loss: 4.04321725e-07
Iter: 437 loss: 4.03957841e-07
Iter: 438 loss: 4.03512445e-07
Iter: 439 loss: 4.03478879e-07
Iter: 440 loss: 4.0299193e-07
Iter: 441 loss: 4.03527082e-07
Iter: 442 loss: 4.02793091e-07
Iter: 443 loss: 4.02429635e-07
Iter: 444 loss: 4.02448393e-07
Iter: 445 loss: 4.02166449e-07
Iter: 446 loss: 4.01894169e-07
Iter: 447 loss: 4.01822746e-07
Iter: 448 loss: 4.01390338e-07
Iter: 449 loss: 4.01246893e-07
Iter: 450 loss: 4.01022788e-07
Iter: 451 loss: 4.005324e-07
Iter: 452 loss: 4.07904565e-07
Iter: 453 loss: 4.00545304e-07
Iter: 454 loss: 4.00150043e-07
Iter: 455 loss: 4.00072537e-07
Iter: 456 loss: 3.99811086e-07
Iter: 457 loss: 3.9932138e-07
Iter: 458 loss: 3.99973317e-07
Iter: 459 loss: 3.99128339e-07
Iter: 460 loss: 3.98755844e-07
Iter: 461 loss: 3.98717788e-07
Iter: 462 loss: 3.98424675e-07
Iter: 463 loss: 3.98019722e-07
Iter: 464 loss: 3.97957336e-07
Iter: 465 loss: 3.97526406e-07
Iter: 466 loss: 3.99325131e-07
Iter: 467 loss: 3.97430824e-07
Iter: 468 loss: 3.97048581e-07
Iter: 469 loss: 3.9705327e-07
Iter: 470 loss: 3.96789915e-07
Iter: 471 loss: 3.96311208e-07
Iter: 472 loss: 3.96326527e-07
Iter: 473 loss: 3.95928026e-07
Iter: 474 loss: 3.96409e-07
Iter: 475 loss: 3.95739278e-07
Iter: 476 loss: 3.9539492e-07
Iter: 477 loss: 3.95375139e-07
Iter: 478 loss: 3.95126165e-07
Iter: 479 loss: 3.9491519e-07
Iter: 480 loss: 3.9484874e-07
Iter: 481 loss: 3.94447966e-07
Iter: 482 loss: 3.95006452e-07
Iter: 483 loss: 3.94233524e-07
Iter: 484 loss: 3.93949051e-07
Iter: 485 loss: 3.98483166e-07
Iter: 486 loss: 3.93983214e-07
Iter: 487 loss: 3.93675748e-07
Iter: 488 loss: 3.93130108e-07
Iter: 489 loss: 4.0469115e-07
Iter: 490 loss: 3.93142159e-07
Iter: 491 loss: 3.92689088e-07
Iter: 492 loss: 3.95572755e-07
Iter: 493 loss: 3.92607149e-07
Iter: 494 loss: 3.92201e-07
Iter: 495 loss: 3.94720445e-07
Iter: 496 loss: 3.9217332e-07
Iter: 497 loss: 3.91722836e-07
Iter: 498 loss: 3.92187729e-07
Iter: 499 loss: 3.91500294e-07
Iter: 500 loss: 3.91226223e-07
Iter: 501 loss: 3.91874522e-07
Iter: 502 loss: 3.91116288e-07
Iter: 503 loss: 3.90714888e-07
Iter: 504 loss: 3.939046e-07
Iter: 505 loss: 3.90675837e-07
Iter: 506 loss: 3.90430614e-07
Iter: 507 loss: 3.90009575e-07
Iter: 508 loss: 3.90007187e-07
Iter: 509 loss: 3.89440402e-07
Iter: 510 loss: 3.8942602e-07
Iter: 511 loss: 3.8903903e-07
Iter: 512 loss: 3.88529372e-07
Iter: 513 loss: 3.96212101e-07
Iter: 514 loss: 3.88520647e-07
Iter: 515 loss: 3.88075307e-07
Iter: 516 loss: 3.90386e-07
Iter: 517 loss: 3.88005617e-07
Iter: 518 loss: 3.87734531e-07
Iter: 519 loss: 3.87196252e-07
Iter: 520 loss: 3.87177977e-07
Iter: 521 loss: 3.86714248e-07
Iter: 522 loss: 3.8900464e-07
Iter: 523 loss: 3.86629466e-07
Iter: 524 loss: 3.86366764e-07
Iter: 525 loss: 3.86338797e-07
Iter: 526 loss: 3.86189384e-07
Iter: 527 loss: 3.85821778e-07
Iter: 528 loss: 3.92996753e-07
Iter: 529 loss: 3.85823682e-07
Iter: 530 loss: 3.85446526e-07
Iter: 531 loss: 3.86132456e-07
Iter: 532 loss: 3.85209262e-07
Iter: 533 loss: 3.84867803e-07
Iter: 534 loss: 3.88551257e-07
Iter: 535 loss: 3.84839296e-07
Iter: 536 loss: 3.84454836e-07
Iter: 537 loss: 3.84933628e-07
Iter: 538 loss: 3.84201542e-07
Iter: 539 loss: 3.83859287e-07
Iter: 540 loss: 3.84231e-07
Iter: 541 loss: 3.83741423e-07
Iter: 542 loss: 3.83417159e-07
Iter: 543 loss: 3.83468603e-07
Iter: 544 loss: 3.83214115e-07
Iter: 545 loss: 3.82743849e-07
Iter: 546 loss: 3.88785622e-07
Iter: 547 loss: 3.82742513e-07
Iter: 548 loss: 3.8214705e-07
Iter: 549 loss: 3.86170683e-07
Iter: 550 loss: 3.82131645e-07
Iter: 551 loss: 3.81686505e-07
Iter: 552 loss: 3.85838291e-07
Iter: 553 loss: 3.817795e-07
Iter: 554 loss: 3.8146095e-07
Iter: 555 loss: 3.81044259e-07
Iter: 556 loss: 3.88757655e-07
Iter: 557 loss: 3.81041218e-07
Iter: 558 loss: 3.80564614e-07
Iter: 559 loss: 3.82074916e-07
Iter: 560 loss: 3.80330107e-07
Iter: 561 loss: 3.79975802e-07
Iter: 562 loss: 3.84202735e-07
Iter: 563 loss: 3.79994276e-07
Iter: 564 loss: 3.79653642e-07
Iter: 565 loss: 3.80284746e-07
Iter: 566 loss: 3.79505138e-07
Iter: 567 loss: 3.79192215e-07
Iter: 568 loss: 3.79045616e-07
Iter: 569 loss: 3.7893e-07
Iter: 570 loss: 3.78482355e-07
Iter: 571 loss: 3.79915832e-07
Iter: 572 loss: 3.78356475e-07
Iter: 573 loss: 3.78143312e-07
Iter: 574 loss: 3.78085474e-07
Iter: 575 loss: 3.7791375e-07
Iter: 576 loss: 3.77466733e-07
Iter: 577 loss: 3.83498161e-07
Iter: 578 loss: 3.77436578e-07
Iter: 579 loss: 3.77396361e-07
Iter: 580 loss: 3.77177031e-07
Iter: 581 loss: 3.77059337e-07
Iter: 582 loss: 3.76742776e-07
Iter: 583 loss: 3.80853919e-07
Iter: 584 loss: 3.76803541e-07
Iter: 585 loss: 3.76479477e-07
Iter: 586 loss: 3.79893919e-07
Iter: 587 loss: 3.76486184e-07
Iter: 588 loss: 3.76191025e-07
Iter: 589 loss: 3.76189263e-07
Iter: 590 loss: 3.76054572e-07
Iter: 591 loss: 3.7572147e-07
Iter: 592 loss: 3.75417358e-07
Iter: 593 loss: 3.75365289e-07
Iter: 594 loss: 3.75071124e-07
Iter: 595 loss: 3.75634272e-07
Iter: 596 loss: 3.74846763e-07
Iter: 597 loss: 3.74530828e-07
Iter: 598 loss: 3.75354091e-07
Iter: 599 loss: 3.74433057e-07
Iter: 600 loss: 3.74130224e-07
Iter: 601 loss: 3.77323886e-07
Iter: 602 loss: 3.74084664e-07
Iter: 603 loss: 3.73873831e-07
Iter: 604 loss: 3.73722031e-07
Iter: 605 loss: 3.73662829e-07
Iter: 606 loss: 3.73349792e-07
Iter: 607 loss: 3.74791824e-07
Iter: 608 loss: 3.73366731e-07
Iter: 609 loss: 3.73013449e-07
Iter: 610 loss: 3.7373519e-07
Iter: 611 loss: 3.72897375e-07
Iter: 612 loss: 3.72580473e-07
Iter: 613 loss: 3.72480741e-07
Iter: 614 loss: 3.72265049e-07
Iter: 615 loss: 3.72096167e-07
Iter: 616 loss: 3.71989358e-07
Iter: 617 loss: 3.71795295e-07
Iter: 618 loss: 3.71401143e-07
Iter: 619 loss: 3.76318724e-07
Iter: 620 loss: 3.71368913e-07
Iter: 621 loss: 3.71078613e-07
Iter: 622 loss: 3.71048486e-07
Iter: 623 loss: 3.70819976e-07
Iter: 624 loss: 3.70489971e-07
Iter: 625 loss: 3.70484969e-07
Iter: 626 loss: 3.70087491e-07
Iter: 627 loss: 3.70911209e-07
Iter: 628 loss: 3.69908662e-07
Iter: 629 loss: 3.6962831e-07
Iter: 630 loss: 3.70272403e-07
Iter: 631 loss: 3.69497684e-07
Iter: 632 loss: 3.69078123e-07
Iter: 633 loss: 3.70726e-07
Iter: 634 loss: 3.68985553e-07
Iter: 635 loss: 3.68781969e-07
Iter: 636 loss: 3.7005276e-07
Iter: 637 loss: 3.68687779e-07
Iter: 638 loss: 3.68398787e-07
Iter: 639 loss: 3.68114314e-07
Iter: 640 loss: 3.67983603e-07
Iter: 641 loss: 3.67667667e-07
Iter: 642 loss: 3.70940825e-07
Iter: 643 loss: 3.67640553e-07
Iter: 644 loss: 3.67420057e-07
Iter: 645 loss: 3.69449424e-07
Iter: 646 loss: 3.67438815e-07
Iter: 647 loss: 3.67129076e-07
Iter: 648 loss: 3.67494977e-07
Iter: 649 loss: 3.67046567e-07
Iter: 650 loss: 3.66865862e-07
Iter: 651 loss: 3.68401516e-07
Iter: 652 loss: 3.66851793e-07
Iter: 653 loss: 3.66603416e-07
Iter: 654 loss: 3.66351685e-07
Iter: 655 loss: 3.66377662e-07
Iter: 656 loss: 3.66043651e-07
Iter: 657 loss: 3.6658e-07
Iter: 658 loss: 3.6591436e-07
Iter: 659 loss: 3.65698497e-07
Iter: 660 loss: 3.65712708e-07
Iter: 661 loss: 3.65518844e-07
Iter: 662 loss: 3.65198048e-07
Iter: 663 loss: 3.65225247e-07
Iter: 664 loss: 3.64830242e-07
Iter: 665 loss: 3.64488557e-07
Iter: 666 loss: 3.64375552e-07
Iter: 667 loss: 3.63768947e-07
Iter: 668 loss: 3.71487744e-07
Iter: 669 loss: 3.63820362e-07
Iter: 670 loss: 3.63362602e-07
Iter: 671 loss: 3.65647679e-07
Iter: 672 loss: 3.63323636e-07
Iter: 673 loss: 3.62941279e-07
Iter: 674 loss: 3.62669397e-07
Iter: 675 loss: 3.62529079e-07
Iter: 676 loss: 3.62041135e-07
Iter: 677 loss: 3.64774024e-07
Iter: 678 loss: 3.61981449e-07
Iter: 679 loss: 3.61629077e-07
Iter: 680 loss: 3.64809523e-07
Iter: 681 loss: 3.61582835e-07
Iter: 682 loss: 3.61363163e-07
Iter: 683 loss: 3.61787869e-07
Iter: 684 loss: 3.61187659e-07
Iter: 685 loss: 3.60984842e-07
Iter: 686 loss: 3.6098578e-07
Iter: 687 loss: 3.60891818e-07
Iter: 688 loss: 3.60594214e-07
Iter: 689 loss: 3.65717199e-07
Iter: 690 loss: 3.60555902e-07
Iter: 691 loss: 3.60317642e-07
Iter: 692 loss: 3.61574223e-07
Iter: 693 loss: 3.6031156e-07
Iter: 694 loss: 3.60045476e-07
Iter: 695 loss: 3.62477067e-07
Iter: 696 loss: 3.60038797e-07
Iter: 697 loss: 3.59877077e-07
Iter: 698 loss: 3.59556282e-07
Iter: 699 loss: 3.6682826e-07
Iter: 700 loss: 3.59534226e-07
Iter: 701 loss: 3.59211157e-07
Iter: 702 loss: 3.59300145e-07
Iter: 703 loss: 3.59025336e-07
Iter: 704 loss: 3.58712526e-07
Iter: 705 loss: 3.62890034e-07
Iter: 706 loss: 3.58738617e-07
Iter: 707 loss: 3.58434363e-07
Iter: 708 loss: 3.58995891e-07
Iter: 709 loss: 3.58281454e-07
Iter: 710 loss: 3.57989e-07
Iter: 711 loss: 3.58380703e-07
Iter: 712 loss: 3.57775946e-07
Iter: 713 loss: 3.5753709e-07
Iter: 714 loss: 3.58861655e-07
Iter: 715 loss: 3.57473311e-07
Iter: 716 loss: 3.57166641e-07
Iter: 717 loss: 3.58272189e-07
Iter: 718 loss: 3.57061822e-07
Iter: 719 loss: 3.5681856e-07
Iter: 720 loss: 3.57663879e-07
Iter: 721 loss: 3.56765923e-07
Iter: 722 loss: 3.56480143e-07
Iter: 723 loss: 3.57246904e-07
Iter: 724 loss: 3.56370151e-07
Iter: 725 loss: 3.56104948e-07
Iter: 726 loss: 3.55648524e-07
Iter: 727 loss: 3.5563869e-07
Iter: 728 loss: 3.55333867e-07
Iter: 729 loss: 3.60621129e-07
Iter: 730 loss: 3.55337477e-07
Iter: 731 loss: 3.54994853e-07
Iter: 732 loss: 3.55376528e-07
Iter: 733 loss: 3.54758043e-07
Iter: 734 loss: 3.54438328e-07
Iter: 735 loss: 3.54420649e-07
Iter: 736 loss: 3.5420058e-07
Iter: 737 loss: 3.53902635e-07
Iter: 738 loss: 3.55163621e-07
Iter: 739 loss: 3.53833599e-07
Iter: 740 loss: 3.53621374e-07
Iter: 741 loss: 3.53629275e-07
Iter: 742 loss: 3.5349845e-07
Iter: 743 loss: 3.53413526e-07
Iter: 744 loss: 3.53298816e-07
Iter: 745 loss: 3.53181974e-07
Iter: 746 loss: 3.54028117e-07
Iter: 747 loss: 3.53125074e-07
Iter: 748 loss: 3.53095629e-07
Iter: 749 loss: 3.53606055e-07
Iter: 750 loss: 3.53000473e-07
Iter: 751 loss: 3.52862742e-07
Iter: 752 loss: 3.52942408e-07
Iter: 753 loss: 3.52792256e-07
Iter: 754 loss: 3.52601404e-07
Iter: 755 loss: 3.53604207e-07
Iter: 756 loss: 3.52545641e-07
Iter: 757 loss: 3.5242e-07
Iter: 758 loss: 3.52227346e-07
Iter: 759 loss: 3.52232234e-07
Iter: 760 loss: 3.51922893e-07
Iter: 761 loss: 3.51973398e-07
Iter: 762 loss: 3.51752931e-07
Iter: 763 loss: 3.51464166e-07
Iter: 764 loss: 3.51444072e-07
Iter: 765 loss: 3.51257711e-07
Iter: 766 loss: 3.50938848e-07
Iter: 767 loss: 3.5825957e-07
Iter: 768 loss: 3.50972215e-07
Iter: 769 loss: 3.50573259e-07
Iter: 770 loss: 3.51208286e-07
Iter: 771 loss: 3.5042865e-07
Iter: 772 loss: 3.50082217e-07
Iter: 773 loss: 3.52424053e-07
Iter: 774 loss: 3.50046065e-07
Iter: 775 loss: 3.49718732e-07
Iter: 776 loss: 3.52584692e-07
Iter: 777 loss: 3.496788e-07
Iter: 778 loss: 3.49531376e-07
Iter: 779 loss: 3.49207369e-07
Iter: 780 loss: 3.49204697e-07
Iter: 781 loss: 3.48909708e-07
Iter: 782 loss: 3.5371724e-07
Iter: 783 loss: 3.48913829e-07
Iter: 784 loss: 3.48701462e-07
Iter: 785 loss: 3.48805202e-07
Iter: 786 loss: 3.48557364e-07
Iter: 787 loss: 3.48244839e-07
Iter: 788 loss: 3.50323802e-07
Iter: 789 loss: 3.48258652e-07
Iter: 790 loss: 3.48028294e-07
Iter: 791 loss: 3.48035883e-07
Iter: 792 loss: 3.478672e-07
Iter: 793 loss: 3.47625132e-07
Iter: 794 loss: 3.48085e-07
Iter: 795 loss: 3.47546148e-07
Iter: 796 loss: 3.47312806e-07
Iter: 797 loss: 3.4895811e-07
Iter: 798 loss: 3.4725403e-07
Iter: 799 loss: 3.47098734e-07
Iter: 800 loss: 3.47725916e-07
Iter: 801 loss: 3.4709285e-07
Iter: 802 loss: 3.46891426e-07
Iter: 803 loss: 3.46762448e-07
Iter: 804 loss: 3.46759464e-07
Iter: 805 loss: 3.46504e-07
Iter: 806 loss: 3.46905722e-07
Iter: 807 loss: 3.46435058e-07
Iter: 808 loss: 3.46269474e-07
Iter: 809 loss: 3.49002107e-07
Iter: 810 loss: 3.46279876e-07
Iter: 811 loss: 3.46045169e-07
Iter: 812 loss: 3.45961269e-07
Iter: 813 loss: 3.45926509e-07
Iter: 814 loss: 3.4559659e-07
Iter: 815 loss: 3.45852698e-07
Iter: 816 loss: 3.45436035e-07
Iter: 817 loss: 3.4509759e-07
Iter: 818 loss: 3.48295941e-07
Iter: 819 loss: 3.45062517e-07
Iter: 820 loss: 3.44954685e-07
Iter: 821 loss: 3.45377316e-07
Iter: 822 loss: 3.44857881e-07
Iter: 823 loss: 3.44620332e-07
Iter: 824 loss: 3.44789299e-07
Iter: 825 loss: 3.44505054e-07
Iter: 826 loss: 3.44238856e-07
Iter: 827 loss: 3.43932413e-07
Iter: 828 loss: 3.43895437e-07
Iter: 829 loss: 3.4353377e-07
Iter: 830 loss: 3.43528313e-07
Iter: 831 loss: 3.4333425e-07
Iter: 832 loss: 3.44882039e-07
Iter: 833 loss: 3.43270415e-07
Iter: 834 loss: 3.43108e-07
Iter: 835 loss: 3.42858215e-07
Iter: 836 loss: 3.42851934e-07
Iter: 837 loss: 3.42505359e-07
Iter: 838 loss: 3.42524146e-07
Iter: 839 loss: 3.42238934e-07
Iter: 840 loss: 3.41928029e-07
Iter: 841 loss: 3.46380517e-07
Iter: 842 loss: 3.4193431e-07
Iter: 843 loss: 3.41653731e-07
Iter: 844 loss: 3.42365269e-07
Iter: 845 loss: 3.4158802e-07
Iter: 846 loss: 3.41329809e-07
Iter: 847 loss: 3.414481e-07
Iter: 848 loss: 3.41172466e-07
Iter: 849 loss: 3.40998071e-07
Iter: 850 loss: 3.41003556e-07
Iter: 851 loss: 3.40846441e-07
Iter: 852 loss: 3.40782236e-07
Iter: 853 loss: 3.4072815e-07
Iter: 854 loss: 3.40534655e-07
Iter: 855 loss: 3.42958401e-07
Iter: 856 loss: 3.40550145e-07
Iter: 857 loss: 3.40424549e-07
Iter: 858 loss: 3.402792e-07
Iter: 859 loss: 3.40279598e-07
Iter: 860 loss: 3.40039833e-07
Iter: 861 loss: 3.40325016e-07
Iter: 862 loss: 3.39941607e-07
Iter: 863 loss: 3.3975931e-07
Iter: 864 loss: 3.39777898e-07
Iter: 865 loss: 3.39641559e-07
Iter: 866 loss: 3.39449e-07
Iter: 867 loss: 3.39472564e-07
Iter: 868 loss: 3.39211567e-07
Iter: 869 loss: 3.39443034e-07
Iter: 870 loss: 3.39058687e-07
Iter: 871 loss: 3.38765375e-07
Iter: 872 loss: 3.39114507e-07
Iter: 873 loss: 3.38585096e-07
Iter: 874 loss: 3.38457596e-07
Iter: 875 loss: 3.38404476e-07
Iter: 876 loss: 3.3834786e-07
Iter: 877 loss: 3.38155871e-07
Iter: 878 loss: 3.38139131e-07
Iter: 879 loss: 3.37992049e-07
Iter: 880 loss: 3.39880017e-07
Iter: 881 loss: 3.37949672e-07
Iter: 882 loss: 3.37828254e-07
Iter: 883 loss: 3.38069128e-07
Iter: 884 loss: 3.37765982e-07
Iter: 885 loss: 3.37679552e-07
Iter: 886 loss: 3.3815212e-07
Iter: 887 loss: 3.37619866e-07
Iter: 888 loss: 3.37433534e-07
Iter: 889 loss: 3.37491826e-07
Iter: 890 loss: 3.37346961e-07
Iter: 891 loss: 3.37166654e-07
Iter: 892 loss: 3.37018577e-07
Iter: 893 loss: 3.36905487e-07
Iter: 894 loss: 3.36659298e-07
Iter: 895 loss: 3.39452157e-07
Iter: 896 loss: 3.36665266e-07
Iter: 897 loss: 3.36440394e-07
Iter: 898 loss: 3.39061444e-07
Iter: 899 loss: 3.3644028e-07
Iter: 900 loss: 3.36326821e-07
Iter: 901 loss: 3.36057695e-07
Iter: 902 loss: 3.41781401e-07
Iter: 903 loss: 3.36066108e-07
Iter: 904 loss: 3.35771233e-07
Iter: 905 loss: 3.36600351e-07
Iter: 906 loss: 3.3569583e-07
Iter: 907 loss: 3.35433072e-07
Iter: 908 loss: 3.36707586e-07
Iter: 909 loss: 3.3541059e-07
Iter: 910 loss: 3.35232585e-07
Iter: 911 loss: 3.37105547e-07
Iter: 912 loss: 3.35246796e-07
Iter: 913 loss: 3.35123104e-07
Iter: 914 loss: 3.34908151e-07
Iter: 915 loss: 3.34868872e-07
Iter: 916 loss: 3.34696438e-07
Iter: 917 loss: 3.34725655e-07
Iter: 918 loss: 3.34630329e-07
Iter: 919 loss: 3.34632176e-07
Iter: 920 loss: 3.34571524e-07
Iter: 921 loss: 3.34416427e-07
Iter: 922 loss: 3.34536196e-07
Iter: 923 loss: 3.34290263e-07
Iter: 924 loss: 3.34128032e-07
Iter: 925 loss: 3.33983394e-07
Iter: 926 loss: 3.33957075e-07
Iter: 927 loss: 3.33632528e-07
Iter: 928 loss: 3.33751927e-07
Iter: 929 loss: 3.33541379e-07
Iter: 930 loss: 3.33338875e-07
Iter: 931 loss: 3.33318951e-07
Iter: 932 loss: 3.33100388e-07
Iter: 933 loss: 3.33261653e-07
Iter: 934 loss: 3.32963708e-07
Iter: 935 loss: 3.32756372e-07
Iter: 936 loss: 3.32747135e-07
Iter: 937 loss: 3.32554976e-07
Iter: 938 loss: 3.32328426e-07
Iter: 939 loss: 3.32746765e-07
Iter: 940 loss: 3.32212323e-07
Iter: 941 loss: 3.31973382e-07
Iter: 942 loss: 3.34036855e-07
Iter: 943 loss: 3.31985177e-07
Iter: 944 loss: 3.31727193e-07
Iter: 945 loss: 3.32512684e-07
Iter: 946 loss: 3.31634169e-07
Iter: 947 loss: 3.31493311e-07
Iter: 948 loss: 3.31675977e-07
Iter: 949 loss: 3.31339038e-07
Iter: 950 loss: 3.3119386e-07
Iter: 951 loss: 3.33877267e-07
Iter: 952 loss: 3.31159e-07
Iter: 953 loss: 3.31003207e-07
Iter: 954 loss: 3.31085118e-07
Iter: 955 loss: 3.3092914e-07
Iter: 956 loss: 3.30680592e-07
Iter: 957 loss: 3.30687328e-07
Iter: 958 loss: 3.30497187e-07
Iter: 959 loss: 3.3030048e-07
Iter: 960 loss: 3.30543685e-07
Iter: 961 loss: 3.3020217e-07
Iter: 962 loss: 3.29973489e-07
Iter: 963 loss: 3.30707394e-07
Iter: 964 loss: 3.29961722e-07
Iter: 965 loss: 3.29855254e-07
Iter: 966 loss: 3.29838059e-07
Iter: 967 loss: 3.2971036e-07
Iter: 968 loss: 3.29560322e-07
Iter: 969 loss: 3.29561942e-07
Iter: 970 loss: 3.2935543e-07
Iter: 971 loss: 3.29585475e-07
Iter: 972 loss: 3.292933e-07
Iter: 973 loss: 3.29054842e-07
Iter: 974 loss: 3.2938911e-07
Iter: 975 loss: 3.28996663e-07
Iter: 976 loss: 3.28804049e-07
Iter: 977 loss: 3.28827753e-07
Iter: 978 loss: 3.28715942e-07
Iter: 979 loss: 3.28679363e-07
Iter: 980 loss: 3.28583781e-07
Iter: 981 loss: 3.28425841e-07
Iter: 982 loss: 3.29284148e-07
Iter: 983 loss: 3.28388865e-07
Iter: 984 loss: 3.2826776e-07
Iter: 985 loss: 3.28772586e-07
Iter: 986 loss: 3.28207562e-07
Iter: 987 loss: 3.28002216e-07
Iter: 988 loss: 3.28417173e-07
Iter: 989 loss: 3.27981127e-07
Iter: 990 loss: 3.2783143e-07
Iter: 991 loss: 3.27645097e-07
Iter: 992 loss: 3.27636883e-07
Iter: 993 loss: 3.27408657e-07
Iter: 994 loss: 3.27529648e-07
Iter: 995 loss: 3.2727894e-07
Iter: 996 loss: 3.27000862e-07
Iter: 997 loss: 3.29044667e-07
Iter: 998 loss: 3.26993927e-07
Iter: 999 loss: 3.26815723e-07
Iter: 1000 loss: 3.29334114e-07
Iter: 1001 loss: 3.26873533e-07
Iter: 1002 loss: 3.26726735e-07
Iter: 1003 loss: 3.2655484e-07
Iter: 1004 loss: 3.2654205e-07
Iter: 1005 loss: 3.26435327e-07
Iter: 1006 loss: 3.26726763e-07
Iter: 1007 loss: 3.26304047e-07
Iter: 1008 loss: 3.2611041e-07
Iter: 1009 loss: 3.26496803e-07
Iter: 1010 loss: 3.25991095e-07
Iter: 1011 loss: 3.25899293e-07
Iter: 1012 loss: 3.25896252e-07
Iter: 1013 loss: 3.25723704e-07
Iter: 1014 loss: 3.25743713e-07
Iter: 1015 loss: 3.25575456e-07
Iter: 1016 loss: 3.25503834e-07
Iter: 1017 loss: 3.26994041e-07
Iter: 1018 loss: 3.25523445e-07
Iter: 1019 loss: 3.2541746e-07
Iter: 1020 loss: 3.25645715e-07
Iter: 1021 loss: 3.25377101e-07
Iter: 1022 loss: 3.25244372e-07
Iter: 1023 loss: 3.25442414e-07
Iter: 1024 loss: 3.2524764e-07
Iter: 1025 loss: 3.2512412e-07
Iter: 1026 loss: 3.25073103e-07
Iter: 1027 loss: 3.24993266e-07
Iter: 1028 loss: 3.24845871e-07
Iter: 1029 loss: 3.24882222e-07
Iter: 1030 loss: 3.24753557e-07
Iter: 1031 loss: 3.24531442e-07
Iter: 1032 loss: 3.2499139e-07
Iter: 1033 loss: 3.24460075e-07
Iter: 1034 loss: 3.242844e-07
Iter: 1035 loss: 3.24230854e-07
Iter: 1036 loss: 3.24114183e-07
Iter: 1037 loss: 3.24037359e-07
Iter: 1038 loss: 3.23942402e-07
Iter: 1039 loss: 3.23785031e-07
Iter: 1040 loss: 3.23766358e-07
Iter: 1041 loss: 3.23675835e-07
Iter: 1042 loss: 3.23440958e-07
Iter: 1043 loss: 3.24887e-07
Iter: 1044 loss: 3.23409552e-07
Iter: 1045 loss: 3.23162425e-07
Iter: 1046 loss: 3.23580679e-07
Iter: 1047 loss: 3.23095321e-07
Iter: 1048 loss: 3.2287889e-07
Iter: 1049 loss: 3.23849235e-07
Iter: 1050 loss: 3.22855925e-07
Iter: 1051 loss: 3.22643899e-07
Iter: 1052 loss: 3.24142775e-07
Iter: 1053 loss: 3.22657513e-07
Iter: 1054 loss: 3.22530553e-07
Iter: 1055 loss: 3.22782967e-07
Iter: 1056 loss: 3.22457396e-07
Iter: 1057 loss: 3.22334103e-07
Iter: 1058 loss: 3.22983283e-07
Iter: 1059 loss: 3.2230156e-07
Iter: 1060 loss: 3.22195859e-07
Iter: 1061 loss: 3.22005349e-07
Iter: 1062 loss: 3.25639718e-07
Iter: 1063 loss: 3.21980792e-07
Iter: 1064 loss: 3.21805175e-07
Iter: 1065 loss: 3.21845675e-07
Iter: 1066 loss: 3.21650219e-07
Iter: 1067 loss: 3.21778742e-07
Iter: 1068 loss: 3.21563107e-07
Iter: 1069 loss: 3.21404428e-07
Iter: 1070 loss: 3.21531047e-07
Iter: 1071 loss: 3.21363871e-07
Iter: 1072 loss: 3.21211132e-07
Iter: 1073 loss: 3.22715863e-07
Iter: 1074 loss: 3.21213918e-07
Iter: 1075 loss: 3.21074509e-07
Iter: 1076 loss: 3.20975232e-07
Iter: 1077 loss: 3.20937716e-07
Iter: 1078 loss: 3.20812404e-07
Iter: 1079 loss: 3.20631386e-07
Iter: 1080 loss: 3.20597792e-07
Iter: 1081 loss: 3.20369935e-07
Iter: 1082 loss: 3.21653829e-07
Iter: 1083 loss: 3.20292202e-07
Iter: 1084 loss: 3.20046269e-07
Iter: 1085 loss: 3.20050077e-07
Iter: 1086 loss: 3.19843934e-07
Iter: 1087 loss: 3.19751479e-07
Iter: 1088 loss: 3.19689292e-07
Iter: 1089 loss: 3.1953266e-07
Iter: 1090 loss: 3.19592459e-07
Iter: 1091 loss: 3.1941957e-07
Iter: 1092 loss: 3.19258788e-07
Iter: 1093 loss: 3.19667663e-07
Iter: 1094 loss: 3.19243327e-07
Iter: 1095 loss: 3.19011292e-07
Iter: 1096 loss: 3.19227439e-07
Iter: 1097 loss: 3.18943421e-07
Iter: 1098 loss: 3.18821378e-07
Iter: 1099 loss: 3.18942938e-07
Iter: 1100 loss: 3.18722471e-07
Iter: 1101 loss: 3.18568027e-07
Iter: 1102 loss: 3.19640151e-07
Iter: 1103 loss: 3.18526361e-07
Iter: 1104 loss: 3.18353557e-07
Iter: 1105 loss: 3.18386e-07
Iter: 1106 loss: 3.18259538e-07
Iter: 1107 loss: 3.18154832e-07
Iter: 1108 loss: 3.20082222e-07
Iter: 1109 loss: 3.18142781e-07
Iter: 1110 loss: 3.18029578e-07
Iter: 1111 loss: 3.17925583e-07
Iter: 1112 loss: 3.178844e-07
Iter: 1113 loss: 3.1769622e-07
Iter: 1114 loss: 3.17998428e-07
Iter: 1115 loss: 3.17653047e-07
Iter: 1116 loss: 3.17469073e-07
Iter: 1117 loss: 3.17857427e-07
Iter: 1118 loss: 3.17348849e-07
Iter: 1119 loss: 3.17177268e-07
Iter: 1120 loss: 3.19008223e-07
Iter: 1121 loss: 3.17198555e-07
Iter: 1122 loss: 3.1706881e-07
Iter: 1123 loss: 3.17064888e-07
Iter: 1124 loss: 3.1698616e-07
Iter: 1125 loss: 3.16905698e-07
Iter: 1126 loss: 3.16919e-07
Iter: 1127 loss: 3.16746707e-07
Iter: 1128 loss: 3.17421296e-07
Iter: 1129 loss: 3.1672576e-07
Iter: 1130 loss: 3.16596015e-07
Iter: 1131 loss: 3.16708025e-07
Iter: 1132 loss: 3.16534283e-07
Iter: 1133 loss: 3.16404368e-07
Iter: 1134 loss: 3.16331693e-07
Iter: 1135 loss: 3.16226533e-07
Iter: 1136 loss: 3.16078172e-07
Iter: 1137 loss: 3.17675585e-07
Iter: 1138 loss: 3.16091842e-07
Iter: 1139 loss: 3.15938166e-07
Iter: 1140 loss: 3.15684474e-07
Iter: 1141 loss: 3.21451807e-07
Iter: 1142 loss: 3.15665829e-07
Iter: 1143 loss: 3.15581332e-07
Iter: 1144 loss: 3.15522641e-07
Iter: 1145 loss: 3.15386188e-07
Iter: 1146 loss: 3.15419129e-07
Iter: 1147 loss: 3.15296e-07
Iter: 1148 loss: 3.15127323e-07
Iter: 1149 loss: 3.148632e-07
Iter: 1150 loss: 3.1485132e-07
Iter: 1151 loss: 3.14572617e-07
Iter: 1152 loss: 3.16724709e-07
Iter: 1153 loss: 3.14605359e-07
Iter: 1154 loss: 3.14503296e-07
Iter: 1155 loss: 3.14446879e-07
Iter: 1156 loss: 3.14333704e-07
Iter: 1157 loss: 3.14562442e-07
Iter: 1158 loss: 3.14308352e-07
Iter: 1159 loss: 3.14193812e-07
Iter: 1160 loss: 3.1415891e-07
Iter: 1161 loss: 3.14118466e-07
Iter: 1162 loss: 3.1397559e-07
Iter: 1163 loss: 3.15196786e-07
Iter: 1164 loss: 3.13951318e-07
Iter: 1165 loss: 3.13793549e-07
Iter: 1166 loss: 3.13691942e-07
Iter: 1167 loss: 3.13697115e-07
Iter: 1168 loss: 3.13520331e-07
Iter: 1169 loss: 3.14404616e-07
Iter: 1170 loss: 3.13473635e-07
Iter: 1171 loss: 3.13286932e-07
Iter: 1172 loss: 3.14078903e-07
Iter: 1173 loss: 3.13250126e-07
Iter: 1174 loss: 3.13111116e-07
Iter: 1175 loss: 3.13031165e-07
Iter: 1176 loss: 3.12939818e-07
Iter: 1177 loss: 3.12876949e-07
Iter: 1178 loss: 3.12875272e-07
Iter: 1179 loss: 3.12738251e-07
Iter: 1180 loss: 3.12567948e-07
Iter: 1181 loss: 3.17024103e-07
Iter: 1182 loss: 3.12582074e-07
Iter: 1183 loss: 3.12365756e-07
Iter: 1184 loss: 3.12512384e-07
Iter: 1185 loss: 3.12241582e-07
Iter: 1186 loss: 3.12030181e-07
Iter: 1187 loss: 3.12629936e-07
Iter: 1188 loss: 3.11916438e-07
Iter: 1189 loss: 3.11768531e-07
Iter: 1190 loss: 3.13804435e-07
Iter: 1191 loss: 3.11810197e-07
Iter: 1192 loss: 3.11554857e-07
Iter: 1193 loss: 3.12127071e-07
Iter: 1194 loss: 3.11505119e-07
Iter: 1195 loss: 3.11344536e-07
Iter: 1196 loss: 3.11608062e-07
Iter: 1197 loss: 3.11299232e-07
Iter: 1198 loss: 3.11162751e-07
Iter: 1199 loss: 3.11972e-07
Iter: 1200 loss: 3.11179491e-07
Iter: 1201 loss: 3.11042442e-07
Iter: 1202 loss: 3.1086725e-07
Iter: 1203 loss: 3.10902e-07
Iter: 1204 loss: 3.10672391e-07
Iter: 1205 loss: 3.1140442e-07
Iter: 1206 loss: 3.10648716e-07
Iter: 1207 loss: 3.10509307e-07
Iter: 1208 loss: 3.1188705e-07
Iter: 1209 loss: 3.10515759e-07
Iter: 1210 loss: 3.10430067e-07
Iter: 1211 loss: 3.10307144e-07
Iter: 1212 loss: 3.10329824e-07
Iter: 1213 loss: 3.10187829e-07
Iter: 1214 loss: 3.11302841e-07
Iter: 1215 loss: 3.10145339e-07
Iter: 1216 loss: 3.09975093e-07
Iter: 1217 loss: 3.10499303e-07
Iter: 1218 loss: 3.09899519e-07
Iter: 1219 loss: 3.09838242e-07
Iter: 1220 loss: 3.09599443e-07
Iter: 1221 loss: 3.1474687e-07
Iter: 1222 loss: 3.09587449e-07
Iter: 1223 loss: 3.0940754e-07
Iter: 1224 loss: 3.10233844e-07
Iter: 1225 loss: 3.09368e-07
Iter: 1226 loss: 3.09244911e-07
Iter: 1227 loss: 3.09174425e-07
Iter: 1228 loss: 3.09091234e-07
Iter: 1229 loss: 3.09440509e-07
Iter: 1230 loss: 3.09053718e-07
Iter: 1231 loss: 3.08948216e-07
Iter: 1232 loss: 3.08829101e-07
Iter: 1233 loss: 3.08848882e-07
Iter: 1234 loss: 3.08639301e-07
Iter: 1235 loss: 3.10603582e-07
Iter: 1236 loss: 3.08640097e-07
Iter: 1237 loss: 3.08601585e-07
Iter: 1238 loss: 3.08423807e-07
Iter: 1239 loss: 3.0841835e-07
Iter: 1240 loss: 3.08243244e-07
Iter: 1241 loss: 3.08438644e-07
Iter: 1242 loss: 3.08101562e-07
Iter: 1243 loss: 3.07979747e-07
Iter: 1244 loss: 3.07959681e-07
Iter: 1245 loss: 3.07827435e-07
Iter: 1246 loss: 3.07587328e-07
Iter: 1247 loss: 3.07555183e-07
Iter: 1248 loss: 3.07293561e-07
Iter: 1249 loss: 3.08518764e-07
Iter: 1250 loss: 3.07287451e-07
Iter: 1251 loss: 3.0707659e-07
Iter: 1252 loss: 3.08940514e-07
Iter: 1253 loss: 3.07045099e-07
Iter: 1254 loss: 3.06921208e-07
Iter: 1255 loss: 3.06801553e-07
Iter: 1256 loss: 3.06775661e-07
Iter: 1257 loss: 3.06565084e-07
Iter: 1258 loss: 3.06763e-07
Iter: 1259 loss: 3.06447873e-07
Iter: 1260 loss: 3.06201684e-07
Iter: 1261 loss: 3.07532304e-07
Iter: 1262 loss: 3.06189122e-07
Iter: 1263 loss: 3.06037236e-07
Iter: 1264 loss: 3.06294311e-07
Iter: 1265 loss: 3.05958935e-07
Iter: 1266 loss: 3.05847095e-07
Iter: 1267 loss: 3.05807134e-07
Iter: 1268 loss: 3.05705186e-07
Iter: 1269 loss: 3.0585224e-07
Iter: 1270 loss: 3.0560409e-07
Iter: 1271 loss: 3.0546687e-07
Iter: 1272 loss: 3.05470252e-07
Iter: 1273 loss: 3.05322772e-07
Iter: 1274 loss: 3.05122853e-07
Iter: 1275 loss: 3.06401e-07
Iter: 1276 loss: 3.05083574e-07
Iter: 1277 loss: 3.049295e-07
Iter: 1278 loss: 3.04772783e-07
Iter: 1279 loss: 3.09529895e-07
Iter: 1280 loss: 3.04734868e-07
Iter: 1281 loss: 3.04477851e-07
Iter: 1282 loss: 3.06384e-07
Iter: 1283 loss: 3.04487514e-07
Iter: 1284 loss: 3.04304166e-07
Iter: 1285 loss: 3.06352661e-07
Iter: 1286 loss: 3.04277819e-07
Iter: 1287 loss: 3.04194486e-07
Iter: 1288 loss: 3.04008665e-07
Iter: 1289 loss: 3.0401057e-07
Iter: 1290 loss: 3.03811134e-07
Iter: 1291 loss: 3.05079539e-07
Iter: 1292 loss: 3.03804569e-07
Iter: 1293 loss: 3.03679656e-07
Iter: 1294 loss: 3.04735067e-07
Iter: 1295 loss: 3.03642167e-07
Iter: 1296 loss: 3.03540958e-07
Iter: 1297 loss: 3.03312447e-07
Iter: 1298 loss: 3.06754913e-07
Iter: 1299 loss: 3.03294456e-07
Iter: 1300 loss: 3.03043521e-07
Iter: 1301 loss: 3.03388418e-07
Iter: 1302 loss: 3.02913946e-07
Iter: 1303 loss: 3.0260955e-07
Iter: 1304 loss: 3.04240899e-07
Iter: 1305 loss: 3.02574392e-07
Iter: 1306 loss: 3.02449251e-07
Iter: 1307 loss: 3.02482164e-07
Iter: 1308 loss: 3.02308308e-07
Iter: 1309 loss: 3.02257234e-07
Iter: 1310 loss: 3.02171486e-07
Iter: 1311 loss: 3.02004793e-07
Iter: 1312 loss: 3.0224183e-07
Iter: 1313 loss: 3.01958e-07
Iter: 1314 loss: 3.01760338e-07
Iter: 1315 loss: 3.02534431e-07
Iter: 1316 loss: 3.01747889e-07
Iter: 1317 loss: 3.01568662e-07
Iter: 1318 loss: 3.0159e-07
Iter: 1319 loss: 3.01447841e-07
Iter: 1320 loss: 3.01306869e-07
Iter: 1321 loss: 3.01614818e-07
Iter: 1322 loss: 3.0131946e-07
Iter: 1323 loss: 3.01087113e-07
Iter: 1324 loss: 3.02830216e-07
Iter: 1325 loss: 3.0107293e-07
Iter: 1326 loss: 3.00949921e-07
Iter: 1327 loss: 3.0108464e-07
Iter: 1328 loss: 3.00916582e-07
Iter: 1329 loss: 3.00776122e-07
Iter: 1330 loss: 3.00880515e-07
Iter: 1331 loss: 3.00666386e-07
Iter: 1332 loss: 3.00519673e-07
Iter: 1333 loss: 3.02239187e-07
Iter: 1334 loss: 3.00509271e-07
Iter: 1335 loss: 3.00435062e-07
Iter: 1336 loss: 3.00308585e-07
Iter: 1337 loss: 3.00324075e-07
Iter: 1338 loss: 3.00130154e-07
Iter: 1339 loss: 3.00390326e-07
Iter: 1340 loss: 3.0006359e-07
Iter: 1341 loss: 2.99908834e-07
Iter: 1342 loss: 3.0009636e-07
Iter: 1343 loss: 2.99779288e-07
Iter: 1344 loss: 2.99693681e-07
Iter: 1345 loss: 2.99654829e-07
Iter: 1346 loss: 2.99573514e-07
Iter: 1347 loss: 2.99326445e-07
Iter: 1348 loss: 3.01198412e-07
Iter: 1349 loss: 2.99290036e-07
Iter: 1350 loss: 2.99005848e-07
Iter: 1351 loss: 3.00174e-07
Iter: 1352 loss: 2.98981092e-07
Iter: 1353 loss: 2.98692186e-07
Iter: 1354 loss: 3.00570463e-07
Iter: 1355 loss: 2.98662144e-07
Iter: 1356 loss: 2.98499e-07
Iter: 1357 loss: 2.98482348e-07
Iter: 1358 loss: 2.98341661e-07
Iter: 1359 loss: 2.98168345e-07
Iter: 1360 loss: 2.99320732e-07
Iter: 1361 loss: 2.98038941e-07
Iter: 1362 loss: 2.97912834e-07
Iter: 1363 loss: 2.99081023e-07
Iter: 1364 loss: 2.97846441e-07
Iter: 1365 loss: 2.97679122e-07
Iter: 1366 loss: 2.97965954e-07
Iter: 1367 loss: 2.9764621e-07
Iter: 1368 loss: 2.97525531e-07
Iter: 1369 loss: 2.9838057e-07
Iter: 1370 loss: 2.97499554e-07
Iter: 1371 loss: 2.97389334e-07
Iter: 1372 loss: 2.9726408e-07
Iter: 1373 loss: 2.97238245e-07
Iter: 1374 loss: 2.97086018e-07
Iter: 1375 loss: 2.97100399e-07
Iter: 1376 loss: 2.96907018e-07
Iter: 1377 loss: 2.96734612e-07
Iter: 1378 loss: 2.9731325e-07
Iter: 1379 loss: 2.96619476e-07
Iter: 1380 loss: 2.96658413e-07
Iter: 1381 loss: 2.96531368e-07
Iter: 1382 loss: 2.96482938e-07
Iter: 1383 loss: 2.96353591e-07
Iter: 1384 loss: 2.96381074e-07
Iter: 1385 loss: 2.96215831e-07
Iter: 1386 loss: 2.9604152e-07
Iter: 1387 loss: 2.96045528e-07
Iter: 1388 loss: 2.95809059e-07
Iter: 1389 loss: 2.96846963e-07
Iter: 1390 loss: 2.95770718e-07
Iter: 1391 loss: 2.95531891e-07
Iter: 1392 loss: 2.96613536e-07
Iter: 1393 loss: 2.95565656e-07
Iter: 1394 loss: 2.95376452e-07
Iter: 1395 loss: 2.96713267e-07
Iter: 1396 loss: 2.9537162e-07
Iter: 1397 loss: 2.95207201e-07
Iter: 1398 loss: 2.95462684e-07
Iter: 1399 loss: 2.95098545e-07
Iter: 1400 loss: 2.94947199e-07
Iter: 1401 loss: 2.95658481e-07
Iter: 1402 loss: 2.9491e-07
Iter: 1403 loss: 2.94823479e-07
Iter: 1404 loss: 2.94825611e-07
Iter: 1405 loss: 2.9471127e-07
Iter: 1406 loss: 2.94501689e-07
Iter: 1407 loss: 2.94771326e-07
Iter: 1408 loss: 2.94450274e-07
Iter: 1409 loss: 2.94328174e-07
Iter: 1410 loss: 2.94313679e-07
Iter: 1411 loss: 2.94174441e-07
Iter: 1412 loss: 2.94030883e-07
Iter: 1413 loss: 2.94003115e-07
Iter: 1414 loss: 2.94000301e-07
Iter: 1415 loss: 2.93921545e-07
Iter: 1416 loss: 2.93880873e-07
Iter: 1417 loss: 2.93767982e-07
Iter: 1418 loss: 2.93784552e-07
Iter: 1419 loss: 2.93693205e-07
Iter: 1420 loss: 2.9363656e-07
Iter: 1421 loss: 2.93582218e-07
Iter: 1422 loss: 2.93412967e-07
Iter: 1423 loss: 2.9374246e-07
Iter: 1424 loss: 2.93376814e-07
Iter: 1425 loss: 2.93192358e-07
Iter: 1426 loss: 2.93889741e-07
Iter: 1427 loss: 2.93146712e-07
Iter: 1428 loss: 2.930324e-07
Iter: 1429 loss: 2.95079218e-07
Iter: 1430 loss: 2.92991047e-07
Iter: 1431 loss: 2.92868236e-07
Iter: 1432 loss: 2.92863149e-07
Iter: 1433 loss: 2.92826513e-07
Iter: 1434 loss: 2.92693812e-07
Iter: 1435 loss: 2.92686764e-07
Iter: 1436 loss: 2.92566881e-07
Iter: 1437 loss: 2.92329759e-07
Iter: 1438 loss: 2.95842938e-07
Iter: 1439 loss: 2.9236196e-07
Iter: 1440 loss: 2.92239804e-07
Iter: 1441 loss: 2.9238015e-07
Iter: 1442 loss: 2.92086781e-07
Iter: 1443 loss: 2.91940466e-07
Iter: 1444 loss: 2.93492974e-07
Iter: 1445 loss: 2.91940864e-07
Iter: 1446 loss: 2.9176573e-07
Iter: 1447 loss: 2.91832464e-07
Iter: 1448 loss: 2.91642e-07
Iter: 1449 loss: 2.91517154e-07
Iter: 1450 loss: 2.92165595e-07
Iter: 1451 loss: 2.91449425e-07
Iter: 1452 loss: 2.91304957e-07
Iter: 1453 loss: 2.92775638e-07
Iter: 1454 loss: 2.91287279e-07
Iter: 1455 loss: 2.91197779e-07
Iter: 1456 loss: 2.90980893e-07
Iter: 1457 loss: 2.94202579e-07
Iter: 1458 loss: 2.90988879e-07
Iter: 1459 loss: 2.90735272e-07
Iter: 1460 loss: 2.91685893e-07
Iter: 1461 loss: 2.90661262e-07
Iter: 1462 loss: 2.905565e-07
Iter: 1463 loss: 2.91021536e-07
Iter: 1464 loss: 2.90454409e-07
Iter: 1465 loss: 2.90301e-07
Iter: 1466 loss: 2.91396191e-07
Iter: 1467 loss: 2.90242923e-07
Iter: 1468 loss: 2.90108289e-07
Iter: 1469 loss: 2.90818974e-07
Iter: 1470 loss: 2.9012071e-07
Iter: 1471 loss: 2.90015549e-07
Iter: 1472 loss: 2.90031466e-07
Iter: 1473 loss: 2.89923094e-07
Iter: 1474 loss: 2.89843967e-07
Iter: 1475 loss: 2.89822367e-07
Iter: 1476 loss: 2.89780587e-07
Iter: 1477 loss: 2.89717264e-07
Iter: 1478 loss: 2.92242163e-07
Iter: 1479 loss: 2.89711664e-07
Iter: 1480 loss: 2.89588201e-07
Iter: 1481 loss: 2.89519e-07
Iter: 1482 loss: 2.89468403e-07
Iter: 1483 loss: 2.89291677e-07
Iter: 1484 loss: 2.90955967e-07
Iter: 1485 loss: 2.89238756e-07
Iter: 1486 loss: 2.89098892e-07
Iter: 1487 loss: 2.89622847e-07
Iter: 1488 loss: 2.89044237e-07
Iter: 1489 loss: 2.88869614e-07
Iter: 1490 loss: 2.8902366e-07
Iter: 1491 loss: 2.88808877e-07
Iter: 1492 loss: 2.88684674e-07
Iter: 1493 loss: 2.8868368e-07
Iter: 1494 loss: 2.88606856e-07
Iter: 1495 loss: 2.88360042e-07
Iter: 1496 loss: 2.90405524e-07
Iter: 1497 loss: 2.88360866e-07
Iter: 1498 loss: 2.88158873e-07
Iter: 1499 loss: 2.89333883e-07
Iter: 1500 loss: 2.88148442e-07
Iter: 1501 loss: 2.8802e-07
Iter: 1502 loss: 2.88872968e-07
Iter: 1503 loss: 2.87949035e-07
Iter: 1504 loss: 2.87871e-07
Iter: 1505 loss: 2.8859e-07
Iter: 1506 loss: 2.87814373e-07
Iter: 1507 loss: 2.87718677e-07
Iter: 1508 loss: 2.87596208e-07
Iter: 1509 loss: 2.87586175e-07
Iter: 1510 loss: 2.87493521e-07
Iter: 1511 loss: 2.87496192e-07
Iter: 1512 loss: 2.87374718e-07
Iter: 1513 loss: 2.87264498e-07
Iter: 1514 loss: 2.8720109e-07
Iter: 1515 loss: 2.87085982e-07
Iter: 1516 loss: 2.87166216e-07
Iter: 1517 loss: 2.87032293e-07
Iter: 1518 loss: 2.86933783e-07
Iter: 1519 loss: 2.87125317e-07
Iter: 1520 loss: 2.86889531e-07
Iter: 1521 loss: 2.86789941e-07
Iter: 1522 loss: 2.88181838e-07
Iter: 1523 loss: 2.86768511e-07
Iter: 1524 loss: 2.8671667e-07
Iter: 1525 loss: 2.86670712e-07
Iter: 1526 loss: 2.86625607e-07
Iter: 1527 loss: 2.86536192e-07
Iter: 1528 loss: 2.8661583e-07
Iter: 1529 loss: 2.86473636e-07
Iter: 1530 loss: 2.86434812e-07
Iter: 1531 loss: 2.86400621e-07
Iter: 1532 loss: 2.86324337e-07
Iter: 1533 loss: 2.86201612e-07
Iter: 1534 loss: 2.88131503e-07
Iter: 1535 loss: 2.86144285e-07
Iter: 1536 loss: 2.86030684e-07
Iter: 1537 loss: 2.8606604e-07
Iter: 1538 loss: 2.85885278e-07
Iter: 1539 loss: 2.8572731e-07
Iter: 1540 loss: 2.88021027e-07
Iter: 1541 loss: 2.85728959e-07
Iter: 1542 loss: 2.85561384e-07
Iter: 1543 loss: 2.85709319e-07
Iter: 1544 loss: 2.8549664e-07
Iter: 1545 loss: 2.85340178e-07
Iter: 1546 loss: 2.85802514e-07
Iter: 1547 loss: 2.8531781e-07
Iter: 1548 loss: 2.85125225e-07
Iter: 1549 loss: 2.85778185e-07
Iter: 1550 loss: 2.85099162e-07
Iter: 1551 loss: 2.84963249e-07
Iter: 1552 loss: 2.84947731e-07
Iter: 1553 loss: 2.84872016e-07
Iter: 1554 loss: 2.84754805e-07
Iter: 1555 loss: 2.84866189e-07
Iter: 1556 loss: 2.84677981e-07
Iter: 1557 loss: 2.84618466e-07
Iter: 1558 loss: 2.84616647e-07
Iter: 1559 loss: 2.84549117e-07
Iter: 1560 loss: 2.84470332e-07
Iter: 1561 loss: 2.84483946e-07
Iter: 1562 loss: 2.84276325e-07
Iter: 1563 loss: 2.84654845e-07
Iter: 1564 loss: 2.84317537e-07
Iter: 1565 loss: 2.84236364e-07
Iter: 1566 loss: 2.84255549e-07
Iter: 1567 loss: 2.84136604e-07
Iter: 1568 loss: 2.84085161e-07
Iter: 1569 loss: 2.84969701e-07
Iter: 1570 loss: 2.84081381e-07
Iter: 1571 loss: 2.83969541e-07
Iter: 1572 loss: 2.84247704e-07
Iter: 1573 loss: 2.83908349e-07
Iter: 1574 loss: 2.83809129e-07
Iter: 1575 loss: 2.83818451e-07
Iter: 1576 loss: 2.83721107e-07
Iter: 1577 loss: 2.83681231e-07
Iter: 1578 loss: 2.8362939e-07
Iter: 1579 loss: 2.83514879e-07
Iter: 1580 loss: 2.84175542e-07
Iter: 1581 loss: 2.83505358e-07
Iter: 1582 loss: 2.83336703e-07
Iter: 1583 loss: 2.8387646e-07
Iter: 1584 loss: 2.83293588e-07
Iter: 1585 loss: 2.832316e-07
Iter: 1586 loss: 2.83195106e-07
Iter: 1587 loss: 2.83211364e-07
Iter: 1588 loss: 2.83006557e-07
Iter: 1589 loss: 2.83130134e-07
Iter: 1590 loss: 2.8287252e-07
Iter: 1591 loss: 2.82784555e-07
Iter: 1592 loss: 2.82758748e-07
Iter: 1593 loss: 2.82635938e-07
Iter: 1594 loss: 2.82508324e-07
Iter: 1595 loss: 2.82480329e-07
Iter: 1596 loss: 2.82341233e-07
Iter: 1597 loss: 2.83019403e-07
Iter: 1598 loss: 2.82315966e-07
Iter: 1599 loss: 2.82267024e-07
Iter: 1600 loss: 2.82237437e-07
Iter: 1601 loss: 2.82178178e-07
Iter: 1602 loss: 2.8204326e-07
Iter: 1603 loss: 2.83923328e-07
Iter: 1604 loss: 2.82042038e-07
Iter: 1605 loss: 2.81919483e-07
Iter: 1606 loss: 2.82069777e-07
Iter: 1607 loss: 2.81872587e-07
Iter: 1608 loss: 2.81852181e-07
Iter: 1609 loss: 2.8180142e-07
Iter: 1610 loss: 2.81757366e-07
Iter: 1611 loss: 2.81706747e-07
Iter: 1612 loss: 2.81679888e-07
Iter: 1613 loss: 2.81635351e-07
Iter: 1614 loss: 2.82284162e-07
Iter: 1615 loss: 2.81614405e-07
Iter: 1616 loss: 2.8156532e-07
Iter: 1617 loss: 2.81655161e-07
Iter: 1618 loss: 2.81503844e-07
Iter: 1619 loss: 2.81488468e-07
Iter: 1620 loss: 2.81409342e-07
Iter: 1621 loss: 2.81400673e-07
Iter: 1622 loss: 2.81268257e-07
Iter: 1623 loss: 2.82084983e-07
Iter: 1624 loss: 2.81275e-07
Iter: 1625 loss: 2.81173925e-07
Iter: 1626 loss: 2.81793604e-07
Iter: 1627 loss: 2.81174465e-07
Iter: 1628 loss: 2.81118048e-07
Iter: 1629 loss: 2.80969886e-07
Iter: 1630 loss: 2.80976849e-07
Iter: 1631 loss: 2.80865379e-07
Iter: 1632 loss: 2.81914254e-07
Iter: 1633 loss: 2.80869045e-07
Iter: 1634 loss: 2.80756524e-07
Iter: 1635 loss: 2.81580157e-07
Iter: 1636 loss: 2.80778238e-07
Iter: 1637 loss: 2.80692205e-07
Iter: 1638 loss: 2.80564706e-07
Iter: 1639 loss: 2.83161711e-07
Iter: 1640 loss: 2.80556947e-07
Iter: 1641 loss: 2.80426747e-07
Iter: 1642 loss: 2.80667336e-07
Iter: 1643 loss: 2.80370045e-07
Iter: 1644 loss: 2.80257979e-07
Iter: 1645 loss: 2.80302146e-07
Iter: 1646 loss: 2.80198691e-07
Iter: 1647 loss: 2.80110442e-07
Iter: 1648 loss: 2.80094554e-07
Iter: 1649 loss: 2.80007242e-07
Iter: 1650 loss: 2.80825617e-07
Iter: 1651 loss: 2.80045242e-07
Iter: 1652 loss: 2.79913166e-07
Iter: 1653 loss: 2.80062267e-07
Iter: 1654 loss: 2.79881391e-07
Iter: 1655 loss: 2.79801782e-07
Iter: 1656 loss: 2.79750168e-07
Iter: 1657 loss: 2.79671326e-07
Iter: 1658 loss: 2.79616387e-07
Iter: 1659 loss: 2.79970408e-07
Iter: 1660 loss: 2.79584896e-07
Iter: 1661 loss: 2.79505656e-07
Iter: 1662 loss: 2.80206393e-07
Iter: 1663 loss: 2.79491672e-07
Iter: 1664 loss: 2.79437785e-07
Iter: 1665 loss: 2.79407914e-07
Iter: 1666 loss: 2.79368862e-07
Iter: 1667 loss: 2.79272456e-07
Iter: 1668 loss: 2.79454525e-07
Iter: 1669 loss: 2.79259069e-07
Iter: 1670 loss: 2.79156296e-07
Iter: 1671 loss: 2.79858853e-07
Iter: 1672 loss: 2.79163118e-07
Iter: 1673 loss: 2.79084787e-07
Iter: 1674 loss: 2.78964478e-07
Iter: 1675 loss: 2.81001e-07
Iter: 1676 loss: 2.789767e-07
Iter: 1677 loss: 2.78832914e-07
Iter: 1678 loss: 2.79071344e-07
Iter: 1679 loss: 2.78716755e-07
Iter: 1680 loss: 2.78586157e-07
Iter: 1681 loss: 2.79638243e-07
Iter: 1682 loss: 2.78549464e-07
Iter: 1683 loss: 2.78405111e-07
Iter: 1684 loss: 2.79602233e-07
Iter: 1685 loss: 2.78435976e-07
Iter: 1686 loss: 2.78317458e-07
Iter: 1687 loss: 2.78374046e-07
Iter: 1688 loss: 2.78267095e-07
Iter: 1689 loss: 2.7816057e-07
Iter: 1690 loss: 2.78759472e-07
Iter: 1691 loss: 2.78157302e-07
Iter: 1692 loss: 2.78009793e-07
Iter: 1693 loss: 2.77948743e-07
Iter: 1694 loss: 2.7796321e-07
Iter: 1695 loss: 2.77837131e-07
Iter: 1696 loss: 2.7836802e-07
Iter: 1697 loss: 2.77809761e-07
Iter: 1698 loss: 2.7771614e-07
Iter: 1699 loss: 2.78139908e-07
Iter: 1700 loss: 2.77649093e-07
Iter: 1701 loss: 2.77598048e-07
Iter: 1702 loss: 2.77484475e-07
Iter: 1703 loss: 2.775094e-07
Iter: 1704 loss: 2.77342053e-07
Iter: 1705 loss: 2.77379542e-07
Iter: 1706 loss: 2.77304736e-07
Iter: 1707 loss: 2.77215463e-07
Iter: 1708 loss: 2.77212933e-07
Iter: 1709 loss: 2.77089327e-07
Iter: 1710 loss: 2.77083e-07
Iter: 1711 loss: 2.76995792e-07
Iter: 1712 loss: 2.76865535e-07
Iter: 1713 loss: 2.76976692e-07
Iter: 1714 loss: 2.76814774e-07
Iter: 1715 loss: 2.7665962e-07
Iter: 1716 loss: 2.77427745e-07
Iter: 1717 loss: 2.76617357e-07
Iter: 1718 loss: 2.76542295e-07
Iter: 1719 loss: 2.77291349e-07
Iter: 1720 loss: 2.76515266e-07
Iter: 1721 loss: 2.76421019e-07
Iter: 1722 loss: 2.76424771e-07
Iter: 1723 loss: 2.76339819e-07
Iter: 1724 loss: 2.76229741e-07
Iter: 1725 loss: 2.76988231e-07
Iter: 1726 loss: 2.76220504e-07
Iter: 1727 loss: 2.76080442e-07
Iter: 1728 loss: 2.76159085e-07
Iter: 1729 loss: 2.75972184e-07
Iter: 1730 loss: 2.75922929e-07
Iter: 1731 loss: 2.75879131e-07
Iter: 1732 loss: 2.75823538e-07
Iter: 1733 loss: 2.75683789e-07
Iter: 1734 loss: 2.76993489e-07
Iter: 1735 loss: 2.75660909e-07
Iter: 1736 loss: 2.75520506e-07
Iter: 1737 loss: 2.75867961e-07
Iter: 1738 loss: 2.75454966e-07
Iter: 1739 loss: 2.75400453e-07
Iter: 1740 loss: 2.76024394e-07
Iter: 1741 loss: 2.75418842e-07
Iter: 1742 loss: 2.75277358e-07
Iter: 1743 loss: 2.75452749e-07
Iter: 1744 loss: 2.75239103e-07
Iter: 1745 loss: 2.75186466e-07
Iter: 1746 loss: 2.75031198e-07
Iter: 1747 loss: 2.7501784e-07
Iter: 1748 loss: 2.74894603e-07
Iter: 1749 loss: 2.75672818e-07
Iter: 1750 loss: 2.74922456e-07
Iter: 1751 loss: 2.74755195e-07
Iter: 1752 loss: 2.74760737e-07
Iter: 1753 loss: 2.74689569e-07
Iter: 1754 loss: 2.74764091e-07
Iter: 1755 loss: 2.74630338e-07
Iter: 1756 loss: 2.74578809e-07
Iter: 1757 loss: 2.74897701e-07
Iter: 1758 loss: 2.74554679e-07
Iter: 1759 loss: 2.74470466e-07
Iter: 1760 loss: 2.74885934e-07
Iter: 1761 loss: 2.74446961e-07
Iter: 1762 loss: 2.74319e-07
Iter: 1763 loss: 2.74292717e-07
Iter: 1764 loss: 2.74264238e-07
Iter: 1765 loss: 2.74167036e-07
Iter: 1766 loss: 2.74902533e-07
Iter: 1767 loss: 2.74159163e-07
Iter: 1768 loss: 2.74063439e-07
Iter: 1769 loss: 2.75115e-07
Iter: 1770 loss: 2.74097e-07
Iter: 1771 loss: 2.74004776e-07
Iter: 1772 loss: 2.73963451e-07
Iter: 1773 loss: 2.73969363e-07
Iter: 1774 loss: 2.73870967e-07
Iter: 1775 loss: 2.74552548e-07
Iter: 1776 loss: 2.73870256e-07
Iter: 1777 loss: 2.73833848e-07
Iter: 1778 loss: 2.73718257e-07
Iter: 1779 loss: 2.76212631e-07
Iter: 1780 loss: 2.73731871e-07
Iter: 1781 loss: 2.73622021e-07
Iter: 1782 loss: 2.73670594e-07
Iter: 1783 loss: 2.73542042e-07
Iter: 1784 loss: 2.73434438e-07
Iter: 1785 loss: 2.74668963e-07
Iter: 1786 loss: 2.73431e-07
Iter: 1787 loss: 2.73345563e-07
Iter: 1788 loss: 2.73697282e-07
Iter: 1789 loss: 2.73318079e-07
Iter: 1790 loss: 2.73246627e-07
Iter: 1791 loss: 2.73159117e-07
Iter: 1792 loss: 2.73108554e-07
Iter: 1793 loss: 2.72974063e-07
Iter: 1794 loss: 2.7413256e-07
Iter: 1795 loss: 2.73040285e-07
Iter: 1796 loss: 2.72907926e-07
Iter: 1797 loss: 2.72937626e-07
Iter: 1798 loss: 2.72814532e-07
Iter: 1799 loss: 2.72677966e-07
Iter: 1800 loss: 2.72796314e-07
Iter: 1801 loss: 2.72644144e-07
Iter: 1802 loss: 2.72539154e-07
Iter: 1803 loss: 2.73741023e-07
Iter: 1804 loss: 2.72536596e-07
Iter: 1805 loss: 2.72408556e-07
Iter: 1806 loss: 2.7262152e-07
Iter: 1807 loss: 2.72326361e-07
Iter: 1808 loss: 2.7225181e-07
Iter: 1809 loss: 2.72764709e-07
Iter: 1810 loss: 2.72256955e-07
Iter: 1811 loss: 2.72109219e-07
Iter: 1812 loss: 2.72034839e-07
Iter: 1813 loss: 2.7197791e-07
Iter: 1814 loss: 2.71830231e-07
Iter: 1815 loss: 2.71944714e-07
Iter: 1816 loss: 2.71685877e-07
Iter: 1817 loss: 2.71518786e-07
Iter: 1818 loss: 2.72291885e-07
Iter: 1819 loss: 2.71499147e-07
Iter: 1820 loss: 2.71384863e-07
Iter: 1821 loss: 2.71357e-07
Iter: 1822 loss: 2.71297779e-07
Iter: 1823 loss: 2.71608798e-07
Iter: 1824 loss: 2.71252645e-07
Iter: 1825 loss: 2.71199781e-07
Iter: 1826 loss: 2.71148764e-07
Iter: 1827 loss: 2.7116954e-07
Iter: 1828 loss: 2.71026948e-07
Iter: 1829 loss: 2.71750878e-07
Iter: 1830 loss: 2.71000658e-07
Iter: 1831 loss: 2.70904394e-07
Iter: 1832 loss: 2.70918207e-07
Iter: 1833 loss: 2.70884556e-07
Iter: 1834 loss: 2.70802332e-07
Iter: 1835 loss: 2.70804861e-07
Iter: 1836 loss: 2.70743385e-07
Iter: 1837 loss: 2.70639532e-07
Iter: 1838 loss: 2.70653175e-07
Iter: 1839 loss: 2.70557223e-07
Iter: 1840 loss: 2.70482815e-07
Iter: 1841 loss: 2.70492e-07
Iter: 1842 loss: 2.70341786e-07
Iter: 1843 loss: 2.71126822e-07
Iter: 1844 loss: 2.7032516e-07
Iter: 1845 loss: 2.70262774e-07
Iter: 1846 loss: 2.70152924e-07
Iter: 1847 loss: 2.72627517e-07
Iter: 1848 loss: 2.70141271e-07
Iter: 1849 loss: 2.69981086e-07
Iter: 1850 loss: 2.70323824e-07
Iter: 1851 loss: 2.69893746e-07
Iter: 1852 loss: 2.6976312e-07
Iter: 1853 loss: 2.71160019e-07
Iter: 1854 loss: 2.69767042e-07
Iter: 1855 loss: 2.69669954e-07
Iter: 1856 loss: 2.70723376e-07
Iter: 1857 loss: 2.69653896e-07
Iter: 1858 loss: 2.69614645e-07
Iter: 1859 loss: 2.69683056e-07
Iter: 1860 loss: 2.6958611e-07
Iter: 1861 loss: 2.69500475e-07
Iter: 1862 loss: 2.69834857e-07
Iter: 1863 loss: 2.69475606e-07
Iter: 1864 loss: 2.69346742e-07
Iter: 1865 loss: 2.69289131e-07
Iter: 1866 loss: 2.69275063e-07
Iter: 1867 loss: 2.69108256e-07
Iter: 1868 loss: 2.69368797e-07
Iter: 1869 loss: 2.69061672e-07
Iter: 1870 loss: 2.68980926e-07
Iter: 1871 loss: 2.69637894e-07
Iter: 1872 loss: 2.68940283e-07
Iter: 1873 loss: 2.68871702e-07
Iter: 1874 loss: 2.70102561e-07
Iter: 1875 loss: 2.68874288e-07
Iter: 1876 loss: 2.68790728e-07
Iter: 1877 loss: 2.68792974e-07
Iter: 1878 loss: 2.68748408e-07
Iter: 1879 loss: 2.68610535e-07
Iter: 1880 loss: 2.69114054e-07
Iter: 1881 loss: 2.68575235e-07
Iter: 1882 loss: 2.68516345e-07
Iter: 1883 loss: 2.68482239e-07
Iter: 1884 loss: 2.68453419e-07
Iter: 1885 loss: 2.6836554e-07
Iter: 1886 loss: 2.68387396e-07
Iter: 1887 loss: 2.68296304e-07
Iter: 1888 loss: 2.68172926e-07
Iter: 1889 loss: 2.68428977e-07
Iter: 1890 loss: 2.68098347e-07
Iter: 1891 loss: 2.68007227e-07
Iter: 1892 loss: 2.68033887e-07
Iter: 1893 loss: 2.67883678e-07
Iter: 1894 loss: 2.67932251e-07
Iter: 1895 loss: 2.67846218e-07
Iter: 1896 loss: 2.67666621e-07
Iter: 1897 loss: 2.67773203e-07
Iter: 1898 loss: 2.67599859e-07
Iter: 1899 loss: 2.67447319e-07
Iter: 1900 loss: 2.69245533e-07
Iter: 1901 loss: 2.67459626e-07
Iter: 1902 loss: 2.67365323e-07
Iter: 1903 loss: 2.6718439e-07
Iter: 1904 loss: 2.67195162e-07
Iter: 1905 loss: 2.67033755e-07
Iter: 1906 loss: 2.67689217e-07
Iter: 1907 loss: 2.66971711e-07
Iter: 1908 loss: 2.66859274e-07
Iter: 1909 loss: 2.68132283e-07
Iter: 1910 loss: 2.66863054e-07
Iter: 1911 loss: 2.66805415e-07
Iter: 1912 loss: 2.67570755e-07
Iter: 1913 loss: 2.66783e-07
Iter: 1914 loss: 2.66715517e-07
Iter: 1915 loss: 2.66735327e-07
Iter: 1916 loss: 2.66673794e-07
Iter: 1917 loss: 2.66565394e-07
Iter: 1918 loss: 2.66957471e-07
Iter: 1919 loss: 2.66546863e-07
Iter: 1920 loss: 2.66478622e-07
Iter: 1921 loss: 2.6635476e-07
Iter: 1922 loss: 2.66393442e-07
Iter: 1923 loss: 2.66272167e-07
Iter: 1924 loss: 2.66743967e-07
Iter: 1925 loss: 2.66206598e-07
Iter: 1926 loss: 2.66074835e-07
Iter: 1927 loss: 2.66232092e-07
Iter: 1928 loss: 2.65993606e-07
Iter: 1929 loss: 2.65979622e-07
Iter: 1930 loss: 2.6595518e-07
Iter: 1931 loss: 2.65889241e-07
Iter: 1932 loss: 2.65898791e-07
Iter: 1933 loss: 2.65830636e-07
Iter: 1934 loss: 2.65790874e-07
Iter: 1935 loss: 2.65896176e-07
Iter: 1936 loss: 2.65748128e-07
Iter: 1937 loss: 2.65650499e-07
Iter: 1938 loss: 2.65883898e-07
Iter: 1939 loss: 2.65633844e-07
Iter: 1940 loss: 2.65554092e-07
Iter: 1941 loss: 2.65477524e-07
Iter: 1942 loss: 2.65491053e-07
Iter: 1943 loss: 2.65409568e-07
Iter: 1944 loss: 2.65523369e-07
Iter: 1945 loss: 2.65382681e-07
Iter: 1946 loss: 2.65274281e-07
Iter: 1947 loss: 2.65548522e-07
Iter: 1948 loss: 2.65208655e-07
Iter: 1949 loss: 2.65150845e-07
Iter: 1950 loss: 2.6512862e-07
Iter: 1951 loss: 2.65069104e-07
Iter: 1952 loss: 2.65065694e-07
Iter: 1953 loss: 2.6499248e-07
Iter: 1954 loss: 2.64903179e-07
Iter: 1955 loss: 2.65378588e-07
Iter: 1956 loss: 2.64899228e-07
Iter: 1957 loss: 2.64828344e-07
Iter: 1958 loss: 2.64747513e-07
Iter: 1959 loss: 2.64745211e-07
Iter: 1960 loss: 2.6461808e-07
Iter: 1961 loss: 2.64715908e-07
Iter: 1962 loss: 2.64547964e-07
Iter: 1963 loss: 2.64453519e-07
Iter: 1964 loss: 2.65195553e-07
Iter: 1965 loss: 2.6446881e-07
Iter: 1966 loss: 2.64339462e-07
Iter: 1967 loss: 2.65071037e-07
Iter: 1968 loss: 2.64334261e-07
Iter: 1969 loss: 2.6429916e-07
Iter: 1970 loss: 2.64227e-07
Iter: 1971 loss: 2.6423541e-07
Iter: 1972 loss: 2.64151566e-07
Iter: 1973 loss: 2.65117905e-07
Iter: 1974 loss: 2.64124935e-07
Iter: 1975 loss: 2.64092876e-07
Iter: 1976 loss: 2.64045894e-07
Iter: 1977 loss: 2.64009e-07
Iter: 1978 loss: 2.63903871e-07
Iter: 1979 loss: 2.63938915e-07
Iter: 1980 loss: 2.63833414e-07
Iter: 1981 loss: 2.63736837e-07
Iter: 1982 loss: 2.65021868e-07
Iter: 1983 loss: 2.63743516e-07
Iter: 1984 loss: 2.63656744e-07
Iter: 1985 loss: 2.64127891e-07
Iter: 1986 loss: 2.63631421e-07
Iter: 1987 loss: 2.63577448e-07
Iter: 1988 loss: 2.63626333e-07
Iter: 1989 loss: 2.63533792e-07
Iter: 1990 loss: 2.63373153e-07
Iter: 1991 loss: 2.6364313e-07
Iter: 1992 loss: 2.63365223e-07
Iter: 1993 loss: 2.63304912e-07
Iter: 1994 loss: 2.63310483e-07
Iter: 1995 loss: 2.63263701e-07
Iter: 1996 loss: 2.63136883e-07
Iter: 1997 loss: 2.63447589e-07
Iter: 1998 loss: 2.63076117e-07
Iter: 1999 loss: 2.6301214e-07
Iter: 2000 loss: 2.64078921e-07
Iter: 2001 loss: 2.63014954e-07
Iter: 2002 loss: 2.62949271e-07
Iter: 2003 loss: 2.62894815e-07
Iter: 2004 loss: 2.62900642e-07
Iter: 2005 loss: 2.62799801e-07
Iter: 2006 loss: 2.62928438e-07
Iter: 2007 loss: 2.62761745e-07
Iter: 2008 loss: 2.62649422e-07
Iter: 2009 loss: 2.63814741e-07
Iter: 2010 loss: 2.62631318e-07
Iter: 2011 loss: 2.62566147e-07
Iter: 2012 loss: 2.62491454e-07
Iter: 2013 loss: 2.6246056e-07
Iter: 2014 loss: 2.62377654e-07
Iter: 2015 loss: 2.624366e-07
Iter: 2016 loss: 2.62293952e-07
Iter: 2017 loss: 2.62284374e-07
Iter: 2018 loss: 2.62234607e-07
Iter: 2019 loss: 2.62204765e-07
Iter: 2020 loss: 2.62233499e-07
Iter: 2021 loss: 2.62149399e-07
Iter: 2022 loss: 2.62056204e-07
Iter: 2023 loss: 2.62083972e-07
Iter: 2024 loss: 2.62023661e-07
Iter: 2025 loss: 2.61979267e-07
Iter: 2026 loss: 2.62820976e-07
Iter: 2027 loss: 2.61957382e-07
Iter: 2028 loss: 2.61955734e-07
Iter: 2029 loss: 2.61874419e-07
Iter: 2030 loss: 2.62785e-07
Iter: 2031 loss: 2.61832781e-07
Iter: 2032 loss: 2.61738393e-07
Iter: 2033 loss: 2.62149683e-07
Iter: 2034 loss: 2.61710198e-07
Iter: 2035 loss: 2.61602707e-07
Iter: 2036 loss: 2.62572769e-07
Iter: 2037 loss: 2.61595886e-07
Iter: 2038 loss: 2.61516561e-07
Iter: 2039 loss: 2.61579e-07
Iter: 2040 loss: 2.61496723e-07
Iter: 2041 loss: 2.61394035e-07
Iter: 2042 loss: 2.61419927e-07
Iter: 2043 loss: 2.61321901e-07
Iter: 2044 loss: 2.6120307e-07
Iter: 2045 loss: 2.61823033e-07
Iter: 2046 loss: 2.61191474e-07
Iter: 2047 loss: 2.61088445e-07
Iter: 2048 loss: 2.61086086e-07
Iter: 2049 loss: 2.61051326e-07
Iter: 2050 loss: 2.60963247e-07
Iter: 2051 loss: 2.61322697e-07
Iter: 2052 loss: 2.60929937e-07
Iter: 2053 loss: 2.60862464e-07
Iter: 2054 loss: 2.61150916e-07
Iter: 2055 loss: 2.60857945e-07
Iter: 2056 loss: 2.60730019e-07
Iter: 2057 loss: 2.60672323e-07
Iter: 2058 loss: 2.60675222e-07
Iter: 2059 loss: 2.60563951e-07
Iter: 2060 loss: 2.60578645e-07
Iter: 2061 loss: 2.60488946e-07
Iter: 2062 loss: 2.60528964e-07
Iter: 2063 loss: 2.60437503e-07
Iter: 2064 loss: 2.60370257e-07
Iter: 2065 loss: 2.60249436e-07
Iter: 2066 loss: 2.63147712e-07
Iter: 2067 loss: 2.6024739e-07
Iter: 2068 loss: 2.60107129e-07
Iter: 2069 loss: 2.61608e-07
Iter: 2070 loss: 2.60132936e-07
Iter: 2071 loss: 2.60060517e-07
Iter: 2072 loss: 2.61177178e-07
Iter: 2073 loss: 2.60067793e-07
Iter: 2074 loss: 2.59994067e-07
Iter: 2075 loss: 2.59957687e-07
Iter: 2076 loss: 2.5993586e-07
Iter: 2077 loss: 2.59915964e-07
Iter: 2078 loss: 2.60344e-07
Iter: 2079 loss: 2.59916106e-07
Iter: 2080 loss: 2.59832348e-07
Iter: 2081 loss: 2.59805773e-07
Iter: 2082 loss: 2.59744269e-07
Iter: 2083 loss: 2.59699874e-07
Iter: 2084 loss: 2.59719599e-07
Iter: 2085 loss: 2.59657128e-07
Iter: 2086 loss: 2.59572886e-07
Iter: 2087 loss: 2.59581782e-07
Iter: 2088 loss: 2.59529969e-07
Iter: 2089 loss: 2.59482533e-07
Iter: 2090 loss: 2.59429157e-07
Iter: 2091 loss: 2.59372939e-07
Iter: 2092 loss: 2.59430067e-07
Iter: 2093 loss: 2.59300236e-07
Iter: 2094 loss: 2.59190926e-07
Iter: 2095 loss: 2.59878391e-07
Iter: 2096 loss: 2.59192404e-07
Iter: 2097 loss: 2.59079343e-07
Iter: 2098 loss: 2.59112227e-07
Iter: 2099 loss: 2.590196e-07
Iter: 2100 loss: 2.58898e-07
Iter: 2101 loss: 2.58815476e-07
Iter: 2102 loss: 2.58795239e-07
Iter: 2103 loss: 2.58672515e-07
Iter: 2104 loss: 2.58652648e-07
Iter: 2105 loss: 2.58579036e-07
Iter: 2106 loss: 2.58923478e-07
Iter: 2107 loss: 2.58519322e-07
Iter: 2108 loss: 2.58415952e-07
Iter: 2109 loss: 2.58364224e-07
Iter: 2110 loss: 2.583146e-07
Iter: 2111 loss: 2.58200629e-07
Iter: 2112 loss: 2.58268074e-07
Iter: 2113 loss: 2.582305e-07
Iter: 2114 loss: 2.5829317e-07
Iter: 2115 loss: 2.58160838e-07
Iter: 2116 loss: 2.58067359e-07
Iter: 2117 loss: 2.57962256e-07
Iter: 2118 loss: 2.57908653e-07
Iter: 2119 loss: 2.57932413e-07
Iter: 2120 loss: 2.57874206e-07
Iter: 2121 loss: 2.57844704e-07
Iter: 2122 loss: 2.5775438e-07
Iter: 2123 loss: 2.57725901e-07
Iter: 2124 loss: 2.57627903e-07
Iter: 2125 loss: 2.58565024e-07
Iter: 2126 loss: 2.57617813e-07
Iter: 2127 loss: 2.57567166e-07
Iter: 2128 loss: 2.5769026e-07
Iter: 2129 loss: 2.57526636e-07
Iter: 2130 loss: 2.57492e-07
Iter: 2131 loss: 2.57463256e-07
Iter: 2132 loss: 2.57446e-07
Iter: 2133 loss: 2.57379838e-07
Iter: 2134 loss: 2.5753198e-07
Iter: 2135 loss: 2.57364746e-07
Iter: 2136 loss: 2.57289116e-07
Iter: 2137 loss: 2.57678039e-07
Iter: 2138 loss: 2.57268226e-07
Iter: 2139 loss: 2.5719109e-07
Iter: 2140 loss: 2.57850957e-07
Iter: 2141 loss: 2.57179579e-07
Iter: 2142 loss: 2.57128022e-07
Iter: 2143 loss: 2.57006889e-07
Iter: 2144 loss: 2.58470976e-07
Iter: 2145 loss: 2.56986425e-07
Iter: 2146 loss: 2.56871033e-07
Iter: 2147 loss: 2.57510436e-07
Iter: 2148 loss: 2.56904798e-07
Iter: 2149 loss: 2.56768e-07
Iter: 2150 loss: 2.57346e-07
Iter: 2151 loss: 2.56753538e-07
Iter: 2152 loss: 2.5666489e-07
Iter: 2153 loss: 2.56626265e-07
Iter: 2154 loss: 2.56566949e-07
Iter: 2155 loss: 2.56445077e-07
Iter: 2156 loss: 2.5642359e-07
Iter: 2157 loss: 2.56391189e-07
Iter: 2158 loss: 2.56276763e-07
Iter: 2159 loss: 2.56264144e-07
Iter: 2160 loss: 2.5616356e-07
Iter: 2161 loss: 2.56729209e-07
Iter: 2162 loss: 2.56142016e-07
Iter: 2163 loss: 2.56086565e-07
Iter: 2164 loss: 2.56099469e-07
Iter: 2165 loss: 2.56035406e-07
Iter: 2166 loss: 2.5594548e-07
Iter: 2167 loss: 2.55911374e-07
Iter: 2168 loss: 2.55826251e-07
Iter: 2169 loss: 2.55753946e-07
Iter: 2170 loss: 2.565084e-07
Iter: 2171 loss: 2.55712678e-07
Iter: 2172 loss: 2.55622524e-07
Iter: 2173 loss: 2.56328178e-07
Iter: 2174 loss: 2.5565484e-07
Iter: 2175 loss: 2.55574832e-07
Iter: 2176 loss: 2.55554227e-07
Iter: 2177 loss: 2.55469786e-07
Iter: 2178 loss: 2.5538813e-07
Iter: 2179 loss: 2.55403791e-07
Iter: 2180 loss: 2.55321652e-07
Iter: 2181 loss: 2.55214928e-07
Iter: 2182 loss: 2.55729304e-07
Iter: 2183 loss: 2.55182442e-07
Iter: 2184 loss: 2.55083705e-07
Iter: 2185 loss: 2.55986407e-07
Iter: 2186 loss: 2.55079811e-07
Iter: 2187 loss: 2.55046416e-07
Iter: 2188 loss: 2.55105476e-07
Iter: 2189 loss: 2.54973259e-07
Iter: 2190 loss: 2.54903341e-07
Iter: 2191 loss: 2.54786812e-07
Iter: 2192 loss: 2.54772317e-07
Iter: 2193 loss: 2.54782663e-07
Iter: 2194 loss: 2.54732754e-07
Iter: 2195 loss: 2.54686881e-07
Iter: 2196 loss: 2.54899817e-07
Iter: 2197 loss: 2.54670965e-07
Iter: 2198 loss: 2.54585558e-07
Iter: 2199 loss: 2.54499071e-07
Iter: 2200 loss: 2.54476475e-07
Iter: 2201 loss: 2.54391864e-07
Iter: 2202 loss: 2.55598337e-07
Iter: 2203 loss: 2.54374328e-07
Iter: 2204 loss: 2.54340392e-07
Iter: 2205 loss: 2.54199534e-07
Iter: 2206 loss: 2.57092893e-07
Iter: 2207 loss: 2.54177024e-07
Iter: 2208 loss: 2.5408383e-07
Iter: 2209 loss: 2.54083204e-07
Iter: 2210 loss: 2.54008171e-07
Iter: 2211 loss: 2.53932484e-07
Iter: 2212 loss: 2.53922053e-07
Iter: 2213 loss: 2.53829626e-07
Iter: 2214 loss: 2.53870297e-07
Iter: 2215 loss: 2.53780314e-07
Iter: 2216 loss: 2.53667736e-07
Iter: 2217 loss: 2.54045091e-07
Iter: 2218 loss: 2.53623398e-07
Iter: 2219 loss: 2.53541714e-07
Iter: 2220 loss: 2.54597808e-07
Iter: 2221 loss: 2.53563769e-07
Iter: 2222 loss: 2.53526849e-07
Iter: 2223 loss: 2.53466283e-07
Iter: 2224 loss: 2.53405432e-07
Iter: 2225 loss: 2.53328466e-07
Iter: 2226 loss: 2.53413617e-07
Iter: 2227 loss: 2.53268297e-07
Iter: 2228 loss: 2.53242575e-07
Iter: 2229 loss: 2.53232542e-07
Iter: 2230 loss: 2.53155633e-07
Iter: 2231 loss: 2.53213301e-07
Iter: 2232 loss: 2.53122522e-07
Iter: 2233 loss: 2.53053202e-07
Iter: 2234 loss: 2.53100552e-07
Iter: 2235 loss: 2.53015e-07
Iter: 2236 loss: 2.52959381e-07
Iter: 2237 loss: 2.53542566e-07
Iter: 2238 loss: 2.52979248e-07
Iter: 2239 loss: 2.52909e-07
Iter: 2240 loss: 2.52914845e-07
Iter: 2241 loss: 2.52871303e-07
Iter: 2242 loss: 2.52817927e-07
Iter: 2243 loss: 2.5294753e-07
Iter: 2244 loss: 2.52771343e-07
Iter: 2245 loss: 2.52694718e-07
Iter: 2246 loss: 2.52910525e-07
Iter: 2247 loss: 2.52643645e-07
Iter: 2248 loss: 2.52609567e-07
Iter: 2249 loss: 2.5254252e-07
Iter: 2250 loss: 2.52539735e-07
Iter: 2251 loss: 2.52430027e-07
Iter: 2252 loss: 2.52435711e-07
Iter: 2253 loss: 2.523295e-07
Iter: 2254 loss: 2.5224108e-07
Iter: 2255 loss: 2.52269416e-07
Iter: 2256 loss: 2.52178154e-07
Iter: 2257 loss: 2.52053951e-07
Iter: 2258 loss: 2.53748425e-07
Iter: 2259 loss: 2.52034539e-07
Iter: 2260 loss: 2.51864606e-07
Iter: 2261 loss: 2.5324124e-07
Iter: 2262 loss: 2.51798895e-07
Iter: 2263 loss: 2.51768512e-07
Iter: 2264 loss: 2.51768967e-07
Iter: 2265 loss: 2.51656985e-07
Iter: 2266 loss: 2.51540484e-07
Iter: 2267 loss: 2.51537841e-07
Iter: 2268 loss: 2.51427025e-07
Iter: 2269 loss: 2.51819756e-07
Iter: 2270 loss: 2.51421966e-07
Iter: 2271 loss: 2.51292789e-07
Iter: 2272 loss: 2.51960159e-07
Iter: 2273 loss: 2.51276902e-07
Iter: 2274 loss: 2.51212725e-07
Iter: 2275 loss: 2.51161254e-07
Iter: 2276 loss: 2.51154859e-07
Iter: 2277 loss: 2.51042337e-07
Iter: 2278 loss: 2.52112045e-07
Iter: 2279 loss: 2.51001865e-07
Iter: 2280 loss: 2.50966821e-07
Iter: 2281 loss: 2.5128773e-07
Iter: 2282 loss: 2.50956617e-07
Iter: 2283 loss: 2.50896505e-07
Iter: 2284 loss: 2.50765e-07
Iter: 2285 loss: 2.52587427e-07
Iter: 2286 loss: 2.50773411e-07
Iter: 2287 loss: 2.50691215e-07
Iter: 2288 loss: 2.51811855e-07
Iter: 2289 loss: 2.50687464e-07
Iter: 2290 loss: 2.5061604e-07
Iter: 2291 loss: 2.51200163e-07
Iter: 2292 loss: 2.50593388e-07
Iter: 2293 loss: 2.50538505e-07
Iter: 2294 loss: 2.50424051e-07
Iter: 2295 loss: 2.50423653e-07
Iter: 2296 loss: 2.50344954e-07
Iter: 2297 loss: 2.50535152e-07
Iter: 2298 loss: 2.50282199e-07
Iter: 2299 loss: 2.5030846e-07
Iter: 2300 loss: 2.50267362e-07
Iter: 2301 loss: 2.50274e-07
Iter: 2302 loss: 2.5026867e-07
Iter: 2303 loss: 2.50254658e-07
Iter: 2304 loss: 2.50276258e-07
Iter: 2305 loss: 2.50268897e-07
Iter: 2306 loss: 2.50264918e-07
Iter: 2307 loss: 2.50239765e-07
Iter: 2308 loss: 2.50254146e-07
Iter: 2309 loss: 2.50285211e-07
Iter: 2310 loss: 2.50263241e-07
Iter: 2311 loss: 2.50308688e-07
Iter: 2312 loss: 2.50275917e-07
Iter: 2313 loss: 2.5027245e-07
Iter: 2314 loss: 2.50276514e-07
Iter: 2315 loss: 2.50274411e-07
Iter: 2316 loss: 2.50263554e-07
Iter: 2317 loss: 2.50263213e-07
Iter: 2318 loss: 2.50275775e-07
Iter: 2319 loss: 2.50264918e-07
Iter: 2320 loss: 2.50278163e-07
Iter: 2321 loss: 2.50275832e-07
Iter: 2322 loss: 2.50274582e-07
Iter: 2323 loss: 2.50273558e-07
Iter: 2324 loss: 2.50265202e-07
Iter: 2325 loss: 2.50266e-07
Iter: 2326 loss: 2.50273558e-07
Iter: 2327 loss: 2.50266e-07
Iter: 2328 loss: 2.50082593e-07
Iter: 2329 loss: 2.52567332e-07
Iter: 2330 loss: 2.5009777e-07
Iter: 2331 loss: 2.49987437e-07
Iter: 2332 loss: 2.50019696e-07
Iter: 2333 loss: 2.49946197e-07
Iter: 2334 loss: 2.50062129e-07
Iter: 2335 loss: 2.4987682e-07
Iter: 2336 loss: 2.49823586e-07
Iter: 2337 loss: 2.4983e-07
Iter: 2338 loss: 2.497558e-07
Iter: 2339 loss: 2.49637537e-07
Iter: 2340 loss: 2.50588869e-07
Iter: 2341 loss: 2.49649332e-07
Iter: 2342 loss: 2.49605534e-07
Iter: 2343 loss: 2.49465643e-07
Iter: 2344 loss: 2.4945416e-07
Iter: 2345 loss: 2.49339251e-07
Iter: 2346 loss: 2.49474937e-07
Iter: 2347 loss: 2.49259358e-07
Iter: 2348 loss: 2.49145415e-07
Iter: 2349 loss: 2.491185e-07
Iter: 2350 loss: 2.49061401e-07
Iter: 2351 loss: 2.493029e-07
Iter: 2352 loss: 2.49053642e-07
Iter: 2353 loss: 2.48989977e-07
Iter: 2354 loss: 2.48919406e-07
Iter: 2355 loss: 2.4886188e-07
Iter: 2356 loss: 2.4873853e-07
Iter: 2357 loss: 2.49251087e-07
Iter: 2358 loss: 2.48774256e-07
Iter: 2359 loss: 2.4874879e-07
Iter: 2360 loss: 2.48738957e-07
Iter: 2361 loss: 2.48695869e-07
Iter: 2362 loss: 2.48612707e-07
Iter: 2363 loss: 2.49738719e-07
Iter: 2364 loss: 2.48607734e-07
Iter: 2365 loss: 2.48536196e-07
Iter: 2366 loss: 2.4856584e-07
Iter: 2367 loss: 2.48388972e-07
Iter: 2368 loss: 2.48328064e-07
Iter: 2369 loss: 2.48341564e-07
Iter: 2370 loss: 2.48278099e-07
Iter: 2371 loss: 2.48256981e-07
Iter: 2372 loss: 2.48209403e-07
Iter: 2373 loss: 2.48144715e-07
Iter: 2374 loss: 2.48624588e-07
Iter: 2375 loss: 2.4810393e-07
Iter: 2376 loss: 2.48067266e-07
Iter: 2377 loss: 2.48035377e-07
Iter: 2378 loss: 2.48027646e-07
Iter: 2379 loss: 2.47900175e-07
Iter: 2380 loss: 2.47763836e-07
Iter: 2381 loss: 2.47793423e-07
Iter: 2382 loss: 2.47617777e-07
Iter: 2383 loss: 2.48096171e-07
Iter: 2384 loss: 2.47624911e-07
Iter: 2385 loss: 2.47494313e-07
Iter: 2386 loss: 2.48352819e-07
Iter: 2387 loss: 2.47423088e-07
Iter: 2388 loss: 2.47313039e-07
Iter: 2389 loss: 2.47896082e-07
Iter: 2390 loss: 2.47279218e-07
Iter: 2391 loss: 2.47180481e-07
Iter: 2392 loss: 2.47049485e-07
Iter: 2393 loss: 2.47069295e-07
Iter: 2394 loss: 2.46929062e-07
Iter: 2395 loss: 2.47849613e-07
Iter: 2396 loss: 2.46880717e-07
Iter: 2397 loss: 2.46831746e-07
Iter: 2398 loss: 2.46789966e-07
Iter: 2399 loss: 2.46757565e-07
Iter: 2400 loss: 2.46709789e-07
Iter: 2401 loss: 2.46667355e-07
Iter: 2402 loss: 2.46599114e-07
Iter: 2403 loss: 2.46649961e-07
Iter: 2404 loss: 2.46580868e-07
Iter: 2405 loss: 2.46454e-07
Iter: 2406 loss: 2.46833821e-07
Iter: 2407 loss: 2.46401925e-07
Iter: 2408 loss: 2.46328e-07
Iter: 2409 loss: 2.46599029e-07
Iter: 2410 loss: 2.46306513e-07
Iter: 2411 loss: 2.46254046e-07
Iter: 2412 loss: 2.46412e-07
Iter: 2413 loss: 2.46213602e-07
Iter: 2414 loss: 2.46152354e-07
Iter: 2415 loss: 2.46168042e-07
Iter: 2416 loss: 2.46039178e-07
Iter: 2417 loss: 2.45981141e-07
Iter: 2418 loss: 2.45848383e-07
Iter: 2419 loss: 2.45889197e-07
Iter: 2420 loss: 2.4568709e-07
Iter: 2421 loss: 2.46356791e-07
Iter: 2422 loss: 2.457069e-07
Iter: 2423 loss: 2.45567577e-07
Iter: 2424 loss: 2.45567918e-07
Iter: 2425 loss: 2.45518237e-07
Iter: 2426 loss: 2.45450451e-07
Iter: 2427 loss: 2.45430726e-07
Iter: 2428 loss: 2.4534134e-07
Iter: 2429 loss: 2.45576473e-07
Iter: 2430 loss: 2.45274833e-07
Iter: 2431 loss: 2.45175954e-07
Iter: 2432 loss: 2.45215858e-07
Iter: 2433 loss: 2.45083868e-07
Iter: 2434 loss: 2.45039985e-07
Iter: 2435 loss: 2.45031799e-07
Iter: 2436 loss: 2.44972966e-07
Iter: 2437 loss: 2.4487727e-07
Iter: 2438 loss: 2.4486e-07
Iter: 2439 loss: 2.44753352e-07
Iter: 2440 loss: 2.4488628e-07
Iter: 2441 loss: 2.44737862e-07
Iter: 2442 loss: 2.44634151e-07
Iter: 2443 loss: 2.44817755e-07
Iter: 2444 loss: 2.44577706e-07
Iter: 2445 loss: 2.44444493e-07
Iter: 2446 loss: 2.46074734e-07
Iter: 2447 loss: 2.44435313e-07
Iter: 2448 loss: 2.44402713e-07
Iter: 2449 loss: 2.4434803e-07
Iter: 2450 loss: 2.44374831e-07
Iter: 2451 loss: 2.44279335e-07
Iter: 2452 loss: 2.44956425e-07
Iter: 2453 loss: 2.44275839e-07
Iter: 2454 loss: 2.44176476e-07
Iter: 2455 loss: 2.4423764e-07
Iter: 2456 loss: 2.44128472e-07
Iter: 2457 loss: 2.4405108e-07
Iter: 2458 loss: 2.44155757e-07
Iter: 2459 loss: 2.44035732e-07
Iter: 2460 loss: 2.43885438e-07
Iter: 2461 loss: 2.44533823e-07
Iter: 2462 loss: 2.43894874e-07
Iter: 2463 loss: 2.43805232e-07
Iter: 2464 loss: 2.43712265e-07
Iter: 2465 loss: 2.46362276e-07
Iter: 2466 loss: 2.43707404e-07
Iter: 2467 loss: 2.4358539e-07
Iter: 2468 loss: 2.44990105e-07
Iter: 2469 loss: 2.43610714e-07
Iter: 2470 loss: 2.43510385e-07
Iter: 2471 loss: 2.43916702e-07
Iter: 2472 loss: 2.43547703e-07
Iter: 2473 loss: 2.43436631e-07
Iter: 2474 loss: 2.43271842e-07
Iter: 2475 loss: 2.43298359e-07
Iter: 2476 loss: 2.43160457e-07
Iter: 2477 loss: 2.43534259e-07
Iter: 2478 loss: 2.43097872e-07
Iter: 2479 loss: 2.4294755e-07
Iter: 2480 loss: 2.44885399e-07
Iter: 2481 loss: 2.4295187e-07
Iter: 2482 loss: 2.4285103e-07
Iter: 2483 loss: 2.43227731e-07
Iter: 2484 loss: 2.42862342e-07
Iter: 2485 loss: 2.42754254e-07
Iter: 2486 loss: 2.42680045e-07
Iter: 2487 loss: 2.42675412e-07
Iter: 2488 loss: 2.42534554e-07
Iter: 2489 loss: 2.42536231e-07
Iter: 2490 loss: 2.42472652e-07
Iter: 2491 loss: 2.4242695e-07
Iter: 2492 loss: 2.42389603e-07
Iter: 2493 loss: 2.42250564e-07
Iter: 2494 loss: 2.43195984e-07
Iter: 2495 loss: 2.42281402e-07
Iter: 2496 loss: 2.4210695e-07
Iter: 2497 loss: 2.42453382e-07
Iter: 2498 loss: 2.42089101e-07
Iter: 2499 loss: 2.42004376e-07
Iter: 2500 loss: 2.41946111e-07
Iter: 2501 loss: 2.4189157e-07
Iter: 2502 loss: 2.41829667e-07
Iter: 2503 loss: 2.41772682e-07
Iter: 2504 loss: 2.41711888e-07
Iter: 2505 loss: 2.41679828e-07
Iter: 2506 loss: 2.41640237e-07
Iter: 2507 loss: 2.41570888e-07
Iter: 2508 loss: 2.41454586e-07
Iter: 2509 loss: 2.41434776e-07
Iter: 2510 loss: 2.41360794e-07
Iter: 2511 loss: 2.41805e-07
Iter: 2512 loss: 2.41309493e-07
Iter: 2513 loss: 2.41274819e-07
Iter: 2514 loss: 2.41212859e-07
Iter: 2515 loss: 2.41212547e-07
Iter: 2516 loss: 2.41120972e-07
Iter: 2517 loss: 2.41164742e-07
Iter: 2518 loss: 2.41036645e-07
Iter: 2519 loss: 2.41291559e-07
Iter: 2520 loss: 2.41026726e-07
Iter: 2521 loss: 2.40913778e-07
Iter: 2522 loss: 2.41398084e-07
Iter: 2523 loss: 2.40909458e-07
Iter: 2524 loss: 2.4086583e-07
Iter: 2525 loss: 2.40758311e-07
Iter: 2526 loss: 2.40743788e-07
Iter: 2527 loss: 2.40611939e-07
Iter: 2528 loss: 2.41955462e-07
Iter: 2529 loss: 2.40666e-07
Iter: 2530 loss: 2.40609523e-07
Iter: 2531 loss: 2.40588122e-07
Iter: 2532 loss: 2.40507632e-07
Iter: 2533 loss: 2.40433337e-07
Iter: 2534 loss: 2.40388886e-07
Iter: 2535 loss: 2.40332412e-07
Iter: 2536 loss: 2.40277103e-07
Iter: 2537 loss: 2.40226655e-07
Iter: 2538 loss: 2.4016893e-07
Iter: 2539 loss: 2.40081732e-07
Iter: 2540 loss: 2.42407793e-07
Iter: 2541 loss: 2.40064111e-07
Iter: 2542 loss: 2.39964322e-07
Iter: 2543 loss: 2.39944541e-07
Iter: 2544 loss: 2.39867802e-07
Iter: 2545 loss: 2.39727626e-07
Iter: 2546 loss: 2.39961651e-07
Iter: 2547 loss: 2.39607772e-07
Iter: 2548 loss: 2.39475042e-07
Iter: 2549 loss: 2.39466459e-07
Iter: 2550 loss: 2.39415556e-07
Iter: 2551 loss: 2.39522421e-07
Iter: 2552 loss: 2.39393501e-07
Iter: 2553 loss: 2.39285214e-07
Iter: 2554 loss: 2.39670044e-07
Iter: 2555 loss: 2.39236329e-07
Iter: 2556 loss: 2.39188097e-07
Iter: 2557 loss: 2.39266342e-07
Iter: 2558 loss: 2.39072904e-07
Iter: 2559 loss: 2.38987838e-07
Iter: 2560 loss: 2.39003498e-07
Iter: 2561 loss: 2.38974e-07
Iter: 2562 loss: 2.38881e-07
Iter: 2563 loss: 2.3888316e-07
Iter: 2564 loss: 2.38821428e-07
Iter: 2565 loss: 2.38807104e-07
Iter: 2566 loss: 2.38798e-07
Iter: 2567 loss: 2.38704331e-07
Iter: 2568 loss: 2.3876251e-07
Iter: 2569 loss: 2.38637824e-07
Iter: 2570 loss: 2.38592236e-07
Iter: 2571 loss: 2.38570294e-07
Iter: 2572 loss: 2.38549489e-07
Iter: 2573 loss: 2.38403885e-07
Iter: 2574 loss: 2.40467671e-07
Iter: 2575 loss: 2.38372749e-07
Iter: 2576 loss: 2.3827522e-07
Iter: 2577 loss: 2.38381773e-07
Iter: 2578 loss: 2.38136977e-07
Iter: 2579 loss: 2.38029116e-07
Iter: 2580 loss: 2.39679565e-07
Iter: 2581 loss: 2.38033664e-07
Iter: 2582 loss: 2.37916538e-07
Iter: 2583 loss: 2.38261066e-07
Iter: 2584 loss: 2.37882503e-07
Iter: 2585 loss: 2.37752417e-07
Iter: 2586 loss: 2.37854707e-07
Iter: 2587 loss: 2.37733673e-07
Iter: 2588 loss: 2.37578931e-07
Iter: 2589 loss: 2.38911269e-07
Iter: 2590 loss: 2.37612085e-07
Iter: 2591 loss: 2.37546743e-07
Iter: 2592 loss: 2.37437703e-07
Iter: 2593 loss: 2.37422569e-07
Iter: 2594 loss: 2.37295936e-07
Iter: 2595 loss: 2.37400513e-07
Iter: 2596 loss: 2.37215346e-07
Iter: 2597 loss: 2.37127807e-07
Iter: 2598 loss: 2.37116353e-07
Iter: 2599 loss: 2.37023016e-07
Iter: 2600 loss: 2.36909756e-07
Iter: 2601 loss: 2.36951109e-07
Iter: 2602 loss: 2.36803e-07
Iter: 2603 loss: 2.37971918e-07
Iter: 2604 loss: 2.36800688e-07
Iter: 2605 loss: 2.36745962e-07
Iter: 2606 loss: 2.36725739e-07
Iter: 2607 loss: 2.3668278e-07
Iter: 2608 loss: 2.36579709e-07
Iter: 2609 loss: 2.36709553e-07
Iter: 2610 loss: 2.36475074e-07
Iter: 2611 loss: 2.36377161e-07
Iter: 2612 loss: 2.37033902e-07
Iter: 2613 loss: 2.36354992e-07
Iter: 2614 loss: 2.36244659e-07
Iter: 2615 loss: 2.37077728e-07
Iter: 2616 loss: 2.36197678e-07
Iter: 2617 loss: 2.36142455e-07
Iter: 2618 loss: 2.36184121e-07
Iter: 2619 loss: 2.36147116e-07
Iter: 2620 loss: 2.3605952e-07
Iter: 2621 loss: 2.36722229e-07
Iter: 2622 loss: 2.36065745e-07
Iter: 2623 loss: 2.35972408e-07
Iter: 2624 loss: 2.35955596e-07
Iter: 2625 loss: 2.35903485e-07
Iter: 2626 loss: 2.35786445e-07
Iter: 2627 loss: 2.35759984e-07
Iter: 2628 loss: 2.35714623e-07
Iter: 2629 loss: 2.35584935e-07
Iter: 2630 loss: 2.36480659e-07
Iter: 2631 loss: 2.35565182e-07
Iter: 2632 loss: 2.35445071e-07
Iter: 2633 loss: 2.35795724e-07
Iter: 2634 loss: 2.35381464e-07
Iter: 2635 loss: 2.35299936e-07
Iter: 2636 loss: 2.35364482e-07
Iter: 2637 loss: 2.35193085e-07
Iter: 2638 loss: 2.35114186e-07
Iter: 2639 loss: 2.35102235e-07
Iter: 2640 loss: 2.3496699e-07
Iter: 2641 loss: 2.3481266e-07
Iter: 2642 loss: 2.38616195e-07
Iter: 2643 loss: 2.3480726e-07
Iter: 2644 loss: 2.34684279e-07
Iter: 2645 loss: 2.35756403e-07
Iter: 2646 loss: 2.34666075e-07
Iter: 2647 loss: 2.34562378e-07
Iter: 2648 loss: 2.35147468e-07
Iter: 2649 loss: 2.34546178e-07
Iter: 2650 loss: 2.34427858e-07
Iter: 2651 loss: 2.34569598e-07
Iter: 2652 loss: 2.34393383e-07
Iter: 2653 loss: 2.34297801e-07
Iter: 2654 loss: 2.34353621e-07
Iter: 2655 loss: 2.34223791e-07
Iter: 2656 loss: 2.34090436e-07
Iter: 2657 loss: 2.35488841e-07
Iter: 2658 loss: 2.34108967e-07
Iter: 2659 loss: 2.34001448e-07
Iter: 2660 loss: 2.33952676e-07
Iter: 2661 loss: 2.33928347e-07
Iter: 2662 loss: 2.33803888e-07
Iter: 2663 loss: 2.34013783e-07
Iter: 2664 loss: 2.33729452e-07
Iter: 2665 loss: 2.33614401e-07
Iter: 2666 loss: 2.33626281e-07
Iter: 2667 loss: 2.33569182e-07
Iter: 2668 loss: 2.33542139e-07
Iter: 2669 loss: 2.33481771e-07
Iter: 2670 loss: 2.33420906e-07
Iter: 2671 loss: 2.34123434e-07
Iter: 2672 loss: 2.3341731e-07
Iter: 2673 loss: 2.33334873e-07
Iter: 2674 loss: 2.33460497e-07
Iter: 2675 loss: 2.33299559e-07
Iter: 2676 loss: 2.33238694e-07
Iter: 2677 loss: 2.33277134e-07
Iter: 2678 loss: 2.33161529e-07
Iter: 2679 loss: 2.33124666e-07
Iter: 2680 loss: 2.3395792e-07
Iter: 2681 loss: 2.3309326e-07
Iter: 2682 loss: 2.33030832e-07
Iter: 2683 loss: 2.33121952e-07
Iter: 2684 loss: 2.32948537e-07
Iter: 2685 loss: 2.32907311e-07
Iter: 2686 loss: 2.32852273e-07
Iter: 2687 loss: 2.3278443e-07
Iter: 2688 loss: 2.32694589e-07
Iter: 2689 loss: 2.34001362e-07
Iter: 2690 loss: 2.32655793e-07
Iter: 2691 loss: 2.32562641e-07
Iter: 2692 loss: 2.32458603e-07
Iter: 2693 loss: 2.32445117e-07
Iter: 2694 loss: 2.32294596e-07
Iter: 2695 loss: 2.3229083e-07
Iter: 2696 loss: 2.32136728e-07
Iter: 2697 loss: 2.32004439e-07
Iter: 2698 loss: 2.32017129e-07
Iter: 2699 loss: 2.31836111e-07
Iter: 2700 loss: 2.31831919e-07
Iter: 2701 loss: 2.31712193e-07
Iter: 2702 loss: 2.31587308e-07
Iter: 2703 loss: 2.32333178e-07
Iter: 2704 loss: 2.31544476e-07
Iter: 2705 loss: 2.31347059e-07
Iter: 2706 loss: 2.32275568e-07
Iter: 2707 loss: 2.31348e-07
Iter: 2708 loss: 2.31226196e-07
Iter: 2709 loss: 2.31154189e-07
Iter: 2710 loss: 2.31109624e-07
Iter: 2711 loss: 2.31001295e-07
Iter: 2712 loss: 2.31589524e-07
Iter: 2713 loss: 2.30983972e-07
Iter: 2714 loss: 2.30799088e-07
Iter: 2715 loss: 2.32119916e-07
Iter: 2716 loss: 2.30804972e-07
Iter: 2717 loss: 2.30693331e-07
Iter: 2718 loss: 2.30670878e-07
Iter: 2719 loss: 2.30644986e-07
Iter: 2720 loss: 2.30526723e-07
Iter: 2721 loss: 2.3105909e-07
Iter: 2722 loss: 2.30496639e-07
Iter: 2723 loss: 2.3042702e-07
Iter: 2724 loss: 2.30541119e-07
Iter: 2725 loss: 2.30373416e-07
Iter: 2726 loss: 2.30262643e-07
Iter: 2727 loss: 2.30212947e-07
Iter: 2728 loss: 2.30189642e-07
Iter: 2729 loss: 2.30074008e-07
Iter: 2730 loss: 2.30913201e-07
Iter: 2731 loss: 2.30094045e-07
Iter: 2732 loss: 2.29994924e-07
Iter: 2733 loss: 2.30856898e-07
Iter: 2734 loss: 2.30003721e-07
Iter: 2735 loss: 2.2995917e-07
Iter: 2736 loss: 2.29848411e-07
Iter: 2737 loss: 2.29826099e-07
Iter: 2738 loss: 2.29776163e-07
Iter: 2739 loss: 2.29708647e-07
Iter: 2740 loss: 2.29686407e-07
Iter: 2741 loss: 2.29548647e-07
Iter: 2742 loss: 2.29592359e-07
Iter: 2743 loss: 2.29453917e-07
Iter: 2744 loss: 2.29734709e-07
Iter: 2745 loss: 2.29411398e-07
Iter: 2746 loss: 2.29308341e-07
Iter: 2747 loss: 2.30815985e-07
Iter: 2748 loss: 2.2930017e-07
Iter: 2749 loss: 2.2919896e-07
Iter: 2750 loss: 2.29078466e-07
Iter: 2751 loss: 2.29092947e-07
Iter: 2752 loss: 2.2898665e-07
Iter: 2753 loss: 2.30121259e-07
Iter: 2754 loss: 2.28971061e-07
Iter: 2755 loss: 2.28858596e-07
Iter: 2756 loss: 2.29297598e-07
Iter: 2757 loss: 2.28847739e-07
Iter: 2758 loss: 2.28788338e-07
Iter: 2759 loss: 2.28721674e-07
Iter: 2760 loss: 2.28711414e-07
Iter: 2761 loss: 2.28560509e-07
Iter: 2762 loss: 2.28633866e-07
Iter: 2763 loss: 2.28470356e-07
Iter: 2764 loss: 2.28413455e-07
Iter: 2765 loss: 2.28382405e-07
Iter: 2766 loss: 2.28304472e-07
Iter: 2767 loss: 2.28244915e-07
Iter: 2768 loss: 2.28216962e-07
Iter: 2769 loss: 2.28122829e-07
Iter: 2770 loss: 2.28665257e-07
Iter: 2771 loss: 2.28102479e-07
Iter: 2772 loss: 2.28014159e-07
Iter: 2773 loss: 2.2840257e-07
Iter: 2774 loss: 2.27928638e-07
Iter: 2775 loss: 2.27889245e-07
Iter: 2776 loss: 2.27758591e-07
Iter: 2777 loss: 2.27775729e-07
Iter: 2778 loss: 2.27656173e-07
Iter: 2779 loss: 2.27656926e-07
Iter: 2780 loss: 2.27611437e-07
Iter: 2781 loss: 2.27810403e-07
Iter: 2782 loss: 2.27569984e-07
Iter: 2783 loss: 2.27479958e-07
Iter: 2784 loss: 2.27601618e-07
Iter: 2785 loss: 2.2745995e-07
Iter: 2786 loss: 2.27410084e-07
Iter: 2787 loss: 2.27955923e-07
Iter: 2788 loss: 2.27392803e-07
Iter: 2789 loss: 2.27314445e-07
Iter: 2790 loss: 2.27231681e-07
Iter: 2791 loss: 2.29829737e-07
Iter: 2792 loss: 2.27227346e-07
Iter: 2793 loss: 2.2709969e-07
Iter: 2794 loss: 2.27316377e-07
Iter: 2795 loss: 2.27031705e-07
Iter: 2796 loss: 2.2690223e-07
Iter: 2797 loss: 2.28374887e-07
Iter: 2798 loss: 2.26906195e-07
Iter: 2799 loss: 2.26776791e-07
Iter: 2800 loss: 2.27091647e-07
Iter: 2801 loss: 2.26757265e-07
Iter: 2802 loss: 2.26659893e-07
Iter: 2803 loss: 2.26616748e-07
Iter: 2804 loss: 2.26554306e-07
Iter: 2805 loss: 2.26440676e-07
Iter: 2806 loss: 2.28127362e-07
Iter: 2807 loss: 2.26434651e-07
Iter: 2808 loss: 2.26331565e-07
Iter: 2809 loss: 2.26237489e-07
Iter: 2810 loss: 2.26195795e-07
Iter: 2811 loss: 2.26097129e-07
Iter: 2812 loss: 2.26683653e-07
Iter: 2813 loss: 2.26063236e-07
Iter: 2814 loss: 2.25993347e-07
Iter: 2815 loss: 2.25976166e-07
Iter: 2816 loss: 2.25913567e-07
Iter: 2817 loss: 2.25798075e-07
Iter: 2818 loss: 2.28048918e-07
Iter: 2819 loss: 2.25816336e-07
Iter: 2820 loss: 2.25717969e-07
Iter: 2821 loss: 2.27159234e-07
Iter: 2822 loss: 2.25729707e-07
Iter: 2823 loss: 2.25651007e-07
Iter: 2824 loss: 2.258233e-07
Iter: 2825 loss: 2.25634182e-07
Iter: 2826 loss: 2.25525383e-07
Iter: 2827 loss: 2.25478317e-07
Iter: 2828 loss: 2.25484399e-07
Iter: 2829 loss: 2.2539335e-07
Iter: 2830 loss: 2.25479909e-07
Iter: 2831 loss: 2.25357311e-07
Iter: 2832 loss: 2.25313528e-07
Iter: 2833 loss: 2.25280843e-07
Iter: 2834 loss: 2.25203536e-07
Iter: 2835 loss: 2.25161557e-07
Iter: 2836 loss: 2.25151226e-07
Iter: 2837 loss: 2.25115883e-07
Iter: 2838 loss: 2.25766016e-07
Iter: 2839 loss: 2.25093075e-07
Iter: 2840 loss: 2.25032522e-07
Iter: 2841 loss: 2.25039358e-07
Iter: 2842 loss: 2.25006019e-07
Iter: 2843 loss: 2.24937679e-07
Iter: 2844 loss: 2.24897846e-07
Iter: 2845 loss: 2.2486941e-07
Iter: 2846 loss: 2.24777452e-07
Iter: 2847 loss: 2.25147915e-07
Iter: 2848 loss: 2.2472608e-07
Iter: 2849 loss: 2.24641127e-07
Iter: 2850 loss: 2.253567e-07
Iter: 2851 loss: 2.24628707e-07
Iter: 2852 loss: 2.24555961e-07
Iter: 2853 loss: 2.24505271e-07
Iter: 2854 loss: 2.26043653e-07
Iter: 2855 loss: 2.24470725e-07
Iter: 2856 loss: 2.24372599e-07
Iter: 2857 loss: 2.25004641e-07
Iter: 2858 loss: 2.24356754e-07
Iter: 2859 loss: 2.24278907e-07
Iter: 2860 loss: 2.24755752e-07
Iter: 2861 loss: 2.24249945e-07
Iter: 2862 loss: 2.24168744e-07
Iter: 2863 loss: 2.24181747e-07
Iter: 2864 loss: 2.241147e-07
Iter: 2865 loss: 2.24050154e-07
Iter: 2866 loss: 2.2422951e-07
Iter: 2867 loss: 2.23991762e-07
Iter: 2868 loss: 2.2393553e-07
Iter: 2869 loss: 2.23934833e-07
Iter: 2870 loss: 2.23869563e-07
Iter: 2871 loss: 2.23822639e-07
Iter: 2872 loss: 2.23805671e-07
Iter: 2873 loss: 2.23739434e-07
Iter: 2874 loss: 2.24310782e-07
Iter: 2875 loss: 2.2372231e-07
Iter: 2876 loss: 2.2363281e-07
Iter: 2877 loss: 2.23830909e-07
Iter: 2878 loss: 2.23606293e-07
Iter: 2879 loss: 2.23600864e-07
Iter: 2880 loss: 2.23497651e-07
Iter: 2881 loss: 2.23487888e-07
Iter: 2882 loss: 2.23442129e-07
Iter: 2883 loss: 2.23454776e-07
Iter: 2884 loss: 2.23401855e-07
Iter: 2885 loss: 2.23519365e-07
Iter: 2886 loss: 2.233174e-07
Iter: 2887 loss: 2.23273645e-07
Iter: 2888 loss: 2.23351265e-07
Iter: 2889 loss: 2.23224049e-07
Iter: 2890 loss: 2.23198427e-07
Iter: 2891 loss: 2.23499612e-07
Iter: 2892 loss: 2.23170986e-07
Iter: 2893 loss: 2.23117212e-07
Iter: 2894 loss: 2.23148191e-07
Iter: 2895 loss: 2.23099732e-07
Iter: 2896 loss: 2.23017878e-07
Iter: 2897 loss: 2.23060141e-07
Iter: 2898 loss: 2.22948543e-07
Iter: 2899 loss: 2.22865282e-07
Iter: 2900 loss: 2.23024813e-07
Iter: 2901 loss: 2.22842303e-07
Iter: 2902 loss: 2.2274142e-07
Iter: 2903 loss: 2.22753869e-07
Iter: 2904 loss: 2.22720132e-07
Iter: 2905 loss: 2.22649291e-07
Iter: 2906 loss: 2.22639414e-07
Iter: 2907 loss: 2.22536357e-07
Iter: 2908 loss: 2.2356005e-07
Iter: 2909 loss: 2.22538603e-07
Iter: 2910 loss: 2.22471243e-07
Iter: 2911 loss: 2.22462205e-07
Iter: 2912 loss: 2.22394334e-07
Iter: 2913 loss: 2.22321248e-07
Iter: 2914 loss: 2.22306028e-07
Iter: 2915 loss: 2.22259928e-07
Iter: 2916 loss: 2.2219524e-07
Iter: 2917 loss: 2.22821086e-07
Iter: 2918 loss: 2.22209223e-07
Iter: 2919 loss: 2.22113101e-07
Iter: 2920 loss: 2.2223324e-07
Iter: 2921 loss: 2.22059583e-07
Iter: 2922 loss: 2.22036277e-07
Iter: 2923 loss: 2.22469197e-07
Iter: 2924 loss: 2.22004303e-07
Iter: 2925 loss: 2.21947289e-07
Iter: 2926 loss: 2.22000523e-07
Iter: 2927 loss: 2.21932908e-07
Iter: 2928 loss: 2.21895206e-07
Iter: 2929 loss: 2.21963774e-07
Iter: 2930 loss: 2.21872227e-07
Iter: 2931 loss: 2.2178493e-07
Iter: 2932 loss: 2.21909076e-07
Iter: 2933 loss: 2.21799951e-07
Iter: 2934 loss: 2.21713549e-07
Iter: 2935 loss: 2.22146127e-07
Iter: 2936 loss: 2.21702123e-07
Iter: 2937 loss: 2.21678022e-07
Iter: 2938 loss: 2.21966843e-07
Iter: 2939 loss: 2.21640661e-07
Iter: 2940 loss: 2.21629534e-07
Iter: 2941 loss: 2.21563084e-07
Iter: 2942 loss: 2.21565e-07
Iter: 2943 loss: 2.21533739e-07
Iter: 2944 loss: 2.21555609e-07
Iter: 2945 loss: 2.21467488e-07
Iter: 2946 loss: 2.21473414e-07
Iter: 2947 loss: 2.21456048e-07
Iter: 2948 loss: 2.21366605e-07
Iter: 2949 loss: 2.21567916e-07
Iter: 2950 loss: 2.21357837e-07
Iter: 2951 loss: 2.21278697e-07
Iter: 2952 loss: 2.21466593e-07
Iter: 2953 loss: 2.21270938e-07
Iter: 2954 loss: 2.21230152e-07
Iter: 2955 loss: 2.2122066e-07
Iter: 2956 loss: 2.21195734e-07
Iter: 2957 loss: 2.21105992e-07
Iter: 2958 loss: 2.21672963e-07
Iter: 2959 loss: 2.21133206e-07
Iter: 2960 loss: 2.21084e-07
Iter: 2961 loss: 2.21034554e-07
Iter: 2962 loss: 2.20984859e-07
Iter: 2963 loss: 2.20911986e-07
Iter: 2964 loss: 2.21189524e-07
Iter: 2965 loss: 2.20914643e-07
Iter: 2966 loss: 2.20886278e-07
Iter: 2967 loss: 2.21204687e-07
Iter: 2968 loss: 2.20834821e-07
Iter: 2969 loss: 2.2079945e-07
Iter: 2970 loss: 2.2117348e-07
Iter: 2971 loss: 2.20778873e-07
Iter: 2972 loss: 2.20745108e-07
Iter: 2973 loss: 2.20708088e-07
Iter: 2974 loss: 2.20698155e-07
Iter: 2975 loss: 2.20640601e-07
Iter: 2976 loss: 2.20723152e-07
Iter: 2977 loss: 2.20601081e-07
Iter: 2978 loss: 2.2058569e-07
Iter: 2979 loss: 2.20566506e-07
Iter: 2980 loss: 2.20542e-07
Iter: 2981 loss: 2.2051006e-07
Iter: 2982 loss: 2.20512845e-07
Iter: 2983 loss: 2.20440597e-07
Iter: 2984 loss: 2.20955016e-07
Iter: 2985 loss: 2.2045549e-07
Iter: 2986 loss: 2.2045856e-07
Iter: 2987 loss: 2.20453103e-07
Iter: 2988 loss: 2.20431616e-07
Iter: 2989 loss: 2.20440413e-07
Iter: 2990 loss: 2.20436618e-07
Iter: 2991 loss: 2.20432312e-07
Iter: 2992 loss: 2.20425278e-07
Iter: 2993 loss: 2.20434075e-07
Iter: 2994 loss: 2.20445244e-07
Iter: 2995 loss: 2.20423601e-07
Iter: 2996 loss: 2.20452449e-07
Iter: 2997 loss: 2.20450175e-07
Iter: 2998 loss: 2.2044199e-07
Iter: 2999 loss: 2.20450133e-07
Iter: 3000 loss: 2.20459583e-07
Iter: 3001 loss: 2.20446964e-07
Iter: 3002 loss: 2.20451057e-07
Iter: 3003 loss: 2.20454609e-07
Iter: 3004 loss: 2.20455206e-07
Iter: 3005 loss: 2.20460194e-07
Iter: 3006 loss: 2.20457849e-07
Iter: 3007 loss: 2.2045576e-07
Iter: 3008 loss: 2.20455988e-07
Iter: 3009 loss: 2.2045549e-07
Iter: 3010 loss: 2.20455732e-07
Iter: 3011 loss: 2.2045549e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_4000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_4000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c319510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c31e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c3ea840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c338e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c2ced90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c3ea048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c3ea378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c2728c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c272620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c1cc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c1cc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c1cc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c197d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c1601e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c170f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c1706a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c12dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c0ba840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c12da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c09e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18c05b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1856902f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1856756a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18563ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18563eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18561af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1855b8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18563e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1855771e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18559a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd185592510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18555b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd18554f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1854fc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1854b3268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1854ddf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.23230279e-06
Iter: 2 loss: 2.18874357e-06
Iter: 3 loss: 2.03205263e-06
Iter: 4 loss: 1.61864364e-06
Iter: 5 loss: 3.06870425e-06
Iter: 6 loss: 1.51079917e-06
Iter: 7 loss: 1.32983769e-06
Iter: 8 loss: 2.79023288e-06
Iter: 9 loss: 1.31806041e-06
Iter: 10 loss: 1.18945559e-06
Iter: 11 loss: 1.19470417e-06
Iter: 12 loss: 1.08813242e-06
Iter: 13 loss: 1.01205615e-06
Iter: 14 loss: 1.01188016e-06
Iter: 15 loss: 9.52806374e-07
Iter: 16 loss: 9.48835e-07
Iter: 17 loss: 9.04300464e-07
Iter: 18 loss: 8.82364418e-07
Iter: 19 loss: 1.03521529e-06
Iter: 20 loss: 8.80355628e-07
Iter: 21 loss: 8.6797985e-07
Iter: 22 loss: 9.75614284e-07
Iter: 23 loss: 8.67307449e-07
Iter: 24 loss: 8.55836106e-07
Iter: 25 loss: 8.57175166e-07
Iter: 26 loss: 8.46978423e-07
Iter: 27 loss: 8.34437969e-07
Iter: 28 loss: 8.30824206e-07
Iter: 29 loss: 8.23237656e-07
Iter: 30 loss: 8.11479708e-07
Iter: 31 loss: 8.87150691e-07
Iter: 32 loss: 8.10182541e-07
Iter: 33 loss: 7.99825e-07
Iter: 34 loss: 8.23896e-07
Iter: 35 loss: 7.95978622e-07
Iter: 36 loss: 7.86999919e-07
Iter: 37 loss: 7.99560553e-07
Iter: 38 loss: 7.82499342e-07
Iter: 39 loss: 7.82088819e-07
Iter: 40 loss: 7.79521201e-07
Iter: 41 loss: 7.75994067e-07
Iter: 42 loss: 7.72372346e-07
Iter: 43 loss: 7.71674763e-07
Iter: 44 loss: 7.67057372e-07
Iter: 45 loss: 8.12397332e-07
Iter: 46 loss: 7.66908954e-07
Iter: 47 loss: 7.62910474e-07
Iter: 48 loss: 7.61465344e-07
Iter: 49 loss: 7.59189447e-07
Iter: 50 loss: 7.53771e-07
Iter: 51 loss: 7.7660269e-07
Iter: 52 loss: 7.52607434e-07
Iter: 53 loss: 7.46126489e-07
Iter: 54 loss: 7.52528877e-07
Iter: 55 loss: 7.42453437e-07
Iter: 56 loss: 7.36813263e-07
Iter: 57 loss: 7.26236635e-07
Iter: 58 loss: 9.60719376e-07
Iter: 59 loss: 7.26196959e-07
Iter: 60 loss: 7.21006245e-07
Iter: 61 loss: 7.19309526e-07
Iter: 62 loss: 7.13700103e-07
Iter: 63 loss: 7.18968408e-07
Iter: 64 loss: 7.10507152e-07
Iter: 65 loss: 7.05931427e-07
Iter: 66 loss: 7.08299808e-07
Iter: 67 loss: 7.02937314e-07
Iter: 68 loss: 6.97888879e-07
Iter: 69 loss: 7.12838755e-07
Iter: 70 loss: 6.96392419e-07
Iter: 71 loss: 6.93044854e-07
Iter: 72 loss: 7.05499701e-07
Iter: 73 loss: 6.92261665e-07
Iter: 74 loss: 6.88961563e-07
Iter: 75 loss: 7.10467646e-07
Iter: 76 loss: 6.88645855e-07
Iter: 77 loss: 6.86650708e-07
Iter: 78 loss: 6.86612168e-07
Iter: 79 loss: 6.85600526e-07
Iter: 80 loss: 6.83927624e-07
Iter: 81 loss: 6.83922963e-07
Iter: 82 loss: 6.81838287e-07
Iter: 83 loss: 7.05323146e-07
Iter: 84 loss: 6.81828396e-07
Iter: 85 loss: 6.80700509e-07
Iter: 86 loss: 6.79632649e-07
Iter: 87 loss: 6.79423124e-07
Iter: 88 loss: 6.77220214e-07
Iter: 89 loss: 6.92615231e-07
Iter: 90 loss: 6.77027117e-07
Iter: 91 loss: 6.76098125e-07
Iter: 92 loss: 6.74638272e-07
Iter: 93 loss: 6.74584214e-07
Iter: 94 loss: 6.73254362e-07
Iter: 95 loss: 6.89737135e-07
Iter: 96 loss: 6.73286877e-07
Iter: 97 loss: 6.71952648e-07
Iter: 98 loss: 6.74509636e-07
Iter: 99 loss: 6.71380917e-07
Iter: 100 loss: 6.6992e-07
Iter: 101 loss: 6.690384e-07
Iter: 102 loss: 6.68441885e-07
Iter: 103 loss: 6.66631479e-07
Iter: 104 loss: 6.6364197e-07
Iter: 105 loss: 6.63636797e-07
Iter: 106 loss: 6.6066616e-07
Iter: 107 loss: 6.60650699e-07
Iter: 108 loss: 6.58939939e-07
Iter: 109 loss: 6.72848444e-07
Iter: 110 loss: 6.58776173e-07
Iter: 111 loss: 6.56954853e-07
Iter: 112 loss: 6.61292631e-07
Iter: 113 loss: 6.56262046e-07
Iter: 114 loss: 6.55065833e-07
Iter: 115 loss: 6.56461907e-07
Iter: 116 loss: 6.54461587e-07
Iter: 117 loss: 6.53108714e-07
Iter: 118 loss: 6.65648145e-07
Iter: 119 loss: 6.5309348e-07
Iter: 120 loss: 6.52682161e-07
Iter: 121 loss: 6.53683e-07
Iter: 122 loss: 6.52574784e-07
Iter: 123 loss: 6.520076e-07
Iter: 124 loss: 6.52289827e-07
Iter: 125 loss: 6.51691e-07
Iter: 126 loss: 6.51180358e-07
Iter: 127 loss: 6.52338372e-07
Iter: 128 loss: 6.50983225e-07
Iter: 129 loss: 6.50641937e-07
Iter: 130 loss: 6.51568882e-07
Iter: 131 loss: 6.50543598e-07
Iter: 132 loss: 6.50060201e-07
Iter: 133 loss: 6.51348842e-07
Iter: 134 loss: 6.49853519e-07
Iter: 135 loss: 6.49452e-07
Iter: 136 loss: 6.48486377e-07
Iter: 137 loss: 6.61183435e-07
Iter: 138 loss: 6.4842e-07
Iter: 139 loss: 6.47155161e-07
Iter: 140 loss: 6.53475183e-07
Iter: 141 loss: 6.46998956e-07
Iter: 142 loss: 6.45723958e-07
Iter: 143 loss: 6.46733497e-07
Iter: 144 loss: 6.44970441e-07
Iter: 145 loss: 6.44495344e-07
Iter: 146 loss: 6.44209479e-07
Iter: 147 loss: 6.43421231e-07
Iter: 148 loss: 6.43020883e-07
Iter: 149 loss: 6.42661234e-07
Iter: 150 loss: 6.42177952e-07
Iter: 151 loss: 6.4638175e-07
Iter: 152 loss: 6.42137081e-07
Iter: 153 loss: 6.41578254e-07
Iter: 154 loss: 6.41679e-07
Iter: 155 loss: 6.41150848e-07
Iter: 156 loss: 6.40546e-07
Iter: 157 loss: 6.43776502e-07
Iter: 158 loss: 6.40462304e-07
Iter: 159 loss: 6.40056783e-07
Iter: 160 loss: 6.4259018e-07
Iter: 161 loss: 6.40026315e-07
Iter: 162 loss: 6.39711175e-07
Iter: 163 loss: 6.39166046e-07
Iter: 164 loss: 6.48972559e-07
Iter: 165 loss: 6.3916832e-07
Iter: 166 loss: 6.38612505e-07
Iter: 167 loss: 6.45067075e-07
Iter: 168 loss: 6.38582264e-07
Iter: 169 loss: 6.38062e-07
Iter: 170 loss: 6.39454754e-07
Iter: 171 loss: 6.37893038e-07
Iter: 172 loss: 6.37439143e-07
Iter: 173 loss: 6.37695621e-07
Iter: 174 loss: 6.37185792e-07
Iter: 175 loss: 6.36684376e-07
Iter: 176 loss: 6.36849165e-07
Iter: 177 loss: 6.36346272e-07
Iter: 178 loss: 6.35833885e-07
Iter: 179 loss: 6.36857067e-07
Iter: 180 loss: 6.35628624e-07
Iter: 181 loss: 6.3580751e-07
Iter: 182 loss: 6.3544519e-07
Iter: 183 loss: 6.35256e-07
Iter: 184 loss: 6.34847652e-07
Iter: 185 loss: 6.40372718e-07
Iter: 186 loss: 6.34806099e-07
Iter: 187 loss: 6.34454125e-07
Iter: 188 loss: 6.37407197e-07
Iter: 189 loss: 6.34428488e-07
Iter: 190 loss: 6.34099138e-07
Iter: 191 loss: 6.3587629e-07
Iter: 192 loss: 6.34049286e-07
Iter: 193 loss: 6.33735681e-07
Iter: 194 loss: 6.33365971e-07
Iter: 195 loss: 6.33372395e-07
Iter: 196 loss: 6.32799868e-07
Iter: 197 loss: 6.38035374e-07
Iter: 198 loss: 6.32773379e-07
Iter: 199 loss: 6.32513718e-07
Iter: 200 loss: 6.31847911e-07
Iter: 201 loss: 6.40125791e-07
Iter: 202 loss: 6.31818921e-07
Iter: 203 loss: 6.31491332e-07
Iter: 204 loss: 6.31387081e-07
Iter: 205 loss: 6.31076e-07
Iter: 206 loss: 6.31650778e-07
Iter: 207 loss: 6.30950126e-07
Iter: 208 loss: 6.3061367e-07
Iter: 209 loss: 6.30205136e-07
Iter: 210 loss: 6.30181262e-07
Iter: 211 loss: 6.29613737e-07
Iter: 212 loss: 6.30370607e-07
Iter: 213 loss: 6.29360215e-07
Iter: 214 loss: 6.28827536e-07
Iter: 215 loss: 6.32296803e-07
Iter: 216 loss: 6.28776888e-07
Iter: 217 loss: 6.28355622e-07
Iter: 218 loss: 6.3067796e-07
Iter: 219 loss: 6.28335442e-07
Iter: 220 loss: 6.27899112e-07
Iter: 221 loss: 6.31473767e-07
Iter: 222 loss: 6.27854e-07
Iter: 223 loss: 6.27670659e-07
Iter: 224 loss: 6.27218242e-07
Iter: 225 loss: 6.350582e-07
Iter: 226 loss: 6.2724348e-07
Iter: 227 loss: 6.2700235e-07
Iter: 228 loss: 6.26975066e-07
Iter: 229 loss: 6.26811072e-07
Iter: 230 loss: 6.26454153e-07
Iter: 231 loss: 6.30314275e-07
Iter: 232 loss: 6.26410554e-07
Iter: 233 loss: 6.26160727e-07
Iter: 234 loss: 6.26170731e-07
Iter: 235 loss: 6.25973485e-07
Iter: 236 loss: 6.2625935e-07
Iter: 237 loss: 6.2584536e-07
Iter: 238 loss: 6.25655389e-07
Iter: 239 loss: 6.25324901e-07
Iter: 240 loss: 6.25304e-07
Iter: 241 loss: 6.2496639e-07
Iter: 242 loss: 6.28423493e-07
Iter: 243 loss: 6.24972756e-07
Iter: 244 loss: 6.24688369e-07
Iter: 245 loss: 6.27440784e-07
Iter: 246 loss: 6.24695303e-07
Iter: 247 loss: 6.24500558e-07
Iter: 248 loss: 6.24109703e-07
Iter: 249 loss: 6.31588932e-07
Iter: 250 loss: 6.24075824e-07
Iter: 251 loss: 6.23548772e-07
Iter: 252 loss: 6.25391635e-07
Iter: 253 loss: 6.23461688e-07
Iter: 254 loss: 6.23134042e-07
Iter: 255 loss: 6.23143194e-07
Iter: 256 loss: 6.22826462e-07
Iter: 257 loss: 6.2261131e-07
Iter: 258 loss: 6.22489e-07
Iter: 259 loss: 6.22210052e-07
Iter: 260 loss: 6.23545588e-07
Iter: 261 loss: 6.22157529e-07
Iter: 262 loss: 6.21899858e-07
Iter: 263 loss: 6.23863514e-07
Iter: 264 loss: 6.21862796e-07
Iter: 265 loss: 6.21694426e-07
Iter: 266 loss: 6.21529807e-07
Iter: 267 loss: 6.21531626e-07
Iter: 268 loss: 6.21272875e-07
Iter: 269 loss: 6.23865e-07
Iter: 270 loss: 6.21317e-07
Iter: 271 loss: 6.21063236e-07
Iter: 272 loss: 6.20683522e-07
Iter: 273 loss: 6.29843782e-07
Iter: 274 loss: 6.2066988e-07
Iter: 275 loss: 6.20277035e-07
Iter: 276 loss: 6.2142658e-07
Iter: 277 loss: 6.20208709e-07
Iter: 278 loss: 6.19812909e-07
Iter: 279 loss: 6.22289747e-07
Iter: 280 loss: 6.19792274e-07
Iter: 281 loss: 6.19434331e-07
Iter: 282 loss: 6.19928926e-07
Iter: 283 loss: 6.19219236e-07
Iter: 284 loss: 6.18883405e-07
Iter: 285 loss: 6.19206162e-07
Iter: 286 loss: 6.18647107e-07
Iter: 287 loss: 6.1840251e-07
Iter: 288 loss: 6.20292781e-07
Iter: 289 loss: 6.1838341e-07
Iter: 290 loss: 6.18128183e-07
Iter: 291 loss: 6.1971889e-07
Iter: 292 loss: 6.18120453e-07
Iter: 293 loss: 6.17925366e-07
Iter: 294 loss: 6.1768452e-07
Iter: 295 loss: 6.17668775e-07
Iter: 296 loss: 6.17526553e-07
Iter: 297 loss: 6.1749455e-07
Iter: 298 loss: 6.17365174e-07
Iter: 299 loss: 6.17304295e-07
Iter: 300 loss: 6.17239721e-07
Iter: 301 loss: 6.17013e-07
Iter: 302 loss: 6.16748423e-07
Iter: 303 loss: 6.16758257e-07
Iter: 304 loss: 6.16343527e-07
Iter: 305 loss: 6.1637752e-07
Iter: 306 loss: 6.16144689e-07
Iter: 307 loss: 6.15711656e-07
Iter: 308 loss: 6.21845402e-07
Iter: 309 loss: 6.15662714e-07
Iter: 310 loss: 6.15160616e-07
Iter: 311 loss: 6.17896e-07
Iter: 312 loss: 6.15057274e-07
Iter: 313 loss: 6.14652777e-07
Iter: 314 loss: 6.19208436e-07
Iter: 315 loss: 6.14660905e-07
Iter: 316 loss: 6.14391752e-07
Iter: 317 loss: 6.14637656e-07
Iter: 318 loss: 6.14245096e-07
Iter: 319 loss: 6.14005955e-07
Iter: 320 loss: 6.14066664e-07
Iter: 321 loss: 6.13851171e-07
Iter: 322 loss: 6.13718839e-07
Iter: 323 loss: 6.13664497e-07
Iter: 324 loss: 6.1358719e-07
Iter: 325 loss: 6.13366581e-07
Iter: 326 loss: 6.17788942e-07
Iter: 327 loss: 6.13339e-07
Iter: 328 loss: 6.1319156e-07
Iter: 329 loss: 6.15062049e-07
Iter: 330 loss: 6.13137786e-07
Iter: 331 loss: 6.13002385e-07
Iter: 332 loss: 6.13271652e-07
Iter: 333 loss: 6.12954864e-07
Iter: 334 loss: 6.12758299e-07
Iter: 335 loss: 6.12480562e-07
Iter: 336 loss: 6.12471e-07
Iter: 337 loss: 6.12270128e-07
Iter: 338 loss: 6.12278313e-07
Iter: 339 loss: 6.12030931e-07
Iter: 340 loss: 6.1195874e-07
Iter: 341 loss: 6.11782298e-07
Iter: 342 loss: 6.11588e-07
Iter: 343 loss: 6.11617565e-07
Iter: 344 loss: 6.11385076e-07
Iter: 345 loss: 6.11095061e-07
Iter: 346 loss: 6.14542955e-07
Iter: 347 loss: 6.1109688e-07
Iter: 348 loss: 6.10867232e-07
Iter: 349 loss: 6.11261385e-07
Iter: 350 loss: 6.10730467e-07
Iter: 351 loss: 6.10506561e-07
Iter: 352 loss: 6.1025213e-07
Iter: 353 loss: 6.10165614e-07
Iter: 354 loss: 6.10023903e-07
Iter: 355 loss: 6.10005372e-07
Iter: 356 loss: 6.09781466e-07
Iter: 357 loss: 6.09674885e-07
Iter: 358 loss: 6.09569156e-07
Iter: 359 loss: 6.09325411e-07
Iter: 360 loss: 6.09736901e-07
Iter: 361 loss: 6.09220137e-07
Iter: 362 loss: 6.09006293e-07
Iter: 363 loss: 6.11648943e-07
Iter: 364 loss: 6.0896258e-07
Iter: 365 loss: 6.08777725e-07
Iter: 366 loss: 6.08564505e-07
Iter: 367 loss: 6.08511357e-07
Iter: 368 loss: 6.08259597e-07
Iter: 369 loss: 6.08549726e-07
Iter: 370 loss: 6.08082928e-07
Iter: 371 loss: 6.07899722e-07
Iter: 372 loss: 6.07894435e-07
Iter: 373 loss: 6.07740617e-07
Iter: 374 loss: 6.07620336e-07
Iter: 375 loss: 6.07576226e-07
Iter: 376 loss: 6.07376137e-07
Iter: 377 loss: 6.07521088e-07
Iter: 378 loss: 6.07206516e-07
Iter: 379 loss: 6.07069751e-07
Iter: 380 loss: 6.07074526e-07
Iter: 381 loss: 6.06885067e-07
Iter: 382 loss: 6.06755e-07
Iter: 383 loss: 6.06671847e-07
Iter: 384 loss: 6.06447088e-07
Iter: 385 loss: 6.06421054e-07
Iter: 386 loss: 6.06263256e-07
Iter: 387 loss: 6.05983814e-07
Iter: 388 loss: 6.06002118e-07
Iter: 389 loss: 6.05835567e-07
Iter: 390 loss: 6.05462446e-07
Iter: 391 loss: 6.1321748e-07
Iter: 392 loss: 6.0548274e-07
Iter: 393 loss: 6.05211369e-07
Iter: 394 loss: 6.08219864e-07
Iter: 395 loss: 6.05202672e-07
Iter: 396 loss: 6.04933462e-07
Iter: 397 loss: 6.05006335e-07
Iter: 398 loss: 6.04707054e-07
Iter: 399 loss: 6.04460695e-07
Iter: 400 loss: 6.04204615e-07
Iter: 401 loss: 6.04129696e-07
Iter: 402 loss: 6.03800345e-07
Iter: 403 loss: 6.06153549e-07
Iter: 404 loss: 6.03806484e-07
Iter: 405 loss: 6.03559329e-07
Iter: 406 loss: 6.05640707e-07
Iter: 407 loss: 6.03549552e-07
Iter: 408 loss: 6.03352476e-07
Iter: 409 loss: 6.03408637e-07
Iter: 410 loss: 6.03217416e-07
Iter: 411 loss: 6.03013518e-07
Iter: 412 loss: 6.02932232e-07
Iter: 413 loss: 6.02810758e-07
Iter: 414 loss: 6.02632781e-07
Iter: 415 loss: 6.02593786e-07
Iter: 416 loss: 6.02491127e-07
Iter: 417 loss: 6.02174907e-07
Iter: 418 loss: 6.07703043e-07
Iter: 419 loss: 6.02197701e-07
Iter: 420 loss: 6.02040302e-07
Iter: 421 loss: 6.02025e-07
Iter: 422 loss: 6.01872216e-07
Iter: 423 loss: 6.02029957e-07
Iter: 424 loss: 6.01783313e-07
Iter: 425 loss: 6.01627335e-07
Iter: 426 loss: 6.01651664e-07
Iter: 427 loss: 6.01513591e-07
Iter: 428 loss: 6.01313445e-07
Iter: 429 loss: 6.03339345e-07
Iter: 430 loss: 6.01338456e-07
Iter: 431 loss: 6.01158717e-07
Iter: 432 loss: 6.01028091e-07
Iter: 433 loss: 6.0101047e-07
Iter: 434 loss: 6.00888029e-07
Iter: 435 loss: 6.00931685e-07
Iter: 436 loss: 6.00769113e-07
Iter: 437 loss: 6.00460226e-07
Iter: 438 loss: 6.00625754e-07
Iter: 439 loss: 6.00249223e-07
Iter: 440 loss: 6.00006786e-07
Iter: 441 loss: 6.00006729e-07
Iter: 442 loss: 5.99769521e-07
Iter: 443 loss: 5.99756163e-07
Iter: 444 loss: 5.99560167e-07
Iter: 445 loss: 5.99275211e-07
Iter: 446 loss: 5.98794372e-07
Iter: 447 loss: 5.98759e-07
Iter: 448 loss: 5.98387e-07
Iter: 449 loss: 5.98383735e-07
Iter: 450 loss: 5.98113274e-07
Iter: 451 loss: 6.00861142e-07
Iter: 452 loss: 5.98157044e-07
Iter: 453 loss: 5.97975827e-07
Iter: 454 loss: 5.97970484e-07
Iter: 455 loss: 5.97780286e-07
Iter: 456 loss: 5.97679048e-07
Iter: 457 loss: 5.97643862e-07
Iter: 458 loss: 5.97589633e-07
Iter: 459 loss: 5.97460485e-07
Iter: 460 loss: 5.97436724e-07
Iter: 461 loss: 5.97289386e-07
Iter: 462 loss: 5.97970825e-07
Iter: 463 loss: 5.97295582e-07
Iter: 464 loss: 5.97169787e-07
Iter: 465 loss: 5.97720486e-07
Iter: 466 loss: 5.97115672e-07
Iter: 467 loss: 5.96980101e-07
Iter: 468 loss: 5.9684578e-07
Iter: 469 loss: 5.96845439e-07
Iter: 470 loss: 5.96650807e-07
Iter: 471 loss: 5.96706684e-07
Iter: 472 loss: 5.96472773e-07
Iter: 473 loss: 5.9626e-07
Iter: 474 loss: 5.99751729e-07
Iter: 475 loss: 5.96252335e-07
Iter: 476 loss: 5.96038205e-07
Iter: 477 loss: 5.95934466e-07
Iter: 478 loss: 5.95796791e-07
Iter: 479 loss: 5.95536562e-07
Iter: 480 loss: 5.96039115e-07
Iter: 481 loss: 5.95445329e-07
Iter: 482 loss: 5.95165943e-07
Iter: 483 loss: 5.95440611e-07
Iter: 484 loss: 5.94970857e-07
Iter: 485 loss: 5.94779294e-07
Iter: 486 loss: 5.94792255e-07
Iter: 487 loss: 5.94543849e-07
Iter: 488 loss: 5.94585515e-07
Iter: 489 loss: 5.94406856e-07
Iter: 490 loss: 5.94225639e-07
Iter: 491 loss: 5.94249912e-07
Iter: 492 loss: 5.94077619e-07
Iter: 493 loss: 5.93731727e-07
Iter: 494 loss: 5.98606334e-07
Iter: 495 loss: 5.9369512e-07
Iter: 496 loss: 5.93569609e-07
Iter: 497 loss: 5.93554887e-07
Iter: 498 loss: 5.93396294e-07
Iter: 499 loss: 5.93292157e-07
Iter: 500 loss: 5.93226048e-07
Iter: 501 loss: 5.92959793e-07
Iter: 502 loss: 5.92928188e-07
Iter: 503 loss: 5.92723154e-07
Iter: 504 loss: 5.92512777e-07
Iter: 505 loss: 5.93304549e-07
Iter: 506 loss: 5.92472247e-07
Iter: 507 loss: 5.92383117e-07
Iter: 508 loss: 5.9234435e-07
Iter: 509 loss: 5.92228162e-07
Iter: 510 loss: 5.92143124e-07
Iter: 511 loss: 5.92139315e-07
Iter: 512 loss: 5.91979301e-07
Iter: 513 loss: 5.92136132e-07
Iter: 514 loss: 5.91853279e-07
Iter: 515 loss: 5.91660637e-07
Iter: 516 loss: 5.9179672e-07
Iter: 517 loss: 5.91521371e-07
Iter: 518 loss: 5.91354592e-07
Iter: 519 loss: 5.91327193e-07
Iter: 520 loss: 5.9121777e-07
Iter: 521 loss: 5.91335265e-07
Iter: 522 loss: 5.91092089e-07
Iter: 523 loss: 5.90932473e-07
Iter: 524 loss: 5.92167112e-07
Iter: 525 loss: 5.90939521e-07
Iter: 526 loss: 5.90792183e-07
Iter: 527 loss: 5.90670709e-07
Iter: 528 loss: 5.90626883e-07
Iter: 529 loss: 5.90485115e-07
Iter: 530 loss: 5.91113178e-07
Iter: 531 loss: 5.90407581e-07
Iter: 532 loss: 5.90242735e-07
Iter: 533 loss: 5.9144395e-07
Iter: 534 loss: 5.90205389e-07
Iter: 535 loss: 5.90116827e-07
Iter: 536 loss: 5.89891044e-07
Iter: 537 loss: 5.93314e-07
Iter: 538 loss: 5.89905085e-07
Iter: 539 loss: 5.89612739e-07
Iter: 540 loss: 5.90202944e-07
Iter: 541 loss: 5.89528327e-07
Iter: 542 loss: 5.8922592e-07
Iter: 543 loss: 5.90111199e-07
Iter: 544 loss: 5.8913804e-07
Iter: 545 loss: 5.88844955e-07
Iter: 546 loss: 5.89723754e-07
Iter: 547 loss: 5.88754403e-07
Iter: 548 loss: 5.88441367e-07
Iter: 549 loss: 5.92606511e-07
Iter: 550 loss: 5.88476382e-07
Iter: 551 loss: 5.88374633e-07
Iter: 552 loss: 5.88284479e-07
Iter: 553 loss: 5.88282091e-07
Iter: 554 loss: 5.88108946e-07
Iter: 555 loss: 5.88292323e-07
Iter: 556 loss: 5.8802533e-07
Iter: 557 loss: 5.8788271e-07
Iter: 558 loss: 5.89411741e-07
Iter: 559 loss: 5.87889872e-07
Iter: 560 loss: 5.87800798e-07
Iter: 561 loss: 5.88682951e-07
Iter: 562 loss: 5.87755721e-07
Iter: 563 loss: 5.87728664e-07
Iter: 564 loss: 5.87782495e-07
Iter: 565 loss: 5.87703539e-07
Iter: 566 loss: 5.87537443e-07
Iter: 567 loss: 5.87499812e-07
Iter: 568 loss: 5.87480429e-07
Iter: 569 loss: 5.8730194e-07
Iter: 570 loss: 5.87472698e-07
Iter: 571 loss: 5.87231739e-07
Iter: 572 loss: 5.87094405e-07
Iter: 573 loss: 5.88945e-07
Iter: 574 loss: 5.87084742e-07
Iter: 575 loss: 5.86971169e-07
Iter: 576 loss: 5.86795466e-07
Iter: 577 loss: 5.8680439e-07
Iter: 578 loss: 5.86588385e-07
Iter: 579 loss: 5.86414558e-07
Iter: 580 loss: 5.86359818e-07
Iter: 581 loss: 5.86131591e-07
Iter: 582 loss: 5.88001399e-07
Iter: 583 loss: 5.86071451e-07
Iter: 584 loss: 5.8584618e-07
Iter: 585 loss: 5.8872e-07
Iter: 586 loss: 5.85859368e-07
Iter: 587 loss: 5.85659052e-07
Iter: 588 loss: 5.85522116e-07
Iter: 589 loss: 5.85459645e-07
Iter: 590 loss: 5.85241651e-07
Iter: 591 loss: 5.85774046e-07
Iter: 592 loss: 5.85178952e-07
Iter: 593 loss: 5.8499262e-07
Iter: 594 loss: 5.85278599e-07
Iter: 595 loss: 5.84922873e-07
Iter: 596 loss: 5.84808788e-07
Iter: 597 loss: 5.84830332e-07
Iter: 598 loss: 5.84714599e-07
Iter: 599 loss: 5.84663781e-07
Iter: 600 loss: 5.84608586e-07
Iter: 601 loss: 5.84476311e-07
Iter: 602 loss: 5.85491136e-07
Iter: 603 loss: 5.84457439e-07
Iter: 604 loss: 5.84381837e-07
Iter: 605 loss: 5.84180214e-07
Iter: 606 loss: 5.84231202e-07
Iter: 607 loss: 5.83981318e-07
Iter: 608 loss: 5.8439673e-07
Iter: 609 loss: 5.83927942e-07
Iter: 610 loss: 5.83716201e-07
Iter: 611 loss: 5.83729275e-07
Iter: 612 loss: 5.83639235e-07
Iter: 613 loss: 5.83479846e-07
Iter: 614 loss: 5.85722262e-07
Iter: 615 loss: 5.83441931e-07
Iter: 616 loss: 5.83242524e-07
Iter: 617 loss: 5.83843871e-07
Iter: 618 loss: 5.83160045e-07
Iter: 619 loss: 5.82951657e-07
Iter: 620 loss: 5.84532415e-07
Iter: 621 loss: 5.82891744e-07
Iter: 622 loss: 5.82710868e-07
Iter: 623 loss: 5.83637302e-07
Iter: 624 loss: 5.82681082e-07
Iter: 625 loss: 5.82531243e-07
Iter: 626 loss: 5.82432222e-07
Iter: 627 loss: 5.82370831e-07
Iter: 628 loss: 5.82217467e-07
Iter: 629 loss: 5.83725e-07
Iter: 630 loss: 5.82209395e-07
Iter: 631 loss: 5.82060466e-07
Iter: 632 loss: 5.83703525e-07
Iter: 633 loss: 5.82059897e-07
Iter: 634 loss: 5.81955305e-07
Iter: 635 loss: 5.81898917e-07
Iter: 636 loss: 5.81879704e-07
Iter: 637 loss: 5.81728898e-07
Iter: 638 loss: 5.82922723e-07
Iter: 639 loss: 5.81766926e-07
Iter: 640 loss: 5.81632662e-07
Iter: 641 loss: 5.81490781e-07
Iter: 642 loss: 5.81500444e-07
Iter: 643 loss: 5.81327811e-07
Iter: 644 loss: 5.82408688e-07
Iter: 645 loss: 5.81337588e-07
Iter: 646 loss: 5.81119366e-07
Iter: 647 loss: 5.81802908e-07
Iter: 648 loss: 5.81067638e-07
Iter: 649 loss: 5.80930362e-07
Iter: 650 loss: 5.80796438e-07
Iter: 651 loss: 5.80728056e-07
Iter: 652 loss: 5.80581059e-07
Iter: 653 loss: 5.80815708e-07
Iter: 654 loss: 5.80488347e-07
Iter: 655 loss: 5.80277e-07
Iter: 656 loss: 5.80805363e-07
Iter: 657 loss: 5.80205551e-07
Iter: 658 loss: 5.80093456e-07
Iter: 659 loss: 5.80120627e-07
Iter: 660 loss: 5.80010123e-07
Iter: 661 loss: 5.80002961e-07
Iter: 662 loss: 5.79890866e-07
Iter: 663 loss: 5.79783546e-07
Iter: 664 loss: 5.79779e-07
Iter: 665 loss: 5.79705215e-07
Iter: 666 loss: 5.79642e-07
Iter: 667 loss: 5.79605285e-07
Iter: 668 loss: 5.79539233e-07
Iter: 669 loss: 5.79393827e-07
Iter: 670 loss: 5.80752669e-07
Iter: 671 loss: 5.79343236e-07
Iter: 672 loss: 5.7918362e-07
Iter: 673 loss: 5.81304903e-07
Iter: 674 loss: 5.79145762e-07
Iter: 675 loss: 5.78997287e-07
Iter: 676 loss: 5.7877952e-07
Iter: 677 loss: 5.7876656e-07
Iter: 678 loss: 5.78474e-07
Iter: 679 loss: 5.79459083e-07
Iter: 680 loss: 5.78455797e-07
Iter: 681 loss: 5.78257414e-07
Iter: 682 loss: 5.78263439e-07
Iter: 683 loss: 5.78202844e-07
Iter: 684 loss: 5.77923515e-07
Iter: 685 loss: 5.82930966e-07
Iter: 686 loss: 5.77926698e-07
Iter: 687 loss: 5.77678918e-07
Iter: 688 loss: 5.7837093e-07
Iter: 689 loss: 5.77643959e-07
Iter: 690 loss: 5.7742011e-07
Iter: 691 loss: 5.78266111e-07
Iter: 692 loss: 5.77403057e-07
Iter: 693 loss: 5.77284936e-07
Iter: 694 loss: 5.78531626e-07
Iter: 695 loss: 5.77232299e-07
Iter: 696 loss: 5.77108324e-07
Iter: 697 loss: 5.77727747e-07
Iter: 698 loss: 5.7712009e-07
Iter: 699 loss: 5.7701078e-07
Iter: 700 loss: 5.76812454e-07
Iter: 701 loss: 5.79247626e-07
Iter: 702 loss: 5.76801085e-07
Iter: 703 loss: 5.7683252e-07
Iter: 704 loss: 5.76662728e-07
Iter: 705 loss: 5.76614411e-07
Iter: 706 loss: 5.76459e-07
Iter: 707 loss: 5.76459115e-07
Iter: 708 loss: 5.76361572e-07
Iter: 709 loss: 5.77030278e-07
Iter: 710 loss: 5.76324624e-07
Iter: 711 loss: 5.76195248e-07
Iter: 712 loss: 5.76566094e-07
Iter: 713 loss: 5.76169441e-07
Iter: 714 loss: 5.76047569e-07
Iter: 715 loss: 5.75906824e-07
Iter: 716 loss: 5.75918364e-07
Iter: 717 loss: 5.75816159e-07
Iter: 718 loss: 5.75803483e-07
Iter: 719 loss: 5.75695708e-07
Iter: 720 loss: 5.75617491e-07
Iter: 721 loss: 5.75594242e-07
Iter: 722 loss: 5.75466458e-07
Iter: 723 loss: 5.75426611e-07
Iter: 724 loss: 5.75319291e-07
Iter: 725 loss: 5.75112608e-07
Iter: 726 loss: 5.75332251e-07
Iter: 727 loss: 5.74947649e-07
Iter: 728 loss: 5.74824242e-07
Iter: 729 loss: 5.74803892e-07
Iter: 730 loss: 5.74652745e-07
Iter: 731 loss: 5.74768706e-07
Iter: 732 loss: 5.74606361e-07
Iter: 733 loss: 5.7443566e-07
Iter: 734 loss: 5.74375235e-07
Iter: 735 loss: 5.7424711e-07
Iter: 736 loss: 5.74137346e-07
Iter: 737 loss: 5.75243121e-07
Iter: 738 loss: 5.7414627e-07
Iter: 739 loss: 5.73932255e-07
Iter: 740 loss: 5.74310036e-07
Iter: 741 loss: 5.7388786e-07
Iter: 742 loss: 5.73778834e-07
Iter: 743 loss: 5.7373984e-07
Iter: 744 loss: 5.73670945e-07
Iter: 745 loss: 5.7357073e-07
Iter: 746 loss: 5.74793944e-07
Iter: 747 loss: 5.73537193e-07
Iter: 748 loss: 5.73449199e-07
Iter: 749 loss: 5.73482339e-07
Iter: 750 loss: 5.73371153e-07
Iter: 751 loss: 5.73237571e-07
Iter: 752 loss: 5.73115926e-07
Iter: 753 loss: 5.73082502e-07
Iter: 754 loss: 5.73060845e-07
Iter: 755 loss: 5.72975296e-07
Iter: 756 loss: 5.72961312e-07
Iter: 757 loss: 5.72798e-07
Iter: 758 loss: 5.74677415e-07
Iter: 759 loss: 5.72805e-07
Iter: 760 loss: 5.72624742e-07
Iter: 761 loss: 5.73103648e-07
Iter: 762 loss: 5.72531349e-07
Iter: 763 loss: 5.72442332e-07
Iter: 764 loss: 5.73842044e-07
Iter: 765 loss: 5.72435965e-07
Iter: 766 loss: 5.72309432e-07
Iter: 767 loss: 5.72495367e-07
Iter: 768 loss: 5.72221609e-07
Iter: 769 loss: 5.72134809e-07
Iter: 770 loss: 5.7211372e-07
Iter: 771 loss: 5.72037038e-07
Iter: 772 loss: 5.71895157e-07
Iter: 773 loss: 5.7244938e-07
Iter: 774 loss: 5.71853e-07
Iter: 775 loss: 5.71704163e-07
Iter: 776 loss: 5.71682904e-07
Iter: 777 loss: 5.71580813e-07
Iter: 778 loss: 5.71378109e-07
Iter: 779 loss: 5.72332965e-07
Iter: 780 loss: 5.71306828e-07
Iter: 781 loss: 5.70951215e-07
Iter: 782 loss: 5.72845579e-07
Iter: 783 loss: 5.70925749e-07
Iter: 784 loss: 5.70682346e-07
Iter: 785 loss: 5.70668703e-07
Iter: 786 loss: 5.70545808e-07
Iter: 787 loss: 5.70460429e-07
Iter: 788 loss: 5.70430643e-07
Iter: 789 loss: 5.70290922e-07
Iter: 790 loss: 5.71020678e-07
Iter: 791 loss: 5.70283305e-07
Iter: 792 loss: 5.70110615e-07
Iter: 793 loss: 5.70606119e-07
Iter: 794 loss: 5.70053203e-07
Iter: 795 loss: 5.69996e-07
Iter: 796 loss: 5.69852887e-07
Iter: 797 loss: 5.69882957e-07
Iter: 798 loss: 5.69739427e-07
Iter: 799 loss: 5.70804787e-07
Iter: 800 loss: 5.69747385e-07
Iter: 801 loss: 5.69623467e-07
Iter: 802 loss: 5.70159045e-07
Iter: 803 loss: 5.6963728e-07
Iter: 804 loss: 5.6951842e-07
Iter: 805 loss: 5.69447479e-07
Iter: 806 loss: 5.69432586e-07
Iter: 807 loss: 5.69294912e-07
Iter: 808 loss: 5.70065481e-07
Iter: 809 loss: 5.69281156e-07
Iter: 810 loss: 5.69090901e-07
Iter: 811 loss: 5.69582767e-07
Iter: 812 loss: 5.69058557e-07
Iter: 813 loss: 5.68925884e-07
Iter: 814 loss: 5.68830956e-07
Iter: 815 loss: 5.68812879e-07
Iter: 816 loss: 5.68638427e-07
Iter: 817 loss: 5.68787925e-07
Iter: 818 loss: 5.68541111e-07
Iter: 819 loss: 5.68389e-07
Iter: 820 loss: 5.68375299e-07
Iter: 821 loss: 5.68259e-07
Iter: 822 loss: 5.68105065e-07
Iter: 823 loss: 5.71533633e-07
Iter: 824 loss: 5.68103872e-07
Iter: 825 loss: 5.68028099e-07
Iter: 826 loss: 5.68017185e-07
Iter: 827 loss: 5.6791481e-07
Iter: 828 loss: 5.67878487e-07
Iter: 829 loss: 5.67868199e-07
Iter: 830 loss: 5.67699544e-07
Iter: 831 loss: 5.67715e-07
Iter: 832 loss: 5.67640654e-07
Iter: 833 loss: 5.67471886e-07
Iter: 834 loss: 5.67654297e-07
Iter: 835 loss: 5.67378663e-07
Iter: 836 loss: 5.67303914e-07
Iter: 837 loss: 5.6728544e-07
Iter: 838 loss: 5.67174254e-07
Iter: 839 loss: 5.67079042e-07
Iter: 840 loss: 5.67128893e-07
Iter: 841 loss: 5.66974336e-07
Iter: 842 loss: 5.67504571e-07
Iter: 843 loss: 5.66952167e-07
Iter: 844 loss: 5.66863264e-07
Iter: 845 loss: 5.6687287e-07
Iter: 846 loss: 5.66829272e-07
Iter: 847 loss: 5.66733831e-07
Iter: 848 loss: 5.68590849e-07
Iter: 849 loss: 5.66717745e-07
Iter: 850 loss: 5.66610652e-07
Iter: 851 loss: 5.67056759e-07
Iter: 852 loss: 5.66544486e-07
Iter: 853 loss: 5.66457857e-07
Iter: 854 loss: 5.67293569e-07
Iter: 855 loss: 5.66442907e-07
Iter: 856 loss: 5.66386916e-07
Iter: 857 loss: 5.66365941e-07
Iter: 858 loss: 5.66334847e-07
Iter: 859 loss: 5.66209394e-07
Iter: 860 loss: 5.66755659e-07
Iter: 861 loss: 5.6619e-07
Iter: 862 loss: 5.66076096e-07
Iter: 863 loss: 5.6671422e-07
Iter: 864 loss: 5.6605e-07
Iter: 865 loss: 5.66015387e-07
Iter: 866 loss: 5.65803248e-07
Iter: 867 loss: 5.67866e-07
Iter: 868 loss: 5.65804953e-07
Iter: 869 loss: 5.65604864e-07
Iter: 870 loss: 5.67124346e-07
Iter: 871 loss: 5.65566779e-07
Iter: 872 loss: 5.65477876e-07
Iter: 873 loss: 5.66562164e-07
Iter: 874 loss: 5.65453945e-07
Iter: 875 loss: 5.65351968e-07
Iter: 876 loss: 5.65564619e-07
Iter: 877 loss: 5.65260621e-07
Iter: 878 loss: 5.6515438e-07
Iter: 879 loss: 5.65282221e-07
Iter: 880 loss: 5.65136418e-07
Iter: 881 loss: 5.65030746e-07
Iter: 882 loss: 5.65049334e-07
Iter: 883 loss: 5.64989705e-07
Iter: 884 loss: 5.64881361e-07
Iter: 885 loss: 5.65297626e-07
Iter: 886 loss: 5.64821676e-07
Iter: 887 loss: 5.64695256e-07
Iter: 888 loss: 5.65632263e-07
Iter: 889 loss: 5.64649667e-07
Iter: 890 loss: 5.64572247e-07
Iter: 891 loss: 5.64556785e-07
Iter: 892 loss: 5.64489255e-07
Iter: 893 loss: 5.64550078e-07
Iter: 894 loss: 5.64428603e-07
Iter: 895 loss: 5.64359766e-07
Iter: 896 loss: 5.64544109e-07
Iter: 897 loss: 5.64343281e-07
Iter: 898 loss: 5.6426461e-07
Iter: 899 loss: 5.64993911e-07
Iter: 900 loss: 5.64272113e-07
Iter: 901 loss: 5.64165248e-07
Iter: 902 loss: 5.64118636e-07
Iter: 903 loss: 5.64106472e-07
Iter: 904 loss: 5.64004495e-07
Iter: 905 loss: 5.64033712e-07
Iter: 906 loss: 5.63938102e-07
Iter: 907 loss: 5.63776894e-07
Iter: 908 loss: 5.64301672e-07
Iter: 909 loss: 5.6373085e-07
Iter: 910 loss: 5.63594483e-07
Iter: 911 loss: 5.63629101e-07
Iter: 912 loss: 5.63531216e-07
Iter: 913 loss: 5.63426227e-07
Iter: 914 loss: 5.63429865e-07
Iter: 915 loss: 5.63302422e-07
Iter: 916 loss: 5.64729703e-07
Iter: 917 loss: 5.63291906e-07
Iter: 918 loss: 5.63197e-07
Iter: 919 loss: 5.63228582e-07
Iter: 920 loss: 5.63102731e-07
Iter: 921 loss: 5.63038043e-07
Iter: 922 loss: 5.62940784e-07
Iter: 923 loss: 5.62920263e-07
Iter: 924 loss: 5.62829939e-07
Iter: 925 loss: 5.62803052e-07
Iter: 926 loss: 5.62752177e-07
Iter: 927 loss: 5.62766672e-07
Iter: 928 loss: 5.62658613e-07
Iter: 929 loss: 5.62608193e-07
Iter: 930 loss: 5.63346816e-07
Iter: 931 loss: 5.6260734e-07
Iter: 932 loss: 5.62548394e-07
Iter: 933 loss: 5.62571e-07
Iter: 934 loss: 5.62529181e-07
Iter: 935 loss: 5.62412197e-07
Iter: 936 loss: 5.62326136e-07
Iter: 937 loss: 5.62305e-07
Iter: 938 loss: 5.62199375e-07
Iter: 939 loss: 5.62598416e-07
Iter: 940 loss: 5.62154696e-07
Iter: 941 loss: 5.62039872e-07
Iter: 942 loss: 5.62126615e-07
Iter: 943 loss: 5.62007301e-07
Iter: 944 loss: 5.61861782e-07
Iter: 945 loss: 5.63143885e-07
Iter: 946 loss: 5.61868944e-07
Iter: 947 loss: 5.61800391e-07
Iter: 948 loss: 5.62682e-07
Iter: 949 loss: 5.61805166e-07
Iter: 950 loss: 5.6172729e-07
Iter: 951 loss: 5.6182256e-07
Iter: 952 loss: 5.61712113e-07
Iter: 953 loss: 5.61576599e-07
Iter: 954 loss: 5.61517595e-07
Iter: 955 loss: 5.61495312e-07
Iter: 956 loss: 5.61353829e-07
Iter: 957 loss: 5.61395041e-07
Iter: 958 loss: 5.61269417e-07
Iter: 959 loss: 5.61122476e-07
Iter: 960 loss: 5.62786e-07
Iter: 961 loss: 5.61120089e-07
Iter: 962 loss: 5.61039315e-07
Iter: 963 loss: 5.61149704e-07
Iter: 964 loss: 5.60961098e-07
Iter: 965 loss: 5.60812623e-07
Iter: 966 loss: 5.60984859e-07
Iter: 967 loss: 5.60742535e-07
Iter: 968 loss: 5.60601336e-07
Iter: 969 loss: 5.6168119e-07
Iter: 970 loss: 5.60608896e-07
Iter: 971 loss: 5.60484352e-07
Iter: 972 loss: 5.60392436e-07
Iter: 973 loss: 5.60387207e-07
Iter: 974 loss: 5.60288413e-07
Iter: 975 loss: 5.60880153e-07
Iter: 976 loss: 5.60278465e-07
Iter: 977 loss: 5.60148408e-07
Iter: 978 loss: 5.60314163e-07
Iter: 979 loss: 5.60115041e-07
Iter: 980 loss: 5.59977252e-07
Iter: 981 loss: 5.60845137e-07
Iter: 982 loss: 5.59967361e-07
Iter: 983 loss: 5.59874081e-07
Iter: 984 loss: 5.60550518e-07
Iter: 985 loss: 5.59888122e-07
Iter: 986 loss: 5.59817465e-07
Iter: 987 loss: 5.59885848e-07
Iter: 988 loss: 5.59745786e-07
Iter: 989 loss: 5.59626073e-07
Iter: 990 loss: 5.59619252e-07
Iter: 991 loss: 5.59559339e-07
Iter: 992 loss: 5.59472653e-07
Iter: 993 loss: 5.59399837e-07
Iter: 994 loss: 5.59369e-07
Iter: 995 loss: 5.59219075e-07
Iter: 996 loss: 5.60932108e-07
Iter: 997 loss: 5.59209752e-07
Iter: 998 loss: 5.59087425e-07
Iter: 999 loss: 5.5931082e-07
Iter: 1000 loss: 5.59026489e-07
Iter: 1001 loss: 5.58912745e-07
Iter: 1002 loss: 5.59231466e-07
Iter: 1003 loss: 5.58892225e-07
Iter: 1004 loss: 5.5881128e-07
Iter: 1005 loss: 5.59298542e-07
Iter: 1006 loss: 5.58821739e-07
Iter: 1007 loss: 5.58700833e-07
Iter: 1008 loss: 5.58597264e-07
Iter: 1009 loss: 5.58605052e-07
Iter: 1010 loss: 5.58489148e-07
Iter: 1011 loss: 5.5871584e-07
Iter: 1012 loss: 5.58380407e-07
Iter: 1013 loss: 5.58246143e-07
Iter: 1014 loss: 5.5857771e-07
Iter: 1015 loss: 5.5815724e-07
Iter: 1016 loss: 5.58039e-07
Iter: 1017 loss: 5.58028773e-07
Iter: 1018 loss: 5.57931685e-07
Iter: 1019 loss: 5.57966814e-07
Iter: 1020 loss: 5.57856197e-07
Iter: 1021 loss: 5.57763656e-07
Iter: 1022 loss: 5.58266095e-07
Iter: 1023 loss: 5.5777457e-07
Iter: 1024 loss: 5.576116e-07
Iter: 1025 loss: 5.57485293e-07
Iter: 1026 loss: 5.57459884e-07
Iter: 1027 loss: 5.57305043e-07
Iter: 1028 loss: 5.57697945e-07
Iter: 1029 loss: 5.57237968e-07
Iter: 1030 loss: 5.57158728e-07
Iter: 1031 loss: 5.57152816e-07
Iter: 1032 loss: 5.57058172e-07
Iter: 1033 loss: 5.56969326e-07
Iter: 1034 loss: 5.56919872e-07
Iter: 1035 loss: 5.56850523e-07
Iter: 1036 loss: 5.56868599e-07
Iter: 1037 loss: 5.56807834e-07
Iter: 1038 loss: 5.56874056e-07
Iter: 1039 loss: 5.56794816e-07
Iter: 1040 loss: 5.56707107e-07
Iter: 1041 loss: 5.56622354e-07
Iter: 1042 loss: 5.58358749e-07
Iter: 1043 loss: 5.56617351e-07
Iter: 1044 loss: 5.56455916e-07
Iter: 1045 loss: 5.57023498e-07
Iter: 1046 loss: 5.56448867e-07
Iter: 1047 loss: 5.56313239e-07
Iter: 1048 loss: 5.57633712e-07
Iter: 1049 loss: 5.5631557e-07
Iter: 1050 loss: 5.56237183e-07
Iter: 1051 loss: 5.57334602e-07
Iter: 1052 loss: 5.56252871e-07
Iter: 1053 loss: 5.56168288e-07
Iter: 1054 loss: 5.56101099e-07
Iter: 1055 loss: 5.56089674e-07
Iter: 1056 loss: 5.55975e-07
Iter: 1057 loss: 5.56553744e-07
Iter: 1058 loss: 5.5593614e-07
Iter: 1059 loss: 5.55852864e-07
Iter: 1060 loss: 5.55826261e-07
Iter: 1061 loss: 5.55733e-07
Iter: 1062 loss: 5.55661131e-07
Iter: 1063 loss: 5.56161638e-07
Iter: 1064 loss: 5.55647603e-07
Iter: 1065 loss: 5.55544318e-07
Iter: 1066 loss: 5.55838483e-07
Iter: 1067 loss: 5.55544887e-07
Iter: 1068 loss: 5.55488668e-07
Iter: 1069 loss: 5.55490715e-07
Iter: 1070 loss: 5.55400732e-07
Iter: 1071 loss: 5.55318e-07
Iter: 1072 loss: 5.56109512e-07
Iter: 1073 loss: 5.55301199e-07
Iter: 1074 loss: 5.55189e-07
Iter: 1075 loss: 5.5510958e-07
Iter: 1076 loss: 5.55103213e-07
Iter: 1077 loss: 5.54938083e-07
Iter: 1078 loss: 5.55073541e-07
Iter: 1079 loss: 5.54882035e-07
Iter: 1080 loss: 5.54762266e-07
Iter: 1081 loss: 5.55578822e-07
Iter: 1082 loss: 5.54719293e-07
Iter: 1083 loss: 5.54633743e-07
Iter: 1084 loss: 5.55959218e-07
Iter: 1085 loss: 5.54644885e-07
Iter: 1086 loss: 5.5455979e-07
Iter: 1087 loss: 5.54601229e-07
Iter: 1088 loss: 5.54486348e-07
Iter: 1089 loss: 5.54466283e-07
Iter: 1090 loss: 5.54919325e-07
Iter: 1091 loss: 5.54452868e-07
Iter: 1092 loss: 5.54383632e-07
Iter: 1093 loss: 5.54445478e-07
Iter: 1094 loss: 5.5434856e-07
Iter: 1095 loss: 5.5427148e-07
Iter: 1096 loss: 5.54166661e-07
Iter: 1097 loss: 5.5419207e-07
Iter: 1098 loss: 5.54127723e-07
Iter: 1099 loss: 5.54109931e-07
Iter: 1100 loss: 5.54073381e-07
Iter: 1101 loss: 5.53969414e-07
Iter: 1102 loss: 5.54005055e-07
Iter: 1103 loss: 5.53884547e-07
Iter: 1104 loss: 5.5482684e-07
Iter: 1105 loss: 5.53885457e-07
Iter: 1106 loss: 5.53807865e-07
Iter: 1107 loss: 5.53915413e-07
Iter: 1108 loss: 5.5377933e-07
Iter: 1109 loss: 5.53719701e-07
Iter: 1110 loss: 5.53643e-07
Iter: 1111 loss: 5.53636255e-07
Iter: 1112 loss: 5.53537916e-07
Iter: 1113 loss: 5.53949747e-07
Iter: 1114 loss: 5.53518475e-07
Iter: 1115 loss: 5.53393761e-07
Iter: 1116 loss: 5.53620112e-07
Iter: 1117 loss: 5.53385348e-07
Iter: 1118 loss: 5.53321456e-07
Iter: 1119 loss: 5.53336577e-07
Iter: 1120 loss: 5.53298264e-07
Iter: 1121 loss: 5.53218854e-07
Iter: 1122 loss: 5.53178097e-07
Iter: 1123 loss: 5.53154e-07
Iter: 1124 loss: 5.53665927e-07
Iter: 1125 loss: 5.53087659e-07
Iter: 1126 loss: 5.53004838e-07
Iter: 1127 loss: 5.52944641e-07
Iter: 1128 loss: 5.52899508e-07
Iter: 1129 loss: 5.52782751e-07
Iter: 1130 loss: 5.53303778e-07
Iter: 1131 loss: 5.52757854e-07
Iter: 1132 loss: 5.5267742e-07
Iter: 1133 loss: 5.52681797e-07
Iter: 1134 loss: 5.52613869e-07
Iter: 1135 loss: 5.52497511e-07
Iter: 1136 loss: 5.52498705e-07
Iter: 1137 loss: 5.52391612e-07
Iter: 1138 loss: 5.52396045e-07
Iter: 1139 loss: 5.52336417e-07
Iter: 1140 loss: 5.52392407e-07
Iter: 1141 loss: 5.52336473e-07
Iter: 1142 loss: 5.52238589e-07
Iter: 1143 loss: 5.52230915e-07
Iter: 1144 loss: 5.52227391e-07
Iter: 1145 loss: 5.5213394e-07
Iter: 1146 loss: 5.52385131e-07
Iter: 1147 loss: 5.5206732e-07
Iter: 1148 loss: 5.5204805e-07
Iter: 1149 loss: 5.52035885e-07
Iter: 1150 loss: 5.51973073e-07
Iter: 1151 loss: 5.51963467e-07
Iter: 1152 loss: 5.51929361e-07
Iter: 1153 loss: 5.51838582e-07
Iter: 1154 loss: 5.52047936e-07
Iter: 1155 loss: 5.51826247e-07
Iter: 1156 loss: 5.51751668e-07
Iter: 1157 loss: 5.51958124e-07
Iter: 1158 loss: 5.5172211e-07
Iter: 1159 loss: 5.51621156e-07
Iter: 1160 loss: 5.51557207e-07
Iter: 1161 loss: 5.51502126e-07
Iter: 1162 loss: 5.5140049e-07
Iter: 1163 loss: 5.52717097e-07
Iter: 1164 loss: 5.51420499e-07
Iter: 1165 loss: 5.51337962e-07
Iter: 1166 loss: 5.52131098e-07
Iter: 1167 loss: 5.51305618e-07
Iter: 1168 loss: 5.51269295e-07
Iter: 1169 loss: 5.51263156e-07
Iter: 1170 loss: 5.51216374e-07
Iter: 1171 loss: 5.51145e-07
Iter: 1172 loss: 5.51606831e-07
Iter: 1173 loss: 5.51153221e-07
Iter: 1174 loss: 5.51123378e-07
Iter: 1175 loss: 5.51052608e-07
Iter: 1176 loss: 5.5105869e-07
Iter: 1177 loss: 5.50971663e-07
Iter: 1178 loss: 5.5115e-07
Iter: 1179 loss: 5.5097172e-07
Iter: 1180 loss: 5.50916866e-07
Iter: 1181 loss: 5.50903678e-07
Iter: 1182 loss: 5.50883271e-07
Iter: 1183 loss: 5.50820744e-07
Iter: 1184 loss: 5.50820914e-07
Iter: 1185 loss: 5.50734626e-07
Iter: 1186 loss: 5.50771858e-07
Iter: 1187 loss: 5.5073707e-07
Iter: 1188 loss: 5.50721154e-07
Iter: 1189 loss: 5.50909931e-07
Iter: 1190 loss: 5.50681932e-07
Iter: 1191 loss: 5.50621962e-07
Iter: 1192 loss: 5.50535333e-07
Iter: 1193 loss: 5.50509299e-07
Iter: 1194 loss: 5.50434834e-07
Iter: 1195 loss: 5.50523737e-07
Iter: 1196 loss: 5.50389586e-07
Iter: 1197 loss: 5.50274535e-07
Iter: 1198 loss: 5.50717687e-07
Iter: 1199 loss: 5.50260495e-07
Iter: 1200 loss: 5.5019018e-07
Iter: 1201 loss: 5.51004e-07
Iter: 1202 loss: 5.50177333e-07
Iter: 1203 loss: 5.50123104e-07
Iter: 1204 loss: 5.50026527e-07
Iter: 1205 loss: 5.5001891e-07
Iter: 1206 loss: 5.49935237e-07
Iter: 1207 loss: 5.51220694e-07
Iter: 1208 loss: 5.49948311e-07
Iter: 1209 loss: 5.49895049e-07
Iter: 1210 loss: 5.49897436e-07
Iter: 1211 loss: 5.49819561e-07
Iter: 1212 loss: 5.49714628e-07
Iter: 1213 loss: 5.49624588e-07
Iter: 1214 loss: 5.49633967e-07
Iter: 1215 loss: 5.49467813e-07
Iter: 1216 loss: 5.50336836e-07
Iter: 1217 loss: 5.49466336e-07
Iter: 1218 loss: 5.49374818e-07
Iter: 1219 loss: 5.50061429e-07
Iter: 1220 loss: 5.49355661e-07
Iter: 1221 loss: 5.49295407e-07
Iter: 1222 loss: 5.4931229e-07
Iter: 1223 loss: 5.49259482e-07
Iter: 1224 loss: 5.49201104e-07
Iter: 1225 loss: 5.50021923e-07
Iter: 1226 loss: 5.49189565e-07
Iter: 1227 loss: 5.4912482e-07
Iter: 1228 loss: 5.49184506e-07
Iter: 1229 loss: 5.49099298e-07
Iter: 1230 loss: 5.49078891e-07
Iter: 1231 loss: 5.49046035e-07
Iter: 1232 loss: 5.48994763e-07
Iter: 1233 loss: 5.48957757e-07
Iter: 1234 loss: 5.48940307e-07
Iter: 1235 loss: 5.48927801e-07
Iter: 1236 loss: 5.4890188e-07
Iter: 1237 loss: 5.48848675e-07
Iter: 1238 loss: 5.48768298e-07
Iter: 1239 loss: 5.50252764e-07
Iter: 1240 loss: 5.48769322e-07
Iter: 1241 loss: 5.48682351e-07
Iter: 1242 loss: 5.49322237e-07
Iter: 1243 loss: 5.48651883e-07
Iter: 1244 loss: 5.48603737e-07
Iter: 1245 loss: 5.48940591e-07
Iter: 1246 loss: 5.48598848e-07
Iter: 1247 loss: 5.48509774e-07
Iter: 1248 loss: 5.48489311e-07
Iter: 1249 loss: 5.48472372e-07
Iter: 1250 loss: 5.4838182e-07
Iter: 1251 loss: 5.48703724e-07
Iter: 1252 loss: 5.48341063e-07
Iter: 1253 loss: 5.48266769e-07
Iter: 1254 loss: 5.48541664e-07
Iter: 1255 loss: 5.48244202e-07
Iter: 1256 loss: 5.48193498e-07
Iter: 1257 loss: 5.48180822e-07
Iter: 1258 loss: 5.48143134e-07
Iter: 1259 loss: 5.48059859e-07
Iter: 1260 loss: 5.49651588e-07
Iter: 1261 loss: 5.48087939e-07
Iter: 1262 loss: 5.47973343e-07
Iter: 1263 loss: 5.48686842e-07
Iter: 1264 loss: 5.47992045e-07
Iter: 1265 loss: 5.47916102e-07
Iter: 1266 loss: 5.47911668e-07
Iter: 1267 loss: 5.47834816e-07
Iter: 1268 loss: 5.47789682e-07
Iter: 1269 loss: 5.47947934e-07
Iter: 1270 loss: 5.47758418e-07
Iter: 1271 loss: 5.47619777e-07
Iter: 1272 loss: 5.48468449e-07
Iter: 1273 loss: 5.47609488e-07
Iter: 1274 loss: 5.47565833e-07
Iter: 1275 loss: 5.47517914e-07
Iter: 1276 loss: 5.47486593e-07
Iter: 1277 loss: 5.47447087e-07
Iter: 1278 loss: 5.47461e-07
Iter: 1279 loss: 5.47420257e-07
Iter: 1280 loss: 5.474364e-07
Iter: 1281 loss: 5.47369496e-07
Iter: 1282 loss: 5.47292e-07
Iter: 1283 loss: 5.47316176e-07
Iter: 1284 loss: 5.47289687e-07
Iter: 1285 loss: 5.47184811e-07
Iter: 1286 loss: 5.4742975e-07
Iter: 1287 loss: 5.47156333e-07
Iter: 1288 loss: 5.47105628e-07
Iter: 1289 loss: 5.47858917e-07
Iter: 1290 loss: 5.4709858e-07
Iter: 1291 loss: 5.47025309e-07
Iter: 1292 loss: 5.47013e-07
Iter: 1293 loss: 5.46916624e-07
Iter: 1294 loss: 5.4684773e-07
Iter: 1295 loss: 5.46717899e-07
Iter: 1296 loss: 5.46723584e-07
Iter: 1297 loss: 5.46593583e-07
Iter: 1298 loss: 5.48327478e-07
Iter: 1299 loss: 5.4658932e-07
Iter: 1300 loss: 5.46495471e-07
Iter: 1301 loss: 5.46397416e-07
Iter: 1302 loss: 5.46404294e-07
Iter: 1303 loss: 5.46274919e-07
Iter: 1304 loss: 5.46651e-07
Iter: 1305 loss: 5.46257468e-07
Iter: 1306 loss: 5.46136e-07
Iter: 1307 loss: 5.47161619e-07
Iter: 1308 loss: 5.46151966e-07
Iter: 1309 loss: 5.46065792e-07
Iter: 1310 loss: 5.46179308e-07
Iter: 1311 loss: 5.46019805e-07
Iter: 1312 loss: 5.45937837e-07
Iter: 1313 loss: 5.45937894e-07
Iter: 1314 loss: 5.45860644e-07
Iter: 1315 loss: 5.45813293e-07
Iter: 1316 loss: 5.46516219e-07
Iter: 1317 loss: 5.4581875e-07
Iter: 1318 loss: 5.45762305e-07
Iter: 1319 loss: 5.45741614e-07
Iter: 1320 loss: 5.45719104e-07
Iter: 1321 loss: 5.45635658e-07
Iter: 1322 loss: 5.45709042e-07
Iter: 1323 loss: 5.45578757e-07
Iter: 1324 loss: 5.45579041e-07
Iter: 1325 loss: 5.45547323e-07
Iter: 1326 loss: 5.45522767e-07
Iter: 1327 loss: 5.45487183e-07
Iter: 1328 loss: 5.4685438e-07
Iter: 1329 loss: 5.45434148e-07
Iter: 1330 loss: 5.45380658e-07
Iter: 1331 loss: 5.45762816e-07
Iter: 1332 loss: 5.45390094e-07
Iter: 1333 loss: 5.4527851e-07
Iter: 1334 loss: 5.45363946e-07
Iter: 1335 loss: 5.45252931e-07
Iter: 1336 loss: 5.45156581e-07
Iter: 1337 loss: 5.4511537e-07
Iter: 1338 loss: 5.45091495e-07
Iter: 1339 loss: 5.44979e-07
Iter: 1340 loss: 5.45453531e-07
Iter: 1341 loss: 5.44967065e-07
Iter: 1342 loss: 5.4483769e-07
Iter: 1343 loss: 5.45908563e-07
Iter: 1344 loss: 5.44819386e-07
Iter: 1345 loss: 5.44723321e-07
Iter: 1346 loss: 5.4473162e-07
Iter: 1347 loss: 5.44642887e-07
Iter: 1348 loss: 5.44526074e-07
Iter: 1349 loss: 5.44659713e-07
Iter: 1350 loss: 5.44455474e-07
Iter: 1351 loss: 5.44416594e-07
Iter: 1352 loss: 5.4583262e-07
Iter: 1353 loss: 5.44405339e-07
Iter: 1354 loss: 5.44299894e-07
Iter: 1355 loss: 5.44215254e-07
Iter: 1356 loss: 5.4420633e-07
Iter: 1357 loss: 5.44099521e-07
Iter: 1358 loss: 5.44702402e-07
Iter: 1359 loss: 5.44089801e-07
Iter: 1360 loss: 5.44028353e-07
Iter: 1361 loss: 5.44049044e-07
Iter: 1362 loss: 5.43992087e-07
Iter: 1363 loss: 5.43862768e-07
Iter: 1364 loss: 5.44381749e-07
Iter: 1365 loss: 5.438269e-07
Iter: 1366 loss: 5.437808e-07
Iter: 1367 loss: 5.4375397e-07
Iter: 1368 loss: 5.43705369e-07
Iter: 1369 loss: 5.43664157e-07
Iter: 1370 loss: 5.43620274e-07
Iter: 1371 loss: 5.43487374e-07
Iter: 1372 loss: 5.43422971e-07
Iter: 1373 loss: 5.4340876e-07
Iter: 1374 loss: 5.43252611e-07
Iter: 1375 loss: 5.43849296e-07
Iter: 1376 loss: 5.43198212e-07
Iter: 1377 loss: 5.43130454e-07
Iter: 1378 loss: 5.43107149e-07
Iter: 1379 loss: 5.43009605e-07
Iter: 1380 loss: 5.42928547e-07
Iter: 1381 loss: 5.42948158e-07
Iter: 1382 loss: 5.42840837e-07
Iter: 1383 loss: 5.42956172e-07
Iter: 1384 loss: 5.42755174e-07
Iter: 1385 loss: 5.42677185e-07
Iter: 1386 loss: 5.43502324e-07
Iter: 1387 loss: 5.4268105e-07
Iter: 1388 loss: 5.42621649e-07
Iter: 1389 loss: 5.42909959e-07
Iter: 1390 loss: 5.42591124e-07
Iter: 1391 loss: 5.42525584e-07
Iter: 1392 loss: 5.42441626e-07
Iter: 1393 loss: 5.42413545e-07
Iter: 1394 loss: 5.42355792e-07
Iter: 1395 loss: 5.42345163e-07
Iter: 1396 loss: 5.42254838e-07
Iter: 1397 loss: 5.42207431e-07
Iter: 1398 loss: 5.44569048e-07
Iter: 1399 loss: 5.42193902e-07
Iter: 1400 loss: 5.42091811e-07
Iter: 1401 loss: 5.42290081e-07
Iter: 1402 loss: 5.42057251e-07
Iter: 1403 loss: 5.41926624e-07
Iter: 1404 loss: 5.42746761e-07
Iter: 1405 loss: 5.41935947e-07
Iter: 1406 loss: 5.4179975e-07
Iter: 1407 loss: 5.41617169e-07
Iter: 1408 loss: 5.41614668e-07
Iter: 1409 loss: 5.41456188e-07
Iter: 1410 loss: 5.42149166e-07
Iter: 1411 loss: 5.41425322e-07
Iter: 1412 loss: 5.41312602e-07
Iter: 1413 loss: 5.41865347e-07
Iter: 1414 loss: 5.41284351e-07
Iter: 1415 loss: 5.41169754e-07
Iter: 1416 loss: 5.41204031e-07
Iter: 1417 loss: 5.41123939e-07
Iter: 1418 loss: 5.41044869e-07
Iter: 1419 loss: 5.41060786e-07
Iter: 1420 loss: 5.40946814e-07
Iter: 1421 loss: 5.41299e-07
Iter: 1422 loss: 5.40903159e-07
Iter: 1423 loss: 5.40831195e-07
Iter: 1424 loss: 5.41614725e-07
Iter: 1425 loss: 5.40850181e-07
Iter: 1426 loss: 5.40751e-07
Iter: 1427 loss: 5.40797942e-07
Iter: 1428 loss: 5.40724045e-07
Iter: 1429 loss: 5.40652763e-07
Iter: 1430 loss: 5.41359725e-07
Iter: 1431 loss: 5.4067425e-07
Iter: 1432 loss: 5.40597512e-07
Iter: 1433 loss: 5.40591941e-07
Iter: 1434 loss: 5.40567441e-07
Iter: 1435 loss: 5.40471547e-07
Iter: 1436 loss: 5.40396286e-07
Iter: 1437 loss: 5.40384065e-07
Iter: 1438 loss: 5.40316194e-07
Iter: 1439 loss: 5.40317615e-07
Iter: 1440 loss: 5.40270094e-07
Iter: 1441 loss: 5.40400208e-07
Iter: 1442 loss: 5.40212511e-07
Iter: 1443 loss: 5.40201711e-07
Iter: 1444 loss: 5.40084329e-07
Iter: 1445 loss: 5.40070573e-07
Iter: 1446 loss: 5.3998491e-07
Iter: 1447 loss: 5.40448923e-07
Iter: 1448 loss: 5.39958762e-07
Iter: 1449 loss: 5.39893676e-07
Iter: 1450 loss: 5.39908058e-07
Iter: 1451 loss: 5.39823247e-07
Iter: 1452 loss: 5.39718e-07
Iter: 1453 loss: 5.41975396e-07
Iter: 1454 loss: 5.39742928e-07
Iter: 1455 loss: 5.39647772e-07
Iter: 1456 loss: 5.39907319e-07
Iter: 1457 loss: 5.39617076e-07
Iter: 1458 loss: 5.39540054e-07
Iter: 1459 loss: 5.39532493e-07
Iter: 1460 loss: 5.39473831e-07
Iter: 1461 loss: 5.39432676e-07
Iter: 1462 loss: 5.39422672e-07
Iter: 1463 loss: 5.3934474e-07
Iter: 1464 loss: 5.40357632e-07
Iter: 1465 loss: 5.39369523e-07
Iter: 1466 loss: 5.39277949e-07
Iter: 1467 loss: 5.39257e-07
Iter: 1468 loss: 5.39210419e-07
Iter: 1469 loss: 5.39170856e-07
Iter: 1470 loss: 5.39104803e-07
Iter: 1471 loss: 5.39076382e-07
Iter: 1472 loss: 5.38961444e-07
Iter: 1473 loss: 5.39317909e-07
Iter: 1474 loss: 5.38966844e-07
Iter: 1475 loss: 5.38845825e-07
Iter: 1476 loss: 5.40040389e-07
Iter: 1477 loss: 5.38858103e-07
Iter: 1478 loss: 5.3879296e-07
Iter: 1479 loss: 5.38709799e-07
Iter: 1480 loss: 5.3867933e-07
Iter: 1481 loss: 5.386525e-07
Iter: 1482 loss: 5.38988957e-07
Iter: 1483 loss: 5.38614927e-07
Iter: 1484 loss: 5.38585084e-07
Iter: 1485 loss: 5.3858389e-07
Iter: 1486 loss: 5.38521476e-07
Iter: 1487 loss: 5.38489644e-07
Iter: 1488 loss: 5.38487484e-07
Iter: 1489 loss: 5.38415861e-07
Iter: 1490 loss: 5.3836493e-07
Iter: 1491 loss: 5.38359473e-07
Iter: 1492 loss: 5.38282166e-07
Iter: 1493 loss: 5.39347582e-07
Iter: 1494 loss: 5.38285121e-07
Iter: 1495 loss: 5.38211e-07
Iter: 1496 loss: 5.38224072e-07
Iter: 1497 loss: 5.38203949e-07
Iter: 1498 loss: 5.38095094e-07
Iter: 1499 loss: 5.38211339e-07
Iter: 1500 loss: 5.38071788e-07
Iter: 1501 loss: 5.37984079e-07
Iter: 1502 loss: 5.37987603e-07
Iter: 1503 loss: 5.37910694e-07
Iter: 1504 loss: 5.37814856e-07
Iter: 1505 loss: 5.39297e-07
Iter: 1506 loss: 5.37793255e-07
Iter: 1507 loss: 5.37649e-07
Iter: 1508 loss: 5.38173367e-07
Iter: 1509 loss: 5.37609e-07
Iter: 1510 loss: 5.37468395e-07
Iter: 1511 loss: 5.3771e-07
Iter: 1512 loss: 5.37436563e-07
Iter: 1513 loss: 5.37396318e-07
Iter: 1514 loss: 5.37371307e-07
Iter: 1515 loss: 5.37337428e-07
Iter: 1516 loss: 5.37362553e-07
Iter: 1517 loss: 5.3730497e-07
Iter: 1518 loss: 5.37255232e-07
Iter: 1519 loss: 5.37517849e-07
Iter: 1520 loss: 5.37253527e-07
Iter: 1521 loss: 5.37193e-07
Iter: 1522 loss: 5.3727166e-07
Iter: 1523 loss: 5.37205494e-07
Iter: 1524 loss: 5.37131541e-07
Iter: 1525 loss: 5.37066e-07
Iter: 1526 loss: 5.37064125e-07
Iter: 1527 loss: 5.37052188e-07
Iter: 1528 loss: 5.37545873e-07
Iter: 1529 loss: 5.3701649e-07
Iter: 1530 loss: 5.36938273e-07
Iter: 1531 loss: 5.37157689e-07
Iter: 1532 loss: 5.36917355e-07
Iter: 1533 loss: 5.36867901e-07
Iter: 1534 loss: 5.36875291e-07
Iter: 1535 loss: 5.36846585e-07
Iter: 1536 loss: 5.36749326e-07
Iter: 1537 loss: 5.36725736e-07
Iter: 1538 loss: 5.36699758e-07
Iter: 1539 loss: 5.36610457e-07
Iter: 1540 loss: 5.37434232e-07
Iter: 1541 loss: 5.36609093e-07
Iter: 1542 loss: 5.3650831e-07
Iter: 1543 loss: 5.36661e-07
Iter: 1544 loss: 5.36442e-07
Iter: 1545 loss: 5.36354776e-07
Iter: 1546 loss: 5.37436165e-07
Iter: 1547 loss: 5.36312882e-07
Iter: 1548 loss: 5.36253083e-07
Iter: 1549 loss: 5.36810489e-07
Iter: 1550 loss: 5.36243533e-07
Iter: 1551 loss: 5.36200332e-07
Iter: 1552 loss: 5.36128141e-07
Iter: 1553 loss: 5.36129619e-07
Iter: 1554 loss: 5.36014113e-07
Iter: 1555 loss: 5.36024459e-07
Iter: 1556 loss: 5.36002517e-07
Iter: 1557 loss: 5.35929871e-07
Iter: 1558 loss: 5.3594249e-07
Iter: 1559 loss: 5.35869106e-07
Iter: 1560 loss: 5.36015762e-07
Iter: 1561 loss: 5.35814479e-07
Iter: 1562 loss: 5.35743652e-07
Iter: 1563 loss: 5.36355458e-07
Iter: 1564 loss: 5.35722393e-07
Iter: 1565 loss: 5.35651452e-07
Iter: 1566 loss: 5.35741435e-07
Iter: 1567 loss: 5.35629397e-07
Iter: 1568 loss: 5.35563515e-07
Iter: 1569 loss: 5.35589038e-07
Iter: 1570 loss: 5.35519689e-07
Iter: 1571 loss: 5.35482855e-07
Iter: 1572 loss: 5.35485583e-07
Iter: 1573 loss: 5.35414188e-07
Iter: 1574 loss: 5.35452841e-07
Iter: 1575 loss: 5.3537218e-07
Iter: 1576 loss: 5.35293395e-07
Iter: 1577 loss: 5.3526594e-07
Iter: 1578 loss: 5.35212791e-07
Iter: 1579 loss: 5.35143386e-07
Iter: 1580 loss: 5.35141965e-07
Iter: 1581 loss: 5.3506119e-07
Iter: 1582 loss: 5.34999629e-07
Iter: 1583 loss: 5.34978881e-07
Iter: 1584 loss: 5.34925846e-07
Iter: 1585 loss: 5.35787194e-07
Iter: 1586 loss: 5.34894298e-07
Iter: 1587 loss: 5.34842115e-07
Iter: 1588 loss: 5.34892934e-07
Iter: 1589 loss: 5.34789365e-07
Iter: 1590 loss: 5.3472462e-07
Iter: 1591 loss: 5.34708079e-07
Iter: 1592 loss: 5.3464214e-07
Iter: 1593 loss: 5.34539595e-07
Iter: 1594 loss: 5.35697382e-07
Iter: 1595 loss: 5.345658e-07
Iter: 1596 loss: 5.34461208e-07
Iter: 1597 loss: 5.34448191e-07
Iter: 1598 loss: 5.3442028e-07
Iter: 1599 loss: 5.34336266e-07
Iter: 1600 loss: 5.3481125e-07
Iter: 1601 loss: 5.34350818e-07
Iter: 1602 loss: 5.34254809e-07
Iter: 1603 loss: 5.3455534e-07
Iter: 1604 loss: 5.34258e-07
Iter: 1605 loss: 5.34169828e-07
Iter: 1606 loss: 5.34054493e-07
Iter: 1607 loss: 5.34062508e-07
Iter: 1608 loss: 5.33981279e-07
Iter: 1609 loss: 5.33989919e-07
Iter: 1610 loss: 5.33862476e-07
Iter: 1611 loss: 5.3372429e-07
Iter: 1612 loss: 5.3497979e-07
Iter: 1613 loss: 5.3374049e-07
Iter: 1614 loss: 5.33614582e-07
Iter: 1615 loss: 5.34811647e-07
Iter: 1616 loss: 5.33676257e-07
Iter: 1617 loss: 5.33571153e-07
Iter: 1618 loss: 5.33536081e-07
Iter: 1619 loss: 5.33501293e-07
Iter: 1620 loss: 5.33415914e-07
Iter: 1621 loss: 5.34266064e-07
Iter: 1622 loss: 5.33400453e-07
Iter: 1623 loss: 5.33383798e-07
Iter: 1624 loss: 5.33264597e-07
Iter: 1625 loss: 5.33285061e-07
Iter: 1626 loss: 5.33209118e-07
Iter: 1627 loss: 5.3396e-07
Iter: 1628 loss: 5.33206503e-07
Iter: 1629 loss: 5.33145908e-07
Iter: 1630 loss: 5.33218156e-07
Iter: 1631 loss: 5.33136244e-07
Iter: 1632 loss: 5.33063258e-07
Iter: 1633 loss: 5.33230263e-07
Iter: 1634 loss: 5.33040861e-07
Iter: 1635 loss: 5.32969352e-07
Iter: 1636 loss: 5.3354745e-07
Iter: 1637 loss: 5.33013122e-07
Iter: 1638 loss: 5.32962e-07
Iter: 1639 loss: 5.32854813e-07
Iter: 1640 loss: 5.32831223e-07
Iter: 1641 loss: 5.32768809e-07
Iter: 1642 loss: 5.32644606e-07
Iter: 1643 loss: 5.32631873e-07
Iter: 1644 loss: 5.32458898e-07
Iter: 1645 loss: 5.33259254e-07
Iter: 1646 loss: 5.32446279e-07
Iter: 1647 loss: 5.32386252e-07
Iter: 1648 loss: 5.32363913e-07
Iter: 1649 loss: 5.32289675e-07
Iter: 1650 loss: 5.32188608e-07
Iter: 1651 loss: 5.32153308e-07
Iter: 1652 loss: 5.32081856e-07
Iter: 1653 loss: 5.33201217e-07
Iter: 1654 loss: 5.32102547e-07
Iter: 1655 loss: 5.32018817e-07
Iter: 1656 loss: 5.32115166e-07
Iter: 1657 loss: 5.32002218e-07
Iter: 1658 loss: 5.31927753e-07
Iter: 1659 loss: 5.32086119e-07
Iter: 1660 loss: 5.31914907e-07
Iter: 1661 loss: 5.31888e-07
Iter: 1662 loss: 5.32197532e-07
Iter: 1663 loss: 5.3187631e-07
Iter: 1664 loss: 5.31803153e-07
Iter: 1665 loss: 5.31700607e-07
Iter: 1666 loss: 5.31727e-07
Iter: 1667 loss: 5.31682758e-07
Iter: 1668 loss: 5.31650301e-07
Iter: 1669 loss: 5.316017e-07
Iter: 1670 loss: 5.3155685e-07
Iter: 1671 loss: 5.31564069e-07
Iter: 1672 loss: 5.31443106e-07
Iter: 1673 loss: 5.31338401e-07
Iter: 1674 loss: 5.31339424e-07
Iter: 1675 loss: 5.31189471e-07
Iter: 1676 loss: 5.31614432e-07
Iter: 1677 loss: 5.31162641e-07
Iter: 1678 loss: 5.30991088e-07
Iter: 1679 loss: 5.31689e-07
Iter: 1680 loss: 5.30984607e-07
Iter: 1681 loss: 5.30843863e-07
Iter: 1682 loss: 5.30856425e-07
Iter: 1683 loss: 5.30824309e-07
Iter: 1684 loss: 5.30807483e-07
Iter: 1685 loss: 5.30760644e-07
Iter: 1686 loss: 5.30681689e-07
Iter: 1687 loss: 5.31423836e-07
Iter: 1688 loss: 5.3066293e-07
Iter: 1689 loss: 5.30606144e-07
Iter: 1690 loss: 5.30511386e-07
Iter: 1691 loss: 5.30528155e-07
Iter: 1692 loss: 5.3043459e-07
Iter: 1693 loss: 5.314742e-07
Iter: 1694 loss: 5.30454599e-07
Iter: 1695 loss: 5.30369789e-07
Iter: 1696 loss: 5.30367629e-07
Iter: 1697 loss: 5.30297882e-07
Iter: 1698 loss: 5.30194427e-07
Iter: 1699 loss: 5.30773832e-07
Iter: 1700 loss: 5.30237571e-07
Iter: 1701 loss: 5.30176578e-07
Iter: 1702 loss: 5.30411683e-07
Iter: 1703 loss: 5.30125703e-07
Iter: 1704 loss: 5.30087618e-07
Iter: 1705 loss: 5.29957219e-07
Iter: 1706 loss: 5.32581225e-07
Iter: 1707 loss: 5.29952558e-07
Iter: 1708 loss: 5.29816077e-07
Iter: 1709 loss: 5.30185048e-07
Iter: 1710 loss: 5.29773558e-07
Iter: 1711 loss: 5.29674878e-07
Iter: 1712 loss: 5.29967338e-07
Iter: 1713 loss: 5.29582394e-07
Iter: 1714 loss: 5.29450404e-07
Iter: 1715 loss: 5.29681358e-07
Iter: 1716 loss: 5.2936474e-07
Iter: 1717 loss: 5.29362126e-07
Iter: 1718 loss: 5.29300905e-07
Iter: 1719 loss: 5.29221325e-07
Iter: 1720 loss: 5.29162207e-07
Iter: 1721 loss: 5.29146917e-07
Iter: 1722 loss: 5.29016177e-07
Iter: 1723 loss: 5.30389e-07
Iter: 1724 loss: 5.29050908e-07
Iter: 1725 loss: 5.28961436e-07
Iter: 1726 loss: 5.2888015e-07
Iter: 1727 loss: 5.28877e-07
Iter: 1728 loss: 5.28796136e-07
Iter: 1729 loss: 5.29478541e-07
Iter: 1730 loss: 5.28779253e-07
Iter: 1731 loss: 5.28721216e-07
Iter: 1732 loss: 5.29016745e-07
Iter: 1733 loss: 5.28700411e-07
Iter: 1734 loss: 5.28638964e-07
Iter: 1735 loss: 5.28668409e-07
Iter: 1736 loss: 5.28649593e-07
Iter: 1737 loss: 5.28565636e-07
Iter: 1738 loss: 5.29271063e-07
Iter: 1739 loss: 5.28563874e-07
Iter: 1740 loss: 5.28500095e-07
Iter: 1741 loss: 5.28496969e-07
Iter: 1742 loss: 5.2917153e-07
Iter: 1743 loss: 5.28474288e-07
Iter: 1744 loss: 5.28340081e-07
Iter: 1745 loss: 5.28509645e-07
Iter: 1746 loss: 5.28298642e-07
Iter: 1747 loss: 5.28214798e-07
Iter: 1748 loss: 5.28690634e-07
Iter: 1749 loss: 5.28205078e-07
Iter: 1750 loss: 5.28059786e-07
Iter: 1751 loss: 5.28232931e-07
Iter: 1752 loss: 5.27997258e-07
Iter: 1753 loss: 5.27924044e-07
Iter: 1754 loss: 5.27907389e-07
Iter: 1755 loss: 5.2782957e-07
Iter: 1756 loss: 5.27757322e-07
Iter: 1757 loss: 5.27795407e-07
Iter: 1758 loss: 5.27679049e-07
Iter: 1759 loss: 5.28729174e-07
Iter: 1760 loss: 5.27670522e-07
Iter: 1761 loss: 5.27613508e-07
Iter: 1762 loss: 5.27587645e-07
Iter: 1763 loss: 5.27544785e-07
Iter: 1764 loss: 5.2749624e-07
Iter: 1765 loss: 5.27924726e-07
Iter: 1766 loss: 5.27476914e-07
Iter: 1767 loss: 5.27401426e-07
Iter: 1768 loss: 5.27632e-07
Iter: 1769 loss: 5.27391137e-07
Iter: 1770 loss: 5.27331395e-07
Iter: 1771 loss: 5.27499537e-07
Iter: 1772 loss: 5.27333896e-07
Iter: 1773 loss: 5.27289558e-07
Iter: 1774 loss: 5.27500674e-07
Iter: 1775 loss: 5.27250336e-07
Iter: 1776 loss: 5.27205486e-07
Iter: 1777 loss: 5.27101065e-07
Iter: 1778 loss: 5.2711539e-07
Iter: 1779 loss: 5.27054681e-07
Iter: 1780 loss: 5.27166208e-07
Iter: 1781 loss: 5.27006478e-07
Iter: 1782 loss: 5.26890858e-07
Iter: 1783 loss: 5.27085149e-07
Iter: 1784 loss: 5.26863289e-07
Iter: 1785 loss: 5.26794793e-07
Iter: 1786 loss: 5.26779104e-07
Iter: 1787 loss: 5.2676e-07
Iter: 1788 loss: 5.26925476e-07
Iter: 1789 loss: 5.2672749e-07
Iter: 1790 loss: 5.26663e-07
Iter: 1791 loss: 5.26694919e-07
Iter: 1792 loss: 5.26617555e-07
Iter: 1793 loss: 5.26556278e-07
Iter: 1794 loss: 5.27120335e-07
Iter: 1795 loss: 5.26541953e-07
Iter: 1796 loss: 5.26495512e-07
Iter: 1797 loss: 5.26408485e-07
Iter: 1798 loss: 5.27941438e-07
Iter: 1799 loss: 5.26393706e-07
Iter: 1800 loss: 5.2632754e-07
Iter: 1801 loss: 5.27418308e-07
Iter: 1802 loss: 5.26344706e-07
Iter: 1803 loss: 5.26249607e-07
Iter: 1804 loss: 5.26356303e-07
Iter: 1805 loss: 5.2621931e-07
Iter: 1806 loss: 5.26149392e-07
Iter: 1807 loss: 5.26157237e-07
Iter: 1808 loss: 5.26130066e-07
Iter: 1809 loss: 5.26054862e-07
Iter: 1810 loss: 5.27190878e-07
Iter: 1811 loss: 5.2604446e-07
Iter: 1812 loss: 5.25962491e-07
Iter: 1813 loss: 5.26291e-07
Iter: 1814 loss: 5.25955556e-07
Iter: 1815 loss: 5.25930318e-07
Iter: 1816 loss: 5.25920882e-07
Iter: 1817 loss: 5.25889732e-07
Iter: 1818 loss: 5.25824589e-07
Iter: 1819 loss: 5.25872963e-07
Iter: 1820 loss: 5.25806627e-07
Iter: 1821 loss: 5.2571977e-07
Iter: 1822 loss: 5.26382451e-07
Iter: 1823 loss: 5.2569942e-07
Iter: 1824 loss: 5.25651103e-07
Iter: 1825 loss: 5.25803443e-07
Iter: 1826 loss: 5.25676285e-07
Iter: 1827 loss: 5.25597045e-07
Iter: 1828 loss: 5.25545545e-07
Iter: 1829 loss: 5.25565383e-07
Iter: 1830 loss: 5.25461758e-07
Iter: 1831 loss: 5.25469204e-07
Iter: 1832 loss: 5.25429641e-07
Iter: 1833 loss: 5.25384507e-07
Iter: 1834 loss: 5.26635233e-07
Iter: 1835 loss: 5.25381552e-07
Iter: 1836 loss: 5.25278e-07
Iter: 1837 loss: 5.25841187e-07
Iter: 1838 loss: 5.25305154e-07
Iter: 1839 loss: 5.25239329e-07
Iter: 1840 loss: 5.25857217e-07
Iter: 1841 loss: 5.25225744e-07
Iter: 1842 loss: 5.25183452e-07
Iter: 1843 loss: 5.25177825e-07
Iter: 1844 loss: 5.25178223e-07
Iter: 1845 loss: 5.25097562e-07
Iter: 1846 loss: 5.25816233e-07
Iter: 1847 loss: 5.25101314e-07
Iter: 1848 loss: 5.25084602e-07
Iter: 1849 loss: 5.25024e-07
Iter: 1850 loss: 5.25557482e-07
Iter: 1851 loss: 5.2496955e-07
Iter: 1852 loss: 5.24884513e-07
Iter: 1853 loss: 5.24901395e-07
Iter: 1854 loss: 5.24825623e-07
Iter: 1855 loss: 5.24727398e-07
Iter: 1856 loss: 5.25737619e-07
Iter: 1857 loss: 5.24698748e-07
Iter: 1858 loss: 5.24611039e-07
Iter: 1859 loss: 5.24786344e-07
Iter: 1860 loss: 5.24571419e-07
Iter: 1861 loss: 5.24492748e-07
Iter: 1862 loss: 5.24499342e-07
Iter: 1863 loss: 5.24452958e-07
Iter: 1864 loss: 5.24398047e-07
Iter: 1865 loss: 5.24393613e-07
Iter: 1866 loss: 5.24327561e-07
Iter: 1867 loss: 5.25131554e-07
Iter: 1868 loss: 5.24339498e-07
Iter: 1869 loss: 5.2427356e-07
Iter: 1870 loss: 5.2424997e-07
Iter: 1871 loss: 5.2424457e-07
Iter: 1872 loss: 5.24178517e-07
Iter: 1873 loss: 5.24424649e-07
Iter: 1874 loss: 5.24189431e-07
Iter: 1875 loss: 5.24169423e-07
Iter: 1876 loss: 5.2416766e-07
Iter: 1877 loss: 5.24152256e-07
Iter: 1878 loss: 5.24082509e-07
Iter: 1879 loss: 5.24085237e-07
Iter: 1880 loss: 5.24037205e-07
Iter: 1881 loss: 5.24492918e-07
Iter: 1882 loss: 5.24035215e-07
Iter: 1883 loss: 5.23998835e-07
Iter: 1884 loss: 5.23910671e-07
Iter: 1885 loss: 5.24900429e-07
Iter: 1886 loss: 5.23908682e-07
Iter: 1887 loss: 5.23808296e-07
Iter: 1888 loss: 5.24274583e-07
Iter: 1889 loss: 5.23814947e-07
Iter: 1890 loss: 5.23706774e-07
Iter: 1891 loss: 5.23873155e-07
Iter: 1892 loss: 5.23673464e-07
Iter: 1893 loss: 5.23632309e-07
Iter: 1894 loss: 5.23642143e-07
Iter: 1895 loss: 5.23543918e-07
Iter: 1896 loss: 5.23527376e-07
Iter: 1897 loss: 5.23535618e-07
Iter: 1898 loss: 5.23446772e-07
Iter: 1899 loss: 5.23468e-07
Iter: 1900 loss: 5.23383733e-07
Iter: 1901 loss: 5.23326946e-07
Iter: 1902 loss: 5.23279937e-07
Iter: 1903 loss: 5.23222184e-07
Iter: 1904 loss: 5.23128108e-07
Iter: 1905 loss: 5.24545214e-07
Iter: 1906 loss: 5.23153631e-07
Iter: 1907 loss: 5.23051767e-07
Iter: 1908 loss: 5.2345348e-07
Iter: 1909 loss: 5.23045685e-07
Iter: 1910 loss: 5.22988387e-07
Iter: 1911 loss: 5.23066319e-07
Iter: 1912 loss: 5.22979406e-07
Iter: 1913 loss: 5.22935466e-07
Iter: 1914 loss: 5.23045514e-07
Iter: 1915 loss: 5.22906248e-07
Iter: 1916 loss: 5.22820756e-07
Iter: 1917 loss: 5.23194501e-07
Iter: 1918 loss: 5.22816663e-07
Iter: 1919 loss: 5.22752941e-07
Iter: 1920 loss: 5.2278159e-07
Iter: 1921 loss: 5.22728897e-07
Iter: 1922 loss: 5.22702067e-07
Iter: 1923 loss: 5.2263033e-07
Iter: 1924 loss: 5.22599919e-07
Iter: 1925 loss: 5.22514426e-07
Iter: 1926 loss: 5.22685298e-07
Iter: 1927 loss: 5.22475659e-07
Iter: 1928 loss: 5.22417395e-07
Iter: 1929 loss: 5.22412051e-07
Iter: 1930 loss: 5.22353105e-07
Iter: 1931 loss: 5.22342702e-07
Iter: 1932 loss: 5.22269488e-07
Iter: 1933 loss: 5.22224695e-07
Iter: 1934 loss: 5.2224965e-07
Iter: 1935 loss: 5.22172343e-07
Iter: 1936 loss: 5.22063715e-07
Iter: 1937 loss: 5.22129312e-07
Iter: 1938 loss: 5.21996753e-07
Iter: 1939 loss: 5.2193559e-07
Iter: 1940 loss: 5.22239532e-07
Iter: 1941 loss: 5.21906429e-07
Iter: 1942 loss: 5.21848108e-07
Iter: 1943 loss: 5.21831737e-07
Iter: 1944 loss: 5.21795585e-07
Iter: 1945 loss: 5.21814911e-07
Iter: 1946 loss: 5.21760171e-07
Iter: 1947 loss: 5.21728111e-07
Iter: 1948 loss: 5.21708444e-07
Iter: 1949 loss: 5.21676043e-07
Iter: 1950 loss: 5.21596e-07
Iter: 1951 loss: 5.22603557e-07
Iter: 1952 loss: 5.21583843e-07
Iter: 1953 loss: 5.21511424e-07
Iter: 1954 loss: 5.21542347e-07
Iter: 1955 loss: 5.21467484e-07
Iter: 1956 loss: 5.21403649e-07
Iter: 1957 loss: 5.21694e-07
Iter: 1958 loss: 5.21410698e-07
Iter: 1959 loss: 5.21365223e-07
Iter: 1960 loss: 5.21272909e-07
Iter: 1961 loss: 5.21242782e-07
Iter: 1962 loss: 5.21149389e-07
Iter: 1963 loss: 5.21898357e-07
Iter: 1964 loss: 5.21143079e-07
Iter: 1965 loss: 5.21081688e-07
Iter: 1966 loss: 5.21084644e-07
Iter: 1967 loss: 5.21037123e-07
Iter: 1968 loss: 5.20950209e-07
Iter: 1969 loss: 5.2174471e-07
Iter: 1970 loss: 5.20919684e-07
Iter: 1971 loss: 5.20825779e-07
Iter: 1972 loss: 5.21272113e-07
Iter: 1973 loss: 5.2079173e-07
Iter: 1974 loss: 5.20726417e-07
Iter: 1975 loss: 5.21057e-07
Iter: 1976 loss: 5.20719709e-07
Iter: 1977 loss: 5.20625861e-07
Iter: 1978 loss: 5.20604942e-07
Iter: 1979 loss: 5.20566459e-07
Iter: 1980 loss: 5.20499043e-07
Iter: 1981 loss: 5.20524623e-07
Iter: 1982 loss: 5.20468e-07
Iter: 1983 loss: 5.2051962e-07
Iter: 1984 loss: 5.20402693e-07
Iter: 1985 loss: 5.20351136e-07
Iter: 1986 loss: 5.20551225e-07
Iter: 1987 loss: 5.20350852e-07
Iter: 1988 loss: 5.20285312e-07
Iter: 1989 loss: 5.2027076e-07
Iter: 1990 loss: 5.20223921e-07
Iter: 1991 loss: 5.20141612e-07
Iter: 1992 loss: 5.20185438e-07
Iter: 1993 loss: 5.20090396e-07
Iter: 1994 loss: 5.2003054e-07
Iter: 1995 loss: 5.20021558e-07
Iter: 1996 loss: 5.19992739e-07
Iter: 1997 loss: 5.19858929e-07
Iter: 1998 loss: 5.21566562e-07
Iter: 1999 loss: 5.19896616e-07
Iter: 2000 loss: 5.19793616e-07
Iter: 2001 loss: 5.19783612e-07
Iter: 2002 loss: 5.19730747e-07
Iter: 2003 loss: 5.19870127e-07
Iter: 2004 loss: 5.19699029e-07
Iter: 2005 loss: 5.19640366e-07
Iter: 2006 loss: 5.19580226e-07
Iter: 2007 loss: 5.19558569e-07
Iter: 2008 loss: 5.19482057e-07
Iter: 2009 loss: 5.19567436e-07
Iter: 2010 loss: 5.19448804e-07
Iter: 2011 loss: 5.19371952e-07
Iter: 2012 loss: 5.20034064e-07
Iter: 2013 loss: 5.19331877e-07
Iter: 2014 loss: 5.19313801e-07
Iter: 2015 loss: 5.1928788e-07
Iter: 2016 loss: 5.19282935e-07
Iter: 2017 loss: 5.19197272e-07
Iter: 2018 loss: 5.20375465e-07
Iter: 2019 loss: 5.19212051e-07
Iter: 2020 loss: 5.19187381e-07
Iter: 2021 loss: 5.19156686e-07
Iter: 2022 loss: 5.19149353e-07
Iter: 2023 loss: 5.190916e-07
Iter: 2024 loss: 5.19904e-07
Iter: 2025 loss: 5.19072501e-07
Iter: 2026 loss: 5.19033506e-07
Iter: 2027 loss: 5.19480352e-07
Iter: 2028 loss: 5.19007529e-07
Iter: 2029 loss: 5.1897706e-07
Iter: 2030 loss: 5.191132e-07
Iter: 2031 loss: 5.1893818e-07
Iter: 2032 loss: 5.18895433e-07
Iter: 2033 loss: 5.18853881e-07
Iter: 2034 loss: 5.18844104e-07
Iter: 2035 loss: 5.18779245e-07
Iter: 2036 loss: 5.18776233e-07
Iter: 2037 loss: 5.18770719e-07
Iter: 2038 loss: 5.18685511e-07
Iter: 2039 loss: 5.20358753e-07
Iter: 2040 loss: 5.18674142e-07
Iter: 2041 loss: 5.18597801e-07
Iter: 2042 loss: 5.18730701e-07
Iter: 2043 loss: 5.185737e-07
Iter: 2044 loss: 5.18500769e-07
Iter: 2045 loss: 5.18732804e-07
Iter: 2046 loss: 5.18438469e-07
Iter: 2047 loss: 5.18406182e-07
Iter: 2048 loss: 5.18513161e-07
Iter: 2049 loss: 5.18354227e-07
Iter: 2050 loss: 5.1823838e-07
Iter: 2051 loss: 5.19403898e-07
Iter: 2052 loss: 5.18247873e-07
Iter: 2053 loss: 5.18218485e-07
Iter: 2054 loss: 5.18225363e-07
Iter: 2055 loss: 5.18150387e-07
Iter: 2056 loss: 5.18093543e-07
Iter: 2057 loss: 5.18874458e-07
Iter: 2058 loss: 5.18072852e-07
Iter: 2059 loss: 5.18049603e-07
Iter: 2060 loss: 5.17975081e-07
Iter: 2061 loss: 5.19571756e-07
Iter: 2062 loss: 5.17976389e-07
Iter: 2063 loss: 5.17852072e-07
Iter: 2064 loss: 5.18716035e-07
Iter: 2065 loss: 5.17856108e-07
Iter: 2066 loss: 5.17794604e-07
Iter: 2067 loss: 5.1798645e-07
Iter: 2068 loss: 5.17755041e-07
Iter: 2069 loss: 5.1770445e-07
Iter: 2070 loss: 5.17679155e-07
Iter: 2071 loss: 5.17659032e-07
Iter: 2072 loss: 5.17621856e-07
Iter: 2073 loss: 5.17611738e-07
Iter: 2074 loss: 5.1757911e-07
Iter: 2075 loss: 5.17548528e-07
Iter: 2076 loss: 5.17543526e-07
Iter: 2077 loss: 5.17505725e-07
Iter: 2078 loss: 5.17530339e-07
Iter: 2079 loss: 5.17462695e-07
Iter: 2080 loss: 5.17428589e-07
Iter: 2081 loss: 5.17563194e-07
Iter: 2082 loss: 5.17412673e-07
Iter: 2083 loss: 5.17373621e-07
Iter: 2084 loss: 5.1750817e-07
Iter: 2085 loss: 5.17329454e-07
Iter: 2086 loss: 5.17279545e-07
Iter: 2087 loss: 5.17866e-07
Iter: 2088 loss: 5.17272269e-07
Iter: 2089 loss: 5.17260617e-07
Iter: 2090 loss: 5.17194792e-07
Iter: 2091 loss: 5.17194621e-07
Iter: 2092 loss: 5.17170577e-07
Iter: 2093 loss: 5.17185811e-07
Iter: 2094 loss: 5.17107651e-07
Iter: 2095 loss: 5.17014712e-07
Iter: 2096 loss: 5.18114064e-07
Iter: 2097 loss: 5.17032277e-07
Iter: 2098 loss: 5.16928708e-07
Iter: 2099 loss: 5.17358615e-07
Iter: 2100 loss: 5.16908642e-07
Iter: 2101 loss: 5.16840203e-07
Iter: 2102 loss: 5.17189278e-07
Iter: 2103 loss: 5.16814112e-07
Iter: 2104 loss: 5.16764658e-07
Iter: 2105 loss: 5.16759201e-07
Iter: 2106 loss: 5.1671833e-07
Iter: 2107 loss: 5.16639261e-07
Iter: 2108 loss: 5.17520789e-07
Iter: 2109 loss: 5.16634e-07
Iter: 2110 loss: 5.16601233e-07
Iter: 2111 loss: 5.16521709e-07
Iter: 2112 loss: 5.16533305e-07
Iter: 2113 loss: 5.16462592e-07
Iter: 2114 loss: 5.16620787e-07
Iter: 2115 loss: 5.16450712e-07
Iter: 2116 loss: 5.16373575e-07
Iter: 2117 loss: 5.16485215e-07
Iter: 2118 loss: 5.16329465e-07
Iter: 2119 loss: 5.16261309e-07
Iter: 2120 loss: 5.16420471e-07
Iter: 2121 loss: 5.16238629e-07
Iter: 2122 loss: 5.16168882e-07
Iter: 2123 loss: 5.16169848e-07
Iter: 2124 loss: 5.16138243e-07
Iter: 2125 loss: 5.16106752e-07
Iter: 2126 loss: 5.17335e-07
Iter: 2127 loss: 5.16104706e-07
Iter: 2128 loss: 5.1602251e-07
Iter: 2129 loss: 5.16951445e-07
Iter: 2130 loss: 5.16028081e-07
Iter: 2131 loss: 5.16022226e-07
Iter: 2132 loss: 5.15975387e-07
Iter: 2133 loss: 5.1600108e-07
Iter: 2134 loss: 5.1590257e-07
Iter: 2135 loss: 5.16218506e-07
Iter: 2136 loss: 5.1587034e-07
Iter: 2137 loss: 5.15826855e-07
Iter: 2138 loss: 5.15997272e-07
Iter: 2139 loss: 5.15800934e-07
Iter: 2140 loss: 5.15728402e-07
Iter: 2141 loss: 5.15742386e-07
Iter: 2142 loss: 5.15691909e-07
Iter: 2143 loss: 5.15628869e-07
Iter: 2144 loss: 5.16541036e-07
Iter: 2145 loss: 5.15631712e-07
Iter: 2146 loss: 5.15615795e-07
Iter: 2147 loss: 5.15517229e-07
Iter: 2148 loss: 5.15489205e-07
Iter: 2149 loss: 5.15429747e-07
Iter: 2150 loss: 5.1562688e-07
Iter: 2151 loss: 5.15440263e-07
Iter: 2152 loss: 5.15372108e-07
Iter: 2153 loss: 5.15458623e-07
Iter: 2154 loss: 5.15308216e-07
Iter: 2155 loss: 5.15258535e-07
Iter: 2156 loss: 5.15380691e-07
Iter: 2157 loss: 5.15211696e-07
Iter: 2158 loss: 5.1509403e-07
Iter: 2159 loss: 5.15630745e-07
Iter: 2160 loss: 5.15099373e-07
Iter: 2161 loss: 5.15101874e-07
Iter: 2162 loss: 5.1508448e-07
Iter: 2163 loss: 5.15026727e-07
Iter: 2164 loss: 5.14978353e-07
Iter: 2165 loss: 5.15947534e-07
Iter: 2166 loss: 5.15006207e-07
Iter: 2167 loss: 5.14937653e-07
Iter: 2168 loss: 5.15461579e-07
Iter: 2169 loss: 5.14906901e-07
Iter: 2170 loss: 5.14866315e-07
Iter: 2171 loss: 5.14795147e-07
Iter: 2172 loss: 5.14821863e-07
Iter: 2173 loss: 5.14720455e-07
Iter: 2174 loss: 5.14803219e-07
Iter: 2175 loss: 5.14700332e-07
Iter: 2176 loss: 5.14667477e-07
Iter: 2177 loss: 5.14645706e-07
Iter: 2178 loss: 5.14641386e-07
Iter: 2179 loss: 5.14587e-07
Iter: 2180 loss: 5.16246871e-07
Iter: 2181 loss: 5.14566e-07
Iter: 2182 loss: 5.14512806e-07
Iter: 2183 loss: 5.15185945e-07
Iter: 2184 loss: 5.1450445e-07
Iter: 2185 loss: 5.14450448e-07
Iter: 2186 loss: 5.14676799e-07
Iter: 2187 loss: 5.14448516e-07
Iter: 2188 loss: 5.14376779e-07
Iter: 2189 loss: 5.14283215e-07
Iter: 2190 loss: 5.16309115e-07
Iter: 2191 loss: 5.14267185e-07
Iter: 2192 loss: 5.14202327e-07
Iter: 2193 loss: 5.14819476e-07
Iter: 2194 loss: 5.14185501e-07
Iter: 2195 loss: 5.1411763e-07
Iter: 2196 loss: 5.14567319e-07
Iter: 2197 loss: 5.14088299e-07
Iter: 2198 loss: 5.14034184e-07
Iter: 2199 loss: 5.14807596e-07
Iter: 2200 loss: 5.14030262e-07
Iter: 2201 loss: 5.14002579e-07
Iter: 2202 loss: 5.13927546e-07
Iter: 2203 loss: 5.13914472e-07
Iter: 2204 loss: 5.13894634e-07
Iter: 2205 loss: 5.145003e-07
Iter: 2206 loss: 5.13832674e-07
Iter: 2207 loss: 5.13827e-07
Iter: 2208 loss: 5.13744908e-07
Iter: 2209 loss: 5.13738e-07
Iter: 2210 loss: 5.13663053e-07
Iter: 2211 loss: 5.14297653e-07
Iter: 2212 loss: 5.13652196e-07
Iter: 2213 loss: 5.13594955e-07
Iter: 2214 loss: 5.1374775e-07
Iter: 2215 loss: 5.13574321e-07
Iter: 2216 loss: 5.13470127e-07
Iter: 2217 loss: 5.13499913e-07
Iter: 2218 loss: 5.13467739e-07
Iter: 2219 loss: 5.13405894e-07
Iter: 2220 loss: 5.14122689e-07
Iter: 2221 loss: 5.1338003e-07
Iter: 2222 loss: 5.13338591e-07
Iter: 2223 loss: 5.1330619e-07
Iter: 2224 loss: 5.13285386e-07
Iter: 2225 loss: 5.13232862e-07
Iter: 2226 loss: 5.13190344e-07
Iter: 2227 loss: 5.13200746e-07
Iter: 2228 loss: 5.13128498e-07
Iter: 2229 loss: 5.13639179e-07
Iter: 2230 loss: 5.1307984e-07
Iter: 2231 loss: 5.13032262e-07
Iter: 2232 loss: 5.13033115e-07
Iter: 2233 loss: 5.12987299e-07
Iter: 2234 loss: 5.1298548e-07
Iter: 2235 loss: 5.12939664e-07
Iter: 2236 loss: 5.12931081e-07
Iter: 2237 loss: 5.13238206e-07
Iter: 2238 loss: 5.12921133e-07
Iter: 2239 loss: 5.12859401e-07
Iter: 2240 loss: 5.12831491e-07
Iter: 2241 loss: 5.12819611e-07
Iter: 2242 loss: 5.12739462e-07
Iter: 2243 loss: 5.12921702e-07
Iter: 2244 loss: 5.12748557e-07
Iter: 2245 loss: 5.12639531e-07
Iter: 2246 loss: 5.13425846e-07
Iter: 2247 loss: 5.12669374e-07
Iter: 2248 loss: 5.12597467e-07
Iter: 2249 loss: 5.12557165e-07
Iter: 2250 loss: 5.12524366e-07
Iter: 2251 loss: 5.12442227e-07
Iter: 2252 loss: 5.13092232e-07
Iter: 2253 loss: 5.12436486e-07
Iter: 2254 loss: 5.12396923e-07
Iter: 2255 loss: 5.12522774e-07
Iter: 2256 loss: 5.12384361e-07
Iter: 2257 loss: 5.12348436e-07
Iter: 2258 loss: 5.12259362e-07
Iter: 2259 loss: 5.12274596e-07
Iter: 2260 loss: 5.12156817e-07
Iter: 2261 loss: 5.12444274e-07
Iter: 2262 loss: 5.12109523e-07
Iter: 2263 loss: 5.12044551e-07
Iter: 2264 loss: 5.12043471e-07
Iter: 2265 loss: 5.12004306e-07
Iter: 2266 loss: 5.12327e-07
Iter: 2267 loss: 5.11962639e-07
Iter: 2268 loss: 5.11929102e-07
Iter: 2269 loss: 5.11932569e-07
Iter: 2270 loss: 5.11894598e-07
Iter: 2271 loss: 5.11813369e-07
Iter: 2272 loss: 5.12075246e-07
Iter: 2273 loss: 5.11798135e-07
Iter: 2274 loss: 5.11730263e-07
Iter: 2275 loss: 5.11712813e-07
Iter: 2276 loss: 5.11704116e-07
Iter: 2277 loss: 5.11539042e-07
Iter: 2278 loss: 5.11952e-07
Iter: 2279 loss: 5.11594806e-07
Iter: 2280 loss: 5.11524e-07
Iter: 2281 loss: 5.12514248e-07
Iter: 2282 loss: 5.11531198e-07
Iter: 2283 loss: 5.11477765e-07
Iter: 2284 loss: 5.11456847e-07
Iter: 2285 loss: 5.11428254e-07
Iter: 2286 loss: 5.11390738e-07
Iter: 2287 loss: 5.12097699e-07
Iter: 2288 loss: 5.11407e-07
Iter: 2289 loss: 5.11343558e-07
Iter: 2290 loss: 5.1132929e-07
Iter: 2291 loss: 5.11303881e-07
Iter: 2292 loss: 5.11250391e-07
Iter: 2293 loss: 5.11372662e-07
Iter: 2294 loss: 5.11207361e-07
Iter: 2295 loss: 5.11147846e-07
Iter: 2296 loss: 5.11196845e-07
Iter: 2297 loss: 5.11132384e-07
Iter: 2298 loss: 5.11063206e-07
Iter: 2299 loss: 5.11054282e-07
Iter: 2300 loss: 5.11032511e-07
Iter: 2301 loss: 5.10942868e-07
Iter: 2302 loss: 5.12566203e-07
Iter: 2303 loss: 5.10977543e-07
Iter: 2304 loss: 5.1085226e-07
Iter: 2305 loss: 5.11803762e-07
Iter: 2306 loss: 5.10863231e-07
Iter: 2307 loss: 5.10820541e-07
Iter: 2308 loss: 5.10772793e-07
Iter: 2309 loss: 5.10728398e-07
Iter: 2310 loss: 5.10681048e-07
Iter: 2311 loss: 5.10848395e-07
Iter: 2312 loss: 5.10642622e-07
Iter: 2313 loss: 5.10582367e-07
Iter: 2314 loss: 5.11333667e-07
Iter: 2315 loss: 5.10553321e-07
Iter: 2316 loss: 5.10514383e-07
Iter: 2317 loss: 5.10676955e-07
Iter: 2318 loss: 5.10465043e-07
Iter: 2319 loss: 5.10423433e-07
Iter: 2320 loss: 5.10568782e-07
Iter: 2321 loss: 5.10427753e-07
Iter: 2322 loss: 5.10364032e-07
Iter: 2323 loss: 5.10437246e-07
Iter: 2324 loss: 5.10350333e-07
Iter: 2325 loss: 5.10291443e-07
Iter: 2326 loss: 5.10324753e-07
Iter: 2327 loss: 5.10264272e-07
Iter: 2328 loss: 5.101856e-07
Iter: 2329 loss: 5.10200607e-07
Iter: 2330 loss: 5.10131485e-07
Iter: 2331 loss: 5.10108521e-07
Iter: 2332 loss: 5.10119833e-07
Iter: 2333 loss: 5.10040479e-07
Iter: 2334 loss: 5.10143195e-07
Iter: 2335 loss: 5.10016946e-07
Iter: 2336 loss: 5.09963513e-07
Iter: 2337 loss: 5.09970391e-07
Iter: 2338 loss: 5.09928782e-07
Iter: 2339 loss: 5.09881943e-07
Iter: 2340 loss: 5.10375287e-07
Iter: 2341 loss: 5.09879214e-07
Iter: 2342 loss: 5.09825e-07
Iter: 2343 loss: 5.09808615e-07
Iter: 2344 loss: 5.09782e-07
Iter: 2345 loss: 5.0973722e-07
Iter: 2346 loss: 5.09949587e-07
Iter: 2347 loss: 5.09752624e-07
Iter: 2348 loss: 5.09669462e-07
Iter: 2349 loss: 5.09974711e-07
Iter: 2350 loss: 5.09663607e-07
Iter: 2351 loss: 5.09627625e-07
Iter: 2352 loss: 5.09603581e-07
Iter: 2353 loss: 5.09572828e-07
Iter: 2354 loss: 5.09505867e-07
Iter: 2355 loss: 5.10208451e-07
Iter: 2356 loss: 5.09492281e-07
Iter: 2357 loss: 5.09416452e-07
Iter: 2358 loss: 5.09394795e-07
Iter: 2359 loss: 5.09401e-07
Iter: 2360 loss: 5.09309473e-07
Iter: 2361 loss: 5.09356198e-07
Iter: 2362 loss: 5.09272411e-07
Iter: 2363 loss: 5.09164181e-07
Iter: 2364 loss: 5.09600738e-07
Iter: 2365 loss: 5.09163328e-07
Iter: 2366 loss: 5.09134168e-07
Iter: 2367 loss: 5.09107736e-07
Iter: 2368 loss: 5.09112056e-07
Iter: 2369 loss: 5.09097674e-07
Iter: 2370 loss: 5.0909324e-07
Iter: 2371 loss: 5.09090398e-07
Iter: 2372 loss: 5.09107849e-07
Iter: 2373 loss: 5.09088409e-07
Iter: 2374 loss: 5.09106087e-07
Iter: 2375 loss: 5.09086e-07
Iter: 2376 loss: 5.09102e-07
Iter: 2377 loss: 5.09106883e-07
Iter: 2378 loss: 5.0909739e-07
Iter: 2379 loss: 5.09115807e-07
Iter: 2380 loss: 5.09100232e-07
Iter: 2381 loss: 5.0910262e-07
Iter: 2382 loss: 5.09109952e-07
Iter: 2383 loss: 5.09106655e-07
Iter: 2384 loss: 5.0910603e-07
Iter: 2385 loss: 5.09103586e-07
Iter: 2386 loss: 5.09111601e-07
Iter: 2387 loss: 5.09106258e-07
Iter: 2388 loss: 5.09108418e-07
Iter: 2389 loss: 5.09107053e-07
Iter: 2390 loss: 5.09107167e-07
Iter: 2391 loss: 5.09108418e-07
Iter: 2392 loss: 5.09108077e-07
Iter: 2393 loss: 5.09108418e-07
Iter: 2394 loss: 5.08966366e-07
Iter: 2395 loss: 5.08969947e-07
Iter: 2396 loss: 5.08940104e-07
Iter: 2397 loss: 5.088948e-07
Iter: 2398 loss: 5.08870755e-07
Iter: 2399 loss: 5.08824883e-07
Iter: 2400 loss: 5.09575898e-07
Iter: 2401 loss: 5.08798621e-07
Iter: 2402 loss: 5.08732114e-07
Iter: 2403 loss: 5.08991e-07
Iter: 2404 loss: 5.08707785e-07
Iter: 2405 loss: 5.08662197e-07
Iter: 2406 loss: 5.08677601e-07
Iter: 2407 loss: 5.08642302e-07
Iter: 2408 loss: 5.08623202e-07
Iter: 2409 loss: 5.08600237e-07
Iter: 2410 loss: 5.08571e-07
Iter: 2411 loss: 5.08788844e-07
Iter: 2412 loss: 5.08554137e-07
Iter: 2413 loss: 5.08513722e-07
Iter: 2414 loss: 5.08624e-07
Iter: 2415 loss: 5.08507298e-07
Iter: 2416 loss: 5.08459493e-07
Iter: 2417 loss: 5.08401456e-07
Iter: 2418 loss: 5.08369453e-07
Iter: 2419 loss: 5.0835871e-07
Iter: 2420 loss: 5.08389803e-07
Iter: 2421 loss: 5.0829675e-07
Iter: 2422 loss: 5.08226947e-07
Iter: 2423 loss: 5.08249343e-07
Iter: 2424 loss: 5.08212565e-07
Iter: 2425 loss: 5.08184485e-07
Iter: 2426 loss: 5.08165556e-07
Iter: 2427 loss: 5.08136281e-07
Iter: 2428 loss: 5.08112521e-07
Iter: 2429 loss: 5.08060907e-07
Iter: 2430 loss: 5.08016115e-07
Iter: 2431 loss: 5.08730864e-07
Iter: 2432 loss: 5.08039761e-07
Iter: 2433 loss: 5.07987124e-07
Iter: 2434 loss: 5.08004575e-07
Iter: 2435 loss: 5.0795046e-07
Iter: 2436 loss: 5.07918173e-07
Iter: 2437 loss: 5.07882874e-07
Iter: 2438 loss: 5.07913114e-07
Iter: 2439 loss: 5.07827963e-07
Iter: 2440 loss: 5.0781432e-07
Iter: 2441 loss: 5.07782715e-07
Iter: 2442 loss: 5.07799882e-07
Iter: 2443 loss: 5.07738832e-07
Iter: 2444 loss: 5.07730363e-07
Iter: 2445 loss: 5.07977745e-07
Iter: 2446 loss: 5.07715185e-07
Iter: 2447 loss: 5.0767818e-07
Iter: 2448 loss: 5.07704954e-07
Iter: 2449 loss: 5.07678692e-07
Iter: 2450 loss: 5.07612754e-07
Iter: 2451 loss: 5.07633615e-07
Iter: 2452 loss: 5.07585298e-07
Iter: 2453 loss: 5.07551533e-07
Iter: 2454 loss: 5.08089386e-07
Iter: 2455 loss: 5.07539085e-07
Iter: 2456 loss: 5.07513164e-07
Iter: 2457 loss: 5.07695745e-07
Iter: 2458 loss: 5.07489858e-07
Iter: 2459 loss: 5.07470872e-07
Iter: 2460 loss: 5.07366281e-07
Iter: 2461 loss: 5.08749054e-07
Iter: 2462 loss: 5.07359857e-07
Iter: 2463 loss: 5.07313928e-07
Iter: 2464 loss: 5.07954269e-07
Iter: 2465 loss: 5.07310403e-07
Iter: 2466 loss: 5.07262769e-07
Iter: 2467 loss: 5.07421078e-07
Iter: 2468 loss: 5.07246455e-07
Iter: 2469 loss: 5.07164714e-07
Iter: 2470 loss: 5.07182563e-07
Iter: 2471 loss: 5.07159712e-07
Iter: 2472 loss: 5.07052221e-07
Iter: 2473 loss: 5.07254242e-07
Iter: 2474 loss: 5.0703477e-07
Iter: 2475 loss: 5.07004643e-07
Iter: 2476 loss: 5.07821937e-07
Iter: 2477 loss: 5.0698128e-07
Iter: 2478 loss: 5.06956042e-07
Iter: 2479 loss: 5.06905849e-07
Iter: 2480 loss: 5.08499738e-07
Iter: 2481 loss: 5.06919491e-07
Iter: 2482 loss: 5.06823653e-07
Iter: 2483 loss: 5.06824449e-07
Iter: 2484 loss: 5.0676374e-07
Iter: 2485 loss: 5.0676141e-07
Iter: 2486 loss: 5.06737e-07
Iter: 2487 loss: 5.06693596e-07
Iter: 2488 loss: 5.0665966e-07
Iter: 2489 loss: 5.06614583e-07
Iter: 2490 loss: 5.06578033e-07
Iter: 2491 loss: 5.07251286e-07
Iter: 2492 loss: 5.06574963e-07
Iter: 2493 loss: 5.06494189e-07
Iter: 2494 loss: 5.06765559e-07
Iter: 2495 loss: 5.06503739e-07
Iter: 2496 loss: 5.06498168e-07
Iter: 2497 loss: 5.06431093e-07
Iter: 2498 loss: 5.07196205e-07
Iter: 2499 loss: 5.06444e-07
Iter: 2500 loss: 5.0635316e-07
Iter: 2501 loss: 5.06358674e-07
Iter: 2502 loss: 5.06347533e-07
Iter: 2503 loss: 5.0640142e-07
Iter: 2504 loss: 5.06331844e-07
Iter: 2505 loss: 5.06272158e-07
Iter: 2506 loss: 5.06311949e-07
Iter: 2507 loss: 5.06250615e-07
Iter: 2508 loss: 5.06233732e-07
Iter: 2509 loss: 5.06385504e-07
Iter: 2510 loss: 5.06191668e-07
Iter: 2511 loss: 5.06143e-07
Iter: 2512 loss: 5.06224296e-07
Iter: 2513 loss: 5.06106971e-07
Iter: 2514 loss: 5.06050128e-07
Iter: 2515 loss: 5.06221e-07
Iter: 2516 loss: 5.06028698e-07
Iter: 2517 loss: 5.0604433e-07
Iter: 2518 loss: 5.06024548e-07
Iter: 2519 loss: 5.06024946e-07
Iter: 2520 loss: 5.05992887e-07
Iter: 2521 loss: 5.06006188e-07
Iter: 2522 loss: 5.06014146e-07
Iter: 2523 loss: 5.06026367e-07
Iter: 2524 loss: 5.06022161e-07
Iter: 2525 loss: 5.06026652e-07
Iter: 2526 loss: 5.0603e-07
Iter: 2527 loss: 5.06026481e-07
Iter: 2528 loss: 5.06022957e-07
Iter: 2529 loss: 5.06034155e-07
Iter: 2530 loss: 5.06029664e-07
Iter: 2531 loss: 5.06022502e-07
Iter: 2532 loss: 5.06029323e-07
Iter: 2533 loss: 5.06021252e-07
Iter: 2534 loss: 5.06031029e-07
Iter: 2535 loss: 5.0602705e-07
Iter: 2536 loss: 5.06030062e-07
Iter: 2537 loss: 5.06028755e-07
Iter: 2538 loss: 5.0603e-07
Iter: 2539 loss: 5.06030403e-07
Iter: 2540 loss: 5.06028243e-07
Iter: 2541 loss: 5.0603046e-07
Iter: 2542 loss: 5.06028243e-07
Iter: 2543 loss: 5.05986634e-07
Iter: 2544 loss: 5.05931212e-07
Iter: 2545 loss: 5.05914556e-07
Iter: 2546 loss: 5.05849471e-07
Iter: 2547 loss: 5.0606161e-07
Iter: 2548 loss: 5.05811613e-07
Iter: 2549 loss: 5.0578177e-07
Iter: 2550 loss: 5.05797402e-07
Iter: 2551 loss: 5.0580519e-07
Iter: 2552 loss: 5.05783532e-07
Iter: 2553 loss: 5.05767218e-07
Iter: 2554 loss: 5.05772618e-07
Iter: 2555 loss: 5.05769833e-07
Iter: 2556 loss: 5.05785692e-07
Iter: 2557 loss: 5.05792855e-07
Iter: 2558 loss: 5.05798539e-07
Iter: 2559 loss: 5.05785692e-07
Iter: 2560 loss: 5.05772732e-07
Iter: 2561 loss: 5.05802404e-07
Iter: 2562 loss: 5.05782396e-07
Iter: 2563 loss: 5.05784e-07
Iter: 2564 loss: 5.05789671e-07
Iter: 2565 loss: 5.05803769e-07
Iter: 2566 loss: 5.05797857e-07
Iter: 2567 loss: 5.05796322e-07
Iter: 2568 loss: 5.0579888e-07
Iter: 2569 loss: 5.05797061e-07
Iter: 2570 loss: 5.05798539e-07
Iter: 2571 loss: 5.05798255e-07
Iter: 2572 loss: 5.05797573e-07
Iter: 2573 loss: 5.05798369e-07
Iter: 2574 loss: 5.05797573e-07
Iter: 2575 loss: 5.05798369e-07
Iter: 2576 loss: 5.05797573e-07
Iter: 2577 loss: 5.05698893e-07
Iter: 2578 loss: 5.06271363e-07
Iter: 2579 loss: 5.05677917e-07
Iter: 2580 loss: 5.05615958e-07
Iter: 2581 loss: 5.055565e-07
Iter: 2582 loss: 5.05496132e-07
Iter: 2583 loss: 5.054967e-07
Iter: 2584 loss: 5.05467938e-07
Iter: 2585 loss: 5.05456683e-07
Iter: 2586 loss: 5.05405296e-07
Iter: 2587 loss: 5.06277786e-07
Iter: 2588 loss: 5.05396e-07
Iter: 2589 loss: 5.05341404e-07
Iter: 2590 loss: 5.05519722e-07
Iter: 2591 loss: 5.05289449e-07
Iter: 2592 loss: 5.05253468e-07
Iter: 2593 loss: 5.0556207e-07
Iter: 2594 loss: 5.05223056e-07
Iter: 2595 loss: 5.05162575e-07
Iter: 2596 loss: 5.05405751e-07
Iter: 2597 loss: 5.05175251e-07
Iter: 2598 loss: 5.05174285e-07
Iter: 2599 loss: 5.05128298e-07
Iter: 2600 loss: 5.05085609e-07
Iter: 2601 loss: 5.050602e-07
Iter: 2602 loss: 5.050548e-07
Iter: 2603 loss: 5.05036098e-07
Iter: 2604 loss: 5.05000116e-07
Iter: 2605 loss: 5.04994659e-07
Iter: 2606 loss: 5.04980619e-07
Iter: 2607 loss: 5.0488859e-07
Iter: 2608 loss: 5.05761e-07
Iter: 2609 loss: 5.04901891e-07
Iter: 2610 loss: 5.04870286e-07
Iter: 2611 loss: 5.04853e-07
Iter: 2612 loss: 5.04816171e-07
Iter: 2613 loss: 5.04766547e-07
Iter: 2614 loss: 5.04754098e-07
Iter: 2615 loss: 5.04688728e-07
Iter: 2616 loss: 5.0464547e-07
Iter: 2617 loss: 5.0464655e-07
Iter: 2618 loss: 5.04593402e-07
Iter: 2619 loss: 5.05089304e-07
Iter: 2620 loss: 5.04577088e-07
Iter: 2621 loss: 5.04560035e-07
Iter: 2622 loss: 5.04957e-07
Iter: 2623 loss: 5.04561967e-07
Iter: 2624 loss: 5.04515526e-07
Iter: 2625 loss: 5.04482898e-07
Iter: 2626 loss: 5.05439857e-07
Iter: 2627 loss: 5.04445893e-07
Iter: 2628 loss: 5.04409627e-07
Iter: 2629 loss: 5.05028e-07
Iter: 2630 loss: 5.04418153e-07
Iter: 2631 loss: 5.0434204e-07
Iter: 2632 loss: 5.04652462e-07
Iter: 2633 loss: 5.04370576e-07
Iter: 2634 loss: 5.04328e-07
Iter: 2635 loss: 5.04265756e-07
Iter: 2636 loss: 5.04281388e-07
Iter: 2637 loss: 5.04207378e-07
Iter: 2638 loss: 5.04342665e-07
Iter: 2639 loss: 5.04182594e-07
Iter: 2640 loss: 5.04158e-07
Iter: 2641 loss: 5.04136324e-07
Iter: 2642 loss: 5.0412109e-07
Iter: 2643 loss: 5.04095453e-07
Iter: 2644 loss: 5.04050888e-07
Iter: 2645 loss: 5.04009506e-07
Iter: 2646 loss: 5.04703394e-07
Iter: 2647 loss: 5.04019908e-07
Iter: 2648 loss: 5.03990407e-07
Iter: 2649 loss: 5.04019454e-07
Iter: 2650 loss: 5.03985234e-07
Iter: 2651 loss: 5.03934473e-07
Iter: 2652 loss: 5.03912418e-07
Iter: 2653 loss: 5.03906676e-07
Iter: 2654 loss: 5.03835849e-07
Iter: 2655 loss: 5.03831131e-07
Iter: 2656 loss: 5.03805836e-07
Iter: 2657 loss: 5.03883257e-07
Iter: 2658 loss: 5.03755302e-07
Iter: 2659 loss: 5.03746605e-07
Iter: 2660 loss: 5.03724493e-07
Iter: 2661 loss: 5.03684532e-07
Iter: 2662 loss: 5.03684817e-07
Iter: 2663 loss: 5.03697095e-07
Iter: 2664 loss: 5.03672254e-07
Iter: 2665 loss: 5.0369573e-07
Iter: 2666 loss: 5.03665319e-07
Iter: 2667 loss: 5.03676574e-07
Iter: 2668 loss: 5.03698061e-07
Iter: 2669 loss: 5.03687602e-07
Iter: 2670 loss: 5.03668105e-07
Iter: 2671 loss: 5.0368e-07
Iter: 2672 loss: 5.03687261e-07
Iter: 2673 loss: 5.03675153e-07
Iter: 2674 loss: 5.03679871e-07
Iter: 2675 loss: 5.03680724e-07
Iter: 2676 loss: 5.03685783e-07
Iter: 2677 loss: 5.03679757e-07
Iter: 2678 loss: 5.0367936e-07
Iter: 2679 loss: 5.036826e-07
Iter: 2680 loss: 5.03689e-07
Iter: 2681 loss: 5.03690842e-07
Iter: 2682 loss: 5.0368476e-07
Iter: 2683 loss: 5.03686692e-07
Iter: 2684 loss: 5.03684305e-07
Iter: 2685 loss: 5.03684362e-07
Iter: 2686 loss: 5.03684589e-07
Iter: 2687 loss: 5.03684817e-07
Iter: 2688 loss: 5.03686692e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.2_8000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc44060620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc4406b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc4406b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc4408c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d614ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d614510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d5afae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d563ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d563d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d563730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d531510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d4eabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d4cef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d4b0268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d4ce950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d5322f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d43ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d414268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d3f9d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d3e2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d3bb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d3702f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d3646a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d37cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d30b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d291f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d2df598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d2910d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d2541e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d2710d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d285510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d2361e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d1db6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d1e99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d1a2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc3d109f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.18887737e-06
Iter: 2 loss: 2.12953955e-06
Iter: 3 loss: 1.99681244e-06
Iter: 4 loss: 1.59313981e-06
Iter: 5 loss: 2.98636724e-06
Iter: 6 loss: 1.48620791e-06
Iter: 7 loss: 1.30846627e-06
Iter: 8 loss: 2.78345988e-06
Iter: 9 loss: 1.29777311e-06
Iter: 10 loss: 1.16743513e-06
Iter: 11 loss: 1.20780805e-06
Iter: 12 loss: 1.07438734e-06
Iter: 13 loss: 1.00454145e-06
Iter: 14 loss: 1.00442242e-06
Iter: 15 loss: 9.4982812e-07
Iter: 16 loss: 9.34575894e-07
Iter: 17 loss: 9.01232227e-07
Iter: 18 loss: 8.78864398e-07
Iter: 19 loss: 1.00218335e-06
Iter: 20 loss: 8.75591923e-07
Iter: 21 loss: 8.60271712e-07
Iter: 22 loss: 8.64856474e-07
Iter: 23 loss: 8.49363914e-07
Iter: 24 loss: 8.32755518e-07
Iter: 25 loss: 8.84054487e-07
Iter: 26 loss: 8.27904614e-07
Iter: 27 loss: 8.27007057e-07
Iter: 28 loss: 8.21430831e-07
Iter: 29 loss: 8.1719412e-07
Iter: 30 loss: 8.07412391e-07
Iter: 31 loss: 9.25960194e-07
Iter: 32 loss: 8.06601861e-07
Iter: 33 loss: 7.96089466e-07
Iter: 34 loss: 8.45988438e-07
Iter: 35 loss: 7.94191124e-07
Iter: 36 loss: 7.86105716e-07
Iter: 37 loss: 8.22978222e-07
Iter: 38 loss: 7.84548e-07
Iter: 39 loss: 7.81423125e-07
Iter: 40 loss: 7.80595713e-07
Iter: 41 loss: 7.78482445e-07
Iter: 42 loss: 7.75633112e-07
Iter: 43 loss: 7.75467583e-07
Iter: 44 loss: 7.70098495e-07
Iter: 45 loss: 7.87829606e-07
Iter: 46 loss: 7.68614086e-07
Iter: 47 loss: 7.64988272e-07
Iter: 48 loss: 7.69235271e-07
Iter: 49 loss: 7.63076514e-07
Iter: 50 loss: 7.5734954e-07
Iter: 51 loss: 7.71476948e-07
Iter: 52 loss: 7.55387305e-07
Iter: 53 loss: 7.50731e-07
Iter: 54 loss: 7.44322733e-07
Iter: 55 loss: 7.44077397e-07
Iter: 56 loss: 7.34567493e-07
Iter: 57 loss: 7.5046421e-07
Iter: 58 loss: 7.30286501e-07
Iter: 59 loss: 7.20610444e-07
Iter: 60 loss: 7.39868767e-07
Iter: 61 loss: 7.166214e-07
Iter: 62 loss: 7.09834922e-07
Iter: 63 loss: 7.09799451e-07
Iter: 64 loss: 7.05937623e-07
Iter: 65 loss: 7.45652471e-07
Iter: 66 loss: 7.05822231e-07
Iter: 67 loss: 7.02832949e-07
Iter: 68 loss: 6.99815587e-07
Iter: 69 loss: 6.99212762e-07
Iter: 70 loss: 6.96430959e-07
Iter: 71 loss: 6.95836263e-07
Iter: 72 loss: 6.94064056e-07
Iter: 73 loss: 6.91802256e-07
Iter: 74 loss: 6.91611433e-07
Iter: 75 loss: 6.90071602e-07
Iter: 76 loss: 7.1052466e-07
Iter: 77 loss: 6.90058528e-07
Iter: 78 loss: 6.89162903e-07
Iter: 79 loss: 6.88548e-07
Iter: 80 loss: 6.88257387e-07
Iter: 81 loss: 6.86734381e-07
Iter: 82 loss: 6.9694255e-07
Iter: 83 loss: 6.86587441e-07
Iter: 84 loss: 6.85586087e-07
Iter: 85 loss: 6.84757765e-07
Iter: 86 loss: 6.84429438e-07
Iter: 87 loss: 6.82815312e-07
Iter: 88 loss: 7.02236321e-07
Iter: 89 loss: 6.82808263e-07
Iter: 90 loss: 6.82155132e-07
Iter: 91 loss: 6.80404696e-07
Iter: 92 loss: 6.91208925e-07
Iter: 93 loss: 6.79931759e-07
Iter: 94 loss: 6.78148183e-07
Iter: 95 loss: 6.99476e-07
Iter: 96 loss: 6.78123911e-07
Iter: 97 loss: 6.76624438e-07
Iter: 98 loss: 6.77122785e-07
Iter: 99 loss: 6.75606543e-07
Iter: 100 loss: 6.74312446e-07
Iter: 101 loss: 6.93513925e-07
Iter: 102 loss: 6.74307898e-07
Iter: 103 loss: 6.72830083e-07
Iter: 104 loss: 6.73229295e-07
Iter: 105 loss: 6.71779617e-07
Iter: 106 loss: 6.70254394e-07
Iter: 107 loss: 6.739848e-07
Iter: 108 loss: 6.69709266e-07
Iter: 109 loss: 6.68185123e-07
Iter: 110 loss: 6.66282745e-07
Iter: 111 loss: 6.66152e-07
Iter: 112 loss: 6.67683253e-07
Iter: 113 loss: 6.65329878e-07
Iter: 114 loss: 6.64631727e-07
Iter: 115 loss: 6.64068239e-07
Iter: 116 loss: 6.63920048e-07
Iter: 117 loss: 6.6345865e-07
Iter: 118 loss: 6.63459559e-07
Iter: 119 loss: 6.63049263e-07
Iter: 120 loss: 6.62276591e-07
Iter: 121 loss: 6.62282844e-07
Iter: 122 loss: 6.61687181e-07
Iter: 123 loss: 6.69887868e-07
Iter: 124 loss: 6.61660238e-07
Iter: 125 loss: 6.61338561e-07
Iter: 126 loss: 6.64321533e-07
Iter: 127 loss: 6.61322247e-07
Iter: 128 loss: 6.61167462e-07
Iter: 129 loss: 6.60685487e-07
Iter: 130 loss: 6.62797845e-07
Iter: 131 loss: 6.60504554e-07
Iter: 132 loss: 6.59784405e-07
Iter: 133 loss: 6.6234378e-07
Iter: 134 loss: 6.59600573e-07
Iter: 135 loss: 6.5884376e-07
Iter: 136 loss: 6.63034939e-07
Iter: 137 loss: 6.5872797e-07
Iter: 138 loss: 6.58048634e-07
Iter: 139 loss: 6.64450454e-07
Iter: 140 loss: 6.58029251e-07
Iter: 141 loss: 6.57408577e-07
Iter: 142 loss: 6.5640404e-07
Iter: 143 loss: 6.56422685e-07
Iter: 144 loss: 6.55296731e-07
Iter: 145 loss: 6.57224859e-07
Iter: 146 loss: 6.54795144e-07
Iter: 147 loss: 6.54846247e-07
Iter: 148 loss: 6.54295718e-07
Iter: 149 loss: 6.53974666e-07
Iter: 150 loss: 6.53173629e-07
Iter: 151 loss: 6.62113848e-07
Iter: 152 loss: 6.53130883e-07
Iter: 153 loss: 6.52656297e-07
Iter: 154 loss: 6.52594906e-07
Iter: 155 loss: 6.52241283e-07
Iter: 156 loss: 6.52398171e-07
Iter: 157 loss: 6.52004928e-07
Iter: 158 loss: 6.51665346e-07
Iter: 159 loss: 6.5175675e-07
Iter: 160 loss: 6.51420748e-07
Iter: 161 loss: 6.50882782e-07
Iter: 162 loss: 6.55104429e-07
Iter: 163 loss: 6.50848278e-07
Iter: 164 loss: 6.50511879e-07
Iter: 165 loss: 6.50014613e-07
Iter: 166 loss: 6.50009724e-07
Iter: 167 loss: 6.49475055e-07
Iter: 168 loss: 6.51190192e-07
Iter: 169 loss: 6.49303274e-07
Iter: 170 loss: 6.48803393e-07
Iter: 171 loss: 6.50904667e-07
Iter: 172 loss: 6.4870477e-07
Iter: 173 loss: 6.48559933e-07
Iter: 174 loss: 6.48536229e-07
Iter: 175 loss: 6.48328182e-07
Iter: 176 loss: 6.4795131e-07
Iter: 177 loss: 6.55803547e-07
Iter: 178 loss: 6.47948298e-07
Iter: 179 loss: 6.47651518e-07
Iter: 180 loss: 6.48642867e-07
Iter: 181 loss: 6.47568527e-07
Iter: 182 loss: 6.47270667e-07
Iter: 183 loss: 6.47287379e-07
Iter: 184 loss: 6.47118327e-07
Iter: 185 loss: 6.46841954e-07
Iter: 186 loss: 6.46837e-07
Iter: 187 loss: 6.4650078e-07
Iter: 188 loss: 6.49225058e-07
Iter: 189 loss: 6.4647179e-07
Iter: 190 loss: 6.46078604e-07
Iter: 191 loss: 6.45737032e-07
Iter: 192 loss: 6.4564972e-07
Iter: 193 loss: 6.45307068e-07
Iter: 194 loss: 6.50621132e-07
Iter: 195 loss: 6.45316845e-07
Iter: 196 loss: 6.45001705e-07
Iter: 197 loss: 6.4451558e-07
Iter: 198 loss: 6.44504553e-07
Iter: 199 loss: 6.44061288e-07
Iter: 200 loss: 6.46023864e-07
Iter: 201 loss: 6.43982389e-07
Iter: 202 loss: 6.43549129e-07
Iter: 203 loss: 6.44519787e-07
Iter: 204 loss: 6.43383942e-07
Iter: 205 loss: 6.43057092e-07
Iter: 206 loss: 6.44762792e-07
Iter: 207 loss: 6.4301156e-07
Iter: 208 loss: 6.42727457e-07
Iter: 209 loss: 6.45586056e-07
Iter: 210 loss: 6.42727059e-07
Iter: 211 loss: 6.42542716e-07
Iter: 212 loss: 6.42064947e-07
Iter: 213 loss: 6.50189861e-07
Iter: 214 loss: 6.42060854e-07
Iter: 215 loss: 6.4182916e-07
Iter: 216 loss: 6.41764814e-07
Iter: 217 loss: 6.41591669e-07
Iter: 218 loss: 6.43038561e-07
Iter: 219 loss: 6.41589793e-07
Iter: 220 loss: 6.41450583e-07
Iter: 221 loss: 6.41149e-07
Iter: 222 loss: 6.45194746e-07
Iter: 223 loss: 6.41102702e-07
Iter: 224 loss: 6.41014481e-07
Iter: 225 loss: 6.40898293e-07
Iter: 226 loss: 6.408319e-07
Iter: 227 loss: 6.405715e-07
Iter: 228 loss: 6.44379611e-07
Iter: 229 loss: 6.40550411e-07
Iter: 230 loss: 6.40402675e-07
Iter: 231 loss: 6.40388294e-07
Iter: 232 loss: 6.40253347e-07
Iter: 233 loss: 6.40021483e-07
Iter: 234 loss: 6.40026258e-07
Iter: 235 loss: 6.3977518e-07
Iter: 236 loss: 6.40137273e-07
Iter: 237 loss: 6.39697134e-07
Iter: 238 loss: 6.39468794e-07
Iter: 239 loss: 6.39481868e-07
Iter: 240 loss: 6.39315e-07
Iter: 241 loss: 6.38996312e-07
Iter: 242 loss: 6.41666475e-07
Iter: 243 loss: 6.38946062e-07
Iter: 244 loss: 6.38570555e-07
Iter: 245 loss: 6.38545544e-07
Iter: 246 loss: 6.38234724e-07
Iter: 247 loss: 6.37934e-07
Iter: 248 loss: 6.38991764e-07
Iter: 249 loss: 6.37846824e-07
Iter: 250 loss: 6.37458584e-07
Iter: 251 loss: 6.38359666e-07
Iter: 252 loss: 6.3730306e-07
Iter: 253 loss: 6.3693426e-07
Iter: 254 loss: 6.38076756e-07
Iter: 255 loss: 6.36799e-07
Iter: 256 loss: 6.36553523e-07
Iter: 257 loss: 6.37866947e-07
Iter: 258 loss: 6.36527488e-07
Iter: 259 loss: 6.36302843e-07
Iter: 260 loss: 6.37874e-07
Iter: 261 loss: 6.36309892e-07
Iter: 262 loss: 6.36211e-07
Iter: 263 loss: 6.36068876e-07
Iter: 264 loss: 6.36063e-07
Iter: 265 loss: 6.35875438e-07
Iter: 266 loss: 6.37558742e-07
Iter: 267 loss: 6.35885158e-07
Iter: 268 loss: 6.3576158e-07
Iter: 269 loss: 6.35650167e-07
Iter: 270 loss: 6.35617312e-07
Iter: 271 loss: 6.35414267e-07
Iter: 272 loss: 6.35184847e-07
Iter: 273 loss: 6.35161484e-07
Iter: 274 loss: 6.34734079e-07
Iter: 275 loss: 6.36023117e-07
Iter: 276 loss: 6.34600042e-07
Iter: 277 loss: 6.34260743e-07
Iter: 278 loss: 6.38784456e-07
Iter: 279 loss: 6.34252956e-07
Iter: 280 loss: 6.3396044e-07
Iter: 281 loss: 6.35160575e-07
Iter: 282 loss: 6.33882e-07
Iter: 283 loss: 6.33622562e-07
Iter: 284 loss: 6.33352386e-07
Iter: 285 loss: 6.33295599e-07
Iter: 286 loss: 6.33136096e-07
Iter: 287 loss: 6.33144225e-07
Iter: 288 loss: 6.32948968e-07
Iter: 289 loss: 6.32993078e-07
Iter: 290 loss: 6.32813e-07
Iter: 291 loss: 6.3264855e-07
Iter: 292 loss: 6.3263218e-07
Iter: 293 loss: 6.32500246e-07
Iter: 294 loss: 6.32314823e-07
Iter: 295 loss: 6.323138e-07
Iter: 296 loss: 6.32132696e-07
Iter: 297 loss: 6.32048568e-07
Iter: 298 loss: 6.32013894e-07
Iter: 299 loss: 6.31854391e-07
Iter: 300 loss: 6.33100854e-07
Iter: 301 loss: 6.3182955e-07
Iter: 302 loss: 6.31665557e-07
Iter: 303 loss: 6.31457738e-07
Iter: 304 loss: 6.31431078e-07
Iter: 305 loss: 6.31171076e-07
Iter: 306 loss: 6.31860303e-07
Iter: 307 loss: 6.31078e-07
Iter: 308 loss: 6.30842123e-07
Iter: 309 loss: 6.31253954e-07
Iter: 310 loss: 6.30745603e-07
Iter: 311 loss: 6.30530735e-07
Iter: 312 loss: 6.30803413e-07
Iter: 313 loss: 6.30392492e-07
Iter: 314 loss: 6.30306715e-07
Iter: 315 loss: 6.30268232e-07
Iter: 316 loss: 6.30152442e-07
Iter: 317 loss: 6.30073885e-07
Iter: 318 loss: 6.30066324e-07
Iter: 319 loss: 6.29884767e-07
Iter: 320 loss: 6.30112481e-07
Iter: 321 loss: 6.29808e-07
Iter: 322 loss: 6.29636247e-07
Iter: 323 loss: 6.29654551e-07
Iter: 324 loss: 6.2955462e-07
Iter: 325 loss: 6.29327246e-07
Iter: 326 loss: 6.32320848e-07
Iter: 327 loss: 6.29312694e-07
Iter: 328 loss: 6.2915791e-07
Iter: 329 loss: 6.29161491e-07
Iter: 330 loss: 6.28995792e-07
Iter: 331 loss: 6.28796e-07
Iter: 332 loss: 6.28765179e-07
Iter: 333 loss: 6.28577254e-07
Iter: 334 loss: 6.29123e-07
Iter: 335 loss: 6.28536e-07
Iter: 336 loss: 6.2835062e-07
Iter: 337 loss: 6.3017e-07
Iter: 338 loss: 6.28362613e-07
Iter: 339 loss: 6.28238126e-07
Iter: 340 loss: 6.28336e-07
Iter: 341 loss: 6.28119835e-07
Iter: 342 loss: 6.27981478e-07
Iter: 343 loss: 6.27639281e-07
Iter: 344 loss: 6.3443315e-07
Iter: 345 loss: 6.27651389e-07
Iter: 346 loss: 6.27292934e-07
Iter: 347 loss: 6.30322631e-07
Iter: 348 loss: 6.27291172e-07
Iter: 349 loss: 6.27035661e-07
Iter: 350 loss: 6.28659109e-07
Iter: 351 loss: 6.27010877e-07
Iter: 352 loss: 6.26815108e-07
Iter: 353 loss: 6.28103635e-07
Iter: 354 loss: 6.2679112e-07
Iter: 355 loss: 6.26660267e-07
Iter: 356 loss: 6.26504743e-07
Iter: 357 loss: 6.26491897e-07
Iter: 358 loss: 6.26451936e-07
Iter: 359 loss: 6.26386168e-07
Iter: 360 loss: 6.263e-07
Iter: 361 loss: 6.26083079e-07
Iter: 362 loss: 6.30035345e-07
Iter: 363 loss: 6.26108829e-07
Iter: 364 loss: 6.25958364e-07
Iter: 365 loss: 6.2682858e-07
Iter: 366 loss: 6.25919029e-07
Iter: 367 loss: 6.25822054e-07
Iter: 368 loss: 6.27313739e-07
Iter: 369 loss: 6.25817108e-07
Iter: 370 loss: 6.25769871e-07
Iter: 371 loss: 6.25589223e-07
Iter: 372 loss: 6.26864164e-07
Iter: 373 loss: 6.25549774e-07
Iter: 374 loss: 6.25306654e-07
Iter: 375 loss: 6.26925953e-07
Iter: 376 loss: 6.25275e-07
Iter: 377 loss: 6.25108555e-07
Iter: 378 loss: 6.26315e-07
Iter: 379 loss: 6.25072403e-07
Iter: 380 loss: 6.24902839e-07
Iter: 381 loss: 6.24904033e-07
Iter: 382 loss: 6.24761e-07
Iter: 383 loss: 6.24577183e-07
Iter: 384 loss: 6.24450706e-07
Iter: 385 loss: 6.24380164e-07
Iter: 386 loss: 6.24115273e-07
Iter: 387 loss: 6.26165104e-07
Iter: 388 loss: 6.24115955e-07
Iter: 389 loss: 6.23954065e-07
Iter: 390 loss: 6.25377595e-07
Iter: 391 loss: 6.2394281e-07
Iter: 392 loss: 6.2381423e-07
Iter: 393 loss: 6.24539325e-07
Iter: 394 loss: 6.23794676e-07
Iter: 395 loss: 6.23668029e-07
Iter: 396 loss: 6.23509266e-07
Iter: 397 loss: 6.23519782e-07
Iter: 398 loss: 6.2347965e-07
Iter: 399 loss: 6.23428093e-07
Iter: 400 loss: 6.23330038e-07
Iter: 401 loss: 6.23146207e-07
Iter: 402 loss: 6.26942096e-07
Iter: 403 loss: 6.23131427e-07
Iter: 404 loss: 6.22945663e-07
Iter: 405 loss: 6.2316019e-07
Iter: 406 loss: 6.22864036e-07
Iter: 407 loss: 6.22660593e-07
Iter: 408 loss: 6.25358325e-07
Iter: 409 loss: 6.2268947e-07
Iter: 410 loss: 6.22493303e-07
Iter: 411 loss: 6.22488642e-07
Iter: 412 loss: 6.22325786e-07
Iter: 413 loss: 6.22232278e-07
Iter: 414 loss: 6.22751315e-07
Iter: 415 loss: 6.22202492e-07
Iter: 416 loss: 6.22084372e-07
Iter: 417 loss: 6.22407e-07
Iter: 418 loss: 6.22004677e-07
Iter: 419 loss: 6.21912818e-07
Iter: 420 loss: 6.21904917e-07
Iter: 421 loss: 6.21847789e-07
Iter: 422 loss: 6.21721028e-07
Iter: 423 loss: 6.22157e-07
Iter: 424 loss: 6.21671859e-07
Iter: 425 loss: 6.21511163e-07
Iter: 426 loss: 6.21521679e-07
Iter: 427 loss: 6.21408162e-07
Iter: 428 loss: 6.2125082e-07
Iter: 429 loss: 6.22307311e-07
Iter: 430 loss: 6.2121569e-07
Iter: 431 loss: 6.21061872e-07
Iter: 432 loss: 6.21320567e-07
Iter: 433 loss: 6.2095296e-07
Iter: 434 loss: 6.20850528e-07
Iter: 435 loss: 6.20799483e-07
Iter: 436 loss: 6.20745141e-07
Iter: 437 loss: 6.20704782e-07
Iter: 438 loss: 6.20678406e-07
Iter: 439 loss: 6.20480819e-07
Iter: 440 loss: 6.21013896e-07
Iter: 441 loss: 6.20437959e-07
Iter: 442 loss: 6.20374237e-07
Iter: 443 loss: 6.20213484e-07
Iter: 444 loss: 6.20200694e-07
Iter: 445 loss: 6.20064952e-07
Iter: 446 loss: 6.20071432e-07
Iter: 447 loss: 6.19988896e-07
Iter: 448 loss: 6.19924094e-07
Iter: 449 loss: 6.1986168e-07
Iter: 450 loss: 6.19732361e-07
Iter: 451 loss: 6.1992705e-07
Iter: 452 loss: 6.19678417e-07
Iter: 453 loss: 6.19570471e-07
Iter: 454 loss: 6.19571097e-07
Iter: 455 loss: 6.19481966e-07
Iter: 456 loss: 6.1929029e-07
Iter: 457 loss: 6.22159746e-07
Iter: 458 loss: 6.19287e-07
Iter: 459 loss: 6.19136131e-07
Iter: 460 loss: 6.19639252e-07
Iter: 461 loss: 6.19113052e-07
Iter: 462 loss: 6.18965316e-07
Iter: 463 loss: 6.1940483e-07
Iter: 464 loss: 6.1891518e-07
Iter: 465 loss: 6.1882713e-07
Iter: 466 loss: 6.19904085e-07
Iter: 467 loss: 6.18798e-07
Iter: 468 loss: 6.18719582e-07
Iter: 469 loss: 6.18725664e-07
Iter: 470 loss: 6.18619481e-07
Iter: 471 loss: 6.1849596e-07
Iter: 472 loss: 6.188925e-07
Iter: 473 loss: 6.18473337e-07
Iter: 474 loss: 6.18330546e-07
Iter: 475 loss: 6.18693434e-07
Iter: 476 loss: 6.18244144e-07
Iter: 477 loss: 6.18100557e-07
Iter: 478 loss: 6.18078e-07
Iter: 479 loss: 6.17993635e-07
Iter: 480 loss: 6.17869432e-07
Iter: 481 loss: 6.17865624e-07
Iter: 482 loss: 6.17771377e-07
Iter: 483 loss: 6.17489263e-07
Iter: 484 loss: 6.21799472e-07
Iter: 485 loss: 6.17501826e-07
Iter: 486 loss: 6.17318221e-07
Iter: 487 loss: 6.17965952e-07
Iter: 488 loss: 6.17231876e-07
Iter: 489 loss: 6.1711529e-07
Iter: 490 loss: 6.18786487e-07
Iter: 491 loss: 6.17107958e-07
Iter: 492 loss: 6.16994782e-07
Iter: 493 loss: 6.17525075e-07
Iter: 494 loss: 6.16980174e-07
Iter: 495 loss: 6.16918442e-07
Iter: 496 loss: 6.16770308e-07
Iter: 497 loss: 6.16746888e-07
Iter: 498 loss: 6.16634679e-07
Iter: 499 loss: 6.17161504e-07
Iter: 500 loss: 6.16602165e-07
Iter: 501 loss: 6.16477791e-07
Iter: 502 loss: 6.17988405e-07
Iter: 503 loss: 6.16499847e-07
Iter: 504 loss: 6.16390253e-07
Iter: 505 loss: 6.16393e-07
Iter: 506 loss: 6.16331931e-07
Iter: 507 loss: 6.16254113e-07
Iter: 508 loss: 6.16759905e-07
Iter: 509 loss: 6.16233308e-07
Iter: 510 loss: 6.16118e-07
Iter: 511 loss: 6.16204829e-07
Iter: 512 loss: 6.16036743e-07
Iter: 513 loss: 6.15978763e-07
Iter: 514 loss: 6.15953695e-07
Iter: 515 loss: 6.15868657e-07
Iter: 516 loss: 6.15732915e-07
Iter: 517 loss: 6.17670594e-07
Iter: 518 loss: 6.15755425e-07
Iter: 519 loss: 6.15652652e-07
Iter: 520 loss: 6.155459e-07
Iter: 521 loss: 6.15538e-07
Iter: 522 loss: 6.15423119e-07
Iter: 523 loss: 6.15520548e-07
Iter: 524 loss: 6.15362183e-07
Iter: 525 loss: 6.15256283e-07
Iter: 526 loss: 6.16297029e-07
Iter: 527 loss: 6.15199383e-07
Iter: 528 loss: 6.15086151e-07
Iter: 529 loss: 6.15232238e-07
Iter: 530 loss: 6.14983378e-07
Iter: 531 loss: 6.14868e-07
Iter: 532 loss: 6.14897601e-07
Iter: 533 loss: 6.14808528e-07
Iter: 534 loss: 6.14588e-07
Iter: 535 loss: 6.14674605e-07
Iter: 536 loss: 6.14447572e-07
Iter: 537 loss: 6.14540113e-07
Iter: 538 loss: 6.14391126e-07
Iter: 539 loss: 6.14318139e-07
Iter: 540 loss: 6.14201099e-07
Iter: 541 loss: 6.16720172e-07
Iter: 542 loss: 6.14196097e-07
Iter: 543 loss: 6.14084115e-07
Iter: 544 loss: 6.15631848e-07
Iter: 545 loss: 6.14083e-07
Iter: 546 loss: 6.1401272e-07
Iter: 547 loss: 6.1392717e-07
Iter: 548 loss: 6.13905115e-07
Iter: 549 loss: 6.13784721e-07
Iter: 550 loss: 6.14174041e-07
Iter: 551 loss: 6.13804502e-07
Iter: 552 loss: 6.13742372e-07
Iter: 553 loss: 6.14904e-07
Iter: 554 loss: 6.13736688e-07
Iter: 555 loss: 6.13682403e-07
Iter: 556 loss: 6.13572752e-07
Iter: 557 loss: 6.1358071e-07
Iter: 558 loss: 6.13503914e-07
Iter: 559 loss: 6.13658131e-07
Iter: 560 loss: 6.13442126e-07
Iter: 561 loss: 6.13330599e-07
Iter: 562 loss: 6.13656141e-07
Iter: 563 loss: 6.13303655e-07
Iter: 564 loss: 6.13209181e-07
Iter: 565 loss: 6.14271926e-07
Iter: 566 loss: 6.1320435e-07
Iter: 567 loss: 6.13145176e-07
Iter: 568 loss: 6.12990277e-07
Iter: 569 loss: 6.15924193e-07
Iter: 570 loss: 6.12990675e-07
Iter: 571 loss: 6.1280582e-07
Iter: 572 loss: 6.1345645e-07
Iter: 573 loss: 6.12772055e-07
Iter: 574 loss: 6.12608233e-07
Iter: 575 loss: 6.12728172e-07
Iter: 576 loss: 6.12557471e-07
Iter: 577 loss: 6.12389726e-07
Iter: 578 loss: 6.123704e-07
Iter: 579 loss: 6.1228036e-07
Iter: 580 loss: 6.12068732e-07
Iter: 581 loss: 6.14739633e-07
Iter: 582 loss: 6.12064923e-07
Iter: 583 loss: 6.11877226e-07
Iter: 584 loss: 6.13976e-07
Iter: 585 loss: 6.11851e-07
Iter: 586 loss: 6.11690666e-07
Iter: 587 loss: 6.12381e-07
Iter: 588 loss: 6.11654514e-07
Iter: 589 loss: 6.11505072e-07
Iter: 590 loss: 6.11721646e-07
Iter: 591 loss: 6.11452208e-07
Iter: 592 loss: 6.11311407e-07
Iter: 593 loss: 6.1277035e-07
Iter: 594 loss: 6.11323117e-07
Iter: 595 loss: 6.11262749e-07
Iter: 596 loss: 6.11108931e-07
Iter: 597 loss: 6.14591215e-07
Iter: 598 loss: 6.11097732e-07
Iter: 599 loss: 6.11011671e-07
Iter: 600 loss: 6.11835731e-07
Iter: 601 loss: 6.10972165e-07
Iter: 602 loss: 6.10911854e-07
Iter: 603 loss: 6.10988877e-07
Iter: 604 loss: 6.10826305e-07
Iter: 605 loss: 6.10763948e-07
Iter: 606 loss: 6.10756672e-07
Iter: 607 loss: 6.10719781e-07
Iter: 608 loss: 6.10604502e-07
Iter: 609 loss: 6.12298777e-07
Iter: 610 loss: 6.10615302e-07
Iter: 611 loss: 6.10451934e-07
Iter: 612 loss: 6.10679535e-07
Iter: 613 loss: 6.10388838e-07
Iter: 614 loss: 6.10282e-07
Iter: 615 loss: 6.10264692e-07
Iter: 616 loss: 6.10151801e-07
Iter: 617 loss: 6.09976269e-07
Iter: 618 loss: 6.09982067e-07
Iter: 619 loss: 6.0981381e-07
Iter: 620 loss: 6.0950407e-07
Iter: 621 loss: 6.09515098e-07
Iter: 622 loss: 6.09325e-07
Iter: 623 loss: 6.09320409e-07
Iter: 624 loss: 6.09206495e-07
Iter: 625 loss: 6.10381278e-07
Iter: 626 loss: 6.09186316e-07
Iter: 627 loss: 6.09077631e-07
Iter: 628 loss: 6.09106337e-07
Iter: 629 loss: 6.0900544e-07
Iter: 630 loss: 6.08912387e-07
Iter: 631 loss: 6.08998675e-07
Iter: 632 loss: 6.08863786e-07
Iter: 633 loss: 6.08756693e-07
Iter: 634 loss: 6.1013975e-07
Iter: 635 loss: 6.08780397e-07
Iter: 636 loss: 6.08716164e-07
Iter: 637 loss: 6.08674213e-07
Iter: 638 loss: 6.08636469e-07
Iter: 639 loss: 6.08544156e-07
Iter: 640 loss: 6.08872142e-07
Iter: 641 loss: 6.08498681e-07
Iter: 642 loss: 6.08378286e-07
Iter: 643 loss: 6.08888342e-07
Iter: 644 loss: 6.08374762e-07
Iter: 645 loss: 6.08258915e-07
Iter: 646 loss: 6.08169898e-07
Iter: 647 loss: 6.08143182e-07
Iter: 648 loss: 6.0805e-07
Iter: 649 loss: 6.08044616e-07
Iter: 650 loss: 6.07999937e-07
Iter: 651 loss: 6.07864251e-07
Iter: 652 loss: 6.08782898e-07
Iter: 653 loss: 6.07844754e-07
Iter: 654 loss: 6.07649042e-07
Iter: 655 loss: 6.08139203e-07
Iter: 656 loss: 6.07584866e-07
Iter: 657 loss: 6.07436846e-07
Iter: 658 loss: 6.07718675e-07
Iter: 659 loss: 6.07329184e-07
Iter: 660 loss: 6.0717332e-07
Iter: 661 loss: 6.08085259e-07
Iter: 662 loss: 6.07167351e-07
Iter: 663 loss: 6.07021207e-07
Iter: 664 loss: 6.07024e-07
Iter: 665 loss: 6.06972549e-07
Iter: 666 loss: 6.06801052e-07
Iter: 667 loss: 6.0871497e-07
Iter: 668 loss: 6.06782748e-07
Iter: 669 loss: 6.06579306e-07
Iter: 670 loss: 6.07784386e-07
Iter: 671 loss: 6.06553215e-07
Iter: 672 loss: 6.064422e-07
Iter: 673 loss: 6.0644e-07
Iter: 674 loss: 6.06350341e-07
Iter: 675 loss: 6.06158608e-07
Iter: 676 loss: 6.09349399e-07
Iter: 677 loss: 6.06130129e-07
Iter: 678 loss: 6.06024685e-07
Iter: 679 loss: 6.06032188e-07
Iter: 680 loss: 6.05905143e-07
Iter: 681 loss: 6.06555034e-07
Iter: 682 loss: 6.05913556e-07
Iter: 683 loss: 6.05848868e-07
Iter: 684 loss: 6.06018e-07
Iter: 685 loss: 6.05814421e-07
Iter: 686 loss: 6.05759283e-07
Iter: 687 loss: 6.06340677e-07
Iter: 688 loss: 6.05764228e-07
Iter: 689 loss: 6.0572745e-07
Iter: 690 loss: 6.05634625e-07
Iter: 691 loss: 6.06465449e-07
Iter: 692 loss: 6.05634909e-07
Iter: 693 loss: 6.05501782e-07
Iter: 694 loss: 6.05567834e-07
Iter: 695 loss: 6.054604e-07
Iter: 696 loss: 6.0530806e-07
Iter: 697 loss: 6.06566118e-07
Iter: 698 loss: 6.0530823e-07
Iter: 699 loss: 6.05233424e-07
Iter: 700 loss: 6.05243827e-07
Iter: 701 loss: 6.05165212e-07
Iter: 702 loss: 6.05038394e-07
Iter: 703 loss: 6.05632408e-07
Iter: 704 loss: 6.05002072e-07
Iter: 705 loss: 6.04819604e-07
Iter: 706 loss: 6.05413e-07
Iter: 707 loss: 6.0473684e-07
Iter: 708 loss: 6.04662944e-07
Iter: 709 loss: 6.04648278e-07
Iter: 710 loss: 6.04541412e-07
Iter: 711 loss: 6.04624233e-07
Iter: 712 loss: 6.0447644e-07
Iter: 713 loss: 6.04368608e-07
Iter: 714 loss: 6.04316142e-07
Iter: 715 loss: 6.04275954e-07
Iter: 716 loss: 6.04104457e-07
Iter: 717 loss: 6.05715684e-07
Iter: 718 loss: 6.04091611e-07
Iter: 719 loss: 6.0395837e-07
Iter: 720 loss: 6.04256968e-07
Iter: 721 loss: 6.03875947e-07
Iter: 722 loss: 6.0377306e-07
Iter: 723 loss: 6.04248e-07
Iter: 724 loss: 6.0373651e-07
Iter: 725 loss: 6.03637829e-07
Iter: 726 loss: 6.03619753e-07
Iter: 727 loss: 6.03498904e-07
Iter: 728 loss: 6.03402441e-07
Iter: 729 loss: 6.03851277e-07
Iter: 730 loss: 6.0339579e-07
Iter: 731 loss: 6.03316437e-07
Iter: 732 loss: 6.03263516e-07
Iter: 733 loss: 6.0322742e-07
Iter: 734 loss: 6.03175408e-07
Iter: 735 loss: 6.03175408e-07
Iter: 736 loss: 6.03101228e-07
Iter: 737 loss: 6.03066837e-07
Iter: 738 loss: 6.03004651e-07
Iter: 739 loss: 6.02939281e-07
Iter: 740 loss: 6.03010903e-07
Iter: 741 loss: 6.02943601e-07
Iter: 742 loss: 6.02807745e-07
Iter: 743 loss: 6.03149488e-07
Iter: 744 loss: 6.02787054e-07
Iter: 745 loss: 6.02681553e-07
Iter: 746 loss: 6.03089745e-07
Iter: 747 loss: 6.02648697e-07
Iter: 748 loss: 6.02603905e-07
Iter: 749 loss: 6.02384944e-07
Iter: 750 loss: 6.05094556e-07
Iter: 751 loss: 6.02375451e-07
Iter: 752 loss: 6.02252214e-07
Iter: 753 loss: 6.02261821e-07
Iter: 754 loss: 6.0216513e-07
Iter: 755 loss: 6.03055071e-07
Iter: 756 loss: 6.02142904e-07
Iter: 757 loss: 6.02058265e-07
Iter: 758 loss: 6.01952252e-07
Iter: 759 loss: 6.01962199e-07
Iter: 760 loss: 6.01849081e-07
Iter: 761 loss: 6.03382603e-07
Iter: 762 loss: 6.01855106e-07
Iter: 763 loss: 6.01791783e-07
Iter: 764 loss: 6.01657803e-07
Iter: 765 loss: 6.01656723e-07
Iter: 766 loss: 6.01555485e-07
Iter: 767 loss: 6.01593399e-07
Iter: 768 loss: 6.0146408e-07
Iter: 769 loss: 6.01433328e-07
Iter: 770 loss: 6.01425199e-07
Iter: 771 loss: 6.01343459e-07
Iter: 772 loss: 6.01279112e-07
Iter: 773 loss: 6.01281499e-07
Iter: 774 loss: 6.0117344e-07
Iter: 775 loss: 6.01219881e-07
Iter: 776 loss: 6.01108184e-07
Iter: 777 loss: 6.01002057e-07
Iter: 778 loss: 6.00967439e-07
Iter: 779 loss: 6.00903718e-07
Iter: 780 loss: 6.00873818e-07
Iter: 781 loss: 6.00823455e-07
Iter: 782 loss: 6.00745409e-07
Iter: 783 loss: 6.00762178e-07
Iter: 784 loss: 6.00671797e-07
Iter: 785 loss: 6.00598923e-07
Iter: 786 loss: 6.0058278e-07
Iter: 787 loss: 6.00513317e-07
Iter: 788 loss: 6.00797762e-07
Iter: 789 loss: 6.00499277e-07
Iter: 790 loss: 6.00435669e-07
Iter: 791 loss: 6.00360352e-07
Iter: 792 loss: 6.02488058e-07
Iter: 793 loss: 6.00347107e-07
Iter: 794 loss: 6.00284068e-07
Iter: 795 loss: 6.00234e-07
Iter: 796 loss: 6.0020966e-07
Iter: 797 loss: 6.00070734e-07
Iter: 798 loss: 6.01373586e-07
Iter: 799 loss: 6.00073236e-07
Iter: 800 loss: 5.99900034e-07
Iter: 801 loss: 6.00825786e-07
Iter: 802 loss: 5.99876898e-07
Iter: 803 loss: 5.99784471e-07
Iter: 804 loss: 5.99933969e-07
Iter: 805 loss: 5.99718192e-07
Iter: 806 loss: 5.99692498e-07
Iter: 807 loss: 5.99681357e-07
Iter: 808 loss: 5.99581426e-07
Iter: 809 loss: 5.9954823e-07
Iter: 810 loss: 5.99555847e-07
Iter: 811 loss: 5.99488089e-07
Iter: 812 loss: 5.9981619e-07
Iter: 813 loss: 5.99458133e-07
Iter: 814 loss: 5.99382474e-07
Iter: 815 loss: 5.99621558e-07
Iter: 816 loss: 5.99337682e-07
Iter: 817 loss: 5.99280042e-07
Iter: 818 loss: 5.99222858e-07
Iter: 819 loss: 5.99194436e-07
Iter: 820 loss: 5.9908723e-07
Iter: 821 loss: 5.98963368e-07
Iter: 822 loss: 5.98961719e-07
Iter: 823 loss: 5.991335e-07
Iter: 824 loss: 5.98892143e-07
Iter: 825 loss: 5.98852864e-07
Iter: 826 loss: 5.98756969e-07
Iter: 827 loss: 6.0048535e-07
Iter: 828 loss: 5.987755e-07
Iter: 829 loss: 5.98647034e-07
Iter: 830 loss: 5.98799943e-07
Iter: 831 loss: 5.98586837e-07
Iter: 832 loss: 5.98515953e-07
Iter: 833 loss: 5.99850864e-07
Iter: 834 loss: 5.98500037e-07
Iter: 835 loss: 5.98439783e-07
Iter: 836 loss: 5.98439328e-07
Iter: 837 loss: 5.98412043e-07
Iter: 838 loss: 5.98307111e-07
Iter: 839 loss: 5.98293241e-07
Iter: 840 loss: 5.98263227e-07
Iter: 841 loss: 5.98207578e-07
Iter: 842 loss: 5.98219117e-07
Iter: 843 loss: 5.98145675e-07
Iter: 844 loss: 5.98072234e-07
Iter: 845 loss: 5.98064503e-07
Iter: 846 loss: 5.97980431e-07
Iter: 847 loss: 5.98114582e-07
Iter: 848 loss: 5.97927681e-07
Iter: 849 loss: 5.97845428e-07
Iter: 850 loss: 5.97798817e-07
Iter: 851 loss: 5.97741e-07
Iter: 852 loss: 5.97634141e-07
Iter: 853 loss: 5.98972861e-07
Iter: 854 loss: 5.9762192e-07
Iter: 855 loss: 5.97535347e-07
Iter: 856 loss: 5.98302393e-07
Iter: 857 loss: 5.97549104e-07
Iter: 858 loss: 5.97472877e-07
Iter: 859 loss: 5.97431608e-07
Iter: 860 loss: 5.97412168e-07
Iter: 861 loss: 5.9734549e-07
Iter: 862 loss: 5.97891358e-07
Iter: 863 loss: 5.97361236e-07
Iter: 864 loss: 5.97307917e-07
Iter: 865 loss: 5.97863902e-07
Iter: 866 loss: 5.97312862e-07
Iter: 867 loss: 5.9727148e-07
Iter: 868 loss: 5.97209e-07
Iter: 869 loss: 5.97341682e-07
Iter: 870 loss: 5.97148869e-07
Iter: 871 loss: 5.97059739e-07
Iter: 872 loss: 5.97935582e-07
Iter: 873 loss: 5.97072585e-07
Iter: 874 loss: 5.96965492e-07
Iter: 875 loss: 5.97110613e-07
Iter: 876 loss: 5.96963901e-07
Iter: 877 loss: 5.96879431e-07
Iter: 878 loss: 5.96844245e-07
Iter: 879 loss: 5.9679985e-07
Iter: 880 loss: 5.96730047e-07
Iter: 881 loss: 5.96727091e-07
Iter: 882 loss: 5.96640461e-07
Iter: 883 loss: 5.9733e-07
Iter: 884 loss: 5.96651148e-07
Iter: 885 loss: 5.96604764e-07
Iter: 886 loss: 5.96643e-07
Iter: 887 loss: 5.96596351e-07
Iter: 888 loss: 5.96504435e-07
Iter: 889 loss: 5.96522227e-07
Iter: 890 loss: 5.96429516e-07
Iter: 891 loss: 5.96346865e-07
Iter: 892 loss: 5.97150347e-07
Iter: 893 loss: 5.96366476e-07
Iter: 894 loss: 5.96286554e-07
Iter: 895 loss: 5.96237953e-07
Iter: 896 loss: 5.96248583e-07
Iter: 897 loss: 5.96155132e-07
Iter: 898 loss: 5.96111079e-07
Iter: 899 loss: 5.96072e-07
Iter: 900 loss: 5.96035591e-07
Iter: 901 loss: 5.96037e-07
Iter: 902 loss: 5.9596357e-07
Iter: 903 loss: 5.95998131e-07
Iter: 904 loss: 5.95897291e-07
Iter: 905 loss: 5.95852725e-07
Iter: 906 loss: 5.95692768e-07
Iter: 907 loss: 5.97993335e-07
Iter: 908 loss: 5.9569345e-07
Iter: 909 loss: 5.95559584e-07
Iter: 910 loss: 5.96133e-07
Iter: 911 loss: 5.95547476e-07
Iter: 912 loss: 5.95493e-07
Iter: 913 loss: 5.95484494e-07
Iter: 914 loss: 5.95420943e-07
Iter: 915 loss: 5.95459596e-07
Iter: 916 loss: 5.95375923e-07
Iter: 917 loss: 5.95332494e-07
Iter: 918 loss: 5.95319477e-07
Iter: 919 loss: 5.95249674e-07
Iter: 920 loss: 5.95223582e-07
Iter: 921 loss: 5.95222048e-07
Iter: 922 loss: 5.95169638e-07
Iter: 923 loss: 5.95076472e-07
Iter: 924 loss: 5.9509e-07
Iter: 925 loss: 5.95026e-07
Iter: 926 loss: 5.95982499e-07
Iter: 927 loss: 5.95035658e-07
Iter: 928 loss: 5.94959374e-07
Iter: 929 loss: 5.95023494e-07
Iter: 930 loss: 5.94938285e-07
Iter: 931 loss: 5.94880817e-07
Iter: 932 loss: 5.94891446e-07
Iter: 933 loss: 5.94834e-07
Iter: 934 loss: 5.94777589e-07
Iter: 935 loss: 5.95247116e-07
Iter: 936 loss: 5.94773326e-07
Iter: 937 loss: 5.94699429e-07
Iter: 938 loss: 5.94683854e-07
Iter: 939 loss: 5.94602284e-07
Iter: 940 loss: 5.94570622e-07
Iter: 941 loss: 5.94557719e-07
Iter: 942 loss: 5.94532e-07
Iter: 943 loss: 5.94410949e-07
Iter: 944 loss: 5.94323922e-07
Iter: 945 loss: 5.9431477e-07
Iter: 946 loss: 5.94233484e-07
Iter: 947 loss: 5.94207108e-07
Iter: 948 loss: 5.9412281e-07
Iter: 949 loss: 5.94495646e-07
Iter: 950 loss: 5.94101095e-07
Iter: 951 loss: 5.93984566e-07
Iter: 952 loss: 5.93964614e-07
Iter: 953 loss: 5.93952223e-07
Iter: 954 loss: 5.93878781e-07
Iter: 955 loss: 5.94756e-07
Iter: 956 loss: 5.93871562e-07
Iter: 957 loss: 5.93825575e-07
Iter: 958 loss: 5.93809e-07
Iter: 959 loss: 5.9377237e-07
Iter: 960 loss: 5.93717459e-07
Iter: 961 loss: 5.93882817e-07
Iter: 962 loss: 5.93690743e-07
Iter: 963 loss: 5.93638902e-07
Iter: 964 loss: 5.94114113e-07
Iter: 965 loss: 5.93650213e-07
Iter: 966 loss: 5.93592574e-07
Iter: 967 loss: 5.93587458e-07
Iter: 968 loss: 5.93589164e-07
Iter: 969 loss: 5.93499522e-07
Iter: 970 loss: 5.94322103e-07
Iter: 971 loss: 5.93518962e-07
Iter: 972 loss: 5.93458253e-07
Iter: 973 loss: 5.93592119e-07
Iter: 974 loss: 5.93471668e-07
Iter: 975 loss: 5.93427217e-07
Iter: 976 loss: 5.93375376e-07
Iter: 977 loss: 5.94110134e-07
Iter: 978 loss: 5.9337026e-07
Iter: 979 loss: 5.93242703e-07
Iter: 980 loss: 5.93493439e-07
Iter: 981 loss: 5.93222808e-07
Iter: 982 loss: 5.93123275e-07
Iter: 983 loss: 5.93686877e-07
Iter: 984 loss: 5.93127254e-07
Iter: 985 loss: 5.93012885e-07
Iter: 986 loss: 5.93035111e-07
Iter: 987 loss: 5.92987931e-07
Iter: 988 loss: 5.92905053e-07
Iter: 989 loss: 5.94044536e-07
Iter: 990 loss: 5.92910681e-07
Iter: 991 loss: 5.92844685e-07
Iter: 992 loss: 5.92850427e-07
Iter: 993 loss: 5.9277869e-07
Iter: 994 loss: 5.92733386e-07
Iter: 995 loss: 5.92723381e-07
Iter: 996 loss: 5.92653691e-07
Iter: 997 loss: 5.93204447e-07
Iter: 998 loss: 5.92632887e-07
Iter: 999 loss: 5.92592073e-07
Iter: 1000 loss: 5.92805577e-07
Iter: 1001 loss: 5.92586105e-07
Iter: 1002 loss: 5.92516e-07
Iter: 1003 loss: 5.92516699e-07
Iter: 1004 loss: 5.92474805e-07
Iter: 1005 loss: 5.92466e-07
Iter: 1006 loss: 5.92448487e-07
Iter: 1007 loss: 5.92403e-07
Iter: 1008 loss: 5.92388858e-07
Iter: 1009 loss: 5.93317395e-07
Iter: 1010 loss: 5.92384936e-07
Iter: 1011 loss: 5.92335425e-07
Iter: 1012 loss: 5.92291599e-07
Iter: 1013 loss: 5.9228438e-07
Iter: 1014 loss: 5.92202696e-07
Iter: 1015 loss: 5.9237459e-07
Iter: 1016 loss: 5.92178708e-07
Iter: 1017 loss: 5.92114475e-07
Iter: 1018 loss: 5.92127094e-07
Iter: 1019 loss: 5.92069512e-07
Iter: 1020 loss: 5.92134484e-07
Iter: 1021 loss: 5.92068773e-07
Iter: 1022 loss: 5.91992546e-07
Iter: 1023 loss: 5.91926892e-07
Iter: 1024 loss: 5.91934906e-07
Iter: 1025 loss: 5.91892785e-07
Iter: 1026 loss: 5.91913192e-07
Iter: 1027 loss: 5.91864818e-07
Iter: 1028 loss: 5.91784612e-07
Iter: 1029 loss: 5.93084906e-07
Iter: 1030 loss: 5.91804621e-07
Iter: 1031 loss: 5.91697358e-07
Iter: 1032 loss: 5.91870844e-07
Iter: 1033 loss: 5.9164563e-07
Iter: 1034 loss: 5.91612434e-07
Iter: 1035 loss: 5.91624541e-07
Iter: 1036 loss: 5.91549e-07
Iter: 1037 loss: 5.91466403e-07
Iter: 1038 loss: 5.91469529e-07
Iter: 1039 loss: 5.9140325e-07
Iter: 1040 loss: 5.92074e-07
Iter: 1041 loss: 5.91415755e-07
Iter: 1042 loss: 5.91284447e-07
Iter: 1043 loss: 5.91692242e-07
Iter: 1044 loss: 5.91256594e-07
Iter: 1045 loss: 5.91221806e-07
Iter: 1046 loss: 5.91157686e-07
Iter: 1047 loss: 5.92414267e-07
Iter: 1048 loss: 5.91156e-07
Iter: 1049 loss: 5.91007506e-07
Iter: 1050 loss: 5.91468847e-07
Iter: 1051 loss: 5.90979653e-07
Iter: 1052 loss: 5.90930711e-07
Iter: 1053 loss: 5.90951231e-07
Iter: 1054 loss: 5.90873583e-07
Iter: 1055 loss: 5.91060314e-07
Iter: 1056 loss: 5.90867103e-07
Iter: 1057 loss: 5.90830268e-07
Iter: 1058 loss: 5.90760692e-07
Iter: 1059 loss: 5.90768877e-07
Iter: 1060 loss: 5.90703507e-07
Iter: 1061 loss: 5.90703735e-07
Iter: 1062 loss: 5.90660534e-07
Iter: 1063 loss: 5.90629384e-07
Iter: 1064 loss: 5.90638933e-07
Iter: 1065 loss: 5.9059721e-07
Iter: 1066 loss: 5.90653713e-07
Iter: 1067 loss: 5.90579873e-07
Iter: 1068 loss: 5.90520585e-07
Iter: 1069 loss: 5.90527e-07
Iter: 1070 loss: 5.90510126e-07
Iter: 1071 loss: 5.90470108e-07
Iter: 1072 loss: 5.9045874e-07
Iter: 1073 loss: 5.90419631e-07
Iter: 1074 loss: 5.90332093e-07
Iter: 1075 loss: 5.91387277e-07
Iter: 1076 loss: 5.90334821e-07
Iter: 1077 loss: 5.90240745e-07
Iter: 1078 loss: 5.90501e-07
Iter: 1079 loss: 5.901843e-07
Iter: 1080 loss: 5.90173045e-07
Iter: 1081 loss: 5.90147351e-07
Iter: 1082 loss: 5.90107e-07
Iter: 1083 loss: 5.9000979e-07
Iter: 1084 loss: 5.91363914e-07
Iter: 1085 loss: 5.90032073e-07
Iter: 1086 loss: 5.89911281e-07
Iter: 1087 loss: 5.8997017e-07
Iter: 1088 loss: 5.89874162e-07
Iter: 1089 loss: 5.8979856e-07
Iter: 1090 loss: 5.89783554e-07
Iter: 1091 loss: 5.89757633e-07
Iter: 1092 loss: 5.89829256e-07
Iter: 1093 loss: 5.89713295e-07
Iter: 1094 loss: 5.89652643e-07
Iter: 1095 loss: 5.89664126e-07
Iter: 1096 loss: 5.89645083e-07
Iter: 1097 loss: 5.89561864e-07
Iter: 1098 loss: 5.89569879e-07
Iter: 1099 loss: 5.89567151e-07
Iter: 1100 loss: 5.89502179e-07
Iter: 1101 loss: 5.90138256e-07
Iter: 1102 loss: 5.89492345e-07
Iter: 1103 loss: 5.89408899e-07
Iter: 1104 loss: 5.89924298e-07
Iter: 1105 loss: 5.8939878e-07
Iter: 1106 loss: 5.89384172e-07
Iter: 1107 loss: 5.89582726e-07
Iter: 1108 loss: 5.89359161e-07
Iter: 1109 loss: 5.89333411e-07
Iter: 1110 loss: 5.89382e-07
Iter: 1111 loss: 5.892947e-07
Iter: 1112 loss: 5.89240756e-07
Iter: 1113 loss: 5.89192894e-07
Iter: 1114 loss: 5.89174533e-07
Iter: 1115 loss: 5.89156343e-07
Iter: 1116 loss: 5.89121271e-07
Iter: 1117 loss: 5.89104161e-07
Iter: 1118 loss: 5.89044305e-07
Iter: 1119 loss: 5.89764227e-07
Iter: 1120 loss: 5.89055048e-07
Iter: 1121 loss: 5.88974217e-07
Iter: 1122 loss: 5.89239903e-07
Iter: 1123 loss: 5.88944374e-07
Iter: 1124 loss: 5.88900662e-07
Iter: 1125 loss: 5.88884518e-07
Iter: 1126 loss: 5.88865078e-07
Iter: 1127 loss: 5.88806301e-07
Iter: 1128 loss: 5.88819603e-07
Iter: 1129 loss: 5.8872979e-07
Iter: 1130 loss: 5.88649584e-07
Iter: 1131 loss: 5.88859734e-07
Iter: 1132 loss: 5.88623209e-07
Iter: 1133 loss: 5.88563523e-07
Iter: 1134 loss: 5.88557441e-07
Iter: 1135 loss: 5.88500939e-07
Iter: 1136 loss: 5.88420562e-07
Iter: 1137 loss: 5.88429e-07
Iter: 1138 loss: 5.88356556e-07
Iter: 1139 loss: 5.88475473e-07
Iter: 1140 loss: 5.88299542e-07
Iter: 1141 loss: 5.88218e-07
Iter: 1142 loss: 5.88708645e-07
Iter: 1143 loss: 5.88226158e-07
Iter: 1144 loss: 5.88152147e-07
Iter: 1145 loss: 5.88727119e-07
Iter: 1146 loss: 5.88165562e-07
Iter: 1147 loss: 5.88096327e-07
Iter: 1148 loss: 5.88139528e-07
Iter: 1149 loss: 5.88060857e-07
Iter: 1150 loss: 5.88001114e-07
Iter: 1151 loss: 5.88061653e-07
Iter: 1152 loss: 5.88005037e-07
Iter: 1153 loss: 5.87941258e-07
Iter: 1154 loss: 5.88369858e-07
Iter: 1155 loss: 5.87936711e-07
Iter: 1156 loss: 5.87869238e-07
Iter: 1157 loss: 5.87941429e-07
Iter: 1158 loss: 5.87863667e-07
Iter: 1159 loss: 5.87821432e-07
Iter: 1160 loss: 5.87947511e-07
Iter: 1161 loss: 5.87803356e-07
Iter: 1162 loss: 5.87777549e-07
Iter: 1163 loss: 5.87732245e-07
Iter: 1164 loss: 5.87733439e-07
Iter: 1165 loss: 5.87665909e-07
Iter: 1166 loss: 5.87814043e-07
Iter: 1167 loss: 5.87659599e-07
Iter: 1168 loss: 5.87621855e-07
Iter: 1169 loss: 5.8780995e-07
Iter: 1170 loss: 5.87576835e-07
Iter: 1171 loss: 5.87545742e-07
Iter: 1172 loss: 5.87524823e-07
Iter: 1173 loss: 5.87503905e-07
Iter: 1174 loss: 5.87466559e-07
Iter: 1175 loss: 5.87393686e-07
Iter: 1176 loss: 5.87392776e-07
Iter: 1177 loss: 5.87284717e-07
Iter: 1178 loss: 5.87505383e-07
Iter: 1179 loss: 5.87247825e-07
Iter: 1180 loss: 5.87122486e-07
Iter: 1181 loss: 5.87666761e-07
Iter: 1182 loss: 5.87120041e-07
Iter: 1183 loss: 5.87028751e-07
Iter: 1184 loss: 5.87144541e-07
Iter: 1185 loss: 5.86974124e-07
Iter: 1186 loss: 5.86847e-07
Iter: 1187 loss: 5.88037e-07
Iter: 1188 loss: 5.86870783e-07
Iter: 1189 loss: 5.86844067e-07
Iter: 1190 loss: 5.86783e-07
Iter: 1191 loss: 5.86774831e-07
Iter: 1192 loss: 5.8671759e-07
Iter: 1193 loss: 5.86720944e-07
Iter: 1194 loss: 5.86683655e-07
Iter: 1195 loss: 5.86665408e-07
Iter: 1196 loss: 5.86633e-07
Iter: 1197 loss: 5.86641136e-07
Iter: 1198 loss: 5.86634656e-07
Iter: 1199 loss: 5.86648298e-07
Iter: 1200 loss: 5.86626697e-07
Iter: 1201 loss: 5.86649321e-07
Iter: 1202 loss: 5.8663835e-07
Iter: 1203 loss: 5.86631245e-07
Iter: 1204 loss: 5.86647843e-07
Iter: 1205 loss: 5.86637952e-07
Iter: 1206 loss: 5.8663727e-07
Iter: 1207 loss: 5.86640226e-07
Iter: 1208 loss: 5.86635679e-07
Iter: 1209 loss: 5.86641249e-07
Iter: 1210 loss: 5.866317e-07
Iter: 1211 loss: 5.86642273e-07
Iter: 1212 loss: 5.86644319e-07
Iter: 1213 loss: 5.86635338e-07
Iter: 1214 loss: 5.86632382e-07
Iter: 1215 loss: 5.86635e-07
Iter: 1216 loss: 5.86634201e-07
Iter: 1217 loss: 5.86633746e-07
Iter: 1218 loss: 5.86633348e-07
Iter: 1219 loss: 5.86634087e-07
Iter: 1220 loss: 5.86634e-07
Iter: 1221 loss: 5.86633348e-07
Iter: 1222 loss: 5.86634e-07
Iter: 1223 loss: 5.86633348e-07
Iter: 1224 loss: 5.86634e-07
Iter: 1225 loss: 5.86594524e-07
Iter: 1226 loss: 5.86918418e-07
Iter: 1227 loss: 5.86575879e-07
Iter: 1228 loss: 5.86519377e-07
Iter: 1229 loss: 5.86451733e-07
Iter: 1230 loss: 5.86461113e-07
Iter: 1231 loss: 5.86408134e-07
Iter: 1232 loss: 5.86371698e-07
Iter: 1233 loss: 5.86331396e-07
Iter: 1234 loss: 5.86298711e-07
Iter: 1235 loss: 5.86671831e-07
Iter: 1236 loss: 5.86271085e-07
Iter: 1237 loss: 5.86182068e-07
Iter: 1238 loss: 5.86364251e-07
Iter: 1239 loss: 5.86193835e-07
Iter: 1240 loss: 5.86117949e-07
Iter: 1241 loss: 5.86076169e-07
Iter: 1242 loss: 5.86055535e-07
Iter: 1243 loss: 5.8597135e-07
Iter: 1244 loss: 5.85947589e-07
Iter: 1245 loss: 5.85891939e-07
Iter: 1246 loss: 5.85797238e-07
Iter: 1247 loss: 5.85804173e-07
Iter: 1248 loss: 5.85778594e-07
Iter: 1249 loss: 5.85822931e-07
Iter: 1250 loss: 5.85721295e-07
Iter: 1251 loss: 5.85677071e-07
Iter: 1252 loss: 5.8624039e-07
Iter: 1253 loss: 5.85682528e-07
Iter: 1254 loss: 5.85643761e-07
Iter: 1255 loss: 5.85591295e-07
Iter: 1256 loss: 5.85604084e-07
Iter: 1257 loss: 5.85507451e-07
Iter: 1258 loss: 5.85545138e-07
Iter: 1259 loss: 5.85480507e-07
Iter: 1260 loss: 5.85442422e-07
Iter: 1261 loss: 5.85423e-07
Iter: 1262 loss: 5.85412e-07
Iter: 1263 loss: 5.85339649e-07
Iter: 1264 loss: 5.86132614e-07
Iter: 1265 loss: 5.85352382e-07
Iter: 1266 loss: 5.85256259e-07
Iter: 1267 loss: 5.85533257e-07
Iter: 1268 loss: 5.85261262e-07
Iter: 1269 loss: 5.85200951e-07
Iter: 1270 loss: 5.85479143e-07
Iter: 1271 loss: 5.85178555e-07
Iter: 1272 loss: 5.85114435e-07
Iter: 1273 loss: 5.85335499e-07
Iter: 1274 loss: 5.85117277e-07
Iter: 1275 loss: 5.85053954e-07
Iter: 1276 loss: 5.85035309e-07
Iter: 1277 loss: 5.85024509e-07
Iter: 1278 loss: 5.8494561e-07
Iter: 1279 loss: 5.85347607e-07
Iter: 1280 loss: 5.84954e-07
Iter: 1281 loss: 5.84873419e-07
Iter: 1282 loss: 5.85119551e-07
Iter: 1283 loss: 5.84891382e-07
Iter: 1284 loss: 5.84818508e-07
Iter: 1285 loss: 5.84718123e-07
Iter: 1286 loss: 5.84679697e-07
Iter: 1287 loss: 5.84669408e-07
Iter: 1288 loss: 5.8463479e-07
Iter: 1289 loss: 5.84607903e-07
Iter: 1290 loss: 5.84512804e-07
Iter: 1291 loss: 5.85765861e-07
Iter: 1292 loss: 5.84519682e-07
Iter: 1293 loss: 5.84458917e-07
Iter: 1294 loss: 5.84813733e-07
Iter: 1295 loss: 5.84450049e-07
Iter: 1296 loss: 5.84389113e-07
Iter: 1297 loss: 5.85140924e-07
Iter: 1298 loss: 5.84390932e-07
Iter: 1299 loss: 5.84331929e-07
Iter: 1300 loss: 5.84283555e-07
Iter: 1301 loss: 5.84290888e-07
Iter: 1302 loss: 5.8423359e-07
Iter: 1303 loss: 5.84299187e-07
Iter: 1304 loss: 5.84216139e-07
Iter: 1305 loss: 5.84183056e-07
Iter: 1306 loss: 5.84866712e-07
Iter: 1307 loss: 5.8419414e-07
Iter: 1308 loss: 5.84148438e-07
Iter: 1309 loss: 5.84110921e-07
Iter: 1310 loss: 5.84117856e-07
Iter: 1311 loss: 5.84024633e-07
Iter: 1312 loss: 5.8464e-07
Iter: 1313 loss: 5.8403657e-07
Iter: 1314 loss: 5.83988253e-07
Iter: 1315 loss: 5.84303962e-07
Iter: 1316 loss: 5.83990129e-07
Iter: 1317 loss: 5.83928625e-07
Iter: 1318 loss: 5.8385092e-07
Iter: 1319 loss: 5.8557e-07
Iter: 1320 loss: 5.83837789e-07
Iter: 1321 loss: 5.83768099e-07
Iter: 1322 loss: 5.84246e-07
Iter: 1323 loss: 5.83744168e-07
Iter: 1324 loss: 5.83688632e-07
Iter: 1325 loss: 5.83774295e-07
Iter: 1326 loss: 5.83635e-07
Iter: 1327 loss: 5.83607e-07
Iter: 1328 loss: 5.83582676e-07
Iter: 1329 loss: 5.83560109e-07
Iter: 1330 loss: 5.8350264e-07
Iter: 1331 loss: 5.84242343e-07
Iter: 1332 loss: 5.83481722e-07
Iter: 1333 loss: 5.83450117e-07
Iter: 1334 loss: 5.83437725e-07
Iter: 1335 loss: 5.83410838e-07
Iter: 1336 loss: 5.83375481e-07
Iter: 1337 loss: 5.83371957e-07
Iter: 1338 loss: 5.83305564e-07
Iter: 1339 loss: 5.83391966e-07
Iter: 1340 loss: 5.8327646e-07
Iter: 1341 loss: 5.83208305e-07
Iter: 1342 loss: 5.83452731e-07
Iter: 1343 loss: 5.83182555e-07
Iter: 1344 loss: 5.83089e-07
Iter: 1345 loss: 5.83059716e-07
Iter: 1346 loss: 5.8304272e-07
Iter: 1347 loss: 5.82908115e-07
Iter: 1348 loss: 5.83638723e-07
Iter: 1349 loss: 5.82910502e-07
Iter: 1350 loss: 5.82825123e-07
Iter: 1351 loss: 5.83690337e-07
Iter: 1352 loss: 5.82833366e-07
Iter: 1353 loss: 5.82783969e-07
Iter: 1354 loss: 5.82848e-07
Iter: 1355 loss: 5.82737e-07
Iter: 1356 loss: 5.82688358e-07
Iter: 1357 loss: 5.82719338e-07
Iter: 1358 loss: 5.8266653e-07
Iter: 1359 loss: 5.82563302e-07
Iter: 1360 loss: 5.82649875e-07
Iter: 1361 loss: 5.82545738e-07
Iter: 1362 loss: 5.82512314e-07
Iter: 1363 loss: 5.82494863e-07
Iter: 1364 loss: 5.82463713e-07
Iter: 1365 loss: 5.8239408e-07
Iter: 1366 loss: 5.8242415e-07
Iter: 1367 loss: 5.82331154e-07
Iter: 1368 loss: 5.8239641e-07
Iter: 1369 loss: 5.82316147e-07
Iter: 1370 loss: 5.82248731e-07
Iter: 1371 loss: 5.82262146e-07
Iter: 1372 loss: 5.82226619e-07
Iter: 1373 loss: 5.82154939e-07
Iter: 1374 loss: 5.82545908e-07
Iter: 1375 loss: 5.82127484e-07
Iter: 1376 loss: 5.82050689e-07
Iter: 1377 loss: 5.82913799e-07
Iter: 1378 loss: 5.82052053e-07
Iter: 1379 loss: 5.82010216e-07
Iter: 1380 loss: 5.82240091e-07
Iter: 1381 loss: 5.82001462e-07
Iter: 1382 loss: 5.81911479e-07
Iter: 1383 loss: 5.81987592e-07
Iter: 1384 loss: 5.81893119e-07
Iter: 1385 loss: 5.81861968e-07
Iter: 1386 loss: 5.81795859e-07
Iter: 1387 loss: 5.81808649e-07
Iter: 1388 loss: 5.81754421e-07
Iter: 1389 loss: 5.81755444e-07
Iter: 1390 loss: 5.81676659e-07
Iter: 1391 loss: 5.8171031e-07
Iter: 1392 loss: 5.81643917e-07
Iter: 1393 loss: 5.81592815e-07
Iter: 1394 loss: 5.81796371e-07
Iter: 1395 loss: 5.81557401e-07
Iter: 1396 loss: 5.81502775e-07
Iter: 1397 loss: 5.81713209e-07
Iter: 1398 loss: 5.81468839e-07
Iter: 1399 loss: 5.81442123e-07
Iter: 1400 loss: 5.81369306e-07
Iter: 1401 loss: 5.8298906e-07
Iter: 1402 loss: 5.81357142e-07
Iter: 1403 loss: 5.8128694e-07
Iter: 1404 loss: 5.8222065e-07
Iter: 1405 loss: 5.81318204e-07
Iter: 1406 loss: 5.81267386e-07
Iter: 1407 loss: 5.81269887e-07
Iter: 1408 loss: 5.8124192e-07
Iter: 1409 loss: 5.81192126e-07
Iter: 1410 loss: 5.82071493e-07
Iter: 1411 loss: 5.81210088e-07
Iter: 1412 loss: 5.81153e-07
Iter: 1413 loss: 5.81197469e-07
Iter: 1414 loss: 5.81132e-07
Iter: 1415 loss: 5.81042798e-07
Iter: 1416 loss: 5.81365839e-07
Iter: 1417 loss: 5.81037284e-07
Iter: 1418 loss: 5.80983851e-07
Iter: 1419 loss: 5.81682912e-07
Iter: 1420 loss: 5.80979076e-07
Iter: 1421 loss: 5.80949688e-07
Iter: 1422 loss: 5.80860615e-07
Iter: 1423 loss: 5.80862888e-07
Iter: 1424 loss: 5.80816845e-07
Iter: 1425 loss: 5.80896085e-07
Iter: 1426 loss: 5.80748917e-07
Iter: 1427 loss: 5.80720837e-07
Iter: 1428 loss: 5.80729761e-07
Iter: 1429 loss: 5.8067144e-07
Iter: 1430 loss: 5.80708615e-07
Iter: 1431 loss: 5.80639096e-07
Iter: 1432 loss: 5.8057492e-07
Iter: 1433 loss: 5.80622668e-07
Iter: 1434 loss: 5.80558719e-07
Iter: 1435 loss: 5.80519554e-07
Iter: 1436 loss: 5.80894493e-07
Iter: 1437 loss: 5.80496817e-07
Iter: 1438 loss: 5.80470783e-07
Iter: 1439 loss: 5.80447e-07
Iter: 1440 loss: 5.80443441e-07
Iter: 1441 loss: 5.80400467e-07
Iter: 1442 loss: 5.80414223e-07
Iter: 1443 loss: 5.80359e-07
Iter: 1444 loss: 5.80339815e-07
Iter: 1445 loss: 5.80324752e-07
Iter: 1446 loss: 5.80238e-07
Iter: 1447 loss: 5.80221126e-07
Iter: 1448 loss: 5.80187361e-07
Iter: 1449 loss: 5.80132905e-07
Iter: 1450 loss: 5.80405185e-07
Iter: 1451 loss: 5.80112044e-07
Iter: 1452 loss: 5.80049232e-07
Iter: 1453 loss: 5.80149447e-07
Iter: 1454 loss: 5.80024e-07
Iter: 1455 loss: 5.79975563e-07
Iter: 1456 loss: 5.79971697e-07
Iter: 1457 loss: 5.7995851e-07
Iter: 1458 loss: 5.79940661e-07
Iter: 1459 loss: 5.79904111e-07
Iter: 1460 loss: 5.79868299e-07
Iter: 1461 loss: 5.79841185e-07
Iter: 1462 loss: 5.79793095e-07
Iter: 1463 loss: 5.79769e-07
Iter: 1464 loss: 5.79774849e-07
Iter: 1465 loss: 5.79751e-07
Iter: 1466 loss: 5.79687196e-07
Iter: 1467 loss: 5.80542519e-07
Iter: 1468 loss: 5.79668722e-07
Iter: 1469 loss: 5.79582093e-07
Iter: 1470 loss: 5.79579478e-07
Iter: 1471 loss: 5.79543212e-07
Iter: 1472 loss: 5.79499101e-07
Iter: 1473 loss: 5.79500806e-07
Iter: 1474 loss: 5.79439529e-07
Iter: 1475 loss: 5.79567256e-07
Iter: 1476 loss: 5.79437597e-07
Iter: 1477 loss: 5.79409061e-07
Iter: 1478 loss: 5.79442144e-07
Iter: 1479 loss: 5.79369043e-07
Iter: 1480 loss: 5.79349262e-07
Iter: 1481 loss: 5.79681227e-07
Iter: 1482 loss: 5.79335619e-07
Iter: 1483 loss: 5.79309756e-07
Iter: 1484 loss: 5.79245921e-07
Iter: 1485 loss: 5.79251662e-07
Iter: 1486 loss: 5.79156335e-07
Iter: 1487 loss: 5.79283778e-07
Iter: 1488 loss: 5.79129278e-07
Iter: 1489 loss: 5.79095399e-07
Iter: 1490 loss: 5.79393088e-07
Iter: 1491 loss: 5.79064135e-07
Iter: 1492 loss: 5.7902804e-07
Iter: 1493 loss: 5.79343805e-07
Iter: 1494 loss: 5.78999789e-07
Iter: 1495 loss: 5.789243e-07
Iter: 1496 loss: 5.78982622e-07
Iter: 1497 loss: 5.78903268e-07
Iter: 1498 loss: 5.78849949e-07
Iter: 1499 loss: 5.79187e-07
Iter: 1500 loss: 5.78830964e-07
Iter: 1501 loss: 5.78767697e-07
Iter: 1502 loss: 5.78813513e-07
Iter: 1503 loss: 5.78748541e-07
Iter: 1504 loss: 5.78677714e-07
Iter: 1505 loss: 5.78734557e-07
Iter: 1506 loss: 5.78665436e-07
Iter: 1507 loss: 5.78640766e-07
Iter: 1508 loss: 5.7876548e-07
Iter: 1509 loss: 5.78632353e-07
Iter: 1510 loss: 5.78562094e-07
Iter: 1511 loss: 5.79177936e-07
Iter: 1512 loss: 5.78572e-07
Iter: 1513 loss: 5.78542085e-07
Iter: 1514 loss: 5.78509116e-07
Iter: 1515 loss: 5.79735229e-07
Iter: 1516 loss: 5.78520712e-07
Iter: 1517 loss: 5.78443291e-07
Iter: 1518 loss: 5.79282641e-07
Iter: 1519 loss: 5.78446134e-07
Iter: 1520 loss: 5.78414529e-07
Iter: 1521 loss: 5.78378149e-07
Iter: 1522 loss: 5.78365245e-07
Iter: 1523 loss: 5.78314882e-07
Iter: 1524 loss: 5.78393269e-07
Iter: 1525 loss: 5.78265258e-07
Iter: 1526 loss: 5.78191418e-07
Iter: 1527 loss: 5.78295612e-07
Iter: 1528 loss: 5.78153106e-07
Iter: 1529 loss: 5.78110587e-07
Iter: 1530 loss: 5.7808785e-07
Iter: 1531 loss: 5.78096149e-07
Iter: 1532 loss: 5.78078698e-07
Iter: 1533 loss: 5.78088134e-07
Iter: 1534 loss: 5.7805147e-07
Iter: 1535 loss: 5.78095865e-07
Iter: 1536 loss: 5.78073241e-07
Iter: 1537 loss: 5.78078527e-07
Iter: 1538 loss: 5.78064487e-07
Iter: 1539 loss: 5.78096547e-07
Iter: 1540 loss: 5.78082677e-07
Iter: 1541 loss: 5.78075174e-07
Iter: 1542 loss: 5.78084496e-07
Iter: 1543 loss: 5.78093818e-07
Iter: 1544 loss: 5.78091829e-07
Iter: 1545 loss: 5.78084837e-07
Iter: 1546 loss: 5.78089498e-07
Iter: 1547 loss: 5.78090578e-07
Iter: 1548 loss: 5.78084951e-07
Iter: 1549 loss: 5.78089157e-07
Iter: 1550 loss: 5.78086656e-07
Iter: 1551 loss: 5.78087395e-07
Iter: 1552 loss: 5.78089157e-07
Iter: 1553 loss: 5.78088e-07
Iter: 1554 loss: 5.78089157e-07
Iter: 1555 loss: 5.78088e-07
Iter: 1556 loss: 5.78089157e-07
Iter: 1557 loss: 5.78038964e-07
Iter: 1558 loss: 5.78193408e-07
Iter: 1559 loss: 5.78019808e-07
Iter: 1560 loss: 5.7800014e-07
Iter: 1561 loss: 5.78448635e-07
Iter: 1562 loss: 5.78012646e-07
Iter: 1563 loss: 5.77956e-07
Iter: 1564 loss: 5.78061872e-07
Iter: 1565 loss: 5.77967114e-07
Iter: 1566 loss: 5.7791334e-07
Iter: 1567 loss: 5.77903506e-07
Iter: 1568 loss: 5.7852651e-07
Iter: 1569 loss: 5.77920957e-07
Iter: 1570 loss: 5.7787588e-07
Iter: 1571 loss: 5.77867752e-07
Iter: 1572 loss: 5.77842854e-07
Iter: 1573 loss: 5.77788853e-07
Iter: 1574 loss: 5.77807896e-07
Iter: 1575 loss: 5.77764183e-07
Iter: 1576 loss: 5.77859055e-07
Iter: 1577 loss: 5.7773093e-07
Iter: 1578 loss: 5.77646347e-07
Iter: 1579 loss: 5.77987237e-07
Iter: 1580 loss: 5.77659534e-07
Iter: 1581 loss: 5.77605249e-07
Iter: 1582 loss: 5.77584103e-07
Iter: 1583 loss: 5.77569892e-07
Iter: 1584 loss: 5.77450862e-07
Iter: 1585 loss: 5.77617925e-07
Iter: 1586 loss: 5.77409708e-07
Iter: 1587 loss: 5.77349454e-07
Iter: 1588 loss: 5.78220181e-07
Iter: 1589 loss: 5.77346327e-07
Iter: 1590 loss: 5.7729585e-07
Iter: 1591 loss: 5.77307617e-07
Iter: 1592 loss: 5.77266064e-07
Iter: 1593 loss: 5.77232868e-07
Iter: 1594 loss: 5.77641799e-07
Iter: 1595 loss: 5.77230594e-07
Iter: 1596 loss: 5.77164542e-07
Iter: 1597 loss: 5.77348601e-07
Iter: 1598 loss: 5.77143624e-07
Iter: 1599 loss: 5.77117817e-07
Iter: 1600 loss: 5.77174092e-07
Iter: 1601 loss: 5.77106164e-07
Iter: 1602 loss: 5.77086439e-07
Iter: 1603 loss: 5.77090191e-07
Iter: 1604 loss: 5.77032722e-07
Iter: 1605 loss: 5.7701277e-07
Iter: 1606 loss: 5.77449271e-07
Iter: 1607 loss: 5.7702016e-07
Iter: 1608 loss: 5.76983041e-07
Iter: 1609 loss: 5.76986849e-07
Iter: 1610 loss: 5.76955699e-07
Iter: 1611 loss: 5.7695155e-07
Iter: 1612 loss: 5.76984917e-07
Iter: 1613 loss: 5.76934781e-07
Iter: 1614 loss: 5.76897378e-07
Iter: 1615 loss: 5.76948082e-07
Iter: 1616 loss: 5.76857133e-07
Iter: 1617 loss: 5.7685611e-07
Iter: 1618 loss: 5.76822799e-07
Iter: 1619 loss: 5.76817683e-07
Iter: 1620 loss: 5.76757088e-07
Iter: 1621 loss: 5.76888965e-07
Iter: 1622 loss: 5.7676607e-07
Iter: 1623 loss: 5.76705361e-07
Iter: 1624 loss: 5.76746e-07
Iter: 1625 loss: 5.76663297e-07
Iter: 1626 loss: 5.76625951e-07
Iter: 1627 loss: 5.76634136e-07
Iter: 1628 loss: 5.76624e-07
Iter: 1629 loss: 5.76633965e-07
Iter: 1630 loss: 5.7660543e-07
Iter: 1631 loss: 5.76563593e-07
Iter: 1632 loss: 5.76659772e-07
Iter: 1633 loss: 5.76537445e-07
Iter: 1634 loss: 5.76489e-07
Iter: 1635 loss: 5.7654745e-07
Iter: 1636 loss: 5.76471734e-07
Iter: 1637 loss: 5.76461275e-07
Iter: 1638 loss: 5.76616799e-07
Iter: 1639 loss: 5.76447519e-07
Iter: 1640 loss: 5.76425236e-07
Iter: 1641 loss: 5.76418813e-07
Iter: 1642 loss: 5.76371065e-07
Iter: 1643 loss: 5.76330535e-07
Iter: 1644 loss: 5.76345656e-07
Iter: 1645 loss: 5.76306661e-07
Iter: 1646 loss: 5.76270168e-07
Iter: 1647 loss: 5.76736056e-07
Iter: 1648 loss: 5.76271418e-07
Iter: 1649 loss: 5.76238676e-07
Iter: 1650 loss: 5.76240666e-07
Iter: 1651 loss: 5.76205593e-07
Iter: 1652 loss: 5.7615631e-07
Iter: 1653 loss: 5.76114587e-07
Iter: 1654 loss: 5.76093157e-07
Iter: 1655 loss: 5.76027048e-07
Iter: 1656 loss: 5.767223e-07
Iter: 1657 loss: 5.76082073e-07
Iter: 1658 loss: 5.76007324e-07
Iter: 1659 loss: 5.76135108e-07
Iter: 1660 loss: 5.7599226e-07
Iter: 1661 loss: 5.75948661e-07
Iter: 1662 loss: 5.76343098e-07
Iter: 1663 loss: 5.75954289e-07
Iter: 1664 loss: 5.75902959e-07
Iter: 1665 loss: 5.75972081e-07
Iter: 1666 loss: 5.75899321e-07
Iter: 1667 loss: 5.75865784e-07
Iter: 1668 loss: 5.75864533e-07
Iter: 1669 loss: 5.75835315e-07
Iter: 1670 loss: 5.75812351e-07
Iter: 1671 loss: 5.76092248e-07
Iter: 1672 loss: 5.75820593e-07
Iter: 1673 loss: 5.75799334e-07
Iter: 1674 loss: 5.75789386e-07
Iter: 1675 loss: 5.75764602e-07
Iter: 1676 loss: 5.75762044e-07
Iter: 1677 loss: 5.75734703e-07
Iter: 1678 loss: 5.75691558e-07
Iter: 1679 loss: 5.75687068e-07
Iter: 1680 loss: 5.75677745e-07
Iter: 1681 loss: 5.75648187e-07
Iter: 1682 loss: 5.75872207e-07
Iter: 1683 loss: 5.7562147e-07
Iter: 1684 loss: 5.75580884e-07
Iter: 1685 loss: 5.75499087e-07
Iter: 1686 loss: 5.75507443e-07
Iter: 1687 loss: 5.75461456e-07
Iter: 1688 loss: 5.75763693e-07
Iter: 1689 loss: 5.75436616e-07
Iter: 1690 loss: 5.75378408e-07
Iter: 1691 loss: 5.75314687e-07
Iter: 1692 loss: 5.7530832e-07
Iter: 1693 loss: 5.75198328e-07
Iter: 1694 loss: 5.75347769e-07
Iter: 1695 loss: 5.7514734e-07
Iter: 1696 loss: 5.7505531e-07
Iter: 1697 loss: 5.75082538e-07
Iter: 1698 loss: 5.7501029e-07
Iter: 1699 loss: 5.7530724e-07
Iter: 1700 loss: 5.75014724e-07
Iter: 1701 loss: 5.74988576e-07
Iter: 1702 loss: 5.75082e-07
Iter: 1703 loss: 5.74987666e-07
Iter: 1704 loss: 5.74928322e-07
Iter: 1705 loss: 5.75080549e-07
Iter: 1706 loss: 5.74955152e-07
Iter: 1707 loss: 5.74911553e-07
Iter: 1708 loss: 5.75128524e-07
Iter: 1709 loss: 5.74860564e-07
Iter: 1710 loss: 5.74850446e-07
Iter: 1711 loss: 5.74845217e-07
Iter: 1712 loss: 5.74850219e-07
Iter: 1713 loss: 5.74797184e-07
Iter: 1714 loss: 5.75054e-07
Iter: 1715 loss: 5.74810031e-07
Iter: 1716 loss: 5.7477007e-07
Iter: 1717 loss: 5.74900525e-07
Iter: 1718 loss: 5.74753415e-07
Iter: 1719 loss: 5.7474648e-07
Iter: 1720 loss: 5.74811224e-07
Iter: 1721 loss: 5.74728801e-07
Iter: 1722 loss: 5.74702426e-07
Iter: 1723 loss: 5.74663886e-07
Iter: 1724 loss: 5.746341e-07
Iter: 1725 loss: 5.74617502e-07
Iter: 1726 loss: 5.74613523e-07
Iter: 1727 loss: 5.74570663e-07
Iter: 1728 loss: 5.74525188e-07
Iter: 1729 loss: 5.74546107e-07
Iter: 1730 loss: 5.74477895e-07
Iter: 1731 loss: 5.74425201e-07
Iter: 1732 loss: 5.74535648e-07
Iter: 1733 loss: 5.74389219e-07
Iter: 1734 loss: 5.74329931e-07
Iter: 1735 loss: 5.75192189e-07
Iter: 1736 loss: 5.74314413e-07
Iter: 1737 loss: 5.74243e-07
Iter: 1738 loss: 5.74454191e-07
Iter: 1739 loss: 5.74232445e-07
Iter: 1740 loss: 5.74196747e-07
Iter: 1741 loss: 5.74416504e-07
Iter: 1742 loss: 5.74183559e-07
Iter: 1743 loss: 5.7414627e-07
Iter: 1744 loss: 5.7426638e-07
Iter: 1745 loss: 5.74140699e-07
Iter: 1746 loss: 5.74091871e-07
Iter: 1747 loss: 5.74064529e-07
Iter: 1748 loss: 5.74049068e-07
Iter: 1749 loss: 5.74013598e-07
Iter: 1750 loss: 5.74011779e-07
Iter: 1751 loss: 5.74007572e-07
Iter: 1752 loss: 5.7397682e-07
Iter: 1753 loss: 5.73981254e-07
Iter: 1754 loss: 5.73928e-07
Iter: 1755 loss: 5.73982049e-07
Iter: 1756 loss: 5.73898888e-07
Iter: 1757 loss: 5.73865577e-07
Iter: 1758 loss: 5.73948569e-07
Iter: 1759 loss: 5.73816635e-07
Iter: 1760 loss: 5.73749844e-07
Iter: 1761 loss: 5.7372722e-07
Iter: 1762 loss: 5.73707894e-07
Iter: 1763 loss: 5.73645934e-07
Iter: 1764 loss: 5.74021669e-07
Iter: 1765 loss: 5.73631269e-07
Iter: 1766 loss: 5.7357903e-07
Iter: 1767 loss: 5.73721422e-07
Iter: 1768 loss: 5.73579314e-07
Iter: 1769 loss: 5.7355129e-07
Iter: 1770 loss: 5.73562659e-07
Iter: 1771 loss: 5.73514512e-07
Iter: 1772 loss: 5.73441866e-07
Iter: 1773 loss: 5.73615466e-07
Iter: 1774 loss: 5.73434932e-07
Iter: 1775 loss: 5.73420834e-07
Iter: 1776 loss: 5.73393322e-07
Iter: 1777 loss: 5.73380191e-07
Iter: 1778 loss: 5.73380646e-07
Iter: 1779 loss: 5.73367799e-07
Iter: 1780 loss: 5.73329942e-07
Iter: 1781 loss: 5.73375416e-07
Iter: 1782 loss: 5.73312946e-07
Iter: 1783 loss: 5.73268323e-07
Iter: 1784 loss: 5.73211423e-07
Iter: 1785 loss: 5.73206307e-07
Iter: 1786 loss: 5.73136049e-07
Iter: 1787 loss: 5.73131e-07
Iter: 1788 loss: 5.73094212e-07
Iter: 1789 loss: 5.73026e-07
Iter: 1790 loss: 5.73033219e-07
Iter: 1791 loss: 5.72959607e-07
Iter: 1792 loss: 5.73265652e-07
Iter: 1793 loss: 5.7293812e-07
Iter: 1794 loss: 5.72882414e-07
Iter: 1795 loss: 5.73120644e-07
Iter: 1796 loss: 5.72851775e-07
Iter: 1797 loss: 5.72756733e-07
Iter: 1798 loss: 5.72930276e-07
Iter: 1799 loss: 5.7278055e-07
Iter: 1800 loss: 5.72776e-07
Iter: 1801 loss: 5.72685394e-07
Iter: 1802 loss: 5.74168212e-07
Iter: 1803 loss: 5.72705744e-07
Iter: 1804 loss: 5.72630711e-07
Iter: 1805 loss: 5.73196758e-07
Iter: 1806 loss: 5.72632189e-07
Iter: 1807 loss: 5.7256625e-07
Iter: 1808 loss: 5.72687497e-07
Iter: 1809 loss: 5.72573697e-07
Iter: 1810 loss: 5.72537374e-07
Iter: 1811 loss: 5.72699605e-07
Iter: 1812 loss: 5.7253078e-07
Iter: 1813 loss: 5.72452791e-07
Iter: 1814 loss: 5.73122e-07
Iter: 1815 loss: 5.72442502e-07
Iter: 1816 loss: 5.72435397e-07
Iter: 1817 loss: 5.72417889e-07
Iter: 1818 loss: 5.72413796e-07
Iter: 1819 loss: 5.72369288e-07
Iter: 1820 loss: 5.7245785e-07
Iter: 1821 loss: 5.72338593e-07
Iter: 1822 loss: 5.72314491e-07
Iter: 1823 loss: 5.72313127e-07
Iter: 1824 loss: 5.72283511e-07
Iter: 1825 loss: 5.72248211e-07
Iter: 1826 loss: 5.72694034e-07
Iter: 1827 loss: 5.72240481e-07
Iter: 1828 loss: 5.72182671e-07
Iter: 1829 loss: 5.72250258e-07
Iter: 1830 loss: 5.72148849e-07
Iter: 1831 loss: 5.72143961e-07
Iter: 1832 loss: 5.72348654e-07
Iter: 1833 loss: 5.7212236e-07
Iter: 1834 loss: 5.72076601e-07
Iter: 1835 loss: 5.72003842e-07
Iter: 1836 loss: 5.73277e-07
Iter: 1837 loss: 5.72008332e-07
Iter: 1838 loss: 5.71933924e-07
Iter: 1839 loss: 5.72396345e-07
Iter: 1840 loss: 5.71910164e-07
Iter: 1841 loss: 5.7187242e-07
Iter: 1842 loss: 5.71889188e-07
Iter: 1843 loss: 5.71823364e-07
Iter: 1844 loss: 5.71749183e-07
Iter: 1845 loss: 5.71954e-07
Iter: 1846 loss: 5.71698365e-07
Iter: 1847 loss: 5.71642545e-07
Iter: 1848 loss: 5.72003273e-07
Iter: 1849 loss: 5.71638793e-07
Iter: 1850 loss: 5.71550572e-07
Iter: 1851 loss: 5.71562282e-07
Iter: 1852 loss: 5.71550117e-07
Iter: 1853 loss: 5.71626231e-07
Iter: 1854 loss: 5.71538e-07
Iter: 1855 loss: 5.71497e-07
Iter: 1856 loss: 5.71431315e-07
Iter: 1857 loss: 5.72075805e-07
Iter: 1858 loss: 5.71425687e-07
Iter: 1859 loss: 5.71409146e-07
Iter: 1860 loss: 5.7140312e-07
Iter: 1861 loss: 5.71369583e-07
Iter: 1862 loss: 5.71311205e-07
Iter: 1863 loss: 5.71302849e-07
Iter: 1864 loss: 5.71296709e-07
Iter: 1865 loss: 5.71645842e-07
Iter: 1866 loss: 5.71272039e-07
Iter: 1867 loss: 5.71246915e-07
Iter: 1868 loss: 5.71325813e-07
Iter: 1869 loss: 5.71230089e-07
Iter: 1870 loss: 5.71184273e-07
Iter: 1871 loss: 5.71147666e-07
Iter: 1872 loss: 5.71128453e-07
Iter: 1873 loss: 5.71141243e-07
Iter: 1874 loss: 5.71135104e-07
Iter: 1875 loss: 5.71135388e-07
Iter: 1876 loss: 5.71136752e-07
Iter: 1877 loss: 5.7112436e-07
Iter: 1878 loss: 5.71110604e-07
Iter: 1879 loss: 5.7113391e-07
Iter: 1880 loss: 5.71128908e-07
Iter: 1881 loss: 5.71133114e-07
Iter: 1882 loss: 5.71126748e-07
Iter: 1883 loss: 5.7113806e-07
Iter: 1884 loss: 5.71127771e-07
Iter: 1885 loss: 5.71120722e-07
Iter: 1886 loss: 5.71130727e-07
Iter: 1887 loss: 5.71126861e-07
Iter: 1888 loss: 5.71133398e-07
Iter: 1889 loss: 5.71128055e-07
Iter: 1890 loss: 5.71131295e-07
Iter: 1891 loss: 5.71128112e-07
Iter: 1892 loss: 5.71133569e-07
Iter: 1893 loss: 5.71129817e-07
Iter: 1894 loss: 5.71130101e-07
Iter: 1895 loss: 5.71128226e-07
Iter: 1896 loss: 5.71128908e-07
Iter: 1897 loss: 5.71129135e-07
Iter: 1898 loss: 5.71129135e-07
Iter: 1899 loss: 5.71129135e-07
Iter: 1900 loss: 5.71128908e-07
Iter: 1901 loss: 5.71129135e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.6
+ date
Mon Nov  9 06:15:53 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.6/500_500_500_500_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_1000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.6/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.6 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_1000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693eead08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693f08a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693f81ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693f81d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693e8b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693e5e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693e5e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693dc6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693dc6c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693d89730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693db4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693d44268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693d04378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693d199d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693d3a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693ceba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693c7f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693d19510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693c75f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693c75950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693c2f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693bd56a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693be8950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693b91e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693bb28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693b77f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693b42c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693b07f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa693b42a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa68051aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa680540b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa6804f4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa6804ae488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa6804c7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa6804c7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa680413ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.74125648e-06
Iter: 2 loss: 7.66488392e-06
Iter: 3 loss: 1.88731565e-06
Iter: 4 loss: 1.5365431e-06
Iter: 5 loss: 2.160858e-06
Iter: 6 loss: 1.3828876e-06
Iter: 7 loss: 1.17065292e-06
Iter: 8 loss: 1.2478456e-06
Iter: 9 loss: 1.02211504e-06
Iter: 10 loss: 8.76257047e-07
Iter: 11 loss: 1.4784024e-06
Iter: 12 loss: 8.44714691e-07
Iter: 13 loss: 7.57518933e-07
Iter: 14 loss: 1.36654819e-06
Iter: 15 loss: 7.49691424e-07
Iter: 16 loss: 6.93381708e-07
Iter: 17 loss: 1.153163e-06
Iter: 18 loss: 6.89892033e-07
Iter: 19 loss: 6.7372946e-07
Iter: 20 loss: 8.05347668e-07
Iter: 21 loss: 6.72703891e-07
Iter: 22 loss: 6.58894919e-07
Iter: 23 loss: 6.66044e-07
Iter: 24 loss: 6.49629783e-07
Iter: 25 loss: 6.37882295e-07
Iter: 26 loss: 6.67480435e-07
Iter: 27 loss: 6.33778541e-07
Iter: 28 loss: 6.25758105e-07
Iter: 29 loss: 6.28490227e-07
Iter: 30 loss: 6.20061257e-07
Iter: 31 loss: 6.10794302e-07
Iter: 32 loss: 6.66675419e-07
Iter: 33 loss: 6.09625715e-07
Iter: 34 loss: 6.01968509e-07
Iter: 35 loss: 6.06647e-07
Iter: 36 loss: 5.97086455e-07
Iter: 37 loss: 5.87883164e-07
Iter: 38 loss: 6.10226834e-07
Iter: 39 loss: 5.84554925e-07
Iter: 40 loss: 5.75304171e-07
Iter: 41 loss: 6.29344811e-07
Iter: 42 loss: 5.74146441e-07
Iter: 43 loss: 5.68882e-07
Iter: 44 loss: 5.68890869e-07
Iter: 45 loss: 5.62747289e-07
Iter: 46 loss: 5.61646061e-07
Iter: 47 loss: 5.57345686e-07
Iter: 48 loss: 5.52882e-07
Iter: 49 loss: 5.91134949e-07
Iter: 50 loss: 5.52719257e-07
Iter: 51 loss: 5.49164668e-07
Iter: 52 loss: 5.41313455e-07
Iter: 53 loss: 6.49964932e-07
Iter: 54 loss: 5.40825056e-07
Iter: 55 loss: 5.34979051e-07
Iter: 56 loss: 6.23725157e-07
Iter: 57 loss: 5.34954609e-07
Iter: 58 loss: 5.28946714e-07
Iter: 59 loss: 5.38088386e-07
Iter: 60 loss: 5.26099313e-07
Iter: 61 loss: 5.20357048e-07
Iter: 62 loss: 5.50777372e-07
Iter: 63 loss: 5.19579658e-07
Iter: 64 loss: 5.14790543e-07
Iter: 65 loss: 5.31144622e-07
Iter: 66 loss: 5.13518273e-07
Iter: 67 loss: 5.09267863e-07
Iter: 68 loss: 5.03876549e-07
Iter: 69 loss: 5.03475405e-07
Iter: 70 loss: 4.97251563e-07
Iter: 71 loss: 5.19387584e-07
Iter: 72 loss: 4.95708321e-07
Iter: 73 loss: 4.90076e-07
Iter: 74 loss: 5.1502343e-07
Iter: 75 loss: 4.88923e-07
Iter: 76 loss: 4.85410794e-07
Iter: 77 loss: 4.98611257e-07
Iter: 78 loss: 4.84667964e-07
Iter: 79 loss: 4.80948074e-07
Iter: 80 loss: 4.88188448e-07
Iter: 81 loss: 4.79426205e-07
Iter: 82 loss: 4.81519749e-07
Iter: 83 loss: 4.78245283e-07
Iter: 84 loss: 4.77670881e-07
Iter: 85 loss: 4.75971092e-07
Iter: 86 loss: 4.75903619e-07
Iter: 87 loss: 4.74139512e-07
Iter: 88 loss: 4.71970651e-07
Iter: 89 loss: 4.71828372e-07
Iter: 90 loss: 4.70276404e-07
Iter: 91 loss: 4.69210818e-07
Iter: 92 loss: 4.6870332e-07
Iter: 93 loss: 4.66137465e-07
Iter: 94 loss: 4.75798061e-07
Iter: 95 loss: 4.65473818e-07
Iter: 96 loss: 4.63275e-07
Iter: 97 loss: 4.85198029e-07
Iter: 98 loss: 4.63207897e-07
Iter: 99 loss: 4.61924174e-07
Iter: 100 loss: 4.62977198e-07
Iter: 101 loss: 4.61116031e-07
Iter: 102 loss: 4.5922414e-07
Iter: 103 loss: 4.63077413e-07
Iter: 104 loss: 4.58385159e-07
Iter: 105 loss: 4.5682242e-07
Iter: 106 loss: 4.5466561e-07
Iter: 107 loss: 4.54632755e-07
Iter: 108 loss: 4.52185e-07
Iter: 109 loss: 4.82396729e-07
Iter: 110 loss: 4.52145457e-07
Iter: 111 loss: 4.50473067e-07
Iter: 112 loss: 4.48295964e-07
Iter: 113 loss: 4.48107841e-07
Iter: 114 loss: 4.45043497e-07
Iter: 115 loss: 4.68346229e-07
Iter: 116 loss: 4.4484014e-07
Iter: 117 loss: 4.4374255e-07
Iter: 118 loss: 4.43590295e-07
Iter: 119 loss: 4.42112565e-07
Iter: 120 loss: 4.4111988e-07
Iter: 121 loss: 4.40594704e-07
Iter: 122 loss: 4.38875588e-07
Iter: 123 loss: 4.3790331e-07
Iter: 124 loss: 4.37207376e-07
Iter: 125 loss: 4.34979768e-07
Iter: 126 loss: 4.61769503e-07
Iter: 127 loss: 4.34983747e-07
Iter: 128 loss: 4.33543221e-07
Iter: 129 loss: 4.34990142e-07
Iter: 130 loss: 4.32668656e-07
Iter: 131 loss: 4.31270536e-07
Iter: 132 loss: 4.30639943e-07
Iter: 133 loss: 4.29953531e-07
Iter: 134 loss: 4.2939476e-07
Iter: 135 loss: 4.29207148e-07
Iter: 136 loss: 4.2834273e-07
Iter: 137 loss: 4.28382464e-07
Iter: 138 loss: 4.27753037e-07
Iter: 139 loss: 4.2694262e-07
Iter: 140 loss: 4.33019466e-07
Iter: 141 loss: 4.26779167e-07
Iter: 142 loss: 4.26067771e-07
Iter: 143 loss: 4.26131379e-07
Iter: 144 loss: 4.25493511e-07
Iter: 145 loss: 4.24415418e-07
Iter: 146 loss: 4.23393033e-07
Iter: 147 loss: 4.23091933e-07
Iter: 148 loss: 4.21619291e-07
Iter: 149 loss: 4.24018765e-07
Iter: 150 loss: 4.20844316e-07
Iter: 151 loss: 4.19288256e-07
Iter: 152 loss: 4.40390863e-07
Iter: 153 loss: 4.19273874e-07
Iter: 154 loss: 4.18144339e-07
Iter: 155 loss: 4.34517432e-07
Iter: 156 loss: 4.18118844e-07
Iter: 157 loss: 4.17442777e-07
Iter: 158 loss: 4.15714965e-07
Iter: 159 loss: 4.27503721e-07
Iter: 160 loss: 4.15295602e-07
Iter: 161 loss: 4.14032229e-07
Iter: 162 loss: 4.1402717e-07
Iter: 163 loss: 4.12987106e-07
Iter: 164 loss: 4.15319249e-07
Iter: 165 loss: 4.12604891e-07
Iter: 166 loss: 4.11371104e-07
Iter: 167 loss: 4.12079544e-07
Iter: 168 loss: 4.10688358e-07
Iter: 169 loss: 4.09628143e-07
Iter: 170 loss: 4.12766525e-07
Iter: 171 loss: 4.09336167e-07
Iter: 172 loss: 4.08307301e-07
Iter: 173 loss: 4.19134835e-07
Iter: 174 loss: 4.0828121e-07
Iter: 175 loss: 4.07644336e-07
Iter: 176 loss: 4.078085e-07
Iter: 177 loss: 4.07123679e-07
Iter: 178 loss: 4.06307549e-07
Iter: 179 loss: 4.11216547e-07
Iter: 180 loss: 4.06115021e-07
Iter: 181 loss: 4.05390551e-07
Iter: 182 loss: 4.04850738e-07
Iter: 183 loss: 4.04611654e-07
Iter: 184 loss: 4.03393983e-07
Iter: 185 loss: 4.04675802e-07
Iter: 186 loss: 4.02789169e-07
Iter: 187 loss: 4.01805153e-07
Iter: 188 loss: 4.11648273e-07
Iter: 189 loss: 4.01727675e-07
Iter: 190 loss: 4.01404577e-07
Iter: 191 loss: 4.01344863e-07
Iter: 192 loss: 4.00944089e-07
Iter: 193 loss: 4.00017939e-07
Iter: 194 loss: 4.09003405e-07
Iter: 195 loss: 3.99908402e-07
Iter: 196 loss: 3.99078289e-07
Iter: 197 loss: 3.99485572e-07
Iter: 198 loss: 3.98536656e-07
Iter: 199 loss: 3.97676899e-07
Iter: 200 loss: 3.97597262e-07
Iter: 201 loss: 3.96929579e-07
Iter: 202 loss: 3.97456063e-07
Iter: 203 loss: 3.96630867e-07
Iter: 204 loss: 3.95865982e-07
Iter: 205 loss: 3.96754047e-07
Iter: 206 loss: 3.95464099e-07
Iter: 207 loss: 3.948673e-07
Iter: 208 loss: 3.94878384e-07
Iter: 209 loss: 3.9448264e-07
Iter: 210 loss: 3.94064216e-07
Iter: 211 loss: 3.93975711e-07
Iter: 212 loss: 3.9321543e-07
Iter: 213 loss: 3.98273e-07
Iter: 214 loss: 3.9315438e-07
Iter: 215 loss: 3.92615448e-07
Iter: 216 loss: 3.92947868e-07
Iter: 217 loss: 3.92301359e-07
Iter: 218 loss: 3.91640015e-07
Iter: 219 loss: 3.90654066e-07
Iter: 220 loss: 3.90676036e-07
Iter: 221 loss: 3.89573273e-07
Iter: 222 loss: 4.04079515e-07
Iter: 223 loss: 3.89573103e-07
Iter: 224 loss: 3.89174801e-07
Iter: 225 loss: 3.89153115e-07
Iter: 226 loss: 3.88775902e-07
Iter: 227 loss: 3.87978e-07
Iter: 228 loss: 3.97259384e-07
Iter: 229 loss: 3.87836451e-07
Iter: 230 loss: 3.86989655e-07
Iter: 231 loss: 3.87311388e-07
Iter: 232 loss: 3.86430543e-07
Iter: 233 loss: 3.85552568e-07
Iter: 234 loss: 3.9191255e-07
Iter: 235 loss: 3.85474522e-07
Iter: 236 loss: 3.84711257e-07
Iter: 237 loss: 3.85179931e-07
Iter: 238 loss: 3.84131283e-07
Iter: 239 loss: 3.83744265e-07
Iter: 240 loss: 3.83650701e-07
Iter: 241 loss: 3.83099064e-07
Iter: 242 loss: 3.82820446e-07
Iter: 243 loss: 3.82617969e-07
Iter: 244 loss: 3.82064826e-07
Iter: 245 loss: 3.87927855e-07
Iter: 246 loss: 3.82103707e-07
Iter: 247 loss: 3.81615052e-07
Iter: 248 loss: 3.81807951e-07
Iter: 249 loss: 3.81300936e-07
Iter: 250 loss: 3.80857273e-07
Iter: 251 loss: 3.81542407e-07
Iter: 252 loss: 3.80568167e-07
Iter: 253 loss: 3.8014096e-07
Iter: 254 loss: 3.80658037e-07
Iter: 255 loss: 3.79884597e-07
Iter: 256 loss: 3.79709547e-07
Iter: 257 loss: 3.79598902e-07
Iter: 258 loss: 3.79315878e-07
Iter: 259 loss: 3.79274184e-07
Iter: 260 loss: 3.79068126e-07
Iter: 261 loss: 3.7873258e-07
Iter: 262 loss: 3.78378445e-07
Iter: 263 loss: 3.78324586e-07
Iter: 264 loss: 3.77715423e-07
Iter: 265 loss: 3.82844036e-07
Iter: 266 loss: 3.77753253e-07
Iter: 267 loss: 3.77372317e-07
Iter: 268 loss: 3.77080426e-07
Iter: 269 loss: 3.76945138e-07
Iter: 270 loss: 3.7630204e-07
Iter: 271 loss: 3.77312602e-07
Iter: 272 loss: 3.76031039e-07
Iter: 273 loss: 3.75422815e-07
Iter: 274 loss: 3.81972711e-07
Iter: 275 loss: 3.75418267e-07
Iter: 276 loss: 3.74801601e-07
Iter: 277 loss: 3.75043e-07
Iter: 278 loss: 3.74427202e-07
Iter: 279 loss: 3.73953469e-07
Iter: 280 loss: 3.77294697e-07
Iter: 281 loss: 3.7388358e-07
Iter: 282 loss: 3.73245086e-07
Iter: 283 loss: 3.73704097e-07
Iter: 284 loss: 3.72918237e-07
Iter: 285 loss: 3.72348779e-07
Iter: 286 loss: 3.7327186e-07
Iter: 287 loss: 3.72046827e-07
Iter: 288 loss: 3.71618341e-07
Iter: 289 loss: 3.71931208e-07
Iter: 290 loss: 3.71363456e-07
Iter: 291 loss: 3.70848795e-07
Iter: 292 loss: 3.73412377e-07
Iter: 293 loss: 3.7071419e-07
Iter: 294 loss: 3.70599025e-07
Iter: 295 loss: 3.70407093e-07
Iter: 296 loss: 3.70284511e-07
Iter: 297 loss: 3.69834765e-07
Iter: 298 loss: 3.76590776e-07
Iter: 299 loss: 3.6978588e-07
Iter: 300 loss: 3.69356798e-07
Iter: 301 loss: 3.70857833e-07
Iter: 302 loss: 3.6931857e-07
Iter: 303 loss: 3.68859958e-07
Iter: 304 loss: 3.69406223e-07
Iter: 305 loss: 3.68559569e-07
Iter: 306 loss: 3.68112239e-07
Iter: 307 loss: 3.68996552e-07
Iter: 308 loss: 3.67873525e-07
Iter: 309 loss: 3.67301197e-07
Iter: 310 loss: 3.67798748e-07
Iter: 311 loss: 3.6705984e-07
Iter: 312 loss: 3.66702267e-07
Iter: 313 loss: 3.66668559e-07
Iter: 314 loss: 3.66355522e-07
Iter: 315 loss: 3.66155945e-07
Iter: 316 loss: 3.6598459e-07
Iter: 317 loss: 3.65630626e-07
Iter: 318 loss: 3.68031806e-07
Iter: 319 loss: 3.65639636e-07
Iter: 320 loss: 3.65200265e-07
Iter: 321 loss: 3.65320943e-07
Iter: 322 loss: 3.64833681e-07
Iter: 323 loss: 3.64466644e-07
Iter: 324 loss: 3.64468804e-07
Iter: 325 loss: 3.64103016e-07
Iter: 326 loss: 3.63944025e-07
Iter: 327 loss: 3.63840684e-07
Iter: 328 loss: 3.63521622e-07
Iter: 329 loss: 3.63592505e-07
Iter: 330 loss: 3.63314541e-07
Iter: 331 loss: 3.6298843e-07
Iter: 332 loss: 3.62292326e-07
Iter: 333 loss: 3.6223156e-07
Iter: 334 loss: 3.61702348e-07
Iter: 335 loss: 3.67218263e-07
Iter: 336 loss: 3.61637149e-07
Iter: 337 loss: 3.60982256e-07
Iter: 338 loss: 3.61386896e-07
Iter: 339 loss: 3.6066649e-07
Iter: 340 loss: 3.6003911e-07
Iter: 341 loss: 3.60339868e-07
Iter: 342 loss: 3.59695775e-07
Iter: 343 loss: 3.59195838e-07
Iter: 344 loss: 3.591704e-07
Iter: 345 loss: 3.58778948e-07
Iter: 346 loss: 3.60778017e-07
Iter: 347 loss: 3.58710224e-07
Iter: 348 loss: 3.58416514e-07
Iter: 349 loss: 3.58033333e-07
Iter: 350 loss: 3.57977342e-07
Iter: 351 loss: 3.57602858e-07
Iter: 352 loss: 3.57589954e-07
Iter: 353 loss: 3.57296329e-07
Iter: 354 loss: 3.56897431e-07
Iter: 355 loss: 3.56850819e-07
Iter: 356 loss: 3.56380838e-07
Iter: 357 loss: 3.57661662e-07
Iter: 358 loss: 3.56182909e-07
Iter: 359 loss: 3.55986657e-07
Iter: 360 loss: 3.55873681e-07
Iter: 361 loss: 3.55560417e-07
Iter: 362 loss: 3.54928318e-07
Iter: 363 loss: 3.6825287e-07
Iter: 364 loss: 3.54928744e-07
Iter: 365 loss: 3.54437475e-07
Iter: 366 loss: 3.54085245e-07
Iter: 367 loss: 3.53884843e-07
Iter: 368 loss: 3.53011814e-07
Iter: 369 loss: 3.58791e-07
Iter: 370 loss: 3.52926634e-07
Iter: 371 loss: 3.52436189e-07
Iter: 372 loss: 3.53391812e-07
Iter: 373 loss: 3.52153876e-07
Iter: 374 loss: 3.51485085e-07
Iter: 375 loss: 3.55664724e-07
Iter: 376 loss: 3.51352696e-07
Iter: 377 loss: 3.51020759e-07
Iter: 378 loss: 3.51439098e-07
Iter: 379 loss: 3.50835592e-07
Iter: 380 loss: 3.5047384e-07
Iter: 381 loss: 3.50355862e-07
Iter: 382 loss: 3.50111549e-07
Iter: 383 loss: 3.49791037e-07
Iter: 384 loss: 3.49772051e-07
Iter: 385 loss: 3.49398931e-07
Iter: 386 loss: 3.49204157e-07
Iter: 387 loss: 3.49068614e-07
Iter: 388 loss: 3.48693504e-07
Iter: 389 loss: 3.50707381e-07
Iter: 390 loss: 3.48689724e-07
Iter: 391 loss: 3.48291877e-07
Iter: 392 loss: 3.48355229e-07
Iter: 393 loss: 3.4799973e-07
Iter: 394 loss: 3.47499906e-07
Iter: 395 loss: 3.480678e-07
Iter: 396 loss: 3.47281173e-07
Iter: 397 loss: 3.46946393e-07
Iter: 398 loss: 3.46931756e-07
Iter: 399 loss: 3.46611358e-07
Iter: 400 loss: 3.46153172e-07
Iter: 401 loss: 3.46167923e-07
Iter: 402 loss: 3.45868187e-07
Iter: 403 loss: 3.45953424e-07
Iter: 404 loss: 3.45571266e-07
Iter: 405 loss: 3.45044612e-07
Iter: 406 loss: 3.45230717e-07
Iter: 407 loss: 3.44696787e-07
Iter: 408 loss: 3.44294136e-07
Iter: 409 loss: 3.49811216e-07
Iter: 410 loss: 3.44257103e-07
Iter: 411 loss: 3.43863e-07
Iter: 412 loss: 3.45017838e-07
Iter: 413 loss: 3.43814833e-07
Iter: 414 loss: 3.43474312e-07
Iter: 415 loss: 3.44190482e-07
Iter: 416 loss: 3.4334056e-07
Iter: 417 loss: 3.42978069e-07
Iter: 418 loss: 3.42903434e-07
Iter: 419 loss: 3.4268669e-07
Iter: 420 loss: 3.42460567e-07
Iter: 421 loss: 3.42427711e-07
Iter: 422 loss: 3.42239815e-07
Iter: 423 loss: 3.41920327e-07
Iter: 424 loss: 3.41923283e-07
Iter: 425 loss: 3.41449095e-07
Iter: 426 loss: 3.43346073e-07
Iter: 427 loss: 3.41340495e-07
Iter: 428 loss: 3.41013333e-07
Iter: 429 loss: 3.42979149e-07
Iter: 430 loss: 3.40966409e-07
Iter: 431 loss: 3.40797158e-07
Iter: 432 loss: 3.43262627e-07
Iter: 433 loss: 3.40800796e-07
Iter: 434 loss: 3.40556227e-07
Iter: 435 loss: 3.40129105e-07
Iter: 436 loss: 3.46447678e-07
Iter: 437 loss: 3.40132488e-07
Iter: 438 loss: 3.39805354e-07
Iter: 439 loss: 3.40451038e-07
Iter: 440 loss: 3.39644515e-07
Iter: 441 loss: 3.39330683e-07
Iter: 442 loss: 3.39990976e-07
Iter: 443 loss: 3.39190933e-07
Iter: 444 loss: 3.38788055e-07
Iter: 445 loss: 3.41292662e-07
Iter: 446 loss: 3.3875159e-07
Iter: 447 loss: 3.38413884e-07
Iter: 448 loss: 3.399241e-07
Iter: 449 loss: 3.3839e-07
Iter: 450 loss: 3.3811898e-07
Iter: 451 loss: 3.38546414e-07
Iter: 452 loss: 3.38024051e-07
Iter: 453 loss: 3.37720564e-07
Iter: 454 loss: 3.38041872e-07
Iter: 455 loss: 3.37517122e-07
Iter: 456 loss: 3.37136157e-07
Iter: 457 loss: 3.40556e-07
Iter: 458 loss: 3.37160799e-07
Iter: 459 loss: 3.3694144e-07
Iter: 460 loss: 3.36654182e-07
Iter: 461 loss: 3.36614221e-07
Iter: 462 loss: 3.36166863e-07
Iter: 463 loss: 3.37960643e-07
Iter: 464 loss: 3.36130086e-07
Iter: 465 loss: 3.3566829e-07
Iter: 466 loss: 3.37872507e-07
Iter: 467 loss: 3.35606956e-07
Iter: 468 loss: 3.35339337e-07
Iter: 469 loss: 3.39332502e-07
Iter: 470 loss: 3.35353946e-07
Iter: 471 loss: 3.35256345e-07
Iter: 472 loss: 3.34796084e-07
Iter: 473 loss: 3.37996596e-07
Iter: 474 loss: 3.34788922e-07
Iter: 475 loss: 3.3435623e-07
Iter: 476 loss: 3.35498612e-07
Iter: 477 loss: 3.34272443e-07
Iter: 478 loss: 3.33863056e-07
Iter: 479 loss: 3.34540147e-07
Iter: 480 loss: 3.33774693e-07
Iter: 481 loss: 3.33389153e-07
Iter: 482 loss: 3.33966767e-07
Iter: 483 loss: 3.33232947e-07
Iter: 484 loss: 3.32793974e-07
Iter: 485 loss: 3.33690821e-07
Iter: 486 loss: 3.3264e-07
Iter: 487 loss: 3.32260072e-07
Iter: 488 loss: 3.34244191e-07
Iter: 489 loss: 3.32243417e-07
Iter: 490 loss: 3.31891869e-07
Iter: 491 loss: 3.34513601e-07
Iter: 492 loss: 3.31842898e-07
Iter: 493 loss: 3.31716308e-07
Iter: 494 loss: 3.31776477e-07
Iter: 495 loss: 3.31567605e-07
Iter: 496 loss: 3.3129561e-07
Iter: 497 loss: 3.33177667e-07
Iter: 498 loss: 3.31238056e-07
Iter: 499 loss: 3.31072954e-07
Iter: 500 loss: 3.31029725e-07
Iter: 501 loss: 3.30949831e-07
Iter: 502 loss: 3.30740448e-07
Iter: 503 loss: 3.30717825e-07
Iter: 504 loss: 3.3061778e-07
Iter: 505 loss: 3.30822672e-07
Iter: 506 loss: 3.3050344e-07
Iter: 507 loss: 3.30316396e-07
Iter: 508 loss: 3.30557356e-07
Iter: 509 loss: 3.3022431e-07
Iter: 510 loss: 3.3004244e-07
Iter: 511 loss: 3.29875775e-07
Iter: 512 loss: 3.29864122e-07
Iter: 513 loss: 3.29500324e-07
Iter: 514 loss: 3.30632389e-07
Iter: 515 loss: 3.29389593e-07
Iter: 516 loss: 3.28998283e-07
Iter: 517 loss: 3.28672087e-07
Iter: 518 loss: 3.28578039e-07
Iter: 519 loss: 3.27899784e-07
Iter: 520 loss: 3.33592055e-07
Iter: 521 loss: 3.2791462e-07
Iter: 522 loss: 3.27517625e-07
Iter: 523 loss: 3.29012153e-07
Iter: 524 loss: 3.27444411e-07
Iter: 525 loss: 3.27075895e-07
Iter: 526 loss: 3.30355817e-07
Iter: 527 loss: 3.27001658e-07
Iter: 528 loss: 3.26727672e-07
Iter: 529 loss: 3.26621318e-07
Iter: 530 loss: 3.26522922e-07
Iter: 531 loss: 3.26132e-07
Iter: 532 loss: 3.31820701e-07
Iter: 533 loss: 3.26154947e-07
Iter: 534 loss: 3.25964066e-07
Iter: 535 loss: 3.25679082e-07
Iter: 536 loss: 3.32735169e-07
Iter: 537 loss: 3.25671749e-07
Iter: 538 loss: 3.25399611e-07
Iter: 539 loss: 3.25407314e-07
Iter: 540 loss: 3.25162574e-07
Iter: 541 loss: 3.25428402e-07
Iter: 542 loss: 3.25071312e-07
Iter: 543 loss: 3.24870854e-07
Iter: 544 loss: 3.24948871e-07
Iter: 545 loss: 3.24623386e-07
Iter: 546 loss: 3.24367477e-07
Iter: 547 loss: 3.2507e-07
Iter: 548 loss: 3.24218405e-07
Iter: 549 loss: 3.2397358e-07
Iter: 550 loss: 3.24948843e-07
Iter: 551 loss: 3.23819961e-07
Iter: 552 loss: 3.23614e-07
Iter: 553 loss: 3.23639e-07
Iter: 554 loss: 3.23403583e-07
Iter: 555 loss: 3.23065706e-07
Iter: 556 loss: 3.24085136e-07
Iter: 557 loss: 3.229909e-07
Iter: 558 loss: 3.22709582e-07
Iter: 559 loss: 3.24189585e-07
Iter: 560 loss: 3.22617979e-07
Iter: 561 loss: 3.22428349e-07
Iter: 562 loss: 3.25682436e-07
Iter: 563 loss: 3.22415019e-07
Iter: 564 loss: 3.22236588e-07
Iter: 565 loss: 3.22105336e-07
Iter: 566 loss: 3.22086578e-07
Iter: 567 loss: 3.21832772e-07
Iter: 568 loss: 3.24052621e-07
Iter: 569 loss: 3.21814923e-07
Iter: 570 loss: 3.21634786e-07
Iter: 571 loss: 3.21488898e-07
Iter: 572 loss: 3.21409317e-07
Iter: 573 loss: 3.21344459e-07
Iter: 574 loss: 3.21280055e-07
Iter: 575 loss: 3.21224377e-07
Iter: 576 loss: 3.20880929e-07
Iter: 577 loss: 3.26736853e-07
Iter: 578 loss: 3.20869844e-07
Iter: 579 loss: 3.20591539e-07
Iter: 580 loss: 3.21846244e-07
Iter: 581 loss: 3.20591596e-07
Iter: 582 loss: 3.20303172e-07
Iter: 583 loss: 3.20323466e-07
Iter: 584 loss: 3.20135655e-07
Iter: 585 loss: 3.19785727e-07
Iter: 586 loss: 3.19755571e-07
Iter: 587 loss: 3.19502192e-07
Iter: 588 loss: 3.19117902e-07
Iter: 589 loss: 3.21569587e-07
Iter: 590 loss: 3.18986281e-07
Iter: 591 loss: 3.18694845e-07
Iter: 592 loss: 3.18504476e-07
Iter: 593 loss: 3.18428874e-07
Iter: 594 loss: 3.179793e-07
Iter: 595 loss: 3.24381205e-07
Iter: 596 loss: 3.17966339e-07
Iter: 597 loss: 3.17675131e-07
Iter: 598 loss: 3.17944284e-07
Iter: 599 loss: 3.17492578e-07
Iter: 600 loss: 3.17345553e-07
Iter: 601 loss: 3.17333559e-07
Iter: 602 loss: 3.17137e-07
Iter: 603 loss: 3.16949e-07
Iter: 604 loss: 3.16945858e-07
Iter: 605 loss: 3.16758815e-07
Iter: 606 loss: 3.16780671e-07
Iter: 607 loss: 3.16629382e-07
Iter: 608 loss: 3.16728801e-07
Iter: 609 loss: 3.1651291e-07
Iter: 610 loss: 3.16347e-07
Iter: 611 loss: 3.16767569e-07
Iter: 612 loss: 3.16279483e-07
Iter: 613 loss: 3.16013654e-07
Iter: 614 loss: 3.16006748e-07
Iter: 615 loss: 3.15834541e-07
Iter: 616 loss: 3.15604723e-07
Iter: 617 loss: 3.17232434e-07
Iter: 618 loss: 3.15570389e-07
Iter: 619 loss: 3.15368652e-07
Iter: 620 loss: 3.15830761e-07
Iter: 621 loss: 3.15319312e-07
Iter: 622 loss: 3.15059594e-07
Iter: 623 loss: 3.14999596e-07
Iter: 624 loss: 3.14863911e-07
Iter: 625 loss: 3.14597344e-07
Iter: 626 loss: 3.15269062e-07
Iter: 627 loss: 3.14519298e-07
Iter: 628 loss: 3.14227634e-07
Iter: 629 loss: 3.14942469e-07
Iter: 630 loss: 3.14050226e-07
Iter: 631 loss: 3.13751428e-07
Iter: 632 loss: 3.15085913e-07
Iter: 633 loss: 3.13700355e-07
Iter: 634 loss: 3.13376773e-07
Iter: 635 loss: 3.16298724e-07
Iter: 636 loss: 3.13386209e-07
Iter: 637 loss: 3.13211729e-07
Iter: 638 loss: 3.132063e-07
Iter: 639 loss: 3.13066494e-07
Iter: 640 loss: 3.1290142e-07
Iter: 641 loss: 3.12852535e-07
Iter: 642 loss: 3.12700081e-07
Iter: 643 loss: 3.12380621e-07
Iter: 644 loss: 3.1241882e-07
Iter: 645 loss: 3.12124968e-07
Iter: 646 loss: 3.137242e-07
Iter: 647 loss: 3.12040612e-07
Iter: 648 loss: 3.1181898e-07
Iter: 649 loss: 3.12202133e-07
Iter: 650 loss: 3.11659733e-07
Iter: 651 loss: 3.11436594e-07
Iter: 652 loss: 3.11518448e-07
Iter: 653 loss: 3.1126126e-07
Iter: 654 loss: 3.11016038e-07
Iter: 655 loss: 3.14284478e-07
Iter: 656 loss: 3.11000917e-07
Iter: 657 loss: 3.10764335e-07
Iter: 658 loss: 3.10758452e-07
Iter: 659 loss: 3.10669918e-07
Iter: 660 loss: 3.1043632e-07
Iter: 661 loss: 3.10593634e-07
Iter: 662 loss: 3.10305239e-07
Iter: 663 loss: 3.09931522e-07
Iter: 664 loss: 3.10986621e-07
Iter: 665 loss: 3.0985035e-07
Iter: 666 loss: 3.09674789e-07
Iter: 667 loss: 3.12690702e-07
Iter: 668 loss: 3.09667143e-07
Iter: 669 loss: 3.09509147e-07
Iter: 670 loss: 3.09300077e-07
Iter: 671 loss: 3.09205859e-07
Iter: 672 loss: 3.09083788e-07
Iter: 673 loss: 3.09089302e-07
Iter: 674 loss: 3.08935853e-07
Iter: 675 loss: 3.08934375e-07
Iter: 676 loss: 3.08764129e-07
Iter: 677 loss: 3.08637823e-07
Iter: 678 loss: 3.08370659e-07
Iter: 679 loss: 3.08342237e-07
Iter: 680 loss: 3.08036562e-07
Iter: 681 loss: 3.09755478e-07
Iter: 682 loss: 3.07989581e-07
Iter: 683 loss: 3.07672963e-07
Iter: 684 loss: 3.08591154e-07
Iter: 685 loss: 3.07576897e-07
Iter: 686 loss: 3.07384369e-07
Iter: 687 loss: 3.08004701e-07
Iter: 688 loss: 3.07290577e-07
Iter: 689 loss: 3.07019207e-07
Iter: 690 loss: 3.08042331e-07
Iter: 691 loss: 3.06943434e-07
Iter: 692 loss: 3.06755339e-07
Iter: 693 loss: 3.06531717e-07
Iter: 694 loss: 3.0645333e-07
Iter: 695 loss: 3.06050822e-07
Iter: 696 loss: 3.0721219e-07
Iter: 697 loss: 3.05882025e-07
Iter: 698 loss: 3.05518256e-07
Iter: 699 loss: 3.06070291e-07
Iter: 700 loss: 3.05250865e-07
Iter: 701 loss: 3.04864159e-07
Iter: 702 loss: 3.04835453e-07
Iter: 703 loss: 3.04693373e-07
Iter: 704 loss: 3.04569369e-07
Iter: 705 loss: 3.04501469e-07
Iter: 706 loss: 3.04230952e-07
Iter: 707 loss: 3.07847387e-07
Iter: 708 loss: 3.04189399e-07
Iter: 709 loss: 3.04084153e-07
Iter: 710 loss: 3.03853227e-07
Iter: 711 loss: 3.03880256e-07
Iter: 712 loss: 3.03632333e-07
Iter: 713 loss: 3.04525201e-07
Iter: 714 loss: 3.03605844e-07
Iter: 715 loss: 3.03326e-07
Iter: 716 loss: 3.03569976e-07
Iter: 717 loss: 3.03189097e-07
Iter: 718 loss: 3.0304227e-07
Iter: 719 loss: 3.03754234e-07
Iter: 720 loss: 3.02915083e-07
Iter: 721 loss: 3.02779029e-07
Iter: 722 loss: 3.04221658e-07
Iter: 723 loss: 3.02794064e-07
Iter: 724 loss: 3.02570072e-07
Iter: 725 loss: 3.02540599e-07
Iter: 726 loss: 3.02445329e-07
Iter: 727 loss: 3.02218098e-07
Iter: 728 loss: 3.0267114e-07
Iter: 729 loss: 3.02145963e-07
Iter: 730 loss: 3.01907392e-07
Iter: 731 loss: 3.02373365e-07
Iter: 732 loss: 3.01821672e-07
Iter: 733 loss: 3.01595861e-07
Iter: 734 loss: 3.02096851e-07
Iter: 735 loss: 3.01522221e-07
Iter: 736 loss: 3.01363229e-07
Iter: 737 loss: 3.0434478e-07
Iter: 738 loss: 3.01345267e-07
Iter: 739 loss: 3.01183945e-07
Iter: 740 loss: 3.01533817e-07
Iter: 741 loss: 3.01133724e-07
Iter: 742 loss: 3.00925478e-07
Iter: 743 loss: 3.00597208e-07
Iter: 744 loss: 3.00633019e-07
Iter: 745 loss: 3.00349797e-07
Iter: 746 loss: 3.01271797e-07
Iter: 747 loss: 3.00306709e-07
Iter: 748 loss: 3.00018399e-07
Iter: 749 loss: 3.00830266e-07
Iter: 750 loss: 3.00038892e-07
Iter: 751 loss: 2.99759904e-07
Iter: 752 loss: 2.99701583e-07
Iter: 753 loss: 2.99546201e-07
Iter: 754 loss: 2.99204089e-07
Iter: 755 loss: 2.99945867e-07
Iter: 756 loss: 2.9906991e-07
Iter: 757 loss: 2.98791917e-07
Iter: 758 loss: 3.02301487e-07
Iter: 759 loss: 2.98786773e-07
Iter: 760 loss: 2.98591715e-07
Iter: 761 loss: 2.9851509e-07
Iter: 762 loss: 2.98352376e-07
Iter: 763 loss: 2.97993552e-07
Iter: 764 loss: 2.98052072e-07
Iter: 765 loss: 2.97761119e-07
Iter: 766 loss: 2.97507711e-07
Iter: 767 loss: 2.97515214e-07
Iter: 768 loss: 2.97377397e-07
Iter: 769 loss: 2.983775e-07
Iter: 770 loss: 2.97429892e-07
Iter: 771 loss: 2.9724265e-07
Iter: 772 loss: 2.97159318e-07
Iter: 773 loss: 2.97027043e-07
Iter: 774 loss: 2.9695812e-07
Iter: 775 loss: 2.96958916e-07
Iter: 776 loss: 2.96818683e-07
Iter: 777 loss: 2.96598927e-07
Iter: 778 loss: 3.0085053e-07
Iter: 779 loss: 2.96610153e-07
Iter: 780 loss: 2.96358394e-07
Iter: 781 loss: 2.97719509e-07
Iter: 782 loss: 2.96350748e-07
Iter: 783 loss: 2.96170413e-07
Iter: 784 loss: 2.96427942e-07
Iter: 785 loss: 2.96136193e-07
Iter: 786 loss: 2.95941589e-07
Iter: 787 loss: 2.9597453e-07
Iter: 788 loss: 2.95802636e-07
Iter: 789 loss: 2.95511086e-07
Iter: 790 loss: 2.95949064e-07
Iter: 791 loss: 2.95363634e-07
Iter: 792 loss: 2.95083026e-07
Iter: 793 loss: 2.96957978e-07
Iter: 794 loss: 2.9506117e-07
Iter: 795 loss: 2.94792528e-07
Iter: 796 loss: 2.95391e-07
Iter: 797 loss: 2.94639932e-07
Iter: 798 loss: 2.94449734e-07
Iter: 799 loss: 2.94312031e-07
Iter: 800 loss: 2.94144513e-07
Iter: 801 loss: 2.93859756e-07
Iter: 802 loss: 2.95882899e-07
Iter: 803 loss: 2.93806e-07
Iter: 804 loss: 2.93609276e-07
Iter: 805 loss: 2.96334321e-07
Iter: 806 loss: 2.93602653e-07
Iter: 807 loss: 2.934527e-07
Iter: 808 loss: 2.93554194e-07
Iter: 809 loss: 2.93284046e-07
Iter: 810 loss: 2.93095411e-07
Iter: 811 loss: 2.96009404e-07
Iter: 812 loss: 2.93106211e-07
Iter: 813 loss: 2.92969787e-07
Iter: 814 loss: 2.92716749e-07
Iter: 815 loss: 2.95086096e-07
Iter: 816 loss: 2.92647513e-07
Iter: 817 loss: 2.92319157e-07
Iter: 818 loss: 2.95262964e-07
Iter: 819 loss: 2.92385806e-07
Iter: 820 loss: 2.92172984e-07
Iter: 821 loss: 2.92878184e-07
Iter: 822 loss: 2.92137315e-07
Iter: 823 loss: 2.9188638e-07
Iter: 824 loss: 2.91649968e-07
Iter: 825 loss: 2.91592414e-07
Iter: 826 loss: 2.91394741e-07
Iter: 827 loss: 2.92713679e-07
Iter: 828 loss: 2.91351967e-07
Iter: 829 loss: 2.91111888e-07
Iter: 830 loss: 2.91718408e-07
Iter: 831 loss: 2.90967023e-07
Iter: 832 loss: 2.90785522e-07
Iter: 833 loss: 2.92621593e-07
Iter: 834 loss: 2.90721118e-07
Iter: 835 loss: 2.90636677e-07
Iter: 836 loss: 2.90414334e-07
Iter: 837 loss: 2.90466e-07
Iter: 838 loss: 2.90239171e-07
Iter: 839 loss: 2.92921015e-07
Iter: 840 loss: 2.90205605e-07
Iter: 841 loss: 2.90074183e-07
Iter: 842 loss: 2.91746119e-07
Iter: 843 loss: 2.90066282e-07
Iter: 844 loss: 2.90022314e-07
Iter: 845 loss: 2.90004664e-07
Iter: 846 loss: 2.89966039e-07
Iter: 847 loss: 2.8979e-07
Iter: 848 loss: 2.90102065e-07
Iter: 849 loss: 2.89680827e-07
Iter: 850 loss: 2.89498672e-07
Iter: 851 loss: 2.89307025e-07
Iter: 852 loss: 2.89299891e-07
Iter: 853 loss: 2.88995068e-07
Iter: 854 loss: 2.90445911e-07
Iter: 855 loss: 2.88916397e-07
Iter: 856 loss: 2.8871284e-07
Iter: 857 loss: 2.90941699e-07
Iter: 858 loss: 2.88710169e-07
Iter: 859 loss: 2.88456391e-07
Iter: 860 loss: 2.88172913e-07
Iter: 861 loss: 2.88104246e-07
Iter: 862 loss: 2.87862775e-07
Iter: 863 loss: 2.89316773e-07
Iter: 864 loss: 2.87851719e-07
Iter: 865 loss: 2.87588051e-07
Iter: 866 loss: 2.88238965e-07
Iter: 867 loss: 2.87430368e-07
Iter: 868 loss: 2.87235196e-07
Iter: 869 loss: 2.87232126e-07
Iter: 870 loss: 2.87115085e-07
Iter: 871 loss: 2.87043832e-07
Iter: 872 loss: 2.8698895e-07
Iter: 873 loss: 2.86807534e-07
Iter: 874 loss: 2.87145298e-07
Iter: 875 loss: 2.86723804e-07
Iter: 876 loss: 2.86506832e-07
Iter: 877 loss: 2.86476023e-07
Iter: 878 loss: 2.8639343e-07
Iter: 879 loss: 2.86435125e-07
Iter: 880 loss: 2.86297023e-07
Iter: 881 loss: 2.86169666e-07
Iter: 882 loss: 2.86702601e-07
Iter: 883 loss: 2.86136469e-07
Iter: 884 loss: 2.85997316e-07
Iter: 885 loss: 2.85830936e-07
Iter: 886 loss: 2.89942875e-07
Iter: 887 loss: 2.85770426e-07
Iter: 888 loss: 2.85523157e-07
Iter: 889 loss: 2.86973602e-07
Iter: 890 loss: 2.85466143e-07
Iter: 891 loss: 2.85279413e-07
Iter: 892 loss: 2.87633725e-07
Iter: 893 loss: 2.8528757e-07
Iter: 894 loss: 2.85136963e-07
Iter: 895 loss: 2.84899613e-07
Iter: 896 loss: 2.84923033e-07
Iter: 897 loss: 2.846173e-07
Iter: 898 loss: 2.85848273e-07
Iter: 899 loss: 2.84610707e-07
Iter: 900 loss: 2.84400926e-07
Iter: 901 loss: 2.85280578e-07
Iter: 902 loss: 2.84356702e-07
Iter: 903 loss: 2.8421195e-07
Iter: 904 loss: 2.85066136e-07
Iter: 905 loss: 2.84125349e-07
Iter: 906 loss: 2.83957661e-07
Iter: 907 loss: 2.83856707e-07
Iter: 908 loss: 2.83722727e-07
Iter: 909 loss: 2.83469717e-07
Iter: 910 loss: 2.85917224e-07
Iter: 911 loss: 2.83490266e-07
Iter: 912 loss: 2.83342189e-07
Iter: 913 loss: 2.84711263e-07
Iter: 914 loss: 2.83298334e-07
Iter: 915 loss: 2.83151707e-07
Iter: 916 loss: 2.83278354e-07
Iter: 917 loss: 2.8305206e-07
Iter: 918 loss: 2.82816984e-07
Iter: 919 loss: 2.83046035e-07
Iter: 920 loss: 2.82701933e-07
Iter: 921 loss: 2.82517e-07
Iter: 922 loss: 2.8252245e-07
Iter: 923 loss: 2.82316392e-07
Iter: 924 loss: 2.82119288e-07
Iter: 925 loss: 2.8230059e-07
Iter: 926 loss: 2.81965157e-07
Iter: 927 loss: 2.81733719e-07
Iter: 928 loss: 2.81755547e-07
Iter: 929 loss: 2.81599711e-07
Iter: 930 loss: 2.8134022e-07
Iter: 931 loss: 2.81320496e-07
Iter: 932 loss: 2.811135e-07
Iter: 933 loss: 2.82147113e-07
Iter: 934 loss: 2.81052792e-07
Iter: 935 loss: 2.80827095e-07
Iter: 936 loss: 2.81799743e-07
Iter: 937 loss: 2.80757035e-07
Iter: 938 loss: 2.80551745e-07
Iter: 939 loss: 2.81941965e-07
Iter: 940 loss: 2.80607821e-07
Iter: 941 loss: 2.80473557e-07
Iter: 942 loss: 2.80344125e-07
Iter: 943 loss: 2.80269148e-07
Iter: 944 loss: 2.80165608e-07
Iter: 945 loss: 2.80142103e-07
Iter: 946 loss: 2.80023926e-07
Iter: 947 loss: 2.80045555e-07
Iter: 948 loss: 2.79884574e-07
Iter: 949 loss: 2.79853e-07
Iter: 950 loss: 2.81014536e-07
Iter: 951 loss: 2.79797518e-07
Iter: 952 loss: 2.79625e-07
Iter: 953 loss: 2.79451228e-07
Iter: 954 loss: 2.83870918e-07
Iter: 955 loss: 2.79501478e-07
Iter: 956 loss: 2.79231955e-07
Iter: 957 loss: 2.79939343e-07
Iter: 958 loss: 2.79218796e-07
Iter: 959 loss: 2.79044798e-07
Iter: 960 loss: 2.79176589e-07
Iter: 961 loss: 2.78880407e-07
Iter: 962 loss: 2.78722553e-07
Iter: 963 loss: 2.81558812e-07
Iter: 964 loss: 2.78737303e-07
Iter: 965 loss: 2.78557621e-07
Iter: 966 loss: 2.7867415e-07
Iter: 967 loss: 2.78465e-07
Iter: 968 loss: 2.783095e-07
Iter: 969 loss: 2.78492365e-07
Iter: 970 loss: 2.7826411e-07
Iter: 971 loss: 2.78054756e-07
Iter: 972 loss: 2.78359209e-07
Iter: 973 loss: 2.77965455e-07
Iter: 974 loss: 2.77761785e-07
Iter: 975 loss: 2.79000204e-07
Iter: 976 loss: 2.77647132e-07
Iter: 977 loss: 2.77550811e-07
Iter: 978 loss: 2.77639572e-07
Iter: 979 loss: 2.77400318e-07
Iter: 980 loss: 2.77320737e-07
Iter: 981 loss: 2.77308658e-07
Iter: 982 loss: 2.77204578e-07
Iter: 983 loss: 2.77068409e-07
Iter: 984 loss: 2.77074889e-07
Iter: 985 loss: 2.76923373e-07
Iter: 986 loss: 2.77583524e-07
Iter: 987 loss: 2.76792775e-07
Iter: 988 loss: 2.76648137e-07
Iter: 989 loss: 2.76668516e-07
Iter: 990 loss: 2.76489402e-07
Iter: 991 loss: 2.76295964e-07
Iter: 992 loss: 2.76483917e-07
Iter: 993 loss: 2.76190121e-07
Iter: 994 loss: 2.75977612e-07
Iter: 995 loss: 2.77308857e-07
Iter: 996 loss: 2.76009587e-07
Iter: 997 loss: 2.7585898e-07
Iter: 998 loss: 2.77492688e-07
Iter: 999 loss: 2.75858525e-07
Iter: 1000 loss: 2.75757714e-07
Iter: 1001 loss: 2.75469887e-07
Iter: 1002 loss: 2.75531448e-07
Iter: 1003 loss: 2.75279064e-07
Iter: 1004 loss: 2.76340643e-07
Iter: 1005 loss: 2.75229183e-07
Iter: 1006 loss: 2.75085767e-07
Iter: 1007 loss: 2.75224892e-07
Iter: 1008 loss: 2.74945648e-07
Iter: 1009 loss: 2.74749397e-07
Iter: 1010 loss: 2.74805416e-07
Iter: 1011 loss: 2.74653473e-07
Iter: 1012 loss: 2.74607913e-07
Iter: 1013 loss: 2.74506931e-07
Iter: 1014 loss: 2.74470267e-07
Iter: 1015 loss: 2.74400861e-07
Iter: 1016 loss: 2.74309e-07
Iter: 1017 loss: 2.74419676e-07
Iter: 1018 loss: 2.7428456e-07
Iter: 1019 loss: 2.74173829e-07
Iter: 1020 loss: 2.74106327e-07
Iter: 1021 loss: 2.74024501e-07
Iter: 1022 loss: 2.73959586e-07
Iter: 1023 loss: 2.73951372e-07
Iter: 1024 loss: 2.73878385e-07
Iter: 1025 loss: 2.73753074e-07
Iter: 1026 loss: 2.73725789e-07
Iter: 1027 loss: 2.73597664e-07
Iter: 1028 loss: 2.73642456e-07
Iter: 1029 loss: 2.73476019e-07
Iter: 1030 loss: 2.73276129e-07
Iter: 1031 loss: 2.74133669e-07
Iter: 1032 loss: 2.73284257e-07
Iter: 1033 loss: 2.7305731e-07
Iter: 1034 loss: 2.74944568e-07
Iter: 1035 loss: 2.7305984e-07
Iter: 1036 loss: 2.72985659e-07
Iter: 1037 loss: 2.72906391e-07
Iter: 1038 loss: 2.72835535e-07
Iter: 1039 loss: 2.72671e-07
Iter: 1040 loss: 2.72902525e-07
Iter: 1041 loss: 2.72563113e-07
Iter: 1042 loss: 2.72373939e-07
Iter: 1043 loss: 2.72880186e-07
Iter: 1044 loss: 2.72363593e-07
Iter: 1045 loss: 2.7221472e-07
Iter: 1046 loss: 2.7297196e-07
Iter: 1047 loss: 2.72197951e-07
Iter: 1048 loss: 2.7194892e-07
Iter: 1049 loss: 2.73314868e-07
Iter: 1050 loss: 2.71977854e-07
Iter: 1051 loss: 2.71872125e-07
Iter: 1052 loss: 2.72597788e-07
Iter: 1053 loss: 2.71864224e-07
Iter: 1054 loss: 2.71782312e-07
Iter: 1055 loss: 2.71792175e-07
Iter: 1056 loss: 2.71689913e-07
Iter: 1057 loss: 2.71622042e-07
Iter: 1058 loss: 2.71472345e-07
Iter: 1059 loss: 2.71473453e-07
Iter: 1060 loss: 2.71352633e-07
Iter: 1061 loss: 2.71299399e-07
Iter: 1062 loss: 2.71132308e-07
Iter: 1063 loss: 2.71394981e-07
Iter: 1064 loss: 2.71099196e-07
Iter: 1065 loss: 2.71046105e-07
Iter: 1066 loss: 2.70899335e-07
Iter: 1067 loss: 2.70887142e-07
Iter: 1068 loss: 2.70747762e-07
Iter: 1069 loss: 2.71297637e-07
Iter: 1070 loss: 2.70646154e-07
Iter: 1071 loss: 2.7051891e-07
Iter: 1072 loss: 2.72029553e-07
Iter: 1073 loss: 2.70496599e-07
Iter: 1074 loss: 2.70402637e-07
Iter: 1075 loss: 2.70730425e-07
Iter: 1076 loss: 2.70390984e-07
Iter: 1077 loss: 2.70293583e-07
Iter: 1078 loss: 2.70065811e-07
Iter: 1079 loss: 2.70097445e-07
Iter: 1080 loss: 2.69923532e-07
Iter: 1081 loss: 2.71432498e-07
Iter: 1082 loss: 2.69890933e-07
Iter: 1083 loss: 2.697887e-07
Iter: 1084 loss: 2.71228203e-07
Iter: 1085 loss: 2.69791968e-07
Iter: 1086 loss: 2.69686979e-07
Iter: 1087 loss: 2.70047508e-07
Iter: 1088 loss: 2.69669698e-07
Iter: 1089 loss: 2.69547741e-07
Iter: 1090 loss: 2.69619136e-07
Iter: 1091 loss: 2.69481774e-07
Iter: 1092 loss: 2.69392814e-07
Iter: 1093 loss: 2.69251103e-07
Iter: 1094 loss: 2.69246641e-07
Iter: 1095 loss: 2.69038054e-07
Iter: 1096 loss: 2.70173189e-07
Iter: 1097 loss: 2.6906568e-07
Iter: 1098 loss: 2.68931188e-07
Iter: 1099 loss: 2.70159234e-07
Iter: 1100 loss: 2.68897224e-07
Iter: 1101 loss: 2.68779928e-07
Iter: 1102 loss: 2.68658624e-07
Iter: 1103 loss: 2.7243567e-07
Iter: 1104 loss: 2.68644101e-07
Iter: 1105 loss: 2.6850168e-07
Iter: 1106 loss: 2.69272789e-07
Iter: 1107 loss: 2.68492272e-07
Iter: 1108 loss: 2.68297867e-07
Iter: 1109 loss: 2.69356207e-07
Iter: 1110 loss: 2.68266888e-07
Iter: 1111 loss: 2.68086069e-07
Iter: 1112 loss: 2.68533597e-07
Iter: 1113 loss: 2.68086723e-07
Iter: 1114 loss: 2.67978692e-07
Iter: 1115 loss: 2.67905079e-07
Iter: 1116 loss: 2.67815636e-07
Iter: 1117 loss: 2.67685266e-07
Iter: 1118 loss: 2.69231919e-07
Iter: 1119 loss: 2.67691945e-07
Iter: 1120 loss: 2.67631975e-07
Iter: 1121 loss: 2.68139843e-07
Iter: 1122 loss: 2.67613359e-07
Iter: 1123 loss: 2.67509961e-07
Iter: 1124 loss: 2.67856137e-07
Iter: 1125 loss: 2.67423303e-07
Iter: 1126 loss: 2.67366488e-07
Iter: 1127 loss: 2.67391044e-07
Iter: 1128 loss: 2.67367795e-07
Iter: 1129 loss: 2.67274231e-07
Iter: 1130 loss: 2.67056e-07
Iter: 1131 loss: 2.67047852e-07
Iter: 1132 loss: 2.66924076e-07
Iter: 1133 loss: 2.68423349e-07
Iter: 1134 loss: 2.66941271e-07
Iter: 1135 loss: 2.66722111e-07
Iter: 1136 loss: 2.67484126e-07
Iter: 1137 loss: 2.66681326e-07
Iter: 1138 loss: 2.66576194e-07
Iter: 1139 loss: 2.66432266e-07
Iter: 1140 loss: 2.66441759e-07
Iter: 1141 loss: 2.66251732e-07
Iter: 1142 loss: 2.67297423e-07
Iter: 1143 loss: 2.66221974e-07
Iter: 1144 loss: 2.66048744e-07
Iter: 1145 loss: 2.66816386e-07
Iter: 1146 loss: 2.66048829e-07
Iter: 1147 loss: 2.65884495e-07
Iter: 1148 loss: 2.66296979e-07
Iter: 1149 loss: 2.65854482e-07
Iter: 1150 loss: 2.65732098e-07
Iter: 1151 loss: 2.65764044e-07
Iter: 1152 loss: 2.65632679e-07
Iter: 1153 loss: 2.65495601e-07
Iter: 1154 loss: 2.67260646e-07
Iter: 1155 loss: 2.65454446e-07
Iter: 1156 loss: 2.65430032e-07
Iter: 1157 loss: 2.65816851e-07
Iter: 1158 loss: 2.65448676e-07
Iter: 1159 loss: 2.65354345e-07
Iter: 1160 loss: 2.65543349e-07
Iter: 1161 loss: 2.65341782e-07
Iter: 1162 loss: 2.65264077e-07
Iter: 1163 loss: 2.65189271e-07
Iter: 1164 loss: 2.65195069e-07
Iter: 1165 loss: 2.65048328e-07
Iter: 1166 loss: 2.64881066e-07
Iter: 1167 loss: 2.64886523e-07
Iter: 1168 loss: 2.64806886e-07
Iter: 1169 loss: 2.64779857e-07
Iter: 1170 loss: 2.64707666e-07
Iter: 1171 loss: 2.65028262e-07
Iter: 1172 loss: 2.64617029e-07
Iter: 1173 loss: 2.64581558e-07
Iter: 1174 loss: 2.64455537e-07
Iter: 1175 loss: 2.64442889e-07
Iter: 1176 loss: 2.6423541e-07
Iter: 1177 loss: 2.64772893e-07
Iter: 1178 loss: 2.64211678e-07
Iter: 1179 loss: 2.64021821e-07
Iter: 1180 loss: 2.65842544e-07
Iter: 1181 loss: 2.64035975e-07
Iter: 1182 loss: 2.64007326e-07
Iter: 1183 loss: 2.6408955e-07
Iter: 1184 loss: 2.63965774e-07
Iter: 1185 loss: 2.63811444e-07
Iter: 1186 loss: 2.64003461e-07
Iter: 1187 loss: 2.63785637e-07
Iter: 1188 loss: 2.63748916e-07
Iter: 1189 loss: 2.64776276e-07
Iter: 1190 loss: 2.637222e-07
Iter: 1191 loss: 2.63647792e-07
Iter: 1192 loss: 2.6369861e-07
Iter: 1193 loss: 2.63600555e-07
Iter: 1194 loss: 2.6351259e-07
Iter: 1195 loss: 2.63722825e-07
Iter: 1196 loss: 2.6344614e-07
Iter: 1197 loss: 2.63384209e-07
Iter: 1198 loss: 2.63263274e-07
Iter: 1199 loss: 2.63282601e-07
Iter: 1200 loss: 2.63076572e-07
Iter: 1201 loss: 2.63135661e-07
Iter: 1202 loss: 2.62964761e-07
Iter: 1203 loss: 2.62834533e-07
Iter: 1204 loss: 2.64281937e-07
Iter: 1205 loss: 2.62821374e-07
Iter: 1206 loss: 2.62783828e-07
Iter: 1207 loss: 2.62761205e-07
Iter: 1208 loss: 2.62695664e-07
Iter: 1209 loss: 2.62589282e-07
Iter: 1210 loss: 2.62556028e-07
Iter: 1211 loss: 2.62502112e-07
Iter: 1212 loss: 2.62607728e-07
Iter: 1213 loss: 2.62403717e-07
Iter: 1214 loss: 2.62338318e-07
Iter: 1215 loss: 2.62355286e-07
Iter: 1216 loss: 2.62279428e-07
Iter: 1217 loss: 2.62215906e-07
Iter: 1218 loss: 2.62168157e-07
Iter: 1219 loss: 2.62107051e-07
Iter: 1220 loss: 2.62090396e-07
Iter: 1221 loss: 2.62045518e-07
Iter: 1222 loss: 2.62057767e-07
Iter: 1223 loss: 2.62010929e-07
Iter: 1224 loss: 2.61911566e-07
Iter: 1225 loss: 2.6201127e-07
Iter: 1226 loss: 2.61854439e-07
Iter: 1227 loss: 2.61731373e-07
Iter: 1228 loss: 2.61862937e-07
Iter: 1229 loss: 2.61693714e-07
Iter: 1230 loss: 2.616313e-07
Iter: 1231 loss: 2.61600832e-07
Iter: 1232 loss: 2.61466568e-07
Iter: 1233 loss: 2.61407934e-07
Iter: 1234 loss: 2.61380535e-07
Iter: 1235 loss: 2.61343075e-07
Iter: 1236 loss: 2.61190905e-07
Iter: 1237 loss: 2.61301125e-07
Iter: 1238 loss: 2.61092595e-07
Iter: 1239 loss: 2.61001531e-07
Iter: 1240 loss: 2.61006107e-07
Iter: 1241 loss: 2.60920018e-07
Iter: 1242 loss: 2.60941249e-07
Iter: 1243 loss: 2.6086596e-07
Iter: 1244 loss: 2.6062e-07
Iter: 1245 loss: 2.60734879e-07
Iter: 1246 loss: 2.60587058e-07
Iter: 1247 loss: 2.60409735e-07
Iter: 1248 loss: 2.60731099e-07
Iter: 1249 loss: 2.60328477e-07
Iter: 1250 loss: 2.60169401e-07
Iter: 1251 loss: 2.62059388e-07
Iter: 1252 loss: 2.60260464e-07
Iter: 1253 loss: 2.6011358e-07
Iter: 1254 loss: 2.60211806e-07
Iter: 1255 loss: 2.60029168e-07
Iter: 1256 loss: 2.59954277e-07
Iter: 1257 loss: 2.61306241e-07
Iter: 1258 loss: 2.59913833e-07
Iter: 1259 loss: 2.5986165e-07
Iter: 1260 loss: 2.59738215e-07
Iter: 1261 loss: 2.59701665e-07
Iter: 1262 loss: 2.59613046e-07
Iter: 1263 loss: 2.60280899e-07
Iter: 1264 loss: 2.59615916e-07
Iter: 1265 loss: 2.59470738e-07
Iter: 1266 loss: 2.59502428e-07
Iter: 1267 loss: 2.59403663e-07
Iter: 1268 loss: 2.59339799e-07
Iter: 1269 loss: 2.59645134e-07
Iter: 1270 loss: 2.59276e-07
Iter: 1271 loss: 2.59206161e-07
Iter: 1272 loss: 2.60122533e-07
Iter: 1273 loss: 2.59189648e-07
Iter: 1274 loss: 2.59118906e-07
Iter: 1275 loss: 2.5919897e-07
Iter: 1276 loss: 2.59102819e-07
Iter: 1277 loss: 2.58978389e-07
Iter: 1278 loss: 2.58984613e-07
Iter: 1279 loss: 2.58923848e-07
Iter: 1280 loss: 2.58797456e-07
Iter: 1281 loss: 2.59145054e-07
Iter: 1282 loss: 2.5876011e-07
Iter: 1283 loss: 2.58697781e-07
Iter: 1284 loss: 2.58739931e-07
Iter: 1285 loss: 2.5862866e-07
Iter: 1286 loss: 2.58533134e-07
Iter: 1287 loss: 2.58518412e-07
Iter: 1288 loss: 2.58501586e-07
Iter: 1289 loss: 2.58475495e-07
Iter: 1290 loss: 2.58461654e-07
Iter: 1291 loss: 2.58346859e-07
Iter: 1292 loss: 2.59126978e-07
Iter: 1293 loss: 2.58341146e-07
Iter: 1294 loss: 2.58279954e-07
Iter: 1295 loss: 2.58224816e-07
Iter: 1296 loss: 2.5823087e-07
Iter: 1297 loss: 2.58184684e-07
Iter: 1298 loss: 2.58641762e-07
Iter: 1299 loss: 2.58118291e-07
Iter: 1300 loss: 2.58056701e-07
Iter: 1301 loss: 2.57925507e-07
Iter: 1302 loss: 2.57955946e-07
Iter: 1303 loss: 2.57794454e-07
Iter: 1304 loss: 2.57955833e-07
Iter: 1305 loss: 2.57769472e-07
Iter: 1306 loss: 2.57679631e-07
Iter: 1307 loss: 2.57662862e-07
Iter: 1308 loss: 2.57592546e-07
Iter: 1309 loss: 2.57598742e-07
Iter: 1310 loss: 2.57554063e-07
Iter: 1311 loss: 2.57419742e-07
Iter: 1312 loss: 2.57404395e-07
Iter: 1313 loss: 2.57338797e-07
Iter: 1314 loss: 2.572379e-07
Iter: 1315 loss: 2.57861188e-07
Iter: 1316 loss: 2.57155193e-07
Iter: 1317 loss: 2.57089084e-07
Iter: 1318 loss: 2.57266e-07
Iter: 1319 loss: 2.57053046e-07
Iter: 1320 loss: 2.56970111e-07
Iter: 1321 loss: 2.56959709e-07
Iter: 1322 loss: 2.56863814e-07
Iter: 1323 loss: 2.5713527e-07
Iter: 1324 loss: 2.56839172e-07
Iter: 1325 loss: 2.5679276e-07
Iter: 1326 loss: 2.56882402e-07
Iter: 1327 loss: 2.56754532e-07
Iter: 1328 loss: 2.56633882e-07
Iter: 1329 loss: 2.5662618e-07
Iter: 1330 loss: 2.56631722e-07
Iter: 1331 loss: 2.56501835e-07
Iter: 1332 loss: 2.56949193e-07
Iter: 1333 loss: 2.56554671e-07
Iter: 1334 loss: 2.5638326e-07
Iter: 1335 loss: 2.56499277e-07
Iter: 1336 loss: 2.56351e-07
Iter: 1337 loss: 2.56211479e-07
Iter: 1338 loss: 2.56146961e-07
Iter: 1339 loss: 2.56093898e-07
Iter: 1340 loss: 2.5596708e-07
Iter: 1341 loss: 2.56896584e-07
Iter: 1342 loss: 2.56000845e-07
Iter: 1343 loss: 2.55896964e-07
Iter: 1344 loss: 2.56582354e-07
Iter: 1345 loss: 2.55885851e-07
Iter: 1346 loss: 2.55758209e-07
Iter: 1347 loss: 2.55863483e-07
Iter: 1348 loss: 2.55736836e-07
Iter: 1349 loss: 2.55573468e-07
Iter: 1350 loss: 2.55536463e-07
Iter: 1351 loss: 2.55525379e-07
Iter: 1352 loss: 2.55336204e-07
Iter: 1353 loss: 2.55564771e-07
Iter: 1354 loss: 2.55321652e-07
Iter: 1355 loss: 2.55244856e-07
Iter: 1356 loss: 2.55487407e-07
Iter: 1357 loss: 2.5520518e-07
Iter: 1358 loss: 2.55070859e-07
Iter: 1359 loss: 2.56567262e-07
Iter: 1360 loss: 2.5506543e-07
Iter: 1361 loss: 2.55005858e-07
Iter: 1362 loss: 2.55095699e-07
Iter: 1363 loss: 2.54969166e-07
Iter: 1364 loss: 2.54905814e-07
Iter: 1365 loss: 2.55112866e-07
Iter: 1366 loss: 2.54862755e-07
Iter: 1367 loss: 2.54817053e-07
Iter: 1368 loss: 2.54676479e-07
Iter: 1369 loss: 2.54674575e-07
Iter: 1370 loss: 2.54603975e-07
Iter: 1371 loss: 2.55328615e-07
Iter: 1372 loss: 2.54584421e-07
Iter: 1373 loss: 2.54442455e-07
Iter: 1374 loss: 2.54976186e-07
Iter: 1375 loss: 2.54457035e-07
Iter: 1376 loss: 2.54380808e-07
Iter: 1377 loss: 2.54433303e-07
Iter: 1378 loss: 2.5434025e-07
Iter: 1379 loss: 2.54253308e-07
Iter: 1380 loss: 2.54305689e-07
Iter: 1381 loss: 2.54173585e-07
Iter: 1382 loss: 2.54046057e-07
Iter: 1383 loss: 2.5539353e-07
Iter: 1384 loss: 2.54087297e-07
Iter: 1385 loss: 2.54024144e-07
Iter: 1386 loss: 2.53831843e-07
Iter: 1387 loss: 2.53830052e-07
Iter: 1388 loss: 2.53696925e-07
Iter: 1389 loss: 2.54007489e-07
Iter: 1390 loss: 2.53609329e-07
Iter: 1391 loss: 2.53429448e-07
Iter: 1392 loss: 2.54444188e-07
Iter: 1393 loss: 2.53426862e-07
Iter: 1394 loss: 2.53291603e-07
Iter: 1395 loss: 2.54591328e-07
Iter: 1396 loss: 2.53341312e-07
Iter: 1397 loss: 2.53278785e-07
Iter: 1398 loss: 2.53234305e-07
Iter: 1399 loss: 2.53135227e-07
Iter: 1400 loss: 2.53026201e-07
Iter: 1401 loss: 2.53585597e-07
Iter: 1402 loss: 2.53058573e-07
Iter: 1403 loss: 2.52951651e-07
Iter: 1404 loss: 2.52783479e-07
Iter: 1405 loss: 2.52772537e-07
Iter: 1406 loss: 2.52651319e-07
Iter: 1407 loss: 2.53020175e-07
Iter: 1408 loss: 2.52574353e-07
Iter: 1409 loss: 2.52444494e-07
Iter: 1410 loss: 2.53161602e-07
Iter: 1411 loss: 2.52346e-07
Iter: 1412 loss: 2.52261231e-07
Iter: 1413 loss: 2.53178456e-07
Iter: 1414 loss: 2.52290647e-07
Iter: 1415 loss: 2.52106162e-07
Iter: 1416 loss: 2.52044799e-07
Iter: 1417 loss: 2.52058e-07
Iter: 1418 loss: 2.5188578e-07
Iter: 1419 loss: 2.52778648e-07
Iter: 1420 loss: 2.51933386e-07
Iter: 1421 loss: 2.51832546e-07
Iter: 1422 loss: 2.51894278e-07
Iter: 1423 loss: 2.51781728e-07
Iter: 1424 loss: 2.51626631e-07
Iter: 1425 loss: 2.52017912e-07
Iter: 1426 loss: 2.51588773e-07
Iter: 1427 loss: 2.51470283e-07
Iter: 1428 loss: 2.51872706e-07
Iter: 1429 loss: 2.51506066e-07
Iter: 1430 loss: 2.51431e-07
Iter: 1431 loss: 2.51744524e-07
Iter: 1432 loss: 2.5138155e-07
Iter: 1433 loss: 2.51319278e-07
Iter: 1434 loss: 2.51252231e-07
Iter: 1435 loss: 2.51237537e-07
Iter: 1436 loss: 2.51136044e-07
Iter: 1437 loss: 2.51414917e-07
Iter: 1438 loss: 2.51071583e-07
Iter: 1439 loss: 2.50914923e-07
Iter: 1440 loss: 2.51188482e-07
Iter: 1441 loss: 2.50876184e-07
Iter: 1442 loss: 2.50766305e-07
Iter: 1443 loss: 2.5054868e-07
Iter: 1444 loss: 2.50560532e-07
Iter: 1445 loss: 2.50301355e-07
Iter: 1446 loss: 2.52140836e-07
Iter: 1447 loss: 2.50346716e-07
Iter: 1448 loss: 2.50191363e-07
Iter: 1449 loss: 2.50175134e-07
Iter: 1450 loss: 2.5004627e-07
Iter: 1451 loss: 2.50073953e-07
Iter: 1452 loss: 2.50037289e-07
Iter: 1453 loss: 2.4988131e-07
Iter: 1454 loss: 2.50705085e-07
Iter: 1455 loss: 2.49863405e-07
Iter: 1456 loss: 2.49751622e-07
Iter: 1457 loss: 2.49805055e-07
Iter: 1458 loss: 2.49639612e-07
Iter: 1459 loss: 2.49575e-07
Iter: 1460 loss: 2.4980946e-07
Iter: 1461 loss: 2.49548748e-07
Iter: 1462 loss: 2.49404764e-07
Iter: 1463 loss: 2.50818402e-07
Iter: 1464 loss: 2.49427643e-07
Iter: 1465 loss: 2.49348915e-07
Iter: 1466 loss: 2.49278287e-07
Iter: 1467 loss: 2.49226758e-07
Iter: 1468 loss: 2.49165083e-07
Iter: 1469 loss: 2.4934775e-07
Iter: 1470 loss: 2.49057052e-07
Iter: 1471 loss: 2.48967325e-07
Iter: 1472 loss: 2.49497276e-07
Iter: 1473 loss: 2.48940864e-07
Iter: 1474 loss: 2.48875722e-07
Iter: 1475 loss: 2.48986964e-07
Iter: 1476 loss: 2.4878e-07
Iter: 1477 loss: 2.4871332e-07
Iter: 1478 loss: 2.48657869e-07
Iter: 1479 loss: 2.48626463e-07
Iter: 1480 loss: 2.48485122e-07
Iter: 1481 loss: 2.48931514e-07
Iter: 1482 loss: 2.48433366e-07
Iter: 1483 loss: 2.48331503e-07
Iter: 1484 loss: 2.48359981e-07
Iter: 1485 loss: 2.48274659e-07
Iter: 1486 loss: 2.48308481e-07
Iter: 1487 loss: 2.48233391e-07
Iter: 1488 loss: 2.48168391e-07
Iter: 1489 loss: 2.4860006e-07
Iter: 1490 loss: 2.48174899e-07
Iter: 1491 loss: 2.48107767e-07
Iter: 1492 loss: 2.48096882e-07
Iter: 1493 loss: 2.48025856e-07
Iter: 1494 loss: 2.47994308e-07
Iter: 1495 loss: 2.48656789e-07
Iter: 1496 loss: 2.48029352e-07
Iter: 1497 loss: 2.4798544e-07
Iter: 1498 loss: 2.47990556e-07
Iter: 1499 loss: 2.47983e-07
Iter: 1500 loss: 2.48009343e-07
Iter: 1501 loss: 2.4801102e-07
Iter: 1502 loss: 2.48005506e-07
Iter: 1503 loss: 2.48014942e-07
Iter: 1504 loss: 2.48030034e-07
Iter: 1505 loss: 2.48011418e-07
Iter: 1506 loss: 2.48024776e-07
Iter: 1507 loss: 2.48026339e-07
Iter: 1508 loss: 2.48026652e-07
Iter: 1509 loss: 2.4802128e-07
Iter: 1510 loss: 2.480229e-07
Iter: 1511 loss: 2.47962419e-07
Iter: 1512 loss: 2.47896793e-07
Iter: 1513 loss: 2.47909327e-07
Iter: 1514 loss: 2.47796407e-07
Iter: 1515 loss: 2.47988766e-07
Iter: 1516 loss: 2.47730554e-07
Iter: 1517 loss: 2.47646881e-07
Iter: 1518 loss: 2.47695027e-07
Iter: 1519 loss: 2.47574263e-07
Iter: 1520 loss: 2.47425845e-07
Iter: 1521 loss: 2.47806099e-07
Iter: 1522 loss: 2.47346037e-07
Iter: 1523 loss: 2.47287687e-07
Iter: 1524 loss: 2.47466915e-07
Iter: 1525 loss: 2.4725415e-07
Iter: 1526 loss: 2.47155896e-07
Iter: 1527 loss: 2.47100559e-07
Iter: 1528 loss: 2.4704832e-07
Iter: 1529 loss: 2.46961179e-07
Iter: 1530 loss: 2.48517551e-07
Iter: 1531 loss: 2.46951231e-07
Iter: 1532 loss: 2.468974e-07
Iter: 1533 loss: 2.47229707e-07
Iter: 1534 loss: 2.46873356e-07
Iter: 1535 loss: 2.46782832e-07
Iter: 1536 loss: 2.46810231e-07
Iter: 1537 loss: 2.4673767e-07
Iter: 1538 loss: 2.4667267e-07
Iter: 1539 loss: 2.47277029e-07
Iter: 1540 loss: 2.46634272e-07
Iter: 1541 loss: 2.46550286e-07
Iter: 1542 loss: 2.466046e-07
Iter: 1543 loss: 2.4648935e-07
Iter: 1544 loss: 2.4649836e-07
Iter: 1545 loss: 2.46495119e-07
Iter: 1546 loss: 2.4647963e-07
Iter: 1547 loss: 2.46435064e-07
Iter: 1548 loss: 2.46321093e-07
Iter: 1549 loss: 2.47156777e-07
Iter: 1550 loss: 2.46295144e-07
Iter: 1551 loss: 2.46188705e-07
Iter: 1552 loss: 2.46909536e-07
Iter: 1553 loss: 2.46191121e-07
Iter: 1554 loss: 2.46054753e-07
Iter: 1555 loss: 2.46252853e-07
Iter: 1556 loss: 2.46052622e-07
Iter: 1557 loss: 2.45927936e-07
Iter: 1558 loss: 2.46005214e-07
Iter: 1559 loss: 2.4584304e-07
Iter: 1560 loss: 2.45809673e-07
Iter: 1561 loss: 2.46036052e-07
Iter: 1562 loss: 2.4570636e-07
Iter: 1563 loss: 2.45628172e-07
Iter: 1564 loss: 2.4568422e-07
Iter: 1565 loss: 2.45528526e-07
Iter: 1566 loss: 2.45520596e-07
Iter: 1567 loss: 2.45475974e-07
Iter: 1568 loss: 2.45369506e-07
Iter: 1569 loss: 2.45500132e-07
Iter: 1570 loss: 2.45337617e-07
Iter: 1571 loss: 2.45300583e-07
Iter: 1572 loss: 2.45388833e-07
Iter: 1573 loss: 2.45265738e-07
Iter: 1574 loss: 2.45132014e-07
Iter: 1575 loss: 2.45517327e-07
Iter: 1576 loss: 2.45132924e-07
Iter: 1577 loss: 2.45046238e-07
Iter: 1578 loss: 2.45811407e-07
Iter: 1579 loss: 2.4505303e-07
Iter: 1580 loss: 2.44999086e-07
Iter: 1581 loss: 2.45029327e-07
Iter: 1582 loss: 2.4489421e-07
Iter: 1583 loss: 2.44871359e-07
Iter: 1584 loss: 2.44818835e-07
Iter: 1585 loss: 2.4480039e-07
Iter: 1586 loss: 2.4464785e-07
Iter: 1587 loss: 2.45360127e-07
Iter: 1588 loss: 2.44692046e-07
Iter: 1589 loss: 2.44520777e-07
Iter: 1590 loss: 2.44695201e-07
Iter: 1591 loss: 2.4453135e-07
Iter: 1592 loss: 2.44410415e-07
Iter: 1593 loss: 2.44479139e-07
Iter: 1594 loss: 2.44357324e-07
Iter: 1595 loss: 2.44204188e-07
Iter: 1596 loss: 2.45032368e-07
Iter: 1597 loss: 2.44250941e-07
Iter: 1598 loss: 2.44166586e-07
Iter: 1599 loss: 2.4413248e-07
Iter: 1600 loss: 2.44137766e-07
Iter: 1601 loss: 2.43985056e-07
Iter: 1602 loss: 2.44621617e-07
Iter: 1603 loss: 2.44002422e-07
Iter: 1604 loss: 2.43913604e-07
Iter: 1605 loss: 2.44381567e-07
Iter: 1606 loss: 2.43882596e-07
Iter: 1607 loss: 2.43822086e-07
Iter: 1608 loss: 2.43838457e-07
Iter: 1609 loss: 2.43830868e-07
Iter: 1610 loss: 2.43669945e-07
Iter: 1611 loss: 2.43828879e-07
Iter: 1612 loss: 2.43625493e-07
Iter: 1613 loss: 2.43489751e-07
Iter: 1614 loss: 2.43654227e-07
Iter: 1615 loss: 2.43435e-07
Iter: 1616 loss: 2.43374188e-07
Iter: 1617 loss: 2.43322717e-07
Iter: 1618 loss: 2.43362535e-07
Iter: 1619 loss: 2.43370238e-07
Iter: 1620 loss: 2.43358528e-07
Iter: 1621 loss: 2.43353668e-07
Iter: 1622 loss: 2.43328969e-07
Iter: 1623 loss: 2.43341617e-07
Iter: 1624 loss: 2.43364468e-07
Iter: 1625 loss: 2.43346705e-07
Iter: 1626 loss: 2.43328486e-07
Iter: 1627 loss: 2.43336785e-07
Iter: 1628 loss: 2.4333707e-07
Iter: 1629 loss: 2.43330845e-07
Iter: 1630 loss: 2.43318198e-07
Iter: 1631 loss: 2.43318198e-07
Iter: 1632 loss: 2.43324962e-07
Iter: 1633 loss: 2.43322603e-07
Iter: 1634 loss: 2.43324706e-07
Iter: 1635 loss: 2.43323683e-07
Iter: 1636 loss: 2.43325104e-07
Iter: 1637 loss: 2.43323313e-07
Iter: 1638 loss: 2.43322376e-07
Iter: 1639 loss: 2.43322404e-07
Iter: 1640 loss: 2.43322972e-07
Iter: 1641 loss: 2.43323115e-07
Iter: 1642 loss: 2.43323171e-07
Iter: 1643 loss: 2.43322972e-07
Iter: 1644 loss: 2.43322972e-07
Iter: 1645 loss: 2.43322972e-07
Iter: 1646 loss: 2.43323171e-07
Iter: 1647 loss: 2.43322972e-07
Iter: 1648 loss: 2.43323171e-07
Iter: 1649 loss: 2.43323171e-07
Iter: 1650 loss: 2.43322972e-07
Iter: 1651 loss: 2.43323171e-07
Iter: 1652 loss: 2.43323171e-07
Iter: 1653 loss: 2.43322972e-07
Iter: 1654 loss: 2.43323171e-07
Iter: 1655 loss: 2.44690312e-07
Iter: 1656 loss: 2.43368561e-07
Iter: 1657 loss: 2.43358187e-07
Iter: 1658 loss: 2.43339144e-07
Iter: 1659 loss: 2.4337541e-07
Iter: 1660 loss: 2.43366429e-07
Iter: 1661 loss: 2.43341077e-07
Iter: 1662 loss: 2.43354691e-07
Iter: 1663 loss: 2.43369129e-07
Iter: 1664 loss: 2.43338604e-07
Iter: 1665 loss: 2.43351963e-07
Iter: 1666 loss: 2.4333022e-07
Iter: 1667 loss: 2.43341503e-07
Iter: 1668 loss: 2.43331897e-07
Iter: 1669 loss: 2.43332295e-07
Iter: 1670 loss: 2.4332212e-07
Iter: 1671 loss: 2.43320869e-07
Iter: 1672 loss: 2.43333147e-07
Iter: 1673 loss: 2.43327861e-07
Iter: 1674 loss: 2.43325e-07
Iter: 1675 loss: 2.43322461e-07
Iter: 1676 loss: 2.43321807e-07
Iter: 1677 loss: 2.43322802e-07
Iter: 1678 loss: 2.43324735e-07
Iter: 1679 loss: 2.43322717e-07
Iter: 1680 loss: 2.43324735e-07
Iter: 1681 loss: 2.43324109e-07
Iter: 1682 loss: 2.43322717e-07
Iter: 1683 loss: 2.43324109e-07
Iter: 1684 loss: 2.43322717e-07
Iter: 1685 loss: 2.43322717e-07
Iter: 1686 loss: 2.43324109e-07
Iter: 1687 loss: 2.43324109e-07
Iter: 1688 loss: 2.43322717e-07
Iter: 1689 loss: 2.43324109e-07
Iter: 1690 loss: 2.43324109e-07
Iter: 1691 loss: 2.43322717e-07
Iter: 1692 loss: 2.43324109e-07
Iter: 1693 loss: 2.43322717e-07
Iter: 1694 loss: 2.43322717e-07
Iter: 1695 loss: 2.43324109e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_4000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.6/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.6 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_4000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10346e2c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10346bc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c5f3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1034748f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1034748a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1034748400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c5c4d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c50f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c52c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c4de158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c4de9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c497ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c4bfd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c46f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c482f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c4827b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c439b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c38ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c3c9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c38f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c385730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c30e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c385c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c2ddc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c2dd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c2c4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c253d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c2c42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c212158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c2450d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c240400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c1f0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c1f0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c1e4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c15b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f100c181c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.74212436e-06
Iter: 2 loss: 7.16402e-06
Iter: 3 loss: 1.90136461e-06
Iter: 4 loss: 1.58082526e-06
Iter: 5 loss: 2.14663396e-06
Iter: 6 loss: 1.439887e-06
Iter: 7 loss: 1.237378e-06
Iter: 8 loss: 1.36689187e-06
Iter: 9 loss: 1.10857695e-06
Iter: 10 loss: 9.70309657e-07
Iter: 11 loss: 1.65450797e-06
Iter: 12 loss: 9.46783871e-07
Iter: 13 loss: 8.54674511e-07
Iter: 14 loss: 1.87458681e-06
Iter: 15 loss: 8.52836422e-07
Iter: 16 loss: 8.02525278e-07
Iter: 17 loss: 7.92550907e-07
Iter: 18 loss: 7.59184445e-07
Iter: 19 loss: 7.39003269e-07
Iter: 20 loss: 8.03471494e-07
Iter: 21 loss: 7.33287834e-07
Iter: 22 loss: 7.20569e-07
Iter: 23 loss: 7.20004323e-07
Iter: 24 loss: 7.14099e-07
Iter: 25 loss: 7.10152335e-07
Iter: 26 loss: 7.08004e-07
Iter: 27 loss: 6.99877262e-07
Iter: 28 loss: 7.20083563e-07
Iter: 29 loss: 6.97010137e-07
Iter: 30 loss: 6.89877709e-07
Iter: 31 loss: 6.99609927e-07
Iter: 32 loss: 6.86362796e-07
Iter: 33 loss: 6.79765549e-07
Iter: 34 loss: 7.04032573e-07
Iter: 35 loss: 6.78178594e-07
Iter: 36 loss: 6.75048454e-07
Iter: 37 loss: 6.74074386e-07
Iter: 38 loss: 6.71306339e-07
Iter: 39 loss: 6.69465749e-07
Iter: 40 loss: 6.68456664e-07
Iter: 41 loss: 6.65313905e-07
Iter: 42 loss: 6.77120511e-07
Iter: 43 loss: 6.64508491e-07
Iter: 44 loss: 6.60632509e-07
Iter: 45 loss: 6.569839e-07
Iter: 46 loss: 6.56088218e-07
Iter: 47 loss: 6.5471329e-07
Iter: 48 loss: 6.53771508e-07
Iter: 49 loss: 6.52007e-07
Iter: 50 loss: 6.47621107e-07
Iter: 51 loss: 6.89420176e-07
Iter: 52 loss: 6.47078e-07
Iter: 53 loss: 6.41911527e-07
Iter: 54 loss: 6.62102877e-07
Iter: 55 loss: 6.40812345e-07
Iter: 56 loss: 6.35889364e-07
Iter: 57 loss: 6.47276579e-07
Iter: 58 loss: 6.34053322e-07
Iter: 59 loss: 6.3038874e-07
Iter: 60 loss: 6.30361058e-07
Iter: 61 loss: 6.28058899e-07
Iter: 62 loss: 6.21928336e-07
Iter: 63 loss: 6.67710196e-07
Iter: 64 loss: 6.2068267e-07
Iter: 65 loss: 6.14861108e-07
Iter: 66 loss: 6.85911232e-07
Iter: 67 loss: 6.14892315e-07
Iter: 68 loss: 6.10967163e-07
Iter: 69 loss: 6.42855525e-07
Iter: 70 loss: 6.10697498e-07
Iter: 71 loss: 6.0784771e-07
Iter: 72 loss: 6.50878292e-07
Iter: 73 loss: 6.07858397e-07
Iter: 74 loss: 6.06993183e-07
Iter: 75 loss: 6.05446814e-07
Iter: 76 loss: 6.40448093e-07
Iter: 77 loss: 6.05417e-07
Iter: 78 loss: 6.03002604e-07
Iter: 79 loss: 6.12347492e-07
Iter: 80 loss: 6.02437581e-07
Iter: 81 loss: 6.01275474e-07
Iter: 82 loss: 6.06350341e-07
Iter: 83 loss: 6.00976e-07
Iter: 84 loss: 5.99738769e-07
Iter: 85 loss: 6.04684885e-07
Iter: 86 loss: 5.99473935e-07
Iter: 87 loss: 5.98515953e-07
Iter: 88 loss: 5.97895905e-07
Iter: 89 loss: 5.97577923e-07
Iter: 90 loss: 5.9593475e-07
Iter: 91 loss: 5.94114226e-07
Iter: 92 loss: 5.93865707e-07
Iter: 93 loss: 5.93100708e-07
Iter: 94 loss: 5.92558138e-07
Iter: 95 loss: 5.91345156e-07
Iter: 96 loss: 5.89639285e-07
Iter: 97 loss: 5.89579713e-07
Iter: 98 loss: 5.87626573e-07
Iter: 99 loss: 5.9854483e-07
Iter: 100 loss: 5.87358841e-07
Iter: 101 loss: 5.85902512e-07
Iter: 102 loss: 5.84253655e-07
Iter: 103 loss: 5.83999167e-07
Iter: 104 loss: 5.86649378e-07
Iter: 105 loss: 5.83295e-07
Iter: 106 loss: 5.82804716e-07
Iter: 107 loss: 5.81750612e-07
Iter: 108 loss: 5.965843e-07
Iter: 109 loss: 5.81639654e-07
Iter: 110 loss: 5.80506139e-07
Iter: 111 loss: 5.85897169e-07
Iter: 112 loss: 5.80230449e-07
Iter: 113 loss: 5.79178334e-07
Iter: 114 loss: 5.84117402e-07
Iter: 115 loss: 5.79015364e-07
Iter: 116 loss: 5.78163565e-07
Iter: 117 loss: 5.80437586e-07
Iter: 118 loss: 5.77927381e-07
Iter: 119 loss: 5.7696252e-07
Iter: 120 loss: 5.76717355e-07
Iter: 121 loss: 5.76087075e-07
Iter: 122 loss: 5.74975104e-07
Iter: 123 loss: 5.7398978e-07
Iter: 124 loss: 5.73633884e-07
Iter: 125 loss: 5.72346153e-07
Iter: 126 loss: 5.72320403e-07
Iter: 127 loss: 5.71545456e-07
Iter: 128 loss: 5.76621972e-07
Iter: 129 loss: 5.71460419e-07
Iter: 130 loss: 5.70636644e-07
Iter: 131 loss: 5.69573444e-07
Iter: 132 loss: 5.6956975e-07
Iter: 133 loss: 5.68613189e-07
Iter: 134 loss: 5.72870704e-07
Iter: 135 loss: 5.68479209e-07
Iter: 136 loss: 5.67819029e-07
Iter: 137 loss: 5.75240676e-07
Iter: 138 loss: 5.67829659e-07
Iter: 139 loss: 5.67331085e-07
Iter: 140 loss: 5.72125373e-07
Iter: 141 loss: 5.67299e-07
Iter: 142 loss: 5.6703891e-07
Iter: 143 loss: 5.66373899e-07
Iter: 144 loss: 5.73953741e-07
Iter: 145 loss: 5.66343545e-07
Iter: 146 loss: 5.65828145e-07
Iter: 147 loss: 5.65859182e-07
Iter: 148 loss: 5.65334119e-07
Iter: 149 loss: 5.65079631e-07
Iter: 150 loss: 5.64893071e-07
Iter: 151 loss: 5.64260461e-07
Iter: 152 loss: 5.72231215e-07
Iter: 153 loss: 5.64281947e-07
Iter: 154 loss: 5.63891263e-07
Iter: 155 loss: 5.63187939e-07
Iter: 156 loss: 5.75814397e-07
Iter: 157 loss: 5.63174922e-07
Iter: 158 loss: 5.62157538e-07
Iter: 159 loss: 5.63764e-07
Iter: 160 loss: 5.61710465e-07
Iter: 161 loss: 5.60884473e-07
Iter: 162 loss: 5.65982532e-07
Iter: 163 loss: 5.60818592e-07
Iter: 164 loss: 5.6015574e-07
Iter: 165 loss: 5.66470533e-07
Iter: 166 loss: 5.60111403e-07
Iter: 167 loss: 5.59699515e-07
Iter: 168 loss: 5.59044679e-07
Iter: 169 loss: 5.59022737e-07
Iter: 170 loss: 5.58336069e-07
Iter: 171 loss: 5.65289042e-07
Iter: 172 loss: 5.58310489e-07
Iter: 173 loss: 5.57972896e-07
Iter: 174 loss: 5.57966928e-07
Iter: 175 loss: 5.57715452e-07
Iter: 176 loss: 5.57045e-07
Iter: 177 loss: 5.64685308e-07
Iter: 178 loss: 5.57003887e-07
Iter: 179 loss: 5.56378609e-07
Iter: 180 loss: 5.60393687e-07
Iter: 181 loss: 5.5629215e-07
Iter: 182 loss: 5.559192e-07
Iter: 183 loss: 5.59023249e-07
Iter: 184 loss: 5.55839733e-07
Iter: 185 loss: 5.55402e-07
Iter: 186 loss: 5.54930409e-07
Iter: 187 loss: 5.54860833e-07
Iter: 188 loss: 5.54144606e-07
Iter: 189 loss: 5.61920501e-07
Iter: 190 loss: 5.54112887e-07
Iter: 191 loss: 5.53797804e-07
Iter: 192 loss: 5.53007567e-07
Iter: 193 loss: 5.64597315e-07
Iter: 194 loss: 5.53003e-07
Iter: 195 loss: 5.52162078e-07
Iter: 196 loss: 5.58508361e-07
Iter: 197 loss: 5.52091478e-07
Iter: 198 loss: 5.51581763e-07
Iter: 199 loss: 5.53043037e-07
Iter: 200 loss: 5.51403559e-07
Iter: 201 loss: 5.50758784e-07
Iter: 202 loss: 5.54699341e-07
Iter: 203 loss: 5.50658854e-07
Iter: 204 loss: 5.50357186e-07
Iter: 205 loss: 5.49787046e-07
Iter: 206 loss: 5.49830702e-07
Iter: 207 loss: 5.49902211e-07
Iter: 208 loss: 5.49591618e-07
Iter: 209 loss: 5.49393633e-07
Iter: 210 loss: 5.49171773e-07
Iter: 211 loss: 5.49133802e-07
Iter: 212 loss: 5.4859305e-07
Iter: 213 loss: 5.4866797e-07
Iter: 214 loss: 5.48169055e-07
Iter: 215 loss: 5.47875402e-07
Iter: 216 loss: 5.51363e-07
Iter: 217 loss: 5.47855848e-07
Iter: 218 loss: 5.47530249e-07
Iter: 219 loss: 5.48305934e-07
Iter: 220 loss: 5.47467437e-07
Iter: 221 loss: 5.47116656e-07
Iter: 222 loss: 5.47694242e-07
Iter: 223 loss: 5.47013826e-07
Iter: 224 loss: 5.46627348e-07
Iter: 225 loss: 5.4835516e-07
Iter: 226 loss: 5.4655834e-07
Iter: 227 loss: 5.46307035e-07
Iter: 228 loss: 5.46087e-07
Iter: 229 loss: 5.46003037e-07
Iter: 230 loss: 5.45548176e-07
Iter: 231 loss: 5.45663966e-07
Iter: 232 loss: 5.45233092e-07
Iter: 233 loss: 5.44908573e-07
Iter: 234 loss: 5.44893737e-07
Iter: 235 loss: 5.44641125e-07
Iter: 236 loss: 5.45836201e-07
Iter: 237 loss: 5.44573879e-07
Iter: 238 loss: 5.44256181e-07
Iter: 239 loss: 5.44379077e-07
Iter: 240 loss: 5.44070474e-07
Iter: 241 loss: 5.43758233e-07
Iter: 242 loss: 5.43471856e-07
Iter: 243 loss: 5.43453211e-07
Iter: 244 loss: 5.43707756e-07
Iter: 245 loss: 5.43223166e-07
Iter: 246 loss: 5.43086855e-07
Iter: 247 loss: 5.42770522e-07
Iter: 248 loss: 5.4553459e-07
Iter: 249 loss: 5.42653765e-07
Iter: 250 loss: 5.4224239e-07
Iter: 251 loss: 5.44300178e-07
Iter: 252 loss: 5.42128134e-07
Iter: 253 loss: 5.41853069e-07
Iter: 254 loss: 5.4317627e-07
Iter: 255 loss: 5.41853353e-07
Iter: 256 loss: 5.41503255e-07
Iter: 257 loss: 5.42137684e-07
Iter: 258 loss: 5.41391728e-07
Iter: 259 loss: 5.41122347e-07
Iter: 260 loss: 5.41467045e-07
Iter: 261 loss: 5.41029635e-07
Iter: 262 loss: 5.40763665e-07
Iter: 263 loss: 5.4053e-07
Iter: 264 loss: 5.40433405e-07
Iter: 265 loss: 5.40242354e-07
Iter: 266 loss: 5.40171868e-07
Iter: 267 loss: 5.40029816e-07
Iter: 268 loss: 5.39678865e-07
Iter: 269 loss: 5.41191412e-07
Iter: 270 loss: 5.39477924e-07
Iter: 271 loss: 5.39050575e-07
Iter: 272 loss: 5.43781766e-07
Iter: 273 loss: 5.39064217e-07
Iter: 274 loss: 5.38579116e-07
Iter: 275 loss: 5.40031067e-07
Iter: 276 loss: 5.3845207e-07
Iter: 277 loss: 5.3823743e-07
Iter: 278 loss: 5.38213442e-07
Iter: 279 loss: 5.38085374e-07
Iter: 280 loss: 5.38621464e-07
Iter: 281 loss: 5.38014831e-07
Iter: 282 loss: 5.37795e-07
Iter: 283 loss: 5.38115501e-07
Iter: 284 loss: 5.37733968e-07
Iter: 285 loss: 5.375461e-07
Iter: 286 loss: 5.37336462e-07
Iter: 287 loss: 5.3732515e-07
Iter: 288 loss: 5.37115739e-07
Iter: 289 loss: 5.39465077e-07
Iter: 290 loss: 5.37074925e-07
Iter: 291 loss: 5.36886319e-07
Iter: 292 loss: 5.38869699e-07
Iter: 293 loss: 5.36918151e-07
Iter: 294 loss: 5.36808784e-07
Iter: 295 loss: 5.36568e-07
Iter: 296 loss: 5.38304448e-07
Iter: 297 loss: 5.36476534e-07
Iter: 298 loss: 5.36183052e-07
Iter: 299 loss: 5.38609413e-07
Iter: 300 loss: 5.36196239e-07
Iter: 301 loss: 5.35860636e-07
Iter: 302 loss: 5.36006326e-07
Iter: 303 loss: 5.35702441e-07
Iter: 304 loss: 5.35398158e-07
Iter: 305 loss: 5.37842e-07
Iter: 306 loss: 5.3536462e-07
Iter: 307 loss: 5.34985702e-07
Iter: 308 loss: 5.35387869e-07
Iter: 309 loss: 5.34801586e-07
Iter: 310 loss: 5.34506739e-07
Iter: 311 loss: 5.33924833e-07
Iter: 312 loss: 5.43670922e-07
Iter: 313 loss: 5.33941034e-07
Iter: 314 loss: 5.34096614e-07
Iter: 315 loss: 5.33671596e-07
Iter: 316 loss: 5.33474861e-07
Iter: 317 loss: 5.34278684e-07
Iter: 318 loss: 5.33413697e-07
Iter: 319 loss: 5.33259367e-07
Iter: 320 loss: 5.33413697e-07
Iter: 321 loss: 5.33239586e-07
Iter: 322 loss: 5.33031425e-07
Iter: 323 loss: 5.32848617e-07
Iter: 324 loss: 5.32846229e-07
Iter: 325 loss: 5.32601064e-07
Iter: 326 loss: 5.33008233e-07
Iter: 327 loss: 5.32545073e-07
Iter: 328 loss: 5.32323668e-07
Iter: 329 loss: 5.32332251e-07
Iter: 330 loss: 5.32188e-07
Iter: 331 loss: 5.32079525e-07
Iter: 332 loss: 5.32020749e-07
Iter: 333 loss: 5.31772059e-07
Iter: 334 loss: 5.31789965e-07
Iter: 335 loss: 5.31602495e-07
Iter: 336 loss: 5.3130384e-07
Iter: 337 loss: 5.32519721e-07
Iter: 338 loss: 5.31277e-07
Iter: 339 loss: 5.30962325e-07
Iter: 340 loss: 5.32582305e-07
Iter: 341 loss: 5.30914861e-07
Iter: 342 loss: 5.30675038e-07
Iter: 343 loss: 5.32043714e-07
Iter: 344 loss: 5.30701129e-07
Iter: 345 loss: 5.30526336e-07
Iter: 346 loss: 5.30406624e-07
Iter: 347 loss: 5.30350633e-07
Iter: 348 loss: 5.30302088e-07
Iter: 349 loss: 5.30181751e-07
Iter: 350 loss: 5.3010416e-07
Iter: 351 loss: 5.29864622e-07
Iter: 352 loss: 5.34375772e-07
Iter: 353 loss: 5.29851e-07
Iter: 354 loss: 5.29624288e-07
Iter: 355 loss: 5.32189233e-07
Iter: 356 loss: 5.29604847e-07
Iter: 357 loss: 5.29414251e-07
Iter: 358 loss: 5.29062277e-07
Iter: 359 loss: 5.32363515e-07
Iter: 360 loss: 5.28915734e-07
Iter: 361 loss: 5.2867756e-07
Iter: 362 loss: 5.28647377e-07
Iter: 363 loss: 5.28407782e-07
Iter: 364 loss: 5.3077224e-07
Iter: 365 loss: 5.28401245e-07
Iter: 366 loss: 5.28202122e-07
Iter: 367 loss: 5.27910856e-07
Iter: 368 loss: 5.27892212e-07
Iter: 369 loss: 5.27570592e-07
Iter: 370 loss: 5.28395333e-07
Iter: 371 loss: 5.2742007e-07
Iter: 372 loss: 5.27132784e-07
Iter: 373 loss: 5.29364684e-07
Iter: 374 loss: 5.27108227e-07
Iter: 375 loss: 5.26852546e-07
Iter: 376 loss: 5.2842222e-07
Iter: 377 loss: 5.26817189e-07
Iter: 378 loss: 5.26637336e-07
Iter: 379 loss: 5.26353233e-07
Iter: 380 loss: 5.26333508e-07
Iter: 381 loss: 5.26225108e-07
Iter: 382 loss: 5.26223516e-07
Iter: 383 loss: 5.26038e-07
Iter: 384 loss: 5.25992618e-07
Iter: 385 loss: 5.25921791e-07
Iter: 386 loss: 5.25720225e-07
Iter: 387 loss: 5.26696908e-07
Iter: 388 loss: 5.25715222e-07
Iter: 389 loss: 5.25552707e-07
Iter: 390 loss: 5.25418727e-07
Iter: 391 loss: 5.25389737e-07
Iter: 392 loss: 5.2513559e-07
Iter: 393 loss: 5.25960104e-07
Iter: 394 loss: 5.25129167e-07
Iter: 395 loss: 5.24876896e-07
Iter: 396 loss: 5.27573775e-07
Iter: 397 loss: 5.24861377e-07
Iter: 398 loss: 5.2474212e-07
Iter: 399 loss: 5.24756899e-07
Iter: 400 loss: 5.24671123e-07
Iter: 401 loss: 5.24492521e-07
Iter: 402 loss: 5.24336826e-07
Iter: 403 loss: 5.24282825e-07
Iter: 404 loss: 5.23978258e-07
Iter: 405 loss: 5.26041219e-07
Iter: 406 loss: 5.23992753e-07
Iter: 407 loss: 5.23712515e-07
Iter: 408 loss: 5.24880363e-07
Iter: 409 loss: 5.23701829e-07
Iter: 410 loss: 5.23378901e-07
Iter: 411 loss: 5.23536073e-07
Iter: 412 loss: 5.23254926e-07
Iter: 413 loss: 5.23033805e-07
Iter: 414 loss: 5.24122925e-07
Iter: 415 loss: 5.23013e-07
Iter: 416 loss: 5.22821153e-07
Iter: 417 loss: 5.24002928e-07
Iter: 418 loss: 5.22777384e-07
Iter: 419 loss: 5.22623054e-07
Iter: 420 loss: 5.22754306e-07
Iter: 421 loss: 5.22543132e-07
Iter: 422 loss: 5.22308937e-07
Iter: 423 loss: 5.22289724e-07
Iter: 424 loss: 5.22160917e-07
Iter: 425 loss: 5.21831112e-07
Iter: 426 loss: 5.2200312e-07
Iter: 427 loss: 5.21673257e-07
Iter: 428 loss: 5.21441507e-07
Iter: 429 loss: 5.21437187e-07
Iter: 430 loss: 5.21220727e-07
Iter: 431 loss: 5.2137284e-07
Iter: 432 loss: 5.2109e-07
Iter: 433 loss: 5.2091525e-07
Iter: 434 loss: 5.20974083e-07
Iter: 435 loss: 5.20775131e-07
Iter: 436 loss: 5.20611366e-07
Iter: 437 loss: 5.21846744e-07
Iter: 438 loss: 5.20574076e-07
Iter: 439 loss: 5.20408719e-07
Iter: 440 loss: 5.21331231e-07
Iter: 441 loss: 5.20354149e-07
Iter: 442 loss: 5.20254844e-07
Iter: 443 loss: 5.20655419e-07
Iter: 444 loss: 5.20166509e-07
Iter: 445 loss: 5.20037759e-07
Iter: 446 loss: 5.20020365e-07
Iter: 447 loss: 5.19957439e-07
Iter: 448 loss: 5.19844093e-07
Iter: 449 loss: 5.19799869e-07
Iter: 450 loss: 5.19700961e-07
Iter: 451 loss: 5.19669868e-07
Iter: 452 loss: 5.1961689e-07
Iter: 453 loss: 5.19540322e-07
Iter: 454 loss: 5.19940443e-07
Iter: 455 loss: 5.19453579e-07
Iter: 456 loss: 5.19300784e-07
Iter: 457 loss: 5.19255366e-07
Iter: 458 loss: 5.19156117e-07
Iter: 459 loss: 5.19007699e-07
Iter: 460 loss: 5.19896162e-07
Iter: 461 loss: 5.18973138e-07
Iter: 462 loss: 5.18736499e-07
Iter: 463 loss: 5.19397076e-07
Iter: 464 loss: 5.18742127e-07
Iter: 465 loss: 5.18547722e-07
Iter: 466 loss: 5.18420961e-07
Iter: 467 loss: 5.18408228e-07
Iter: 468 loss: 5.18156412e-07
Iter: 469 loss: 5.18569891e-07
Iter: 470 loss: 5.18078195e-07
Iter: 471 loss: 5.17832405e-07
Iter: 472 loss: 5.19312323e-07
Iter: 473 loss: 5.17780336e-07
Iter: 474 loss: 5.17504532e-07
Iter: 475 loss: 5.18363777e-07
Iter: 476 loss: 5.17467583e-07
Iter: 477 loss: 5.17255785e-07
Iter: 478 loss: 5.17263402e-07
Iter: 479 loss: 5.1716097e-07
Iter: 480 loss: 5.17021306e-07
Iter: 481 loss: 5.16967702e-07
Iter: 482 loss: 5.16877094e-07
Iter: 483 loss: 5.16843727e-07
Iter: 484 loss: 5.16718274e-07
Iter: 485 loss: 5.16599243e-07
Iter: 486 loss: 5.16765169e-07
Iter: 487 loss: 5.16547288e-07
Iter: 488 loss: 5.16335604e-07
Iter: 489 loss: 5.16555247e-07
Iter: 490 loss: 5.16186674e-07
Iter: 491 loss: 5.1599875e-07
Iter: 492 loss: 5.16327304e-07
Iter: 493 loss: 5.15948045e-07
Iter: 494 loss: 5.15744091e-07
Iter: 495 loss: 5.17607759e-07
Iter: 496 loss: 5.15720217e-07
Iter: 497 loss: 5.15606246e-07
Iter: 498 loss: 5.15578108e-07
Iter: 499 loss: 5.15479712e-07
Iter: 500 loss: 5.15325439e-07
Iter: 501 loss: 5.15284341e-07
Iter: 502 loss: 5.15200554e-07
Iter: 503 loss: 5.14980059e-07
Iter: 504 loss: 5.17195929e-07
Iter: 505 loss: 5.1498256e-07
Iter: 506 loss: 5.1482084e-07
Iter: 507 loss: 5.15688498e-07
Iter: 508 loss: 5.14786677e-07
Iter: 509 loss: 5.14651674e-07
Iter: 510 loss: 5.14723467e-07
Iter: 511 loss: 5.14574481e-07
Iter: 512 loss: 5.14471139e-07
Iter: 513 loss: 5.16060481e-07
Iter: 514 loss: 5.14454e-07
Iter: 515 loss: 5.14343e-07
Iter: 516 loss: 5.14465569e-07
Iter: 517 loss: 5.1426241e-07
Iter: 518 loss: 5.14160035e-07
Iter: 519 loss: 5.14085855e-07
Iter: 520 loss: 5.14036572e-07
Iter: 521 loss: 5.13888097e-07
Iter: 522 loss: 5.1493447e-07
Iter: 523 loss: 5.13832106e-07
Iter: 524 loss: 5.13747182e-07
Iter: 525 loss: 5.13663849e-07
Iter: 526 loss: 5.13618374e-07
Iter: 527 loss: 5.13464e-07
Iter: 528 loss: 5.156773e-07
Iter: 529 loss: 5.13437726e-07
Iter: 530 loss: 5.13348255e-07
Iter: 531 loss: 5.13201542e-07
Iter: 532 loss: 5.13169766e-07
Iter: 533 loss: 5.12962743e-07
Iter: 534 loss: 5.12823362e-07
Iter: 535 loss: 5.12747874e-07
Iter: 536 loss: 5.12583938e-07
Iter: 537 loss: 5.14544809e-07
Iter: 538 loss: 5.12554095e-07
Iter: 539 loss: 5.12356962e-07
Iter: 540 loss: 5.13375653e-07
Iter: 541 loss: 5.1236583e-07
Iter: 542 loss: 5.12208089e-07
Iter: 543 loss: 5.12379813e-07
Iter: 544 loss: 5.12146073e-07
Iter: 545 loss: 5.1196173e-07
Iter: 546 loss: 5.12826432e-07
Iter: 547 loss: 5.11966618e-07
Iter: 548 loss: 5.11820417e-07
Iter: 549 loss: 5.12745487e-07
Iter: 550 loss: 5.11776705e-07
Iter: 551 loss: 5.11743906e-07
Iter: 552 loss: 5.11647954e-07
Iter: 553 loss: 5.11651933e-07
Iter: 554 loss: 5.11483051e-07
Iter: 555 loss: 5.12862357e-07
Iter: 556 loss: 5.11532903e-07
Iter: 557 loss: 5.11425299e-07
Iter: 558 loss: 5.11343274e-07
Iter: 559 loss: 5.11325652e-07
Iter: 560 loss: 5.11188887e-07
Iter: 561 loss: 5.12594283e-07
Iter: 562 loss: 5.11185135e-07
Iter: 563 loss: 5.11061899e-07
Iter: 564 loss: 5.11250448e-07
Iter: 565 loss: 5.11036831e-07
Iter: 566 loss: 5.10885798e-07
Iter: 567 loss: 5.10760174e-07
Iter: 568 loss: 5.10777e-07
Iter: 569 loss: 5.10622e-07
Iter: 570 loss: 5.11015969e-07
Iter: 571 loss: 5.10556902e-07
Iter: 572 loss: 5.10396376e-07
Iter: 573 loss: 5.10727546e-07
Iter: 574 loss: 5.10364828e-07
Iter: 575 loss: 5.10192365e-07
Iter: 576 loss: 5.11377721e-07
Iter: 577 loss: 5.1013626e-07
Iter: 578 loss: 5.10059749e-07
Iter: 579 loss: 5.09948109e-07
Iter: 580 loss: 5.09891152e-07
Iter: 581 loss: 5.09769393e-07
Iter: 582 loss: 5.09751658e-07
Iter: 583 loss: 5.09674351e-07
Iter: 584 loss: 5.09511267e-07
Iter: 585 loss: 5.10649556e-07
Iter: 586 loss: 5.09434926e-07
Iter: 587 loss: 5.09255642e-07
Iter: 588 loss: 5.1125096e-07
Iter: 589 loss: 5.09230176e-07
Iter: 590 loss: 5.09081e-07
Iter: 591 loss: 5.09483812e-07
Iter: 592 loss: 5.09010817e-07
Iter: 593 loss: 5.08891844e-07
Iter: 594 loss: 5.09354777e-07
Iter: 595 loss: 5.08870869e-07
Iter: 596 loss: 5.08770711e-07
Iter: 597 loss: 5.09847325e-07
Iter: 598 loss: 5.08761332e-07
Iter: 599 loss: 5.08655887e-07
Iter: 600 loss: 5.08456651e-07
Iter: 601 loss: 5.11102655e-07
Iter: 602 loss: 5.08490416e-07
Iter: 603 loss: 5.08326707e-07
Iter: 604 loss: 5.09461245e-07
Iter: 605 loss: 5.08274297e-07
Iter: 606 loss: 5.08178289e-07
Iter: 607 loss: 5.08746894e-07
Iter: 608 loss: 5.08148673e-07
Iter: 609 loss: 5.08077392e-07
Iter: 610 loss: 5.08619621e-07
Iter: 611 loss: 5.08058406e-07
Iter: 612 loss: 5.07982463e-07
Iter: 613 loss: 5.0792039e-07
Iter: 614 loss: 5.07846266e-07
Iter: 615 loss: 5.07892423e-07
Iter: 616 loss: 5.07792549e-07
Iter: 617 loss: 5.07780555e-07
Iter: 618 loss: 5.07649816e-07
Iter: 619 loss: 5.08622747e-07
Iter: 620 loss: 5.07679829e-07
Iter: 621 loss: 5.07550396e-07
Iter: 622 loss: 5.07580353e-07
Iter: 623 loss: 5.07419372e-07
Iter: 624 loss: 5.07320351e-07
Iter: 625 loss: 5.08755193e-07
Iter: 626 loss: 5.07319e-07
Iter: 627 loss: 5.07187906e-07
Iter: 628 loss: 5.07218601e-07
Iter: 629 loss: 5.07105483e-07
Iter: 630 loss: 5.06960305e-07
Iter: 631 loss: 5.07554887e-07
Iter: 632 loss: 5.06928473e-07
Iter: 633 loss: 5.06834112e-07
Iter: 634 loss: 5.07077743e-07
Iter: 635 loss: 5.0674e-07
Iter: 636 loss: 5.06599747e-07
Iter: 637 loss: 5.06637548e-07
Iter: 638 loss: 5.06499759e-07
Iter: 639 loss: 5.06345486e-07
Iter: 640 loss: 5.06395054e-07
Iter: 641 loss: 5.0623305e-07
Iter: 642 loss: 5.06054278e-07
Iter: 643 loss: 5.08536459e-07
Iter: 644 loss: 5.06080482e-07
Iter: 645 loss: 5.05920639e-07
Iter: 646 loss: 5.06151537e-07
Iter: 647 loss: 5.05869e-07
Iter: 648 loss: 5.05757612e-07
Iter: 649 loss: 5.06224296e-07
Iter: 650 loss: 5.05726121e-07
Iter: 651 loss: 5.0568093e-07
Iter: 652 loss: 5.05825881e-07
Iter: 653 loss: 5.05625735e-07
Iter: 654 loss: 5.05568437e-07
Iter: 655 loss: 5.06618221e-07
Iter: 656 loss: 5.0551148e-07
Iter: 657 loss: 5.05470894e-07
Iter: 658 loss: 5.05403705e-07
Iter: 659 loss: 5.07061827e-07
Iter: 660 loss: 5.05396486e-07
Iter: 661 loss: 5.05325374e-07
Iter: 662 loss: 5.05683829e-07
Iter: 663 loss: 5.05323328e-07
Iter: 664 loss: 5.0521993e-07
Iter: 665 loss: 5.06102424e-07
Iter: 666 loss: 5.052338e-07
Iter: 667 loss: 5.0513961e-07
Iter: 668 loss: 5.0505389e-07
Iter: 669 loss: 5.06792844e-07
Iter: 670 loss: 5.05043374e-07
Iter: 671 loss: 5.04988861e-07
Iter: 672 loss: 5.05007733e-07
Iter: 673 loss: 5.04867785e-07
Iter: 674 loss: 5.04975219e-07
Iter: 675 loss: 5.04852153e-07
Iter: 676 loss: 5.04669401e-07
Iter: 677 loss: 5.04669742e-07
Iter: 678 loss: 5.04608579e-07
Iter: 679 loss: 5.0447585e-07
Iter: 680 loss: 5.04643538e-07
Iter: 681 loss: 5.04424122e-07
Iter: 682 loss: 5.04315949e-07
Iter: 683 loss: 5.05272453e-07
Iter: 684 loss: 5.0429486e-07
Iter: 685 loss: 5.0416088e-07
Iter: 686 loss: 5.04663149e-07
Iter: 687 loss: 5.0415025e-07
Iter: 688 loss: 5.04060836e-07
Iter: 689 loss: 5.04273544e-07
Iter: 690 loss: 5.04024e-07
Iter: 691 loss: 5.0393146e-07
Iter: 692 loss: 5.04551053e-07
Iter: 693 loss: 5.03913554e-07
Iter: 694 loss: 5.03851425e-07
Iter: 695 loss: 5.03758599e-07
Iter: 696 loss: 5.03714e-07
Iter: 697 loss: 5.03648153e-07
Iter: 698 loss: 5.03673846e-07
Iter: 699 loss: 5.03531794e-07
Iter: 700 loss: 5.03417255e-07
Iter: 701 loss: 5.03828687e-07
Iter: 702 loss: 5.03377919e-07
Iter: 703 loss: 5.03268666e-07
Iter: 704 loss: 5.03254341e-07
Iter: 705 loss: 5.03212107e-07
Iter: 706 loss: 5.03070453e-07
Iter: 707 loss: 5.05261255e-07
Iter: 708 loss: 5.03064769e-07
Iter: 709 loss: 5.02920784e-07
Iter: 710 loss: 5.02919647e-07
Iter: 711 loss: 5.02831369e-07
Iter: 712 loss: 5.02873945e-07
Iter: 713 loss: 5.02827334e-07
Iter: 714 loss: 5.0266533e-07
Iter: 715 loss: 5.02666865e-07
Iter: 716 loss: 5.02580633e-07
Iter: 717 loss: 5.02487751e-07
Iter: 718 loss: 5.02654e-07
Iter: 719 loss: 5.02382534e-07
Iter: 720 loss: 5.02233036e-07
Iter: 721 loss: 5.03129172e-07
Iter: 722 loss: 5.02239459e-07
Iter: 723 loss: 5.02186367e-07
Iter: 724 loss: 5.02856494e-07
Iter: 725 loss: 5.02198816e-07
Iter: 726 loss: 5.02096213e-07
Iter: 727 loss: 5.02464331e-07
Iter: 728 loss: 5.02072e-07
Iter: 729 loss: 5.01999409e-07
Iter: 730 loss: 5.02249236e-07
Iter: 731 loss: 5.0199219e-07
Iter: 732 loss: 5.0190863e-07
Iter: 733 loss: 5.01795341e-07
Iter: 734 loss: 5.03860065e-07
Iter: 735 loss: 5.01785337e-07
Iter: 736 loss: 5.01618331e-07
Iter: 737 loss: 5.02198418e-07
Iter: 738 loss: 5.01605e-07
Iter: 739 loss: 5.0143808e-07
Iter: 740 loss: 5.02854618e-07
Iter: 741 loss: 5.01472698e-07
Iter: 742 loss: 5.01374757e-07
Iter: 743 loss: 5.01351565e-07
Iter: 744 loss: 5.01299212e-07
Iter: 745 loss: 5.0113124e-07
Iter: 746 loss: 5.0177556e-07
Iter: 747 loss: 5.01122145e-07
Iter: 748 loss: 5.00976512e-07
Iter: 749 loss: 5.01278066e-07
Iter: 750 loss: 5.00923761e-07
Iter: 751 loss: 5.00768692e-07
Iter: 752 loss: 5.00651765e-07
Iter: 753 loss: 5.00652561e-07
Iter: 754 loss: 5.00502779e-07
Iter: 755 loss: 5.01927559e-07
Iter: 756 loss: 5.00535236e-07
Iter: 757 loss: 5.00382271e-07
Iter: 758 loss: 5.00585429e-07
Iter: 759 loss: 5.002953e-07
Iter: 760 loss: 5.00263582e-07
Iter: 761 loss: 5.00262558e-07
Iter: 762 loss: 5.00213673e-07
Iter: 763 loss: 5.00330202e-07
Iter: 764 loss: 5.00160809e-07
Iter: 765 loss: 5.00129e-07
Iter: 766 loss: 5.00179965e-07
Iter: 767 loss: 5.0008407e-07
Iter: 768 loss: 4.99991302e-07
Iter: 769 loss: 4.99922294e-07
Iter: 770 loss: 4.99930707e-07
Iter: 771 loss: 4.99822079e-07
Iter: 772 loss: 4.99988118e-07
Iter: 773 loss: 4.99766486e-07
Iter: 774 loss: 4.99665248e-07
Iter: 775 loss: 4.99788939e-07
Iter: 776 loss: 4.99583905e-07
Iter: 777 loss: 4.99464591e-07
Iter: 778 loss: 4.99463567e-07
Iter: 779 loss: 4.99388307e-07
Iter: 780 loss: 4.99298e-07
Iter: 781 loss: 4.99314297e-07
Iter: 782 loss: 4.99215162e-07
Iter: 783 loss: 4.99234602e-07
Iter: 784 loss: 4.99143084e-07
Iter: 785 loss: 4.99093062e-07
Iter: 786 loss: 4.99099656e-07
Iter: 787 loss: 4.98967e-07
Iter: 788 loss: 4.98845452e-07
Iter: 789 loss: 4.98850568e-07
Iter: 790 loss: 4.98783322e-07
Iter: 791 loss: 4.98950385e-07
Iter: 792 loss: 4.98727729e-07
Iter: 793 loss: 4.9864849e-07
Iter: 794 loss: 4.98937197e-07
Iter: 795 loss: 4.98606198e-07
Iter: 796 loss: 4.98506893e-07
Iter: 797 loss: 4.98428506e-07
Iter: 798 loss: 4.98438e-07
Iter: 799 loss: 4.98319707e-07
Iter: 800 loss: 4.99026555e-07
Iter: 801 loss: 4.98315899e-07
Iter: 802 loss: 4.98185841e-07
Iter: 803 loss: 4.99004727e-07
Iter: 804 loss: 4.98202439e-07
Iter: 805 loss: 4.98113536e-07
Iter: 806 loss: 4.98249506e-07
Iter: 807 loss: 4.98034922e-07
Iter: 808 loss: 4.98012128e-07
Iter: 809 loss: 4.97880649e-07
Iter: 810 loss: 4.97889118e-07
Iter: 811 loss: 4.97834264e-07
Iter: 812 loss: 4.97825681e-07
Iter: 813 loss: 4.97714268e-07
Iter: 814 loss: 4.97726887e-07
Iter: 815 loss: 4.97657652e-07
Iter: 816 loss: 4.97568408e-07
Iter: 817 loss: 4.9853395e-07
Iter: 818 loss: 4.97567839e-07
Iter: 819 loss: 4.9749633e-07
Iter: 820 loss: 4.97428061e-07
Iter: 821 loss: 4.97383e-07
Iter: 822 loss: 4.9730329e-07
Iter: 823 loss: 4.97381279e-07
Iter: 824 loss: 4.97196368e-07
Iter: 825 loss: 4.97127076e-07
Iter: 826 loss: 4.9890167e-07
Iter: 827 loss: 4.97112524e-07
Iter: 828 loss: 4.97024587e-07
Iter: 829 loss: 4.97025269e-07
Iter: 830 loss: 4.96977577e-07
Iter: 831 loss: 4.96896917e-07
Iter: 832 loss: 4.96793859e-07
Iter: 833 loss: 4.96785e-07
Iter: 834 loss: 4.96652774e-07
Iter: 835 loss: 4.96679093e-07
Iter: 836 loss: 4.96529481e-07
Iter: 837 loss: 4.96343318e-07
Iter: 838 loss: 4.9864542e-07
Iter: 839 loss: 4.96324787e-07
Iter: 840 loss: 4.96199505e-07
Iter: 841 loss: 4.96655616e-07
Iter: 842 loss: 4.96187681e-07
Iter: 843 loss: 4.96050063e-07
Iter: 844 loss: 4.97281349e-07
Iter: 845 loss: 4.96017606e-07
Iter: 846 loss: 4.95997e-07
Iter: 847 loss: 4.95879533e-07
Iter: 848 loss: 4.95878908e-07
Iter: 849 loss: 4.95798872e-07
Iter: 850 loss: 4.95795291e-07
Iter: 851 loss: 4.95772042e-07
Iter: 852 loss: 4.95729807e-07
Iter: 853 loss: 4.95738675e-07
Iter: 854 loss: 4.95657787e-07
Iter: 855 loss: 4.95848099e-07
Iter: 856 loss: 4.95663926e-07
Iter: 857 loss: 4.95547283e-07
Iter: 858 loss: 4.95751692e-07
Iter: 859 loss: 4.95488962e-07
Iter: 860 loss: 4.95454628e-07
Iter: 861 loss: 4.95388065e-07
Iter: 862 loss: 4.95385507e-07
Iter: 863 loss: 4.95285462e-07
Iter: 864 loss: 4.95272047e-07
Iter: 865 loss: 4.95206905e-07
Iter: 866 loss: 4.95884876e-07
Iter: 867 loss: 4.95208781e-07
Iter: 868 loss: 4.95178483e-07
Iter: 869 loss: 4.9505212e-07
Iter: 870 loss: 4.95691e-07
Iter: 871 loss: 4.95008521e-07
Iter: 872 loss: 4.94950427e-07
Iter: 873 loss: 4.94970152e-07
Iter: 874 loss: 4.94910125e-07
Iter: 875 loss: 4.94995902e-07
Iter: 876 loss: 4.9488051e-07
Iter: 877 loss: 4.94832705e-07
Iter: 878 loss: 4.94907113e-07
Iter: 879 loss: 4.94787173e-07
Iter: 880 loss: 4.9468747e-07
Iter: 881 loss: 4.94629887e-07
Iter: 882 loss: 4.9462858e-07
Iter: 883 loss: 4.9453e-07
Iter: 884 loss: 4.95089466e-07
Iter: 885 loss: 4.94557128e-07
Iter: 886 loss: 4.94486187e-07
Iter: 887 loss: 4.94734707e-07
Iter: 888 loss: 4.94427468e-07
Iter: 889 loss: 4.94353969e-07
Iter: 890 loss: 4.95379e-07
Iter: 891 loss: 4.94371e-07
Iter: 892 loss: 4.94322535e-07
Iter: 893 loss: 4.94271035e-07
Iter: 894 loss: 4.95671316e-07
Iter: 895 loss: 4.94285871e-07
Iter: 896 loss: 4.94192818e-07
Iter: 897 loss: 4.9459959e-07
Iter: 898 loss: 4.94215e-07
Iter: 899 loss: 4.94090216e-07
Iter: 900 loss: 4.94094877e-07
Iter: 901 loss: 4.94062078e-07
Iter: 902 loss: 4.94015808e-07
Iter: 903 loss: 4.93972152e-07
Iter: 904 loss: 4.93979e-07
Iter: 905 loss: 4.9397795e-07
Iter: 906 loss: 4.9397795e-07
Iter: 907 loss: 4.93991649e-07
Iter: 908 loss: 4.9399415e-07
Iter: 909 loss: 4.93992104e-07
Iter: 910 loss: 4.93994094e-07
Iter: 911 loss: 4.93981e-07
Iter: 912 loss: 4.94005064e-07
Iter: 913 loss: 4.93987955e-07
Iter: 914 loss: 4.93982043e-07
Iter: 915 loss: 4.93976586e-07
Iter: 916 loss: 4.93973289e-07
Iter: 917 loss: 4.93973403e-07
Iter: 918 loss: 4.93975222e-07
Iter: 919 loss: 4.93972891e-07
Iter: 920 loss: 4.93972209e-07
Iter: 921 loss: 4.93973062e-07
Iter: 922 loss: 4.93972664e-07
Iter: 923 loss: 4.93973062e-07
Iter: 924 loss: 4.93972834e-07
Iter: 925 loss: 4.93972834e-07
Iter: 926 loss: 4.93972777e-07
Iter: 927 loss: 4.93972777e-07
Iter: 928 loss: 4.93972777e-07
Iter: 929 loss: 4.93972721e-07
Iter: 930 loss: 4.93972721e-07
Iter: 931 loss: 4.93972664e-07
Iter: 932 loss: 4.93972664e-07
Iter: 933 loss: 4.93972721e-07
Iter: 934 loss: 4.93972664e-07
Iter: 935 loss: 4.93972664e-07
Iter: 936 loss: 4.93972664e-07
Iter: 937 loss: 4.93972721e-07
Iter: 938 loss: 4.93972664e-07
Iter: 939 loss: 4.93972664e-07
Iter: 940 loss: 4.93972664e-07
Iter: 941 loss: 4.93972721e-07
Iter: 942 loss: 4.93972664e-07
Iter: 943 loss: 4.93972664e-07
Iter: 944 loss: 4.93972721e-07
Iter: 945 loss: 4.96224459e-07
Iter: 946 loss: 4.9398318e-07
Iter: 947 loss: 4.94002279e-07
Iter: 948 loss: 4.93990456e-07
Iter: 949 loss: 4.93967264e-07
Iter: 950 loss: 4.93981588e-07
Iter: 951 loss: 4.94024277e-07
Iter: 952 loss: 4.94016831e-07
Iter: 953 loss: 4.94013648e-07
Iter: 954 loss: 4.94005576e-07
Iter: 955 loss: 4.94017058e-07
Iter: 956 loss: 4.94003302e-07
Iter: 957 loss: 4.93986e-07
Iter: 958 loss: 4.93982839e-07
Iter: 959 loss: 4.93969196e-07
Iter: 960 loss: 4.93971356e-07
Iter: 961 loss: 4.93981474e-07
Iter: 962 loss: 4.93974937e-07
Iter: 963 loss: 4.93971584e-07
Iter: 964 loss: 4.9396931e-07
Iter: 965 loss: 4.93972664e-07
Iter: 966 loss: 4.93973403e-07
Iter: 967 loss: 4.93972664e-07
Iter: 968 loss: 4.9397255e-07
Iter: 969 loss: 4.9397255e-07
Iter: 970 loss: 4.93973403e-07
Iter: 971 loss: 4.93973403e-07
Iter: 972 loss: 4.93973403e-07
Iter: 973 loss: 4.9397255e-07
Iter: 974 loss: 4.93973403e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.6/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.6 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi1.6_8000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c904cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c9074730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c9103b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c9078620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c904ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c9103158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c9033ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8fd9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8fd9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8f9ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8f9f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8f98ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8f3ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8efb268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8f1c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8f46378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8f1cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8e6ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8e74ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8e6f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8e270d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8dc9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8e27a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8d81ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8d886a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8d13ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8d5f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8d13158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8cc7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8c800d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8c91400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8c6f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8c6f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8c8dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8c201e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f52c8c21598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.84318946e-06
Iter: 2 loss: 8.42173085e-06
Iter: 3 loss: 1.90534467e-06
Iter: 4 loss: 1.58593184e-06
Iter: 5 loss: 2.09833024e-06
Iter: 6 loss: 1.43820057e-06
Iter: 7 loss: 1.23255722e-06
Iter: 8 loss: 1.3267811e-06
Iter: 9 loss: 1.09320808e-06
Iter: 10 loss: 9.61038268e-07
Iter: 11 loss: 1.94222139e-06
Iter: 12 loss: 9.50437084e-07
Iter: 13 loss: 8.58949534e-07
Iter: 14 loss: 1.4785553e-06
Iter: 15 loss: 8.49910123e-07
Iter: 16 loss: 8.00180601e-07
Iter: 17 loss: 7.83447149e-07
Iter: 18 loss: 7.54815517e-07
Iter: 19 loss: 7.31759826e-07
Iter: 20 loss: 8.11499376e-07
Iter: 21 loss: 7.25645577e-07
Iter: 22 loss: 7.17814e-07
Iter: 23 loss: 7.16040063e-07
Iter: 24 loss: 7.09682922e-07
Iter: 25 loss: 7.20105902e-07
Iter: 26 loss: 7.06783e-07
Iter: 27 loss: 7.00454279e-07
Iter: 28 loss: 7.02349382e-07
Iter: 29 loss: 6.95874519e-07
Iter: 30 loss: 6.89105718e-07
Iter: 31 loss: 6.97270934e-07
Iter: 32 loss: 6.8557074e-07
Iter: 33 loss: 6.79259415e-07
Iter: 34 loss: 6.90196373e-07
Iter: 35 loss: 6.76397917e-07
Iter: 36 loss: 6.7431688e-07
Iter: 37 loss: 6.72666772e-07
Iter: 38 loss: 6.69338419e-07
Iter: 39 loss: 6.79538061e-07
Iter: 40 loss: 6.68343091e-07
Iter: 41 loss: 6.6619782e-07
Iter: 42 loss: 6.61796719e-07
Iter: 43 loss: 7.4471177e-07
Iter: 44 loss: 6.61765853e-07
Iter: 45 loss: 6.55911435e-07
Iter: 46 loss: 7.07865809e-07
Iter: 47 loss: 6.55665417e-07
Iter: 48 loss: 6.53460177e-07
Iter: 49 loss: 6.59367515e-07
Iter: 50 loss: 6.52760662e-07
Iter: 51 loss: 6.49494496e-07
Iter: 52 loss: 6.4961074e-07
Iter: 53 loss: 6.46955357e-07
Iter: 54 loss: 6.43732051e-07
Iter: 55 loss: 6.4354947e-07
Iter: 56 loss: 6.41088548e-07
Iter: 57 loss: 6.35625952e-07
Iter: 58 loss: 6.40752376e-07
Iter: 59 loss: 6.32531794e-07
Iter: 60 loss: 6.27485861e-07
Iter: 61 loss: 6.39945938e-07
Iter: 62 loss: 6.25739858e-07
Iter: 63 loss: 6.22688958e-07
Iter: 64 loss: 6.2221136e-07
Iter: 65 loss: 6.20151241e-07
Iter: 66 loss: 6.14331157e-07
Iter: 67 loss: 6.45576392e-07
Iter: 68 loss: 6.12513645e-07
Iter: 69 loss: 6.1026833e-07
Iter: 70 loss: 6.09502763e-07
Iter: 71 loss: 6.07266429e-07
Iter: 72 loss: 6.04182105e-07
Iter: 73 loss: 6.04044715e-07
Iter: 74 loss: 6.07295476e-07
Iter: 75 loss: 6.03395847e-07
Iter: 76 loss: 6.02656655e-07
Iter: 77 loss: 6.01902457e-07
Iter: 78 loss: 6.01757108e-07
Iter: 79 loss: 6.00847329e-07
Iter: 80 loss: 6.01409795e-07
Iter: 81 loss: 6.00293504e-07
Iter: 82 loss: 5.9907336e-07
Iter: 83 loss: 6.04619913e-07
Iter: 84 loss: 5.98896122e-07
Iter: 85 loss: 5.97692406e-07
Iter: 86 loss: 5.96990162e-07
Iter: 87 loss: 5.96547e-07
Iter: 88 loss: 5.95178562e-07
Iter: 89 loss: 6.03128115e-07
Iter: 90 loss: 5.94994162e-07
Iter: 91 loss: 5.9351396e-07
Iter: 92 loss: 5.95029519e-07
Iter: 93 loss: 5.92612935e-07
Iter: 94 loss: 5.91305934e-07
Iter: 95 loss: 5.93478944e-07
Iter: 96 loss: 5.90806735e-07
Iter: 97 loss: 5.89283502e-07
Iter: 98 loss: 5.90777404e-07
Iter: 99 loss: 5.88445e-07
Iter: 100 loss: 5.87304385e-07
Iter: 101 loss: 5.8727943e-07
Iter: 102 loss: 5.86201338e-07
Iter: 103 loss: 5.85999317e-07
Iter: 104 loss: 5.85274449e-07
Iter: 105 loss: 5.84339091e-07
Iter: 106 loss: 5.85414341e-07
Iter: 107 loss: 5.83844439e-07
Iter: 108 loss: 5.83445171e-07
Iter: 109 loss: 5.83265489e-07
Iter: 110 loss: 5.82698306e-07
Iter: 111 loss: 5.82096959e-07
Iter: 112 loss: 5.81995891e-07
Iter: 113 loss: 5.81196e-07
Iter: 114 loss: 5.79710786e-07
Iter: 115 loss: 6.13112149e-07
Iter: 116 loss: 5.79706182e-07
Iter: 117 loss: 5.80087033e-07
Iter: 118 loss: 5.79031848e-07
Iter: 119 loss: 5.78637e-07
Iter: 120 loss: 5.77407832e-07
Iter: 121 loss: 5.8180774e-07
Iter: 122 loss: 5.76849345e-07
Iter: 123 loss: 5.75924787e-07
Iter: 124 loss: 5.75829631e-07
Iter: 125 loss: 5.75206855e-07
Iter: 126 loss: 5.78175559e-07
Iter: 127 loss: 5.75119316e-07
Iter: 128 loss: 5.74607895e-07
Iter: 129 loss: 5.74235344e-07
Iter: 130 loss: 5.74063904e-07
Iter: 131 loss: 5.73427371e-07
Iter: 132 loss: 5.73672139e-07
Iter: 133 loss: 5.72974727e-07
Iter: 134 loss: 5.72758267e-07
Iter: 135 loss: 5.72547606e-07
Iter: 136 loss: 5.721854e-07
Iter: 137 loss: 5.71937e-07
Iter: 138 loss: 5.71793066e-07
Iter: 139 loss: 5.71229066e-07
Iter: 140 loss: 5.71854571e-07
Iter: 141 loss: 5.70936322e-07
Iter: 142 loss: 5.70316843e-07
Iter: 143 loss: 5.70955194e-07
Iter: 144 loss: 5.70007046e-07
Iter: 145 loss: 5.69635404e-07
Iter: 146 loss: 5.69526378e-07
Iter: 147 loss: 5.69103e-07
Iter: 148 loss: 5.68714654e-07
Iter: 149 loss: 5.68631663e-07
Iter: 150 loss: 5.68180837e-07
Iter: 151 loss: 5.68045095e-07
Iter: 152 loss: 5.67790835e-07
Iter: 153 loss: 5.67366726e-07
Iter: 154 loss: 5.67376901e-07
Iter: 155 loss: 5.66961717e-07
Iter: 156 loss: 5.66517429e-07
Iter: 157 loss: 5.66432675e-07
Iter: 158 loss: 5.65976279e-07
Iter: 159 loss: 5.66742472e-07
Iter: 160 loss: 5.65792163e-07
Iter: 161 loss: 5.65230266e-07
Iter: 162 loss: 5.68077e-07
Iter: 163 loss: 5.65108e-07
Iter: 164 loss: 5.64559059e-07
Iter: 165 loss: 5.6647616e-07
Iter: 166 loss: 5.64452762e-07
Iter: 167 loss: 5.64088964e-07
Iter: 168 loss: 5.63613867e-07
Iter: 169 loss: 5.63551396e-07
Iter: 170 loss: 5.6297813e-07
Iter: 171 loss: 5.65586959e-07
Iter: 172 loss: 5.62900311e-07
Iter: 173 loss: 5.62220748e-07
Iter: 174 loss: 5.6658314e-07
Iter: 175 loss: 5.62144464e-07
Iter: 176 loss: 5.61825e-07
Iter: 177 loss: 5.62754849e-07
Iter: 178 loss: 5.61710067e-07
Iter: 179 loss: 5.61426532e-07
Iter: 180 loss: 5.61046136e-07
Iter: 181 loss: 5.61008164e-07
Iter: 182 loss: 5.60829e-07
Iter: 183 loss: 5.60745889e-07
Iter: 184 loss: 5.60456613e-07
Iter: 185 loss: 5.60525791e-07
Iter: 186 loss: 5.60216051e-07
Iter: 187 loss: 5.59932346e-07
Iter: 188 loss: 5.59915293e-07
Iter: 189 loss: 5.59709633e-07
Iter: 190 loss: 5.59482601e-07
Iter: 191 loss: 5.62593812e-07
Iter: 192 loss: 5.59500393e-07
Iter: 193 loss: 5.59238e-07
Iter: 194 loss: 5.588779e-07
Iter: 195 loss: 5.58863462e-07
Iter: 196 loss: 5.58516319e-07
Iter: 197 loss: 5.59374428e-07
Iter: 198 loss: 5.58346187e-07
Iter: 199 loss: 5.58037698e-07
Iter: 200 loss: 5.6117608e-07
Iter: 201 loss: 5.57990802e-07
Iter: 202 loss: 5.57752173e-07
Iter: 203 loss: 5.58247734e-07
Iter: 204 loss: 5.57641101e-07
Iter: 205 loss: 5.57374165e-07
Iter: 206 loss: 5.57224382e-07
Iter: 207 loss: 5.5712303e-07
Iter: 208 loss: 5.56788564e-07
Iter: 209 loss: 5.58055717e-07
Iter: 210 loss: 5.56712621e-07
Iter: 211 loss: 5.56377927e-07
Iter: 212 loss: 5.59892953e-07
Iter: 213 loss: 5.56354848e-07
Iter: 214 loss: 5.56112866e-07
Iter: 215 loss: 5.55941256e-07
Iter: 216 loss: 5.55876795e-07
Iter: 217 loss: 5.55542215e-07
Iter: 218 loss: 5.56409304e-07
Iter: 219 loss: 5.55390557e-07
Iter: 220 loss: 5.55087752e-07
Iter: 221 loss: 5.55080192e-07
Iter: 222 loss: 5.54809958e-07
Iter: 223 loss: 5.55200359e-07
Iter: 224 loss: 5.5466e-07
Iter: 225 loss: 5.54585824e-07
Iter: 226 loss: 5.54381586e-07
Iter: 227 loss: 5.56426244e-07
Iter: 228 loss: 5.5438727e-07
Iter: 229 loss: 5.54104133e-07
Iter: 230 loss: 5.54521e-07
Iter: 231 loss: 5.54025803e-07
Iter: 232 loss: 5.53765858e-07
Iter: 233 loss: 5.57724547e-07
Iter: 234 loss: 5.53764949e-07
Iter: 235 loss: 5.53652455e-07
Iter: 236 loss: 5.53268137e-07
Iter: 237 loss: 5.56929e-07
Iter: 238 loss: 5.53241762e-07
Iter: 239 loss: 5.53038717e-07
Iter: 240 loss: 5.53058271e-07
Iter: 241 loss: 5.52864549e-07
Iter: 242 loss: 5.53479254e-07
Iter: 243 loss: 5.52783661e-07
Iter: 244 loss: 5.52649226e-07
Iter: 245 loss: 5.52680945e-07
Iter: 246 loss: 5.52521328e-07
Iter: 247 loss: 5.52322888e-07
Iter: 248 loss: 5.52068059e-07
Iter: 249 loss: 5.52018321e-07
Iter: 250 loss: 5.51858307e-07
Iter: 251 loss: 5.51852e-07
Iter: 252 loss: 5.51644121e-07
Iter: 253 loss: 5.52090626e-07
Iter: 254 loss: 5.51558742e-07
Iter: 255 loss: 5.51372068e-07
Iter: 256 loss: 5.51276287e-07
Iter: 257 loss: 5.51191e-07
Iter: 258 loss: 5.51083531e-07
Iter: 259 loss: 5.51068297e-07
Iter: 260 loss: 5.50955406e-07
Iter: 261 loss: 5.50789309e-07
Iter: 262 loss: 5.50735763e-07
Iter: 263 loss: 5.506202e-07
Iter: 264 loss: 5.50387085e-07
Iter: 265 loss: 5.50411755e-07
Iter: 266 loss: 5.50304833e-07
Iter: 267 loss: 5.50272034e-07
Iter: 268 loss: 5.50172558e-07
Iter: 269 loss: 5.50009645e-07
Iter: 270 loss: 5.50018967e-07
Iter: 271 loss: 5.49827064e-07
Iter: 272 loss: 5.50188588e-07
Iter: 273 loss: 5.49762831e-07
Iter: 274 loss: 5.49636809e-07
Iter: 275 loss: 5.50081893e-07
Iter: 276 loss: 5.49636297e-07
Iter: 277 loss: 5.49344406e-07
Iter: 278 loss: 5.49675633e-07
Iter: 279 loss: 5.49223046e-07
Iter: 280 loss: 5.490582e-07
Iter: 281 loss: 5.49135962e-07
Iter: 282 loss: 5.48927233e-07
Iter: 283 loss: 5.4861556e-07
Iter: 284 loss: 5.49046263e-07
Iter: 285 loss: 5.48491471e-07
Iter: 286 loss: 5.48238e-07
Iter: 287 loss: 5.51452672e-07
Iter: 288 loss: 5.48256253e-07
Iter: 289 loss: 5.48031437e-07
Iter: 290 loss: 5.48014839e-07
Iter: 291 loss: 5.47860736e-07
Iter: 292 loss: 5.47748812e-07
Iter: 293 loss: 5.47771663e-07
Iter: 294 loss: 5.47617219e-07
Iter: 295 loss: 5.47324817e-07
Iter: 296 loss: 5.5070177e-07
Iter: 297 loss: 5.47308105e-07
Iter: 298 loss: 5.4705481e-07
Iter: 299 loss: 5.47938839e-07
Iter: 300 loss: 5.46992396e-07
Iter: 301 loss: 5.46843069e-07
Iter: 302 loss: 5.4749728e-07
Iter: 303 loss: 5.46801289e-07
Iter: 304 loss: 5.466934e-07
Iter: 305 loss: 5.46700107e-07
Iter: 306 loss: 5.46577951e-07
Iter: 307 loss: 5.46353135e-07
Iter: 308 loss: 5.48261e-07
Iter: 309 loss: 5.46332046e-07
Iter: 310 loss: 5.46123374e-07
Iter: 311 loss: 5.47927414e-07
Iter: 312 loss: 5.46129343e-07
Iter: 313 loss: 5.45962962e-07
Iter: 314 loss: 5.46864044e-07
Iter: 315 loss: 5.4591078e-07
Iter: 316 loss: 5.45830233e-07
Iter: 317 loss: 5.46015258e-07
Iter: 318 loss: 5.45738885e-07
Iter: 319 loss: 5.45587909e-07
Iter: 320 loss: 5.4532552e-07
Iter: 321 loss: 5.51128096e-07
Iter: 322 loss: 5.4531904e-07
Iter: 323 loss: 5.45331204e-07
Iter: 324 loss: 5.45193e-07
Iter: 325 loss: 5.45070179e-07
Iter: 326 loss: 5.45371904e-07
Iter: 327 loss: 5.4504045e-07
Iter: 328 loss: 5.44913291e-07
Iter: 329 loss: 5.45016064e-07
Iter: 330 loss: 5.44839e-07
Iter: 331 loss: 5.44727243e-07
Iter: 332 loss: 5.44632144e-07
Iter: 333 loss: 5.44624186e-07
Iter: 334 loss: 5.4439829e-07
Iter: 335 loss: 5.44398176e-07
Iter: 336 loss: 5.44228669e-07
Iter: 337 loss: 5.4412277e-07
Iter: 338 loss: 5.44094064e-07
Iter: 339 loss: 5.43968952e-07
Iter: 340 loss: 5.43773e-07
Iter: 341 loss: 5.4378944e-07
Iter: 342 loss: 5.43577414e-07
Iter: 343 loss: 5.43913757e-07
Iter: 344 loss: 5.43513352e-07
Iter: 345 loss: 5.43294732e-07
Iter: 346 loss: 5.43832243e-07
Iter: 347 loss: 5.43239253e-07
Iter: 348 loss: 5.4305292e-07
Iter: 349 loss: 5.45753153e-07
Iter: 350 loss: 5.43047406e-07
Iter: 351 loss: 5.42900239e-07
Iter: 352 loss: 5.42686394e-07
Iter: 353 loss: 5.42710268e-07
Iter: 354 loss: 5.42515863e-07
Iter: 355 loss: 5.43158421e-07
Iter: 356 loss: 5.42477324e-07
Iter: 357 loss: 5.42298096e-07
Iter: 358 loss: 5.44966099e-07
Iter: 359 loss: 5.42282e-07
Iter: 360 loss: 5.4220834e-07
Iter: 361 loss: 5.43235956e-07
Iter: 362 loss: 5.42208625e-07
Iter: 363 loss: 5.42142061e-07
Iter: 364 loss: 5.4205e-07
Iter: 365 loss: 5.42048497e-07
Iter: 366 loss: 5.41888369e-07
Iter: 367 loss: 5.41649229e-07
Iter: 368 loss: 5.45891453e-07
Iter: 369 loss: 5.4160796e-07
Iter: 370 loss: 5.41347845e-07
Iter: 371 loss: 5.42062821e-07
Iter: 372 loss: 5.41272811e-07
Iter: 373 loss: 5.41296572e-07
Iter: 374 loss: 5.41166912e-07
Iter: 375 loss: 5.41103134e-07
Iter: 376 loss: 5.4095392e-07
Iter: 377 loss: 5.40924e-07
Iter: 378 loss: 5.40777251e-07
Iter: 379 loss: 5.41221823e-07
Iter: 380 loss: 5.40724727e-07
Iter: 381 loss: 5.40587052e-07
Iter: 382 loss: 5.40366614e-07
Iter: 383 loss: 5.40349788e-07
Iter: 384 loss: 5.40112353e-07
Iter: 385 loss: 5.43503802e-07
Iter: 386 loss: 5.40129179e-07
Iter: 387 loss: 5.39936195e-07
Iter: 388 loss: 5.4063139e-07
Iter: 389 loss: 5.39897258e-07
Iter: 390 loss: 5.39755547e-07
Iter: 391 loss: 5.41165093e-07
Iter: 392 loss: 5.39692e-07
Iter: 393 loss: 5.39591497e-07
Iter: 394 loss: 5.39430914e-07
Iter: 395 loss: 5.39435121e-07
Iter: 396 loss: 5.39458142e-07
Iter: 397 loss: 5.39337634e-07
Iter: 398 loss: 5.3927738e-07
Iter: 399 loss: 5.39199277e-07
Iter: 400 loss: 5.39188363e-07
Iter: 401 loss: 5.39067742e-07
Iter: 402 loss: 5.39389248e-07
Iter: 403 loss: 5.39028065e-07
Iter: 404 loss: 5.38948029e-07
Iter: 405 loss: 5.39030509e-07
Iter: 406 loss: 5.38865095e-07
Iter: 407 loss: 5.38780569e-07
Iter: 408 loss: 5.39818075e-07
Iter: 409 loss: 5.38782729e-07
Iter: 410 loss: 5.38686095e-07
Iter: 411 loss: 5.38693371e-07
Iter: 412 loss: 5.38601626e-07
Iter: 413 loss: 5.38529036e-07
Iter: 414 loss: 5.38372774e-07
Iter: 415 loss: 5.38363565e-07
Iter: 416 loss: 5.38253687e-07
Iter: 417 loss: 5.3954534e-07
Iter: 418 loss: 5.3821725e-07
Iter: 419 loss: 5.38148925e-07
Iter: 420 loss: 5.38083896e-07
Iter: 421 loss: 5.3803393e-07
Iter: 422 loss: 5.37918652e-07
Iter: 423 loss: 5.38826555e-07
Iter: 424 loss: 5.37891765e-07
Iter: 425 loss: 5.37798769e-07
Iter: 426 loss: 5.37810479e-07
Iter: 427 loss: 5.37722315e-07
Iter: 428 loss: 5.37812923e-07
Iter: 429 loss: 5.37689289e-07
Iter: 430 loss: 5.3764137e-07
Iter: 431 loss: 5.38564279e-07
Iter: 432 loss: 5.37640631e-07
Iter: 433 loss: 5.37554229e-07
Iter: 434 loss: 5.37476922e-07
Iter: 435 loss: 5.39010102e-07
Iter: 436 loss: 5.37434289e-07
Iter: 437 loss: 5.37322421e-07
Iter: 438 loss: 5.38450251e-07
Iter: 439 loss: 5.37330266e-07
Iter: 440 loss: 5.3722772e-07
Iter: 441 loss: 5.37089363e-07
Iter: 442 loss: 5.37082769e-07
Iter: 443 loss: 5.3704764e-07
Iter: 444 loss: 5.3699e-07
Iter: 445 loss: 5.36939183e-07
Iter: 446 loss: 5.3680327e-07
Iter: 447 loss: 5.36800542e-07
Iter: 448 loss: 5.36633934e-07
Iter: 449 loss: 5.36593404e-07
Iter: 450 loss: 5.36489836e-07
Iter: 451 loss: 5.36343691e-07
Iter: 452 loss: 5.36395532e-07
Iter: 453 loss: 5.36224093e-07
Iter: 454 loss: 5.36057655e-07
Iter: 455 loss: 5.36920652e-07
Iter: 456 loss: 5.36054927e-07
Iter: 457 loss: 5.35942377e-07
Iter: 458 loss: 5.36531275e-07
Iter: 459 loss: 5.35902302e-07
Iter: 460 loss: 5.3577304e-07
Iter: 461 loss: 5.36570496e-07
Iter: 462 loss: 5.35806691e-07
Iter: 463 loss: 5.3574604e-07
Iter: 464 loss: 5.36036566e-07
Iter: 465 loss: 5.35755817e-07
Iter: 466 loss: 5.35695449e-07
Iter: 467 loss: 5.35984327e-07
Iter: 468 loss: 5.35703066e-07
Iter: 469 loss: 5.35620757e-07
Iter: 470 loss: 5.35538049e-07
Iter: 471 loss: 5.36718858e-07
Iter: 472 loss: 5.35519405e-07
Iter: 473 loss: 5.35470406e-07
Iter: 474 loss: 5.35468246e-07
Iter: 475 loss: 5.35391791e-07
Iter: 476 loss: 5.35425102e-07
Iter: 477 loss: 5.35331765e-07
Iter: 478 loss: 5.35287199e-07
Iter: 479 loss: 5.354824e-07
Iter: 480 loss: 5.35239565e-07
Iter: 481 loss: 5.35167942e-07
Iter: 482 loss: 5.35835113e-07
Iter: 483 loss: 5.351921e-07
Iter: 484 loss: 5.3512457e-07
Iter: 485 loss: 5.34974333e-07
Iter: 486 loss: 5.36907351e-07
Iter: 487 loss: 5.35002869e-07
Iter: 488 loss: 5.34840296e-07
Iter: 489 loss: 5.35155e-07
Iter: 490 loss: 5.34784192e-07
Iter: 491 loss: 5.34638104e-07
Iter: 492 loss: 5.352573e-07
Iter: 493 loss: 5.34583933e-07
Iter: 494 loss: 5.34491448e-07
Iter: 495 loss: 5.34611104e-07
Iter: 496 loss: 5.34422384e-07
Iter: 497 loss: 5.34321543e-07
Iter: 498 loss: 5.34305912e-07
Iter: 499 loss: 5.3426561e-07
Iter: 500 loss: 5.34681362e-07
Iter: 501 loss: 5.34264e-07
Iter: 502 loss: 5.34230367e-07
Iter: 503 loss: 5.34158914e-07
Iter: 504 loss: 5.34145e-07
Iter: 505 loss: 5.34070409e-07
Iter: 506 loss: 5.33990715e-07
Iter: 507 loss: 5.33970479e-07
Iter: 508 loss: 5.33864522e-07
Iter: 509 loss: 5.35095637e-07
Iter: 510 loss: 5.33851562e-07
Iter: 511 loss: 5.33769e-07
Iter: 512 loss: 5.3378028e-07
Iter: 513 loss: 5.336708e-07
Iter: 514 loss: 5.3356e-07
Iter: 515 loss: 5.3397e-07
Iter: 516 loss: 5.33559046e-07
Iter: 517 loss: 5.3340807e-07
Iter: 518 loss: 5.34063702e-07
Iter: 519 loss: 5.33342472e-07
Iter: 520 loss: 5.33245725e-07
Iter: 521 loss: 5.33210198e-07
Iter: 522 loss: 5.33149887e-07
Iter: 523 loss: 5.33060188e-07
Iter: 524 loss: 5.33171772e-07
Iter: 525 loss: 5.32999081e-07
Iter: 526 loss: 5.32869137e-07
Iter: 527 loss: 5.33316552e-07
Iter: 528 loss: 5.32854415e-07
Iter: 529 loss: 5.32776767e-07
Iter: 530 loss: 5.32802062e-07
Iter: 531 loss: 5.32743911e-07
Iter: 532 loss: 5.32971626e-07
Iter: 533 loss: 5.32724243e-07
Iter: 534 loss: 5.32667286e-07
Iter: 535 loss: 5.32692297e-07
Iter: 536 loss: 5.32626814e-07
Iter: 537 loss: 5.32579918e-07
Iter: 538 loss: 5.32552463e-07
Iter: 539 loss: 5.32501531e-07
Iter: 540 loss: 5.3243707e-07
Iter: 541 loss: 5.32408308e-07
Iter: 542 loss: 5.32343961e-07
Iter: 543 loss: 5.32279046e-07
Iter: 544 loss: 5.3228041e-07
Iter: 545 loss: 5.32207196e-07
Iter: 546 loss: 5.320843e-07
Iter: 547 loss: 5.32099e-07
Iter: 548 loss: 5.31991077e-07
Iter: 549 loss: 5.32776937e-07
Iter: 550 loss: 5.3196203e-07
Iter: 551 loss: 5.3183993e-07
Iter: 552 loss: 5.32626359e-07
Iter: 553 loss: 5.31834132e-07
Iter: 554 loss: 5.31780415e-07
Iter: 555 loss: 5.31571573e-07
Iter: 556 loss: 5.32984927e-07
Iter: 557 loss: 5.31494436e-07
Iter: 558 loss: 5.31294631e-07
Iter: 559 loss: 5.32401828e-07
Iter: 560 loss: 5.31291903e-07
Iter: 561 loss: 5.31147862e-07
Iter: 562 loss: 5.32377612e-07
Iter: 563 loss: 5.31140245e-07
Iter: 564 loss: 5.31013541e-07
Iter: 565 loss: 5.31778198e-07
Iter: 566 loss: 5.30994043e-07
Iter: 567 loss: 5.30869215e-07
Iter: 568 loss: 5.31467549e-07
Iter: 569 loss: 5.30849e-07
Iter: 570 loss: 5.30767295e-07
Iter: 571 loss: 5.30882062e-07
Iter: 572 loss: 5.3074541e-07
Iter: 573 loss: 5.3066708e-07
Iter: 574 loss: 5.30545776e-07
Iter: 575 loss: 5.30548164e-07
Iter: 576 loss: 5.30426746e-07
Iter: 577 loss: 5.31788714e-07
Iter: 578 loss: 5.30390707e-07
Iter: 579 loss: 5.30287593e-07
Iter: 580 loss: 5.30521106e-07
Iter: 581 loss: 5.30201532e-07
Iter: 582 loss: 5.30156967e-07
Iter: 583 loss: 5.30521334e-07
Iter: 584 loss: 5.3012144e-07
Iter: 585 loss: 5.30085e-07
Iter: 586 loss: 5.30543048e-07
Iter: 587 loss: 5.30064654e-07
Iter: 588 loss: 5.30039358e-07
Iter: 589 loss: 5.29918736e-07
Iter: 590 loss: 5.29922772e-07
Iter: 591 loss: 5.29866327e-07
Iter: 592 loss: 5.29827162e-07
Iter: 593 loss: 5.29792601e-07
Iter: 594 loss: 5.29665954e-07
Iter: 595 loss: 5.30261104e-07
Iter: 596 loss: 5.29628664e-07
Iter: 597 loss: 5.29564886e-07
Iter: 598 loss: 5.29771e-07
Iter: 599 loss: 5.29536237e-07
Iter: 600 loss: 5.29411295e-07
Iter: 601 loss: 5.29410499e-07
Iter: 602 loss: 5.29342913e-07
Iter: 603 loss: 5.29278225e-07
Iter: 604 loss: 5.29279248e-07
Iter: 605 loss: 5.29145836e-07
Iter: 606 loss: 5.2921024e-07
Iter: 607 loss: 5.2906455e-07
Iter: 608 loss: 5.28949272e-07
Iter: 609 loss: 5.29117528e-07
Iter: 610 loss: 5.2888447e-07
Iter: 611 loss: 5.28759756e-07
Iter: 612 loss: 5.30147076e-07
Iter: 613 loss: 5.28777719e-07
Iter: 614 loss: 5.28663577e-07
Iter: 615 loss: 5.28761802e-07
Iter: 616 loss: 5.28632938e-07
Iter: 617 loss: 5.28525e-07
Iter: 618 loss: 5.29115e-07
Iter: 619 loss: 5.2849191e-07
Iter: 620 loss: 5.28436e-07
Iter: 621 loss: 5.28701491e-07
Iter: 622 loss: 5.28402e-07
Iter: 623 loss: 5.28364239e-07
Iter: 624 loss: 5.28260671e-07
Iter: 625 loss: 5.30066927e-07
Iter: 626 loss: 5.28267151e-07
Iter: 627 loss: 5.28217242e-07
Iter: 628 loss: 5.28571832e-07
Iter: 629 loss: 5.28144142e-07
Iter: 630 loss: 5.28074111e-07
Iter: 631 loss: 5.2837413e-07
Iter: 632 loss: 5.28053761e-07
Iter: 633 loss: 5.28015164e-07
Iter: 634 loss: 5.28021076e-07
Iter: 635 loss: 5.27985378e-07
Iter: 636 loss: 5.27932059e-07
Iter: 637 loss: 5.2792052e-07
Iter: 638 loss: 5.27845714e-07
Iter: 639 loss: 5.27975089e-07
Iter: 640 loss: 5.27825307e-07
Iter: 641 loss: 5.27763689e-07
Iter: 642 loss: 5.27736916e-07
Iter: 643 loss: 5.27723557e-07
Iter: 644 loss: 5.2762573e-07
Iter: 645 loss: 5.28460646e-07
Iter: 646 loss: 5.27586451e-07
Iter: 647 loss: 5.27548423e-07
Iter: 648 loss: 5.27485724e-07
Iter: 649 loss: 5.2745844e-07
Iter: 650 loss: 5.27357429e-07
Iter: 651 loss: 5.28674661e-07
Iter: 652 loss: 5.27360271e-07
Iter: 653 loss: 5.27301e-07
Iter: 654 loss: 5.27753855e-07
Iter: 655 loss: 5.27297971e-07
Iter: 656 loss: 5.27202303e-07
Iter: 657 loss: 5.27098337e-07
Iter: 658 loss: 5.28340365e-07
Iter: 659 loss: 5.27113343e-07
Iter: 660 loss: 5.26934969e-07
Iter: 661 loss: 5.27529266e-07
Iter: 662 loss: 5.26907684e-07
Iter: 663 loss: 5.26775921e-07
Iter: 664 loss: 5.27289899e-07
Iter: 665 loss: 5.26752615e-07
Iter: 666 loss: 5.26645238e-07
Iter: 667 loss: 5.27523355e-07
Iter: 668 loss: 5.26615736e-07
Iter: 669 loss: 5.26507677e-07
Iter: 670 loss: 5.2714995e-07
Iter: 671 loss: 5.26481585e-07
Iter: 672 loss: 5.26441966e-07
Iter: 673 loss: 5.2659243e-07
Iter: 674 loss: 5.2641883e-07
Iter: 675 loss: 5.26358576e-07
Iter: 676 loss: 5.26256258e-07
Iter: 677 loss: 5.26259839e-07
Iter: 678 loss: 5.26185318e-07
Iter: 679 loss: 5.2718957e-07
Iter: 680 loss: 5.26177473e-07
Iter: 681 loss: 5.26081408e-07
Iter: 682 loss: 5.26241877e-07
Iter: 683 loss: 5.26044687e-07
Iter: 684 loss: 5.26016663e-07
Iter: 685 loss: 5.26122108e-07
Iter: 686 loss: 5.25944358e-07
Iter: 687 loss: 5.25852329e-07
Iter: 688 loss: 5.25875407e-07
Iter: 689 loss: 5.25855512e-07
Iter: 690 loss: 5.25784e-07
Iter: 691 loss: 5.25797645e-07
Iter: 692 loss: 5.25676228e-07
Iter: 693 loss: 5.25604833e-07
Iter: 694 loss: 5.25599773e-07
Iter: 695 loss: 5.25481369e-07
Iter: 696 loss: 5.26388874e-07
Iter: 697 loss: 5.25500241e-07
Iter: 698 loss: 5.25374844e-07
Iter: 699 loss: 5.25508142e-07
Iter: 700 loss: 5.25331302e-07
Iter: 701 loss: 5.25250584e-07
Iter: 702 loss: 5.25226596e-07
Iter: 703 loss: 5.25206417e-07
Iter: 704 loss: 5.2515e-07
Iter: 705 loss: 5.2515793e-07
Iter: 706 loss: 5.25079e-07
Iter: 707 loss: 5.25156054e-07
Iter: 708 loss: 5.25045493e-07
Iter: 709 loss: 5.24965344e-07
Iter: 710 loss: 5.25345683e-07
Iter: 711 loss: 5.24931352e-07
Iter: 712 loss: 5.24859729e-07
Iter: 713 loss: 5.24964491e-07
Iter: 714 loss: 5.24833354e-07
Iter: 715 loss: 5.24718644e-07
Iter: 716 loss: 5.24948859e-07
Iter: 717 loss: 5.24713641e-07
Iter: 718 loss: 5.24653785e-07
Iter: 719 loss: 5.25067605e-07
Iter: 720 loss: 5.24638551e-07
Iter: 721 loss: 5.24570225e-07
Iter: 722 loss: 5.24574943e-07
Iter: 723 loss: 5.24471375e-07
Iter: 724 loss: 5.24378379e-07
Iter: 725 loss: 5.24374627e-07
Iter: 726 loss: 5.24370137e-07
Iter: 727 loss: 5.24274128e-07
Iter: 728 loss: 5.24575739e-07
Iter: 729 loss: 5.2420728e-07
Iter: 730 loss: 5.2411508e-07
Iter: 731 loss: 5.24304141e-07
Iter: 732 loss: 5.24082e-07
Iter: 733 loss: 5.24076e-07
Iter: 734 loss: 5.24027087e-07
Iter: 735 loss: 5.23960693e-07
Iter: 736 loss: 5.23886399e-07
Iter: 737 loss: 5.24643042e-07
Iter: 738 loss: 5.23885205e-07
Iter: 739 loss: 5.23800963e-07
Iter: 740 loss: 5.24629627e-07
Iter: 741 loss: 5.23804943e-07
Iter: 742 loss: 5.23728318e-07
Iter: 743 loss: 5.23769643e-07
Iter: 744 loss: 5.23698873e-07
Iter: 745 loss: 5.23639073e-07
Iter: 746 loss: 5.23914139e-07
Iter: 747 loss: 5.23635549e-07
Iter: 748 loss: 5.23563699e-07
Iter: 749 loss: 5.23539484e-07
Iter: 750 loss: 5.23518679e-07
Iter: 751 loss: 5.23425911e-07
Iter: 752 loss: 5.23774702e-07
Iter: 753 loss: 5.23445919e-07
Iter: 754 loss: 5.23387712e-07
Iter: 755 loss: 5.23561368e-07
Iter: 756 loss: 5.23362473e-07
Iter: 757 loss: 5.23318818e-07
Iter: 758 loss: 5.23197969e-07
Iter: 759 loss: 5.24950565e-07
Iter: 760 loss: 5.23224458e-07
Iter: 761 loss: 5.2305586e-07
Iter: 762 loss: 5.23627364e-07
Iter: 763 loss: 5.23003223e-07
Iter: 764 loss: 5.22867538e-07
Iter: 765 loss: 5.23384472e-07
Iter: 766 loss: 5.22833147e-07
Iter: 767 loss: 5.22807227e-07
Iter: 768 loss: 5.23783967e-07
Iter: 769 loss: 5.22792561e-07
Iter: 770 loss: 5.2268507e-07
Iter: 771 loss: 5.22877826e-07
Iter: 772 loss: 5.22631069e-07
Iter: 773 loss: 5.22589858e-07
Iter: 774 loss: 5.22697e-07
Iter: 775 loss: 5.22556093e-07
Iter: 776 loss: 5.2249743e-07
Iter: 777 loss: 5.22507889e-07
Iter: 778 loss: 5.22449909e-07
Iter: 779 loss: 5.22352821e-07
Iter: 780 loss: 5.22868618e-07
Iter: 781 loss: 5.22344862e-07
Iter: 782 loss: 5.2227665e-07
Iter: 783 loss: 5.22427911e-07
Iter: 784 loss: 5.22264372e-07
Iter: 785 loss: 5.22158075e-07
Iter: 786 loss: 5.22351627e-07
Iter: 787 loss: 5.22185132e-07
Iter: 788 loss: 5.22086907e-07
Iter: 789 loss: 5.22364815e-07
Iter: 790 loss: 5.22079176e-07
Iter: 791 loss: 5.22006303e-07
Iter: 792 loss: 5.21955258e-07
Iter: 793 loss: 5.21938887e-07
Iter: 794 loss: 5.21848e-07
Iter: 795 loss: 5.21917627e-07
Iter: 796 loss: 5.21795243e-07
Iter: 797 loss: 5.21713332e-07
Iter: 798 loss: 5.22228333e-07
Iter: 799 loss: 5.21730669e-07
Iter: 800 loss: 5.21638469e-07
Iter: 801 loss: 5.21717539e-07
Iter: 802 loss: 5.2161937e-07
Iter: 803 loss: 5.21640459e-07
Iter: 804 loss: 5.21556e-07
Iter: 805 loss: 5.21569177e-07
Iter: 806 loss: 5.21571565e-07
Iter: 807 loss: 5.2156156e-07
Iter: 808 loss: 5.21562527e-07
Iter: 809 loss: 5.21563152e-07
Iter: 810 loss: 5.21549737e-07
Iter: 811 loss: 5.2156139e-07
Iter: 812 loss: 5.21533934e-07
Iter: 813 loss: 5.21571792e-07
Iter: 814 loss: 5.2155707e-07
Iter: 815 loss: 5.21539732e-07
Iter: 816 loss: 5.21551783e-07
Iter: 817 loss: 5.21552181e-07
Iter: 818 loss: 5.21551328e-07
Iter: 819 loss: 5.21557922e-07
Iter: 820 loss: 5.2155292e-07
Iter: 821 loss: 5.21556558e-07
Iter: 822 loss: 5.21553034e-07
Iter: 823 loss: 5.21556103e-07
Iter: 824 loss: 5.21556331e-07
Iter: 825 loss: 5.21556387e-07
Iter: 826 loss: 5.21556331e-07
Iter: 827 loss: 5.21556501e-07
Iter: 828 loss: 5.21556558e-07
Iter: 829 loss: 5.21556558e-07
Iter: 830 loss: 5.21556558e-07
Iter: 831 loss: 5.21556558e-07
Iter: 832 loss: 5.21556501e-07
Iter: 833 loss: 5.21556501e-07
Iter: 834 loss: 5.21556558e-07
Iter: 835 loss: 5.2176415e-07
Iter: 836 loss: 5.21498123e-07
Iter: 837 loss: 5.21428944e-07
Iter: 838 loss: 5.21446736e-07
Iter: 839 loss: 5.21372044e-07
Iter: 840 loss: 5.21397851e-07
Iter: 841 loss: 5.21354195e-07
Iter: 842 loss: 5.21281e-07
Iter: 843 loss: 5.21259722e-07
Iter: 844 loss: 5.21211462e-07
Iter: 845 loss: 5.2116377e-07
Iter: 846 loss: 5.21732318e-07
Iter: 847 loss: 5.21129891e-07
Iter: 848 loss: 5.21074867e-07
Iter: 849 loss: 5.21385289e-07
Iter: 850 loss: 5.21057189e-07
Iter: 851 loss: 5.20944809e-07
Iter: 852 loss: 5.21098798e-07
Iter: 853 loss: 5.20929234e-07
Iter: 854 loss: 5.20835499e-07
Iter: 855 loss: 5.21090897e-07
Iter: 856 loss: 5.20822312e-07
Iter: 857 loss: 5.20734488e-07
Iter: 858 loss: 5.2146595e-07
Iter: 859 loss: 5.20720732e-07
Iter: 860 loss: 5.20668095e-07
Iter: 861 loss: 5.20543949e-07
Iter: 862 loss: 5.22557116e-07
Iter: 863 loss: 5.20516437e-07
Iter: 864 loss: 5.20452431e-07
Iter: 865 loss: 5.20850733e-07
Iter: 866 loss: 5.20420826e-07
Iter: 867 loss: 5.2044e-07
Iter: 868 loss: 5.20409344e-07
Iter: 869 loss: 5.20377284e-07
Iter: 870 loss: 5.2031e-07
Iter: 871 loss: 5.21522679e-07
Iter: 872 loss: 5.20309641e-07
Iter: 873 loss: 5.20276387e-07
Iter: 874 loss: 5.202387e-07
Iter: 875 loss: 5.20212325e-07
Iter: 876 loss: 5.20132119e-07
Iter: 877 loss: 5.20443564e-07
Iter: 878 loss: 5.20115407e-07
Iter: 879 loss: 5.20047479e-07
Iter: 880 loss: 5.20061519e-07
Iter: 881 loss: 5.20022354e-07
Iter: 882 loss: 5.20047649e-07
Iter: 883 loss: 5.19991715e-07
Iter: 884 loss: 5.19931064e-07
Iter: 885 loss: 5.2000064e-07
Iter: 886 loss: 5.19928562e-07
Iter: 887 loss: 5.19865353e-07
Iter: 888 loss: 5.20458116e-07
Iter: 889 loss: 5.19860919e-07
Iter: 890 loss: 5.19813739e-07
Iter: 891 loss: 5.19841478e-07
Iter: 892 loss: 5.19815671e-07
Iter: 893 loss: 5.19763262e-07
Iter: 894 loss: 5.19795321e-07
Iter: 895 loss: 5.19686182e-07
Iter: 896 loss: 5.19658e-07
Iter: 897 loss: 5.19651337e-07
Iter: 898 loss: 5.19619334e-07
Iter: 899 loss: 5.19598586e-07
Iter: 900 loss: 5.19605e-07
Iter: 901 loss: 5.19542311e-07
Iter: 902 loss: 5.19459e-07
Iter: 903 loss: 5.19437151e-07
Iter: 904 loss: 5.19348589e-07
Iter: 905 loss: 5.19359162e-07
Iter: 906 loss: 5.19303e-07
Iter: 907 loss: 5.19291461e-07
Iter: 908 loss: 5.19263324e-07
Iter: 909 loss: 5.19162654e-07
Iter: 910 loss: 5.20350113e-07
Iter: 911 loss: 5.1916868e-07
Iter: 912 loss: 5.19088928e-07
Iter: 913 loss: 5.19344667e-07
Iter: 914 loss: 5.19041237e-07
Iter: 915 loss: 5.18980528e-07
Iter: 916 loss: 5.19415266e-07
Iter: 917 loss: 5.18964725e-07
Iter: 918 loss: 5.1886559e-07
Iter: 919 loss: 5.18900151e-07
Iter: 920 loss: 5.18845695e-07
Iter: 921 loss: 5.18783736e-07
Iter: 922 loss: 5.19303285e-07
Iter: 923 loss: 5.18747811e-07
Iter: 924 loss: 5.18700631e-07
Iter: 925 loss: 5.19021683e-07
Iter: 926 loss: 5.18688864e-07
Iter: 927 loss: 5.18652882e-07
Iter: 928 loss: 5.18597858e-07
Iter: 929 loss: 5.18609909e-07
Iter: 930 loss: 5.18544368e-07
Iter: 931 loss: 5.18538229e-07
Iter: 932 loss: 5.18492527e-07
Iter: 933 loss: 5.18593822e-07
Iter: 934 loss: 5.18472916e-07
Iter: 935 loss: 5.18398394e-07
Iter: 936 loss: 5.18374e-07
Iter: 937 loss: 5.18345246e-07
Iter: 938 loss: 5.18315233e-07
Iter: 939 loss: 5.18644e-07
Iter: 940 loss: 5.18282718e-07
Iter: 941 loss: 5.18247646e-07
Iter: 942 loss: 5.18251795e-07
Iter: 943 loss: 5.18228433e-07
Iter: 944 loss: 5.18182048e-07
Iter: 945 loss: 5.18547949e-07
Iter: 946 loss: 5.18202853e-07
Iter: 947 loss: 5.18154138e-07
Iter: 948 loss: 5.18117304e-07
Iter: 949 loss: 5.18110937e-07
Iter: 950 loss: 5.18032721e-07
Iter: 951 loss: 5.18035904e-07
Iter: 952 loss: 5.17992703e-07
Iter: 953 loss: 5.17917783e-07
Iter: 954 loss: 5.19501e-07
Iter: 955 loss: 5.17892317e-07
Iter: 956 loss: 5.17791818e-07
Iter: 957 loss: 5.18127308e-07
Iter: 958 loss: 5.17759645e-07
Iter: 959 loss: 5.17678473e-07
Iter: 960 loss: 5.18455806e-07
Iter: 961 loss: 5.17691262e-07
Iter: 962 loss: 5.17620037e-07
Iter: 963 loss: 5.17567287e-07
Iter: 964 loss: 5.17510443e-07
Iter: 965 loss: 5.17438423e-07
Iter: 966 loss: 5.17430806e-07
Iter: 967 loss: 5.17389367e-07
Iter: 968 loss: 5.17480828e-07
Iter: 969 loss: 5.17342869e-07
Iter: 970 loss: 5.17282729e-07
Iter: 971 loss: 5.17220315e-07
Iter: 972 loss: 5.17203318e-07
Iter: 973 loss: 5.17105946e-07
Iter: 974 loss: 5.18397087e-07
Iter: 975 loss: 5.17120895e-07
Iter: 976 loss: 5.17014655e-07
Iter: 977 loss: 5.17724175e-07
Iter: 978 loss: 5.17024546e-07
Iter: 979 loss: 5.16986233e-07
Iter: 980 loss: 5.16879936e-07
Iter: 981 loss: 5.17627029e-07
Iter: 982 loss: 5.16875389e-07
Iter: 983 loss: 5.1680496e-07
Iter: 984 loss: 5.17494698e-07
Iter: 985 loss: 5.16791488e-07
Iter: 986 loss: 5.16707814e-07
Iter: 987 loss: 5.17161823e-07
Iter: 988 loss: 5.16738226e-07
Iter: 989 loss: 5.1666234e-07
Iter: 990 loss: 5.16693717e-07
Iter: 991 loss: 5.16604928e-07
Iter: 992 loss: 5.16570424e-07
Iter: 993 loss: 5.16507498e-07
Iter: 994 loss: 5.1645e-07
Iter: 995 loss: 5.1635692e-07
Iter: 996 loss: 5.1761009e-07
Iter: 997 loss: 5.16371529e-07
Iter: 998 loss: 5.16336968e-07
Iter: 999 loss: 5.16356408e-07
Iter: 1000 loss: 5.16300872e-07
Iter: 1001 loss: 5.16240789e-07
Iter: 1002 loss: 5.16618456e-07
Iter: 1003 loss: 5.16204409e-07
Iter: 1004 loss: 5.1614029e-07
Iter: 1005 loss: 5.16305192e-07
Iter: 1006 loss: 5.16124942e-07
Iter: 1007 loss: 5.16048431e-07
Iter: 1008 loss: 5.16007219e-07
Iter: 1009 loss: 5.16013927e-07
Iter: 1010 loss: 5.15939632e-07
Iter: 1011 loss: 5.1630127e-07
Iter: 1012 loss: 5.15910529e-07
Iter: 1013 loss: 5.15814349e-07
Iter: 1014 loss: 5.15983345e-07
Iter: 1015 loss: 5.15772285e-07
Iter: 1016 loss: 5.15700094e-07
Iter: 1017 loss: 5.15615511e-07
Iter: 1018 loss: 5.15620798e-07
Iter: 1019 loss: 5.15502734e-07
Iter: 1020 loss: 5.15411898e-07
Iter: 1021 loss: 5.15357613e-07
Iter: 1022 loss: 5.15185206e-07
Iter: 1023 loss: 5.16939508e-07
Iter: 1024 loss: 5.15186571e-07
Iter: 1025 loss: 5.15014904e-07
Iter: 1026 loss: 5.15197542e-07
Iter: 1027 loss: 5.14974829e-07
Iter: 1028 loss: 5.14874273e-07
Iter: 1029 loss: 5.14865576e-07
Iter: 1030 loss: 5.14803787e-07
Iter: 1031 loss: 5.1487541e-07
Iter: 1032 loss: 5.14751605e-07
Iter: 1033 loss: 5.14677595e-07
Iter: 1034 loss: 5.14768431e-07
Iter: 1035 loss: 5.14640305e-07
Iter: 1036 loss: 5.14574708e-07
Iter: 1037 loss: 5.15500119e-07
Iter: 1038 loss: 5.14537874e-07
Iter: 1039 loss: 5.14482281e-07
Iter: 1040 loss: 5.14458861e-07
Iter: 1041 loss: 5.14423959e-07
Iter: 1042 loss: 5.1440162e-07
Iter: 1043 loss: 5.1482732e-07
Iter: 1044 loss: 5.14380304e-07
Iter: 1045 loss: 5.14360181e-07
Iter: 1046 loss: 5.14708347e-07
Iter: 1047 loss: 5.14336762e-07
Iter: 1048 loss: 5.14294868e-07
Iter: 1049 loss: 5.14202554e-07
Iter: 1050 loss: 5.14936801e-07
Iter: 1051 loss: 5.14173109e-07
Iter: 1052 loss: 5.14138321e-07
Iter: 1053 loss: 5.14871317e-07
Iter: 1054 loss: 5.14134229e-07
Iter: 1055 loss: 5.14066642e-07
Iter: 1056 loss: 5.14284466e-07
Iter: 1057 loss: 5.1402958e-07
Iter: 1058 loss: 5.13987288e-07
Iter: 1059 loss: 5.13898101e-07
Iter: 1060 loss: 5.13928683e-07
Iter: 1061 loss: 5.13818122e-07
Iter: 1062 loss: 5.14542933e-07
Iter: 1063 loss: 5.13819032e-07
Iter: 1064 loss: 5.1373604e-07
Iter: 1065 loss: 5.1368994e-07
Iter: 1066 loss: 5.13663622e-07
Iter: 1067 loss: 5.1359325e-07
Iter: 1068 loss: 5.13559542e-07
Iter: 1069 loss: 5.13522707e-07
Iter: 1070 loss: 5.13531177e-07
Iter: 1071 loss: 5.13462055e-07
Iter: 1072 loss: 5.13389068e-07
Iter: 1073 loss: 5.13985924e-07
Iter: 1074 loss: 5.13402881e-07
Iter: 1075 loss: 5.13311875e-07
Iter: 1076 loss: 5.13457678e-07
Iter: 1077 loss: 5.13297323e-07
Iter: 1078 loss: 5.13210807e-07
Iter: 1079 loss: 5.13189775e-07
Iter: 1080 loss: 5.13119232e-07
Iter: 1081 loss: 5.13097802e-07
Iter: 1082 loss: 5.13071143e-07
Iter: 1083 loss: 5.13046e-07
Iter: 1084 loss: 5.12953534e-07
Iter: 1085 loss: 5.13574719e-07
Iter: 1086 loss: 5.12942165e-07
Iter: 1087 loss: 5.12881684e-07
Iter: 1088 loss: 5.13014e-07
Iter: 1089 loss: 5.12820179e-07
Iter: 1090 loss: 5.12745032e-07
Iter: 1091 loss: 5.13046189e-07
Iter: 1092 loss: 5.12751285e-07
Iter: 1093 loss: 5.12665792e-07
Iter: 1094 loss: 5.13189605e-07
Iter: 1095 loss: 5.12652548e-07
Iter: 1096 loss: 5.12604288e-07
Iter: 1097 loss: 5.12584165e-07
Iter: 1098 loss: 5.12526185e-07
Iter: 1099 loss: 5.12435122e-07
Iter: 1100 loss: 5.12616396e-07
Iter: 1101 loss: 5.12410907e-07
Iter: 1102 loss: 5.12323254e-07
Iter: 1103 loss: 5.1290516e-07
Iter: 1104 loss: 5.12299096e-07
Iter: 1105 loss: 5.1219132e-07
Iter: 1106 loss: 5.12291649e-07
Iter: 1107 loss: 5.12171709e-07
Iter: 1108 loss: 5.12128338e-07
Iter: 1109 loss: 5.12505721e-07
Iter: 1110 loss: 5.12123961e-07
Iter: 1111 loss: 5.12036195e-07
Iter: 1112 loss: 5.11972416e-07
Iter: 1113 loss: 5.11945132e-07
Iter: 1114 loss: 5.11922394e-07
Iter: 1115 loss: 5.11918245e-07
Iter: 1116 loss: 5.11874873e-07
Iter: 1117 loss: 5.11811095e-07
Iter: 1118 loss: 5.11799726e-07
Iter: 1119 loss: 5.11715939e-07
Iter: 1120 loss: 5.1173032e-07
Iter: 1121 loss: 5.11656935e-07
Iter: 1122 loss: 5.11608164e-07
Iter: 1123 loss: 5.11742655e-07
Iter: 1124 loss: 5.11539724e-07
Iter: 1125 loss: 5.11453209e-07
Iter: 1126 loss: 5.12139195e-07
Iter: 1127 loss: 5.11469239e-07
Iter: 1128 loss: 5.11420694e-07
Iter: 1129 loss: 5.11677e-07
Iter: 1130 loss: 5.11399776e-07
Iter: 1131 loss: 5.11305188e-07
Iter: 1132 loss: 5.11319342e-07
Iter: 1133 loss: 5.11281883e-07
Iter: 1134 loss: 5.11209464e-07
Iter: 1135 loss: 5.11033477e-07
Iter: 1136 loss: 5.1373911e-07
Iter: 1137 loss: 5.11033136e-07
Iter: 1138 loss: 5.11207247e-07
Iter: 1139 loss: 5.11014946e-07
Iter: 1140 loss: 5.1099903e-07
Iter: 1141 loss: 5.10917857e-07
Iter: 1142 loss: 5.1218268e-07
Iter: 1143 loss: 5.10929226e-07
Iter: 1144 loss: 5.10872042e-07
Iter: 1145 loss: 5.11380506e-07
Iter: 1146 loss: 5.10817301e-07
Iter: 1147 loss: 5.10765176e-07
Iter: 1148 loss: 5.10999257e-07
Iter: 1149 loss: 5.10758184e-07
Iter: 1150 loss: 5.10759946e-07
Iter: 1151 loss: 5.10754546e-07
Iter: 1152 loss: 5.10729706e-07
Iter: 1153 loss: 5.10755399e-07
Iter: 1154 loss: 5.10735e-07
Iter: 1155 loss: 5.10739653e-07
Iter: 1156 loss: 5.10759e-07
Iter: 1157 loss: 5.10741131e-07
Iter: 1158 loss: 5.10744769e-07
Iter: 1159 loss: 5.10752841e-07
Iter: 1160 loss: 5.10752557e-07
Iter: 1161 loss: 5.10763243e-07
Iter: 1162 loss: 5.1076222e-07
Iter: 1163 loss: 5.10759378e-07
Iter: 1164 loss: 5.10755513e-07
Iter: 1165 loss: 5.10755683e-07
Iter: 1166 loss: 5.10757104e-07
Iter: 1167 loss: 5.10758184e-07
Iter: 1168 loss: 5.10758355e-07
Iter: 1169 loss: 5.10759548e-07
Iter: 1170 loss: 5.10757843e-07
Iter: 1171 loss: 5.10759321e-07
Iter: 1172 loss: 5.10758923e-07
Iter: 1173 loss: 5.10757843e-07
Iter: 1174 loss: 5.10758923e-07
Iter: 1175 loss: 5.10757843e-07
Iter: 1176 loss: 5.10695031e-07
Iter: 1177 loss: 5.10757332e-07
Iter: 1178 loss: 5.10662176e-07
Iter: 1179 loss: 5.10600898e-07
Iter: 1180 loss: 5.10752898e-07
Iter: 1181 loss: 5.10563268e-07
Iter: 1182 loss: 5.10545647e-07
Iter: 1183 loss: 5.10501081e-07
Iter: 1184 loss: 5.10524615e-07
Iter: 1185 loss: 5.10462542e-07
Iter: 1186 loss: 5.10420819e-07
Iter: 1187 loss: 5.10426958e-07
Iter: 1188 loss: 5.10342034e-07
Iter: 1189 loss: 5.10992891e-07
Iter: 1190 loss: 5.10303607e-07
Iter: 1191 loss: 5.10283769e-07
Iter: 1192 loss: 5.10242671e-07
Iter: 1193 loss: 5.10219138e-07
Iter: 1194 loss: 5.10130917e-07
Iter: 1195 loss: 5.10295536e-07
Iter: 1196 loss: 5.10127e-07
Iter: 1197 loss: 5.10072539e-07
Iter: 1198 loss: 5.10891255e-07
Iter: 1199 loss: 5.10067366e-07
Iter: 1200 loss: 5.10034795e-07
Iter: 1201 loss: 5.10002053e-07
Iter: 1202 loss: 5.09996312e-07
Iter: 1203 loss: 5.09930146e-07
Iter: 1204 loss: 5.10659333e-07
Iter: 1205 loss: 5.09932761e-07
Iter: 1206 loss: 5.09876941e-07
Iter: 1207 loss: 5.09807e-07
Iter: 1208 loss: 5.09799293e-07
Iter: 1209 loss: 5.09719143e-07
Iter: 1210 loss: 5.1022505e-07
Iter: 1211 loss: 5.09701181e-07
Iter: 1212 loss: 5.09680376e-07
Iter: 1213 loss: 5.09688164e-07
Iter: 1214 loss: 5.09631548e-07
Iter: 1215 loss: 5.09715505e-07
Iter: 1216 loss: 5.09627e-07
Iter: 1217 loss: 5.09579081e-07
Iter: 1218 loss: 5.09591359e-07
Iter: 1219 loss: 5.09569929e-07
Iter: 1220 loss: 5.09528718e-07
Iter: 1221 loss: 5.09648e-07
Iter: 1222 loss: 5.09487677e-07
Iter: 1223 loss: 5.09459142e-07
Iter: 1224 loss: 5.09753534e-07
Iter: 1225 loss: 5.0945863e-07
Iter: 1226 loss: 5.09394113e-07
Iter: 1227 loss: 5.09415599e-07
Iter: 1228 loss: 5.09362053e-07
Iter: 1229 loss: 5.09343238e-07
Iter: 1230 loss: 5.0983806e-07
Iter: 1231 loss: 5.09328629e-07
Iter: 1232 loss: 5.0931169e-07
Iter: 1233 loss: 5.09283154e-07
Iter: 1234 loss: 5.09262577e-07
Iter: 1235 loss: 5.09230915e-07
Iter: 1236 loss: 5.09643939e-07
Iter: 1237 loss: 5.09241943e-07
Iter: 1238 loss: 5.09170036e-07
Iter: 1239 loss: 5.09229039e-07
Iter: 1240 loss: 5.09185952e-07
Iter: 1241 loss: 5.09169524e-07
Iter: 1242 loss: 5.09166682e-07
Iter: 1243 loss: 5.09106712e-07
Iter: 1244 loss: 5.09058282e-07
Iter: 1245 loss: 5.09116262e-07
Iter: 1246 loss: 5.09063113e-07
Iter: 1247 loss: 5.09e-07
Iter: 1248 loss: 5.09616541e-07
Iter: 1249 loss: 5.09020083e-07
Iter: 1250 loss: 5.08979952e-07
Iter: 1251 loss: 5.08939252e-07
Iter: 1252 loss: 5.098e-07
Iter: 1253 loss: 5.0892686e-07
Iter: 1254 loss: 5.08868538e-07
Iter: 1255 loss: 5.09095116e-07
Iter: 1256 loss: 5.08858363e-07
Iter: 1257 loss: 5.08806352e-07
Iter: 1258 loss: 5.09284234e-07
Iter: 1259 loss: 5.08825735e-07
Iter: 1260 loss: 5.08757921e-07
Iter: 1261 loss: 5.08680614e-07
Iter: 1262 loss: 5.08688117e-07
Iter: 1263 loss: 5.08612743e-07
Iter: 1264 loss: 5.09542474e-07
Iter: 1265 loss: 5.08596941e-07
Iter: 1266 loss: 5.08576363e-07
Iter: 1267 loss: 5.08714606e-07
Iter: 1268 loss: 5.08552262e-07
Iter: 1269 loss: 5.08524749e-07
Iter: 1270 loss: 5.08592905e-07
Iter: 1271 loss: 5.08510254e-07
Iter: 1272 loss: 5.08438916e-07
Iter: 1273 loss: 5.08546748e-07
Iter: 1274 loss: 5.08455514e-07
Iter: 1275 loss: 5.08394237e-07
Iter: 1276 loss: 5.0840373e-07
Iter: 1277 loss: 5.0836843e-07
Iter: 1278 loss: 5.08309199e-07
Iter: 1279 loss: 5.08709547e-07
Iter: 1280 loss: 5.08302435e-07
Iter: 1281 loss: 5.08277935e-07
Iter: 1282 loss: 5.08605922e-07
Iter: 1283 loss: 5.08298172e-07
Iter: 1284 loss: 5.08281346e-07
Iter: 1285 loss: 5.08231722e-07
Iter: 1286 loss: 5.08218818e-07
Iter: 1287 loss: 5.08207222e-07
Iter: 1288 loss: 5.08256164e-07
Iter: 1289 loss: 5.08180392e-07
Iter: 1290 loss: 5.08151913e-07
Iter: 1291 loss: 5.08476433e-07
Iter: 1292 loss: 5.08146854e-07
Iter: 1293 loss: 5.08124174e-07
Iter: 1294 loss: 5.0809831e-07
Iter: 1295 loss: 5.08057155e-07
Iter: 1296 loss: 5.08044764e-07
Iter: 1297 loss: 5.08340804e-07
Iter: 1298 loss: 5.08005e-07
Iter: 1299 loss: 5.07951427e-07
Iter: 1300 loss: 5.08182097e-07
Iter: 1301 loss: 5.07970185e-07
Iter: 1302 loss: 5.07934942e-07
Iter: 1303 loss: 5.07926e-07
Iter: 1304 loss: 5.07911238e-07
Iter: 1305 loss: 5.07880145e-07
Iter: 1306 loss: 5.08248547e-07
Iter: 1307 loss: 5.07849563e-07
Iter: 1308 loss: 5.07831942e-07
Iter: 1309 loss: 5.07803804e-07
Iter: 1310 loss: 5.07779305e-07
Iter: 1311 loss: 5.07776178e-07
Iter: 1312 loss: 5.07933e-07
Iter: 1313 loss: 5.0775111e-07
Iter: 1314 loss: 5.07697166e-07
Iter: 1315 loss: 5.08094899e-07
Iter: 1316 loss: 5.07738775e-07
Iter: 1317 loss: 5.07693073e-07
Iter: 1318 loss: 5.07645382e-07
Iter: 1319 loss: 5.07650611e-07
Iter: 1320 loss: 5.0762344e-07
Iter: 1321 loss: 5.07716493e-07
Iter: 1322 loss: 5.0759985e-07
Iter: 1323 loss: 5.07571372e-07
Iter: 1324 loss: 5.07655159e-07
Iter: 1325 loss: 5.07556e-07
Iter: 1326 loss: 5.0751305e-07
Iter: 1327 loss: 5.07789537e-07
Iter: 1328 loss: 5.07484913e-07
Iter: 1329 loss: 5.07459049e-07
Iter: 1330 loss: 5.07440518e-07
Iter: 1331 loss: 5.07415621e-07
Iter: 1332 loss: 5.07359118e-07
Iter: 1333 loss: 5.07652e-07
Iter: 1334 loss: 5.07374807e-07
Iter: 1335 loss: 5.07310062e-07
Iter: 1336 loss: 5.07348e-07
Iter: 1337 loss: 5.07293066e-07
Iter: 1338 loss: 5.07213883e-07
Iter: 1339 loss: 5.0744876e-07
Iter: 1340 loss: 5.07217464e-07
Iter: 1341 loss: 5.07172501e-07
Iter: 1342 loss: 5.07221387e-07
Iter: 1343 loss: 5.07155619e-07
Iter: 1344 loss: 5.07141181e-07
Iter: 1345 loss: 5.07150276e-07
Iter: 1346 loss: 5.07068876e-07
Iter: 1347 loss: 5.07037157e-07
Iter: 1348 loss: 5.07401751e-07
Iter: 1349 loss: 5.07030791e-07
Iter: 1350 loss: 5.07000379e-07
Iter: 1351 loss: 5.07143113e-07
Iter: 1352 loss: 5.06979404e-07
Iter: 1353 loss: 5.06933361e-07
Iter: 1354 loss: 5.06878791e-07
Iter: 1355 loss: 5.06879928e-07
Iter: 1356 loss: 5.0681e-07
Iter: 1357 loss: 5.07551704e-07
Iter: 1358 loss: 5.06811716e-07
Iter: 1359 loss: 5.06754873e-07
Iter: 1360 loss: 5.06898459e-07
Iter: 1361 loss: 5.06756578e-07
Iter: 1362 loss: 5.06723211e-07
Iter: 1363 loss: 5.06822403e-07
Iter: 1364 loss: 5.06710762e-07
Iter: 1365 loss: 5.06660399e-07
Iter: 1366 loss: 5.0685486e-07
Iter: 1367 loss: 5.06629931e-07
Iter: 1368 loss: 5.06553533e-07
Iter: 1369 loss: 5.06610263e-07
Iter: 1370 loss: 5.06508684e-07
Iter: 1371 loss: 5.06466222e-07
Iter: 1372 loss: 5.0702738e-07
Iter: 1373 loss: 5.06467302e-07
Iter: 1374 loss: 5.06416882e-07
Iter: 1375 loss: 5.0636703e-07
Iter: 1376 loss: 5.06407901e-07
Iter: 1377 loss: 5.06296431e-07
Iter: 1378 loss: 5.06619699e-07
Iter: 1379 loss: 5.06261813e-07
Iter: 1380 loss: 5.06215372e-07
Iter: 1381 loss: 5.06444906e-07
Iter: 1382 loss: 5.06236574e-07
Iter: 1383 loss: 5.0618894e-07
Iter: 1384 loss: 5.06292508e-07
Iter: 1385 loss: 5.06145284e-07
Iter: 1386 loss: 5.06087645e-07
Iter: 1387 loss: 5.06135166e-07
Iter: 1388 loss: 5.06071785e-07
Iter: 1389 loss: 5.06039498e-07
Iter: 1390 loss: 5.06114e-07
Iter: 1391 loss: 5.06023e-07
Iter: 1392 loss: 5.05952244e-07
Iter: 1393 loss: 5.06193942e-07
Iter: 1394 loss: 5.05929052e-07
Iter: 1395 loss: 5.05896082e-07
Iter: 1396 loss: 5.059714e-07
Iter: 1397 loss: 5.05870332e-07
Iter: 1398 loss: 5.05846799e-07
Iter: 1399 loss: 5.05961793e-07
Iter: 1400 loss: 5.05821049e-07
Iter: 1401 loss: 5.05766138e-07
Iter: 1402 loss: 5.05995274e-07
Iter: 1403 loss: 5.0574954e-07
Iter: 1404 loss: 5.05698324e-07
Iter: 1405 loss: 5.05742378e-07
Iter: 1406 loss: 5.05705316e-07
Iter: 1407 loss: 5.05630624e-07
Iter: 1408 loss: 5.05711455e-07
Iter: 1409 loss: 5.05586e-07
Iter: 1410 loss: 5.05555647e-07
Iter: 1411 loss: 5.05783532e-07
Iter: 1412 loss: 5.05560706e-07
Iter: 1413 loss: 5.05539219e-07
Iter: 1414 loss: 5.05603566e-07
Iter: 1415 loss: 5.05499372e-07
Iter: 1416 loss: 5.05453727e-07
Iter: 1417 loss: 5.05805701e-07
Iter: 1418 loss: 5.05474077e-07
Iter: 1419 loss: 5.05403364e-07
Iter: 1420 loss: 5.054045e-07
Iter: 1421 loss: 5.05384264e-07
Iter: 1422 loss: 5.05325033e-07
Iter: 1423 loss: 5.05392734e-07
Iter: 1424 loss: 5.05284561e-07
Iter: 1425 loss: 5.05265234e-07
Iter: 1426 loss: 5.05506137e-07
Iter: 1427 loss: 5.05272055e-07
Iter: 1428 loss: 5.05197249e-07
Iter: 1429 loss: 5.05274215e-07
Iter: 1430 loss: 5.05174114e-07
Iter: 1431 loss: 5.05127787e-07
Iter: 1432 loss: 5.05576168e-07
Iter: 1433 loss: 5.05125399e-07
Iter: 1434 loss: 5.05089e-07
Iter: 1435 loss: 5.05143589e-07
Iter: 1436 loss: 5.05042067e-07
Iter: 1437 loss: 5.05001e-07
Iter: 1438 loss: 5.05051219e-07
Iter: 1439 loss: 5.04973286e-07
Iter: 1440 loss: 5.04902687e-07
Iter: 1441 loss: 5.05411e-07
Iter: 1442 loss: 5.04871366e-07
Iter: 1443 loss: 5.04882337e-07
Iter: 1444 loss: 5.04900868e-07
Iter: 1445 loss: 5.04919171e-07
Iter: 1446 loss: 5.0491019e-07
Iter: 1447 loss: 5.04895183e-07
Iter: 1448 loss: 5.04916102e-07
Iter: 1449 loss: 5.0489291e-07
Iter: 1450 loss: 5.04892341e-07
Iter: 1451 loss: 5.04892512e-07
Iter: 1452 loss: 5.04897e-07
Iter: 1453 loss: 5.04879381e-07
Iter: 1454 loss: 5.04875686e-07
Iter: 1455 loss: 5.04869547e-07
Iter: 1456 loss: 5.04877619e-07
Iter: 1457 loss: 5.0487165e-07
Iter: 1458 loss: 5.04877789e-07
Iter: 1459 loss: 5.04875118e-07
Iter: 1460 loss: 5.04873071e-07
Iter: 1461 loss: 5.04872673e-07
Iter: 1462 loss: 5.04872105e-07
Iter: 1463 loss: 5.04871934e-07
Iter: 1464 loss: 5.04871593e-07
Iter: 1465 loss: 5.0487165e-07
Iter: 1466 loss: 5.04871764e-07
Iter: 1467 loss: 5.04871934e-07
Iter: 1468 loss: 5.04871934e-07
Iter: 1469 loss: 5.04871764e-07
Iter: 1470 loss: 5.04871934e-07
Iter: 1471 loss: 5.04871934e-07
Iter: 1472 loss: 5.04871764e-07
Iter: 1473 loss: 5.04871764e-07
Iter: 1474 loss: 5.04871764e-07
Iter: 1475 loss: 5.04871764e-07
Iter: 1476 loss: 5.04871764e-07
Iter: 1477 loss: 5.04871934e-07
Iter: 1478 loss: 5.04871934e-07
Iter: 1479 loss: 5.04871764e-07
Iter: 1480 loss: 0.000171500054
Iter: 1481 loss: 5.04909053e-07
Iter: 1482 loss: 5.04878358e-07
Iter: 1483 loss: 5.04899958e-07
Iter: 1484 loss: 5.04894047e-07
Iter: 1485 loss: 5.04900754e-07
Iter: 1486 loss: 5.04915647e-07
Iter: 1487 loss: 5.04908598e-07
Iter: 1488 loss: 5.0489723e-07
Iter: 1489 loss: 5.04878926e-07
Iter: 1490 loss: 5.04889272e-07
Iter: 1491 loss: 5.0488552e-07
Iter: 1492 loss: 5.04871082e-07
Iter: 1493 loss: 5.0488552e-07
Iter: 1494 loss: 5.04880859e-07
Iter: 1495 loss: 5.04878358e-07
Iter: 1496 loss: 5.04871139e-07
Iter: 1497 loss: 5.04875345e-07
Iter: 1498 loss: 5.04871423e-07
Iter: 1499 loss: 5.0487165e-07
Iter: 1500 loss: 5.04872901e-07
Iter: 1501 loss: 5.04871764e-07
Iter: 1502 loss: 5.04870911e-07
Iter: 1503 loss: 5.04872446e-07
Iter: 1504 loss: 5.04872e-07
Iter: 1505 loss: 5.04872162e-07
Iter: 1506 loss: 5.04872048e-07
Iter: 1507 loss: 5.04872048e-07
Iter: 1508 loss: 5.04872332e-07
Iter: 1509 loss: 5.04872048e-07
Iter: 1510 loss: 5.04872332e-07
Iter: 1511 loss: 5.04872e-07
Iter: 1512 loss: 5.04872e-07
Iter: 1513 loss: 5.04872332e-07
Iter: 1514 loss: 5.04872e-07
Iter: 1515 loss: 5.04872e-07
Iter: 1516 loss: 5.04872332e-07
Iter: 1517 loss: 5.04872e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi1.6/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2
+ date
Mon Nov  9 06:54:55 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2/500_500_500_500_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_1000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_1000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdde2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdded048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdee8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cde35840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cde35598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cddba598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cddba158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdd92a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdd68378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdce0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdcf61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdcc4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdd07400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdc74d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdc9a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdc4e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdbfb378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdbfbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdbbdea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdbbd9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdbbdb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdb21e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdb21ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88cdb00510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c5528488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c5528950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c5552400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c54e7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c5512598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c54b5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c5512d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c55129d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c542b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c5443510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c53f1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c53ff048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.07505468e-06
Iter: 2 loss: 3.67645916e-05
Iter: 3 loss: 2.222273e-06
Iter: 4 loss: 1.99798069e-06
Iter: 5 loss: 1.59047602e-06
Iter: 6 loss: 1.12858725e-05
Iter: 7 loss: 1.59023045e-06
Iter: 8 loss: 1.28192141e-06
Iter: 9 loss: 3.43118154e-06
Iter: 10 loss: 1.2531591e-06
Iter: 11 loss: 1.05099673e-06
Iter: 12 loss: 1.3215415e-06
Iter: 13 loss: 9.49028959e-07
Iter: 14 loss: 8.53969254e-07
Iter: 15 loss: 1.98470661e-06
Iter: 16 loss: 8.52574715e-07
Iter: 17 loss: 8.10957317e-07
Iter: 18 loss: 8.52259291e-07
Iter: 19 loss: 7.87549425e-07
Iter: 20 loss: 7.56078578e-07
Iter: 21 loss: 7.87478314e-07
Iter: 22 loss: 7.38174094e-07
Iter: 23 loss: 7.20720664e-07
Iter: 24 loss: 7.26652615e-07
Iter: 25 loss: 7.08280425e-07
Iter: 26 loss: 6.86920316e-07
Iter: 27 loss: 7.33946365e-07
Iter: 28 loss: 6.78722586e-07
Iter: 29 loss: 6.62252e-07
Iter: 30 loss: 6.83231633e-07
Iter: 31 loss: 6.53693633e-07
Iter: 32 loss: 6.40634369e-07
Iter: 33 loss: 6.3932896e-07
Iter: 34 loss: 6.2987715e-07
Iter: 35 loss: 6.17479486e-07
Iter: 36 loss: 6.30676482e-07
Iter: 37 loss: 6.10447387e-07
Iter: 38 loss: 6.02258126e-07
Iter: 39 loss: 6.00856765e-07
Iter: 40 loss: 5.9396325e-07
Iter: 41 loss: 6.01070496e-07
Iter: 42 loss: 5.90046398e-07
Iter: 43 loss: 5.84376e-07
Iter: 44 loss: 5.73047259e-07
Iter: 45 loss: 7.81547328e-07
Iter: 46 loss: 5.7270546e-07
Iter: 47 loss: 5.61858599e-07
Iter: 48 loss: 6.52825747e-07
Iter: 49 loss: 5.61303636e-07
Iter: 50 loss: 5.55231225e-07
Iter: 51 loss: 5.55195754e-07
Iter: 52 loss: 5.50541131e-07
Iter: 53 loss: 5.56927489e-07
Iter: 54 loss: 5.48208618e-07
Iter: 55 loss: 5.43441956e-07
Iter: 56 loss: 5.3632283e-07
Iter: 57 loss: 5.36022753e-07
Iter: 58 loss: 5.29144359e-07
Iter: 59 loss: 5.71339228e-07
Iter: 60 loss: 5.2826465e-07
Iter: 61 loss: 5.2061597e-07
Iter: 62 loss: 5.63694584e-07
Iter: 63 loss: 5.19388152e-07
Iter: 64 loss: 5.15788e-07
Iter: 65 loss: 5.56971486e-07
Iter: 66 loss: 5.15664e-07
Iter: 67 loss: 5.1197145e-07
Iter: 68 loss: 5.09008544e-07
Iter: 69 loss: 5.0805329e-07
Iter: 70 loss: 5.02703756e-07
Iter: 71 loss: 5.16466059e-07
Iter: 72 loss: 5.00802741e-07
Iter: 73 loss: 4.98276847e-07
Iter: 74 loss: 4.97838244e-07
Iter: 75 loss: 4.96010898e-07
Iter: 76 loss: 4.91836204e-07
Iter: 77 loss: 5.44358443e-07
Iter: 78 loss: 4.91406411e-07
Iter: 79 loss: 4.85448254e-07
Iter: 80 loss: 5.0894846e-07
Iter: 81 loss: 4.84104419e-07
Iter: 82 loss: 4.80638505e-07
Iter: 83 loss: 4.85940063e-07
Iter: 84 loss: 4.78949914e-07
Iter: 85 loss: 4.74092559e-07
Iter: 86 loss: 4.81367579e-07
Iter: 87 loss: 4.71769624e-07
Iter: 88 loss: 4.68727393e-07
Iter: 89 loss: 4.68522416e-07
Iter: 90 loss: 4.66630553e-07
Iter: 91 loss: 4.62574405e-07
Iter: 92 loss: 5.27385055e-07
Iter: 93 loss: 4.62440454e-07
Iter: 94 loss: 4.58423017e-07
Iter: 95 loss: 4.78107665e-07
Iter: 96 loss: 4.57812604e-07
Iter: 97 loss: 4.55051747e-07
Iter: 98 loss: 4.75738716e-07
Iter: 99 loss: 4.55040407e-07
Iter: 100 loss: 4.52477593e-07
Iter: 101 loss: 4.6891023e-07
Iter: 102 loss: 4.52354158e-07
Iter: 103 loss: 4.50574106e-07
Iter: 104 loss: 4.55289637e-07
Iter: 105 loss: 4.50107052e-07
Iter: 106 loss: 4.4844947e-07
Iter: 107 loss: 4.51350388e-07
Iter: 108 loss: 4.4787555e-07
Iter: 109 loss: 4.46284275e-07
Iter: 110 loss: 4.55703e-07
Iter: 111 loss: 4.46213932e-07
Iter: 112 loss: 4.4480916e-07
Iter: 113 loss: 4.43526176e-07
Iter: 114 loss: 4.43300763e-07
Iter: 115 loss: 4.41530347e-07
Iter: 116 loss: 4.47440812e-07
Iter: 117 loss: 4.41013356e-07
Iter: 118 loss: 4.39281223e-07
Iter: 119 loss: 4.47510047e-07
Iter: 120 loss: 4.38985e-07
Iter: 121 loss: 4.37265982e-07
Iter: 122 loss: 4.36609355e-07
Iter: 123 loss: 4.35680334e-07
Iter: 124 loss: 4.34702088e-07
Iter: 125 loss: 4.34494353e-07
Iter: 126 loss: 4.33606516e-07
Iter: 127 loss: 4.32130207e-07
Iter: 128 loss: 4.3218941e-07
Iter: 129 loss: 4.30347086e-07
Iter: 130 loss: 4.33560416e-07
Iter: 131 loss: 4.29642114e-07
Iter: 132 loss: 4.2782284e-07
Iter: 133 loss: 4.36012272e-07
Iter: 134 loss: 4.27581483e-07
Iter: 135 loss: 4.2612362e-07
Iter: 136 loss: 4.26104634e-07
Iter: 137 loss: 4.25336736e-07
Iter: 138 loss: 4.25837413e-07
Iter: 139 loss: 4.24873349e-07
Iter: 140 loss: 4.23656132e-07
Iter: 141 loss: 4.24832365e-07
Iter: 142 loss: 4.23055326e-07
Iter: 143 loss: 4.21863604e-07
Iter: 144 loss: 4.25889965e-07
Iter: 145 loss: 4.21581888e-07
Iter: 146 loss: 4.20567e-07
Iter: 147 loss: 4.22108172e-07
Iter: 148 loss: 4.1996546e-07
Iter: 149 loss: 4.18783543e-07
Iter: 150 loss: 4.17368085e-07
Iter: 151 loss: 4.17145259e-07
Iter: 152 loss: 4.15423074e-07
Iter: 153 loss: 4.32899071e-07
Iter: 154 loss: 4.15233444e-07
Iter: 155 loss: 4.14002614e-07
Iter: 156 loss: 4.19226041e-07
Iter: 157 loss: 4.13627248e-07
Iter: 158 loss: 4.12341109e-07
Iter: 159 loss: 4.15935119e-07
Iter: 160 loss: 4.1182787e-07
Iter: 161 loss: 4.10732525e-07
Iter: 162 loss: 4.17279892e-07
Iter: 163 loss: 4.10448592e-07
Iter: 164 loss: 4.09648806e-07
Iter: 165 loss: 4.0801018e-07
Iter: 166 loss: 4.08031269e-07
Iter: 167 loss: 4.06226349e-07
Iter: 168 loss: 4.13527744e-07
Iter: 169 loss: 4.05768446e-07
Iter: 170 loss: 4.04331587e-07
Iter: 171 loss: 4.07857897e-07
Iter: 172 loss: 4.03718445e-07
Iter: 173 loss: 4.03418369e-07
Iter: 174 loss: 4.03015918e-07
Iter: 175 loss: 4.0223324e-07
Iter: 176 loss: 4.01262639e-07
Iter: 177 loss: 4.011643e-07
Iter: 178 loss: 4.00125202e-07
Iter: 179 loss: 4.01339435e-07
Iter: 180 loss: 3.99670711e-07
Iter: 181 loss: 3.98756697e-07
Iter: 182 loss: 4.03223197e-07
Iter: 183 loss: 3.98635791e-07
Iter: 184 loss: 3.97915926e-07
Iter: 185 loss: 3.97516828e-07
Iter: 186 loss: 3.97072625e-07
Iter: 187 loss: 3.96093441e-07
Iter: 188 loss: 4.009257e-07
Iter: 189 loss: 3.96003344e-07
Iter: 190 loss: 3.9519341e-07
Iter: 191 loss: 3.96044669e-07
Iter: 192 loss: 3.94678295e-07
Iter: 193 loss: 3.93979548e-07
Iter: 194 loss: 3.93963262e-07
Iter: 195 loss: 3.93422084e-07
Iter: 196 loss: 3.93565387e-07
Iter: 197 loss: 3.9305371e-07
Iter: 198 loss: 3.92249348e-07
Iter: 199 loss: 3.91993581e-07
Iter: 200 loss: 3.91543466e-07
Iter: 201 loss: 3.90416687e-07
Iter: 202 loss: 3.95302095e-07
Iter: 203 loss: 3.90321276e-07
Iter: 204 loss: 3.89443073e-07
Iter: 205 loss: 3.92476636e-07
Iter: 206 loss: 3.89322935e-07
Iter: 207 loss: 3.88505043e-07
Iter: 208 loss: 3.99910192e-07
Iter: 209 loss: 3.88485688e-07
Iter: 210 loss: 3.88003627e-07
Iter: 211 loss: 3.87202903e-07
Iter: 212 loss: 4.07942423e-07
Iter: 213 loss: 3.87172577e-07
Iter: 214 loss: 3.86420083e-07
Iter: 215 loss: 3.88635897e-07
Iter: 216 loss: 3.86144308e-07
Iter: 217 loss: 3.85486032e-07
Iter: 218 loss: 3.88741171e-07
Iter: 219 loss: 3.85434305e-07
Iter: 220 loss: 3.84806015e-07
Iter: 221 loss: 3.85034497e-07
Iter: 222 loss: 3.84295305e-07
Iter: 223 loss: 3.83601474e-07
Iter: 224 loss: 3.85435612e-07
Iter: 225 loss: 3.83221845e-07
Iter: 226 loss: 3.82547228e-07
Iter: 227 loss: 3.84756504e-07
Iter: 228 loss: 3.82287425e-07
Iter: 229 loss: 3.81558607e-07
Iter: 230 loss: 3.87252101e-07
Iter: 231 loss: 3.81379323e-07
Iter: 232 loss: 3.80989604e-07
Iter: 233 loss: 3.81306904e-07
Iter: 234 loss: 3.80603296e-07
Iter: 235 loss: 3.7992308e-07
Iter: 236 loss: 3.79922398e-07
Iter: 237 loss: 3.79457958e-07
Iter: 238 loss: 3.78649929e-07
Iter: 239 loss: 3.85044075e-07
Iter: 240 loss: 3.78592176e-07
Iter: 241 loss: 3.78296875e-07
Iter: 242 loss: 3.78302047e-07
Iter: 243 loss: 3.77908663e-07
Iter: 244 loss: 3.77264513e-07
Iter: 245 loss: 3.92895913e-07
Iter: 246 loss: 3.77210711e-07
Iter: 247 loss: 3.76648416e-07
Iter: 248 loss: 3.78409112e-07
Iter: 249 loss: 3.76476976e-07
Iter: 250 loss: 3.76120084e-07
Iter: 251 loss: 3.76040759e-07
Iter: 252 loss: 3.75621966e-07
Iter: 253 loss: 3.75052878e-07
Iter: 254 loss: 3.79825053e-07
Iter: 255 loss: 3.74997768e-07
Iter: 256 loss: 3.74493709e-07
Iter: 257 loss: 3.74725118e-07
Iter: 258 loss: 3.74110527e-07
Iter: 259 loss: 3.73563523e-07
Iter: 260 loss: 3.73593025e-07
Iter: 261 loss: 3.73101358e-07
Iter: 262 loss: 3.72450415e-07
Iter: 263 loss: 3.72404514e-07
Iter: 264 loss: 3.71779691e-07
Iter: 265 loss: 3.72307227e-07
Iter: 266 loss: 3.71549675e-07
Iter: 267 loss: 3.70747443e-07
Iter: 268 loss: 3.70911948e-07
Iter: 269 loss: 3.70080585e-07
Iter: 270 loss: 3.69156282e-07
Iter: 271 loss: 3.74507778e-07
Iter: 272 loss: 3.69164979e-07
Iter: 273 loss: 3.68364454e-07
Iter: 274 loss: 3.71668193e-07
Iter: 275 loss: 3.68356439e-07
Iter: 276 loss: 3.68120965e-07
Iter: 277 loss: 3.6798798e-07
Iter: 278 loss: 3.67810685e-07
Iter: 279 loss: 3.67172106e-07
Iter: 280 loss: 3.67856671e-07
Iter: 281 loss: 3.6661163e-07
Iter: 282 loss: 3.65883e-07
Iter: 283 loss: 3.77096285e-07
Iter: 284 loss: 3.65887189e-07
Iter: 285 loss: 3.65503439e-07
Iter: 286 loss: 3.65190544e-07
Iter: 287 loss: 3.65002222e-07
Iter: 288 loss: 3.64335591e-07
Iter: 289 loss: 3.69124734e-07
Iter: 290 loss: 3.64129562e-07
Iter: 291 loss: 3.63578692e-07
Iter: 292 loss: 3.6696639e-07
Iter: 293 loss: 3.63684308e-07
Iter: 294 loss: 3.63175673e-07
Iter: 295 loss: 3.62714559e-07
Iter: 296 loss: 3.62595244e-07
Iter: 297 loss: 3.62275955e-07
Iter: 298 loss: 3.62189809e-07
Iter: 299 loss: 3.61922616e-07
Iter: 300 loss: 3.61138e-07
Iter: 301 loss: 3.74903266e-07
Iter: 302 loss: 3.611392e-07
Iter: 303 loss: 3.60465378e-07
Iter: 304 loss: 3.63697382e-07
Iter: 305 loss: 3.6027663e-07
Iter: 306 loss: 3.59782973e-07
Iter: 307 loss: 3.6145849e-07
Iter: 308 loss: 3.59559039e-07
Iter: 309 loss: 3.59085789e-07
Iter: 310 loss: 3.59131064e-07
Iter: 311 loss: 3.58621662e-07
Iter: 312 loss: 3.57875933e-07
Iter: 313 loss: 3.59598346e-07
Iter: 314 loss: 3.57545048e-07
Iter: 315 loss: 3.57855043e-07
Iter: 316 loss: 3.57239685e-07
Iter: 317 loss: 3.56931082e-07
Iter: 318 loss: 3.56540284e-07
Iter: 319 loss: 3.67399309e-07
Iter: 320 loss: 3.56456241e-07
Iter: 321 loss: 3.5601505e-07
Iter: 322 loss: 3.55350551e-07
Iter: 323 loss: 3.55364051e-07
Iter: 324 loss: 3.5447755e-07
Iter: 325 loss: 3.57667886e-07
Iter: 326 loss: 3.54313784e-07
Iter: 327 loss: 3.5371e-07
Iter: 328 loss: 3.55806208e-07
Iter: 329 loss: 3.53483358e-07
Iter: 330 loss: 3.52887128e-07
Iter: 331 loss: 3.55898464e-07
Iter: 332 loss: 3.52838867e-07
Iter: 333 loss: 3.5221737e-07
Iter: 334 loss: 3.54609028e-07
Iter: 335 loss: 3.52117809e-07
Iter: 336 loss: 3.51672327e-07
Iter: 337 loss: 3.53568112e-07
Iter: 338 loss: 3.51596e-07
Iter: 339 loss: 3.51158775e-07
Iter: 340 loss: 3.52155155e-07
Iter: 341 loss: 3.5097807e-07
Iter: 342 loss: 3.50549641e-07
Iter: 343 loss: 3.50290691e-07
Iter: 344 loss: 3.50141e-07
Iter: 345 loss: 3.49569774e-07
Iter: 346 loss: 3.51648225e-07
Iter: 347 loss: 3.49495338e-07
Iter: 348 loss: 3.48850676e-07
Iter: 349 loss: 3.50682058e-07
Iter: 350 loss: 3.48805969e-07
Iter: 351 loss: 3.48328655e-07
Iter: 352 loss: 3.4943514e-07
Iter: 353 loss: 3.48209397e-07
Iter: 354 loss: 3.47768662e-07
Iter: 355 loss: 3.48668635e-07
Iter: 356 loss: 3.47517243e-07
Iter: 357 loss: 3.47013213e-07
Iter: 358 loss: 3.54866302e-07
Iter: 359 loss: 3.46996671e-07
Iter: 360 loss: 3.46835805e-07
Iter: 361 loss: 3.46371e-07
Iter: 362 loss: 3.49101299e-07
Iter: 363 loss: 3.46213568e-07
Iter: 364 loss: 3.45680775e-07
Iter: 365 loss: 3.47196192e-07
Iter: 366 loss: 3.45479293e-07
Iter: 367 loss: 3.44959574e-07
Iter: 368 loss: 3.47065907e-07
Iter: 369 loss: 3.44854e-07
Iter: 370 loss: 3.44278817e-07
Iter: 371 loss: 3.50344408e-07
Iter: 372 loss: 3.44240192e-07
Iter: 373 loss: 3.4393679e-07
Iter: 374 loss: 3.44171951e-07
Iter: 375 loss: 3.435552e-07
Iter: 376 loss: 3.43311143e-07
Iter: 377 loss: 3.46051053e-07
Iter: 378 loss: 3.43206409e-07
Iter: 379 loss: 3.42921055e-07
Iter: 380 loss: 3.42291457e-07
Iter: 381 loss: 3.42374079e-07
Iter: 382 loss: 3.41738456e-07
Iter: 383 loss: 3.43661782e-07
Iter: 384 loss: 3.41524071e-07
Iter: 385 loss: 3.40991164e-07
Iter: 386 loss: 3.43713026e-07
Iter: 387 loss: 3.40891404e-07
Iter: 388 loss: 3.40442398e-07
Iter: 389 loss: 3.41810534e-07
Iter: 390 loss: 3.40436685e-07
Iter: 391 loss: 3.40132175e-07
Iter: 392 loss: 3.40030795e-07
Iter: 393 loss: 3.39690359e-07
Iter: 394 loss: 3.39606316e-07
Iter: 395 loss: 3.39454118e-07
Iter: 396 loss: 3.39101831e-07
Iter: 397 loss: 3.38608402e-07
Iter: 398 loss: 3.38587427e-07
Iter: 399 loss: 3.38139245e-07
Iter: 400 loss: 3.41124235e-07
Iter: 401 loss: 3.37987672e-07
Iter: 402 loss: 3.37553161e-07
Iter: 403 loss: 3.3702679e-07
Iter: 404 loss: 3.36906282e-07
Iter: 405 loss: 3.36528103e-07
Iter: 406 loss: 3.36429935e-07
Iter: 407 loss: 3.36072731e-07
Iter: 408 loss: 3.36184485e-07
Iter: 409 loss: 3.3579235e-07
Iter: 410 loss: 3.35233949e-07
Iter: 411 loss: 3.37027132e-07
Iter: 412 loss: 3.35025135e-07
Iter: 413 loss: 3.34648178e-07
Iter: 414 loss: 3.35146069e-07
Iter: 415 loss: 3.34314194e-07
Iter: 416 loss: 3.33953125e-07
Iter: 417 loss: 3.34263945e-07
Iter: 418 loss: 3.33647847e-07
Iter: 419 loss: 3.33119146e-07
Iter: 420 loss: 3.34655056e-07
Iter: 421 loss: 3.32954272e-07
Iter: 422 loss: 3.32704673e-07
Iter: 423 loss: 3.32692423e-07
Iter: 424 loss: 3.32402919e-07
Iter: 425 loss: 3.35144421e-07
Iter: 426 loss: 3.32387884e-07
Iter: 427 loss: 3.32166e-07
Iter: 428 loss: 3.31773037e-07
Iter: 429 loss: 3.40314898e-07
Iter: 430 loss: 3.31852704e-07
Iter: 431 loss: 3.31505703e-07
Iter: 432 loss: 3.31790716e-07
Iter: 433 loss: 3.31317835e-07
Iter: 434 loss: 3.30849616e-07
Iter: 435 loss: 3.31448405e-07
Iter: 436 loss: 3.30610163e-07
Iter: 437 loss: 3.301231e-07
Iter: 438 loss: 3.31553508e-07
Iter: 439 loss: 3.30010835e-07
Iter: 440 loss: 3.29546253e-07
Iter: 441 loss: 3.33258981e-07
Iter: 442 loss: 3.29522663e-07
Iter: 443 loss: 3.29070559e-07
Iter: 444 loss: 3.30944658e-07
Iter: 445 loss: 3.2897114e-07
Iter: 446 loss: 3.2873217e-07
Iter: 447 loss: 3.28745273e-07
Iter: 448 loss: 3.28560247e-07
Iter: 449 loss: 3.28030637e-07
Iter: 450 loss: 3.29696036e-07
Iter: 451 loss: 3.27899215e-07
Iter: 452 loss: 3.27530074e-07
Iter: 453 loss: 3.27668261e-07
Iter: 454 loss: 3.27292582e-07
Iter: 455 loss: 3.26926283e-07
Iter: 456 loss: 3.27067255e-07
Iter: 457 loss: 3.26651815e-07
Iter: 458 loss: 3.26433707e-07
Iter: 459 loss: 3.26374902e-07
Iter: 460 loss: 3.26057148e-07
Iter: 461 loss: 3.27050969e-07
Iter: 462 loss: 3.25958638e-07
Iter: 463 loss: 3.25680105e-07
Iter: 464 loss: 3.2537389e-07
Iter: 465 loss: 3.2535138e-07
Iter: 466 loss: 3.24915788e-07
Iter: 467 loss: 3.26232737e-07
Iter: 468 loss: 3.24835753e-07
Iter: 469 loss: 3.2440559e-07
Iter: 470 loss: 3.24713653e-07
Iter: 471 loss: 3.24165e-07
Iter: 472 loss: 3.23572237e-07
Iter: 473 loss: 3.24156332e-07
Iter: 474 loss: 3.23341965e-07
Iter: 475 loss: 3.22853538e-07
Iter: 476 loss: 3.25947298e-07
Iter: 477 loss: 3.22769836e-07
Iter: 478 loss: 3.22426729e-07
Iter: 479 loss: 3.25792769e-07
Iter: 480 loss: 3.22399444e-07
Iter: 481 loss: 3.22135463e-07
Iter: 482 loss: 3.22010862e-07
Iter: 483 loss: 3.21789656e-07
Iter: 484 loss: 3.21530166e-07
Iter: 485 loss: 3.23227823e-07
Iter: 486 loss: 3.2158e-07
Iter: 487 loss: 3.21191322e-07
Iter: 488 loss: 3.21542416e-07
Iter: 489 loss: 3.21091022e-07
Iter: 490 loss: 3.20782817e-07
Iter: 491 loss: 3.20517302e-07
Iter: 492 loss: 3.20376273e-07
Iter: 493 loss: 3.19898618e-07
Iter: 494 loss: 3.22716744e-07
Iter: 495 loss: 3.19816479e-07
Iter: 496 loss: 3.19641345e-07
Iter: 497 loss: 3.19589674e-07
Iter: 498 loss: 3.19339136e-07
Iter: 499 loss: 3.18998019e-07
Iter: 500 loss: 3.24495829e-07
Iter: 501 loss: 3.19076122e-07
Iter: 502 loss: 3.18716815e-07
Iter: 503 loss: 3.18197749e-07
Iter: 504 loss: 3.18152559e-07
Iter: 505 loss: 3.17583243e-07
Iter: 506 loss: 3.20445338e-07
Iter: 507 loss: 3.17493971e-07
Iter: 508 loss: 3.17063552e-07
Iter: 509 loss: 3.20908612e-07
Iter: 510 loss: 3.17028025e-07
Iter: 511 loss: 3.16672271e-07
Iter: 512 loss: 3.16569867e-07
Iter: 513 loss: 3.16425428e-07
Iter: 514 loss: 3.15975228e-07
Iter: 515 loss: 3.1713e-07
Iter: 516 loss: 3.15879078e-07
Iter: 517 loss: 3.15423392e-07
Iter: 518 loss: 3.19171448e-07
Iter: 519 loss: 3.15396619e-07
Iter: 520 loss: 3.15026739e-07
Iter: 521 loss: 3.16123874e-07
Iter: 522 loss: 3.15036232e-07
Iter: 523 loss: 3.1478757e-07
Iter: 524 loss: 3.14539534e-07
Iter: 525 loss: 3.1454158e-07
Iter: 526 loss: 3.14097662e-07
Iter: 527 loss: 3.17024984e-07
Iter: 528 loss: 3.141e-07
Iter: 529 loss: 3.13811483e-07
Iter: 530 loss: 3.15139062e-07
Iter: 531 loss: 3.13796789e-07
Iter: 532 loss: 3.13622252e-07
Iter: 533 loss: 3.1357888e-07
Iter: 534 loss: 3.13523714e-07
Iter: 535 loss: 3.13135189e-07
Iter: 536 loss: 3.14232523e-07
Iter: 537 loss: 3.13188963e-07
Iter: 538 loss: 3.12694795e-07
Iter: 539 loss: 3.13491199e-07
Iter: 540 loss: 3.12570421e-07
Iter: 541 loss: 3.12290126e-07
Iter: 542 loss: 3.12788416e-07
Iter: 543 loss: 3.12144437e-07
Iter: 544 loss: 3.11824749e-07
Iter: 545 loss: 3.13030142e-07
Iter: 546 loss: 3.1163276e-07
Iter: 547 loss: 3.11312817e-07
Iter: 548 loss: 3.11948583e-07
Iter: 549 loss: 3.1112e-07
Iter: 550 loss: 3.10742024e-07
Iter: 551 loss: 3.12231862e-07
Iter: 552 loss: 3.10589513e-07
Iter: 553 loss: 3.10296571e-07
Iter: 554 loss: 3.11121312e-07
Iter: 555 loss: 3.10130304e-07
Iter: 556 loss: 3.09750362e-07
Iter: 557 loss: 3.12619193e-07
Iter: 558 loss: 3.09756018e-07
Iter: 559 loss: 3.0960166e-07
Iter: 560 loss: 3.09485301e-07
Iter: 561 loss: 3.09327874e-07
Iter: 562 loss: 3.09104763e-07
Iter: 563 loss: 3.11873691e-07
Iter: 564 loss: 3.09131451e-07
Iter: 565 loss: 3.08897313e-07
Iter: 566 loss: 3.10733725e-07
Iter: 567 loss: 3.08901605e-07
Iter: 568 loss: 3.08690858e-07
Iter: 569 loss: 3.08467833e-07
Iter: 570 loss: 3.08502081e-07
Iter: 571 loss: 3.08297302e-07
Iter: 572 loss: 3.08242903e-07
Iter: 573 loss: 3.08036221e-07
Iter: 574 loss: 3.07749559e-07
Iter: 575 loss: 3.08078199e-07
Iter: 576 loss: 3.07613e-07
Iter: 577 loss: 3.0724442e-07
Iter: 578 loss: 3.09276885e-07
Iter: 579 loss: 3.07176e-07
Iter: 580 loss: 3.06944e-07
Iter: 581 loss: 3.07892776e-07
Iter: 582 loss: 3.06922914e-07
Iter: 583 loss: 3.06674309e-07
Iter: 584 loss: 3.0787254e-07
Iter: 585 loss: 3.06578073e-07
Iter: 586 loss: 3.06401859e-07
Iter: 587 loss: 3.06958412e-07
Iter: 588 loss: 3.06311563e-07
Iter: 589 loss: 3.06073048e-07
Iter: 590 loss: 3.07022958e-07
Iter: 591 loss: 3.06071286e-07
Iter: 592 loss: 3.05829701e-07
Iter: 593 loss: 3.05818503e-07
Iter: 594 loss: 3.05711836e-07
Iter: 595 loss: 3.0541915e-07
Iter: 596 loss: 3.0693792e-07
Iter: 597 loss: 3.05397805e-07
Iter: 598 loss: 3.05234863e-07
Iter: 599 loss: 3.06336204e-07
Iter: 600 loss: 3.05244981e-07
Iter: 601 loss: 3.05002544e-07
Iter: 602 loss: 3.05423839e-07
Iter: 603 loss: 3.0493652e-07
Iter: 604 loss: 3.04771788e-07
Iter: 605 loss: 3.04557119e-07
Iter: 606 loss: 3.04514856e-07
Iter: 607 loss: 3.04299391e-07
Iter: 608 loss: 3.04536144e-07
Iter: 609 loss: 3.04152337e-07
Iter: 610 loss: 3.03949719e-07
Iter: 611 loss: 3.05110291e-07
Iter: 612 loss: 3.03872838e-07
Iter: 613 loss: 3.03558579e-07
Iter: 614 loss: 3.04587189e-07
Iter: 615 loss: 3.03587825e-07
Iter: 616 loss: 3.0332302e-07
Iter: 617 loss: 3.03418346e-07
Iter: 618 loss: 3.03234941e-07
Iter: 619 loss: 3.02943249e-07
Iter: 620 loss: 3.05493927e-07
Iter: 621 loss: 3.02929777e-07
Iter: 622 loss: 3.02728779e-07
Iter: 623 loss: 3.03200295e-07
Iter: 624 loss: 3.02657611e-07
Iter: 625 loss: 3.0239903e-07
Iter: 626 loss: 3.02950582e-07
Iter: 627 loss: 3.02328687e-07
Iter: 628 loss: 3.02098158e-07
Iter: 629 loss: 3.02372655e-07
Iter: 630 loss: 3.02014513e-07
Iter: 631 loss: 3.01707757e-07
Iter: 632 loss: 3.02704962e-07
Iter: 633 loss: 3.01626642e-07
Iter: 634 loss: 3.01548681e-07
Iter: 635 loss: 3.01533163e-07
Iter: 636 loss: 3.01444373e-07
Iter: 637 loss: 3.0125014e-07
Iter: 638 loss: 3.04291348e-07
Iter: 639 loss: 3.01276941e-07
Iter: 640 loss: 3.00950177e-07
Iter: 641 loss: 3.00980844e-07
Iter: 642 loss: 3.00770267e-07
Iter: 643 loss: 3.00582172e-07
Iter: 644 loss: 3.00999091e-07
Iter: 645 loss: 3.0051811e-07
Iter: 646 loss: 3.0014337e-07
Iter: 647 loss: 3.00800195e-07
Iter: 648 loss: 3.00071974e-07
Iter: 649 loss: 2.9968237e-07
Iter: 650 loss: 3.00280533e-07
Iter: 651 loss: 2.99480632e-07
Iter: 652 loss: 2.9930527e-07
Iter: 653 loss: 3.01398444e-07
Iter: 654 loss: 2.99241407e-07
Iter: 655 loss: 2.98978165e-07
Iter: 656 loss: 2.99172427e-07
Iter: 657 loss: 2.98832134e-07
Iter: 658 loss: 2.98481581e-07
Iter: 659 loss: 3.01854e-07
Iter: 660 loss: 2.98506563e-07
Iter: 661 loss: 2.98271544e-07
Iter: 662 loss: 2.98739508e-07
Iter: 663 loss: 2.98158824e-07
Iter: 664 loss: 2.97858406e-07
Iter: 665 loss: 2.98159904e-07
Iter: 666 loss: 2.97644249e-07
Iter: 667 loss: 2.97446604e-07
Iter: 668 loss: 2.98258442e-07
Iter: 669 loss: 2.9745172e-07
Iter: 670 loss: 2.97254928e-07
Iter: 671 loss: 2.99952546e-07
Iter: 672 loss: 2.97286817e-07
Iter: 673 loss: 2.97047109e-07
Iter: 674 loss: 2.97072859e-07
Iter: 675 loss: 2.96890903e-07
Iter: 676 loss: 2.96789807e-07
Iter: 677 loss: 2.96796941e-07
Iter: 678 loss: 2.96619191e-07
Iter: 679 loss: 2.96462048e-07
Iter: 680 loss: 2.96682657e-07
Iter: 681 loss: 2.96328e-07
Iter: 682 loss: 2.96050473e-07
Iter: 683 loss: 2.96183714e-07
Iter: 684 loss: 2.95853908e-07
Iter: 685 loss: 2.95511569e-07
Iter: 686 loss: 2.9602819e-07
Iter: 687 loss: 2.95449951e-07
Iter: 688 loss: 2.95064467e-07
Iter: 689 loss: 2.96337419e-07
Iter: 690 loss: 2.95043662e-07
Iter: 691 loss: 2.94768398e-07
Iter: 692 loss: 2.96001076e-07
Iter: 693 loss: 2.9462953e-07
Iter: 694 loss: 2.94424098e-07
Iter: 695 loss: 2.96651081e-07
Iter: 696 loss: 2.94547164e-07
Iter: 697 loss: 2.94291539e-07
Iter: 698 loss: 2.94287474e-07
Iter: 699 loss: 2.9409415e-07
Iter: 700 loss: 2.93907704e-07
Iter: 701 loss: 2.94760952e-07
Iter: 702 loss: 2.93916884e-07
Iter: 703 loss: 2.93718387e-07
Iter: 704 loss: 2.94107309e-07
Iter: 705 loss: 2.93568718e-07
Iter: 706 loss: 2.93268215e-07
Iter: 707 loss: 2.96519573e-07
Iter: 708 loss: 2.93346e-07
Iter: 709 loss: 2.93288849e-07
Iter: 710 loss: 2.93005144e-07
Iter: 711 loss: 2.93104165e-07
Iter: 712 loss: 2.9284891e-07
Iter: 713 loss: 2.93268556e-07
Iter: 714 loss: 2.92759836e-07
Iter: 715 loss: 2.92595359e-07
Iter: 716 loss: 2.92700321e-07
Iter: 717 loss: 2.92350222e-07
Iter: 718 loss: 2.92250093e-07
Iter: 719 loss: 2.92660076e-07
Iter: 720 loss: 2.9224492e-07
Iter: 721 loss: 2.91915285e-07
Iter: 722 loss: 2.92617614e-07
Iter: 723 loss: 2.91820186e-07
Iter: 724 loss: 2.91663753e-07
Iter: 725 loss: 2.91926455e-07
Iter: 726 loss: 2.91542506e-07
Iter: 727 loss: 2.91348442e-07
Iter: 728 loss: 2.92802724e-07
Iter: 729 loss: 2.9135424e-07
Iter: 730 loss: 2.91208949e-07
Iter: 731 loss: 2.92393935e-07
Iter: 732 loss: 2.91209346e-07
Iter: 733 loss: 2.91070137e-07
Iter: 734 loss: 2.91089378e-07
Iter: 735 loss: 2.90969126e-07
Iter: 736 loss: 2.90769918e-07
Iter: 737 loss: 2.91243225e-07
Iter: 738 loss: 2.90675956e-07
Iter: 739 loss: 2.90675928e-07
Iter: 740 loss: 2.90693123e-07
Iter: 741 loss: 2.90640401e-07
Iter: 742 loss: 2.90559683e-07
Iter: 743 loss: 2.90409304e-07
Iter: 744 loss: 2.92766686e-07
Iter: 745 loss: 2.90492e-07
Iter: 746 loss: 2.9023596e-07
Iter: 747 loss: 2.90513668e-07
Iter: 748 loss: 2.90181134e-07
Iter: 749 loss: 2.90024786e-07
Iter: 750 loss: 2.90322305e-07
Iter: 751 loss: 2.8998258e-07
Iter: 752 loss: 2.89792297e-07
Iter: 753 loss: 2.89857326e-07
Iter: 754 loss: 2.89616963e-07
Iter: 755 loss: 2.8949492e-07
Iter: 756 loss: 2.9008163e-07
Iter: 757 loss: 2.89400703e-07
Iter: 758 loss: 2.89215279e-07
Iter: 759 loss: 2.8948574e-07
Iter: 760 loss: 2.89170771e-07
Iter: 761 loss: 2.88882347e-07
Iter: 762 loss: 2.88985063e-07
Iter: 763 loss: 2.88636841e-07
Iter: 764 loss: 2.88456334e-07
Iter: 765 loss: 2.90947753e-07
Iter: 766 loss: 2.88341226e-07
Iter: 767 loss: 2.88156599e-07
Iter: 768 loss: 2.90127929e-07
Iter: 769 loss: 2.88095976e-07
Iter: 770 loss: 2.87969357e-07
Iter: 771 loss: 2.87989621e-07
Iter: 772 loss: 2.87847257e-07
Iter: 773 loss: 2.87678489e-07
Iter: 774 loss: 2.8866009e-07
Iter: 775 loss: 2.87614654e-07
Iter: 776 loss: 2.87477292e-07
Iter: 777 loss: 2.88312265e-07
Iter: 778 loss: 2.87520038e-07
Iter: 779 loss: 2.87241306e-07
Iter: 780 loss: 2.8734172e-07
Iter: 781 loss: 2.8706404e-07
Iter: 782 loss: 2.86978377e-07
Iter: 783 loss: 2.86814952e-07
Iter: 784 loss: 2.91157136e-07
Iter: 785 loss: 2.86797643e-07
Iter: 786 loss: 2.86509845e-07
Iter: 787 loss: 2.89091446e-07
Iter: 788 loss: 2.86430804e-07
Iter: 789 loss: 2.86424324e-07
Iter: 790 loss: 2.86306772e-07
Iter: 791 loss: 2.86217102e-07
Iter: 792 loss: 2.86115608e-07
Iter: 793 loss: 2.86798411e-07
Iter: 794 loss: 2.85919782e-07
Iter: 795 loss: 2.8575181e-07
Iter: 796 loss: 2.86523658e-07
Iter: 797 loss: 2.85729556e-07
Iter: 798 loss: 2.85557803e-07
Iter: 799 loss: 2.85684735e-07
Iter: 800 loss: 2.85497663e-07
Iter: 801 loss: 2.85396112e-07
Iter: 802 loss: 2.86773485e-07
Iter: 803 loss: 2.85388097e-07
Iter: 804 loss: 2.85203754e-07
Iter: 805 loss: 2.8560828e-07
Iter: 806 loss: 2.85246074e-07
Iter: 807 loss: 2.85080517e-07
Iter: 808 loss: 2.85297801e-07
Iter: 809 loss: 2.84985873e-07
Iter: 810 loss: 2.84876705e-07
Iter: 811 loss: 2.84849079e-07
Iter: 812 loss: 2.84721295e-07
Iter: 813 loss: 2.84839643e-07
Iter: 814 loss: 2.84669795e-07
Iter: 815 loss: 2.84626736e-07
Iter: 816 loss: 2.8444552e-07
Iter: 817 loss: 2.86314616e-07
Iter: 818 loss: 2.84423322e-07
Iter: 819 loss: 2.84313558e-07
Iter: 820 loss: 2.84404422e-07
Iter: 821 loss: 2.84201832e-07
Iter: 822 loss: 2.84036361e-07
Iter: 823 loss: 2.85907049e-07
Iter: 824 loss: 2.84032126e-07
Iter: 825 loss: 2.8379813e-07
Iter: 826 loss: 2.83809044e-07
Iter: 827 loss: 2.83733357e-07
Iter: 828 loss: 2.83488305e-07
Iter: 829 loss: 2.83745862e-07
Iter: 830 loss: 2.83395309e-07
Iter: 831 loss: 2.83166173e-07
Iter: 832 loss: 2.83706e-07
Iter: 833 loss: 2.83178053e-07
Iter: 834 loss: 2.82922059e-07
Iter: 835 loss: 2.84488635e-07
Iter: 836 loss: 2.82748431e-07
Iter: 837 loss: 2.82713927e-07
Iter: 838 loss: 2.8296239e-07
Iter: 839 loss: 2.82585347e-07
Iter: 840 loss: 2.82459467e-07
Iter: 841 loss: 2.82627497e-07
Iter: 842 loss: 2.82307212e-07
Iter: 843 loss: 2.82356609e-07
Iter: 844 loss: 2.82320627e-07
Iter: 845 loss: 2.82330632e-07
Iter: 846 loss: 2.82253126e-07
Iter: 847 loss: 2.82303517e-07
Iter: 848 loss: 2.82279302e-07
Iter: 849 loss: 2.82296497e-07
Iter: 850 loss: 2.82331683e-07
Iter: 851 loss: 2.82278421e-07
Iter: 852 loss: 2.82305592e-07
Iter: 853 loss: 2.82296071e-07
Iter: 854 loss: 2.82278506e-07
Iter: 855 loss: 2.82311561e-07
Iter: 856 loss: 2.82272879e-07
Iter: 857 loss: 2.82323725e-07
Iter: 858 loss: 2.82288141e-07
Iter: 859 loss: 2.82299567e-07
Iter: 860 loss: 2.82323839e-07
Iter: 861 loss: 2.82313522e-07
Iter: 862 loss: 2.82294877e-07
Iter: 863 loss: 2.8231284e-07
Iter: 864 loss: 2.82301016e-07
Iter: 865 loss: 2.82305109e-07
Iter: 866 loss: 2.82306786e-07
Iter: 867 loss: 2.82312527e-07
Iter: 868 loss: 2.82312527e-07
Iter: 869 loss: 2.82312527e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_4000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_4000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc93278d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc93278c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9327dcb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9380c3158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9380c3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9380c3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc932729730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc93277c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9326d76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9326cfbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9326851e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9326857b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc932670bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9326b4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc93262ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc93262e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8d81767b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc932620598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8d8176a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8d80e31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8d809d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8d80c02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8d80c16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8d8073f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8b00f9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8b00e6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8b0128840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8b00e6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8b00af1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8b00580d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8b004d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8a826f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8a8280598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8a8213840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8a81d4268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8a8203d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.77401102e-06
Iter: 2 loss: 2.18177574e-05
Iter: 3 loss: 2.21384175e-06
Iter: 4 loss: 1.95886969e-06
Iter: 5 loss: 1.5394038e-06
Iter: 6 loss: 1.53748465e-06
Iter: 7 loss: 1.27689486e-06
Iter: 8 loss: 2.75943967e-06
Iter: 9 loss: 1.24116673e-06
Iter: 10 loss: 1.02085721e-06
Iter: 11 loss: 1.72548755e-06
Iter: 12 loss: 9.58054216e-07
Iter: 13 loss: 8.90675267e-07
Iter: 14 loss: 1.56720409e-06
Iter: 15 loss: 8.88588943e-07
Iter: 16 loss: 8.4754538e-07
Iter: 17 loss: 8.41667031e-07
Iter: 18 loss: 8.12937856e-07
Iter: 19 loss: 7.80890673e-07
Iter: 20 loss: 9.20286084e-07
Iter: 21 loss: 7.74300474e-07
Iter: 22 loss: 7.55572842e-07
Iter: 23 loss: 7.55508324e-07
Iter: 24 loss: 7.40659175e-07
Iter: 25 loss: 7.21052e-07
Iter: 26 loss: 9.43433861e-07
Iter: 27 loss: 7.20599303e-07
Iter: 28 loss: 7.06447167e-07
Iter: 29 loss: 7.10894426e-07
Iter: 30 loss: 6.96323923e-07
Iter: 31 loss: 6.87552529e-07
Iter: 32 loss: 6.94790742e-07
Iter: 33 loss: 6.82235395e-07
Iter: 34 loss: 6.7513912e-07
Iter: 35 loss: 6.92184472e-07
Iter: 36 loss: 6.7254058e-07
Iter: 37 loss: 6.64533559e-07
Iter: 38 loss: 6.74329783e-07
Iter: 39 loss: 6.60199532e-07
Iter: 40 loss: 6.53978077e-07
Iter: 41 loss: 6.47141519e-07
Iter: 42 loss: 6.46241e-07
Iter: 43 loss: 6.40320422e-07
Iter: 44 loss: 6.39545817e-07
Iter: 45 loss: 6.35384367e-07
Iter: 46 loss: 6.40611574e-07
Iter: 47 loss: 6.3307283e-07
Iter: 48 loss: 6.28412522e-07
Iter: 49 loss: 6.30343152e-07
Iter: 50 loss: 6.25251118e-07
Iter: 51 loss: 6.20072171e-07
Iter: 52 loss: 6.65564244e-07
Iter: 53 loss: 6.19730145e-07
Iter: 54 loss: 6.16792e-07
Iter: 55 loss: 6.12976407e-07
Iter: 56 loss: 6.12727376e-07
Iter: 57 loss: 6.07092375e-07
Iter: 58 loss: 6.33103582e-07
Iter: 59 loss: 6.06086928e-07
Iter: 60 loss: 5.998549e-07
Iter: 61 loss: 6.13065424e-07
Iter: 62 loss: 5.97365329e-07
Iter: 63 loss: 5.94422204e-07
Iter: 64 loss: 5.94407709e-07
Iter: 65 loss: 5.91940193e-07
Iter: 66 loss: 6.02871125e-07
Iter: 67 loss: 5.91436446e-07
Iter: 68 loss: 5.89293393e-07
Iter: 69 loss: 5.90318734e-07
Iter: 70 loss: 5.87854629e-07
Iter: 71 loss: 5.85466466e-07
Iter: 72 loss: 5.83514804e-07
Iter: 73 loss: 5.82773055e-07
Iter: 74 loss: 5.79034e-07
Iter: 75 loss: 6.06240746e-07
Iter: 76 loss: 5.7869147e-07
Iter: 77 loss: 5.75257559e-07
Iter: 78 loss: 5.81717302e-07
Iter: 79 loss: 5.73807768e-07
Iter: 80 loss: 5.701134e-07
Iter: 81 loss: 5.87144655e-07
Iter: 82 loss: 5.69276324e-07
Iter: 83 loss: 5.66359859e-07
Iter: 84 loss: 5.67383097e-07
Iter: 85 loss: 5.64243578e-07
Iter: 86 loss: 5.60444391e-07
Iter: 87 loss: 5.65161145e-07
Iter: 88 loss: 5.58458339e-07
Iter: 89 loss: 5.55337863e-07
Iter: 90 loss: 5.72871897e-07
Iter: 91 loss: 5.54824965e-07
Iter: 92 loss: 5.51044309e-07
Iter: 93 loss: 5.56629e-07
Iter: 94 loss: 5.49196898e-07
Iter: 95 loss: 5.47119043e-07
Iter: 96 loss: 5.56497412e-07
Iter: 97 loss: 5.46734555e-07
Iter: 98 loss: 5.45329499e-07
Iter: 99 loss: 5.45300395e-07
Iter: 100 loss: 5.44186037e-07
Iter: 101 loss: 5.42908e-07
Iter: 102 loss: 5.42669227e-07
Iter: 103 loss: 5.41418956e-07
Iter: 104 loss: 5.44351451e-07
Iter: 105 loss: 5.41027e-07
Iter: 106 loss: 5.39659652e-07
Iter: 107 loss: 5.41365e-07
Iter: 108 loss: 5.39023347e-07
Iter: 109 loss: 5.37758808e-07
Iter: 110 loss: 5.51197445e-07
Iter: 111 loss: 5.3773158e-07
Iter: 112 loss: 5.36938501e-07
Iter: 113 loss: 5.38114421e-07
Iter: 114 loss: 5.36405594e-07
Iter: 115 loss: 5.35370816e-07
Iter: 116 loss: 5.38084464e-07
Iter: 117 loss: 5.34975243e-07
Iter: 118 loss: 5.34129583e-07
Iter: 119 loss: 5.33717241e-07
Iter: 120 loss: 5.3331047e-07
Iter: 121 loss: 5.32063723e-07
Iter: 122 loss: 5.38849235e-07
Iter: 123 loss: 5.31814862e-07
Iter: 124 loss: 5.30755187e-07
Iter: 125 loss: 5.34838364e-07
Iter: 126 loss: 5.30492912e-07
Iter: 127 loss: 5.29309546e-07
Iter: 128 loss: 5.31997102e-07
Iter: 129 loss: 5.28884755e-07
Iter: 130 loss: 5.28527494e-07
Iter: 131 loss: 5.28475653e-07
Iter: 132 loss: 5.27950419e-07
Iter: 133 loss: 5.27169959e-07
Iter: 134 loss: 5.27106806e-07
Iter: 135 loss: 5.2638984e-07
Iter: 136 loss: 5.26724421e-07
Iter: 137 loss: 5.25755297e-07
Iter: 138 loss: 5.24684083e-07
Iter: 139 loss: 5.24640654e-07
Iter: 140 loss: 5.23761798e-07
Iter: 141 loss: 5.22135281e-07
Iter: 142 loss: 5.34513333e-07
Iter: 143 loss: 5.22011476e-07
Iter: 144 loss: 5.20689468e-07
Iter: 145 loss: 5.26159454e-07
Iter: 146 loss: 5.20400761e-07
Iter: 147 loss: 5.19249511e-07
Iter: 148 loss: 5.20488356e-07
Iter: 149 loss: 5.18592969e-07
Iter: 150 loss: 5.17181775e-07
Iter: 151 loss: 5.19163336e-07
Iter: 152 loss: 5.16575597e-07
Iter: 153 loss: 5.14830731e-07
Iter: 154 loss: 5.15314582e-07
Iter: 155 loss: 5.13635e-07
Iter: 156 loss: 5.12395331e-07
Iter: 157 loss: 5.28431258e-07
Iter: 158 loss: 5.12399879e-07
Iter: 159 loss: 5.11168878e-07
Iter: 160 loss: 5.12348208e-07
Iter: 161 loss: 5.10519328e-07
Iter: 162 loss: 5.09721815e-07
Iter: 163 loss: 5.19270202e-07
Iter: 164 loss: 5.09674692e-07
Iter: 165 loss: 5.09031565e-07
Iter: 166 loss: 5.15141437e-07
Iter: 167 loss: 5.09033555e-07
Iter: 168 loss: 5.08566131e-07
Iter: 169 loss: 5.07476216e-07
Iter: 170 loss: 5.17309388e-07
Iter: 171 loss: 5.07290792e-07
Iter: 172 loss: 5.06391871e-07
Iter: 173 loss: 5.1427412e-07
Iter: 174 loss: 5.06359868e-07
Iter: 175 loss: 5.05616583e-07
Iter: 176 loss: 5.07639697e-07
Iter: 177 loss: 5.05330263e-07
Iter: 178 loss: 5.04757281e-07
Iter: 179 loss: 5.10117161e-07
Iter: 180 loss: 5.04640639e-07
Iter: 181 loss: 5.0425939e-07
Iter: 182 loss: 5.04677928e-07
Iter: 183 loss: 5.03983586e-07
Iter: 184 loss: 5.03361321e-07
Iter: 185 loss: 5.03880301e-07
Iter: 186 loss: 5.03061472e-07
Iter: 187 loss: 5.02314435e-07
Iter: 188 loss: 5.0245842e-07
Iter: 189 loss: 5.01745944e-07
Iter: 190 loss: 5.00965598e-07
Iter: 191 loss: 5.07922209e-07
Iter: 192 loss: 5.00914041e-07
Iter: 193 loss: 5.00390115e-07
Iter: 194 loss: 5.02417834e-07
Iter: 195 loss: 5.0032213e-07
Iter: 196 loss: 4.99767566e-07
Iter: 197 loss: 5.00565534e-07
Iter: 198 loss: 4.99442706e-07
Iter: 199 loss: 4.99203225e-07
Iter: 200 loss: 4.99157636e-07
Iter: 201 loss: 4.98918951e-07
Iter: 202 loss: 4.98359e-07
Iter: 203 loss: 5.02655212e-07
Iter: 204 loss: 4.98169584e-07
Iter: 205 loss: 4.97477e-07
Iter: 206 loss: 4.99196403e-07
Iter: 207 loss: 4.97213534e-07
Iter: 208 loss: 4.96487587e-07
Iter: 209 loss: 5.00954286e-07
Iter: 210 loss: 4.96372252e-07
Iter: 211 loss: 4.95890617e-07
Iter: 212 loss: 4.98784573e-07
Iter: 213 loss: 4.95774657e-07
Iter: 214 loss: 4.95293307e-07
Iter: 215 loss: 4.96833195e-07
Iter: 216 loss: 4.95126187e-07
Iter: 217 loss: 4.94718392e-07
Iter: 218 loss: 4.94632161e-07
Iter: 219 loss: 4.9429e-07
Iter: 220 loss: 4.93814298e-07
Iter: 221 loss: 4.97109113e-07
Iter: 222 loss: 4.93629841e-07
Iter: 223 loss: 4.93154118e-07
Iter: 224 loss: 4.92954541e-07
Iter: 225 loss: 4.92724098e-07
Iter: 226 loss: 4.92187667e-07
Iter: 227 loss: 4.99869657e-07
Iter: 228 loss: 4.92196648e-07
Iter: 229 loss: 4.91808692e-07
Iter: 230 loss: 4.9301218e-07
Iter: 231 loss: 4.91605e-07
Iter: 232 loss: 4.91280048e-07
Iter: 233 loss: 4.91298124e-07
Iter: 234 loss: 4.91040737e-07
Iter: 235 loss: 4.90725e-07
Iter: 236 loss: 4.90690582e-07
Iter: 237 loss: 4.90345485e-07
Iter: 238 loss: 4.90008745e-07
Iter: 239 loss: 4.89969068e-07
Iter: 240 loss: 4.89462082e-07
Iter: 241 loss: 4.93701805e-07
Iter: 242 loss: 4.89349418e-07
Iter: 243 loss: 4.88968453e-07
Iter: 244 loss: 4.90647722e-07
Iter: 245 loss: 4.88899616e-07
Iter: 246 loss: 4.88498813e-07
Iter: 247 loss: 4.89591116e-07
Iter: 248 loss: 4.88327032e-07
Iter: 249 loss: 4.87974035e-07
Iter: 250 loss: 4.88042417e-07
Iter: 251 loss: 4.87718182e-07
Iter: 252 loss: 4.87109787e-07
Iter: 253 loss: 4.88339424e-07
Iter: 254 loss: 4.86992349e-07
Iter: 255 loss: 4.86608315e-07
Iter: 256 loss: 4.87486204e-07
Iter: 257 loss: 4.86402826e-07
Iter: 258 loss: 4.85911244e-07
Iter: 259 loss: 4.86993372e-07
Iter: 260 loss: 4.85717e-07
Iter: 261 loss: 4.85328428e-07
Iter: 262 loss: 4.90938476e-07
Iter: 263 loss: 4.85325472e-07
Iter: 264 loss: 4.85126634e-07
Iter: 265 loss: 4.8728441e-07
Iter: 266 loss: 4.8513e-07
Iter: 267 loss: 4.8485424e-07
Iter: 268 loss: 4.84877546e-07
Iter: 269 loss: 4.8467632e-07
Iter: 270 loss: 4.84400744e-07
Iter: 271 loss: 4.83975e-07
Iter: 272 loss: 4.90865602e-07
Iter: 273 loss: 4.84021314e-07
Iter: 274 loss: 4.83532403e-07
Iter: 275 loss: 4.89653587e-07
Iter: 276 loss: 4.83511371e-07
Iter: 277 loss: 4.83204872e-07
Iter: 278 loss: 4.84315194e-07
Iter: 279 loss: 4.83130634e-07
Iter: 280 loss: 4.8287643e-07
Iter: 281 loss: 4.83514839e-07
Iter: 282 loss: 4.8267907e-07
Iter: 283 loss: 4.8237132e-07
Iter: 284 loss: 4.83234487e-07
Iter: 285 loss: 4.82317432e-07
Iter: 286 loss: 4.82018322e-07
Iter: 287 loss: 4.81907e-07
Iter: 288 loss: 4.81714665e-07
Iter: 289 loss: 4.81266056e-07
Iter: 290 loss: 4.82729206e-07
Iter: 291 loss: 4.8114606e-07
Iter: 292 loss: 4.80660219e-07
Iter: 293 loss: 4.8158148e-07
Iter: 294 loss: 4.80482527e-07
Iter: 295 loss: 4.80070184e-07
Iter: 296 loss: 4.83204644e-07
Iter: 297 loss: 4.80024e-07
Iter: 298 loss: 4.79671769e-07
Iter: 299 loss: 4.83740735e-07
Iter: 300 loss: 4.79735775e-07
Iter: 301 loss: 4.79472362e-07
Iter: 302 loss: 4.79903747e-07
Iter: 303 loss: 4.79328264e-07
Iter: 304 loss: 4.79170694e-07
Iter: 305 loss: 4.78756874e-07
Iter: 306 loss: 4.87105808e-07
Iter: 307 loss: 4.78721574e-07
Iter: 308 loss: 4.7832566e-07
Iter: 309 loss: 4.78959237e-07
Iter: 310 loss: 4.78079187e-07
Iter: 311 loss: 4.77740457e-07
Iter: 312 loss: 4.81951361e-07
Iter: 313 loss: 4.77758363e-07
Iter: 314 loss: 4.77426852e-07
Iter: 315 loss: 4.77609774e-07
Iter: 316 loss: 4.77207948e-07
Iter: 317 loss: 4.76855291e-07
Iter: 318 loss: 4.78671154e-07
Iter: 319 loss: 4.76758942e-07
Iter: 320 loss: 4.7647643e-07
Iter: 321 loss: 4.76492517e-07
Iter: 322 loss: 4.76281457e-07
Iter: 323 loss: 4.75903306e-07
Iter: 324 loss: 4.76557e-07
Iter: 325 loss: 4.75718821e-07
Iter: 326 loss: 4.75319951e-07
Iter: 327 loss: 4.75954863e-07
Iter: 328 loss: 4.7507416e-07
Iter: 329 loss: 4.74761208e-07
Iter: 330 loss: 4.79567575e-07
Iter: 331 loss: 4.74760014e-07
Iter: 332 loss: 4.74560636e-07
Iter: 333 loss: 4.75944518e-07
Iter: 334 loss: 4.74603269e-07
Iter: 335 loss: 4.74350287e-07
Iter: 336 loss: 4.74935234e-07
Iter: 337 loss: 4.74239926e-07
Iter: 338 loss: 4.74077353e-07
Iter: 339 loss: 4.73881244e-07
Iter: 340 loss: 4.73867402e-07
Iter: 341 loss: 4.73609617e-07
Iter: 342 loss: 4.73635282e-07
Iter: 343 loss: 4.73398387e-07
Iter: 344 loss: 4.73085322e-07
Iter: 345 loss: 4.74810776e-07
Iter: 346 loss: 4.73117552e-07
Iter: 347 loss: 4.72718966e-07
Iter: 348 loss: 4.74062119e-07
Iter: 349 loss: 4.7274e-07
Iter: 350 loss: 4.72579075e-07
Iter: 351 loss: 4.73160895e-07
Iter: 352 loss: 4.72435772e-07
Iter: 353 loss: 4.72220137e-07
Iter: 354 loss: 4.72095934e-07
Iter: 355 loss: 4.72018201e-07
Iter: 356 loss: 4.71738332e-07
Iter: 357 loss: 4.73027342e-07
Iter: 358 loss: 4.7156e-07
Iter: 359 loss: 4.7130888e-07
Iter: 360 loss: 4.71276138e-07
Iter: 361 loss: 4.71110127e-07
Iter: 362 loss: 4.70807578e-07
Iter: 363 loss: 4.74092872e-07
Iter: 364 loss: 4.70808516e-07
Iter: 365 loss: 4.70535412e-07
Iter: 366 loss: 4.72773763e-07
Iter: 367 loss: 4.70560281e-07
Iter: 368 loss: 4.70346606e-07
Iter: 369 loss: 4.71393e-07
Iter: 370 loss: 4.70324153e-07
Iter: 371 loss: 4.70181419e-07
Iter: 372 loss: 4.70061224e-07
Iter: 373 loss: 4.6998926e-07
Iter: 374 loss: 4.69807276e-07
Iter: 375 loss: 4.69712262e-07
Iter: 376 loss: 4.6963595e-07
Iter: 377 loss: 4.69227132e-07
Iter: 378 loss: 4.70203844e-07
Iter: 379 loss: 4.69144481e-07
Iter: 380 loss: 4.6880831e-07
Iter: 381 loss: 4.71095802e-07
Iter: 382 loss: 4.68820105e-07
Iter: 383 loss: 4.6849982e-07
Iter: 384 loss: 4.69524281e-07
Iter: 385 loss: 4.68420751e-07
Iter: 386 loss: 4.68121215e-07
Iter: 387 loss: 4.68344126e-07
Iter: 388 loss: 4.67999456e-07
Iter: 389 loss: 4.67686363e-07
Iter: 390 loss: 4.67874116e-07
Iter: 391 loss: 4.67447364e-07
Iter: 392 loss: 4.67023256e-07
Iter: 393 loss: 4.67759179e-07
Iter: 394 loss: 4.66910478e-07
Iter: 395 loss: 4.66531503e-07
Iter: 396 loss: 4.68712642e-07
Iter: 397 loss: 4.6646673e-07
Iter: 398 loss: 4.66147782e-07
Iter: 399 loss: 4.67740733e-07
Iter: 400 loss: 4.66114557e-07
Iter: 401 loss: 4.65867657e-07
Iter: 402 loss: 4.68734754e-07
Iter: 403 loss: 4.65818e-07
Iter: 404 loss: 4.65580428e-07
Iter: 405 loss: 4.6562397e-07
Iter: 406 loss: 4.6543741e-07
Iter: 407 loss: 4.65319943e-07
Iter: 408 loss: 4.65142705e-07
Iter: 409 loss: 4.64990933e-07
Iter: 410 loss: 4.64780612e-07
Iter: 411 loss: 4.66228641e-07
Iter: 412 loss: 4.64683637e-07
Iter: 413 loss: 4.64500545e-07
Iter: 414 loss: 4.663124e-07
Iter: 415 loss: 4.64432617e-07
Iter: 416 loss: 4.64267629e-07
Iter: 417 loss: 4.65124344e-07
Iter: 418 loss: 4.64284369e-07
Iter: 419 loss: 4.6402613e-07
Iter: 420 loss: 4.64223461e-07
Iter: 421 loss: 4.64049805e-07
Iter: 422 loss: 4.63824449e-07
Iter: 423 loss: 4.63973947e-07
Iter: 424 loss: 4.63716532e-07
Iter: 425 loss: 4.63495269e-07
Iter: 426 loss: 4.63639708e-07
Iter: 427 loss: 4.63370895e-07
Iter: 428 loss: 4.63061269e-07
Iter: 429 loss: 4.63899568e-07
Iter: 430 loss: 4.62987146e-07
Iter: 431 loss: 4.62773016e-07
Iter: 432 loss: 4.64130579e-07
Iter: 433 loss: 4.62726518e-07
Iter: 434 loss: 4.62486128e-07
Iter: 435 loss: 4.6496524e-07
Iter: 436 loss: 4.62515146e-07
Iter: 437 loss: 4.62397907e-07
Iter: 438 loss: 4.6235138e-07
Iter: 439 loss: 4.62295304e-07
Iter: 440 loss: 4.62031608e-07
Iter: 441 loss: 4.61781269e-07
Iter: 442 loss: 4.61791359e-07
Iter: 443 loss: 4.61446575e-07
Iter: 444 loss: 4.63072212e-07
Iter: 445 loss: 4.61401328e-07
Iter: 446 loss: 4.61115576e-07
Iter: 447 loss: 4.62441761e-07
Iter: 448 loss: 4.61047421e-07
Iter: 449 loss: 4.60790574e-07
Iter: 450 loss: 4.62888806e-07
Iter: 451 loss: 4.6078037e-07
Iter: 452 loss: 4.60564e-07
Iter: 453 loss: 4.6076218e-07
Iter: 454 loss: 4.60564678e-07
Iter: 455 loss: 4.60357853e-07
Iter: 456 loss: 4.60321189e-07
Iter: 457 loss: 4.60093815e-07
Iter: 458 loss: 4.59819546e-07
Iter: 459 loss: 4.60727364e-07
Iter: 460 loss: 4.59784076e-07
Iter: 461 loss: 4.59620281e-07
Iter: 462 loss: 4.59865873e-07
Iter: 463 loss: 4.59443328e-07
Iter: 464 loss: 4.59109117e-07
Iter: 465 loss: 4.60477452e-07
Iter: 466 loss: 4.59146548e-07
Iter: 467 loss: 4.58984317e-07
Iter: 468 loss: 4.59037381e-07
Iter: 469 loss: 4.58861706e-07
Iter: 470 loss: 4.58895471e-07
Iter: 471 loss: 4.58817851e-07
Iter: 472 loss: 4.58646298e-07
Iter: 473 loss: 4.5847105e-07
Iter: 474 loss: 4.58433135e-07
Iter: 475 loss: 4.5818652e-07
Iter: 476 loss: 4.58689271e-07
Iter: 477 loss: 4.5802679e-07
Iter: 478 loss: 4.57837785e-07
Iter: 479 loss: 4.58392634e-07
Iter: 480 loss: 4.57772757e-07
Iter: 481 loss: 4.57583752e-07
Iter: 482 loss: 4.5993e-07
Iter: 483 loss: 4.575449e-07
Iter: 484 loss: 4.57414046e-07
Iter: 485 loss: 4.57486806e-07
Iter: 486 loss: 4.57226577e-07
Iter: 487 loss: 4.56996531e-07
Iter: 488 loss: 4.57519235e-07
Iter: 489 loss: 4.56923e-07
Iter: 490 loss: 4.56719874e-07
Iter: 491 loss: 4.57118972e-07
Iter: 492 loss: 4.566906e-07
Iter: 493 loss: 4.56456036e-07
Iter: 494 loss: 4.56377649e-07
Iter: 495 loss: 4.56244379e-07
Iter: 496 loss: 4.55974856e-07
Iter: 497 loss: 4.5794809e-07
Iter: 498 loss: 4.55976874e-07
Iter: 499 loss: 4.55870634e-07
Iter: 500 loss: 4.55880382e-07
Iter: 501 loss: 4.55700643e-07
Iter: 502 loss: 4.55939812e-07
Iter: 503 loss: 4.55692117e-07
Iter: 504 loss: 4.55611172e-07
Iter: 505 loss: 4.5545994e-07
Iter: 506 loss: 4.55467784e-07
Iter: 507 loss: 4.55361373e-07
Iter: 508 loss: 4.55314165e-07
Iter: 509 loss: 4.55168845e-07
Iter: 510 loss: 4.54922e-07
Iter: 511 loss: 4.55576867e-07
Iter: 512 loss: 4.54922258e-07
Iter: 513 loss: 4.54772447e-07
Iter: 514 loss: 4.56548861e-07
Iter: 515 loss: 4.54735812e-07
Iter: 516 loss: 4.54570824e-07
Iter: 517 loss: 4.54906058e-07
Iter: 518 loss: 4.54516112e-07
Iter: 519 loss: 4.54388584e-07
Iter: 520 loss: 4.5424639e-07
Iter: 521 loss: 4.54254092e-07
Iter: 522 loss: 4.53951145e-07
Iter: 523 loss: 4.55864949e-07
Iter: 524 loss: 4.54001508e-07
Iter: 525 loss: 4.53859712e-07
Iter: 526 loss: 4.53715245e-07
Iter: 527 loss: 4.53651722e-07
Iter: 528 loss: 4.53397774e-07
Iter: 529 loss: 4.54865642e-07
Iter: 530 loss: 4.53463684e-07
Iter: 531 loss: 4.53307877e-07
Iter: 532 loss: 4.53888447e-07
Iter: 533 loss: 4.53220935e-07
Iter: 534 loss: 4.53112762e-07
Iter: 535 loss: 4.53133026e-07
Iter: 536 loss: 4.53028662e-07
Iter: 537 loss: 4.52954225e-07
Iter: 538 loss: 4.52935694e-07
Iter: 539 loss: 4.52765022e-07
Iter: 540 loss: 4.52718041e-07
Iter: 541 loss: 4.52615723e-07
Iter: 542 loss: 4.52412053e-07
Iter: 543 loss: 4.53196407e-07
Iter: 544 loss: 4.52395113e-07
Iter: 545 loss: 4.52224128e-07
Iter: 546 loss: 4.52601682e-07
Iter: 547 loss: 4.52142331e-07
Iter: 548 loss: 4.51940338e-07
Iter: 549 loss: 4.51937524e-07
Iter: 550 loss: 4.51891964e-07
Iter: 551 loss: 4.51728766e-07
Iter: 552 loss: 4.51746928e-07
Iter: 553 loss: 4.51583475e-07
Iter: 554 loss: 4.52743791e-07
Iter: 555 loss: 4.51545e-07
Iter: 556 loss: 4.5141573e-07
Iter: 557 loss: 4.5148343e-07
Iter: 558 loss: 4.51348569e-07
Iter: 559 loss: 4.51165704e-07
Iter: 560 loss: 4.51705375e-07
Iter: 561 loss: 4.51150839e-07
Iter: 562 loss: 4.50994918e-07
Iter: 563 loss: 4.51022402e-07
Iter: 564 loss: 4.5085028e-07
Iter: 565 loss: 4.5084866e-07
Iter: 566 loss: 4.50728237e-07
Iter: 567 loss: 4.50694245e-07
Iter: 568 loss: 4.50573651e-07
Iter: 569 loss: 4.50576238e-07
Iter: 570 loss: 4.50473067e-07
Iter: 571 loss: 4.50381066e-07
Iter: 572 loss: 4.50403888e-07
Iter: 573 loss: 4.50234552e-07
Iter: 574 loss: 4.50430377e-07
Iter: 575 loss: 4.50065556e-07
Iter: 576 loss: 4.49937602e-07
Iter: 577 loss: 4.50083235e-07
Iter: 578 loss: 4.49786484e-07
Iter: 579 loss: 4.4966103e-07
Iter: 580 loss: 4.51137964e-07
Iter: 581 loss: 4.49634626e-07
Iter: 582 loss: 4.49456707e-07
Iter: 583 loss: 4.50505723e-07
Iter: 584 loss: 4.49472395e-07
Iter: 585 loss: 4.49341542e-07
Iter: 586 loss: 4.49313e-07
Iter: 587 loss: 4.49286858e-07
Iter: 588 loss: 4.49097683e-07
Iter: 589 loss: 4.49443888e-07
Iter: 590 loss: 4.49039476e-07
Iter: 591 loss: 4.48929711e-07
Iter: 592 loss: 4.49864785e-07
Iter: 593 loss: 4.48935964e-07
Iter: 594 loss: 4.48843082e-07
Iter: 595 loss: 4.48616277e-07
Iter: 596 loss: 4.48675138e-07
Iter: 597 loss: 4.48505261e-07
Iter: 598 loss: 4.48519927e-07
Iter: 599 loss: 4.48361e-07
Iter: 600 loss: 4.49211655e-07
Iter: 601 loss: 4.482674e-07
Iter: 602 loss: 4.48229912e-07
Iter: 603 loss: 4.48089622e-07
Iter: 604 loss: 4.48174205e-07
Iter: 605 loss: 4.47987475e-07
Iter: 606 loss: 4.48304831e-07
Iter: 607 loss: 4.47903233e-07
Iter: 608 loss: 4.47641696e-07
Iter: 609 loss: 4.47898202e-07
Iter: 610 loss: 4.47690297e-07
Iter: 611 loss: 4.47540032e-07
Iter: 612 loss: 4.47582977e-07
Iter: 613 loss: 4.47394939e-07
Iter: 614 loss: 4.47265e-07
Iter: 615 loss: 4.49389177e-07
Iter: 616 loss: 4.47225858e-07
Iter: 617 loss: 4.4713795e-07
Iter: 618 loss: 4.47995376e-07
Iter: 619 loss: 4.47167849e-07
Iter: 620 loss: 4.47020341e-07
Iter: 621 loss: 4.47160176e-07
Iter: 622 loss: 4.46972535e-07
Iter: 623 loss: 4.46890539e-07
Iter: 624 loss: 4.46852198e-07
Iter: 625 loss: 4.46776511e-07
Iter: 626 loss: 4.46657651e-07
Iter: 627 loss: 4.48145158e-07
Iter: 628 loss: 4.4659663e-07
Iter: 629 loss: 4.46558886e-07
Iter: 630 loss: 4.46287601e-07
Iter: 631 loss: 4.50523885e-07
Iter: 632 loss: 4.46347656e-07
Iter: 633 loss: 4.46143076e-07
Iter: 634 loss: 4.48065975e-07
Iter: 635 loss: 4.46115621e-07
Iter: 636 loss: 4.46112324e-07
Iter: 637 loss: 4.46091661e-07
Iter: 638 loss: 4.46121135e-07
Iter: 639 loss: 4.4610664e-07
Iter: 640 loss: 4.46122158e-07
Iter: 641 loss: 4.46076712e-07
Iter: 642 loss: 4.46127217e-07
Iter: 643 loss: 4.46124233e-07
Iter: 644 loss: 4.46098596e-07
Iter: 645 loss: 4.46123522e-07
Iter: 646 loss: 4.46103684e-07
Iter: 647 loss: 4.46118662e-07
Iter: 648 loss: 4.46097943e-07
Iter: 649 loss: 4.46075433e-07
Iter: 650 loss: 4.46100103e-07
Iter: 651 loss: 4.46099648e-07
Iter: 652 loss: 4.46086915e-07
Iter: 653 loss: 4.46101e-07
Iter: 654 loss: 4.46099193e-07
Iter: 655 loss: 4.46098227e-07
Iter: 656 loss: 4.4608737e-07
Iter: 657 loss: 4.46087142e-07
Iter: 658 loss: 4.46087029e-07
Iter: 659 loss: 4.46087029e-07
Iter: 660 loss: 4.46084e-07
Iter: 661 loss: 4.46098227e-07
Iter: 662 loss: 4.46098227e-07
Iter: 663 loss: 4.46084e-07
Iter: 664 loss: 4.46098227e-07
Iter: 665 loss: 4.46084e-07
Iter: 666 loss: 4.45843312e-07
Iter: 667 loss: 4.45816937e-07
Iter: 668 loss: 4.45735452e-07
Iter: 669 loss: 4.46190427e-07
Iter: 670 loss: 4.45652233e-07
Iter: 671 loss: 4.45586977e-07
Iter: 672 loss: 4.45821343e-07
Iter: 673 loss: 4.45572823e-07
Iter: 674 loss: 4.45436854e-07
Iter: 675 loss: 4.45956573e-07
Iter: 676 loss: 4.45426451e-07
Iter: 677 loss: 4.45303243e-07
Iter: 678 loss: 4.45608691e-07
Iter: 679 loss: 4.45297388e-07
Iter: 680 loss: 4.45185464e-07
Iter: 681 loss: 4.45424945e-07
Iter: 682 loss: 4.45187254e-07
Iter: 683 loss: 4.45104291e-07
Iter: 684 loss: 4.4512791e-07
Iter: 685 loss: 4.44986028e-07
Iter: 686 loss: 4.44933733e-07
Iter: 687 loss: 4.4505498e-07
Iter: 688 loss: 4.44869215e-07
Iter: 689 loss: 4.44716193e-07
Iter: 690 loss: 4.45687533e-07
Iter: 691 loss: 4.44752743e-07
Iter: 692 loss: 4.44665687e-07
Iter: 693 loss: 4.44671173e-07
Iter: 694 loss: 4.44644314e-07
Iter: 695 loss: 4.44454599e-07
Iter: 696 loss: 4.44659747e-07
Iter: 697 loss: 4.44383716e-07
Iter: 698 loss: 4.44312917e-07
Iter: 699 loss: 4.44143836e-07
Iter: 700 loss: 4.46251192e-07
Iter: 701 loss: 4.440802e-07
Iter: 702 loss: 4.4375625e-07
Iter: 703 loss: 4.44139744e-07
Iter: 704 loss: 4.43657768e-07
Iter: 705 loss: 4.43325433e-07
Iter: 706 loss: 4.44299246e-07
Iter: 707 loss: 4.43286353e-07
Iter: 708 loss: 4.43064323e-07
Iter: 709 loss: 4.44302856e-07
Iter: 710 loss: 4.43000744e-07
Iter: 711 loss: 4.42806254e-07
Iter: 712 loss: 4.44113255e-07
Iter: 713 loss: 4.42843742e-07
Iter: 714 loss: 4.42645785e-07
Iter: 715 loss: 4.4272096e-07
Iter: 716 loss: 4.42539601e-07
Iter: 717 loss: 4.42389762e-07
Iter: 718 loss: 4.44399518e-07
Iter: 719 loss: 4.42401e-07
Iter: 720 loss: 4.4225655e-07
Iter: 721 loss: 4.42147922e-07
Iter: 722 loss: 4.42133597e-07
Iter: 723 loss: 4.41907e-07
Iter: 724 loss: 4.42162417e-07
Iter: 725 loss: 4.41731515e-07
Iter: 726 loss: 4.41532563e-07
Iter: 727 loss: 4.43516541e-07
Iter: 728 loss: 4.4152182e-07
Iter: 729 loss: 4.41389972e-07
Iter: 730 loss: 4.43447391e-07
Iter: 731 loss: 4.41396509e-07
Iter: 732 loss: 4.41319e-07
Iter: 733 loss: 4.41184511e-07
Iter: 734 loss: 4.41172233e-07
Iter: 735 loss: 4.40947645e-07
Iter: 736 loss: 4.40719077e-07
Iter: 737 loss: 4.40678264e-07
Iter: 738 loss: 4.404842e-07
Iter: 739 loss: 4.42147609e-07
Iter: 740 loss: 4.40551162e-07
Iter: 741 loss: 4.40307474e-07
Iter: 742 loss: 4.40087746e-07
Iter: 743 loss: 4.40109318e-07
Iter: 744 loss: 4.398741e-07
Iter: 745 loss: 4.41982053e-07
Iter: 746 loss: 4.39874242e-07
Iter: 747 loss: 4.39715166e-07
Iter: 748 loss: 4.4142962e-07
Iter: 749 loss: 4.39685692e-07
Iter: 750 loss: 4.39619896e-07
Iter: 751 loss: 4.3971022e-07
Iter: 752 loss: 4.39581584e-07
Iter: 753 loss: 4.3947054e-07
Iter: 754 loss: 4.39883053e-07
Iter: 755 loss: 4.3936322e-07
Iter: 756 loss: 4.39258969e-07
Iter: 757 loss: 4.39280825e-07
Iter: 758 loss: 4.39119816e-07
Iter: 759 loss: 4.38864873e-07
Iter: 760 loss: 4.38970403e-07
Iter: 761 loss: 4.38707218e-07
Iter: 762 loss: 4.38878033e-07
Iter: 763 loss: 4.38689199e-07
Iter: 764 loss: 4.38562523e-07
Iter: 765 loss: 4.38416e-07
Iter: 766 loss: 4.38492975e-07
Iter: 767 loss: 4.38375139e-07
Iter: 768 loss: 4.38275919e-07
Iter: 769 loss: 4.38209156e-07
Iter: 770 loss: 4.38091604e-07
Iter: 771 loss: 4.3819972e-07
Iter: 772 loss: 4.37998239e-07
Iter: 773 loss: 4.37739516e-07
Iter: 774 loss: 4.37974137e-07
Iter: 775 loss: 4.37646293e-07
Iter: 776 loss: 4.37343033e-07
Iter: 777 loss: 4.37706888e-07
Iter: 778 loss: 4.37294773e-07
Iter: 779 loss: 4.3700669e-07
Iter: 780 loss: 4.37026699e-07
Iter: 781 loss: 4.36931487e-07
Iter: 782 loss: 4.37526097e-07
Iter: 783 loss: 4.36872739e-07
Iter: 784 loss: 4.36760473e-07
Iter: 785 loss: 4.37009248e-07
Iter: 786 loss: 4.36671883e-07
Iter: 787 loss: 4.36586845e-07
Iter: 788 loss: 4.37279112e-07
Iter: 789 loss: 4.36500187e-07
Iter: 790 loss: 4.36462955e-07
Iter: 791 loss: 4.36179107e-07
Iter: 792 loss: 4.36138436e-07
Iter: 793 loss: 4.36253e-07
Iter: 794 loss: 4.36075084e-07
Iter: 795 loss: 4.360312e-07
Iter: 796 loss: 4.3601969e-07
Iter: 797 loss: 4.35903e-07
Iter: 798 loss: 4.3582952e-07
Iter: 799 loss: 4.3600096e-07
Iter: 800 loss: 4.35806072e-07
Iter: 801 loss: 4.35631762e-07
Iter: 802 loss: 4.36079688e-07
Iter: 803 loss: 4.35617778e-07
Iter: 804 loss: 4.35520803e-07
Iter: 805 loss: 4.35419651e-07
Iter: 806 loss: 4.35427154e-07
Iter: 807 loss: 4.35266344e-07
Iter: 808 loss: 4.35521201e-07
Iter: 809 loss: 4.35177043e-07
Iter: 810 loss: 4.35038203e-07
Iter: 811 loss: 4.36794522e-07
Iter: 812 loss: 4.35023082e-07
Iter: 813 loss: 4.34957144e-07
Iter: 814 loss: 4.35648957e-07
Iter: 815 loss: 4.34942706e-07
Iter: 816 loss: 4.34836551e-07
Iter: 817 loss: 4.34793833e-07
Iter: 818 loss: 4.34771323e-07
Iter: 819 loss: 4.34647603e-07
Iter: 820 loss: 4.35585434e-07
Iter: 821 loss: 4.34663974e-07
Iter: 822 loss: 4.34543267e-07
Iter: 823 loss: 4.34426568e-07
Iter: 824 loss: 4.3450396e-07
Iter: 825 loss: 4.34316519e-07
Iter: 826 loss: 4.34334254e-07
Iter: 827 loss: 4.34248477e-07
Iter: 828 loss: 4.34776553e-07
Iter: 829 loss: 4.34251263e-07
Iter: 830 loss: 4.34181601e-07
Iter: 831 loss: 4.34048985e-07
Iter: 832 loss: 4.36364388e-07
Iter: 833 loss: 4.34081016e-07
Iter: 834 loss: 4.33952977e-07
Iter: 835 loss: 4.34811454e-07
Iter: 836 loss: 4.33915176e-07
Iter: 837 loss: 4.33826756e-07
Iter: 838 loss: 4.33714206e-07
Iter: 839 loss: 4.33702269e-07
Iter: 840 loss: 4.33511389e-07
Iter: 841 loss: 4.34469143e-07
Iter: 842 loss: 4.33445962e-07
Iter: 843 loss: 4.33233e-07
Iter: 844 loss: 4.33217139e-07
Iter: 845 loss: 4.33167287e-07
Iter: 846 loss: 4.32893728e-07
Iter: 847 loss: 4.34264535e-07
Iter: 848 loss: 4.32882246e-07
Iter: 849 loss: 4.32601382e-07
Iter: 850 loss: 4.34619636e-07
Iter: 851 loss: 4.32649529e-07
Iter: 852 loss: 4.3251805e-07
Iter: 853 loss: 4.32699267e-07
Iter: 854 loss: 4.32472376e-07
Iter: 855 loss: 4.32286839e-07
Iter: 856 loss: 4.32573472e-07
Iter: 857 loss: 4.32218059e-07
Iter: 858 loss: 4.32038348e-07
Iter: 859 loss: 4.32489884e-07
Iter: 860 loss: 4.320664e-07
Iter: 861 loss: 4.31999695e-07
Iter: 862 loss: 4.3190596e-07
Iter: 863 loss: 4.31894478e-07
Iter: 864 loss: 4.3180313e-07
Iter: 865 loss: 4.32246281e-07
Iter: 866 loss: 4.317383e-07
Iter: 867 loss: 4.31509648e-07
Iter: 868 loss: 4.3288594e-07
Iter: 869 loss: 4.315323e-07
Iter: 870 loss: 4.31414207e-07
Iter: 871 loss: 4.31847639e-07
Iter: 872 loss: 4.31385757e-07
Iter: 873 loss: 4.31273719e-07
Iter: 874 loss: 4.31162476e-07
Iter: 875 loss: 4.31190244e-07
Iter: 876 loss: 4.31018805e-07
Iter: 877 loss: 4.31399258e-07
Iter: 878 loss: 4.30888122e-07
Iter: 879 loss: 4.30733706e-07
Iter: 880 loss: 4.3124777e-07
Iter: 881 loss: 4.30700396e-07
Iter: 882 loss: 4.30549619e-07
Iter: 883 loss: 4.31197066e-07
Iter: 884 loss: 4.30528701e-07
Iter: 885 loss: 4.30356835e-07
Iter: 886 loss: 4.31933415e-07
Iter: 887 loss: 4.30396511e-07
Iter: 888 loss: 4.30283734e-07
Iter: 889 loss: 4.30364366e-07
Iter: 890 loss: 4.30200885e-07
Iter: 891 loss: 4.30131109e-07
Iter: 892 loss: 4.3049576e-07
Iter: 893 loss: 4.30102517e-07
Iter: 894 loss: 4.30073015e-07
Iter: 895 loss: 4.30036152e-07
Iter: 896 loss: 4.29965695e-07
Iter: 897 loss: 4.30057867e-07
Iter: 898 loss: 4.29964501e-07
Iter: 899 loss: 4.29875257e-07
Iter: 900 loss: 4.29722263e-07
Iter: 901 loss: 4.31776357e-07
Iter: 902 loss: 4.29640892e-07
Iter: 903 loss: 4.29548322e-07
Iter: 904 loss: 4.29583594e-07
Iter: 905 loss: 4.2945112e-07
Iter: 906 loss: 4.29369521e-07
Iter: 907 loss: 4.29421675e-07
Iter: 908 loss: 4.29199986e-07
Iter: 909 loss: 4.29470361e-07
Iter: 910 loss: 4.29146496e-07
Iter: 911 loss: 4.29040625e-07
Iter: 912 loss: 4.29371283e-07
Iter: 913 loss: 4.28885443e-07
Iter: 914 loss: 4.28742823e-07
Iter: 915 loss: 4.28982275e-07
Iter: 916 loss: 4.28716135e-07
Iter: 917 loss: 4.28642693e-07
Iter: 918 loss: 4.28630585e-07
Iter: 919 loss: 4.28619046e-07
Iter: 920 loss: 4.28568342e-07
Iter: 921 loss: 4.28532047e-07
Iter: 922 loss: 4.28406537e-07
Iter: 923 loss: 4.28636639e-07
Iter: 924 loss: 4.28372971e-07
Iter: 925 loss: 4.28305782e-07
Iter: 926 loss: 4.28481485e-07
Iter: 927 loss: 4.28212388e-07
Iter: 928 loss: 4.28196188e-07
Iter: 929 loss: 4.28805862e-07
Iter: 930 loss: 4.28153953e-07
Iter: 931 loss: 4.28077556e-07
Iter: 932 loss: 4.28477506e-07
Iter: 933 loss: 4.27981377e-07
Iter: 934 loss: 4.27915978e-07
Iter: 935 loss: 4.27947867e-07
Iter: 936 loss: 4.29132882e-07
Iter: 937 loss: 4.27941131e-07
Iter: 938 loss: 4.27801922e-07
Iter: 939 loss: 4.28104727e-07
Iter: 940 loss: 4.27724501e-07
Iter: 941 loss: 4.27645034e-07
Iter: 942 loss: 4.28836699e-07
Iter: 943 loss: 4.27635939e-07
Iter: 944 loss: 4.27544506e-07
Iter: 945 loss: 4.27400096e-07
Iter: 946 loss: 4.27397168e-07
Iter: 947 loss: 4.27371504e-07
Iter: 948 loss: 4.2818661e-07
Iter: 949 loss: 4.27291297e-07
Iter: 950 loss: 4.27105249e-07
Iter: 951 loss: 4.27211546e-07
Iter: 952 loss: 4.27044284e-07
Iter: 953 loss: 4.27009411e-07
Iter: 954 loss: 4.27790525e-07
Iter: 955 loss: 4.26948304e-07
Iter: 956 loss: 4.26811113e-07
Iter: 957 loss: 4.27472344e-07
Iter: 958 loss: 4.26761943e-07
Iter: 959 loss: 4.26712916e-07
Iter: 960 loss: 4.26780673e-07
Iter: 961 loss: 4.26708709e-07
Iter: 962 loss: 4.26615145e-07
Iter: 963 loss: 4.27005148e-07
Iter: 964 loss: 4.26586951e-07
Iter: 965 loss: 4.26542613e-07
Iter: 966 loss: 4.27169283e-07
Iter: 967 loss: 4.26562906e-07
Iter: 968 loss: 4.26423213e-07
Iter: 969 loss: 4.26394678e-07
Iter: 970 loss: 4.26340193e-07
Iter: 971 loss: 4.26260129e-07
Iter: 972 loss: 4.26143401e-07
Iter: 973 loss: 4.26107732e-07
Iter: 974 loss: 4.26001947e-07
Iter: 975 loss: 4.26921787e-07
Iter: 976 loss: 4.2604546e-07
Iter: 977 loss: 4.2594985e-07
Iter: 978 loss: 4.2651078e-07
Iter: 979 loss: 4.25920859e-07
Iter: 980 loss: 4.25824538e-07
Iter: 981 loss: 4.25978357e-07
Iter: 982 loss: 4.25874333e-07
Iter: 983 loss: 4.25759879e-07
Iter: 984 loss: 4.25633743e-07
Iter: 985 loss: 4.25625643e-07
Iter: 986 loss: 4.25550667e-07
Iter: 987 loss: 4.26185437e-07
Iter: 988 loss: 4.25454317e-07
Iter: 989 loss: 4.25350493e-07
Iter: 990 loss: 4.25980829e-07
Iter: 991 loss: 4.25370843e-07
Iter: 992 loss: 4.25323151e-07
Iter: 993 loss: 4.26324277e-07
Iter: 994 loss: 4.25315534e-07
Iter: 995 loss: 4.25166661e-07
Iter: 996 loss: 4.25122352e-07
Iter: 997 loss: 4.27642846e-07
Iter: 998 loss: 4.25128064e-07
Iter: 999 loss: 4.25063462e-07
Iter: 1000 loss: 4.25021966e-07
Iter: 1001 loss: 4.25023245e-07
Iter: 1002 loss: 4.25003407e-07
Iter: 1003 loss: 4.25003122e-07
Iter: 1004 loss: 4.25025604e-07
Iter: 1005 loss: 4.24974104e-07
Iter: 1006 loss: 4.24976349e-07
Iter: 1007 loss: 4.25001787e-07
Iter: 1008 loss: 4.24993857e-07
Iter: 1009 loss: 4.24998e-07
Iter: 1010 loss: 4.25009603e-07
Iter: 1011 loss: 4.25042856e-07
Iter: 1012 loss: 4.25040184e-07
Iter: 1013 loss: 4.25014747e-07
Iter: 1014 loss: 4.25028361e-07
Iter: 1015 loss: 4.25006448e-07
Iter: 1016 loss: 4.25019095e-07
Iter: 1017 loss: 4.25021483e-07
Iter: 1018 loss: 4.25033704e-07
Iter: 1019 loss: 4.2502549e-07
Iter: 1020 loss: 4.25022563e-07
Iter: 1021 loss: 4.25021454e-07
Iter: 1022 loss: 4.25020232e-07
Iter: 1023 loss: 4.25022677e-07
Iter: 1024 loss: 4.25020232e-07
Iter: 1025 loss: 4.25020687e-07
Iter: 1026 loss: 4.25022677e-07
Iter: 1027 loss: 4.24882444e-07
Iter: 1028 loss: 4.25572722e-07
Iter: 1029 loss: 4.24902424e-07
Iter: 1030 loss: 4.24774839e-07
Iter: 1031 loss: 4.24819802e-07
Iter: 1032 loss: 4.24721719e-07
Iter: 1033 loss: 4.24711715e-07
Iter: 1034 loss: 4.2460141e-07
Iter: 1035 loss: 4.24590866e-07
Iter: 1036 loss: 4.24524842e-07
Iter: 1037 loss: 4.24781433e-07
Iter: 1038 loss: 4.24477321e-07
Iter: 1039 loss: 4.24394841e-07
Iter: 1040 loss: 4.24341579e-07
Iter: 1041 loss: 4.24329357e-07
Iter: 1042 loss: 4.24204757e-07
Iter: 1043 loss: 4.24190262e-07
Iter: 1044 loss: 4.24134356e-07
Iter: 1045 loss: 4.24184748e-07
Iter: 1046 loss: 4.24068332e-07
Iter: 1047 loss: 4.23985796e-07
Iter: 1048 loss: 4.24130491e-07
Iter: 1049 loss: 4.23999836e-07
Iter: 1050 loss: 4.23844142e-07
Iter: 1051 loss: 4.23865146e-07
Iter: 1052 loss: 4.2381464e-07
Iter: 1053 loss: 4.237871e-07
Iter: 1054 loss: 4.23827657e-07
Iter: 1055 loss: 4.23667359e-07
Iter: 1056 loss: 4.23721758e-07
Iter: 1057 loss: 4.23661533e-07
Iter: 1058 loss: 4.23623931e-07
Iter: 1059 loss: 4.24657628e-07
Iter: 1060 loss: 4.23606053e-07
Iter: 1061 loss: 4.23509164e-07
Iter: 1062 loss: 4.24399701e-07
Iter: 1063 loss: 4.23496829e-07
Iter: 1064 loss: 4.23431175e-07
Iter: 1065 loss: 4.24060431e-07
Iter: 1066 loss: 4.23445584e-07
Iter: 1067 loss: 4.23358813e-07
Iter: 1068 loss: 4.23346535e-07
Iter: 1069 loss: 4.23330363e-07
Iter: 1070 loss: 4.2327639e-07
Iter: 1071 loss: 4.23438e-07
Iter: 1072 loss: 4.23204739e-07
Iter: 1073 loss: 4.23174356e-07
Iter: 1074 loss: 4.2311629e-07
Iter: 1075 loss: 4.23093439e-07
Iter: 1076 loss: 4.230142e-07
Iter: 1077 loss: 4.22976171e-07
Iter: 1078 loss: 4.22908386e-07
Iter: 1079 loss: 4.2284131e-07
Iter: 1080 loss: 4.22861831e-07
Iter: 1081 loss: 4.22808029e-07
Iter: 1082 loss: 4.23315441e-07
Iter: 1083 loss: 4.22732569e-07
Iter: 1084 loss: 4.22688942e-07
Iter: 1085 loss: 4.23275083e-07
Iter: 1086 loss: 4.22663192e-07
Iter: 1087 loss: 4.22611492e-07
Iter: 1088 loss: 4.2279288e-07
Iter: 1089 loss: 4.22600976e-07
Iter: 1090 loss: 4.22521367e-07
Iter: 1091 loss: 4.22673395e-07
Iter: 1092 loss: 4.2250511e-07
Iter: 1093 loss: 4.22467195e-07
Iter: 1094 loss: 4.2246424e-07
Iter: 1095 loss: 4.22478678e-07
Iter: 1096 loss: 4.22331226e-07
Iter: 1097 loss: 4.23094377e-07
Iter: 1098 loss: 4.22366981e-07
Iter: 1099 loss: 4.22295386e-07
Iter: 1100 loss: 4.22228595e-07
Iter: 1101 loss: 4.22198752e-07
Iter: 1102 loss: 4.22104961e-07
Iter: 1103 loss: 4.22406458e-07
Iter: 1104 loss: 4.22018502e-07
Iter: 1105 loss: 4.21886199e-07
Iter: 1106 loss: 4.21975557e-07
Iter: 1107 loss: 4.21804657e-07
Iter: 1108 loss: 4.21821568e-07
Iter: 1109 loss: 4.21842117e-07
Iter: 1110 loss: 4.21799029e-07
Iter: 1111 loss: 4.21724906e-07
Iter: 1112 loss: 4.21671444e-07
Iter: 1113 loss: 4.21670478e-07
Iter: 1114 loss: 4.21560344e-07
Iter: 1115 loss: 4.21756425e-07
Iter: 1116 loss: 4.21532917e-07
Iter: 1117 loss: 4.21442223e-07
Iter: 1118 loss: 4.2147704e-07
Iter: 1119 loss: 4.21443758e-07
Iter: 1120 loss: 4.21355395e-07
Iter: 1121 loss: 4.21404025e-07
Iter: 1122 loss: 4.21305089e-07
Iter: 1123 loss: 4.21319356e-07
Iter: 1124 loss: 4.21262058e-07
Iter: 1125 loss: 4.21228407e-07
Iter: 1126 loss: 4.22526114e-07
Iter: 1127 loss: 4.21126316e-07
Iter: 1128 loss: 4.21096104e-07
Iter: 1129 loss: 4.21467576e-07
Iter: 1130 loss: 4.21055404e-07
Iter: 1131 loss: 4.20977102e-07
Iter: 1132 loss: 4.21662151e-07
Iter: 1133 loss: 4.21000209e-07
Iter: 1134 loss: 4.20907952e-07
Iter: 1135 loss: 4.20876745e-07
Iter: 1136 loss: 4.20830929e-07
Iter: 1137 loss: 4.20759505e-07
Iter: 1138 loss: 4.20728554e-07
Iter: 1139 loss: 4.20653151e-07
Iter: 1140 loss: 4.20576896e-07
Iter: 1141 loss: 4.20553647e-07
Iter: 1142 loss: 4.20514397e-07
Iter: 1143 loss: 4.2062743e-07
Iter: 1144 loss: 4.20423532e-07
Iter: 1145 loss: 4.20379962e-07
Iter: 1146 loss: 4.20436947e-07
Iter: 1147 loss: 4.20370156e-07
Iter: 1148 loss: 4.20208892e-07
Iter: 1149 loss: 4.20470144e-07
Iter: 1150 loss: 4.20164554e-07
Iter: 1151 loss: 4.20138235e-07
Iter: 1152 loss: 4.21476074e-07
Iter: 1153 loss: 4.20113821e-07
Iter: 1154 loss: 4.20069568e-07
Iter: 1155 loss: 4.20247346e-07
Iter: 1156 loss: 4.20053908e-07
Iter: 1157 loss: 4.19999679e-07
Iter: 1158 loss: 4.20003687e-07
Iter: 1159 loss: 4.1996222e-07
Iter: 1160 loss: 4.19865671e-07
Iter: 1161 loss: 4.1979763e-07
Iter: 1162 loss: 4.19753633e-07
Iter: 1163 loss: 4.19652906e-07
Iter: 1164 loss: 4.21146524e-07
Iter: 1165 loss: 4.19711284e-07
Iter: 1166 loss: 4.19612832e-07
Iter: 1167 loss: 4.19576168e-07
Iter: 1168 loss: 4.19501191e-07
Iter: 1169 loss: 4.19311732e-07
Iter: 1170 loss: 4.19275892e-07
Iter: 1171 loss: 4.19224961e-07
Iter: 1172 loss: 4.19085211e-07
Iter: 1173 loss: 4.2045238e-07
Iter: 1174 loss: 4.19095272e-07
Iter: 1175 loss: 4.18961207e-07
Iter: 1176 loss: 4.20134938e-07
Iter: 1177 loss: 4.18984541e-07
Iter: 1178 loss: 4.18831632e-07
Iter: 1179 loss: 4.18877278e-07
Iter: 1180 loss: 4.1880233e-07
Iter: 1181 loss: 4.18654906e-07
Iter: 1182 loss: 4.18838908e-07
Iter: 1183 loss: 4.18628161e-07
Iter: 1184 loss: 4.18570778e-07
Iter: 1185 loss: 4.18545739e-07
Iter: 1186 loss: 4.1848341e-07
Iter: 1187 loss: 4.18700864e-07
Iter: 1188 loss: 4.18438333e-07
Iter: 1189 loss: 4.18397292e-07
Iter: 1190 loss: 4.18372963e-07
Iter: 1191 loss: 4.1837967e-07
Iter: 1192 loss: 4.18249186e-07
Iter: 1193 loss: 4.18302591e-07
Iter: 1194 loss: 4.18161392e-07
Iter: 1195 loss: 4.18148431e-07
Iter: 1196 loss: 4.18412583e-07
Iter: 1197 loss: 4.18105458e-07
Iter: 1198 loss: 4.17965282e-07
Iter: 1199 loss: 4.18322173e-07
Iter: 1200 loss: 4.1796477e-07
Iter: 1201 loss: 4.1789832e-07
Iter: 1202 loss: 4.17890845e-07
Iter: 1203 loss: 4.17799242e-07
Iter: 1204 loss: 4.17677683e-07
Iter: 1205 loss: 4.17809645e-07
Iter: 1206 loss: 4.17562291e-07
Iter: 1207 loss: 4.174602e-07
Iter: 1208 loss: 4.18498587e-07
Iter: 1209 loss: 4.17464719e-07
Iter: 1210 loss: 4.17282649e-07
Iter: 1211 loss: 4.17769741e-07
Iter: 1212 loss: 4.17294558e-07
Iter: 1213 loss: 4.17258605e-07
Iter: 1214 loss: 4.17220804e-07
Iter: 1215 loss: 4.17132469e-07
Iter: 1216 loss: 4.17030378e-07
Iter: 1217 loss: 4.17006845e-07
Iter: 1218 loss: 4.16984022e-07
Iter: 1219 loss: 4.1704584e-07
Iter: 1220 loss: 4.16830176e-07
Iter: 1221 loss: 4.16737862e-07
Iter: 1222 loss: 4.17194258e-07
Iter: 1223 loss: 4.16751163e-07
Iter: 1224 loss: 4.16681559e-07
Iter: 1225 loss: 4.16668314e-07
Iter: 1226 loss: 4.16620622e-07
Iter: 1227 loss: 4.16479224e-07
Iter: 1228 loss: 4.16458704e-07
Iter: 1229 loss: 4.16372e-07
Iter: 1230 loss: 4.16231444e-07
Iter: 1231 loss: 4.16224e-07
Iter: 1232 loss: 4.16207058e-07
Iter: 1233 loss: 4.16041217e-07
Iter: 1234 loss: 4.16118041e-07
Iter: 1235 loss: 4.15981759e-07
Iter: 1236 loss: 4.16014444e-07
Iter: 1237 loss: 4.15883136e-07
Iter: 1238 loss: 4.15776753e-07
Iter: 1239 loss: 4.15959676e-07
Iter: 1240 loss: 4.1568461e-07
Iter: 1241 loss: 4.15525562e-07
Iter: 1242 loss: 4.1558738e-07
Iter: 1243 loss: 4.15475284e-07
Iter: 1244 loss: 4.15403804e-07
Iter: 1245 loss: 4.15374444e-07
Iter: 1246 loss: 4.15293044e-07
Iter: 1247 loss: 4.1585497e-07
Iter: 1248 loss: 4.15206813e-07
Iter: 1249 loss: 4.15159207e-07
Iter: 1250 loss: 4.15814583e-07
Iter: 1251 loss: 4.15167563e-07
Iter: 1252 loss: 4.15118507e-07
Iter: 1253 loss: 4.1536174e-07
Iter: 1254 loss: 4.15092188e-07
Iter: 1255 loss: 4.14982395e-07
Iter: 1256 loss: 4.15003115e-07
Iter: 1257 loss: 4.14928536e-07
Iter: 1258 loss: 4.14882493e-07
Iter: 1259 loss: 4.1478927e-07
Iter: 1260 loss: 4.14738565e-07
Iter: 1261 loss: 4.14652845e-07
Iter: 1262 loss: 4.16300111e-07
Iter: 1263 loss: 4.14643353e-07
Iter: 1264 loss: 4.14508435e-07
Iter: 1265 loss: 4.14637356e-07
Iter: 1266 loss: 4.14549532e-07
Iter: 1267 loss: 4.14421208e-07
Iter: 1268 loss: 4.14462306e-07
Iter: 1269 loss: 4.14365218e-07
Iter: 1270 loss: 4.14241185e-07
Iter: 1271 loss: 4.14306e-07
Iter: 1272 loss: 4.14173485e-07
Iter: 1273 loss: 4.14041068e-07
Iter: 1274 loss: 4.14052721e-07
Iter: 1275 loss: 4.14017848e-07
Iter: 1276 loss: 4.14059059e-07
Iter: 1277 loss: 4.13923061e-07
Iter: 1278 loss: 4.1382205e-07
Iter: 1279 loss: 4.14030609e-07
Iter: 1280 loss: 4.13813609e-07
Iter: 1281 loss: 4.13713479e-07
Iter: 1282 loss: 4.14863223e-07
Iter: 1283 loss: 4.13726752e-07
Iter: 1284 loss: 4.13717203e-07
Iter: 1285 loss: 4.13726696e-07
Iter: 1286 loss: 4.13633302e-07
Iter: 1287 loss: 4.13619205e-07
Iter: 1288 loss: 4.13794425e-07
Iter: 1289 loss: 4.13557501e-07
Iter: 1290 loss: 4.13467603e-07
Iter: 1291 loss: 4.13438897e-07
Iter: 1292 loss: 4.13443672e-07
Iter: 1293 loss: 4.13336068e-07
Iter: 1294 loss: 4.13728e-07
Iter: 1295 loss: 4.13316229e-07
Iter: 1296 loss: 4.13282123e-07
Iter: 1297 loss: 4.13893417e-07
Iter: 1298 loss: 4.1329065e-07
Iter: 1299 loss: 4.13208426e-07
Iter: 1300 loss: 4.13103123e-07
Iter: 1301 loss: 4.13063788e-07
Iter: 1302 loss: 4.12973577e-07
Iter: 1303 loss: 4.13005267e-07
Iter: 1304 loss: 4.12872595e-07
Iter: 1305 loss: 4.12758567e-07
Iter: 1306 loss: 4.14132984e-07
Iter: 1307 loss: 4.12767747e-07
Iter: 1308 loss: 4.12738103e-07
Iter: 1309 loss: 4.13468626e-07
Iter: 1310 loss: 4.12699251e-07
Iter: 1311 loss: 4.12647978e-07
Iter: 1312 loss: 4.12617e-07
Iter: 1313 loss: 4.12579141e-07
Iter: 1314 loss: 4.12516073e-07
Iter: 1315 loss: 4.13331577e-07
Iter: 1316 loss: 4.12557512e-07
Iter: 1317 loss: 4.12446752e-07
Iter: 1318 loss: 4.12469376e-07
Iter: 1319 loss: 4.12451669e-07
Iter: 1320 loss: 4.12345599e-07
Iter: 1321 loss: 4.12777467e-07
Iter: 1322 loss: 4.12324908e-07
Iter: 1323 loss: 4.12230037e-07
Iter: 1324 loss: 4.12134114e-07
Iter: 1325 loss: 4.12109586e-07
Iter: 1326 loss: 4.12027219e-07
Iter: 1327 loss: 4.12256895e-07
Iter: 1328 loss: 4.11985496e-07
Iter: 1329 loss: 4.11907422e-07
Iter: 1330 loss: 4.11923168e-07
Iter: 1331 loss: 4.11875817e-07
Iter: 1332 loss: 4.11774181e-07
Iter: 1333 loss: 4.11768553e-07
Iter: 1334 loss: 4.1166561e-07
Iter: 1335 loss: 4.11826335e-07
Iter: 1336 loss: 4.1162042e-07
Iter: 1337 loss: 4.11399611e-07
Iter: 1338 loss: 4.11782537e-07
Iter: 1339 loss: 4.11403818e-07
Iter: 1340 loss: 4.11347969e-07
Iter: 1341 loss: 4.12473241e-07
Iter: 1342 loss: 4.11303063e-07
Iter: 1343 loss: 4.11204041e-07
Iter: 1344 loss: 4.11333133e-07
Iter: 1345 loss: 4.11139e-07
Iter: 1346 loss: 4.11117e-07
Iter: 1347 loss: 4.11375311e-07
Iter: 1348 loss: 4.11078616e-07
Iter: 1349 loss: 4.10973485e-07
Iter: 1350 loss: 4.11417489e-07
Iter: 1351 loss: 4.10919313e-07
Iter: 1352 loss: 4.1092369e-07
Iter: 1353 loss: 4.10957909e-07
Iter: 1354 loss: 4.10937218e-07
Iter: 1355 loss: 4.10957426e-07
Iter: 1356 loss: 4.10948957e-07
Iter: 1357 loss: 4.10929289e-07
Iter: 1358 loss: 4.1092207e-07
Iter: 1359 loss: 4.10944978e-07
Iter: 1360 loss: 4.1094475e-07
Iter: 1361 loss: 4.10932e-07
Iter: 1362 loss: 4.10913344e-07
Iter: 1363 loss: 4.10938924e-07
Iter: 1364 loss: 4.10916641e-07
Iter: 1365 loss: 4.10932785e-07
Iter: 1366 loss: 4.10943812e-07
Iter: 1367 loss: 4.10930909e-07
Iter: 1368 loss: 4.10930937e-07
Iter: 1369 loss: 4.10914339e-07
Iter: 1370 loss: 4.1092764e-07
Iter: 1371 loss: 4.10916982e-07
Iter: 1372 loss: 4.10921615e-07
Iter: 1373 loss: 4.10918688e-07
Iter: 1374 loss: 4.10919824e-07
Iter: 1375 loss: 4.1091883e-07
Iter: 1376 loss: 4.10918801e-07
Iter: 1377 loss: 4.10918801e-07
Iter: 1378 loss: 4.10918858e-07
Iter: 1379 loss: 4.10919824e-07
Iter: 1380 loss: 4.10918858e-07
Iter: 1381 loss: 4.10918858e-07
Iter: 1382 loss: 4.10919824e-07
Iter: 1383 loss: 4.10919824e-07
Iter: 1384 loss: 4.10918858e-07
Iter: 1385 loss: 4.10919824e-07
Iter: 1386 loss: 4.10918858e-07
Iter: 1387 loss: 4.11026889e-07
Iter: 1388 loss: 4.10949212e-07
Iter: 1389 loss: 4.10906e-07
Iter: 1390 loss: 4.10939e-07
Iter: 1391 loss: 4.10939e-07
Iter: 1392 loss: 4.10895126e-07
Iter: 1393 loss: 4.10932728e-07
Iter: 1394 loss: 4.10928948e-07
Iter: 1395 loss: 4.10903851e-07
Iter: 1396 loss: 4.10906e-07
Iter: 1397 loss: 4.10916527e-07
Iter: 1398 loss: 4.10922297e-07
Iter: 1399 loss: 4.10919455e-07
Iter: 1400 loss: 4.10915e-07
Iter: 1401 loss: 4.10925423e-07
Iter: 1402 loss: 4.10920393e-07
Iter: 1403 loss: 4.10915959e-07
Iter: 1404 loss: 4.10916869e-07
Iter: 1405 loss: 4.10919768e-07
Iter: 1406 loss: 4.10921189e-07
Iter: 1407 loss: 4.10912264e-07
Iter: 1408 loss: 4.10915163e-07
Iter: 1409 loss: 4.10915476e-07
Iter: 1410 loss: 4.10919284e-07
Iter: 1411 loss: 4.10919284e-07
Iter: 1412 loss: 4.10918375e-07
Iter: 1413 loss: 4.10918375e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2_8000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fd40620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fdc4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fc769d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fd9c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fc80f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fcc9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fc4bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fbfea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fbfe510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fbfe598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fbdb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fb84c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fb9e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fb422f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fb9eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fbc6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fb09d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fb090d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421faa7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fa50b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fa59950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fa1b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421fa59f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421f9f1f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41d955b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41d950de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41d950d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41d94b4048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41d949c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41d94a6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41d9499598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41d943b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41b44ec620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41b4520a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41b44b8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41b4489f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.27833402e-06
Iter: 2 loss: 3.6406811e-05
Iter: 3 loss: 2.30900719e-06
Iter: 4 loss: 2.04308367e-06
Iter: 5 loss: 1.59315346e-06
Iter: 6 loss: 1.59232013e-06
Iter: 7 loss: 1.31348213e-06
Iter: 8 loss: 2.70643659e-06
Iter: 9 loss: 1.26656039e-06
Iter: 10 loss: 1.05115362e-06
Iter: 11 loss: 1.89699142e-06
Iter: 12 loss: 1.00166267e-06
Iter: 13 loss: 9.24599874e-07
Iter: 14 loss: 1.6853021e-06
Iter: 15 loss: 9.21992068e-07
Iter: 16 loss: 8.80679295e-07
Iter: 17 loss: 8.50138633e-07
Iter: 18 loss: 8.36389745e-07
Iter: 19 loss: 8.0517e-07
Iter: 20 loss: 8.54587142e-07
Iter: 21 loss: 7.90716626e-07
Iter: 22 loss: 7.75184049e-07
Iter: 23 loss: 7.79633297e-07
Iter: 24 loss: 7.64019546e-07
Iter: 25 loss: 7.50715913e-07
Iter: 26 loss: 7.49539254e-07
Iter: 27 loss: 7.39661232e-07
Iter: 28 loss: 7.2095645e-07
Iter: 29 loss: 7.63208106e-07
Iter: 30 loss: 7.13964482e-07
Iter: 31 loss: 7.06514868e-07
Iter: 32 loss: 6.95118388e-07
Iter: 33 loss: 6.94983555e-07
Iter: 34 loss: 6.82639154e-07
Iter: 35 loss: 7.98771168e-07
Iter: 36 loss: 6.82073676e-07
Iter: 37 loss: 6.76464481e-07
Iter: 38 loss: 6.71276666e-07
Iter: 39 loss: 6.69923224e-07
Iter: 40 loss: 6.61017111e-07
Iter: 41 loss: 6.82399275e-07
Iter: 42 loss: 6.578083e-07
Iter: 43 loss: 6.51783921e-07
Iter: 44 loss: 7.01907084e-07
Iter: 45 loss: 6.51412392e-07
Iter: 46 loss: 6.45653927e-07
Iter: 47 loss: 6.73879072e-07
Iter: 48 loss: 6.44661554e-07
Iter: 49 loss: 6.41396639e-07
Iter: 50 loss: 6.4790936e-07
Iter: 51 loss: 6.40113171e-07
Iter: 52 loss: 6.36442337e-07
Iter: 53 loss: 6.45329749e-07
Iter: 54 loss: 6.35138576e-07
Iter: 55 loss: 6.32334206e-07
Iter: 56 loss: 6.41246686e-07
Iter: 57 loss: 6.31517253e-07
Iter: 58 loss: 6.28147745e-07
Iter: 59 loss: 6.46620379e-07
Iter: 60 loss: 6.27688848e-07
Iter: 61 loss: 6.24225777e-07
Iter: 62 loss: 6.18765512e-07
Iter: 63 loss: 6.18743059e-07
Iter: 64 loss: 6.16698912e-07
Iter: 65 loss: 6.16318516e-07
Iter: 66 loss: 6.1414e-07
Iter: 67 loss: 6.13407792e-07
Iter: 68 loss: 6.12222379e-07
Iter: 69 loss: 6.08702294e-07
Iter: 70 loss: 6.17674687e-07
Iter: 71 loss: 6.074564e-07
Iter: 72 loss: 6.0503686e-07
Iter: 73 loss: 6.03549609e-07
Iter: 74 loss: 6.02586852e-07
Iter: 75 loss: 5.98690121e-07
Iter: 76 loss: 6.10983591e-07
Iter: 77 loss: 5.97612257e-07
Iter: 78 loss: 5.94042888e-07
Iter: 79 loss: 6.29868168e-07
Iter: 80 loss: 5.93952677e-07
Iter: 81 loss: 5.90823e-07
Iter: 82 loss: 5.93935567e-07
Iter: 83 loss: 5.89096317e-07
Iter: 84 loss: 5.8628234e-07
Iter: 85 loss: 5.94813685e-07
Iter: 86 loss: 5.85397629e-07
Iter: 87 loss: 5.82197e-07
Iter: 88 loss: 5.90187e-07
Iter: 89 loss: 5.81058828e-07
Iter: 90 loss: 5.7918794e-07
Iter: 91 loss: 6.04815114e-07
Iter: 92 loss: 5.79146899e-07
Iter: 93 loss: 5.77275046e-07
Iter: 94 loss: 5.75037461e-07
Iter: 95 loss: 5.74803664e-07
Iter: 96 loss: 5.7296927e-07
Iter: 97 loss: 5.89877573e-07
Iter: 98 loss: 5.72850468e-07
Iter: 99 loss: 5.71728378e-07
Iter: 100 loss: 5.81949053e-07
Iter: 101 loss: 5.71644478e-07
Iter: 102 loss: 5.70471343e-07
Iter: 103 loss: 5.68657128e-07
Iter: 104 loss: 5.68546625e-07
Iter: 105 loss: 5.6655449e-07
Iter: 106 loss: 5.77016408e-07
Iter: 107 loss: 5.66209394e-07
Iter: 108 loss: 5.64701736e-07
Iter: 109 loss: 5.64311506e-07
Iter: 110 loss: 5.63477215e-07
Iter: 111 loss: 5.62111268e-07
Iter: 112 loss: 5.76207412e-07
Iter: 113 loss: 5.62101718e-07
Iter: 114 loss: 5.60704393e-07
Iter: 115 loss: 5.65471055e-07
Iter: 116 loss: 5.60407216e-07
Iter: 117 loss: 5.59443833e-07
Iter: 118 loss: 5.61173579e-07
Iter: 119 loss: 5.59138698e-07
Iter: 120 loss: 5.58068905e-07
Iter: 121 loss: 5.59688772e-07
Iter: 122 loss: 5.57539181e-07
Iter: 123 loss: 5.56522309e-07
Iter: 124 loss: 5.63628532e-07
Iter: 125 loss: 5.56361726e-07
Iter: 126 loss: 5.55477868e-07
Iter: 127 loss: 5.60764647e-07
Iter: 128 loss: 5.5544217e-07
Iter: 129 loss: 5.54754536e-07
Iter: 130 loss: 5.53530697e-07
Iter: 131 loss: 5.81926201e-07
Iter: 132 loss: 5.5354144e-07
Iter: 133 loss: 5.53106815e-07
Iter: 134 loss: 5.52845677e-07
Iter: 135 loss: 5.52448967e-07
Iter: 136 loss: 5.52179586e-07
Iter: 137 loss: 5.51975518e-07
Iter: 138 loss: 5.51124e-07
Iter: 139 loss: 5.50612185e-07
Iter: 140 loss: 5.50328764e-07
Iter: 141 loss: 5.49069341e-07
Iter: 142 loss: 5.54193207e-07
Iter: 143 loss: 5.48847709e-07
Iter: 144 loss: 5.47928835e-07
Iter: 145 loss: 5.48286152e-07
Iter: 146 loss: 5.47145248e-07
Iter: 147 loss: 5.46281683e-07
Iter: 148 loss: 5.46282195e-07
Iter: 149 loss: 5.45312162e-07
Iter: 150 loss: 5.43846795e-07
Iter: 151 loss: 5.43767044e-07
Iter: 152 loss: 5.42629891e-07
Iter: 153 loss: 5.56713189e-07
Iter: 154 loss: 5.42625457e-07
Iter: 155 loss: 5.41693908e-07
Iter: 156 loss: 5.43255737e-07
Iter: 157 loss: 5.41288557e-07
Iter: 158 loss: 5.40288568e-07
Iter: 159 loss: 5.51346602e-07
Iter: 160 loss: 5.40281349e-07
Iter: 161 loss: 5.3956029e-07
Iter: 162 loss: 5.39923917e-07
Iter: 163 loss: 5.39180519e-07
Iter: 164 loss: 5.38522613e-07
Iter: 165 loss: 5.39541304e-07
Iter: 166 loss: 5.38231802e-07
Iter: 167 loss: 5.37203846e-07
Iter: 168 loss: 5.39198084e-07
Iter: 169 loss: 5.36754044e-07
Iter: 170 loss: 5.36161565e-07
Iter: 171 loss: 5.37447249e-07
Iter: 172 loss: 5.3587496e-07
Iter: 173 loss: 5.35058689e-07
Iter: 174 loss: 5.34386288e-07
Iter: 175 loss: 5.34151809e-07
Iter: 176 loss: 5.33228672e-07
Iter: 177 loss: 5.42107614e-07
Iter: 178 loss: 5.33187063e-07
Iter: 179 loss: 5.32395575e-07
Iter: 180 loss: 5.32916545e-07
Iter: 181 loss: 5.31931164e-07
Iter: 182 loss: 5.30890304e-07
Iter: 183 loss: 5.43495275e-07
Iter: 184 loss: 5.30887746e-07
Iter: 185 loss: 5.30548164e-07
Iter: 186 loss: 5.29814258e-07
Iter: 187 loss: 5.29812269e-07
Iter: 188 loss: 5.28937278e-07
Iter: 189 loss: 5.36805885e-07
Iter: 190 loss: 5.28850819e-07
Iter: 191 loss: 5.28422333e-07
Iter: 192 loss: 5.34042442e-07
Iter: 193 loss: 5.28389478e-07
Iter: 194 loss: 5.28081046e-07
Iter: 195 loss: 5.2809e-07
Iter: 196 loss: 5.27791371e-07
Iter: 197 loss: 5.27367547e-07
Iter: 198 loss: 5.28145392e-07
Iter: 199 loss: 5.27171665e-07
Iter: 200 loss: 5.26714871e-07
Iter: 201 loss: 5.30309876e-07
Iter: 202 loss: 5.26642566e-07
Iter: 203 loss: 5.26363579e-07
Iter: 204 loss: 5.25961866e-07
Iter: 205 loss: 5.25914913e-07
Iter: 206 loss: 5.25356825e-07
Iter: 207 loss: 5.275067e-07
Iter: 208 loss: 5.25236374e-07
Iter: 209 loss: 5.24781854e-07
Iter: 210 loss: 5.24557379e-07
Iter: 211 loss: 5.24286406e-07
Iter: 212 loss: 5.23587289e-07
Iter: 213 loss: 5.2888322e-07
Iter: 214 loss: 5.23530616e-07
Iter: 215 loss: 5.22992138e-07
Iter: 216 loss: 5.28958083e-07
Iter: 217 loss: 5.22975199e-07
Iter: 218 loss: 5.22563141e-07
Iter: 219 loss: 5.21953552e-07
Iter: 220 loss: 5.21937864e-07
Iter: 221 loss: 5.21408765e-07
Iter: 222 loss: 5.26051224e-07
Iter: 223 loss: 5.21443951e-07
Iter: 224 loss: 5.20887227e-07
Iter: 225 loss: 5.22367543e-07
Iter: 226 loss: 5.20722551e-07
Iter: 227 loss: 5.20305548e-07
Iter: 228 loss: 5.23524193e-07
Iter: 229 loss: 5.20242054e-07
Iter: 230 loss: 5.20058052e-07
Iter: 231 loss: 5.20023946e-07
Iter: 232 loss: 5.1990213e-07
Iter: 233 loss: 5.195526e-07
Iter: 234 loss: 5.20987953e-07
Iter: 235 loss: 5.19518608e-07
Iter: 236 loss: 5.19139519e-07
Iter: 237 loss: 5.18920842e-07
Iter: 238 loss: 5.18728427e-07
Iter: 239 loss: 5.18323077e-07
Iter: 240 loss: 5.1946347e-07
Iter: 241 loss: 5.18185402e-07
Iter: 242 loss: 5.17604747e-07
Iter: 243 loss: 5.17830586e-07
Iter: 244 loss: 5.17224805e-07
Iter: 245 loss: 5.16717364e-07
Iter: 246 loss: 5.18145157e-07
Iter: 247 loss: 5.16545526e-07
Iter: 248 loss: 5.15979934e-07
Iter: 249 loss: 5.22208211e-07
Iter: 250 loss: 5.16004093e-07
Iter: 251 loss: 5.15484e-07
Iter: 252 loss: 5.15947e-07
Iter: 253 loss: 5.15293664e-07
Iter: 254 loss: 5.14921226e-07
Iter: 255 loss: 5.14935778e-07
Iter: 256 loss: 5.14543956e-07
Iter: 257 loss: 5.14129965e-07
Iter: 258 loss: 5.14121894e-07
Iter: 259 loss: 5.13778787e-07
Iter: 260 loss: 5.14768317e-07
Iter: 261 loss: 5.13818463e-07
Iter: 262 loss: 5.1348627e-07
Iter: 263 loss: 5.1332313e-07
Iter: 264 loss: 5.13232123e-07
Iter: 265 loss: 5.12891916e-07
Iter: 266 loss: 5.16990042e-07
Iter: 267 loss: 5.1293722e-07
Iter: 268 loss: 5.12657721e-07
Iter: 269 loss: 5.12533916e-07
Iter: 270 loss: 5.12395047e-07
Iter: 271 loss: 5.12040174e-07
Iter: 272 loss: 5.11741064e-07
Iter: 273 loss: 5.11634653e-07
Iter: 274 loss: 5.11121129e-07
Iter: 275 loss: 5.15732609e-07
Iter: 276 loss: 5.11135568e-07
Iter: 277 loss: 5.10791551e-07
Iter: 278 loss: 5.10279506e-07
Iter: 279 loss: 5.10286895e-07
Iter: 280 loss: 5.10018367e-07
Iter: 281 loss: 5.09981646e-07
Iter: 282 loss: 5.09639449e-07
Iter: 283 loss: 5.09642746e-07
Iter: 284 loss: 5.093558e-07
Iter: 285 loss: 5.08946641e-07
Iter: 286 loss: 5.09322604e-07
Iter: 287 loss: 5.08693688e-07
Iter: 288 loss: 5.08487e-07
Iter: 289 loss: 5.08496669e-07
Iter: 290 loss: 5.08283904e-07
Iter: 291 loss: 5.08454661e-07
Iter: 292 loss: 5.08133439e-07
Iter: 293 loss: 5.07804089e-07
Iter: 294 loss: 5.08483e-07
Iter: 295 loss: 5.07661412e-07
Iter: 296 loss: 5.07422328e-07
Iter: 297 loss: 5.08503149e-07
Iter: 298 loss: 5.07336324e-07
Iter: 299 loss: 5.07054835e-07
Iter: 300 loss: 5.0706069e-07
Iter: 301 loss: 5.06836386e-07
Iter: 302 loss: 5.06477249e-07
Iter: 303 loss: 5.07190293e-07
Iter: 304 loss: 5.06297283e-07
Iter: 305 loss: 5.05954404e-07
Iter: 306 loss: 5.06669949e-07
Iter: 307 loss: 5.05832588e-07
Iter: 308 loss: 5.05483058e-07
Iter: 309 loss: 5.06121353e-07
Iter: 310 loss: 5.05300477e-07
Iter: 311 loss: 5.04854597e-07
Iter: 312 loss: 5.05382445e-07
Iter: 313 loss: 5.0465087e-07
Iter: 314 loss: 5.04229433e-07
Iter: 315 loss: 5.10799623e-07
Iter: 316 loss: 5.04232275e-07
Iter: 317 loss: 5.03976196e-07
Iter: 318 loss: 5.03607112e-07
Iter: 319 loss: 5.03608362e-07
Iter: 320 loss: 5.0315e-07
Iter: 321 loss: 5.07245261e-07
Iter: 322 loss: 5.03049e-07
Iter: 323 loss: 5.02757416e-07
Iter: 324 loss: 5.05936725e-07
Iter: 325 loss: 5.02758212e-07
Iter: 326 loss: 5.02572e-07
Iter: 327 loss: 5.02781063e-07
Iter: 328 loss: 5.02436e-07
Iter: 329 loss: 5.02247303e-07
Iter: 330 loss: 5.0223889e-07
Iter: 331 loss: 5.02041132e-07
Iter: 332 loss: 5.01730938e-07
Iter: 333 loss: 5.04516208e-07
Iter: 334 loss: 5.01695695e-07
Iter: 335 loss: 5.0152687e-07
Iter: 336 loss: 5.01276645e-07
Iter: 337 loss: 5.01254817e-07
Iter: 338 loss: 5.00878343e-07
Iter: 339 loss: 5.01782608e-07
Iter: 340 loss: 5.00662964e-07
Iter: 341 loss: 5.00421834e-07
Iter: 342 loss: 5.01527154e-07
Iter: 343 loss: 5.00376245e-07
Iter: 344 loss: 4.99985731e-07
Iter: 345 loss: 4.99580153e-07
Iter: 346 loss: 4.99533655e-07
Iter: 347 loss: 4.99442194e-07
Iter: 348 loss: 4.99223745e-07
Iter: 349 loss: 4.99047871e-07
Iter: 350 loss: 4.98683789e-07
Iter: 351 loss: 5.05267849e-07
Iter: 352 loss: 4.98701752e-07
Iter: 353 loss: 4.98309078e-07
Iter: 354 loss: 5.02269e-07
Iter: 355 loss: 4.98298846e-07
Iter: 356 loss: 4.98112115e-07
Iter: 357 loss: 5.0058236e-07
Iter: 358 loss: 4.98096824e-07
Iter: 359 loss: 4.97951191e-07
Iter: 360 loss: 4.97914e-07
Iter: 361 loss: 4.97805786e-07
Iter: 362 loss: 4.97590861e-07
Iter: 363 loss: 4.9800235e-07
Iter: 364 loss: 4.97468534e-07
Iter: 365 loss: 4.97262477e-07
Iter: 366 loss: 4.99385919e-07
Iter: 367 loss: 4.97284191e-07
Iter: 368 loss: 4.97140377e-07
Iter: 369 loss: 4.96790278e-07
Iter: 370 loss: 5.01711554e-07
Iter: 371 loss: 4.96830353e-07
Iter: 372 loss: 4.96522262e-07
Iter: 373 loss: 4.97878148e-07
Iter: 374 loss: 4.96371968e-07
Iter: 375 loss: 4.96093776e-07
Iter: 376 loss: 4.96747873e-07
Iter: 377 loss: 4.96036932e-07
Iter: 378 loss: 4.95732252e-07
Iter: 379 loss: 4.96110431e-07
Iter: 380 loss: 4.95499421e-07
Iter: 381 loss: 4.9534151e-07
Iter: 382 loss: 4.95304675e-07
Iter: 383 loss: 4.95100721e-07
Iter: 384 loss: 4.94734934e-07
Iter: 385 loss: 4.94702704e-07
Iter: 386 loss: 4.94405299e-07
Iter: 387 loss: 4.98093414e-07
Iter: 388 loss: 4.94452593e-07
Iter: 389 loss: 4.94234e-07
Iter: 390 loss: 4.95667564e-07
Iter: 391 loss: 4.94230619e-07
Iter: 392 loss: 4.93975335e-07
Iter: 393 loss: 4.94122219e-07
Iter: 394 loss: 4.93922812e-07
Iter: 395 loss: 4.93682137e-07
Iter: 396 loss: 4.941665e-07
Iter: 397 loss: 4.93527295e-07
Iter: 398 loss: 4.93333175e-07
Iter: 399 loss: 4.94436563e-07
Iter: 400 loss: 4.93340053e-07
Iter: 401 loss: 4.93121888e-07
Iter: 402 loss: 4.93089601e-07
Iter: 403 loss: 4.92942206e-07
Iter: 404 loss: 4.92735467e-07
Iter: 405 loss: 4.93207835e-07
Iter: 406 loss: 4.92679078e-07
Iter: 407 loss: 4.92451136e-07
Iter: 408 loss: 4.92454774e-07
Iter: 409 loss: 4.92271283e-07
Iter: 410 loss: 4.92001163e-07
Iter: 411 loss: 4.93683729e-07
Iter: 412 loss: 4.91976607e-07
Iter: 413 loss: 4.91713763e-07
Iter: 414 loss: 4.92109166e-07
Iter: 415 loss: 4.91639639e-07
Iter: 416 loss: 4.91253445e-07
Iter: 417 loss: 4.93306516e-07
Iter: 418 loss: 4.91267e-07
Iter: 419 loss: 4.91103663e-07
Iter: 420 loss: 4.90831042e-07
Iter: 421 loss: 4.90838659e-07
Iter: 422 loss: 4.90716616e-07
Iter: 423 loss: 4.90668072e-07
Iter: 424 loss: 4.90558421e-07
Iter: 425 loss: 4.90763682e-07
Iter: 426 loss: 4.90484354e-07
Iter: 427 loss: 4.90407729e-07
Iter: 428 loss: 4.90360208e-07
Iter: 429 loss: 4.90303478e-07
Iter: 430 loss: 4.90134198e-07
Iter: 431 loss: 4.90547279e-07
Iter: 432 loss: 4.90086677e-07
Iter: 433 loss: 4.89888407e-07
Iter: 434 loss: 4.90688535e-07
Iter: 435 loss: 4.89913532e-07
Iter: 436 loss: 4.89731065e-07
Iter: 437 loss: 4.89564968e-07
Iter: 438 loss: 4.89560534e-07
Iter: 439 loss: 4.89302238e-07
Iter: 440 loss: 4.90511184e-07
Iter: 441 loss: 4.89256365e-07
Iter: 442 loss: 4.89109084e-07
Iter: 443 loss: 4.89151887e-07
Iter: 444 loss: 4.89045874e-07
Iter: 445 loss: 4.88763192e-07
Iter: 446 loss: 4.89772e-07
Iter: 447 loss: 4.88689238e-07
Iter: 448 loss: 4.88493356e-07
Iter: 449 loss: 4.88483352e-07
Iter: 450 loss: 4.88353635e-07
Iter: 451 loss: 4.88083629e-07
Iter: 452 loss: 4.91310288e-07
Iter: 453 loss: 4.88067883e-07
Iter: 454 loss: 4.8795448e-07
Iter: 455 loss: 4.87929469e-07
Iter: 456 loss: 4.87739385e-07
Iter: 457 loss: 4.87932084e-07
Iter: 458 loss: 4.87693057e-07
Iter: 459 loss: 4.87564364e-07
Iter: 460 loss: 4.87633713e-07
Iter: 461 loss: 4.87508373e-07
Iter: 462 loss: 4.87351485e-07
Iter: 463 loss: 4.87914463e-07
Iter: 464 loss: 4.87286513e-07
Iter: 465 loss: 4.8713639e-07
Iter: 466 loss: 4.87350235e-07
Iter: 467 loss: 4.87073919e-07
Iter: 468 loss: 4.86909244e-07
Iter: 469 loss: 4.86784529e-07
Iter: 470 loss: 4.86784188e-07
Iter: 471 loss: 4.86522e-07
Iter: 472 loss: 4.87968691e-07
Iter: 473 loss: 4.86423119e-07
Iter: 474 loss: 4.86267e-07
Iter: 475 loss: 4.86419822e-07
Iter: 476 loss: 4.86158683e-07
Iter: 477 loss: 4.85907435e-07
Iter: 478 loss: 4.87435727e-07
Iter: 479 loss: 4.85831265e-07
Iter: 480 loss: 4.85638168e-07
Iter: 481 loss: 4.8680522e-07
Iter: 482 loss: 4.856239e-07
Iter: 483 loss: 4.85419719e-07
Iter: 484 loss: 4.85522321e-07
Iter: 485 loss: 4.85238729e-07
Iter: 486 loss: 4.85175178e-07
Iter: 487 loss: 4.86021918e-07
Iter: 488 loss: 4.85185296e-07
Iter: 489 loss: 4.85007945e-07
Iter: 490 loss: 4.85598321e-07
Iter: 491 loss: 4.84995269e-07
Iter: 492 loss: 4.84812688e-07
Iter: 493 loss: 4.85071041e-07
Iter: 494 loss: 4.84761e-07
Iter: 495 loss: 4.8468263e-07
Iter: 496 loss: 4.84854581e-07
Iter: 497 loss: 4.84588554e-07
Iter: 498 loss: 4.84439227e-07
Iter: 499 loss: 4.8471162e-07
Iter: 500 loss: 4.84396537e-07
Iter: 501 loss: 4.84224302e-07
Iter: 502 loss: 4.84412567e-07
Iter: 503 loss: 4.84182578e-07
Iter: 504 loss: 4.83957535e-07
Iter: 505 loss: 4.84109137e-07
Iter: 506 loss: 4.83927465e-07
Iter: 507 loss: 4.83705776e-07
Iter: 508 loss: 4.84677457e-07
Iter: 509 loss: 4.83602662e-07
Iter: 510 loss: 4.83481472e-07
Iter: 511 loss: 4.83782969e-07
Iter: 512 loss: 4.83409394e-07
Iter: 513 loss: 4.83268536e-07
Iter: 514 loss: 4.84155237e-07
Iter: 515 loss: 4.8323659e-07
Iter: 516 loss: 4.8309937e-07
Iter: 517 loss: 4.8341883e-07
Iter: 518 loss: 4.82951293e-07
Iter: 519 loss: 4.82863413e-07
Iter: 520 loss: 4.82911332e-07
Iter: 521 loss: 4.82774453e-07
Iter: 522 loss: 4.82662585e-07
Iter: 523 loss: 4.82631208e-07
Iter: 524 loss: 4.82583175e-07
Iter: 525 loss: 4.82543896e-07
Iter: 526 loss: 4.82556288e-07
Iter: 527 loss: 4.82365294e-07
Iter: 528 loss: 4.82385303e-07
Iter: 529 loss: 4.82306e-07
Iter: 530 loss: 4.82128257e-07
Iter: 531 loss: 4.83292297e-07
Iter: 532 loss: 4.8212371e-07
Iter: 533 loss: 4.82047312e-07
Iter: 534 loss: 4.82010137e-07
Iter: 535 loss: 4.81943971e-07
Iter: 536 loss: 4.8168755e-07
Iter: 537 loss: 4.81785e-07
Iter: 538 loss: 4.81608708e-07
Iter: 539 loss: 4.81401116e-07
Iter: 540 loss: 4.82689188e-07
Iter: 541 loss: 4.81396171e-07
Iter: 542 loss: 4.81184031e-07
Iter: 543 loss: 4.81158622e-07
Iter: 544 loss: 4.80969788e-07
Iter: 545 loss: 4.8085235e-07
Iter: 546 loss: 4.80829158e-07
Iter: 547 loss: 4.80712288e-07
Iter: 548 loss: 4.80719564e-07
Iter: 549 loss: 4.80601329e-07
Iter: 550 loss: 4.80436e-07
Iter: 551 loss: 4.80591382e-07
Iter: 552 loss: 4.80301537e-07
Iter: 553 loss: 4.80215078e-07
Iter: 554 loss: 4.80238498e-07
Iter: 555 loss: 4.80144763e-07
Iter: 556 loss: 4.8004091e-07
Iter: 557 loss: 4.80020844e-07
Iter: 558 loss: 4.79828259e-07
Iter: 559 loss: 4.80074391e-07
Iter: 560 loss: 4.79734695e-07
Iter: 561 loss: 4.79618279e-07
Iter: 562 loss: 4.80702965e-07
Iter: 563 loss: 4.79560867e-07
Iter: 564 loss: 4.79457071e-07
Iter: 565 loss: 4.79309847e-07
Iter: 566 loss: 4.79261644e-07
Iter: 567 loss: 4.79014545e-07
Iter: 568 loss: 4.80150732e-07
Iter: 569 loss: 4.78980382e-07
Iter: 570 loss: 4.78814059e-07
Iter: 571 loss: 4.79308483e-07
Iter: 572 loss: 4.78804452e-07
Iter: 573 loss: 4.78604932e-07
Iter: 574 loss: 4.78772449e-07
Iter: 575 loss: 4.78492552e-07
Iter: 576 loss: 4.78305651e-07
Iter: 577 loss: 4.79836672e-07
Iter: 578 loss: 4.78331572e-07
Iter: 579 loss: 4.7823238e-07
Iter: 580 loss: 4.78288712e-07
Iter: 581 loss: 4.78071684e-07
Iter: 582 loss: 4.77896151e-07
Iter: 583 loss: 4.78697189e-07
Iter: 584 loss: 4.77878189e-07
Iter: 585 loss: 4.77785591e-07
Iter: 586 loss: 4.77772915e-07
Iter: 587 loss: 4.77700041e-07
Iter: 588 loss: 4.77583399e-07
Iter: 589 loss: 4.77591129e-07
Iter: 590 loss: 4.77438903e-07
Iter: 591 loss: 4.78072252e-07
Iter: 592 loss: 4.77391154e-07
Iter: 593 loss: 4.77255355e-07
Iter: 594 loss: 4.77590788e-07
Iter: 595 loss: 4.77222386e-07
Iter: 596 loss: 4.77086814e-07
Iter: 597 loss: 4.77246431e-07
Iter: 598 loss: 4.76988248e-07
Iter: 599 loss: 4.76934247e-07
Iter: 600 loss: 4.77167816e-07
Iter: 601 loss: 4.76836647e-07
Iter: 602 loss: 4.76737569e-07
Iter: 603 loss: 4.76696698e-07
Iter: 604 loss: 4.76608164e-07
Iter: 605 loss: 4.76391307e-07
Iter: 606 loss: 4.7786142e-07
Iter: 607 loss: 4.76378801e-07
Iter: 608 loss: 4.76209038e-07
Iter: 609 loss: 4.76592845e-07
Iter: 610 loss: 4.7617587e-07
Iter: 611 loss: 4.76063462e-07
Iter: 612 loss: 4.77108586e-07
Iter: 613 loss: 4.76016879e-07
Iter: 614 loss: 4.75932836e-07
Iter: 615 loss: 4.7605937e-07
Iter: 616 loss: 4.75907399e-07
Iter: 617 loss: 4.75848594e-07
Iter: 618 loss: 4.76655146e-07
Iter: 619 loss: 4.75807497e-07
Iter: 620 loss: 4.75705349e-07
Iter: 621 loss: 4.75945797e-07
Iter: 622 loss: 4.75646289e-07
Iter: 623 loss: 4.75542606e-07
Iter: 624 loss: 4.75561251e-07
Iter: 625 loss: 4.75494858e-07
Iter: 626 loss: 4.75372815e-07
Iter: 627 loss: 4.75439208e-07
Iter: 628 loss: 4.75322679e-07
Iter: 629 loss: 4.75173351e-07
Iter: 630 loss: 4.7642493e-07
Iter: 631 loss: 4.75135835e-07
Iter: 632 loss: 4.75052246e-07
Iter: 633 loss: 4.75071971e-07
Iter: 634 loss: 4.74942425e-07
Iter: 635 loss: 4.74782155e-07
Iter: 636 loss: 4.75147488e-07
Iter: 637 loss: 4.74770133e-07
Iter: 638 loss: 4.74656815e-07
Iter: 639 loss: 4.75003105e-07
Iter: 640 loss: 4.74607788e-07
Iter: 641 loss: 4.74464571e-07
Iter: 642 loss: 4.74743e-07
Iter: 643 loss: 4.74372428e-07
Iter: 644 loss: 4.74248111e-07
Iter: 645 loss: 4.75511399e-07
Iter: 646 loss: 4.74232138e-07
Iter: 647 loss: 4.74142439e-07
Iter: 648 loss: 4.74013746e-07
Iter: 649 loss: 4.74029548e-07
Iter: 650 loss: 4.73938741e-07
Iter: 651 loss: 4.73951502e-07
Iter: 652 loss: 4.73819426e-07
Iter: 653 loss: 4.74246292e-07
Iter: 654 loss: 4.7379956e-07
Iter: 655 loss: 4.73724327e-07
Iter: 656 loss: 4.73630564e-07
Iter: 657 loss: 4.73625335e-07
Iter: 658 loss: 4.7353285e-07
Iter: 659 loss: 4.74291312e-07
Iter: 660 loss: 4.73468447e-07
Iter: 661 loss: 4.73393129e-07
Iter: 662 loss: 4.73756671e-07
Iter: 663 loss: 4.73375707e-07
Iter: 664 loss: 4.73283535e-07
Iter: 665 loss: 4.73251418e-07
Iter: 666 loss: 4.73182354e-07
Iter: 667 loss: 4.73078217e-07
Iter: 668 loss: 4.73578439e-07
Iter: 669 loss: 4.73042263e-07
Iter: 670 loss: 4.72937245e-07
Iter: 671 loss: 4.72904389e-07
Iter: 672 loss: 4.72817959e-07
Iter: 673 loss: 4.72682501e-07
Iter: 674 loss: 4.74601e-07
Iter: 675 loss: 4.72702567e-07
Iter: 676 loss: 4.72567763e-07
Iter: 677 loss: 4.72778453e-07
Iter: 678 loss: 4.72561027e-07
Iter: 679 loss: 4.72449443e-07
Iter: 680 loss: 4.72472721e-07
Iter: 681 loss: 4.72382453e-07
Iter: 682 loss: 4.72221842e-07
Iter: 683 loss: 4.72703277e-07
Iter: 684 loss: 4.72191118e-07
Iter: 685 loss: 4.72028432e-07
Iter: 686 loss: 4.73440963e-07
Iter: 687 loss: 4.72036106e-07
Iter: 688 loss: 4.71969599e-07
Iter: 689 loss: 4.71888768e-07
Iter: 690 loss: 4.71847244e-07
Iter: 691 loss: 4.71759137e-07
Iter: 692 loss: 4.72377707e-07
Iter: 693 loss: 4.71755385e-07
Iter: 694 loss: 4.71609781e-07
Iter: 695 loss: 4.71651333e-07
Iter: 696 loss: 4.71556433e-07
Iter: 697 loss: 4.7140577e-07
Iter: 698 loss: 4.72071e-07
Iter: 699 loss: 4.71410033e-07
Iter: 700 loss: 4.71301462e-07
Iter: 701 loss: 4.7124297e-07
Iter: 702 loss: 4.71210171e-07
Iter: 703 loss: 4.7104507e-07
Iter: 704 loss: 4.72003705e-07
Iter: 705 loss: 4.70994053e-07
Iter: 706 loss: 4.70929024e-07
Iter: 707 loss: 4.71086565e-07
Iter: 708 loss: 4.70873346e-07
Iter: 709 loss: 4.7077404e-07
Iter: 710 loss: 4.71679414e-07
Iter: 711 loss: 4.70736893e-07
Iter: 712 loss: 4.70630482e-07
Iter: 713 loss: 4.70867292e-07
Iter: 714 loss: 4.70622126e-07
Iter: 715 loss: 4.704753e-07
Iter: 716 loss: 4.70291752e-07
Iter: 717 loss: 4.7030116e-07
Iter: 718 loss: 4.70416381e-07
Iter: 719 loss: 4.70191537e-07
Iter: 720 loss: 4.70160046e-07
Iter: 721 loss: 4.70066198e-07
Iter: 722 loss: 4.71593467e-07
Iter: 723 loss: 4.70093056e-07
Iter: 724 loss: 4.69945121e-07
Iter: 725 loss: 4.70499856e-07
Iter: 726 loss: 4.69920849e-07
Iter: 727 loss: 4.69864688e-07
Iter: 728 loss: 4.70141174e-07
Iter: 729 loss: 4.69846043e-07
Iter: 730 loss: 4.6974975e-07
Iter: 731 loss: 4.69866848e-07
Iter: 732 loss: 4.6971752e-07
Iter: 733 loss: 4.69632141e-07
Iter: 734 loss: 4.69986162e-07
Iter: 735 loss: 4.69579277e-07
Iter: 736 loss: 4.69521183e-07
Iter: 737 loss: 4.6957814e-07
Iter: 738 loss: 4.69511235e-07
Iter: 739 loss: 4.69449276e-07
Iter: 740 loss: 4.69700296e-07
Iter: 741 loss: 4.69379358e-07
Iter: 742 loss: 4.69297504e-07
Iter: 743 loss: 4.69443421e-07
Iter: 744 loss: 4.69295799e-07
Iter: 745 loss: 4.69230656e-07
Iter: 746 loss: 4.69464908e-07
Iter: 747 loss: 4.69160682e-07
Iter: 748 loss: 4.69121289e-07
Iter: 749 loss: 4.69284402e-07
Iter: 750 loss: 4.69136523e-07
Iter: 751 loss: 4.69092754e-07
Iter: 752 loss: 4.6942813e-07
Iter: 753 loss: 4.69077747e-07
Iter: 754 loss: 4.68967357e-07
Iter: 755 loss: 4.69028e-07
Iter: 756 loss: 4.68945643e-07
Iter: 757 loss: 4.68951299e-07
Iter: 758 loss: 4.68891102e-07
Iter: 759 loss: 4.68928789e-07
Iter: 760 loss: 4.68906734e-07
Iter: 761 loss: 4.68920916e-07
Iter: 762 loss: 4.68935866e-07
Iter: 763 loss: 4.68922224e-07
Iter: 764 loss: 4.68926487e-07
Iter: 765 loss: 4.68912731e-07
Iter: 766 loss: 4.68922337e-07
Iter: 767 loss: 4.68917392e-07
Iter: 768 loss: 4.68909775e-07
Iter: 769 loss: 4.6893274e-07
Iter: 770 loss: 4.68943654e-07
Iter: 771 loss: 4.68938765e-07
Iter: 772 loss: 4.68943796e-07
Iter: 773 loss: 4.68943369e-07
Iter: 774 loss: 4.68943142e-07
Iter: 775 loss: 4.68946098e-07
Iter: 776 loss: 4.68947832e-07
Iter: 777 loss: 4.68947803e-07
Iter: 778 loss: 4.68945757e-07
Iter: 779 loss: 4.68947377e-07
Iter: 780 loss: 4.68945814e-07
Iter: 781 loss: 4.68947377e-07
Iter: 782 loss: 4.68945814e-07
Iter: 783 loss: 4.68823828e-07
Iter: 784 loss: 4.6908491e-07
Iter: 785 loss: 4.68807116e-07
Iter: 786 loss: 4.68711619e-07
Iter: 787 loss: 4.68882718e-07
Iter: 788 loss: 4.68647073e-07
Iter: 789 loss: 4.68569397e-07
Iter: 790 loss: 4.69312681e-07
Iter: 791 loss: 4.68584602e-07
Iter: 792 loss: 4.68525258e-07
Iter: 793 loss: 4.68385679e-07
Iter: 794 loss: 4.68751665e-07
Iter: 795 loss: 4.68311924e-07
Iter: 796 loss: 4.68163535e-07
Iter: 797 loss: 4.68960025e-07
Iter: 798 loss: 4.68183146e-07
Iter: 799 loss: 4.68039161e-07
Iter: 800 loss: 4.68383462e-07
Iter: 801 loss: 4.68041321e-07
Iter: 802 loss: 4.67928601e-07
Iter: 803 loss: 4.67908706e-07
Iter: 804 loss: 4.67913821e-07
Iter: 805 loss: 4.678854e-07
Iter: 806 loss: 4.67921836e-07
Iter: 807 loss: 4.67894694e-07
Iter: 808 loss: 4.67922291e-07
Iter: 809 loss: 4.67862776e-07
Iter: 810 loss: 4.67915015e-07
Iter: 811 loss: 4.67909757e-07
Iter: 812 loss: 4.67914901e-07
Iter: 813 loss: 4.67874202e-07
Iter: 814 loss: 4.67906375e-07
Iter: 815 loss: 4.67899241e-07
Iter: 816 loss: 4.67911661e-07
Iter: 817 loss: 4.67918284e-07
Iter: 818 loss: 4.67915356e-07
Iter: 819 loss: 4.67909786e-07
Iter: 820 loss: 4.67907029e-07
Iter: 821 loss: 4.67915697e-07
Iter: 822 loss: 4.67911406e-07
Iter: 823 loss: 4.67910525e-07
Iter: 824 loss: 4.67907455e-07
Iter: 825 loss: 4.67907853e-07
Iter: 826 loss: 4.67911093e-07
Iter: 827 loss: 4.67911093e-07
Iter: 828 loss: 4.67911093e-07
Iter: 829 loss: 4.67907853e-07
Iter: 830 loss: 4.67755541e-07
Iter: 831 loss: 4.69089855e-07
Iter: 832 loss: 4.67801812e-07
Iter: 833 loss: 4.67772281e-07
Iter: 834 loss: 4.67753921e-07
Iter: 835 loss: 4.67723709e-07
Iter: 836 loss: 4.67699522e-07
Iter: 837 loss: 4.67682213e-07
Iter: 838 loss: 4.67625256e-07
Iter: 839 loss: 4.67603058e-07
Iter: 840 loss: 4.67564178e-07
Iter: 841 loss: 4.67504947e-07
Iter: 842 loss: 4.67541042e-07
Iter: 843 loss: 4.67482664e-07
Iter: 844 loss: 4.67392908e-07
Iter: 845 loss: 4.67796156e-07
Iter: 846 loss: 4.67363293e-07
Iter: 847 loss: 4.67336463e-07
Iter: 848 loss: 4.68283872e-07
Iter: 849 loss: 4.67321911e-07
Iter: 850 loss: 4.67310656e-07
Iter: 851 loss: 4.67176193e-07
Iter: 852 loss: 4.68698232e-07
Iter: 853 loss: 4.67185032e-07
Iter: 854 loss: 4.67003815e-07
Iter: 855 loss: 4.67914134e-07
Iter: 856 loss: 4.6699725e-07
Iter: 857 loss: 4.66839367e-07
Iter: 858 loss: 4.67506e-07
Iter: 859 loss: 4.66827743e-07
Iter: 860 loss: 4.66686714e-07
Iter: 861 loss: 4.6676e-07
Iter: 862 loss: 4.66573738e-07
Iter: 863 loss: 4.66499642e-07
Iter: 864 loss: 4.66293045e-07
Iter: 865 loss: 4.66338236e-07
Iter: 866 loss: 4.66084714e-07
Iter: 867 loss: 4.6788665e-07
Iter: 868 loss: 4.66051375e-07
Iter: 869 loss: 4.66020282e-07
Iter: 870 loss: 4.65962984e-07
Iter: 871 loss: 4.65935443e-07
Iter: 872 loss: 4.65810899e-07
Iter: 873 loss: 4.66305693e-07
Iter: 874 loss: 4.65811866e-07
Iter: 875 loss: 4.65658019e-07
Iter: 876 loss: 4.66639023e-07
Iter: 877 loss: 4.65627636e-07
Iter: 878 loss: 4.65538562e-07
Iter: 879 loss: 4.65605098e-07
Iter: 880 loss: 4.654637e-07
Iter: 881 loss: 4.65360529e-07
Iter: 882 loss: 4.65701646e-07
Iter: 883 loss: 4.65331567e-07
Iter: 884 loss: 4.65192841e-07
Iter: 885 loss: 4.65467707e-07
Iter: 886 loss: 4.65188407e-07
Iter: 887 loss: 4.6502393e-07
Iter: 888 loss: 4.65045957e-07
Iter: 889 loss: 4.64988716e-07
Iter: 890 loss: 4.64915075e-07
Iter: 891 loss: 4.66998131e-07
Iter: 892 loss: 4.64899813e-07
Iter: 893 loss: 4.64750116e-07
Iter: 894 loss: 4.65117751e-07
Iter: 895 loss: 4.64755743e-07
Iter: 896 loss: 4.64652032e-07
Iter: 897 loss: 4.64559719e-07
Iter: 898 loss: 4.64570689e-07
Iter: 899 loss: 4.6440644e-07
Iter: 900 loss: 4.64617386e-07
Iter: 901 loss: 4.64333539e-07
Iter: 902 loss: 4.64277917e-07
Iter: 903 loss: 4.65042774e-07
Iter: 904 loss: 4.64279083e-07
Iter: 905 loss: 4.6421323e-07
Iter: 906 loss: 4.64064669e-07
Iter: 907 loss: 4.64098719e-07
Iter: 908 loss: 4.63993672e-07
Iter: 909 loss: 4.64928803e-07
Iter: 910 loss: 4.63984236e-07
Iter: 911 loss: 4.63898061e-07
Iter: 912 loss: 4.64075356e-07
Iter: 913 loss: 4.63894253e-07
Iter: 914 loss: 4.63802905e-07
Iter: 915 loss: 4.63667618e-07
Iter: 916 loss: 4.6372719e-07
Iter: 917 loss: 4.63589458e-07
Iter: 918 loss: 4.64146581e-07
Iter: 919 loss: 4.63533638e-07
Iter: 920 loss: 4.6346338e-07
Iter: 921 loss: 4.64599566e-07
Iter: 922 loss: 4.63483133e-07
Iter: 923 loss: 4.6339926e-07
Iter: 924 loss: 4.63563595e-07
Iter: 925 loss: 4.63361914e-07
Iter: 926 loss: 4.63300466e-07
Iter: 927 loss: 4.63291514e-07
Iter: 928 loss: 4.63264712e-07
Iter: 929 loss: 4.63187803e-07
Iter: 930 loss: 4.63580648e-07
Iter: 931 loss: 4.63156141e-07
Iter: 932 loss: 4.6305837e-07
Iter: 933 loss: 4.62979813e-07
Iter: 934 loss: 4.63001186e-07
Iter: 935 loss: 4.62920923e-07
Iter: 936 loss: 4.64365343e-07
Iter: 937 loss: 4.6288784e-07
Iter: 938 loss: 4.62857855e-07
Iter: 939 loss: 4.63220033e-07
Iter: 940 loss: 4.62782509e-07
Iter: 941 loss: 4.627463e-07
Iter: 942 loss: 4.6269929e-07
Iter: 943 loss: 4.64787973e-07
Iter: 944 loss: 4.62702502e-07
Iter: 945 loss: 4.62600894e-07
Iter: 946 loss: 4.63851507e-07
Iter: 947 loss: 4.62568835e-07
Iter: 948 loss: 4.62492324e-07
Iter: 949 loss: 4.62526771e-07
Iter: 950 loss: 4.62435565e-07
Iter: 951 loss: 4.62351409e-07
Iter: 952 loss: 4.62262506e-07
Iter: 953 loss: 4.62232833e-07
Iter: 954 loss: 4.62166497e-07
Iter: 955 loss: 4.62116816e-07
Iter: 956 loss: 4.62027742e-07
Iter: 957 loss: 4.6269e-07
Iter: 958 loss: 4.6208055e-07
Iter: 959 loss: 4.61984229e-07
Iter: 960 loss: 4.62076798e-07
Iter: 961 loss: 4.61981614e-07
Iter: 962 loss: 4.61885065e-07
Iter: 963 loss: 4.62024303e-07
Iter: 964 loss: 4.61829671e-07
Iter: 965 loss: 4.61788545e-07
Iter: 966 loss: 4.6199321e-07
Iter: 967 loss: 4.61747334e-07
Iter: 968 loss: 4.61737642e-07
Iter: 969 loss: 4.61845673e-07
Iter: 970 loss: 4.616615e-07
Iter: 971 loss: 4.61653343e-07
Iter: 972 loss: 4.61661955e-07
Iter: 973 loss: 4.61638876e-07
Iter: 974 loss: 4.6151257e-07
Iter: 975 loss: 4.61510183e-07
Iter: 976 loss: 4.6144919e-07
Iter: 977 loss: 4.61533716e-07
Iter: 978 loss: 4.61443676e-07
Iter: 979 loss: 4.61299521e-07
Iter: 980 loss: 4.61737045e-07
Iter: 981 loss: 4.61270645e-07
Iter: 982 loss: 4.61197573e-07
Iter: 983 loss: 4.61134903e-07
Iter: 984 loss: 4.61134505e-07
Iter: 985 loss: 4.61003083e-07
Iter: 986 loss: 4.620357e-07
Iter: 987 loss: 4.60952634e-07
Iter: 988 loss: 4.60859383e-07
Iter: 989 loss: 4.61571119e-07
Iter: 990 loss: 4.60845513e-07
Iter: 991 loss: 4.60743195e-07
Iter: 992 loss: 4.61063621e-07
Iter: 993 loss: 4.6067197e-07
Iter: 994 loss: 4.60633885e-07
Iter: 995 loss: 4.60640194e-07
Iter: 996 loss: 4.60603928e-07
Iter: 997 loss: 4.60469e-07
Iter: 998 loss: 4.60533613e-07
Iter: 999 loss: 4.60411343e-07
Iter: 1000 loss: 4.60372178e-07
Iter: 1001 loss: 4.60864783e-07
Iter: 1002 loss: 4.60340232e-07
Iter: 1003 loss: 4.60242461e-07
Iter: 1004 loss: 4.60979749e-07
Iter: 1005 loss: 4.60238653e-07
Iter: 1006 loss: 4.60198066e-07
Iter: 1007 loss: 4.60219383e-07
Iter: 1008 loss: 4.6014776e-07
Iter: 1009 loss: 4.60102285e-07
Iter: 1010 loss: 4.60039587e-07
Iter: 1011 loss: 4.60053144e-07
Iter: 1012 loss: 4.59974899e-07
Iter: 1013 loss: 4.60855233e-07
Iter: 1014 loss: 4.59961029e-07
Iter: 1015 loss: 4.59858143e-07
Iter: 1016 loss: 4.59861553e-07
Iter: 1017 loss: 4.59856267e-07
Iter: 1018 loss: 4.59748748e-07
Iter: 1019 loss: 4.5989924e-07
Iter: 1020 loss: 4.59750311e-07
Iter: 1021 loss: 4.59691051e-07
Iter: 1022 loss: 4.59800731e-07
Iter: 1023 loss: 4.59596691e-07
Iter: 1024 loss: 4.59514922e-07
Iter: 1025 loss: 4.59490366e-07
Iter: 1026 loss: 4.59479793e-07
Iter: 1027 loss: 4.59440912e-07
Iter: 1028 loss: 4.59452735e-07
Iter: 1029 loss: 4.59363434e-07
Iter: 1030 loss: 4.59430396e-07
Iter: 1031 loss: 4.59294824e-07
Iter: 1032 loss: 4.59278908e-07
Iter: 1033 loss: 4.59240312e-07
Iter: 1034 loss: 4.59244291e-07
Iter: 1035 loss: 4.59110851e-07
Iter: 1036 loss: 4.59089847e-07
Iter: 1037 loss: 4.59032094e-07
Iter: 1038 loss: 4.592344e-07
Iter: 1039 loss: 4.59029593e-07
Iter: 1040 loss: 4.58954389e-07
Iter: 1041 loss: 4.58965189e-07
Iter: 1042 loss: 4.58895926e-07
Iter: 1043 loss: 4.5886236e-07
Iter: 1044 loss: 4.59371165e-07
Iter: 1045 loss: 4.58833654e-07
Iter: 1046 loss: 4.58751572e-07
Iter: 1047 loss: 4.58918e-07
Iter: 1048 loss: 4.58768511e-07
Iter: 1049 loss: 4.58695467e-07
Iter: 1050 loss: 4.58600084e-07
Iter: 1051 loss: 4.58617478e-07
Iter: 1052 loss: 4.58469117e-07
Iter: 1053 loss: 4.58641125e-07
Iter: 1054 loss: 4.58434243e-07
Iter: 1055 loss: 4.58419208e-07
Iter: 1056 loss: 4.58369811e-07
Iter: 1057 loss: 4.58316322e-07
Iter: 1058 loss: 4.58312343e-07
Iter: 1059 loss: 4.58306374e-07
Iter: 1060 loss: 4.58210707e-07
Iter: 1061 loss: 4.58251918e-07
Iter: 1062 loss: 4.58169779e-07
Iter: 1063 loss: 4.58089687e-07
Iter: 1064 loss: 4.58794318e-07
Iter: 1065 loss: 4.58077352e-07
Iter: 1066 loss: 4.58003512e-07
Iter: 1067 loss: 4.57954229e-07
Iter: 1068 loss: 4.60294444e-07
Iter: 1069 loss: 4.5794863e-07
Iter: 1070 loss: 4.5796321e-07
Iter: 1071 loss: 4.57948289e-07
Iter: 1072 loss: 4.57843953e-07
Iter: 1073 loss: 4.57843242e-07
Iter: 1074 loss: 4.57829714e-07
Iter: 1075 loss: 4.5776568e-07
Iter: 1076 loss: 4.57705767e-07
Iter: 1077 loss: 4.57704459e-07
Iter: 1078 loss: 4.57629199e-07
Iter: 1079 loss: 4.58012153e-07
Iter: 1080 loss: 4.57560702e-07
Iter: 1081 loss: 4.57484759e-07
Iter: 1082 loss: 4.57613254e-07
Iter: 1083 loss: 4.57521139e-07
Iter: 1084 loss: 4.57446674e-07
Iter: 1085 loss: 4.57882948e-07
Iter: 1086 loss: 4.57413307e-07
Iter: 1087 loss: 4.5735905e-07
Iter: 1088 loss: 4.57382612e-07
Iter: 1089 loss: 4.57339922e-07
Iter: 1090 loss: 4.57293567e-07
Iter: 1091 loss: 4.57281828e-07
Iter: 1092 loss: 4.57261592e-07
Iter: 1093 loss: 4.57158734e-07
Iter: 1094 loss: 4.58480741e-07
Iter: 1095 loss: 4.57164077e-07
Iter: 1096 loss: 4.57039931e-07
Iter: 1097 loss: 4.57731971e-07
Iter: 1098 loss: 4.57041864e-07
Iter: 1099 loss: 4.56998407e-07
Iter: 1100 loss: 4.56903621e-07
Iter: 1101 loss: 4.56894838e-07
Iter: 1102 loss: 4.56753185e-07
Iter: 1103 loss: 4.58057229e-07
Iter: 1104 loss: 4.56827649e-07
Iter: 1105 loss: 4.56779333e-07
Iter: 1106 loss: 4.56779958e-07
Iter: 1107 loss: 4.56746761e-07
Iter: 1108 loss: 4.56725502e-07
Iter: 1109 loss: 4.56707539e-07
Iter: 1110 loss: 4.56668658e-07
Iter: 1111 loss: 4.56626708e-07
Iter: 1112 loss: 4.58079228e-07
Iter: 1113 loss: 4.56586918e-07
Iter: 1114 loss: 4.56486816e-07
Iter: 1115 loss: 4.57221745e-07
Iter: 1116 loss: 4.56527744e-07
Iter: 1117 loss: 4.56433952e-07
Iter: 1118 loss: 4.56621791e-07
Iter: 1119 loss: 4.56356787e-07
Iter: 1120 loss: 4.56374494e-07
Iter: 1121 loss: 4.56346669e-07
Iter: 1122 loss: 4.56356418e-07
Iter: 1123 loss: 4.56340331e-07
Iter: 1124 loss: 4.56341468e-07
Iter: 1125 loss: 4.56340388e-07
Iter: 1126 loss: 4.56343827e-07
Iter: 1127 loss: 4.56365314e-07
Iter: 1128 loss: 4.56360681e-07
Iter: 1129 loss: 4.56372163e-07
Iter: 1130 loss: 4.56362955e-07
Iter: 1131 loss: 4.56334249e-07
Iter: 1132 loss: 4.5634323e-07
Iter: 1133 loss: 4.56343713e-07
Iter: 1134 loss: 4.56355366e-07
Iter: 1135 loss: 4.56357725e-07
Iter: 1136 loss: 4.56357242e-07
Iter: 1137 loss: 4.56360709e-07
Iter: 1138 loss: 4.5636267e-07
Iter: 1139 loss: 4.56363978e-07
Iter: 1140 loss: 4.56364944e-07
Iter: 1141 loss: 4.56362443e-07
Iter: 1142 loss: 4.56362415e-07
Iter: 1143 loss: 4.56357213e-07
Iter: 1144 loss: 4.56363239e-07
Iter: 1145 loss: 4.56357213e-07
Iter: 1146 loss: 4.56253474e-07
Iter: 1147 loss: 4.57897272e-07
Iter: 1148 loss: 4.56264615e-07
Iter: 1149 loss: 4.5630469e-07
Iter: 1150 loss: 4.56217521e-07
Iter: 1151 loss: 4.56182221e-07
Iter: 1152 loss: 4.56116283e-07
Iter: 1153 loss: 4.56660189e-07
Iter: 1154 loss: 4.56105028e-07
Iter: 1155 loss: 4.56059297e-07
Iter: 1156 loss: 4.56096359e-07
Iter: 1157 loss: 4.56017517e-07
Iter: 1158 loss: 4.55975055e-07
Iter: 1159 loss: 4.56052078e-07
Iter: 1160 loss: 4.55894224e-07
Iter: 1161 loss: 4.55889392e-07
Iter: 1162 loss: 4.56260437e-07
Iter: 1163 loss: 4.55878364e-07
Iter: 1164 loss: 4.55827546e-07
Iter: 1165 loss: 4.56078112e-07
Iter: 1166 loss: 4.55797448e-07
Iter: 1167 loss: 4.55777524e-07
Iter: 1168 loss: 4.55994297e-07
Iter: 1169 loss: 4.5575058e-07
Iter: 1170 loss: 4.55728127e-07
Iter: 1171 loss: 4.55767747e-07
Iter: 1172 loss: 4.55734579e-07
Iter: 1173 loss: 4.55693652e-07
Iter: 1174 loss: 4.55877796e-07
Iter: 1175 loss: 4.55622683e-07
Iter: 1176 loss: 4.55627401e-07
Iter: 1177 loss: 4.5562382e-07
Iter: 1178 loss: 4.55653606e-07
Iter: 1179 loss: 4.55643345e-07
Iter: 1180 loss: 4.55633341e-07
Iter: 1181 loss: 4.5561859e-07
Iter: 1182 loss: 4.55651048e-07
Iter: 1183 loss: 4.55610717e-07
Iter: 1184 loss: 4.5562e-07
Iter: 1185 loss: 4.55613872e-07
Iter: 1186 loss: 4.55634165e-07
Iter: 1187 loss: 4.55617055e-07
Iter: 1188 loss: 4.55644624e-07
Iter: 1189 loss: 4.55631294e-07
Iter: 1190 loss: 4.55632346e-07
Iter: 1191 loss: 4.55619244e-07
Iter: 1192 loss: 4.55623706e-07
Iter: 1193 loss: 4.55623194e-07
Iter: 1194 loss: 4.55620437e-07
Iter: 1195 loss: 4.55623194e-07
Iter: 1196 loss: 4.55623251e-07
Iter: 1197 loss: 4.55623166e-07
Iter: 1198 loss: 4.55620437e-07
Iter: 1199 loss: 4.55623592e-07
Iter: 1200 loss: 4.55620437e-07
Iter: 1201 loss: 4.55620437e-07
Iter: 1202 loss: 4.55623592e-07
Iter: 1203 loss: 4.55623592e-07
Iter: 1204 loss: 4.55620437e-07
Iter: 1205 loss: 4.55623592e-07
Iter: 1206 loss: 4.55553277e-07
Iter: 1207 loss: 4.55560837e-07
Iter: 1208 loss: 4.555082e-07
Iter: 1209 loss: 4.56336551e-07
Iter: 1210 loss: 4.55518659e-07
Iter: 1211 loss: 4.55500555e-07
Iter: 1212 loss: 4.5590923e-07
Iter: 1213 loss: 4.55477164e-07
Iter: 1214 loss: 4.5545022e-07
Iter: 1215 loss: 4.55354126e-07
Iter: 1216 loss: 4.55389e-07
Iter: 1217 loss: 4.55316382e-07
Iter: 1218 loss: 4.55343582e-07
Iter: 1219 loss: 4.5525843e-07
Iter: 1220 loss: 4.55234442e-07
Iter: 1221 loss: 4.55213183e-07
Iter: 1222 loss: 4.55216195e-07
Iter: 1223 loss: 4.55106942e-07
Iter: 1224 loss: 4.55592328e-07
Iter: 1225 loss: 4.55084688e-07
Iter: 1226 loss: 4.55061411e-07
Iter: 1227 loss: 4.5510177e-07
Iter: 1228 loss: 4.55067777e-07
Iter: 1229 loss: 4.55019233e-07
Iter: 1230 loss: 4.55071643e-07
Iter: 1231 loss: 4.5496941e-07
Iter: 1232 loss: 4.54920695e-07
Iter: 1233 loss: 4.55090287e-07
Iter: 1234 loss: 4.54939311e-07
Iter: 1235 loss: 4.5486297e-07
Iter: 1236 loss: 4.5496671e-07
Iter: 1237 loss: 4.54870644e-07
Iter: 1238 loss: 4.54840603e-07
Iter: 1239 loss: 4.54846884e-07
Iter: 1240 loss: 4.54795497e-07
Iter: 1241 loss: 4.5473152e-07
Iter: 1242 loss: 4.5486027e-07
Iter: 1243 loss: 4.54753291e-07
Iter: 1244 loss: 4.54706822e-07
Iter: 1245 loss: 4.5482119e-07
Iter: 1246 loss: 4.54712534e-07
Iter: 1247 loss: 4.54619595e-07
Iter: 1248 loss: 4.55057204e-07
Iter: 1249 loss: 4.54671351e-07
Iter: 1250 loss: 4.54606806e-07
Iter: 1251 loss: 4.54578554e-07
Iter: 1252 loss: 4.54572074e-07
Iter: 1253 loss: 4.54525207e-07
Iter: 1254 loss: 4.54480954e-07
Iter: 1255 loss: 4.54461372e-07
Iter: 1256 loss: 4.54425049e-07
Iter: 1257 loss: 4.5442934e-07
Iter: 1258 loss: 4.54354506e-07
Iter: 1259 loss: 4.54352033e-07
Iter: 1260 loss: 4.54978817e-07
Iter: 1261 loss: 4.54340267e-07
Iter: 1262 loss: 4.54246759e-07
Iter: 1263 loss: 4.54657481e-07
Iter: 1264 loss: 4.54262533e-07
Iter: 1265 loss: 4.54218082e-07
Iter: 1266 loss: 4.54117469e-07
Iter: 1267 loss: 4.54132021e-07
Iter: 1268 loss: 4.54099165e-07
Iter: 1269 loss: 4.5463338e-07
Iter: 1270 loss: 4.54067e-07
Iter: 1271 loss: 4.53976043e-07
Iter: 1272 loss: 4.54100672e-07
Iter: 1273 loss: 4.53982921e-07
Iter: 1274 loss: 4.53934149e-07
Iter: 1275 loss: 4.53945489e-07
Iter: 1276 loss: 4.5392909e-07
Iter: 1277 loss: 4.53798293e-07
Iter: 1278 loss: 4.5425611e-07
Iter: 1279 loss: 4.53790591e-07
Iter: 1280 loss: 4.53775897e-07
Iter: 1281 loss: 4.53757877e-07
Iter: 1282 loss: 4.53714932e-07
Iter: 1283 loss: 4.53745628e-07
Iter: 1284 loss: 4.53713824e-07
Iter: 1285 loss: 4.5366221e-07
Iter: 1286 loss: 4.5364385e-07
Iter: 1287 loss: 4.5364e-07
Iter: 1288 loss: 4.53622278e-07
Iter: 1289 loss: 4.5359667e-07
Iter: 1290 loss: 4.54688404e-07
Iter: 1291 loss: 4.5362961e-07
Iter: 1292 loss: 4.53501059e-07
Iter: 1293 loss: 4.53876623e-07
Iter: 1294 loss: 4.53510779e-07
Iter: 1295 loss: 4.53474968e-07
Iter: 1296 loss: 4.53468374e-07
Iter: 1297 loss: 4.53453083e-07
Iter: 1298 loss: 4.53418721e-07
Iter: 1299 loss: 4.53351049e-07
Iter: 1300 loss: 4.5331717e-07
Iter: 1301 loss: 4.53312595e-07
Iter: 1302 loss: 4.53294803e-07
Iter: 1303 loss: 4.5328278e-07
Iter: 1304 loss: 4.53312964e-07
Iter: 1305 loss: 4.53255893e-07
Iter: 1306 loss: 4.53210305e-07
Iter: 1307 loss: 4.53166223e-07
Iter: 1308 loss: 4.53134817e-07
Iter: 1309 loss: 4.53104832e-07
Iter: 1310 loss: 4.53626456e-07
Iter: 1311 loss: 4.53093548e-07
Iter: 1312 loss: 4.53001235e-07
Iter: 1313 loss: 4.53065439e-07
Iter: 1314 loss: 4.5302852e-07
Iter: 1315 loss: 4.52953259e-07
Iter: 1316 loss: 4.53252369e-07
Iter: 1317 loss: 4.52962354e-07
Iter: 1318 loss: 4.52889765e-07
Iter: 1319 loss: 4.52897183e-07
Iter: 1320 loss: 4.52865265e-07
Iter: 1321 loss: 4.52852703e-07
Iter: 1322 loss: 4.52818824e-07
Iter: 1323 loss: 4.52848695e-07
Iter: 1324 loss: 4.52822633e-07
Iter: 1325 loss: 4.52842585e-07
Iter: 1326 loss: 4.52838947e-07
Iter: 1327 loss: 4.52841618e-07
Iter: 1328 loss: 4.52824366e-07
Iter: 1329 loss: 4.52843608e-07
Iter: 1330 loss: 4.52821894e-07
Iter: 1331 loss: 4.52845512e-07
Iter: 1332 loss: 4.52817574e-07
Iter: 1333 loss: 4.52826669e-07
Iter: 1334 loss: 4.52813794e-07
Iter: 1335 loss: 4.52825645e-07
Iter: 1336 loss: 4.52821268e-07
Iter: 1337 loss: 4.52819449e-07
Iter: 1338 loss: 4.52814277e-07
Iter: 1339 loss: 4.52817687e-07
Iter: 1340 loss: 4.52817744e-07
Iter: 1341 loss: 4.52817545e-07
Iter: 1342 loss: 4.52817602e-07
Iter: 1343 loss: 4.52819222e-07
Iter: 1344 loss: 4.52819222e-07
Iter: 1345 loss: 4.52819222e-07
Iter: 1346 loss: 4.52819222e-07
Iter: 1347 loss: 4.52819449e-07
Iter: 1348 loss: 4.52819449e-07
Iter: 1349 loss: 4.52819222e-07
Iter: 1350 loss: 4.52819222e-07
Iter: 1351 loss: 4.52819449e-07
Iter: 1352 loss: 4.52819222e-07
Iter: 1353 loss: 4.52819222e-07
Iter: 1354 loss: 4.52819449e-07
Iter: 1355 loss: 4.52819449e-07
Iter: 1356 loss: 4.52819222e-07
Iter: 1357 loss: 4.59101159e-07
Iter: 1358 loss: 4.52805e-07
Iter: 1359 loss: 4.52760389e-07
Iter: 1360 loss: 4.52751181e-07
Iter: 1361 loss: 4.527908e-07
Iter: 1362 loss: 4.52747656e-07
Iter: 1363 loss: 4.52751749e-07
Iter: 1364 loss: 4.52729751e-07
Iter: 1365 loss: 4.52731e-07
Iter: 1366 loss: 4.52723214e-07
Iter: 1367 loss: 4.52731115e-07
Iter: 1368 loss: 4.52736458e-07
Iter: 1369 loss: 4.52724862e-07
Iter: 1370 loss: 4.52728955e-07
Iter: 1371 loss: 4.5273606e-07
Iter: 1372 loss: 4.52753795e-07
Iter: 1373 loss: 4.52737396e-07
Iter: 1374 loss: 4.5272094e-07
Iter: 1375 loss: 4.52722787e-07
Iter: 1376 loss: 4.52735264e-07
Iter: 1377 loss: 4.52736941e-07
Iter: 1378 loss: 4.52747457e-07
Iter: 1379 loss: 4.52746775e-07
Iter: 1380 loss: 4.52748452e-07
Iter: 1381 loss: 4.52746349e-07
Iter: 1382 loss: 4.52747969e-07
Iter: 1383 loss: 4.52748282e-07
Iter: 1384 loss: 4.52748225e-07
Iter: 1385 loss: 4.52748282e-07
Iter: 1386 loss: 4.52747969e-07
Iter: 1387 loss: 4.52747969e-07
Iter: 1388 loss: 4.52748282e-07
Iter: 1389 loss: 4.52589632e-07
Iter: 1390 loss: 4.53229234e-07
Iter: 1391 loss: 4.52567235e-07
Iter: 1392 loss: 4.52570731e-07
Iter: 1393 loss: 4.52572067e-07
Iter: 1394 loss: 4.52585482e-07
Iter: 1395 loss: 4.52547965e-07
Iter: 1396 loss: 4.52530173e-07
Iter: 1397 loss: 4.5252105e-07
Iter: 1398 loss: 4.52519117e-07
Iter: 1399 loss: 4.52571328e-07
Iter: 1400 loss: 4.52537279e-07
Iter: 1401 loss: 4.52535943e-07
Iter: 1402 loss: 4.52542736e-07
Iter: 1403 loss: 4.52533271e-07
Iter: 1404 loss: 4.52540746e-07
Iter: 1405 loss: 4.52550637e-07
Iter: 1406 loss: 4.52556748e-07
Iter: 1407 loss: 4.52552172e-07
Iter: 1408 loss: 4.52557686e-07
Iter: 1409 loss: 4.52561665e-07
Iter: 1410 loss: 4.52574454e-07
Iter: 1411 loss: 4.52563484e-07
Iter: 1412 loss: 4.52573829e-07
Iter: 1413 loss: 4.52567548e-07
Iter: 1414 loss: 4.52569736e-07
Iter: 1415 loss: 4.52567662e-07
Iter: 1416 loss: 4.52569338e-07
Iter: 1417 loss: 4.52567804e-07
Iter: 1418 loss: 4.52567804e-07
Iter: 1419 loss: 4.52567662e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4
+ date
Mon Nov  9 07:33:58 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/500_500_500_500_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_1000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_1000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc534620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc4caa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc594e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc594400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc4a1048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc594840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc42e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc42e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc3e4268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc393598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc3a5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc36e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc3432f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc323ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc2d5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc2f4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc2a8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc2f4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc26c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc21a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc21a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc1d48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc1d4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc1af048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc1af8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc165f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc165620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc101ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc0c48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc0e9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc0c4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc0aa8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc0b3950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fddfc060a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdda00b62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdda00e0c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 7.34731075e-05
Iter: 2 loss: 0.0086535383
Iter: 3 loss: 4.65050689e-05
Iter: 4 loss: 3.52052375e-05
Iter: 5 loss: 8.15492094e-05
Iter: 6 loss: 3.26759218e-05
Iter: 7 loss: 2.88634055e-05
Iter: 8 loss: 3.0102301e-05
Iter: 9 loss: 2.61586974e-05
Iter: 10 loss: 2.13496787e-05
Iter: 11 loss: 5.27468073e-05
Iter: 12 loss: 2.0835645e-05
Iter: 13 loss: 1.77832462e-05
Iter: 14 loss: 1.71375304e-05
Iter: 15 loss: 1.51466393e-05
Iter: 16 loss: 1.29804384e-05
Iter: 17 loss: 2.84131838e-05
Iter: 18 loss: 1.2786867e-05
Iter: 19 loss: 1.14064433e-05
Iter: 20 loss: 1.42308782e-05
Iter: 21 loss: 1.08506538e-05
Iter: 22 loss: 9.41241888e-06
Iter: 23 loss: 1.12445741e-05
Iter: 24 loss: 8.67259405e-06
Iter: 25 loss: 7.55710835e-06
Iter: 26 loss: 7.14857197e-06
Iter: 27 loss: 6.53199822e-06
Iter: 28 loss: 5.79543075e-06
Iter: 29 loss: 5.75845024e-06
Iter: 30 loss: 5.24551e-06
Iter: 31 loss: 6.45341515e-06
Iter: 32 loss: 5.05773824e-06
Iter: 33 loss: 4.6666014e-06
Iter: 34 loss: 6.46346507e-06
Iter: 35 loss: 4.59440525e-06
Iter: 36 loss: 4.31387343e-06
Iter: 37 loss: 6.96348252e-06
Iter: 38 loss: 4.30285127e-06
Iter: 39 loss: 4.30154432e-06
Iter: 40 loss: 4.23760366e-06
Iter: 41 loss: 4.16253806e-06
Iter: 42 loss: 3.93626e-06
Iter: 43 loss: 4.65122594e-06
Iter: 44 loss: 3.82642565e-06
Iter: 45 loss: 3.7573609e-06
Iter: 46 loss: 3.71960778e-06
Iter: 47 loss: 3.64257357e-06
Iter: 48 loss: 3.52977304e-06
Iter: 49 loss: 3.52631014e-06
Iter: 50 loss: 3.36082758e-06
Iter: 51 loss: 3.88860281e-06
Iter: 52 loss: 3.31435353e-06
Iter: 53 loss: 3.19135506e-06
Iter: 54 loss: 3.85107751e-06
Iter: 55 loss: 3.17274771e-06
Iter: 56 loss: 3.05420645e-06
Iter: 57 loss: 3.11928784e-06
Iter: 58 loss: 2.97527663e-06
Iter: 59 loss: 2.88248566e-06
Iter: 60 loss: 3.30986836e-06
Iter: 61 loss: 2.86509339e-06
Iter: 62 loss: 2.77953905e-06
Iter: 63 loss: 2.76827973e-06
Iter: 64 loss: 2.70643523e-06
Iter: 65 loss: 2.63710649e-06
Iter: 66 loss: 3.32265904e-06
Iter: 67 loss: 2.63564652e-06
Iter: 68 loss: 2.57508509e-06
Iter: 69 loss: 2.61628429e-06
Iter: 70 loss: 2.53716553e-06
Iter: 71 loss: 2.51876281e-06
Iter: 72 loss: 2.50202447e-06
Iter: 73 loss: 2.47228559e-06
Iter: 74 loss: 2.71020326e-06
Iter: 75 loss: 2.47010939e-06
Iter: 76 loss: 2.45644515e-06
Iter: 77 loss: 2.41940052e-06
Iter: 78 loss: 2.63792526e-06
Iter: 79 loss: 2.40922236e-06
Iter: 80 loss: 2.37015593e-06
Iter: 81 loss: 2.91527635e-06
Iter: 82 loss: 2.36958977e-06
Iter: 83 loss: 2.33749051e-06
Iter: 84 loss: 2.37462723e-06
Iter: 85 loss: 2.3204866e-06
Iter: 86 loss: 2.29029865e-06
Iter: 87 loss: 2.27448e-06
Iter: 88 loss: 2.25903113e-06
Iter: 89 loss: 2.22370863e-06
Iter: 90 loss: 2.30373576e-06
Iter: 91 loss: 2.21041682e-06
Iter: 92 loss: 2.17369802e-06
Iter: 93 loss: 2.68156919e-06
Iter: 94 loss: 2.17342722e-06
Iter: 95 loss: 2.15164141e-06
Iter: 96 loss: 2.11841621e-06
Iter: 97 loss: 2.11772885e-06
Iter: 98 loss: 2.08171446e-06
Iter: 99 loss: 2.44685702e-06
Iter: 100 loss: 2.08070355e-06
Iter: 101 loss: 2.04786147e-06
Iter: 102 loss: 2.01056537e-06
Iter: 103 loss: 2.00588329e-06
Iter: 104 loss: 1.98669363e-06
Iter: 105 loss: 1.98200291e-06
Iter: 106 loss: 1.97434883e-06
Iter: 107 loss: 1.96986821e-06
Iter: 108 loss: 1.96269139e-06
Iter: 109 loss: 1.94382574e-06
Iter: 110 loss: 2.09722975e-06
Iter: 111 loss: 1.94119275e-06
Iter: 112 loss: 1.91786307e-06
Iter: 113 loss: 1.94743507e-06
Iter: 114 loss: 1.90650712e-06
Iter: 115 loss: 1.88577894e-06
Iter: 116 loss: 2.16857075e-06
Iter: 117 loss: 1.88557487e-06
Iter: 118 loss: 1.87156911e-06
Iter: 119 loss: 1.85077852e-06
Iter: 120 loss: 1.8503365e-06
Iter: 121 loss: 1.82760141e-06
Iter: 122 loss: 1.90308606e-06
Iter: 123 loss: 1.82055373e-06
Iter: 124 loss: 1.79736935e-06
Iter: 125 loss: 1.82599706e-06
Iter: 126 loss: 1.7847608e-06
Iter: 127 loss: 1.77015829e-06
Iter: 128 loss: 1.76952688e-06
Iter: 129 loss: 1.75676075e-06
Iter: 130 loss: 1.73090916e-06
Iter: 131 loss: 2.17662068e-06
Iter: 132 loss: 1.73045669e-06
Iter: 133 loss: 1.70530598e-06
Iter: 134 loss: 1.9406591e-06
Iter: 135 loss: 1.7046234e-06
Iter: 136 loss: 1.68527708e-06
Iter: 137 loss: 1.73179887e-06
Iter: 138 loss: 1.67881149e-06
Iter: 139 loss: 1.6797901e-06
Iter: 140 loss: 1.67157668e-06
Iter: 141 loss: 1.66367806e-06
Iter: 142 loss: 1.65041399e-06
Iter: 143 loss: 1.65046163e-06
Iter: 144 loss: 1.64089704e-06
Iter: 145 loss: 1.6507305e-06
Iter: 146 loss: 1.63675145e-06
Iter: 147 loss: 1.62723154e-06
Iter: 148 loss: 1.70847977e-06
Iter: 149 loss: 1.62704418e-06
Iter: 150 loss: 1.61654634e-06
Iter: 151 loss: 1.61231151e-06
Iter: 152 loss: 1.60709351e-06
Iter: 153 loss: 1.59664967e-06
Iter: 154 loss: 1.59838805e-06
Iter: 155 loss: 1.58904868e-06
Iter: 156 loss: 1.57726618e-06
Iter: 157 loss: 1.66892391e-06
Iter: 158 loss: 1.57577e-06
Iter: 159 loss: 1.56684393e-06
Iter: 160 loss: 1.55159955e-06
Iter: 161 loss: 1.55166276e-06
Iter: 162 loss: 1.53922758e-06
Iter: 163 loss: 1.53945302e-06
Iter: 164 loss: 1.53065048e-06
Iter: 165 loss: 1.55161035e-06
Iter: 166 loss: 1.52766302e-06
Iter: 167 loss: 1.51804716e-06
Iter: 168 loss: 1.50108349e-06
Iter: 169 loss: 1.50088e-06
Iter: 170 loss: 1.48113475e-06
Iter: 171 loss: 1.56750639e-06
Iter: 172 loss: 1.47678315e-06
Iter: 173 loss: 1.51193967e-06
Iter: 174 loss: 1.47319849e-06
Iter: 175 loss: 1.47036394e-06
Iter: 176 loss: 1.46273317e-06
Iter: 177 loss: 1.46418654e-06
Iter: 178 loss: 1.45453487e-06
Iter: 179 loss: 1.44173293e-06
Iter: 180 loss: 1.57081945e-06
Iter: 181 loss: 1.44061698e-06
Iter: 182 loss: 1.43523766e-06
Iter: 183 loss: 1.43516468e-06
Iter: 184 loss: 1.43112845e-06
Iter: 185 loss: 1.42116369e-06
Iter: 186 loss: 1.50950609e-06
Iter: 187 loss: 1.41903729e-06
Iter: 188 loss: 1.40787438e-06
Iter: 189 loss: 1.5285799e-06
Iter: 190 loss: 1.40751615e-06
Iter: 191 loss: 1.40002749e-06
Iter: 192 loss: 1.39810925e-06
Iter: 193 loss: 1.39266297e-06
Iter: 194 loss: 1.38231815e-06
Iter: 195 loss: 1.39236522e-06
Iter: 196 loss: 1.37629286e-06
Iter: 197 loss: 1.36834478e-06
Iter: 198 loss: 1.45593503e-06
Iter: 199 loss: 1.36781409e-06
Iter: 200 loss: 1.35950256e-06
Iter: 201 loss: 1.36552512e-06
Iter: 202 loss: 1.35378639e-06
Iter: 203 loss: 1.34597803e-06
Iter: 204 loss: 1.36715835e-06
Iter: 205 loss: 1.34344873e-06
Iter: 206 loss: 1.34051334e-06
Iter: 207 loss: 1.33998276e-06
Iter: 208 loss: 1.33557876e-06
Iter: 209 loss: 1.33605647e-06
Iter: 210 loss: 1.33233812e-06
Iter: 211 loss: 1.32949094e-06
Iter: 212 loss: 1.3251389e-06
Iter: 213 loss: 1.42177976e-06
Iter: 214 loss: 1.32548519e-06
Iter: 215 loss: 1.31791376e-06
Iter: 216 loss: 1.33993069e-06
Iter: 217 loss: 1.31567117e-06
Iter: 218 loss: 1.30657281e-06
Iter: 219 loss: 1.34299455e-06
Iter: 220 loss: 1.30490014e-06
Iter: 221 loss: 1.29975865e-06
Iter: 222 loss: 1.29400223e-06
Iter: 223 loss: 1.29420278e-06
Iter: 224 loss: 1.28470833e-06
Iter: 225 loss: 1.32112302e-06
Iter: 226 loss: 1.28238344e-06
Iter: 227 loss: 1.27569695e-06
Iter: 228 loss: 1.29871717e-06
Iter: 229 loss: 1.27407498e-06
Iter: 230 loss: 1.267377e-06
Iter: 231 loss: 1.27197518e-06
Iter: 232 loss: 1.26276404e-06
Iter: 233 loss: 1.25698591e-06
Iter: 234 loss: 1.27385692e-06
Iter: 235 loss: 1.25583665e-06
Iter: 236 loss: 1.24857218e-06
Iter: 237 loss: 1.29856153e-06
Iter: 238 loss: 1.24805354e-06
Iter: 239 loss: 1.24321502e-06
Iter: 240 loss: 1.26634427e-06
Iter: 241 loss: 1.24219855e-06
Iter: 242 loss: 1.23758412e-06
Iter: 243 loss: 1.28551437e-06
Iter: 244 loss: 1.23765153e-06
Iter: 245 loss: 1.23609038e-06
Iter: 246 loss: 1.23092036e-06
Iter: 247 loss: 1.25713018e-06
Iter: 248 loss: 1.22973131e-06
Iter: 249 loss: 1.22165306e-06
Iter: 250 loss: 1.22445886e-06
Iter: 251 loss: 1.21606058e-06
Iter: 252 loss: 1.21502774e-06
Iter: 253 loss: 1.21221137e-06
Iter: 254 loss: 1.20917321e-06
Iter: 255 loss: 1.20498532e-06
Iter: 256 loss: 1.20426455e-06
Iter: 257 loss: 1.19961055e-06
Iter: 258 loss: 1.20456127e-06
Iter: 259 loss: 1.19630715e-06
Iter: 260 loss: 1.19050037e-06
Iter: 261 loss: 1.2270765e-06
Iter: 262 loss: 1.18940682e-06
Iter: 263 loss: 1.1852768e-06
Iter: 264 loss: 1.18436321e-06
Iter: 265 loss: 1.18123296e-06
Iter: 266 loss: 1.17425861e-06
Iter: 267 loss: 1.20049276e-06
Iter: 268 loss: 1.17295883e-06
Iter: 269 loss: 1.16727608e-06
Iter: 270 loss: 1.16916044e-06
Iter: 271 loss: 1.16343358e-06
Iter: 272 loss: 1.15783769e-06
Iter: 273 loss: 1.17847435e-06
Iter: 274 loss: 1.15585931e-06
Iter: 275 loss: 1.15084458e-06
Iter: 276 loss: 1.18076798e-06
Iter: 277 loss: 1.14962359e-06
Iter: 278 loss: 1.14806403e-06
Iter: 279 loss: 1.14681325e-06
Iter: 280 loss: 1.14464729e-06
Iter: 281 loss: 1.1415857e-06
Iter: 282 loss: 1.14179841e-06
Iter: 283 loss: 1.13917247e-06
Iter: 284 loss: 1.14008446e-06
Iter: 285 loss: 1.13799467e-06
Iter: 286 loss: 1.13350791e-06
Iter: 287 loss: 1.13964256e-06
Iter: 288 loss: 1.13168858e-06
Iter: 289 loss: 1.12888461e-06
Iter: 290 loss: 1.12930331e-06
Iter: 291 loss: 1.12738815e-06
Iter: 292 loss: 1.12333191e-06
Iter: 293 loss: 1.13905753e-06
Iter: 294 loss: 1.12290229e-06
Iter: 295 loss: 1.1196073e-06
Iter: 296 loss: 1.12157113e-06
Iter: 297 loss: 1.11805696e-06
Iter: 298 loss: 1.11388829e-06
Iter: 299 loss: 1.11189786e-06
Iter: 300 loss: 1.10968108e-06
Iter: 301 loss: 1.10513542e-06
Iter: 302 loss: 1.11828501e-06
Iter: 303 loss: 1.10342478e-06
Iter: 304 loss: 1.09780945e-06
Iter: 305 loss: 1.10572557e-06
Iter: 306 loss: 1.09551979e-06
Iter: 307 loss: 1.09088046e-06
Iter: 308 loss: 1.13263627e-06
Iter: 309 loss: 1.09092889e-06
Iter: 310 loss: 1.08851043e-06
Iter: 311 loss: 1.08815379e-06
Iter: 312 loss: 1.08592155e-06
Iter: 313 loss: 1.0890094e-06
Iter: 314 loss: 1.08486825e-06
Iter: 315 loss: 1.08268046e-06
Iter: 316 loss: 1.07890503e-06
Iter: 317 loss: 1.0788433e-06
Iter: 318 loss: 1.07593507e-06
Iter: 319 loss: 1.10899907e-06
Iter: 320 loss: 1.07644928e-06
Iter: 321 loss: 1.07413325e-06
Iter: 322 loss: 1.07366691e-06
Iter: 323 loss: 1.07199583e-06
Iter: 324 loss: 1.06946266e-06
Iter: 325 loss: 1.07146866e-06
Iter: 326 loss: 1.06724588e-06
Iter: 327 loss: 1.06385232e-06
Iter: 328 loss: 1.06225809e-06
Iter: 329 loss: 1.06089692e-06
Iter: 330 loss: 1.0579522e-06
Iter: 331 loss: 1.09476593e-06
Iter: 332 loss: 1.05810943e-06
Iter: 333 loss: 1.05487584e-06
Iter: 334 loss: 1.0575809e-06
Iter: 335 loss: 1.05313597e-06
Iter: 336 loss: 1.05041e-06
Iter: 337 loss: 1.05129948e-06
Iter: 338 loss: 1.04805e-06
Iter: 339 loss: 1.0446272e-06
Iter: 340 loss: 1.05598156e-06
Iter: 341 loss: 1.04384e-06
Iter: 342 loss: 1.0402556e-06
Iter: 343 loss: 1.06596985e-06
Iter: 344 loss: 1.03987747e-06
Iter: 345 loss: 1.03720026e-06
Iter: 346 loss: 1.08242114e-06
Iter: 347 loss: 1.03753155e-06
Iter: 348 loss: 1.0354305e-06
Iter: 349 loss: 1.03464663e-06
Iter: 350 loss: 1.03364141e-06
Iter: 351 loss: 1.03224829e-06
Iter: 352 loss: 1.03497246e-06
Iter: 353 loss: 1.03120624e-06
Iter: 354 loss: 1.02864578e-06
Iter: 355 loss: 1.03178729e-06
Iter: 356 loss: 1.02694e-06
Iter: 357 loss: 1.02414538e-06
Iter: 358 loss: 1.03101263e-06
Iter: 359 loss: 1.02306262e-06
Iter: 360 loss: 1.01988871e-06
Iter: 361 loss: 1.02574484e-06
Iter: 362 loss: 1.01857017e-06
Iter: 363 loss: 1.01609157e-06
Iter: 364 loss: 1.01171668e-06
Iter: 365 loss: 1.01125363e-06
Iter: 366 loss: 1.00804925e-06
Iter: 367 loss: 1.0082482e-06
Iter: 368 loss: 1.00575096e-06
Iter: 369 loss: 1.00335171e-06
Iter: 370 loss: 1.00264901e-06
Iter: 371 loss: 9.99341296e-07
Iter: 372 loss: 1.02048557e-06
Iter: 373 loss: 9.98650194e-07
Iter: 374 loss: 9.95574169e-07
Iter: 375 loss: 1.0251398e-06
Iter: 376 loss: 9.95671e-07
Iter: 377 loss: 9.95431833e-07
Iter: 378 loss: 9.948875e-07
Iter: 379 loss: 9.9448107e-07
Iter: 380 loss: 9.93743583e-07
Iter: 381 loss: 9.93269e-07
Iter: 382 loss: 9.91753382e-07
Iter: 383 loss: 9.91647539e-07
Iter: 384 loss: 9.90534204e-07
Iter: 385 loss: 9.88232841e-07
Iter: 386 loss: 9.90772719e-07
Iter: 387 loss: 9.86999794e-07
Iter: 388 loss: 9.85097245e-07
Iter: 389 loss: 1.01100193e-06
Iter: 390 loss: 9.84710937e-07
Iter: 391 loss: 9.83420819e-07
Iter: 392 loss: 9.94581342e-07
Iter: 393 loss: 9.83538e-07
Iter: 394 loss: 9.82463689e-07
Iter: 395 loss: 9.81115932e-07
Iter: 396 loss: 9.81143899e-07
Iter: 397 loss: 9.79183142e-07
Iter: 398 loss: 9.82126267e-07
Iter: 399 loss: 9.77618924e-07
Iter: 400 loss: 9.7580687e-07
Iter: 401 loss: 9.80250661e-07
Iter: 402 loss: 9.75099169e-07
Iter: 403 loss: 9.72458565e-07
Iter: 404 loss: 9.75624289e-07
Iter: 405 loss: 9.70962674e-07
Iter: 406 loss: 9.69485086e-07
Iter: 407 loss: 9.69383791e-07
Iter: 408 loss: 9.6866313e-07
Iter: 409 loss: 9.71800318e-07
Iter: 410 loss: 9.68216114e-07
Iter: 411 loss: 9.66646e-07
Iter: 412 loss: 9.65640652e-07
Iter: 413 loss: 9.64929882e-07
Iter: 414 loss: 9.64248329e-07
Iter: 415 loss: 9.66215111e-07
Iter: 416 loss: 9.63335651e-07
Iter: 417 loss: 9.62061e-07
Iter: 418 loss: 9.71250756e-07
Iter: 419 loss: 9.62107492e-07
Iter: 420 loss: 9.6130384e-07
Iter: 421 loss: 9.6067879e-07
Iter: 422 loss: 9.59947783e-07
Iter: 423 loss: 9.58632654e-07
Iter: 424 loss: 9.71129566e-07
Iter: 425 loss: 9.58559667e-07
Iter: 426 loss: 9.57276825e-07
Iter: 427 loss: 9.57900511e-07
Iter: 428 loss: 9.56054464e-07
Iter: 429 loss: 9.54008328e-07
Iter: 430 loss: 9.65394747e-07
Iter: 431 loss: 9.5400037e-07
Iter: 432 loss: 9.51779896e-07
Iter: 433 loss: 9.53101676e-07
Iter: 434 loss: 9.50610854e-07
Iter: 435 loss: 9.48638e-07
Iter: 436 loss: 9.48007937e-07
Iter: 437 loss: 9.46922341e-07
Iter: 438 loss: 9.44731767e-07
Iter: 439 loss: 9.67909273e-07
Iter: 440 loss: 9.44740236e-07
Iter: 441 loss: 9.44228077e-07
Iter: 442 loss: 9.44095405e-07
Iter: 443 loss: 9.43374516e-07
Iter: 444 loss: 9.45771717e-07
Iter: 445 loss: 9.42883162e-07
Iter: 446 loss: 9.42006068e-07
Iter: 447 loss: 9.41136648e-07
Iter: 448 loss: 9.41146595e-07
Iter: 449 loss: 9.39893312e-07
Iter: 450 loss: 9.43446253e-07
Iter: 451 loss: 9.39633821e-07
Iter: 452 loss: 9.38119229e-07
Iter: 453 loss: 9.41169e-07
Iter: 454 loss: 9.37626169e-07
Iter: 455 loss: 9.36546826e-07
Iter: 456 loss: 9.37245716e-07
Iter: 457 loss: 9.35673484e-07
Iter: 458 loss: 9.33982506e-07
Iter: 459 loss: 9.39275367e-07
Iter: 460 loss: 9.33105525e-07
Iter: 461 loss: 9.31282e-07
Iter: 462 loss: 9.31950581e-07
Iter: 463 loss: 9.30115789e-07
Iter: 464 loss: 9.28205907e-07
Iter: 465 loss: 9.29215105e-07
Iter: 466 loss: 9.27096607e-07
Iter: 467 loss: 9.25024437e-07
Iter: 468 loss: 9.26506971e-07
Iter: 469 loss: 9.23556627e-07
Iter: 470 loss: 9.21433411e-07
Iter: 471 loss: 9.27698693e-07
Iter: 472 loss: 9.20985826e-07
Iter: 473 loss: 9.19154331e-07
Iter: 474 loss: 9.18814749e-07
Iter: 475 loss: 9.17710736e-07
Iter: 476 loss: 9.19479589e-07
Iter: 477 loss: 9.17188743e-07
Iter: 478 loss: 9.16364229e-07
Iter: 479 loss: 9.14601742e-07
Iter: 480 loss: 9.31022e-07
Iter: 481 loss: 9.14035468e-07
Iter: 482 loss: 9.1196523e-07
Iter: 483 loss: 9.26397149e-07
Iter: 484 loss: 9.11979498e-07
Iter: 485 loss: 9.10482356e-07
Iter: 486 loss: 9.25291715e-07
Iter: 487 loss: 9.10536642e-07
Iter: 488 loss: 9.09772893e-07
Iter: 489 loss: 9.08804338e-07
Iter: 490 loss: 9.0833953e-07
Iter: 491 loss: 9.06946639e-07
Iter: 492 loss: 9.21434776e-07
Iter: 493 loss: 9.06401056e-07
Iter: 494 loss: 9.05469506e-07
Iter: 495 loss: 9.07899e-07
Iter: 496 loss: 9.04880437e-07
Iter: 497 loss: 9.03804391e-07
Iter: 498 loss: 9.10575068e-07
Iter: 499 loss: 9.03761247e-07
Iter: 500 loss: 9.02776605e-07
Iter: 501 loss: 9.05030674e-07
Iter: 502 loss: 9.02664112e-07
Iter: 503 loss: 9.01661394e-07
Iter: 504 loss: 9.00214e-07
Iter: 505 loss: 9.00181647e-07
Iter: 506 loss: 8.9870008e-07
Iter: 507 loss: 8.97815539e-07
Iter: 508 loss: 8.9706208e-07
Iter: 509 loss: 8.95071707e-07
Iter: 510 loss: 9.02791157e-07
Iter: 511 loss: 8.94721325e-07
Iter: 512 loss: 8.96932647e-07
Iter: 513 loss: 8.93865376e-07
Iter: 514 loss: 8.93826041e-07
Iter: 515 loss: 8.92670528e-07
Iter: 516 loss: 8.9504897e-07
Iter: 517 loss: 8.91943955e-07
Iter: 518 loss: 8.90488877e-07
Iter: 519 loss: 8.98474411e-07
Iter: 520 loss: 8.90323236e-07
Iter: 521 loss: 8.88498903e-07
Iter: 522 loss: 8.99861448e-07
Iter: 523 loss: 8.88053364e-07
Iter: 524 loss: 8.87437295e-07
Iter: 525 loss: 8.87114481e-07
Iter: 526 loss: 8.8638734e-07
Iter: 527 loss: 8.85155146e-07
Iter: 528 loss: 8.9030641e-07
Iter: 529 loss: 8.84768781e-07
Iter: 530 loss: 8.83298469e-07
Iter: 531 loss: 8.89157775e-07
Iter: 532 loss: 8.83115206e-07
Iter: 533 loss: 8.81706569e-07
Iter: 534 loss: 8.85377915e-07
Iter: 535 loss: 8.81635287e-07
Iter: 536 loss: 8.80096877e-07
Iter: 537 loss: 8.85645193e-07
Iter: 538 loss: 8.7985336e-07
Iter: 539 loss: 8.78589503e-07
Iter: 540 loss: 8.80190498e-07
Iter: 541 loss: 8.78035166e-07
Iter: 542 loss: 8.76833781e-07
Iter: 543 loss: 8.7629013e-07
Iter: 544 loss: 8.7561267e-07
Iter: 545 loss: 8.74006e-07
Iter: 546 loss: 8.88072918e-07
Iter: 547 loss: 8.73881277e-07
Iter: 548 loss: 8.72966041e-07
Iter: 549 loss: 8.72938301e-07
Iter: 550 loss: 8.72468e-07
Iter: 551 loss: 8.7153893e-07
Iter: 552 loss: 8.85105749e-07
Iter: 553 loss: 8.71307236e-07
Iter: 554 loss: 8.70879603e-07
Iter: 555 loss: 8.70768304e-07
Iter: 556 loss: 8.70073734e-07
Iter: 557 loss: 8.69316295e-07
Iter: 558 loss: 8.69151279e-07
Iter: 559 loss: 8.68031407e-07
Iter: 560 loss: 8.71553652e-07
Iter: 561 loss: 8.67570861e-07
Iter: 562 loss: 8.66410176e-07
Iter: 563 loss: 8.74135424e-07
Iter: 564 loss: 8.66309165e-07
Iter: 565 loss: 8.65853963e-07
Iter: 566 loss: 8.66510334e-07
Iter: 567 loss: 8.65336915e-07
Iter: 568 loss: 8.65143534e-07
Iter: 569 loss: 8.66955247e-07
Iter: 570 loss: 8.64612048e-07
Iter: 571 loss: 8.63640878e-07
Iter: 572 loss: 8.63372122e-07
Iter: 573 loss: 8.62939771e-07
Iter: 574 loss: 8.61831893e-07
Iter: 575 loss: 8.64893082e-07
Iter: 576 loss: 8.61182968e-07
Iter: 577 loss: 8.60147509e-07
Iter: 578 loss: 8.63256162e-07
Iter: 579 loss: 8.60024159e-07
Iter: 580 loss: 8.59519844e-07
Iter: 581 loss: 8.59102215e-07
Iter: 582 loss: 8.58688622e-07
Iter: 583 loss: 8.57581824e-07
Iter: 584 loss: 8.7449132e-07
Iter: 585 loss: 8.57644238e-07
Iter: 586 loss: 8.56353608e-07
Iter: 587 loss: 8.60401599e-07
Iter: 588 loss: 8.56207464e-07
Iter: 589 loss: 8.55483052e-07
Iter: 590 loss: 8.57230589e-07
Iter: 591 loss: 8.55168707e-07
Iter: 592 loss: 8.53682593e-07
Iter: 593 loss: 8.54759037e-07
Iter: 594 loss: 8.53027643e-07
Iter: 595 loss: 8.52053063e-07
Iter: 596 loss: 8.52839e-07
Iter: 597 loss: 8.51485254e-07
Iter: 598 loss: 8.50690526e-07
Iter: 599 loss: 8.52509629e-07
Iter: 600 loss: 8.50405058e-07
Iter: 601 loss: 8.49347543e-07
Iter: 602 loss: 8.56121687e-07
Iter: 603 loss: 8.49289449e-07
Iter: 604 loss: 8.48300829e-07
Iter: 605 loss: 8.4853383e-07
Iter: 606 loss: 8.4785097e-07
Iter: 607 loss: 8.47280319e-07
Iter: 608 loss: 8.46322166e-07
Iter: 609 loss: 8.46350076e-07
Iter: 610 loss: 8.45374e-07
Iter: 611 loss: 8.50806259e-07
Iter: 612 loss: 8.4505848e-07
Iter: 613 loss: 8.44383749e-07
Iter: 614 loss: 8.47022193e-07
Iter: 615 loss: 8.44136935e-07
Iter: 616 loss: 8.43606529e-07
Iter: 617 loss: 8.43605221e-07
Iter: 618 loss: 8.43138764e-07
Iter: 619 loss: 8.43207715e-07
Iter: 620 loss: 8.43011946e-07
Iter: 621 loss: 8.42317377e-07
Iter: 622 loss: 8.42162422e-07
Iter: 623 loss: 8.41852e-07
Iter: 624 loss: 8.41072e-07
Iter: 625 loss: 8.41082681e-07
Iter: 626 loss: 8.40737528e-07
Iter: 627 loss: 8.40237249e-07
Iter: 628 loss: 8.40243388e-07
Iter: 629 loss: 8.39333e-07
Iter: 630 loss: 8.3858987e-07
Iter: 631 loss: 8.38501535e-07
Iter: 632 loss: 8.37335676e-07
Iter: 633 loss: 8.44827412e-07
Iter: 634 loss: 8.37104267e-07
Iter: 635 loss: 8.36163224e-07
Iter: 636 loss: 8.40285793e-07
Iter: 637 loss: 8.35637366e-07
Iter: 638 loss: 8.34945581e-07
Iter: 639 loss: 8.3391717e-07
Iter: 640 loss: 8.33874196e-07
Iter: 641 loss: 8.32367618e-07
Iter: 642 loss: 8.33377101e-07
Iter: 643 loss: 8.31613647e-07
Iter: 644 loss: 8.31009856e-07
Iter: 645 loss: 8.30840577e-07
Iter: 646 loss: 8.30475415e-07
Iter: 647 loss: 8.32698902e-07
Iter: 648 loss: 8.30122417e-07
Iter: 649 loss: 8.29484748e-07
Iter: 650 loss: 8.31331477e-07
Iter: 651 loss: 8.292742e-07
Iter: 652 loss: 8.2867939e-07
Iter: 653 loss: 8.28614645e-07
Iter: 654 loss: 8.28192469e-07
Iter: 655 loss: 8.27722488e-07
Iter: 656 loss: 8.2708334e-07
Iter: 657 loss: 8.27000804e-07
Iter: 658 loss: 8.26909172e-07
Iter: 659 loss: 8.26087387e-07
Iter: 660 loss: 8.25933398e-07
Iter: 661 loss: 8.25236953e-07
Iter: 662 loss: 8.43695318e-07
Iter: 663 loss: 8.25132588e-07
Iter: 664 loss: 8.24166932e-07
Iter: 665 loss: 8.24632139e-07
Iter: 666 loss: 8.2354444e-07
Iter: 667 loss: 8.2258839e-07
Iter: 668 loss: 8.28763859e-07
Iter: 669 loss: 8.22558036e-07
Iter: 670 loss: 8.21799517e-07
Iter: 671 loss: 8.23647554e-07
Iter: 672 loss: 8.21906e-07
Iter: 673 loss: 8.21218691e-07
Iter: 674 loss: 8.20808168e-07
Iter: 675 loss: 8.20711875e-07
Iter: 676 loss: 8.19760317e-07
Iter: 677 loss: 8.231371e-07
Iter: 678 loss: 8.19639808e-07
Iter: 679 loss: 8.19075638e-07
Iter: 680 loss: 8.19420848e-07
Iter: 681 loss: 8.18675403e-07
Iter: 682 loss: 8.18804779e-07
Iter: 683 loss: 8.1847088e-07
Iter: 684 loss: 8.17864645e-07
Iter: 685 loss: 8.17240675e-07
Iter: 686 loss: 8.29302508e-07
Iter: 687 loss: 8.17675641e-07
Iter: 688 loss: 8.16782688e-07
Iter: 689 loss: 8.1587757e-07
Iter: 690 loss: 8.16018883e-07
Iter: 691 loss: 8.15253031e-07
Iter: 692 loss: 8.19113552e-07
Iter: 693 loss: 8.14869281e-07
Iter: 694 loss: 8.14232067e-07
Iter: 695 loss: 8.23717073e-07
Iter: 696 loss: 8.1430278e-07
Iter: 697 loss: 8.13413521e-07
Iter: 698 loss: 8.12245901e-07
Iter: 699 loss: 8.12322412e-07
Iter: 700 loss: 8.11597261e-07
Iter: 701 loss: 8.15703345e-07
Iter: 702 loss: 8.11138307e-07
Iter: 703 loss: 8.09941866e-07
Iter: 704 loss: 8.18558192e-07
Iter: 705 loss: 8.1014e-07
Iter: 706 loss: 8.09472851e-07
Iter: 707 loss: 8.09875473e-07
Iter: 708 loss: 8.08767254e-07
Iter: 709 loss: 8.08360824e-07
Iter: 710 loss: 8.08850359e-07
Iter: 711 loss: 8.07758568e-07
Iter: 712 loss: 8.07247716e-07
Iter: 713 loss: 8.09400092e-07
Iter: 714 loss: 8.07004426e-07
Iter: 715 loss: 8.05935485e-07
Iter: 716 loss: 8.11287e-07
Iter: 717 loss: 8.0588552e-07
Iter: 718 loss: 8.04941919e-07
Iter: 719 loss: 8.13976158e-07
Iter: 720 loss: 8.04948058e-07
Iter: 721 loss: 8.04402362e-07
Iter: 722 loss: 8.03839328e-07
Iter: 723 loss: 8.09763264e-07
Iter: 724 loss: 8.03956766e-07
Iter: 725 loss: 8.02798e-07
Iter: 726 loss: 8.10716188e-07
Iter: 727 loss: 8.02893965e-07
Iter: 728 loss: 8.02516468e-07
Iter: 729 loss: 8.02633622e-07
Iter: 730 loss: 8.0181519e-07
Iter: 731 loss: 8.01545752e-07
Iter: 732 loss: 8.07653237e-07
Iter: 733 loss: 8.01214469e-07
Iter: 734 loss: 8.00756482e-07
Iter: 735 loss: 8.01602937e-07
Iter: 736 loss: 8.00506768e-07
Iter: 737 loss: 8.00068733e-07
Iter: 738 loss: 7.98698579e-07
Iter: 739 loss: 7.98726774e-07
Iter: 740 loss: 7.97438474e-07
Iter: 741 loss: 7.97434268e-07
Iter: 742 loss: 7.96305926e-07
Iter: 743 loss: 8.04751437e-07
Iter: 744 loss: 7.96080769e-07
Iter: 745 loss: 7.9566928e-07
Iter: 746 loss: 7.96119934e-07
Iter: 747 loss: 7.95466235e-07
Iter: 748 loss: 7.94967775e-07
Iter: 749 loss: 7.95189123e-07
Iter: 750 loss: 7.9471522e-07
Iter: 751 loss: 7.94972152e-07
Iter: 752 loss: 7.94199366e-07
Iter: 753 loss: 7.94137918e-07
Iter: 754 loss: 7.93648439e-07
Iter: 755 loss: 8.00224143e-07
Iter: 756 loss: 7.93622917e-07
Iter: 757 loss: 7.9267528e-07
Iter: 758 loss: 7.96011818e-07
Iter: 759 loss: 7.92742355e-07
Iter: 760 loss: 7.9199981e-07
Iter: 761 loss: 7.97261123e-07
Iter: 762 loss: 7.92114747e-07
Iter: 763 loss: 7.91693651e-07
Iter: 764 loss: 7.91262721e-07
Iter: 765 loss: 7.91114303e-07
Iter: 766 loss: 7.90486297e-07
Iter: 767 loss: 7.93954882e-07
Iter: 768 loss: 7.90529953e-07
Iter: 769 loss: 7.89985336e-07
Iter: 770 loss: 7.89194701e-07
Iter: 771 loss: 7.89143826e-07
Iter: 772 loss: 7.88549301e-07
Iter: 773 loss: 7.93559252e-07
Iter: 774 loss: 7.88353873e-07
Iter: 775 loss: 7.87965575e-07
Iter: 776 loss: 7.88218472e-07
Iter: 777 loss: 7.87644922e-07
Iter: 778 loss: 7.87809768e-07
Iter: 779 loss: 7.87536408e-07
Iter: 780 loss: 7.87090755e-07
Iter: 781 loss: 7.87412546e-07
Iter: 782 loss: 7.86944838e-07
Iter: 783 loss: 7.86374812e-07
Iter: 784 loss: 7.86464966e-07
Iter: 785 loss: 7.85945872e-07
Iter: 786 loss: 7.85073439e-07
Iter: 787 loss: 7.93308e-07
Iter: 788 loss: 7.85021371e-07
Iter: 789 loss: 7.84682527e-07
Iter: 790 loss: 7.84366193e-07
Iter: 791 loss: 7.84402573e-07
Iter: 792 loss: 7.83971927e-07
Iter: 793 loss: 7.83081589e-07
Iter: 794 loss: 7.83110863e-07
Iter: 795 loss: 7.82596544e-07
Iter: 796 loss: 7.85254201e-07
Iter: 797 loss: 7.82414361e-07
Iter: 798 loss: 7.81988604e-07
Iter: 799 loss: 7.87174145e-07
Iter: 800 loss: 7.82389407e-07
Iter: 801 loss: 7.81664482e-07
Iter: 802 loss: 7.81184212e-07
Iter: 803 loss: 7.81015217e-07
Iter: 804 loss: 7.80566097e-07
Iter: 805 loss: 7.82873542e-07
Iter: 806 loss: 7.80418077e-07
Iter: 807 loss: 7.79870788e-07
Iter: 808 loss: 7.80629364e-07
Iter: 809 loss: 7.79457309e-07
Iter: 810 loss: 7.79186735e-07
Iter: 811 loss: 7.8387643e-07
Iter: 812 loss: 7.79156721e-07
Iter: 813 loss: 7.78604885e-07
Iter: 814 loss: 7.78803951e-07
Iter: 815 loss: 7.78264678e-07
Iter: 816 loss: 7.77562661e-07
Iter: 817 loss: 7.76781121e-07
Iter: 818 loss: 7.76928e-07
Iter: 819 loss: 7.77320906e-07
Iter: 820 loss: 7.76424827e-07
Iter: 821 loss: 7.76168918e-07
Iter: 822 loss: 7.75089575e-07
Iter: 823 loss: 7.85690304e-07
Iter: 824 loss: 7.75093e-07
Iter: 825 loss: 7.74362718e-07
Iter: 826 loss: 7.75023807e-07
Iter: 827 loss: 7.74207592e-07
Iter: 828 loss: 7.73247336e-07
Iter: 829 loss: 7.73176396e-07
Iter: 830 loss: 7.72522867e-07
Iter: 831 loss: 7.72193289e-07
Iter: 832 loss: 7.7204345e-07
Iter: 833 loss: 7.71746727e-07
Iter: 834 loss: 7.71715804e-07
Iter: 835 loss: 7.71483599e-07
Iter: 836 loss: 7.71011173e-07
Iter: 837 loss: 7.70439897e-07
Iter: 838 loss: 7.70292104e-07
Iter: 839 loss: 7.69628912e-07
Iter: 840 loss: 7.70593715e-07
Iter: 841 loss: 7.69251869e-07
Iter: 842 loss: 7.68814061e-07
Iter: 843 loss: 7.71089617e-07
Iter: 844 loss: 7.68671384e-07
Iter: 845 loss: 7.6805577e-07
Iter: 846 loss: 7.6945588e-07
Iter: 847 loss: 7.68348514e-07
Iter: 848 loss: 7.67794802e-07
Iter: 849 loss: 7.67320557e-07
Iter: 850 loss: 7.66957555e-07
Iter: 851 loss: 7.66691301e-07
Iter: 852 loss: 7.71924306e-07
Iter: 853 loss: 7.66760365e-07
Iter: 854 loss: 7.66175845e-07
Iter: 855 loss: 7.6940978e-07
Iter: 856 loss: 7.66096264e-07
Iter: 857 loss: 7.65824495e-07
Iter: 858 loss: 7.65706659e-07
Iter: 859 loss: 7.65753327e-07
Iter: 860 loss: 7.65357697e-07
Iter: 861 loss: 7.67255642e-07
Iter: 862 loss: 7.64977472e-07
Iter: 863 loss: 7.64480035e-07
Iter: 864 loss: 7.65491e-07
Iter: 865 loss: 7.64190759e-07
Iter: 866 loss: 7.64036713e-07
Iter: 867 loss: 7.67833058e-07
Iter: 868 loss: 7.64136644e-07
Iter: 869 loss: 7.6379763e-07
Iter: 870 loss: 7.63673484e-07
Iter: 871 loss: 7.63684625e-07
Iter: 872 loss: 7.63214302e-07
Iter: 873 loss: 7.63534558e-07
Iter: 874 loss: 7.63182129e-07
Iter: 875 loss: 7.62592322e-07
Iter: 876 loss: 7.63793082e-07
Iter: 877 loss: 7.62320042e-07
Iter: 878 loss: 7.62168838e-07
Iter: 879 loss: 7.6863e-07
Iter: 880 loss: 7.62132174e-07
Iter: 881 loss: 7.61681406e-07
Iter: 882 loss: 7.61285719e-07
Iter: 883 loss: 7.68471068e-07
Iter: 884 loss: 7.60985188e-07
Iter: 885 loss: 7.60791636e-07
Iter: 886 loss: 7.60766795e-07
Iter: 887 loss: 7.60403509e-07
Iter: 888 loss: 7.62997161e-07
Iter: 889 loss: 7.60361559e-07
Iter: 890 loss: 7.5999742e-07
Iter: 891 loss: 7.59853e-07
Iter: 892 loss: 7.59860029e-07
Iter: 893 loss: 7.59223497e-07
Iter: 894 loss: 7.61659e-07
Iter: 895 loss: 7.5941e-07
Iter: 896 loss: 7.58697524e-07
Iter: 897 loss: 7.58846795e-07
Iter: 898 loss: 7.58390911e-07
Iter: 899 loss: 7.58039846e-07
Iter: 900 loss: 7.58070257e-07
Iter: 901 loss: 7.5764882e-07
Iter: 902 loss: 7.57574071e-07
Iter: 903 loss: 7.63567471e-07
Iter: 904 loss: 7.57407292e-07
Iter: 905 loss: 7.57035878e-07
Iter: 906 loss: 7.59000386e-07
Iter: 907 loss: 7.56625127e-07
Iter: 908 loss: 7.56170152e-07
Iter: 909 loss: 7.5814512e-07
Iter: 910 loss: 7.56093868e-07
Iter: 911 loss: 7.55593e-07
Iter: 912 loss: 7.55584722e-07
Iter: 913 loss: 7.55532596e-07
Iter: 914 loss: 7.55626161e-07
Iter: 915 loss: 7.55327108e-07
Iter: 916 loss: 7.54945745e-07
Iter: 917 loss: 7.54340647e-07
Iter: 918 loss: 7.64356685e-07
Iter: 919 loss: 7.54246628e-07
Iter: 920 loss: 7.53363e-07
Iter: 921 loss: 7.5499463e-07
Iter: 922 loss: 7.52890855e-07
Iter: 923 loss: 7.52233461e-07
Iter: 924 loss: 7.56207669e-07
Iter: 925 loss: 7.52323956e-07
Iter: 926 loss: 7.51714651e-07
Iter: 927 loss: 7.51958169e-07
Iter: 928 loss: 7.51290258e-07
Iter: 929 loss: 7.50748029e-07
Iter: 930 loss: 7.58270232e-07
Iter: 931 loss: 7.50805725e-07
Iter: 932 loss: 7.50417257e-07
Iter: 933 loss: 7.53911763e-07
Iter: 934 loss: 7.50387073e-07
Iter: 935 loss: 7.49991273e-07
Iter: 936 loss: 7.50171182e-07
Iter: 937 loss: 7.4992488e-07
Iter: 938 loss: 7.49622359e-07
Iter: 939 loss: 7.49101844e-07
Iter: 940 loss: 7.49118044e-07
Iter: 941 loss: 7.48616117e-07
Iter: 942 loss: 7.49519245e-07
Iter: 943 loss: 7.48337754e-07
Iter: 944 loss: 7.47781257e-07
Iter: 945 loss: 7.48395337e-07
Iter: 946 loss: 7.47413594e-07
Iter: 947 loss: 7.46953901e-07
Iter: 948 loss: 7.48701098e-07
Iter: 949 loss: 7.46625403e-07
Iter: 950 loss: 7.46068736e-07
Iter: 951 loss: 7.46281273e-07
Iter: 952 loss: 7.45822945e-07
Iter: 953 loss: 7.46671788e-07
Iter: 954 loss: 7.45983243e-07
Iter: 955 loss: 7.45597276e-07
Iter: 956 loss: 7.45830732e-07
Iter: 957 loss: 7.45576926e-07
Iter: 958 loss: 7.45047316e-07
Iter: 959 loss: 7.44745762e-07
Iter: 960 loss: 7.44614e-07
Iter: 961 loss: 7.43922442e-07
Iter: 962 loss: 7.46973399e-07
Iter: 963 loss: 7.43966e-07
Iter: 964 loss: 7.43853661e-07
Iter: 965 loss: 7.46806336e-07
Iter: 966 loss: 7.43889188e-07
Iter: 967 loss: 7.43646638e-07
Iter: 968 loss: 7.43306828e-07
Iter: 969 loss: 7.43267606e-07
Iter: 970 loss: 7.42801944e-07
Iter: 971 loss: 7.43576379e-07
Iter: 972 loss: 7.42648581e-07
Iter: 973 loss: 7.41859708e-07
Iter: 974 loss: 7.44518957e-07
Iter: 975 loss: 7.41601468e-07
Iter: 976 loss: 7.41279791e-07
Iter: 977 loss: 7.4096846e-07
Iter: 978 loss: 7.40752853e-07
Iter: 979 loss: 7.40226653e-07
Iter: 980 loss: 7.43711439e-07
Iter: 981 loss: 7.40403493e-07
Iter: 982 loss: 7.39925e-07
Iter: 983 loss: 7.44378212e-07
Iter: 984 loss: 7.3963588e-07
Iter: 985 loss: 7.39374457e-07
Iter: 986 loss: 7.42676377e-07
Iter: 987 loss: 7.39555105e-07
Iter: 988 loss: 7.3929948e-07
Iter: 989 loss: 7.39287032e-07
Iter: 990 loss: 7.39054599e-07
Iter: 991 loss: 7.38845927e-07
Iter: 992 loss: 7.3917704e-07
Iter: 993 loss: 7.38746849e-07
Iter: 994 loss: 7.3849958e-07
Iter: 995 loss: 7.38919482e-07
Iter: 996 loss: 7.38439496e-07
Iter: 997 loss: 7.38079393e-07
Iter: 998 loss: 7.40090627e-07
Iter: 999 loss: 7.38008112e-07
Iter: 1000 loss: 7.37832124e-07
Iter: 1001 loss: 7.38331096e-07
Iter: 1002 loss: 7.37510732e-07
Iter: 1003 loss: 7.37498567e-07
Iter: 1004 loss: 7.37250048e-07
Iter: 1005 loss: 7.36901939e-07
Iter: 1006 loss: 7.36599645e-07
Iter: 1007 loss: 7.39923166e-07
Iter: 1008 loss: 7.36814798e-07
Iter: 1009 loss: 7.36633467e-07
Iter: 1010 loss: 7.37186213e-07
Iter: 1011 loss: 7.36033314e-07
Iter: 1012 loss: 7.35659683e-07
Iter: 1013 loss: 7.35409344e-07
Iter: 1014 loss: 7.3544436e-07
Iter: 1015 loss: 7.34985463e-07
Iter: 1016 loss: 7.39933739e-07
Iter: 1017 loss: 7.35061633e-07
Iter: 1018 loss: 7.34812829e-07
Iter: 1019 loss: 7.34910941e-07
Iter: 1020 loss: 7.34839887e-07
Iter: 1021 loss: 7.34525088e-07
Iter: 1022 loss: 7.34427886e-07
Iter: 1023 loss: 7.34307662e-07
Iter: 1024 loss: 7.33685965e-07
Iter: 1025 loss: 7.33938919e-07
Iter: 1026 loss: 7.33475474e-07
Iter: 1027 loss: 7.33071204e-07
Iter: 1028 loss: 7.4482864e-07
Iter: 1029 loss: 7.3326305e-07
Iter: 1030 loss: 7.32718604e-07
Iter: 1031 loss: 7.32597812e-07
Iter: 1032 loss: 7.32420574e-07
Iter: 1033 loss: 7.32801482e-07
Iter: 1034 loss: 7.32507374e-07
Iter: 1035 loss: 7.32012836e-07
Iter: 1036 loss: 7.31504144e-07
Iter: 1037 loss: 7.4485439e-07
Iter: 1038 loss: 7.31515343e-07
Iter: 1039 loss: 7.31035357e-07
Iter: 1040 loss: 7.34558341e-07
Iter: 1041 loss: 7.30876252e-07
Iter: 1042 loss: 7.30506827e-07
Iter: 1043 loss: 7.35118078e-07
Iter: 1044 loss: 7.30535589e-07
Iter: 1045 loss: 7.30268084e-07
Iter: 1046 loss: 7.30125294e-07
Iter: 1047 loss: 7.30091642e-07
Iter: 1048 loss: 7.29468525e-07
Iter: 1049 loss: 7.31994362e-07
Iter: 1050 loss: 7.29366377e-07
Iter: 1051 loss: 7.29258318e-07
Iter: 1052 loss: 7.29278e-07
Iter: 1053 loss: 7.29324199e-07
Iter: 1054 loss: 7.29109104e-07
Iter: 1055 loss: 7.29148837e-07
Iter: 1056 loss: 7.29001499e-07
Iter: 1057 loss: 7.2927196e-07
Iter: 1058 loss: 7.29231488e-07
Iter: 1059 loss: 7.29299472e-07
Iter: 1060 loss: 7.2925809e-07
Iter: 1061 loss: 7.29178282e-07
Iter: 1062 loss: 7.29251894e-07
Iter: 1063 loss: 7.29391274e-07
Iter: 1064 loss: 7.29273665e-07
Iter: 1065 loss: 7.29369276e-07
Iter: 1066 loss: 7.29251269e-07
Iter: 1067 loss: 7.29350802e-07
Iter: 1068 loss: 7.29281226e-07
Iter: 1069 loss: 7.29261501e-07
Iter: 1070 loss: 7.2927844e-07
Iter: 1071 loss: 7.29274177e-07
Iter: 1072 loss: 7.29265651e-07
Iter: 1073 loss: 7.29268095e-07
Iter: 1074 loss: 7.29270369e-07
Iter: 1075 loss: 7.29270369e-07
Iter: 1076 loss: 7.29270596e-07
Iter: 1077 loss: 7.29281226e-07
Iter: 1078 loss: 7.29270596e-07
Iter: 1079 loss: 7.28584837e-07
Iter: 1080 loss: 7.29484e-07
Iter: 1081 loss: 7.28747352e-07
Iter: 1082 loss: 7.28414079e-07
Iter: 1083 loss: 7.28273108e-07
Iter: 1084 loss: 7.2814845e-07
Iter: 1085 loss: 7.27700751e-07
Iter: 1086 loss: 7.284047e-07
Iter: 1087 loss: 7.27623046e-07
Iter: 1088 loss: 7.27224176e-07
Iter: 1089 loss: 7.29249678e-07
Iter: 1090 loss: 7.27699899e-07
Iter: 1091 loss: 7.27407667e-07
Iter: 1092 loss: 7.27484121e-07
Iter: 1093 loss: 7.27408064e-07
Iter: 1094 loss: 7.27437509e-07
Iter: 1095 loss: 7.27558358e-07
Iter: 1096 loss: 7.27244696e-07
Iter: 1097 loss: 7.2749e-07
Iter: 1098 loss: 7.27232532e-07
Iter: 1099 loss: 7.26952294e-07
Iter: 1100 loss: 7.27006409e-07
Iter: 1101 loss: 7.26539497e-07
Iter: 1102 loss: 7.26498683e-07
Iter: 1103 loss: 7.26485837e-07
Iter: 1104 loss: 7.26338044e-07
Iter: 1105 loss: 7.2590052e-07
Iter: 1106 loss: 7.26112034e-07
Iter: 1107 loss: 7.25457539e-07
Iter: 1108 loss: 7.25150073e-07
Iter: 1109 loss: 7.26944677e-07
Iter: 1110 loss: 7.24925485e-07
Iter: 1111 loss: 7.2461404e-07
Iter: 1112 loss: 7.25966345e-07
Iter: 1113 loss: 7.24668382e-07
Iter: 1114 loss: 7.24733809e-07
Iter: 1115 loss: 7.24444e-07
Iter: 1116 loss: 7.24708684e-07
Iter: 1117 loss: 7.24604263e-07
Iter: 1118 loss: 7.2470516e-07
Iter: 1119 loss: 7.2463024e-07
Iter: 1120 loss: 7.24795768e-07
Iter: 1121 loss: 7.24693336e-07
Iter: 1122 loss: 7.24705899e-07
Iter: 1123 loss: 7.24831e-07
Iter: 1124 loss: 7.24621827e-07
Iter: 1125 loss: 7.24756e-07
Iter: 1126 loss: 7.24650761e-07
Iter: 1127 loss: 7.24654342e-07
Iter: 1128 loss: 7.24733e-07
Iter: 1129 loss: 7.24707775e-07
Iter: 1130 loss: 7.24693678e-07
Iter: 1131 loss: 7.24689869e-07
Iter: 1132 loss: 7.24656275e-07
Iter: 1133 loss: 7.24662414e-07
Iter: 1134 loss: 7.24680717e-07
Iter: 1135 loss: 7.24662186e-07
Iter: 1136 loss: 7.24661561e-07
Iter: 1137 loss: 7.24661447e-07
Iter: 1138 loss: 7.24680717e-07
Iter: 1139 loss: 7.24661447e-07
Iter: 1140 loss: 7.23799701e-07
Iter: 1141 loss: 7.32268347e-07
Iter: 1142 loss: 7.23981316e-07
Iter: 1143 loss: 7.23315907e-07
Iter: 1144 loss: 7.23548908e-07
Iter: 1145 loss: 7.23113544e-07
Iter: 1146 loss: 7.23028734e-07
Iter: 1147 loss: 7.22895209e-07
Iter: 1148 loss: 7.22666641e-07
Iter: 1149 loss: 7.23167204e-07
Iter: 1150 loss: 7.22601499e-07
Iter: 1151 loss: 7.22284085e-07
Iter: 1152 loss: 7.22880657e-07
Iter: 1153 loss: 7.22127083e-07
Iter: 1154 loss: 7.21830588e-07
Iter: 1155 loss: 7.22630602e-07
Iter: 1156 loss: 7.21615152e-07
Iter: 1157 loss: 7.2128978e-07
Iter: 1158 loss: 7.22280618e-07
Iter: 1159 loss: 7.21042454e-07
Iter: 1160 loss: 7.20732658e-07
Iter: 1161 loss: 7.23010487e-07
Iter: 1162 loss: 7.20483968e-07
Iter: 1163 loss: 7.20202934e-07
Iter: 1164 loss: 7.20461628e-07
Iter: 1165 loss: 7.20255457e-07
Iter: 1166 loss: 7.19973855e-07
Iter: 1167 loss: 7.20600099e-07
Iter: 1168 loss: 7.19651894e-07
Iter: 1169 loss: 7.19490515e-07
Iter: 1170 loss: 7.21933247e-07
Iter: 1171 loss: 7.19561285e-07
Iter: 1172 loss: 7.19507625e-07
Iter: 1173 loss: 7.19191917e-07
Iter: 1174 loss: 7.19203399e-07
Iter: 1175 loss: 7.1902042e-07
Iter: 1176 loss: 7.18669241e-07
Iter: 1177 loss: 7.18503088e-07
Iter: 1178 loss: 7.18046181e-07
Iter: 1179 loss: 7.20769094e-07
Iter: 1180 loss: 7.18098136e-07
Iter: 1181 loss: 7.17909359e-07
Iter: 1182 loss: 7.18155093e-07
Iter: 1183 loss: 7.17635e-07
Iter: 1184 loss: 7.17186708e-07
Iter: 1185 loss: 7.20509092e-07
Iter: 1186 loss: 7.17237128e-07
Iter: 1187 loss: 7.16926e-07
Iter: 1188 loss: 7.17126341e-07
Iter: 1189 loss: 7.16735371e-07
Iter: 1190 loss: 7.1666858e-07
Iter: 1191 loss: 7.16526415e-07
Iter: 1192 loss: 7.16164209e-07
Iter: 1193 loss: 7.159083e-07
Iter: 1194 loss: 7.1667813e-07
Iter: 1195 loss: 7.1574874e-07
Iter: 1196 loss: 7.15448778e-07
Iter: 1197 loss: 7.18830506e-07
Iter: 1198 loss: 7.15554961e-07
Iter: 1199 loss: 7.1535186e-07
Iter: 1200 loss: 7.15423539e-07
Iter: 1201 loss: 7.15183944e-07
Iter: 1202 loss: 7.15260853e-07
Iter: 1203 loss: 7.15190197e-07
Iter: 1204 loss: 7.15032456e-07
Iter: 1205 loss: 7.14806674e-07
Iter: 1206 loss: 7.14688326e-07
Iter: 1207 loss: 7.1438e-07
Iter: 1208 loss: 7.14546e-07
Iter: 1209 loss: 7.14268197e-07
Iter: 1210 loss: 7.13945042e-07
Iter: 1211 loss: 7.1438e-07
Iter: 1212 loss: 7.1376985e-07
Iter: 1213 loss: 7.13334941e-07
Iter: 1214 loss: 7.15117608e-07
Iter: 1215 loss: 7.1343095e-07
Iter: 1216 loss: 7.13077213e-07
Iter: 1217 loss: 7.14163264e-07
Iter: 1218 loss: 7.13162763e-07
Iter: 1219 loss: 7.12974042e-07
Iter: 1220 loss: 7.14157466e-07
Iter: 1221 loss: 7.12751898e-07
Iter: 1222 loss: 7.12567896e-07
Iter: 1223 loss: 7.13200848e-07
Iter: 1224 loss: 7.12598307e-07
Iter: 1225 loss: 7.12229507e-07
Iter: 1226 loss: 7.13056e-07
Iter: 1227 loss: 7.11985081e-07
Iter: 1228 loss: 7.11831944e-07
Iter: 1229 loss: 7.12652479e-07
Iter: 1230 loss: 7.11675341e-07
Iter: 1231 loss: 7.11386122e-07
Iter: 1232 loss: 7.11814437e-07
Iter: 1233 loss: 7.11567964e-07
Iter: 1234 loss: 7.11616167e-07
Iter: 1235 loss: 7.11507198e-07
Iter: 1236 loss: 7.11396297e-07
Iter: 1237 loss: 7.11457687e-07
Iter: 1238 loss: 7.11342864e-07
Iter: 1239 loss: 7.11422103e-07
Iter: 1240 loss: 7.11479629e-07
Iter: 1241 loss: 7.11419602e-07
Iter: 1242 loss: 7.11552843e-07
Iter: 1243 loss: 7.11481448e-07
Iter: 1244 loss: 7.11586608e-07
Iter: 1245 loss: 7.11585358e-07
Iter: 1246 loss: 7.11520784e-07
Iter: 1247 loss: 7.11516e-07
Iter: 1248 loss: 7.11578537e-07
Iter: 1249 loss: 7.11567282e-07
Iter: 1250 loss: 7.11553866e-07
Iter: 1251 loss: 7.11554662e-07
Iter: 1252 loss: 7.11565576e-07
Iter: 1253 loss: 7.11580753e-07
Iter: 1254 loss: 7.11568589e-07
Iter: 1255 loss: 7.11570465e-07
Iter: 1256 loss: 7.11568475e-07
Iter: 1257 loss: 7.11568475e-07
Iter: 1258 loss: 7.1157092e-07
Iter: 1259 loss: 7.11568475e-07
Iter: 1260 loss: 7.11179382e-07
Iter: 1261 loss: 7.11972632e-07
Iter: 1262 loss: 7.11165683e-07
Iter: 1263 loss: 7.10739585e-07
Iter: 1264 loss: 7.10935808e-07
Iter: 1265 loss: 7.10661197e-07
Iter: 1266 loss: 7.10149948e-07
Iter: 1267 loss: 7.12962333e-07
Iter: 1268 loss: 7.10166887e-07
Iter: 1269 loss: 7.1001682e-07
Iter: 1270 loss: 7.09890742e-07
Iter: 1271 loss: 7.09671554e-07
Iter: 1272 loss: 7.09503297e-07
Iter: 1273 loss: 7.0922772e-07
Iter: 1274 loss: 7.09037181e-07
Iter: 1275 loss: 7.08927359e-07
Iter: 1276 loss: 7.09855783e-07
Iter: 1277 loss: 7.08727157e-07
Iter: 1278 loss: 7.08383936e-07
Iter: 1279 loss: 7.13155373e-07
Iter: 1280 loss: 7.08376888e-07
Iter: 1281 loss: 7.08241089e-07
Iter: 1282 loss: 7.08020195e-07
Iter: 1283 loss: 7.08142124e-07
Iter: 1284 loss: 7.07858817e-07
Iter: 1285 loss: 7.07692948e-07
Iter: 1286 loss: 7.0749843e-07
Iter: 1287 loss: 7.07283334e-07
Iter: 1288 loss: 7.08312086e-07
Iter: 1289 loss: 7.07286e-07
Iter: 1290 loss: 7.06934713e-07
Iter: 1291 loss: 7.06936817e-07
Iter: 1292 loss: 7.07049423e-07
Iter: 1293 loss: 7.06855e-07
Iter: 1294 loss: 7.07097115e-07
Iter: 1295 loss: 7.07029699e-07
Iter: 1296 loss: 7.06941819e-07
Iter: 1297 loss: 7.06987294e-07
Iter: 1298 loss: 7.06974333e-07
Iter: 1299 loss: 7.07006848e-07
Iter: 1300 loss: 7.07018273e-07
Iter: 1301 loss: 7.06969729e-07
Iter: 1302 loss: 7.06990818e-07
Iter: 1303 loss: 7.06982803e-07
Iter: 1304 loss: 7.06881e-07
Iter: 1305 loss: 7.06923743e-07
Iter: 1306 loss: 7.06927722e-07
Iter: 1307 loss: 7.06941819e-07
Iter: 1308 loss: 7.06935e-07
Iter: 1309 loss: 7.06944149e-07
Iter: 1310 loss: 7.06943467e-07
Iter: 1311 loss: 7.06936419e-07
Iter: 1312 loss: 7.06942956e-07
Iter: 1313 loss: 7.06942956e-07
Iter: 1314 loss: 7.06943354e-07
Iter: 1315 loss: 7.06943354e-07
Iter: 1316 loss: 7.06936419e-07
Iter: 1317 loss: 7.06943354e-07
Iter: 1318 loss: 7.06482865e-07
Iter: 1319 loss: 7.06412379e-07
Iter: 1320 loss: 7.06177843e-07
Iter: 1321 loss: 7.06622529e-07
Iter: 1322 loss: 7.0604176e-07
Iter: 1323 loss: 7.05810407e-07
Iter: 1324 loss: 7.06998264e-07
Iter: 1325 loss: 7.05741172e-07
Iter: 1326 loss: 7.05462753e-07
Iter: 1327 loss: 7.06911919e-07
Iter: 1328 loss: 7.0568575e-07
Iter: 1329 loss: 7.05258572e-07
Iter: 1330 loss: 7.05579396e-07
Iter: 1331 loss: 7.05067748e-07
Iter: 1332 loss: 7.04756872e-07
Iter: 1333 loss: 7.05751e-07
Iter: 1334 loss: 7.04615161e-07
Iter: 1335 loss: 7.04440595e-07
Iter: 1336 loss: 7.07057552e-07
Iter: 1337 loss: 7.04375566e-07
Iter: 1338 loss: 7.04156264e-07
Iter: 1339 loss: 7.03925139e-07
Iter: 1340 loss: 7.03933665e-07
Iter: 1341 loss: 7.03267744e-07
Iter: 1342 loss: 7.0551431e-07
Iter: 1343 loss: 7.03276157e-07
Iter: 1344 loss: 7.03985165e-07
Iter: 1345 loss: 7.02874559e-07
Iter: 1346 loss: 7.02818e-07
Iter: 1347 loss: 7.02667e-07
Iter: 1348 loss: 7.06558865e-07
Iter: 1349 loss: 7.02496948e-07
Iter: 1350 loss: 7.02100692e-07
Iter: 1351 loss: 7.01917884e-07
Iter: 1352 loss: 7.01879628e-07
Iter: 1353 loss: 7.01769238e-07
Iter: 1354 loss: 7.0177e-07
Iter: 1355 loss: 7.01371846e-07
Iter: 1356 loss: 7.01165561e-07
Iter: 1357 loss: 7.0114254e-07
Iter: 1358 loss: 7.00934493e-07
Iter: 1359 loss: 7.00582405e-07
Iter: 1360 loss: 7.02718e-07
Iter: 1361 loss: 7.00563533e-07
Iter: 1362 loss: 7.00038299e-07
Iter: 1363 loss: 7.02511272e-07
Iter: 1364 loss: 7.00242e-07
Iter: 1365 loss: 7.00024657e-07
Iter: 1366 loss: 7.02153386e-07
Iter: 1367 loss: 6.99931604e-07
Iter: 1368 loss: 6.9984327e-07
Iter: 1369 loss: 6.99716168e-07
Iter: 1370 loss: 6.99620443e-07
Iter: 1371 loss: 6.99318718e-07
Iter: 1372 loss: 6.99908469e-07
Iter: 1373 loss: 6.99490215e-07
Iter: 1374 loss: 6.99002953e-07
Iter: 1375 loss: 6.99370958e-07
Iter: 1376 loss: 6.98727376e-07
Iter: 1377 loss: 6.98493409e-07
Iter: 1378 loss: 6.98495455e-07
Iter: 1379 loss: 6.98249835e-07
Iter: 1380 loss: 6.98949407e-07
Iter: 1381 loss: 6.98468227e-07
Iter: 1382 loss: 6.98255e-07
Iter: 1383 loss: 6.98481244e-07
Iter: 1384 loss: 6.98011263e-07
Iter: 1385 loss: 6.97787073e-07
Iter: 1386 loss: 6.994415e-07
Iter: 1387 loss: 6.97798384e-07
Iter: 1388 loss: 6.97597557e-07
Iter: 1389 loss: 6.9784403e-07
Iter: 1390 loss: 6.97517862e-07
Iter: 1391 loss: 6.972449e-07
Iter: 1392 loss: 6.97029179e-07
Iter: 1393 loss: 6.97058681e-07
Iter: 1394 loss: 6.96881557e-07
Iter: 1395 loss: 6.96743143e-07
Iter: 1396 loss: 6.96381733e-07
Iter: 1397 loss: 6.96330289e-07
Iter: 1398 loss: 6.96167717e-07
Iter: 1399 loss: 6.96123607e-07
Iter: 1400 loss: 6.95878271e-07
Iter: 1401 loss: 6.95751055e-07
Iter: 1402 loss: 6.95494577e-07
Iter: 1403 loss: 6.95298468e-07
Iter: 1404 loss: 6.95450922e-07
Iter: 1405 loss: 6.94878e-07
Iter: 1406 loss: 6.95784365e-07
Iter: 1407 loss: 6.94856794e-07
Iter: 1408 loss: 6.94906646e-07
Iter: 1409 loss: 6.94656819e-07
Iter: 1410 loss: 6.94670803e-07
Iter: 1411 loss: 6.94692289e-07
Iter: 1412 loss: 6.94651135e-07
Iter: 1413 loss: 6.94660116e-07
Iter: 1414 loss: 6.94723838e-07
Iter: 1415 loss: 6.94700759e-07
Iter: 1416 loss: 6.94827634e-07
Iter: 1417 loss: 6.94830192e-07
Iter: 1418 loss: 6.94794608e-07
Iter: 1419 loss: 6.94728726e-07
Iter: 1420 loss: 6.94799212e-07
Iter: 1421 loss: 6.948747e-07
Iter: 1422 loss: 6.94861342e-07
Iter: 1423 loss: 6.9483076e-07
Iter: 1424 loss: 6.94860717e-07
Iter: 1425 loss: 6.94864696e-07
Iter: 1426 loss: 6.94831328e-07
Iter: 1427 loss: 6.94829907e-07
Iter: 1428 loss: 6.94865832e-07
Iter: 1429 loss: 6.94865776e-07
Iter: 1430 loss: 6.94866344e-07
Iter: 1431 loss: 6.94867e-07
Iter: 1432 loss: 6.94867e-07
Iter: 1433 loss: 6.94829907e-07
Iter: 1434 loss: 6.94683933e-07
Iter: 1435 loss: 6.95009533e-07
Iter: 1436 loss: 6.94520622e-07
Iter: 1437 loss: 6.94104472e-07
Iter: 1438 loss: 6.95040058e-07
Iter: 1439 loss: 6.94168762e-07
Iter: 1440 loss: 6.93857714e-07
Iter: 1441 loss: 6.9399789e-07
Iter: 1442 loss: 6.93876245e-07
Iter: 1443 loss: 6.93556728e-07
Iter: 1444 loss: 6.93566e-07
Iter: 1445 loss: 6.93479194e-07
Iter: 1446 loss: 6.93263587e-07
Iter: 1447 loss: 6.93222944e-07
Iter: 1448 loss: 6.92952483e-07
Iter: 1449 loss: 6.92874153e-07
Iter: 1450 loss: 6.96146685e-07
Iter: 1451 loss: 6.92698563e-07
Iter: 1452 loss: 6.92332662e-07
Iter: 1453 loss: 6.93280811e-07
Iter: 1454 loss: 6.92539913e-07
Iter: 1455 loss: 6.92132971e-07
Iter: 1456 loss: 6.92328058e-07
Iter: 1457 loss: 6.92197318e-07
Iter: 1458 loss: 6.91972787e-07
Iter: 1459 loss: 6.93976062e-07
Iter: 1460 loss: 6.9188917e-07
Iter: 1461 loss: 6.91733135e-07
Iter: 1462 loss: 6.91872458e-07
Iter: 1463 loss: 6.91620585e-07
Iter: 1464 loss: 6.91296293e-07
Iter: 1465 loss: 6.91319428e-07
Iter: 1466 loss: 6.91471826e-07
Iter: 1467 loss: 6.91014066e-07
Iter: 1468 loss: 6.94691266e-07
Iter: 1469 loss: 6.91141111e-07
Iter: 1470 loss: 6.90843478e-07
Iter: 1471 loss: 6.91143384e-07
Iter: 1472 loss: 6.90673687e-07
Iter: 1473 loss: 6.90514298e-07
Iter: 1474 loss: 6.91777814e-07
Iter: 1475 loss: 6.90318757e-07
Iter: 1476 loss: 6.89992362e-07
Iter: 1477 loss: 6.93148081e-07
Iter: 1478 loss: 6.90041929e-07
Iter: 1479 loss: 6.89824731e-07
Iter: 1480 loss: 6.89907552e-07
Iter: 1481 loss: 6.89647948e-07
Iter: 1482 loss: 6.89371802e-07
Iter: 1483 loss: 6.90924367e-07
Iter: 1484 loss: 6.89510387e-07
Iter: 1485 loss: 6.89081389e-07
Iter: 1486 loss: 6.89543242e-07
Iter: 1487 loss: 6.8903546e-07
Iter: 1488 loss: 6.88693945e-07
Iter: 1489 loss: 6.88646196e-07
Iter: 1490 loss: 6.88508237e-07
Iter: 1491 loss: 6.88329351e-07
Iter: 1492 loss: 6.88965486e-07
Iter: 1493 loss: 6.88205716e-07
Iter: 1494 loss: 6.87895636e-07
Iter: 1495 loss: 6.88240732e-07
Iter: 1496 loss: 6.87845841e-07
Iter: 1497 loss: 6.87528427e-07
Iter: 1498 loss: 6.87468855e-07
Iter: 1499 loss: 6.87384158e-07
Iter: 1500 loss: 6.8687325e-07
Iter: 1501 loss: 6.88208843e-07
Iter: 1502 loss: 6.86843805e-07
Iter: 1503 loss: 6.86485407e-07
Iter: 1504 loss: 6.86498822e-07
Iter: 1505 loss: 6.86378371e-07
Iter: 1506 loss: 6.86352621e-07
Iter: 1507 loss: 6.86165095e-07
Iter: 1508 loss: 6.86108706e-07
Iter: 1509 loss: 6.87845898e-07
Iter: 1510 loss: 6.85979e-07
Iter: 1511 loss: 6.85589271e-07
Iter: 1512 loss: 6.85417e-07
Iter: 1513 loss: 6.85359794e-07
Iter: 1514 loss: 6.84842632e-07
Iter: 1515 loss: 6.86460055e-07
Iter: 1516 loss: 6.84773738e-07
Iter: 1517 loss: 6.84587235e-07
Iter: 1518 loss: 6.8445911e-07
Iter: 1519 loss: 6.8406689e-07
Iter: 1520 loss: 6.83921769e-07
Iter: 1521 loss: 6.83867199e-07
Iter: 1522 loss: 6.83512e-07
Iter: 1523 loss: 6.86811461e-07
Iter: 1524 loss: 6.83470375e-07
Iter: 1525 loss: 6.83270684e-07
Iter: 1526 loss: 6.84290285e-07
Iter: 1527 loss: 6.83201847e-07
Iter: 1528 loss: 6.82949803e-07
Iter: 1529 loss: 6.82919733e-07
Iter: 1530 loss: 6.82906e-07
Iter: 1531 loss: 6.82590496e-07
Iter: 1532 loss: 6.82763584e-07
Iter: 1533 loss: 6.82452139e-07
Iter: 1534 loss: 6.82251425e-07
Iter: 1535 loss: 6.82706514e-07
Iter: 1536 loss: 6.82106929e-07
Iter: 1537 loss: 6.81771439e-07
Iter: 1538 loss: 6.81790198e-07
Iter: 1539 loss: 6.81506663e-07
Iter: 1540 loss: 6.8246203e-07
Iter: 1541 loss: 6.81247457e-07
Iter: 1542 loss: 6.81351e-07
Iter: 1543 loss: 6.81428446e-07
Iter: 1544 loss: 6.81570157e-07
Iter: 1545 loss: 6.81474091e-07
Iter: 1546 loss: 6.8147034e-07
Iter: 1547 loss: 6.81383881e-07
Iter: 1548 loss: 6.81548045e-07
Iter: 1549 loss: 6.81449251e-07
Iter: 1550 loss: 6.81523659e-07
Iter: 1551 loss: 6.81440838e-07
Iter: 1552 loss: 6.81410711e-07
Iter: 1553 loss: 6.81329936e-07
Iter: 1554 loss: 6.81312883e-07
Iter: 1555 loss: 6.81288157e-07
Iter: 1556 loss: 6.81257291e-07
Iter: 1557 loss: 6.81254619e-07
Iter: 1558 loss: 6.81248252e-07
Iter: 1559 loss: 6.81248e-07
Iter: 1560 loss: 6.81248707e-07
Iter: 1561 loss: 6.81248594e-07
Iter: 1562 loss: 6.81248252e-07
Iter: 1563 loss: 6.81248252e-07
Iter: 1564 loss: 6.81248e-07
Iter: 1565 loss: 6.81248e-07
Iter: 1566 loss: 6.81248252e-07
Iter: 1567 loss: 6.81248e-07
Iter: 1568 loss: 6.81248252e-07
Iter: 1569 loss: 6.81248252e-07
Iter: 1570 loss: 6.81248252e-07
Iter: 1571 loss: 6.81248e-07
Iter: 1572 loss: 6.81248252e-07
Iter: 1573 loss: 6.81248e-07
Iter: 1574 loss: 6.81248e-07
Iter: 1575 loss: 6.81248e-07
Iter: 1576 loss: 6.81248252e-07
Iter: 1577 loss: 6.81248252e-07
Iter: 1578 loss: 6.81248e-07
Iter: 1579 loss: 6.81248e-07
Iter: 1580 loss: 6.81248e-07
Iter: 1581 loss: 6.81248252e-07
Iter: 1582 loss: 6.81248e-07
Iter: 1583 loss: 6.81248252e-07
Iter: 1584 loss: 6.85124178e-07
Iter: 1585 loss: 6.81392748e-07
Iter: 1586 loss: 6.81405822e-07
Iter: 1587 loss: 6.8150473e-07
Iter: 1588 loss: 6.81403776e-07
Iter: 1589 loss: 6.81439303e-07
Iter: 1590 loss: 6.81413212e-07
Iter: 1591 loss: 6.8142333e-07
Iter: 1592 loss: 6.8145539e-07
Iter: 1593 loss: 6.81437768e-07
Iter: 1594 loss: 6.81382915e-07
Iter: 1595 loss: 6.81407357e-07
Iter: 1596 loss: 6.81392464e-07
Iter: 1597 loss: 6.81358358e-07
Iter: 1598 loss: 6.81294694e-07
Iter: 1599 loss: 6.81267863e-07
Iter: 1600 loss: 6.81252914e-07
Iter: 1601 loss: 6.81238305e-07
Iter: 1602 loss: 6.81243705e-07
Iter: 1603 loss: 6.81248196e-07
Iter: 1604 loss: 6.8125e-07
Iter: 1605 loss: 6.81249105e-07
Iter: 1606 loss: 6.81248423e-07
Iter: 1607 loss: 6.81249105e-07
Iter: 1608 loss: 6.81248423e-07
Iter: 1609 loss: 6.81249503e-07
Iter: 1610 loss: 6.81248252e-07
Iter: 1611 loss: 6.81249503e-07
Iter: 1612 loss: 6.81249503e-07
Iter: 1613 loss: 6.81249503e-07
Iter: 1614 loss: 6.81248252e-07
Iter: 1615 loss: 6.81249503e-07
Iter: 1616 loss: 6.81248252e-07
Iter: 1617 loss: 6.81248252e-07
Iter: 1618 loss: 6.81248252e-07
Iter: 1619 loss: 6.81249503e-07
Iter: 1620 loss: 6.81248252e-07
Iter: 1621 loss: 6.81249503e-07
Iter: 1622 loss: 6.81248252e-07
Iter: 1623 loss: 6.81248252e-07
Iter: 1624 loss: 6.81249503e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_4000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_4000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906bb37488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906bacc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906ba97bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906bb9e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906bb9ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906bb9eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906bb9ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b9ba950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b9f6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b9e5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b98f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b962ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b962c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b9a61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b8d5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b936378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b924f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b9e56a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b8669d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b7ffa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b8247b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b7dc2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b7c36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b78ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b78cd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b78c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f902927bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f906b78ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9029236400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f902925a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9029243598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f902921e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f902921b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f90291c2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f902916e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f90291a3c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6.94130285e-05
Iter: 2 loss: 0.0031795227
Iter: 3 loss: 5.11668404e-05
Iter: 4 loss: 4.28193707e-05
Iter: 5 loss: 4.80826202e-05
Iter: 6 loss: 3.74514384e-05
Iter: 7 loss: 3.16861915e-05
Iter: 8 loss: 4.42323908e-05
Iter: 9 loss: 2.9486182e-05
Iter: 10 loss: 2.56040184e-05
Iter: 11 loss: 2.78363714e-05
Iter: 12 loss: 2.30836522e-05
Iter: 13 loss: 1.90375522e-05
Iter: 14 loss: 4.23130841e-05
Iter: 15 loss: 1.85033441e-05
Iter: 16 loss: 1.55273774e-05
Iter: 17 loss: 1.54786048e-05
Iter: 18 loss: 1.31278912e-05
Iter: 19 loss: 1.14101213e-05
Iter: 20 loss: 2.63062484e-05
Iter: 21 loss: 1.13182014e-05
Iter: 22 loss: 1.02310369e-05
Iter: 23 loss: 9.9703775e-06
Iter: 24 loss: 9.27783e-06
Iter: 25 loss: 8.32269689e-06
Iter: 26 loss: 1.88376671e-05
Iter: 27 loss: 8.30181489e-06
Iter: 28 loss: 7.66040193e-06
Iter: 29 loss: 7.75580156e-06
Iter: 30 loss: 7.17564399e-06
Iter: 31 loss: 6.33709215e-06
Iter: 32 loss: 1.01526712e-05
Iter: 33 loss: 6.17491332e-06
Iter: 34 loss: 5.76480534e-06
Iter: 35 loss: 6.82231e-06
Iter: 36 loss: 5.62446758e-06
Iter: 37 loss: 5.58303964e-06
Iter: 38 loss: 5.48254684e-06
Iter: 39 loss: 5.314e-06
Iter: 40 loss: 5.3683907e-06
Iter: 41 loss: 5.19349032e-06
Iter: 42 loss: 5.03172259e-06
Iter: 43 loss: 5.0279632e-06
Iter: 44 loss: 4.90201091e-06
Iter: 45 loss: 4.76876767e-06
Iter: 46 loss: 6.34841126e-06
Iter: 47 loss: 4.76711e-06
Iter: 48 loss: 4.64761e-06
Iter: 49 loss: 4.69652969e-06
Iter: 50 loss: 4.56561202e-06
Iter: 51 loss: 4.44111447e-06
Iter: 52 loss: 4.4391586e-06
Iter: 53 loss: 4.33989771e-06
Iter: 54 loss: 4.19116532e-06
Iter: 55 loss: 5.05582921e-06
Iter: 56 loss: 4.17165302e-06
Iter: 57 loss: 4.04720231e-06
Iter: 58 loss: 4.02289425e-06
Iter: 59 loss: 3.94029848e-06
Iter: 60 loss: 3.7841553e-06
Iter: 61 loss: 4.98850886e-06
Iter: 62 loss: 3.77287824e-06
Iter: 63 loss: 3.68169435e-06
Iter: 64 loss: 3.98885e-06
Iter: 65 loss: 3.65713345e-06
Iter: 66 loss: 3.55424527e-06
Iter: 67 loss: 3.66373206e-06
Iter: 68 loss: 3.49793731e-06
Iter: 69 loss: 3.39653093e-06
Iter: 70 loss: 3.71258466e-06
Iter: 71 loss: 3.36657763e-06
Iter: 72 loss: 3.50228879e-06
Iter: 73 loss: 3.34863171e-06
Iter: 74 loss: 3.32969876e-06
Iter: 75 loss: 3.27148859e-06
Iter: 76 loss: 3.27598514e-06
Iter: 77 loss: 3.21130574e-06
Iter: 78 loss: 3.15135139e-06
Iter: 79 loss: 3.15096986e-06
Iter: 80 loss: 3.09765528e-06
Iter: 81 loss: 3.28425e-06
Iter: 82 loss: 3.0838487e-06
Iter: 83 loss: 3.03449519e-06
Iter: 84 loss: 3.04041987e-06
Iter: 85 loss: 2.99600129e-06
Iter: 86 loss: 2.93734502e-06
Iter: 87 loss: 2.9729656e-06
Iter: 88 loss: 2.89977265e-06
Iter: 89 loss: 2.84896191e-06
Iter: 90 loss: 3.35949153e-06
Iter: 91 loss: 2.84711564e-06
Iter: 92 loss: 2.8063921e-06
Iter: 93 loss: 2.75542061e-06
Iter: 94 loss: 2.75135426e-06
Iter: 95 loss: 2.71179874e-06
Iter: 96 loss: 2.71131444e-06
Iter: 97 loss: 2.68647864e-06
Iter: 98 loss: 2.66383495e-06
Iter: 99 loss: 2.65797144e-06
Iter: 100 loss: 2.61069908e-06
Iter: 101 loss: 2.71985459e-06
Iter: 102 loss: 2.59335957e-06
Iter: 103 loss: 2.56931071e-06
Iter: 104 loss: 2.80703216e-06
Iter: 105 loss: 2.56853309e-06
Iter: 106 loss: 2.54160454e-06
Iter: 107 loss: 2.69407451e-06
Iter: 108 loss: 2.53804183e-06
Iter: 109 loss: 2.52572408e-06
Iter: 110 loss: 2.4955234e-06
Iter: 111 loss: 2.77965682e-06
Iter: 112 loss: 2.4912556e-06
Iter: 113 loss: 2.48084e-06
Iter: 114 loss: 2.47659091e-06
Iter: 115 loss: 2.46299214e-06
Iter: 116 loss: 2.44727585e-06
Iter: 117 loss: 2.44478e-06
Iter: 118 loss: 2.41804219e-06
Iter: 119 loss: 2.49005552e-06
Iter: 120 loss: 2.40903114e-06
Iter: 121 loss: 2.3847133e-06
Iter: 122 loss: 2.4176336e-06
Iter: 123 loss: 2.37252175e-06
Iter: 124 loss: 2.34487334e-06
Iter: 125 loss: 2.37387485e-06
Iter: 126 loss: 2.32966886e-06
Iter: 127 loss: 2.29854118e-06
Iter: 128 loss: 2.64717255e-06
Iter: 129 loss: 2.29789316e-06
Iter: 130 loss: 2.27771056e-06
Iter: 131 loss: 2.26328712e-06
Iter: 132 loss: 2.25576377e-06
Iter: 133 loss: 2.22403833e-06
Iter: 134 loss: 2.49615e-06
Iter: 135 loss: 2.22219342e-06
Iter: 136 loss: 2.20629158e-06
Iter: 137 loss: 2.35321158e-06
Iter: 138 loss: 2.2056156e-06
Iter: 139 loss: 2.20030688e-06
Iter: 140 loss: 2.1984406e-06
Iter: 141 loss: 2.19393246e-06
Iter: 142 loss: 2.17981164e-06
Iter: 143 loss: 2.20644142e-06
Iter: 144 loss: 2.17010438e-06
Iter: 145 loss: 2.15237105e-06
Iter: 146 loss: 2.21555069e-06
Iter: 147 loss: 2.14694637e-06
Iter: 148 loss: 2.13774956e-06
Iter: 149 loss: 2.13796511e-06
Iter: 150 loss: 2.12703776e-06
Iter: 151 loss: 2.10890312e-06
Iter: 152 loss: 2.10875169e-06
Iter: 153 loss: 2.09620544e-06
Iter: 154 loss: 2.17915863e-06
Iter: 155 loss: 2.09512086e-06
Iter: 156 loss: 2.08194865e-06
Iter: 157 loss: 2.0734019e-06
Iter: 158 loss: 2.06872414e-06
Iter: 159 loss: 2.05010792e-06
Iter: 160 loss: 2.12553346e-06
Iter: 161 loss: 2.04599473e-06
Iter: 162 loss: 2.0327418e-06
Iter: 163 loss: 2.06953973e-06
Iter: 164 loss: 2.02819137e-06
Iter: 165 loss: 2.01301782e-06
Iter: 166 loss: 2.03646732e-06
Iter: 167 loss: 2.00551517e-06
Iter: 168 loss: 1.99013903e-06
Iter: 169 loss: 2.13495946e-06
Iter: 170 loss: 1.98918315e-06
Iter: 171 loss: 1.98841599e-06
Iter: 172 loss: 1.98595444e-06
Iter: 173 loss: 1.98206294e-06
Iter: 174 loss: 1.97231384e-06
Iter: 175 loss: 2.10302346e-06
Iter: 176 loss: 1.97161694e-06
Iter: 177 loss: 1.96274209e-06
Iter: 178 loss: 1.95102939e-06
Iter: 179 loss: 1.94992731e-06
Iter: 180 loss: 1.93687288e-06
Iter: 181 loss: 2.01851253e-06
Iter: 182 loss: 1.93547294e-06
Iter: 183 loss: 1.92683342e-06
Iter: 184 loss: 1.92702873e-06
Iter: 185 loss: 1.9198e-06
Iter: 186 loss: 1.90715036e-06
Iter: 187 loss: 1.90748915e-06
Iter: 188 loss: 1.89618561e-06
Iter: 189 loss: 1.948e-06
Iter: 190 loss: 1.89423781e-06
Iter: 191 loss: 1.883702e-06
Iter: 192 loss: 1.90498872e-06
Iter: 193 loss: 1.87922763e-06
Iter: 194 loss: 1.86633338e-06
Iter: 195 loss: 1.87304852e-06
Iter: 196 loss: 1.85741737e-06
Iter: 197 loss: 1.84498731e-06
Iter: 198 loss: 1.92668358e-06
Iter: 199 loss: 1.84372243e-06
Iter: 200 loss: 1.83254429e-06
Iter: 201 loss: 1.81623113e-06
Iter: 202 loss: 1.81610767e-06
Iter: 203 loss: 1.81189091e-06
Iter: 204 loss: 1.80477548e-06
Iter: 205 loss: 1.80206621e-06
Iter: 206 loss: 1.8009024e-06
Iter: 207 loss: 1.79938581e-06
Iter: 208 loss: 1.79484346e-06
Iter: 209 loss: 1.79090557e-06
Iter: 210 loss: 1.78905532e-06
Iter: 211 loss: 1.77799063e-06
Iter: 212 loss: 1.85540875e-06
Iter: 213 loss: 1.77697723e-06
Iter: 214 loss: 1.77409333e-06
Iter: 215 loss: 1.77222842e-06
Iter: 216 loss: 1.76804258e-06
Iter: 217 loss: 1.76205e-06
Iter: 218 loss: 1.76171693e-06
Iter: 219 loss: 1.75295577e-06
Iter: 220 loss: 1.75584898e-06
Iter: 221 loss: 1.7464854e-06
Iter: 222 loss: 1.73805051e-06
Iter: 223 loss: 1.86862633e-06
Iter: 224 loss: 1.7381808e-06
Iter: 225 loss: 1.72991554e-06
Iter: 226 loss: 1.72710543e-06
Iter: 227 loss: 1.72264185e-06
Iter: 228 loss: 1.71183774e-06
Iter: 229 loss: 1.76390711e-06
Iter: 230 loss: 1.71054444e-06
Iter: 231 loss: 1.70271824e-06
Iter: 232 loss: 1.7104519e-06
Iter: 233 loss: 1.6987359e-06
Iter: 234 loss: 1.69152008e-06
Iter: 235 loss: 1.75582761e-06
Iter: 236 loss: 1.69096472e-06
Iter: 237 loss: 1.68978443e-06
Iter: 238 loss: 1.68779411e-06
Iter: 239 loss: 1.68531415e-06
Iter: 240 loss: 1.67960093e-06
Iter: 241 loss: 1.73494448e-06
Iter: 242 loss: 1.67895394e-06
Iter: 243 loss: 1.67447797e-06
Iter: 244 loss: 1.66556367e-06
Iter: 245 loss: 1.83387647e-06
Iter: 246 loss: 1.66532197e-06
Iter: 247 loss: 1.65398296e-06
Iter: 248 loss: 1.73579633e-06
Iter: 249 loss: 1.65283041e-06
Iter: 250 loss: 1.64772973e-06
Iter: 251 loss: 1.64707058e-06
Iter: 252 loss: 1.64241158e-06
Iter: 253 loss: 1.63722927e-06
Iter: 254 loss: 1.63652123e-06
Iter: 255 loss: 1.62914853e-06
Iter: 256 loss: 1.62964386e-06
Iter: 257 loss: 1.62348226e-06
Iter: 258 loss: 1.61505886e-06
Iter: 259 loss: 1.66185691e-06
Iter: 260 loss: 1.61422645e-06
Iter: 261 loss: 1.60624711e-06
Iter: 262 loss: 1.62739934e-06
Iter: 263 loss: 1.60366642e-06
Iter: 264 loss: 1.59672777e-06
Iter: 265 loss: 1.61478511e-06
Iter: 266 loss: 1.59400292e-06
Iter: 267 loss: 1.58901116e-06
Iter: 268 loss: 1.60322656e-06
Iter: 269 loss: 1.58727926e-06
Iter: 270 loss: 1.582197e-06
Iter: 271 loss: 1.61414118e-06
Iter: 272 loss: 1.58150237e-06
Iter: 273 loss: 1.57562681e-06
Iter: 274 loss: 1.63136133e-06
Iter: 275 loss: 1.57515365e-06
Iter: 276 loss: 1.57366276e-06
Iter: 277 loss: 1.57095576e-06
Iter: 278 loss: 1.61198409e-06
Iter: 279 loss: 1.57080103e-06
Iter: 280 loss: 1.56648582e-06
Iter: 281 loss: 1.56352439e-06
Iter: 282 loss: 1.56220574e-06
Iter: 283 loss: 1.55581074e-06
Iter: 284 loss: 1.58168359e-06
Iter: 285 loss: 1.55440523e-06
Iter: 286 loss: 1.55082694e-06
Iter: 287 loss: 1.55085957e-06
Iter: 288 loss: 1.5459218e-06
Iter: 289 loss: 1.53941767e-06
Iter: 290 loss: 1.53978419e-06
Iter: 291 loss: 1.53484575e-06
Iter: 292 loss: 1.5566e-06
Iter: 293 loss: 1.53378596e-06
Iter: 294 loss: 1.53048609e-06
Iter: 295 loss: 1.53389419e-06
Iter: 296 loss: 1.52823043e-06
Iter: 297 loss: 1.52272264e-06
Iter: 298 loss: 1.53961219e-06
Iter: 299 loss: 1.52130065e-06
Iter: 300 loss: 1.51693837e-06
Iter: 301 loss: 1.53976612e-06
Iter: 302 loss: 1.51591632e-06
Iter: 303 loss: 1.51217796e-06
Iter: 304 loss: 1.51095355e-06
Iter: 305 loss: 1.50885398e-06
Iter: 306 loss: 1.5036801e-06
Iter: 307 loss: 1.54174882e-06
Iter: 308 loss: 1.50353219e-06
Iter: 309 loss: 1.50307892e-06
Iter: 310 loss: 1.50227766e-06
Iter: 311 loss: 1.50020048e-06
Iter: 312 loss: 1.4955607e-06
Iter: 313 loss: 1.5254866e-06
Iter: 314 loss: 1.49400284e-06
Iter: 315 loss: 1.490356e-06
Iter: 316 loss: 1.49475898e-06
Iter: 317 loss: 1.48878587e-06
Iter: 318 loss: 1.48466461e-06
Iter: 319 loss: 1.48901427e-06
Iter: 320 loss: 1.4828471e-06
Iter: 321 loss: 1.4781092e-06
Iter: 322 loss: 1.50073879e-06
Iter: 323 loss: 1.47718094e-06
Iter: 324 loss: 1.4736313e-06
Iter: 325 loss: 1.48258323e-06
Iter: 326 loss: 1.47244953e-06
Iter: 327 loss: 1.46972957e-06
Iter: 328 loss: 1.46939033e-06
Iter: 329 loss: 1.4672288e-06
Iter: 330 loss: 1.462873e-06
Iter: 331 loss: 1.55509633e-06
Iter: 332 loss: 1.46274238e-06
Iter: 333 loss: 1.45912736e-06
Iter: 334 loss: 1.45944978e-06
Iter: 335 loss: 1.45627882e-06
Iter: 336 loss: 1.45069225e-06
Iter: 337 loss: 1.46569334e-06
Iter: 338 loss: 1.44879959e-06
Iter: 339 loss: 1.44557737e-06
Iter: 340 loss: 1.44529668e-06
Iter: 341 loss: 1.44250112e-06
Iter: 342 loss: 1.44025546e-06
Iter: 343 loss: 1.43976433e-06
Iter: 344 loss: 1.44014552e-06
Iter: 345 loss: 1.43763464e-06
Iter: 346 loss: 1.43637772e-06
Iter: 347 loss: 1.43290504e-06
Iter: 348 loss: 1.45277932e-06
Iter: 349 loss: 1.43216062e-06
Iter: 350 loss: 1.42752856e-06
Iter: 351 loss: 1.43257716e-06
Iter: 352 loss: 1.42523959e-06
Iter: 353 loss: 1.42087151e-06
Iter: 354 loss: 1.44043975e-06
Iter: 355 loss: 1.41976818e-06
Iter: 356 loss: 1.41554301e-06
Iter: 357 loss: 1.42637953e-06
Iter: 358 loss: 1.41376427e-06
Iter: 359 loss: 1.4095408e-06
Iter: 360 loss: 1.41479723e-06
Iter: 361 loss: 1.4071727e-06
Iter: 362 loss: 1.40500435e-06
Iter: 363 loss: 1.40446514e-06
Iter: 364 loss: 1.40230134e-06
Iter: 365 loss: 1.39923247e-06
Iter: 366 loss: 1.39893791e-06
Iter: 367 loss: 1.39567987e-06
Iter: 368 loss: 1.39401845e-06
Iter: 369 loss: 1.39213728e-06
Iter: 370 loss: 1.38862129e-06
Iter: 371 loss: 1.4294618e-06
Iter: 372 loss: 1.3885666e-06
Iter: 373 loss: 1.38523205e-06
Iter: 374 loss: 1.39014674e-06
Iter: 375 loss: 1.38354426e-06
Iter: 376 loss: 1.3798832e-06
Iter: 377 loss: 1.39659778e-06
Iter: 378 loss: 1.37952452e-06
Iter: 379 loss: 1.38013445e-06
Iter: 380 loss: 1.37823054e-06
Iter: 381 loss: 1.37735833e-06
Iter: 382 loss: 1.37518964e-06
Iter: 383 loss: 1.37791881e-06
Iter: 384 loss: 1.37349525e-06
Iter: 385 loss: 1.36964513e-06
Iter: 386 loss: 1.38660744e-06
Iter: 387 loss: 1.3688225e-06
Iter: 388 loss: 1.36641631e-06
Iter: 389 loss: 1.37090592e-06
Iter: 390 loss: 1.36496692e-06
Iter: 391 loss: 1.36197878e-06
Iter: 392 loss: 1.36289339e-06
Iter: 393 loss: 1.35970436e-06
Iter: 394 loss: 1.35614664e-06
Iter: 395 loss: 1.39373242e-06
Iter: 396 loss: 1.35606672e-06
Iter: 397 loss: 1.35443383e-06
Iter: 398 loss: 1.36503775e-06
Iter: 399 loss: 1.35412836e-06
Iter: 400 loss: 1.35209325e-06
Iter: 401 loss: 1.35439882e-06
Iter: 402 loss: 1.35087532e-06
Iter: 403 loss: 1.34915922e-06
Iter: 404 loss: 1.34789957e-06
Iter: 405 loss: 1.34709285e-06
Iter: 406 loss: 1.34494667e-06
Iter: 407 loss: 1.34679772e-06
Iter: 408 loss: 1.34347101e-06
Iter: 409 loss: 1.33999367e-06
Iter: 410 loss: 1.35982452e-06
Iter: 411 loss: 1.33926505e-06
Iter: 412 loss: 1.33966785e-06
Iter: 413 loss: 1.33867547e-06
Iter: 414 loss: 1.33773665e-06
Iter: 415 loss: 1.33687377e-06
Iter: 416 loss: 1.33663821e-06
Iter: 417 loss: 1.33542687e-06
Iter: 418 loss: 1.33226717e-06
Iter: 419 loss: 1.36883591e-06
Iter: 420 loss: 1.33244964e-06
Iter: 421 loss: 1.32935088e-06
Iter: 422 loss: 1.36550364e-06
Iter: 423 loss: 1.3294873e-06
Iter: 424 loss: 1.32781634e-06
Iter: 425 loss: 1.33173296e-06
Iter: 426 loss: 1.32694527e-06
Iter: 427 loss: 1.32523678e-06
Iter: 428 loss: 1.3230831e-06
Iter: 429 loss: 1.32264e-06
Iter: 430 loss: 1.31967431e-06
Iter: 431 loss: 1.33551373e-06
Iter: 432 loss: 1.31950378e-06
Iter: 433 loss: 1.31768627e-06
Iter: 434 loss: 1.31770912e-06
Iter: 435 loss: 1.31565309e-06
Iter: 436 loss: 1.31635852e-06
Iter: 437 loss: 1.31446905e-06
Iter: 438 loss: 1.31272395e-06
Iter: 439 loss: 1.31209163e-06
Iter: 440 loss: 1.31119759e-06
Iter: 441 loss: 1.30898104e-06
Iter: 442 loss: 1.31254683e-06
Iter: 443 loss: 1.30768422e-06
Iter: 444 loss: 1.30567491e-06
Iter: 445 loss: 1.31615946e-06
Iter: 446 loss: 1.3052769e-06
Iter: 447 loss: 1.30638819e-06
Iter: 448 loss: 1.30464286e-06
Iter: 449 loss: 1.30409467e-06
Iter: 450 loss: 1.30278374e-06
Iter: 451 loss: 1.30763749e-06
Iter: 452 loss: 1.30196281e-06
Iter: 453 loss: 1.29994112e-06
Iter: 454 loss: 1.29931448e-06
Iter: 455 loss: 1.29806176e-06
Iter: 456 loss: 1.2961566e-06
Iter: 457 loss: 1.31945649e-06
Iter: 458 loss: 1.2962912e-06
Iter: 459 loss: 1.2948617e-06
Iter: 460 loss: 1.29433613e-06
Iter: 461 loss: 1.29329237e-06
Iter: 462 loss: 1.29112618e-06
Iter: 463 loss: 1.29410682e-06
Iter: 464 loss: 1.29037016e-06
Iter: 465 loss: 1.28856914e-06
Iter: 466 loss: 1.29618923e-06
Iter: 467 loss: 1.28835825e-06
Iter: 468 loss: 1.2866692e-06
Iter: 469 loss: 1.28663305e-06
Iter: 470 loss: 1.28521231e-06
Iter: 471 loss: 1.28463842e-06
Iter: 472 loss: 1.28415218e-06
Iter: 473 loss: 1.28356101e-06
Iter: 474 loss: 1.28214219e-06
Iter: 475 loss: 1.29252953e-06
Iter: 476 loss: 1.28163992e-06
Iter: 477 loss: 1.28010834e-06
Iter: 478 loss: 1.28250031e-06
Iter: 479 loss: 1.27948067e-06
Iter: 480 loss: 1.27893782e-06
Iter: 481 loss: 1.28153238e-06
Iter: 482 loss: 1.27875296e-06
Iter: 483 loss: 1.27806436e-06
Iter: 484 loss: 1.27833096e-06
Iter: 485 loss: 1.27765315e-06
Iter: 486 loss: 1.27655085e-06
Iter: 487 loss: 1.27524299e-06
Iter: 488 loss: 1.27492035e-06
Iter: 489 loss: 1.27331725e-06
Iter: 490 loss: 1.2762348e-06
Iter: 491 loss: 1.27259216e-06
Iter: 492 loss: 1.2704952e-06
Iter: 493 loss: 1.27295482e-06
Iter: 494 loss: 1.26949067e-06
Iter: 495 loss: 1.2673047e-06
Iter: 496 loss: 1.28635452e-06
Iter: 497 loss: 1.26728992e-06
Iter: 498 loss: 1.26589509e-06
Iter: 499 loss: 1.26748341e-06
Iter: 500 loss: 1.26485008e-06
Iter: 501 loss: 1.26323403e-06
Iter: 502 loss: 1.26897942e-06
Iter: 503 loss: 1.26254906e-06
Iter: 504 loss: 1.26185375e-06
Iter: 505 loss: 1.27495287e-06
Iter: 506 loss: 1.26180112e-06
Iter: 507 loss: 1.26058865e-06
Iter: 508 loss: 1.26160376e-06
Iter: 509 loss: 1.26005034e-06
Iter: 510 loss: 1.25880729e-06
Iter: 511 loss: 1.26083887e-06
Iter: 512 loss: 1.25842394e-06
Iter: 513 loss: 1.25750137e-06
Iter: 514 loss: 1.25740962e-06
Iter: 515 loss: 1.25681925e-06
Iter: 516 loss: 1.25606675e-06
Iter: 517 loss: 1.25585791e-06
Iter: 518 loss: 1.25472457e-06
Iter: 519 loss: 1.254567e-06
Iter: 520 loss: 1.25398174e-06
Iter: 521 loss: 1.25205736e-06
Iter: 522 loss: 1.25262386e-06
Iter: 523 loss: 1.25048223e-06
Iter: 524 loss: 1.24845008e-06
Iter: 525 loss: 1.25978659e-06
Iter: 526 loss: 1.24789722e-06
Iter: 527 loss: 1.24580163e-06
Iter: 528 loss: 1.24521091e-06
Iter: 529 loss: 1.24380426e-06
Iter: 530 loss: 1.24200699e-06
Iter: 531 loss: 1.24195356e-06
Iter: 532 loss: 1.24053417e-06
Iter: 533 loss: 1.24090241e-06
Iter: 534 loss: 1.23955056e-06
Iter: 535 loss: 1.23823213e-06
Iter: 536 loss: 1.252478e-06
Iter: 537 loss: 1.23821656e-06
Iter: 538 loss: 1.23685652e-06
Iter: 539 loss: 1.24131088e-06
Iter: 540 loss: 1.23646385e-06
Iter: 541 loss: 1.23563223e-06
Iter: 542 loss: 1.23839231e-06
Iter: 543 loss: 1.23528071e-06
Iter: 544 loss: 1.23463826e-06
Iter: 545 loss: 1.23440168e-06
Iter: 546 loss: 1.23400923e-06
Iter: 547 loss: 1.23300129e-06
Iter: 548 loss: 1.25324414e-06
Iter: 549 loss: 1.23293671e-06
Iter: 550 loss: 1.2316857e-06
Iter: 551 loss: 1.23213113e-06
Iter: 552 loss: 1.2306723e-06
Iter: 553 loss: 1.22935705e-06
Iter: 554 loss: 1.23643372e-06
Iter: 555 loss: 1.22912206e-06
Iter: 556 loss: 1.22797292e-06
Iter: 557 loss: 1.22790652e-06
Iter: 558 loss: 1.22718802e-06
Iter: 559 loss: 1.22508663e-06
Iter: 560 loss: 1.23110328e-06
Iter: 561 loss: 1.22459016e-06
Iter: 562 loss: 1.2234932e-06
Iter: 563 loss: 1.23188101e-06
Iter: 564 loss: 1.22309825e-06
Iter: 565 loss: 1.22173401e-06
Iter: 566 loss: 1.22292909e-06
Iter: 567 loss: 1.22104757e-06
Iter: 568 loss: 1.2194854e-06
Iter: 569 loss: 1.23120492e-06
Iter: 570 loss: 1.2195278e-06
Iter: 571 loss: 1.21849359e-06
Iter: 572 loss: 1.22864526e-06
Iter: 573 loss: 1.21842641e-06
Iter: 574 loss: 1.21769642e-06
Iter: 575 loss: 1.21817493e-06
Iter: 576 loss: 1.21734809e-06
Iter: 577 loss: 1.21665482e-06
Iter: 578 loss: 1.21663163e-06
Iter: 579 loss: 1.21643973e-06
Iter: 580 loss: 1.21533196e-06
Iter: 581 loss: 1.21525773e-06
Iter: 582 loss: 1.21459743e-06
Iter: 583 loss: 1.21469816e-06
Iter: 584 loss: 1.21371113e-06
Iter: 585 loss: 1.21291544e-06
Iter: 586 loss: 1.21325274e-06
Iter: 587 loss: 1.21186031e-06
Iter: 588 loss: 1.21044411e-06
Iter: 589 loss: 1.21597941e-06
Iter: 590 loss: 1.20998652e-06
Iter: 591 loss: 1.20864229e-06
Iter: 592 loss: 1.21264418e-06
Iter: 593 loss: 1.20828633e-06
Iter: 594 loss: 1.20660798e-06
Iter: 595 loss: 1.20900449e-06
Iter: 596 loss: 1.20605614e-06
Iter: 597 loss: 1.20479888e-06
Iter: 598 loss: 1.21599498e-06
Iter: 599 loss: 1.20469213e-06
Iter: 600 loss: 1.2036628e-06
Iter: 601 loss: 1.20430025e-06
Iter: 602 loss: 1.20300399e-06
Iter: 603 loss: 1.20228538e-06
Iter: 604 loss: 1.20231448e-06
Iter: 605 loss: 1.20125458e-06
Iter: 606 loss: 1.20170489e-06
Iter: 607 loss: 1.20068125e-06
Iter: 608 loss: 1.20037203e-06
Iter: 609 loss: 1.20025788e-06
Iter: 610 loss: 1.19977949e-06
Iter: 611 loss: 1.20005257e-06
Iter: 612 loss: 1.19951119e-06
Iter: 613 loss: 1.19918013e-06
Iter: 614 loss: 1.19822755e-06
Iter: 615 loss: 1.20753521e-06
Iter: 616 loss: 1.19817742e-06
Iter: 617 loss: 1.19688616e-06
Iter: 618 loss: 1.20276013e-06
Iter: 619 loss: 1.1966157e-06
Iter: 620 loss: 1.19587776e-06
Iter: 621 loss: 1.19765514e-06
Iter: 622 loss: 1.19512652e-06
Iter: 623 loss: 1.19433435e-06
Iter: 624 loss: 1.19574975e-06
Iter: 625 loss: 1.19363949e-06
Iter: 626 loss: 1.19277536e-06
Iter: 627 loss: 1.19927699e-06
Iter: 628 loss: 1.19250319e-06
Iter: 629 loss: 1.19185665e-06
Iter: 630 loss: 1.19291155e-06
Iter: 631 loss: 1.19164076e-06
Iter: 632 loss: 1.19049957e-06
Iter: 633 loss: 1.19182539e-06
Iter: 634 loss: 1.19004858e-06
Iter: 635 loss: 1.18892694e-06
Iter: 636 loss: 1.19351876e-06
Iter: 637 loss: 1.18885259e-06
Iter: 638 loss: 1.1877305e-06
Iter: 639 loss: 1.19571769e-06
Iter: 640 loss: 1.18765e-06
Iter: 641 loss: 1.18686535e-06
Iter: 642 loss: 1.18801438e-06
Iter: 643 loss: 1.1866224e-06
Iter: 644 loss: 1.18554158e-06
Iter: 645 loss: 1.19589129e-06
Iter: 646 loss: 1.18541084e-06
Iter: 647 loss: 1.18503567e-06
Iter: 648 loss: 1.18413493e-06
Iter: 649 loss: 1.19630226e-06
Iter: 650 loss: 1.18401636e-06
Iter: 651 loss: 1.18326125e-06
Iter: 652 loss: 1.1850525e-06
Iter: 653 loss: 1.18340165e-06
Iter: 654 loss: 1.18215485e-06
Iter: 655 loss: 1.18404296e-06
Iter: 656 loss: 1.18162041e-06
Iter: 657 loss: 1.18045614e-06
Iter: 658 loss: 1.18323578e-06
Iter: 659 loss: 1.18022012e-06
Iter: 660 loss: 1.17920729e-06
Iter: 661 loss: 1.18144544e-06
Iter: 662 loss: 1.17879415e-06
Iter: 663 loss: 1.17795162e-06
Iter: 664 loss: 1.18056573e-06
Iter: 665 loss: 1.17771026e-06
Iter: 666 loss: 1.17710078e-06
Iter: 667 loss: 1.17910633e-06
Iter: 668 loss: 1.1768135e-06
Iter: 669 loss: 1.17601826e-06
Iter: 670 loss: 1.18142566e-06
Iter: 671 loss: 1.17592754e-06
Iter: 672 loss: 1.17541333e-06
Iter: 673 loss: 1.17712284e-06
Iter: 674 loss: 1.17526133e-06
Iter: 675 loss: 1.17439367e-06
Iter: 676 loss: 1.17836021e-06
Iter: 677 loss: 1.17455011e-06
Iter: 678 loss: 1.17410923e-06
Iter: 679 loss: 1.1754953e-06
Iter: 680 loss: 1.17392551e-06
Iter: 681 loss: 1.17341483e-06
Iter: 682 loss: 1.17768218e-06
Iter: 683 loss: 1.17338118e-06
Iter: 684 loss: 1.17311743e-06
Iter: 685 loss: 1.17227842e-06
Iter: 686 loss: 1.17622562e-06
Iter: 687 loss: 1.17215961e-06
Iter: 688 loss: 1.17131094e-06
Iter: 689 loss: 1.1751265e-06
Iter: 690 loss: 1.1709833e-06
Iter: 691 loss: 1.17021216e-06
Iter: 692 loss: 1.17089166e-06
Iter: 693 loss: 1.16982324e-06
Iter: 694 loss: 1.16920626e-06
Iter: 695 loss: 1.17101627e-06
Iter: 696 loss: 1.16874958e-06
Iter: 697 loss: 1.16824299e-06
Iter: 698 loss: 1.1689342e-06
Iter: 699 loss: 1.16798628e-06
Iter: 700 loss: 1.16730598e-06
Iter: 701 loss: 1.16761203e-06
Iter: 702 loss: 1.16689023e-06
Iter: 703 loss: 1.1661466e-06
Iter: 704 loss: 1.16947342e-06
Iter: 705 loss: 1.16602575e-06
Iter: 706 loss: 1.16544641e-06
Iter: 707 loss: 1.16573324e-06
Iter: 708 loss: 1.16524416e-06
Iter: 709 loss: 1.1646282e-06
Iter: 710 loss: 1.16778426e-06
Iter: 711 loss: 1.16457079e-06
Iter: 712 loss: 1.16423064e-06
Iter: 713 loss: 1.1672962e-06
Iter: 714 loss: 1.16395563e-06
Iter: 715 loss: 1.16392221e-06
Iter: 716 loss: 1.16402487e-06
Iter: 717 loss: 1.16407273e-06
Iter: 718 loss: 1.16393414e-06
Iter: 719 loss: 1.16409365e-06
Iter: 720 loss: 1.16383899e-06
Iter: 721 loss: 1.1638997e-06
Iter: 722 loss: 1.16395734e-06
Iter: 723 loss: 1.16384172e-06
Iter: 724 loss: 1.16393812e-06
Iter: 725 loss: 1.1640185e-06
Iter: 726 loss: 1.16395245e-06
Iter: 727 loss: 1.16402543e-06
Iter: 728 loss: 1.16398519e-06
Iter: 729 loss: 1.16395313e-06
Iter: 730 loss: 1.16400474e-06
Iter: 731 loss: 1.1639404e-06
Iter: 732 loss: 1.1639363e-06
Iter: 733 loss: 1.16397291e-06
Iter: 734 loss: 1.16392198e-06
Iter: 735 loss: 1.16394813e-06
Iter: 736 loss: 1.16395313e-06
Iter: 737 loss: 1.16396131e-06
Iter: 738 loss: 1.16396131e-06
Iter: 739 loss: 1.16395904e-06
Iter: 740 loss: 1.16395859e-06
Iter: 741 loss: 1.16395859e-06
Iter: 742 loss: 1.16395313e-06
Iter: 743 loss: 1.16395859e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.4_8000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a732378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a7277b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a7322f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a75a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a68dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a68d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a632ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a5be730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a5be048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a58af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a58a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a588ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a542d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a520268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a5067b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a570378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a4d8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a46df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a46bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a46d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a43c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a3ef268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a43ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a381c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa67a381f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa63dea7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa63deaed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa63dea72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa63de64158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa63de940d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa63de1a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa63de00158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa63de00510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa63de3bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa6186ae1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa618689c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.95554957e-05
Iter: 2 loss: 0.00263365218
Iter: 3 loss: 4.3822587e-05
Iter: 4 loss: 3.75228119e-05
Iter: 5 loss: 5.63489e-05
Iter: 6 loss: 3.5589419e-05
Iter: 7 loss: 3.15489378e-05
Iter: 8 loss: 2.62935027e-05
Iter: 9 loss: 2.59489352e-05
Iter: 10 loss: 2.21554819e-05
Iter: 11 loss: 2.16974986e-05
Iter: 12 loss: 1.89789753e-05
Iter: 13 loss: 1.53136207e-05
Iter: 14 loss: 2.2360884e-05
Iter: 15 loss: 1.37808165e-05
Iter: 16 loss: 1.20669165e-05
Iter: 17 loss: 2.06798104e-05
Iter: 18 loss: 1.17791715e-05
Iter: 19 loss: 1.11897079e-05
Iter: 20 loss: 1.08031782e-05
Iter: 21 loss: 1.05781564e-05
Iter: 22 loss: 9.85833594e-06
Iter: 23 loss: 9.64805167e-06
Iter: 24 loss: 9.21463e-06
Iter: 25 loss: 8.4715939e-06
Iter: 26 loss: 1.00224224e-05
Iter: 27 loss: 8.17672662e-06
Iter: 28 loss: 7.58900387e-06
Iter: 29 loss: 1.03537313e-05
Iter: 30 loss: 7.48030925e-06
Iter: 31 loss: 6.85356463e-06
Iter: 32 loss: 8.85225199e-06
Iter: 33 loss: 6.6751445e-06
Iter: 34 loss: 6.24304175e-06
Iter: 35 loss: 8.3712539e-06
Iter: 36 loss: 6.16943453e-06
Iter: 37 loss: 5.88978037e-06
Iter: 38 loss: 6.30328941e-06
Iter: 39 loss: 5.7547586e-06
Iter: 40 loss: 5.62013884e-06
Iter: 41 loss: 5.61315755e-06
Iter: 42 loss: 5.42412636e-06
Iter: 43 loss: 5.54312555e-06
Iter: 44 loss: 5.3036606e-06
Iter: 45 loss: 5.24182269e-06
Iter: 46 loss: 5.08040648e-06
Iter: 47 loss: 6.29904434e-06
Iter: 48 loss: 5.04814216e-06
Iter: 49 loss: 4.91288574e-06
Iter: 50 loss: 4.89705144e-06
Iter: 51 loss: 4.79029086e-06
Iter: 52 loss: 5.45379316e-06
Iter: 53 loss: 4.77746062e-06
Iter: 54 loss: 4.72417651e-06
Iter: 55 loss: 4.66414758e-06
Iter: 56 loss: 4.65645462e-06
Iter: 57 loss: 4.55729923e-06
Iter: 58 loss: 4.51358028e-06
Iter: 59 loss: 4.4631297e-06
Iter: 60 loss: 4.31192575e-06
Iter: 61 loss: 5.01855538e-06
Iter: 62 loss: 4.28422936e-06
Iter: 63 loss: 4.20825654e-06
Iter: 64 loss: 4.7915e-06
Iter: 65 loss: 4.20261904e-06
Iter: 66 loss: 4.12175086e-06
Iter: 67 loss: 4.26467432e-06
Iter: 68 loss: 4.08565711e-06
Iter: 69 loss: 4.01378838e-06
Iter: 70 loss: 4.13919588e-06
Iter: 71 loss: 3.98222e-06
Iter: 72 loss: 3.9041629e-06
Iter: 73 loss: 4.12789086e-06
Iter: 74 loss: 3.87944874e-06
Iter: 75 loss: 3.89874276e-06
Iter: 76 loss: 3.8461867e-06
Iter: 77 loss: 3.82096459e-06
Iter: 78 loss: 3.73965395e-06
Iter: 79 loss: 3.8409712e-06
Iter: 80 loss: 3.6785209e-06
Iter: 81 loss: 3.59626029e-06
Iter: 82 loss: 3.78813911e-06
Iter: 83 loss: 3.56606188e-06
Iter: 84 loss: 3.57426052e-06
Iter: 85 loss: 3.53415203e-06
Iter: 86 loss: 3.50155119e-06
Iter: 87 loss: 3.43787542e-06
Iter: 88 loss: 4.68818689e-06
Iter: 89 loss: 3.43775582e-06
Iter: 90 loss: 3.38345239e-06
Iter: 91 loss: 3.69759141e-06
Iter: 92 loss: 3.37586766e-06
Iter: 93 loss: 3.34112542e-06
Iter: 94 loss: 3.29208387e-06
Iter: 95 loss: 3.29029399e-06
Iter: 96 loss: 3.23726795e-06
Iter: 97 loss: 3.58112288e-06
Iter: 98 loss: 3.23170548e-06
Iter: 99 loss: 3.19598644e-06
Iter: 100 loss: 3.55107636e-06
Iter: 101 loss: 3.19502033e-06
Iter: 102 loss: 3.15942498e-06
Iter: 103 loss: 3.13796954e-06
Iter: 104 loss: 3.1232903e-06
Iter: 105 loss: 3.08968424e-06
Iter: 106 loss: 3.43976444e-06
Iter: 107 loss: 3.08850281e-06
Iter: 108 loss: 3.06708694e-06
Iter: 109 loss: 3.11897043e-06
Iter: 110 loss: 3.05949675e-06
Iter: 111 loss: 3.03258548e-06
Iter: 112 loss: 3.37937217e-06
Iter: 113 loss: 3.03205798e-06
Iter: 114 loss: 3.02036779e-06
Iter: 115 loss: 2.98265331e-06
Iter: 116 loss: 3.07467826e-06
Iter: 117 loss: 2.96157e-06
Iter: 118 loss: 2.92397112e-06
Iter: 119 loss: 2.99636758e-06
Iter: 120 loss: 2.90827393e-06
Iter: 121 loss: 2.888984e-06
Iter: 122 loss: 2.88111141e-06
Iter: 123 loss: 2.8653883e-06
Iter: 124 loss: 2.83365443e-06
Iter: 125 loss: 3.43809597e-06
Iter: 126 loss: 2.83350209e-06
Iter: 127 loss: 2.80472341e-06
Iter: 128 loss: 2.90162257e-06
Iter: 129 loss: 2.7970159e-06
Iter: 130 loss: 2.76474316e-06
Iter: 131 loss: 2.80973063e-06
Iter: 132 loss: 2.74872764e-06
Iter: 133 loss: 2.71403e-06
Iter: 134 loss: 2.87499506e-06
Iter: 135 loss: 2.70756959e-06
Iter: 136 loss: 2.68205395e-06
Iter: 137 loss: 2.70963028e-06
Iter: 138 loss: 2.66830739e-06
Iter: 139 loss: 2.6352584e-06
Iter: 140 loss: 2.7320948e-06
Iter: 141 loss: 2.62547883e-06
Iter: 142 loss: 2.59502735e-06
Iter: 143 loss: 2.8730326e-06
Iter: 144 loss: 2.59360013e-06
Iter: 145 loss: 2.57868669e-06
Iter: 146 loss: 2.6400553e-06
Iter: 147 loss: 2.57569e-06
Iter: 148 loss: 2.55574196e-06
Iter: 149 loss: 2.66536244e-06
Iter: 150 loss: 2.5526258e-06
Iter: 151 loss: 2.54388669e-06
Iter: 152 loss: 2.52039399e-06
Iter: 153 loss: 2.6736036e-06
Iter: 154 loss: 2.51447364e-06
Iter: 155 loss: 2.49343384e-06
Iter: 156 loss: 2.67288578e-06
Iter: 157 loss: 2.49202208e-06
Iter: 158 loss: 2.47867638e-06
Iter: 159 loss: 2.49517257e-06
Iter: 160 loss: 2.47163052e-06
Iter: 161 loss: 2.46947866e-06
Iter: 162 loss: 2.46375885e-06
Iter: 163 loss: 2.45668843e-06
Iter: 164 loss: 2.4522285e-06
Iter: 165 loss: 2.44945159e-06
Iter: 166 loss: 2.42810256e-06
Iter: 167 loss: 2.44804141e-06
Iter: 168 loss: 2.41590078e-06
Iter: 169 loss: 2.38962821e-06
Iter: 170 loss: 2.45920046e-06
Iter: 171 loss: 2.38075336e-06
Iter: 172 loss: 2.36472897e-06
Iter: 173 loss: 2.60767501e-06
Iter: 174 loss: 2.36471305e-06
Iter: 175 loss: 2.34976e-06
Iter: 176 loss: 2.33588389e-06
Iter: 177 loss: 2.33257765e-06
Iter: 178 loss: 2.31963531e-06
Iter: 179 loss: 2.31936065e-06
Iter: 180 loss: 2.31699687e-06
Iter: 181 loss: 2.31458125e-06
Iter: 182 loss: 2.31114336e-06
Iter: 183 loss: 2.30003457e-06
Iter: 184 loss: 2.3395371e-06
Iter: 185 loss: 2.29539501e-06
Iter: 186 loss: 2.27944292e-06
Iter: 187 loss: 2.28241061e-06
Iter: 188 loss: 2.26757493e-06
Iter: 189 loss: 2.25141093e-06
Iter: 190 loss: 2.29407988e-06
Iter: 191 loss: 2.24620362e-06
Iter: 192 loss: 2.23188727e-06
Iter: 193 loss: 2.43285149e-06
Iter: 194 loss: 2.23172924e-06
Iter: 195 loss: 2.21876849e-06
Iter: 196 loss: 2.29536931e-06
Iter: 197 loss: 2.21670507e-06
Iter: 198 loss: 2.20724496e-06
Iter: 199 loss: 2.20975176e-06
Iter: 200 loss: 2.20040329e-06
Iter: 201 loss: 2.19166736e-06
Iter: 202 loss: 2.17423553e-06
Iter: 203 loss: 2.5122074e-06
Iter: 204 loss: 2.17407433e-06
Iter: 205 loss: 2.15814498e-06
Iter: 206 loss: 2.33030323e-06
Iter: 207 loss: 2.15754108e-06
Iter: 208 loss: 2.1482947e-06
Iter: 209 loss: 2.1687315e-06
Iter: 210 loss: 2.14451666e-06
Iter: 211 loss: 2.13102021e-06
Iter: 212 loss: 2.1536689e-06
Iter: 213 loss: 2.12471e-06
Iter: 214 loss: 2.13935436e-06
Iter: 215 loss: 2.12142459e-06
Iter: 216 loss: 2.11835732e-06
Iter: 217 loss: 2.11312135e-06
Iter: 218 loss: 2.23758252e-06
Iter: 219 loss: 2.11310225e-06
Iter: 220 loss: 2.10786084e-06
Iter: 221 loss: 2.10388612e-06
Iter: 222 loss: 2.10225721e-06
Iter: 223 loss: 2.09063819e-06
Iter: 224 loss: 2.076805e-06
Iter: 225 loss: 2.0755142e-06
Iter: 226 loss: 2.064623e-06
Iter: 227 loss: 2.23539678e-06
Iter: 228 loss: 2.06469349e-06
Iter: 229 loss: 2.05574088e-06
Iter: 230 loss: 2.09741847e-06
Iter: 231 loss: 2.05419974e-06
Iter: 232 loss: 2.0414227e-06
Iter: 233 loss: 2.07348262e-06
Iter: 234 loss: 2.03700688e-06
Iter: 235 loss: 2.02753699e-06
Iter: 236 loss: 2.03528862e-06
Iter: 237 loss: 2.02180217e-06
Iter: 238 loss: 2.01357034e-06
Iter: 239 loss: 2.02177262e-06
Iter: 240 loss: 2.00881323e-06
Iter: 241 loss: 1.99642272e-06
Iter: 242 loss: 2.00381874e-06
Iter: 243 loss: 1.98865223e-06
Iter: 244 loss: 1.9782583e-06
Iter: 245 loss: 2.01404509e-06
Iter: 246 loss: 1.97538156e-06
Iter: 247 loss: 1.96549718e-06
Iter: 248 loss: 1.99354713e-06
Iter: 249 loss: 1.96213637e-06
Iter: 250 loss: 1.96810288e-06
Iter: 251 loss: 1.95830307e-06
Iter: 252 loss: 1.95584721e-06
Iter: 253 loss: 1.94991298e-06
Iter: 254 loss: 1.98477073e-06
Iter: 255 loss: 1.94816289e-06
Iter: 256 loss: 1.94210497e-06
Iter: 257 loss: 1.94368226e-06
Iter: 258 loss: 1.93745041e-06
Iter: 259 loss: 1.92917469e-06
Iter: 260 loss: 1.92793163e-06
Iter: 261 loss: 1.92258267e-06
Iter: 262 loss: 1.91698837e-06
Iter: 263 loss: 1.9164911e-06
Iter: 264 loss: 1.91308163e-06
Iter: 265 loss: 1.95867347e-06
Iter: 266 loss: 1.91302661e-06
Iter: 267 loss: 1.90858214e-06
Iter: 268 loss: 1.89819889e-06
Iter: 269 loss: 2.0109137e-06
Iter: 270 loss: 1.89714274e-06
Iter: 271 loss: 1.89123239e-06
Iter: 272 loss: 1.96934752e-06
Iter: 273 loss: 1.89125035e-06
Iter: 274 loss: 1.88643639e-06
Iter: 275 loss: 1.88448644e-06
Iter: 276 loss: 1.88190597e-06
Iter: 277 loss: 1.8734994e-06
Iter: 278 loss: 1.87167348e-06
Iter: 279 loss: 1.86666193e-06
Iter: 280 loss: 1.85787292e-06
Iter: 281 loss: 1.95438088e-06
Iter: 282 loss: 1.85781619e-06
Iter: 283 loss: 1.85735212e-06
Iter: 284 loss: 1.85520821e-06
Iter: 285 loss: 1.85208455e-06
Iter: 286 loss: 1.84560531e-06
Iter: 287 loss: 1.95158918e-06
Iter: 288 loss: 1.845631e-06
Iter: 289 loss: 1.84103897e-06
Iter: 290 loss: 1.84101873e-06
Iter: 291 loss: 1.83760608e-06
Iter: 292 loss: 1.83085217e-06
Iter: 293 loss: 1.84736075e-06
Iter: 294 loss: 1.82850033e-06
Iter: 295 loss: 1.82016379e-06
Iter: 296 loss: 1.82559234e-06
Iter: 297 loss: 1.81519454e-06
Iter: 298 loss: 1.81397945e-06
Iter: 299 loss: 1.81245787e-06
Iter: 300 loss: 1.80952395e-06
Iter: 301 loss: 1.81455562e-06
Iter: 302 loss: 1.80822212e-06
Iter: 303 loss: 1.80624329e-06
Iter: 304 loss: 1.8013053e-06
Iter: 305 loss: 1.87904402e-06
Iter: 306 loss: 1.80135567e-06
Iter: 307 loss: 1.79498693e-06
Iter: 308 loss: 1.8138046e-06
Iter: 309 loss: 1.79305562e-06
Iter: 310 loss: 1.78708285e-06
Iter: 311 loss: 1.81830728e-06
Iter: 312 loss: 1.78627499e-06
Iter: 313 loss: 1.78232426e-06
Iter: 314 loss: 1.77709808e-06
Iter: 315 loss: 1.77668585e-06
Iter: 316 loss: 1.77107927e-06
Iter: 317 loss: 1.84986743e-06
Iter: 318 loss: 1.77126731e-06
Iter: 319 loss: 1.76727792e-06
Iter: 320 loss: 1.76687468e-06
Iter: 321 loss: 1.76609728e-06
Iter: 322 loss: 1.76317212e-06
Iter: 323 loss: 1.77452512e-06
Iter: 324 loss: 1.76179469e-06
Iter: 325 loss: 1.75677087e-06
Iter: 326 loss: 1.76459901e-06
Iter: 327 loss: 1.75427419e-06
Iter: 328 loss: 1.75053765e-06
Iter: 329 loss: 1.77104505e-06
Iter: 330 loss: 1.74987008e-06
Iter: 331 loss: 1.74694151e-06
Iter: 332 loss: 1.75742855e-06
Iter: 333 loss: 1.74609124e-06
Iter: 334 loss: 1.74237243e-06
Iter: 335 loss: 1.77125321e-06
Iter: 336 loss: 1.74209868e-06
Iter: 337 loss: 1.7393611e-06
Iter: 338 loss: 1.73593446e-06
Iter: 339 loss: 1.73556873e-06
Iter: 340 loss: 1.73197429e-06
Iter: 341 loss: 1.7353301e-06
Iter: 342 loss: 1.7300149e-06
Iter: 343 loss: 1.7244588e-06
Iter: 344 loss: 1.73101648e-06
Iter: 345 loss: 1.72145906e-06
Iter: 346 loss: 1.71511704e-06
Iter: 347 loss: 1.7300506e-06
Iter: 348 loss: 1.71276724e-06
Iter: 349 loss: 1.7071e-06
Iter: 350 loss: 1.71159149e-06
Iter: 351 loss: 1.70369117e-06
Iter: 352 loss: 1.69799762e-06
Iter: 353 loss: 1.78533298e-06
Iter: 354 loss: 1.69788973e-06
Iter: 355 loss: 1.69352438e-06
Iter: 356 loss: 1.69334123e-06
Iter: 357 loss: 1.69238785e-06
Iter: 358 loss: 1.68923566e-06
Iter: 359 loss: 1.68721954e-06
Iter: 360 loss: 1.68493227e-06
Iter: 361 loss: 1.67642406e-06
Iter: 362 loss: 1.70145347e-06
Iter: 363 loss: 1.67351743e-06
Iter: 364 loss: 1.66859411e-06
Iter: 365 loss: 1.66837719e-06
Iter: 366 loss: 1.66614268e-06
Iter: 367 loss: 1.66608311e-06
Iter: 368 loss: 1.66363088e-06
Iter: 369 loss: 1.66148743e-06
Iter: 370 loss: 1.66056657e-06
Iter: 371 loss: 1.65773486e-06
Iter: 372 loss: 1.65681831e-06
Iter: 373 loss: 1.65500228e-06
Iter: 374 loss: 1.65128449e-06
Iter: 375 loss: 1.67149108e-06
Iter: 376 loss: 1.65090751e-06
Iter: 377 loss: 1.64630308e-06
Iter: 378 loss: 1.64914456e-06
Iter: 379 loss: 1.64324058e-06
Iter: 380 loss: 1.63908953e-06
Iter: 381 loss: 1.65728034e-06
Iter: 382 loss: 1.63813343e-06
Iter: 383 loss: 1.63483764e-06
Iter: 384 loss: 1.64030337e-06
Iter: 385 loss: 1.6331137e-06
Iter: 386 loss: 1.63364234e-06
Iter: 387 loss: 1.63132631e-06
Iter: 388 loss: 1.62992399e-06
Iter: 389 loss: 1.6254736e-06
Iter: 390 loss: 1.64998221e-06
Iter: 391 loss: 1.62432707e-06
Iter: 392 loss: 1.62024332e-06
Iter: 393 loss: 1.63073946e-06
Iter: 394 loss: 1.61882838e-06
Iter: 395 loss: 1.61500748e-06
Iter: 396 loss: 1.6191982e-06
Iter: 397 loss: 1.61265143e-06
Iter: 398 loss: 1.60899071e-06
Iter: 399 loss: 1.64169012e-06
Iter: 400 loss: 1.60883747e-06
Iter: 401 loss: 1.60843501e-06
Iter: 402 loss: 1.60758373e-06
Iter: 403 loss: 1.60645016e-06
Iter: 404 loss: 1.60495745e-06
Iter: 405 loss: 1.60474917e-06
Iter: 406 loss: 1.60255615e-06
Iter: 407 loss: 1.59956357e-06
Iter: 408 loss: 1.59937736e-06
Iter: 409 loss: 1.59625222e-06
Iter: 410 loss: 1.60474065e-06
Iter: 411 loss: 1.59548244e-06
Iter: 412 loss: 1.5922011e-06
Iter: 413 loss: 1.59271212e-06
Iter: 414 loss: 1.58990952e-06
Iter: 415 loss: 1.5858559e-06
Iter: 416 loss: 1.59453623e-06
Iter: 417 loss: 1.58432704e-06
Iter: 418 loss: 1.58111914e-06
Iter: 419 loss: 1.58076182e-06
Iter: 420 loss: 1.57916224e-06
Iter: 421 loss: 1.57935119e-06
Iter: 422 loss: 1.57850513e-06
Iter: 423 loss: 1.57633815e-06
Iter: 424 loss: 1.59186209e-06
Iter: 425 loss: 1.57586953e-06
Iter: 426 loss: 1.57292925e-06
Iter: 427 loss: 1.5723017e-06
Iter: 428 loss: 1.57023214e-06
Iter: 429 loss: 1.56573265e-06
Iter: 430 loss: 1.58463683e-06
Iter: 431 loss: 1.56491342e-06
Iter: 432 loss: 1.56240492e-06
Iter: 433 loss: 1.57873797e-06
Iter: 434 loss: 1.56193562e-06
Iter: 435 loss: 1.56082501e-06
Iter: 436 loss: 1.56082115e-06
Iter: 437 loss: 1.55932878e-06
Iter: 438 loss: 1.55591874e-06
Iter: 439 loss: 1.60082834e-06
Iter: 440 loss: 1.55567659e-06
Iter: 441 loss: 1.55253679e-06
Iter: 442 loss: 1.5645893e-06
Iter: 443 loss: 1.55225075e-06
Iter: 444 loss: 1.54978511e-06
Iter: 445 loss: 1.55274211e-06
Iter: 446 loss: 1.54880286e-06
Iter: 447 loss: 1.54549105e-06
Iter: 448 loss: 1.54548957e-06
Iter: 449 loss: 1.54295549e-06
Iter: 450 loss: 1.54014072e-06
Iter: 451 loss: 1.55545604e-06
Iter: 452 loss: 1.53970882e-06
Iter: 453 loss: 1.54024212e-06
Iter: 454 loss: 1.53822793e-06
Iter: 455 loss: 1.5369568e-06
Iter: 456 loss: 1.53452197e-06
Iter: 457 loss: 1.58256728e-06
Iter: 458 loss: 1.53454823e-06
Iter: 459 loss: 1.53226938e-06
Iter: 460 loss: 1.53811447e-06
Iter: 461 loss: 1.53167241e-06
Iter: 462 loss: 1.52974064e-06
Iter: 463 loss: 1.53434758e-06
Iter: 464 loss: 1.52917914e-06
Iter: 465 loss: 1.52722839e-06
Iter: 466 loss: 1.52839436e-06
Iter: 467 loss: 1.52625921e-06
Iter: 468 loss: 1.5247366e-06
Iter: 469 loss: 1.5245821e-06
Iter: 470 loss: 1.52296025e-06
Iter: 471 loss: 1.52366113e-06
Iter: 472 loss: 1.52210396e-06
Iter: 473 loss: 1.52086341e-06
Iter: 474 loss: 1.51958318e-06
Iter: 475 loss: 1.519232e-06
Iter: 476 loss: 1.51708332e-06
Iter: 477 loss: 1.5165341e-06
Iter: 478 loss: 1.5150506e-06
Iter: 479 loss: 1.51206677e-06
Iter: 480 loss: 1.53401265e-06
Iter: 481 loss: 1.51204654e-06
Iter: 482 loss: 1.50987637e-06
Iter: 483 loss: 1.50716187e-06
Iter: 484 loss: 1.50650885e-06
Iter: 485 loss: 1.50665448e-06
Iter: 486 loss: 1.505206e-06
Iter: 487 loss: 1.50339872e-06
Iter: 488 loss: 1.50956976e-06
Iter: 489 loss: 1.50286212e-06
Iter: 490 loss: 1.50214373e-06
Iter: 491 loss: 1.50034202e-06
Iter: 492 loss: 1.51984625e-06
Iter: 493 loss: 1.50005189e-06
Iter: 494 loss: 1.49734524e-06
Iter: 495 loss: 1.49823552e-06
Iter: 496 loss: 1.4952393e-06
Iter: 497 loss: 1.49280208e-06
Iter: 498 loss: 1.52392022e-06
Iter: 499 loss: 1.49288098e-06
Iter: 500 loss: 1.49075777e-06
Iter: 501 loss: 1.48970116e-06
Iter: 502 loss: 1.48882225e-06
Iter: 503 loss: 1.48665663e-06
Iter: 504 loss: 1.48637298e-06
Iter: 505 loss: 1.48471668e-06
Iter: 506 loss: 1.48282857e-06
Iter: 507 loss: 1.48269351e-06
Iter: 508 loss: 1.48075867e-06
Iter: 509 loss: 1.48283084e-06
Iter: 510 loss: 1.47995502e-06
Iter: 511 loss: 1.47744868e-06
Iter: 512 loss: 1.47470985e-06
Iter: 513 loss: 1.47431467e-06
Iter: 514 loss: 1.47022115e-06
Iter: 515 loss: 1.50239771e-06
Iter: 516 loss: 1.46985644e-06
Iter: 517 loss: 1.46760908e-06
Iter: 518 loss: 1.46956e-06
Iter: 519 loss: 1.46621153e-06
Iter: 520 loss: 1.46355035e-06
Iter: 521 loss: 1.49052096e-06
Iter: 522 loss: 1.46343757e-06
Iter: 523 loss: 1.46134198e-06
Iter: 524 loss: 1.4880552e-06
Iter: 525 loss: 1.46130697e-06
Iter: 526 loss: 1.4607981e-06
Iter: 527 loss: 1.45900367e-06
Iter: 528 loss: 1.45897934e-06
Iter: 529 loss: 1.45737692e-06
Iter: 530 loss: 1.45531033e-06
Iter: 531 loss: 1.45537774e-06
Iter: 532 loss: 1.45399076e-06
Iter: 533 loss: 1.47206788e-06
Iter: 534 loss: 1.45411627e-06
Iter: 535 loss: 1.45355762e-06
Iter: 536 loss: 1.45824401e-06
Iter: 537 loss: 1.45338925e-06
Iter: 538 loss: 1.45233844e-06
Iter: 539 loss: 1.45212039e-06
Iter: 540 loss: 1.45177137e-06
Iter: 541 loss: 1.45058971e-06
Iter: 542 loss: 1.44950968e-06
Iter: 543 loss: 1.44925946e-06
Iter: 544 loss: 1.44703142e-06
Iter: 545 loss: 1.45402441e-06
Iter: 546 loss: 1.4463983e-06
Iter: 547 loss: 1.44396336e-06
Iter: 548 loss: 1.45570698e-06
Iter: 549 loss: 1.44361638e-06
Iter: 550 loss: 1.44171076e-06
Iter: 551 loss: 1.44531987e-06
Iter: 552 loss: 1.44106139e-06
Iter: 553 loss: 1.43915236e-06
Iter: 554 loss: 1.44958142e-06
Iter: 555 loss: 1.43894556e-06
Iter: 556 loss: 1.43905322e-06
Iter: 557 loss: 1.43850332e-06
Iter: 558 loss: 1.43802345e-06
Iter: 559 loss: 1.43668194e-06
Iter: 560 loss: 1.43920795e-06
Iter: 561 loss: 1.43592865e-06
Iter: 562 loss: 1.43410955e-06
Iter: 563 loss: 1.43243892e-06
Iter: 564 loss: 1.43191028e-06
Iter: 565 loss: 1.42984914e-06
Iter: 566 loss: 1.44909109e-06
Iter: 567 loss: 1.42969429e-06
Iter: 568 loss: 1.42868271e-06
Iter: 569 loss: 1.44096794e-06
Iter: 570 loss: 1.4286577e-06
Iter: 571 loss: 1.42733666e-06
Iter: 572 loss: 1.43619923e-06
Iter: 573 loss: 1.42729141e-06
Iter: 574 loss: 1.42663032e-06
Iter: 575 loss: 1.42514136e-06
Iter: 576 loss: 1.44224532e-06
Iter: 577 loss: 1.42519957e-06
Iter: 578 loss: 1.4233508e-06
Iter: 579 loss: 1.42605722e-06
Iter: 580 loss: 1.42225326e-06
Iter: 581 loss: 1.41994872e-06
Iter: 582 loss: 1.43367606e-06
Iter: 583 loss: 1.41947112e-06
Iter: 584 loss: 1.41750797e-06
Iter: 585 loss: 1.42461681e-06
Iter: 586 loss: 1.41686724e-06
Iter: 587 loss: 1.41518376e-06
Iter: 588 loss: 1.41763724e-06
Iter: 589 loss: 1.41463238e-06
Iter: 590 loss: 1.4137222e-06
Iter: 591 loss: 1.41351825e-06
Iter: 592 loss: 1.41273802e-06
Iter: 593 loss: 1.41074077e-06
Iter: 594 loss: 1.449877e-06
Iter: 595 loss: 1.4108432e-06
Iter: 596 loss: 1.40923191e-06
Iter: 597 loss: 1.40940938e-06
Iter: 598 loss: 1.40832287e-06
Iter: 599 loss: 1.40641009e-06
Iter: 600 loss: 1.40672239e-06
Iter: 601 loss: 1.40519387e-06
Iter: 602 loss: 1.40271516e-06
Iter: 603 loss: 1.41555915e-06
Iter: 604 loss: 1.40252666e-06
Iter: 605 loss: 1.40097347e-06
Iter: 606 loss: 1.40267491e-06
Iter: 607 loss: 1.40027248e-06
Iter: 608 loss: 1.39941835e-06
Iter: 609 loss: 1.39917779e-06
Iter: 610 loss: 1.39778717e-06
Iter: 611 loss: 1.39621181e-06
Iter: 612 loss: 1.3962316e-06
Iter: 613 loss: 1.39535553e-06
Iter: 614 loss: 1.39563417e-06
Iter: 615 loss: 1.39465578e-06
Iter: 616 loss: 1.39278745e-06
Iter: 617 loss: 1.39143867e-06
Iter: 618 loss: 1.39074393e-06
Iter: 619 loss: 1.38807548e-06
Iter: 620 loss: 1.41197779e-06
Iter: 621 loss: 1.38790301e-06
Iter: 622 loss: 1.38770167e-06
Iter: 623 loss: 1.38684027e-06
Iter: 624 loss: 1.38594623e-06
Iter: 625 loss: 1.38666314e-06
Iter: 626 loss: 1.38548671e-06
Iter: 627 loss: 1.38465862e-06
Iter: 628 loss: 1.38291443e-06
Iter: 629 loss: 1.41150599e-06
Iter: 630 loss: 1.38285384e-06
Iter: 631 loss: 1.380958e-06
Iter: 632 loss: 1.39030124e-06
Iter: 633 loss: 1.38043288e-06
Iter: 634 loss: 1.37863447e-06
Iter: 635 loss: 1.38464679e-06
Iter: 636 loss: 1.37792915e-06
Iter: 637 loss: 1.37617837e-06
Iter: 638 loss: 1.38360247e-06
Iter: 639 loss: 1.37555867e-06
Iter: 640 loss: 1.37434517e-06
Iter: 641 loss: 1.37430789e-06
Iter: 642 loss: 1.37340078e-06
Iter: 643 loss: 1.3783623e-06
Iter: 644 loss: 1.37315988e-06
Iter: 645 loss: 1.37247343e-06
Iter: 646 loss: 1.37149334e-06
Iter: 647 loss: 1.37131929e-06
Iter: 648 loss: 1.37017469e-06
Iter: 649 loss: 1.37059192e-06
Iter: 650 loss: 1.36922188e-06
Iter: 651 loss: 1.36728931e-06
Iter: 652 loss: 1.36711947e-06
Iter: 653 loss: 1.36550352e-06
Iter: 654 loss: 1.3634052e-06
Iter: 655 loss: 1.38516748e-06
Iter: 656 loss: 1.36310189e-06
Iter: 657 loss: 1.36336951e-06
Iter: 658 loss: 1.36272718e-06
Iter: 659 loss: 1.36203289e-06
Iter: 660 loss: 1.36071253e-06
Iter: 661 loss: 1.38455744e-06
Iter: 662 loss: 1.36044753e-06
Iter: 663 loss: 1.35901939e-06
Iter: 664 loss: 1.35737923e-06
Iter: 665 loss: 1.35721893e-06
Iter: 666 loss: 1.35510982e-06
Iter: 667 loss: 1.36600295e-06
Iter: 668 loss: 1.35490438e-06
Iter: 669 loss: 1.35347796e-06
Iter: 670 loss: 1.3528836e-06
Iter: 671 loss: 1.35219091e-06
Iter: 672 loss: 1.3500055e-06
Iter: 673 loss: 1.37491907e-06
Iter: 674 loss: 1.34981678e-06
Iter: 675 loss: 1.34898653e-06
Iter: 676 loss: 1.34877507e-06
Iter: 677 loss: 1.34842958e-06
Iter: 678 loss: 1.3481515e-06
Iter: 679 loss: 1.34749348e-06
Iter: 680 loss: 1.34651896e-06
Iter: 681 loss: 1.34481718e-06
Iter: 682 loss: 1.34475147e-06
Iter: 683 loss: 1.34255993e-06
Iter: 684 loss: 1.34994821e-06
Iter: 685 loss: 1.34185268e-06
Iter: 686 loss: 1.34024458e-06
Iter: 687 loss: 1.34186439e-06
Iter: 688 loss: 1.33937669e-06
Iter: 689 loss: 1.33801177e-06
Iter: 690 loss: 1.33791571e-06
Iter: 691 loss: 1.33679487e-06
Iter: 692 loss: 1.35512153e-06
Iter: 693 loss: 1.33678361e-06
Iter: 694 loss: 1.33616925e-06
Iter: 695 loss: 1.33540379e-06
Iter: 696 loss: 1.34460765e-06
Iter: 697 loss: 1.33542403e-06
Iter: 698 loss: 1.33428739e-06
Iter: 699 loss: 1.33326944e-06
Iter: 700 loss: 1.33317633e-06
Iter: 701 loss: 1.33089929e-06
Iter: 702 loss: 1.34021275e-06
Iter: 703 loss: 1.33071183e-06
Iter: 704 loss: 1.32905166e-06
Iter: 705 loss: 1.32967602e-06
Iter: 706 loss: 1.32819923e-06
Iter: 707 loss: 1.32633454e-06
Iter: 708 loss: 1.34791878e-06
Iter: 709 loss: 1.32653895e-06
Iter: 710 loss: 1.32522177e-06
Iter: 711 loss: 1.34266668e-06
Iter: 712 loss: 1.32503783e-06
Iter: 713 loss: 1.32450873e-06
Iter: 714 loss: 1.32448668e-06
Iter: 715 loss: 1.32406012e-06
Iter: 716 loss: 1.32340301e-06
Iter: 717 loss: 1.32371679e-06
Iter: 718 loss: 1.32308048e-06
Iter: 719 loss: 1.32216542e-06
Iter: 720 loss: 1.32174137e-06
Iter: 721 loss: 1.32127707e-06
Iter: 722 loss: 1.3200181e-06
Iter: 723 loss: 1.32822811e-06
Iter: 724 loss: 1.31990578e-06
Iter: 725 loss: 1.32027435e-06
Iter: 726 loss: 1.31941817e-06
Iter: 727 loss: 1.31920558e-06
Iter: 728 loss: 1.31830257e-06
Iter: 729 loss: 1.32232572e-06
Iter: 730 loss: 1.31797447e-06
Iter: 731 loss: 1.31681077e-06
Iter: 732 loss: 1.31542606e-06
Iter: 733 loss: 1.31525314e-06
Iter: 734 loss: 1.31391062e-06
Iter: 735 loss: 1.33250342e-06
Iter: 736 loss: 1.31397167e-06
Iter: 737 loss: 1.31322918e-06
Iter: 738 loss: 1.31337288e-06
Iter: 739 loss: 1.31272657e-06
Iter: 740 loss: 1.3114593e-06
Iter: 741 loss: 1.31589354e-06
Iter: 742 loss: 1.31116781e-06
Iter: 743 loss: 1.31040576e-06
Iter: 744 loss: 1.31047227e-06
Iter: 745 loss: 1.30984813e-06
Iter: 746 loss: 1.31093384e-06
Iter: 747 loss: 1.30950912e-06
Iter: 748 loss: 1.309053e-06
Iter: 749 loss: 1.30937906e-06
Iter: 750 loss: 1.30869535e-06
Iter: 751 loss: 1.30800822e-06
Iter: 752 loss: 1.3087481e-06
Iter: 753 loss: 1.30764215e-06
Iter: 754 loss: 1.30693843e-06
Iter: 755 loss: 1.30561102e-06
Iter: 756 loss: 1.30545664e-06
Iter: 757 loss: 1.30392323e-06
Iter: 758 loss: 1.31776926e-06
Iter: 759 loss: 1.30373803e-06
Iter: 760 loss: 1.30447347e-06
Iter: 761 loss: 1.30343426e-06
Iter: 762 loss: 1.30306807e-06
Iter: 763 loss: 1.30250237e-06
Iter: 764 loss: 1.30243291e-06
Iter: 765 loss: 1.30169383e-06
Iter: 766 loss: 1.30019316e-06
Iter: 767 loss: 1.30176591e-06
Iter: 768 loss: 1.29925411e-06
Iter: 769 loss: 1.29848524e-06
Iter: 770 loss: 1.298499e-06
Iter: 771 loss: 1.29785928e-06
Iter: 772 loss: 1.29717318e-06
Iter: 773 loss: 1.29702539e-06
Iter: 774 loss: 1.29578916e-06
Iter: 775 loss: 1.29743023e-06
Iter: 776 loss: 1.29517571e-06
Iter: 777 loss: 1.29416742e-06
Iter: 778 loss: 1.30615922e-06
Iter: 779 loss: 1.29424143e-06
Iter: 780 loss: 1.29367822e-06
Iter: 781 loss: 1.2935559e-06
Iter: 782 loss: 1.29309251e-06
Iter: 783 loss: 1.29184332e-06
Iter: 784 loss: 1.31712954e-06
Iter: 785 loss: 1.29174043e-06
Iter: 786 loss: 1.29110174e-06
Iter: 787 loss: 1.29130581e-06
Iter: 788 loss: 1.29044986e-06
Iter: 789 loss: 1.28977035e-06
Iter: 790 loss: 1.28910642e-06
Iter: 791 loss: 1.2888413e-06
Iter: 792 loss: 1.28764907e-06
Iter: 793 loss: 1.29153841e-06
Iter: 794 loss: 1.28742283e-06
Iter: 795 loss: 1.28742943e-06
Iter: 796 loss: 1.28689294e-06
Iter: 797 loss: 1.28663123e-06
Iter: 798 loss: 1.28606939e-06
Iter: 799 loss: 1.29007822e-06
Iter: 800 loss: 1.28599072e-06
Iter: 801 loss: 1.28538784e-06
Iter: 802 loss: 1.2845411e-06
Iter: 803 loss: 1.28464455e-06
Iter: 804 loss: 1.28375154e-06
Iter: 805 loss: 1.28596184e-06
Iter: 806 loss: 1.28371789e-06
Iter: 807 loss: 1.28274803e-06
Iter: 808 loss: 1.2832063e-06
Iter: 809 loss: 1.28221268e-06
Iter: 810 loss: 1.28113322e-06
Iter: 811 loss: 1.28253305e-06
Iter: 812 loss: 1.28068064e-06
Iter: 813 loss: 1.28001477e-06
Iter: 814 loss: 1.28201725e-06
Iter: 815 loss: 1.2799469e-06
Iter: 816 loss: 1.27895521e-06
Iter: 817 loss: 1.27957674e-06
Iter: 818 loss: 1.27843759e-06
Iter: 819 loss: 1.27773365e-06
Iter: 820 loss: 1.28144018e-06
Iter: 821 loss: 1.27767589e-06
Iter: 822 loss: 1.27727276e-06
Iter: 823 loss: 1.28080069e-06
Iter: 824 loss: 1.27710689e-06
Iter: 825 loss: 1.27664634e-06
Iter: 826 loss: 1.27589465e-06
Iter: 827 loss: 1.29551e-06
Iter: 828 loss: 1.27582973e-06
Iter: 829 loss: 1.27483281e-06
Iter: 830 loss: 1.27957912e-06
Iter: 831 loss: 1.27462499e-06
Iter: 832 loss: 1.27515136e-06
Iter: 833 loss: 1.27465546e-06
Iter: 834 loss: 1.27445753e-06
Iter: 835 loss: 1.27464159e-06
Iter: 836 loss: 1.27469389e-06
Iter: 837 loss: 1.27455041e-06
Iter: 838 loss: 1.27451392e-06
Iter: 839 loss: 1.27455814e-06
Iter: 840 loss: 1.27453666e-06
Iter: 841 loss: 1.27460203e-06
Iter: 842 loss: 1.27465307e-06
Iter: 843 loss: 1.27463295e-06
Iter: 844 loss: 1.27453427e-06
Iter: 845 loss: 1.27456883e-06
Iter: 846 loss: 1.27464796e-06
Iter: 847 loss: 1.27456428e-06
Iter: 848 loss: 1.27462681e-06
Iter: 849 loss: 1.27458156e-06
Iter: 850 loss: 1.27463204e-06
Iter: 851 loss: 1.27459589e-06
Iter: 852 loss: 1.274601e-06
Iter: 853 loss: 1.27460476e-06
Iter: 854 loss: 1.2746309e-06
Iter: 855 loss: 1.27463045e-06
Iter: 856 loss: 1.27463113e-06
Iter: 857 loss: 1.27460498e-06
Iter: 858 loss: 1.27463113e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8
+ date
Mon Nov  9 08:05:51 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/500_500_500_500_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_1000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_1000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d82f2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d82a0bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d8275ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d82756a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d836e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d820e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d81ef8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d81ef048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d8234bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d81c1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d8234598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d8177e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d8131598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d82349d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d80fe8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d80ae9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d806c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d806ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88d8021bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c01fdc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c01fd9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c01af378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c01afbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c0174e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c01978c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c019eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c01436a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c0143840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c00e0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c00b57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c00d1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c00d1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c0093730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88c003bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88747ca2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f88747f5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 412.115967
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Traceback (most recent call last):
  File "biholoNN_train.py", line 172, in <module>
    results = tfp.optimizer.lbfgs_minimize(value_and_gradients_function=train_func, initial_position=init_params, max_iterations=max_epochs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 287, in minimize
    parallel_iterations=parallel_iterations)[0]
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 574, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2499, in while_loop_v2
    return_same_structure=True)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2735, in while_loop
    loop_vars = body(*loop_vars)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 260, in _body
    max_line_search_iterations)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 156, in line_search_step
    max_iterations=max_iterations)  # No search needed for these.
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 259, in hager_zhang
    threshold_use_approximate_wolfe_condition)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 609, in _prepare_args
    val_initial = value_and_gradients_function(initial_step_size)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 251, in _restricted_func
    objective_value, gradient = value_and_gradients_function(pt)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 780, in __call__
    result = self._call(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 814, in _call
    results = self._stateful_fn(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 550, in call
    ctx=ctx)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
	 [[Sum_1/_34]]
  (1) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_f_16876]

Function call stack:
f -> f

+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_4000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_4000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d81ec378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d81c99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d823a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d8157158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d81570d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d8157598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d81572f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d805eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d805e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d802f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d802fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d802fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d8049d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d27a50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d2752158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d2766d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d27b7ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d27b7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d26ca9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d2684a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d26a6048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d26442f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d26406a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d260be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d260bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d260b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d2586f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12d260ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12820b7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12820cc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12820df598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f128209f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1282097950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1282053a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f12820032f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1282024c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2266.77393
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Traceback (most recent call last):
  File "biholoNN_train.py", line 172, in <module>
    results = tfp.optimizer.lbfgs_minimize(value_and_gradients_function=train_func, initial_position=init_params, max_iterations=max_epochs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 287, in minimize
    parallel_iterations=parallel_iterations)[0]
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 574, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2499, in while_loop_v2
    return_same_structure=True)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2735, in while_loop
    loop_vars = body(*loop_vars)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 260, in _body
    max_line_search_iterations)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 156, in line_search_step
    max_iterations=max_iterations)  # No search needed for these.
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 259, in hager_zhang
    threshold_use_approximate_wolfe_condition)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 609, in _prepare_args
    val_initial = value_and_gradients_function(initial_step_size)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 251, in _restricted_func
    objective_value, gradient = value_and_gradients_function(pt)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 780, in __call__
    result = self._call(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 814, in _call
    results = self._stateful_fn(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 550, in call
    ctx=ctx)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
	 [[Sum_1/_34]]
  (1) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_f_16876]

Function call stack:
f -> f

+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi2.8_8000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a1a5e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a1af950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a2579d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a2b1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a1c6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a1c6598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a146b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a10ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a10c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a10c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a0c91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a094bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a082950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a06f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a082f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a079730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f5a013bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59faaf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59f77b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59faa158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59f60048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59f022f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59f2d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59edbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59edbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59e8cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59ea1ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59e8c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59dfb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59dc10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f59dcf510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f1290d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f129056a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f1290b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f128dc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f12884f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6419.125
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Traceback (most recent call last):
  File "biholoNN_train.py", line 172, in <module>
    results = tfp.optimizer.lbfgs_minimize(value_and_gradients_function=train_func, initial_position=init_params, max_iterations=max_epochs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 287, in minimize
    parallel_iterations=parallel_iterations)[0]
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 574, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2499, in while_loop_v2
    return_same_structure=True)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2735, in while_loop
    loop_vars = body(*loop_vars)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 260, in _body
    max_line_search_iterations)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 156, in line_search_step
    max_iterations=max_iterations)  # No search needed for these.
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 259, in hager_zhang
    threshold_use_approximate_wolfe_condition)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 609, in _prepare_args
    val_initial = value_and_gradients_function(initial_step_size)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 251, in _restricted_func
    objective_value, gradient = value_and_gradients_function(pt)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 780, in __call__
    result = self._call(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 814, in _call
    results = self._stateful_fn(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 550, in call
    ctx=ctx)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
	 [[Sum_1/_34]]
  (1) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_f_16876]

Function call stack:
f -> f

++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi2.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3
+ date
Mon Nov  9 08:14:08 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/500_500_500_500_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_1000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 3 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_1000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c1cae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c1dce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c155d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c155730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c2796a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c120840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c151598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c1521e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c142950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c0576a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c084c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c094268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f232c041158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2325fdbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2325f93a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2325fadc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2325f602f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2325f608c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22ebab8bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22eba75840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22eba75620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22eba2b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22eba2bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22eb9f5e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22eba0d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22eba1db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22eba1d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22eb9dfd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c41476a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c40e9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c4147400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c41471e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c40b99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c4063b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c40142f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c4043f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1967.14185
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Traceback (most recent call last):
  File "biholoNN_train.py", line 172, in <module>
    results = tfp.optimizer.lbfgs_minimize(value_and_gradients_function=train_func, initial_position=init_params, max_iterations=max_epochs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 287, in minimize
    parallel_iterations=parallel_iterations)[0]
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 574, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2499, in while_loop_v2
    return_same_structure=True)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2735, in while_loop
    loop_vars = body(*loop_vars)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 260, in _body
    max_line_search_iterations)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 156, in line_search_step
    max_iterations=max_iterations)  # No search needed for these.
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 259, in hager_zhang
    threshold_use_approximate_wolfe_condition)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 609, in _prepare_args
    val_initial = value_and_gradients_function(initial_step_size)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 251, in _restricted_func
    objective_value, gradient = value_and_gradients_function(pt)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 780, in __call__
    result = self._call(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 814, in _call
    results = self._stateful_fn(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 550, in call
    ctx=ctx)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
	 [[Sum_1/_34]]
  (1) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_f_16876]

Function call stack:
f -> f

+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_4000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 3 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_4000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75287f76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f752879e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7540021b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528763620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75287630d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75286c7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75286c7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528654730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528654048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528609158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75286099d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75285cbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75285ead08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f752859e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f752858ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f752858f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528569bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528511840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528569b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75284dc1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f752849d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75284562f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f752843a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f752846dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528402598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75283e7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528435840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75283e7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75283611e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75283530d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528345510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75283271e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7528337950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75282e09d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f752827e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75282b8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 42748.9023
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Traceback (most recent call last):
  File "biholoNN_train.py", line 172, in <module>
    results = tfp.optimizer.lbfgs_minimize(value_and_gradients_function=train_func, initial_position=init_params, max_iterations=max_epochs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 287, in minimize
    parallel_iterations=parallel_iterations)[0]
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 574, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2499, in while_loop_v2
    return_same_structure=True)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2735, in while_loop
    loop_vars = body(*loop_vars)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 260, in _body
    max_line_search_iterations)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 156, in line_search_step
    max_iterations=max_iterations)  # No search needed for these.
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 259, in hager_zhang
    threshold_use_approximate_wolfe_condition)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 609, in _prepare_args
    val_initial = value_and_gradients_function(initial_step_size)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 251, in _restricted_func
    objective_value, gradient = value_and_gradients_function(pt)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 780, in __call__
    result = self._call(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 814, in _call
    results = self._stateful_fn(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 550, in call
    ctx=ctx)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
	 [[Sum_1/_34]]
  (1) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_f_16876]

Function call stack:
f -> f

+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/500_500_500_500_1 --optimizer lbfgs --function f1 --psi 0 --phi 3 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi0_phi3_8000/ --save_name 500_500_500_500_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49bca27378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49bca3d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49bca27268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49bc9d7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f498922bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f498922b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4989194a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f498913e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f498913ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f498913e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4944cb11e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4944c60bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4944c7c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4944c37268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4944c7cd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4944c8d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4944bcaa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4944be08c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492047cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492045f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492043c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49203f92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49203e96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49203dff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4920397598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4920339f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4920374840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4920339378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49202fb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49202d70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49202f1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492026a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4920247598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f492027a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4920209268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f49201c0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6613.87793
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
Traceback (most recent call last):
  File "biholoNN_train.py", line 172, in <module>
    results = tfp.optimizer.lbfgs_minimize(value_and_gradients_function=train_func, initial_position=init_params, max_iterations=max_epochs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 287, in minimize
    parallel_iterations=parallel_iterations)[0]
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 574, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2499, in while_loop_v2
    return_same_structure=True)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 2735, in while_loop
    loop_vars = body(*loop_vars)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/lbfgs.py", line 260, in _body
    max_line_search_iterations)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 156, in line_search_step
    max_iterations=max_iterations)  # No search needed for these.
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 507, in new_func
    return func(*args, **kwargs)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 259, in hager_zhang
    threshold_use_approximate_wolfe_condition)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/linesearch/hager_zhang.py", line 609, in _prepare_args
    val_initial = value_and_gradients_function(initial_step_size)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow_probability/python/optimizer/bfgs_utils.py", line 251, in _restricted_func
    objective_value, gradient = value_and_gradients_function(pt)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 780, in __call__
    result = self._call(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 814, in _call
    results = self._stateful_fn(*args, **kwds)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 550, in call
    ctx=ctx)
  File "/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
	 [[Sum_1/_34]]
  (1) Invalid argument:  Input is not invertible.
	 [[{{node PartitionedCall/gradients/MatrixDeterminant_grad/MatrixInverse}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_f_16876]

Function call stack:
f -> f

++ basename experiments.final/script75
+ '[' -r STOP.script75 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi0_phi3/500_500_500_500_1
+ for psi in $PSI
+ for layers in $LAYERS
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f1_psi1_phi0
+ date
Mon Nov  9 08:21:23 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f1_psi1_phi0/300_300_300_1 ']'
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_1000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_1000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_1000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 100013 --n_pairs 1000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi1_phi0/300_300_300_1 --optimizer lbfgs --function f1 --psi 1 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_1000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bc12e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bc127b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bc2e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bc582f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bc58730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bc58488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bc58a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bc72730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bb7fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bb9ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bb7f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bb9e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37bb7f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37badb8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff37badbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3365eaea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3365ea488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3365a5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3365a5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3365a5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff336520840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3365207b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3364e5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff336506d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff336506ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3105aa488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff336506b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff31055e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff310532bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3104d4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff310590e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3104b6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3104b37b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3104b3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff3104b3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff310438f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.28677868e-06
Iter: 2 loss: 3.60810054e-06
Iter: 3 loss: 3.57415911e-06
Iter: 4 loss: 3.28535634e-06
Iter: 5 loss: 4.03197919e-06
Iter: 6 loss: 3.18687466e-06
Iter: 7 loss: 2.98005261e-06
Iter: 8 loss: 3.3977185e-06
Iter: 9 loss: 2.89602713e-06
Iter: 10 loss: 2.74173181e-06
Iter: 11 loss: 2.74168451e-06
Iter: 12 loss: 2.69451903e-06
Iter: 13 loss: 2.64809114e-06
Iter: 14 loss: 2.63811626e-06
Iter: 15 loss: 2.6042203e-06
Iter: 16 loss: 2.59951912e-06
Iter: 17 loss: 2.5725767e-06
Iter: 18 loss: 2.48817219e-06
Iter: 19 loss: 2.62915e-06
Iter: 20 loss: 2.43080763e-06
Iter: 21 loss: 2.32539742e-06
Iter: 22 loss: 3.38392374e-06
Iter: 23 loss: 2.32212119e-06
Iter: 24 loss: 2.23594793e-06
Iter: 25 loss: 3.40297e-06
Iter: 26 loss: 2.2356694e-06
Iter: 27 loss: 2.20120501e-06
Iter: 28 loss: 2.13119233e-06
Iter: 29 loss: 3.38959535e-06
Iter: 30 loss: 2.12987561e-06
Iter: 31 loss: 2.07888866e-06
Iter: 32 loss: 2.21212781e-06
Iter: 33 loss: 2.06152959e-06
Iter: 34 loss: 2.02128172e-06
Iter: 35 loss: 2.12388386e-06
Iter: 36 loss: 2.00731711e-06
Iter: 37 loss: 1.94936365e-06
Iter: 38 loss: 1.89208492e-06
Iter: 39 loss: 1.87996136e-06
Iter: 40 loss: 1.87175192e-06
Iter: 41 loss: 1.82929034e-06
Iter: 42 loss: 1.7843206e-06
Iter: 43 loss: 1.72756609e-06
Iter: 44 loss: 1.72311866e-06
Iter: 45 loss: 1.69367104e-06
Iter: 46 loss: 1.68758277e-06
Iter: 47 loss: 1.6601532e-06
Iter: 48 loss: 1.60135448e-06
Iter: 49 loss: 2.51628762e-06
Iter: 50 loss: 1.59913338e-06
Iter: 51 loss: 1.58961757e-06
Iter: 52 loss: 1.5798098e-06
Iter: 53 loss: 1.56563567e-06
Iter: 54 loss: 1.56518615e-06
Iter: 55 loss: 1.55410021e-06
Iter: 56 loss: 1.53299413e-06
Iter: 57 loss: 1.51993822e-06
Iter: 58 loss: 1.51142285e-06
Iter: 59 loss: 1.48218157e-06
Iter: 60 loss: 1.62868969e-06
Iter: 61 loss: 1.47731737e-06
Iter: 62 loss: 1.43761406e-06
Iter: 63 loss: 1.4978682e-06
Iter: 64 loss: 1.41887051e-06
Iter: 65 loss: 1.39372355e-06
Iter: 66 loss: 1.35163157e-06
Iter: 67 loss: 1.35153221e-06
Iter: 68 loss: 1.30831779e-06
Iter: 69 loss: 1.46713455e-06
Iter: 70 loss: 1.29756415e-06
Iter: 71 loss: 1.26843895e-06
Iter: 72 loss: 1.45153444e-06
Iter: 73 loss: 1.26506075e-06
Iter: 74 loss: 1.25949e-06
Iter: 75 loss: 1.25299812e-06
Iter: 76 loss: 1.2418916e-06
Iter: 77 loss: 1.21795597e-06
Iter: 78 loss: 1.59624153e-06
Iter: 79 loss: 1.2171048e-06
Iter: 80 loss: 1.21030314e-06
Iter: 81 loss: 1.20434686e-06
Iter: 82 loss: 1.1978957e-06
Iter: 83 loss: 1.17995421e-06
Iter: 84 loss: 1.28349666e-06
Iter: 85 loss: 1.17487491e-06
Iter: 86 loss: 1.17333752e-06
Iter: 87 loss: 1.16548597e-06
Iter: 88 loss: 1.15886019e-06
Iter: 89 loss: 1.14686702e-06
Iter: 90 loss: 1.43460204e-06
Iter: 91 loss: 1.14685668e-06
Iter: 92 loss: 1.13233659e-06
Iter: 93 loss: 1.16885599e-06
Iter: 94 loss: 1.12721796e-06
Iter: 95 loss: 1.11218492e-06
Iter: 96 loss: 1.18669197e-06
Iter: 97 loss: 1.10959445e-06
Iter: 98 loss: 1.09230882e-06
Iter: 99 loss: 1.11575127e-06
Iter: 100 loss: 1.08378765e-06
Iter: 101 loss: 1.06989467e-06
Iter: 102 loss: 1.04617141e-06
Iter: 103 loss: 1.04615083e-06
Iter: 104 loss: 1.02457238e-06
Iter: 105 loss: 1.20853e-06
Iter: 106 loss: 1.02340528e-06
Iter: 107 loss: 1.00994885e-06
Iter: 108 loss: 1.02095953e-06
Iter: 109 loss: 1.00196792e-06
Iter: 110 loss: 9.84722078e-07
Iter: 111 loss: 1.03607829e-06
Iter: 112 loss: 9.79427909e-07
Iter: 113 loss: 9.72159341e-07
Iter: 114 loss: 9.70556e-07
Iter: 115 loss: 9.59935619e-07
Iter: 116 loss: 9.58010787e-07
Iter: 117 loss: 9.50860681e-07
Iter: 118 loss: 9.43984105e-07
Iter: 119 loss: 1.0447726e-06
Iter: 120 loss: 9.44002693e-07
Iter: 121 loss: 9.37163918e-07
Iter: 122 loss: 9.24383698e-07
Iter: 123 loss: 1.20873335e-06
Iter: 124 loss: 9.24362098e-07
Iter: 125 loss: 9.18196463e-07
Iter: 126 loss: 9.87597332e-07
Iter: 127 loss: 9.18110743e-07
Iter: 128 loss: 9.11287486e-07
Iter: 129 loss: 9.21757533e-07
Iter: 130 loss: 9.08068728e-07
Iter: 131 loss: 9.0228383e-07
Iter: 132 loss: 8.92159505e-07
Iter: 133 loss: 8.92158937e-07
Iter: 134 loss: 8.86154567e-07
Iter: 135 loss: 8.84849328e-07
Iter: 136 loss: 8.7909558e-07
Iter: 137 loss: 8.80672e-07
Iter: 138 loss: 8.74894113e-07
Iter: 139 loss: 8.6666364e-07
Iter: 140 loss: 8.62327113e-07
Iter: 141 loss: 8.58615749e-07
Iter: 142 loss: 8.4981923e-07
Iter: 143 loss: 8.72287956e-07
Iter: 144 loss: 8.46798e-07
Iter: 145 loss: 8.39549557e-07
Iter: 146 loss: 8.38472431e-07
Iter: 147 loss: 8.33429851e-07
Iter: 148 loss: 8.32450041e-07
Iter: 149 loss: 8.28910629e-07
Iter: 150 loss: 8.23599635e-07
Iter: 151 loss: 8.18471278e-07
Iter: 152 loss: 8.17314515e-07
Iter: 153 loss: 8.11188329e-07
Iter: 154 loss: 8.63986486e-07
Iter: 155 loss: 8.10943902e-07
Iter: 156 loss: 8.0381227e-07
Iter: 157 loss: 7.92108835e-07
Iter: 158 loss: 7.92056e-07
Iter: 159 loss: 7.84564691e-07
Iter: 160 loss: 8.232239e-07
Iter: 161 loss: 7.8335097e-07
Iter: 162 loss: 7.78496599e-07
Iter: 163 loss: 7.78421111e-07
Iter: 164 loss: 7.76307445e-07
Iter: 165 loss: 7.70946e-07
Iter: 166 loss: 8.14737689e-07
Iter: 167 loss: 7.7001647e-07
Iter: 168 loss: 7.66189714e-07
Iter: 169 loss: 7.65915161e-07
Iter: 170 loss: 7.61350066e-07
Iter: 171 loss: 7.52921494e-07
Iter: 172 loss: 9.47395961e-07
Iter: 173 loss: 7.52917856e-07
Iter: 174 loss: 7.44661747e-07
Iter: 175 loss: 7.81712799e-07
Iter: 176 loss: 7.43003056e-07
Iter: 177 loss: 7.34597336e-07
Iter: 178 loss: 7.3094219e-07
Iter: 179 loss: 7.26616e-07
Iter: 180 loss: 7.17961427e-07
Iter: 181 loss: 7.66475523e-07
Iter: 182 loss: 7.16781869e-07
Iter: 183 loss: 7.19683385e-07
Iter: 184 loss: 7.14640578e-07
Iter: 185 loss: 7.13098757e-07
Iter: 186 loss: 7.08920822e-07
Iter: 187 loss: 7.32529884e-07
Iter: 188 loss: 7.07665e-07
Iter: 189 loss: 7.03220508e-07
Iter: 190 loss: 7.03154683e-07
Iter: 191 loss: 7.00146927e-07
Iter: 192 loss: 6.92832486e-07
Iter: 193 loss: 7.6937323e-07
Iter: 194 loss: 6.9202963e-07
Iter: 195 loss: 6.86468e-07
Iter: 196 loss: 7.62877107e-07
Iter: 197 loss: 6.86444366e-07
Iter: 198 loss: 6.79782033e-07
Iter: 199 loss: 6.82989196e-07
Iter: 200 loss: 6.75230126e-07
Iter: 201 loss: 6.7029481e-07
Iter: 202 loss: 6.73300462e-07
Iter: 203 loss: 6.67139943e-07
Iter: 204 loss: 6.67429447e-07
Iter: 205 loss: 6.65254902e-07
Iter: 206 loss: 6.639807e-07
Iter: 207 loss: 6.60168894e-07
Iter: 208 loss: 6.72772956e-07
Iter: 209 loss: 6.58384181e-07
Iter: 210 loss: 6.54052087e-07
Iter: 211 loss: 6.89280739e-07
Iter: 212 loss: 6.53767813e-07
Iter: 213 loss: 6.50294965e-07
Iter: 214 loss: 6.50059803e-07
Iter: 215 loss: 6.47430625e-07
Iter: 216 loss: 6.44715897e-07
Iter: 217 loss: 6.44507963e-07
Iter: 218 loss: 6.41963652e-07
Iter: 219 loss: 6.37333301e-07
Iter: 220 loss: 7.51215566e-07
Iter: 221 loss: 6.37321079e-07
Iter: 222 loss: 6.35603101e-07
Iter: 223 loss: 6.35010906e-07
Iter: 224 loss: 6.33001207e-07
Iter: 225 loss: 6.30572458e-07
Iter: 226 loss: 6.30304839e-07
Iter: 227 loss: 6.27423049e-07
Iter: 228 loss: 6.39252846e-07
Iter: 229 loss: 6.2679527e-07
Iter: 230 loss: 6.23558208e-07
Iter: 231 loss: 6.4366742e-07
Iter: 232 loss: 6.23197195e-07
Iter: 233 loss: 6.2074696e-07
Iter: 234 loss: 6.15676697e-07
Iter: 235 loss: 6.99808879e-07
Iter: 236 loss: 6.15518104e-07
Iter: 237 loss: 6.10484847e-07
Iter: 238 loss: 6.3114021e-07
Iter: 239 loss: 6.09379185e-07
Iter: 240 loss: 6.04737465e-07
Iter: 241 loss: 6.04761567e-07
Iter: 242 loss: 6.02390116e-07
Iter: 243 loss: 5.96188443e-07
Iter: 244 loss: 6.42242526e-07
Iter: 245 loss: 5.94886444e-07
Iter: 246 loss: 5.91161154e-07
Iter: 247 loss: 5.90979198e-07
Iter: 248 loss: 5.87777379e-07
Iter: 249 loss: 5.82754183e-07
Iter: 250 loss: 5.8267841e-07
Iter: 251 loss: 5.78398783e-07
Iter: 252 loss: 5.78341826e-07
Iter: 253 loss: 5.74287583e-07
Iter: 254 loss: 5.97773351e-07
Iter: 255 loss: 5.73725458e-07
Iter: 256 loss: 5.7187134e-07
Iter: 257 loss: 5.69213285e-07
Iter: 258 loss: 5.69105339e-07
Iter: 259 loss: 5.65580478e-07
Iter: 260 loss: 6.17750743e-07
Iter: 261 loss: 5.65581104e-07
Iter: 262 loss: 5.6403411e-07
Iter: 263 loss: 5.60696833e-07
Iter: 264 loss: 6.07236871e-07
Iter: 265 loss: 5.60525734e-07
Iter: 266 loss: 5.58761712e-07
Iter: 267 loss: 5.586827e-07
Iter: 268 loss: 5.56479108e-07
Iter: 269 loss: 5.55600536e-07
Iter: 270 loss: 5.54393694e-07
Iter: 271 loss: 5.52004735e-07
Iter: 272 loss: 5.51765652e-07
Iter: 273 loss: 5.50015955e-07
Iter: 274 loss: 5.47287812e-07
Iter: 275 loss: 5.47241712e-07
Iter: 276 loss: 5.45815908e-07
Iter: 277 loss: 5.42577709e-07
Iter: 278 loss: 5.81647555e-07
Iter: 279 loss: 5.42290081e-07
Iter: 280 loss: 5.38826725e-07
Iter: 281 loss: 5.4425459e-07
Iter: 282 loss: 5.37207711e-07
Iter: 283 loss: 5.34345e-07
Iter: 284 loss: 5.72709212e-07
Iter: 285 loss: 5.3437e-07
Iter: 286 loss: 5.32002332e-07
Iter: 287 loss: 5.46252522e-07
Iter: 288 loss: 5.31741591e-07
Iter: 289 loss: 5.2913748e-07
Iter: 290 loss: 5.36792072e-07
Iter: 291 loss: 5.28340422e-07
Iter: 292 loss: 5.26534e-07
Iter: 293 loss: 5.26535189e-07
Iter: 294 loss: 5.25140479e-07
Iter: 295 loss: 5.23043354e-07
Iter: 296 loss: 5.54182918e-07
Iter: 297 loss: 5.23054211e-07
Iter: 298 loss: 5.22001471e-07
Iter: 299 loss: 5.19179764e-07
Iter: 300 loss: 5.40884969e-07
Iter: 301 loss: 5.18638387e-07
Iter: 302 loss: 5.16542855e-07
Iter: 303 loss: 5.16535238e-07
Iter: 304 loss: 5.14329429e-07
Iter: 305 loss: 5.24036182e-07
Iter: 306 loss: 5.13939483e-07
Iter: 307 loss: 5.12595307e-07
Iter: 308 loss: 5.08847791e-07
Iter: 309 loss: 5.32297e-07
Iter: 310 loss: 5.07908112e-07
Iter: 311 loss: 5.07070922e-07
Iter: 312 loss: 5.05766252e-07
Iter: 313 loss: 5.03475349e-07
Iter: 314 loss: 5.01527154e-07
Iter: 315 loss: 5.00928593e-07
Iter: 316 loss: 4.98549639e-07
Iter: 317 loss: 4.97328642e-07
Iter: 318 loss: 4.96269706e-07
Iter: 319 loss: 4.93420828e-07
Iter: 320 loss: 4.99378075e-07
Iter: 321 loss: 4.92308175e-07
Iter: 322 loss: 4.91009e-07
Iter: 323 loss: 4.90747937e-07
Iter: 324 loss: 4.89144895e-07
Iter: 325 loss: 4.9077039e-07
Iter: 326 loss: 4.88298156e-07
Iter: 327 loss: 4.86419765e-07
Iter: 328 loss: 4.87412308e-07
Iter: 329 loss: 4.85128794e-07
Iter: 330 loss: 4.82973405e-07
Iter: 331 loss: 5.01765953e-07
Iter: 332 loss: 4.82834082e-07
Iter: 333 loss: 4.81127e-07
Iter: 334 loss: 4.78947868e-07
Iter: 335 loss: 4.78776656e-07
Iter: 336 loss: 4.76604953e-07
Iter: 337 loss: 4.80983601e-07
Iter: 338 loss: 4.75753751e-07
Iter: 339 loss: 4.73503036e-07
Iter: 340 loss: 4.73508e-07
Iter: 341 loss: 4.72400274e-07
Iter: 342 loss: 4.69251773e-07
Iter: 343 loss: 4.83064639e-07
Iter: 344 loss: 4.67999911e-07
Iter: 345 loss: 4.64685257e-07
Iter: 346 loss: 4.97740757e-07
Iter: 347 loss: 4.64564124e-07
Iter: 348 loss: 4.63350659e-07
Iter: 349 loss: 4.62969496e-07
Iter: 350 loss: 4.62097603e-07
Iter: 351 loss: 4.5963256e-07
Iter: 352 loss: 4.71218641e-07
Iter: 353 loss: 4.58772945e-07
Iter: 354 loss: 4.55591362e-07
Iter: 355 loss: 4.68325624e-07
Iter: 356 loss: 4.54912339e-07
Iter: 357 loss: 4.54679878e-07
Iter: 358 loss: 4.53776977e-07
Iter: 359 loss: 4.52568401e-07
Iter: 360 loss: 4.50287729e-07
Iter: 361 loss: 5.00038539e-07
Iter: 362 loss: 4.50288383e-07
Iter: 363 loss: 4.48186029e-07
Iter: 364 loss: 4.69819042e-07
Iter: 365 loss: 4.48105823e-07
Iter: 366 loss: 4.46370791e-07
Iter: 367 loss: 4.50114641e-07
Iter: 368 loss: 4.45703279e-07
Iter: 369 loss: 4.44003319e-07
Iter: 370 loss: 4.43254265e-07
Iter: 371 loss: 4.42360545e-07
Iter: 372 loss: 4.40646374e-07
Iter: 373 loss: 4.48493893e-07
Iter: 374 loss: 4.40283543e-07
Iter: 375 loss: 4.38214414e-07
Iter: 376 loss: 4.50897119e-07
Iter: 377 loss: 4.37969788e-07
Iter: 378 loss: 4.36966e-07
Iter: 379 loss: 4.34617533e-07
Iter: 380 loss: 4.621985e-07
Iter: 381 loss: 4.34450499e-07
Iter: 382 loss: 4.31984375e-07
Iter: 383 loss: 4.45147521e-07
Iter: 384 loss: 4.31598096e-07
Iter: 385 loss: 4.28993928e-07
Iter: 386 loss: 4.56610252e-07
Iter: 387 loss: 4.28943963e-07
Iter: 388 loss: 4.27741696e-07
Iter: 389 loss: 4.24846405e-07
Iter: 390 loss: 4.58643513e-07
Iter: 391 loss: 4.24586233e-07
Iter: 392 loss: 4.21965694e-07
Iter: 393 loss: 4.35462852e-07
Iter: 394 loss: 4.21549032e-07
Iter: 395 loss: 4.21907487e-07
Iter: 396 loss: 4.20629476e-07
Iter: 397 loss: 4.19924561e-07
Iter: 398 loss: 4.18127286e-07
Iter: 399 loss: 4.3415281e-07
Iter: 400 loss: 4.17810128e-07
Iter: 401 loss: 4.16848735e-07
Iter: 402 loss: 4.16719729e-07
Iter: 403 loss: 4.15752339e-07
Iter: 404 loss: 4.1436968e-07
Iter: 405 loss: 4.14322557e-07
Iter: 406 loss: 4.12125246e-07
Iter: 407 loss: 4.12453403e-07
Iter: 408 loss: 4.10434154e-07
Iter: 409 loss: 4.08382505e-07
Iter: 410 loss: 4.33226717e-07
Iter: 411 loss: 4.08350644e-07
Iter: 412 loss: 4.06492546e-07
Iter: 413 loss: 4.1479575e-07
Iter: 414 loss: 4.06167459e-07
Iter: 415 loss: 4.05256714e-07
Iter: 416 loss: 4.03128325e-07
Iter: 417 loss: 4.28077612e-07
Iter: 418 loss: 4.0297212e-07
Iter: 419 loss: 4.01058401e-07
Iter: 420 loss: 4.19545643e-07
Iter: 421 loss: 4.00959e-07
Iter: 422 loss: 3.99551539e-07
Iter: 423 loss: 3.99538976e-07
Iter: 424 loss: 3.98706277e-07
Iter: 425 loss: 3.9615162e-07
Iter: 426 loss: 4.0289072e-07
Iter: 427 loss: 3.94803436e-07
Iter: 428 loss: 3.91089884e-07
Iter: 429 loss: 4.05895207e-07
Iter: 430 loss: 3.90209436e-07
Iter: 431 loss: 3.92746841e-07
Iter: 432 loss: 3.89305683e-07
Iter: 433 loss: 3.88515076e-07
Iter: 434 loss: 3.86600959e-07
Iter: 435 loss: 4.06765082e-07
Iter: 436 loss: 3.86411159e-07
Iter: 437 loss: 3.85480291e-07
Iter: 438 loss: 3.85418502e-07
Iter: 439 loss: 3.84395037e-07
Iter: 440 loss: 3.83552e-07
Iter: 441 loss: 3.83282895e-07
Iter: 442 loss: 3.82180019e-07
Iter: 443 loss: 3.8457992e-07
Iter: 444 loss: 3.81756024e-07
Iter: 445 loss: 3.80326981e-07
Iter: 446 loss: 3.81592344e-07
Iter: 447 loss: 3.79495361e-07
Iter: 448 loss: 3.78181085e-07
Iter: 449 loss: 3.78172786e-07
Iter: 450 loss: 3.7722856e-07
Iter: 451 loss: 3.75378818e-07
Iter: 452 loss: 4.15435892e-07
Iter: 453 loss: 3.75387799e-07
Iter: 454 loss: 3.73641598e-07
Iter: 455 loss: 3.79132359e-07
Iter: 456 loss: 3.7310221e-07
Iter: 457 loss: 3.71028364e-07
Iter: 458 loss: 3.90710454e-07
Iter: 459 loss: 3.7093011e-07
Iter: 460 loss: 3.69860629e-07
Iter: 461 loss: 3.67255069e-07
Iter: 462 loss: 3.92133245e-07
Iter: 463 loss: 3.66911252e-07
Iter: 464 loss: 3.64517746e-07
Iter: 465 loss: 3.91368e-07
Iter: 466 loss: 3.64483299e-07
Iter: 467 loss: 3.62654276e-07
Iter: 468 loss: 3.62650809e-07
Iter: 469 loss: 3.62050116e-07
Iter: 470 loss: 3.60396086e-07
Iter: 471 loss: 3.72515785e-07
Iter: 472 loss: 3.60046869e-07
Iter: 473 loss: 3.59783343e-07
Iter: 474 loss: 3.59091e-07
Iter: 475 loss: 3.58563426e-07
Iter: 476 loss: 3.57335296e-07
Iter: 477 loss: 3.70338341e-07
Iter: 478 loss: 3.57189435e-07
Iter: 479 loss: 3.55419985e-07
Iter: 480 loss: 3.53717979e-07
Iter: 481 loss: 3.53367284e-07
Iter: 482 loss: 3.51457516e-07
Iter: 483 loss: 3.51384358e-07
Iter: 484 loss: 3.49476124e-07
Iter: 485 loss: 3.5566174e-07
Iter: 486 loss: 3.48947026e-07
Iter: 487 loss: 3.47106379e-07
Iter: 488 loss: 3.48953336e-07
Iter: 489 loss: 3.46059352e-07
Iter: 490 loss: 3.44590319e-07
Iter: 491 loss: 3.47326534e-07
Iter: 492 loss: 3.43947846e-07
Iter: 493 loss: 3.43392429e-07
Iter: 494 loss: 3.43177248e-07
Iter: 495 loss: 3.4265463e-07
Iter: 496 loss: 3.41155328e-07
Iter: 497 loss: 3.47932257e-07
Iter: 498 loss: 3.4058877e-07
Iter: 499 loss: 3.39280234e-07
Iter: 500 loss: 3.39256133e-07
Iter: 501 loss: 3.3779628e-07
Iter: 502 loss: 3.43224684e-07
Iter: 503 loss: 3.37436461e-07
Iter: 504 loss: 3.3651304e-07
Iter: 505 loss: 3.34221113e-07
Iter: 506 loss: 3.55829286e-07
Iter: 507 loss: 3.33879541e-07
Iter: 508 loss: 3.35103323e-07
Iter: 509 loss: 3.32969364e-07
Iter: 510 loss: 3.32389646e-07
Iter: 511 loss: 3.3101287e-07
Iter: 512 loss: 3.49920924e-07
Iter: 513 loss: 3.30923115e-07
Iter: 514 loss: 3.29787326e-07
Iter: 515 loss: 3.35886114e-07
Iter: 516 loss: 3.29613897e-07
Iter: 517 loss: 3.28741947e-07
Iter: 518 loss: 3.28710485e-07
Iter: 519 loss: 3.27980672e-07
Iter: 520 loss: 3.27302871e-07
Iter: 521 loss: 3.27125434e-07
Iter: 522 loss: 3.25812806e-07
Iter: 523 loss: 3.26987305e-07
Iter: 524 loss: 3.25056931e-07
Iter: 525 loss: 3.24094145e-07
Iter: 526 loss: 3.38683833e-07
Iter: 527 loss: 3.24087523e-07
Iter: 528 loss: 3.23167626e-07
Iter: 529 loss: 3.24995938e-07
Iter: 530 loss: 3.22792346e-07
Iter: 531 loss: 3.22194211e-07
Iter: 532 loss: 3.20824483e-07
Iter: 533 loss: 3.40862528e-07
Iter: 534 loss: 3.20749621e-07
Iter: 535 loss: 3.19242787e-07
Iter: 536 loss: 3.24872133e-07
Iter: 537 loss: 3.18864778e-07
Iter: 538 loss: 3.18882599e-07
Iter: 539 loss: 3.18213296e-07
Iter: 540 loss: 3.17627183e-07
Iter: 541 loss: 3.15788895e-07
Iter: 542 loss: 3.21252656e-07
Iter: 543 loss: 3.1485348e-07
Iter: 544 loss: 3.13447941e-07
Iter: 545 loss: 3.13444986e-07
Iter: 546 loss: 3.12383435e-07
Iter: 547 loss: 3.25183e-07
Iter: 548 loss: 3.12357173e-07
Iter: 549 loss: 3.11961486e-07
Iter: 550 loss: 3.10935036e-07
Iter: 551 loss: 3.1664635e-07
Iter: 552 loss: 3.10617565e-07
Iter: 553 loss: 3.09323838e-07
Iter: 554 loss: 3.16030963e-07
Iter: 555 loss: 3.09143218e-07
Iter: 556 loss: 3.08541956e-07
Iter: 557 loss: 3.08494378e-07
Iter: 558 loss: 3.07825189e-07
Iter: 559 loss: 3.07305072e-07
Iter: 560 loss: 3.07059793e-07
Iter: 561 loss: 3.05961493e-07
Iter: 562 loss: 3.07213554e-07
Iter: 563 loss: 3.05322516e-07
Iter: 564 loss: 3.04348333e-07
Iter: 565 loss: 3.10412759e-07
Iter: 566 loss: 3.04207646e-07
Iter: 567 loss: 3.03311907e-07
Iter: 568 loss: 3.11483433e-07
Iter: 569 loss: 3.03310259e-07
Iter: 570 loss: 3.02858808e-07
Iter: 571 loss: 3.01894033e-07
Iter: 572 loss: 3.14785723e-07
Iter: 573 loss: 3.01827242e-07
Iter: 574 loss: 3.00924e-07
Iter: 575 loss: 3.09644065e-07
Iter: 576 loss: 3.00891145e-07
Iter: 577 loss: 2.9989809e-07
Iter: 578 loss: 3.05347157e-07
Iter: 579 loss: 2.99729464e-07
Iter: 580 loss: 2.9926764e-07
Iter: 581 loss: 2.9824065e-07
Iter: 582 loss: 3.10718235e-07
Iter: 583 loss: 2.98136939e-07
Iter: 584 loss: 2.97470251e-07
Iter: 585 loss: 2.9732783e-07
Iter: 586 loss: 2.9679353e-07
Iter: 587 loss: 2.9552163e-07
Iter: 588 loss: 3.11130833e-07
Iter: 589 loss: 2.95423945e-07
Iter: 590 loss: 2.9450274e-07
Iter: 591 loss: 2.9768583e-07
Iter: 592 loss: 2.94244956e-07
Iter: 593 loss: 2.93853049e-07
Iter: 594 loss: 2.93717079e-07
Iter: 595 loss: 2.93264634e-07
Iter: 596 loss: 2.92180573e-07
Iter: 597 loss: 3.04314824e-07
Iter: 598 loss: 2.92063135e-07
Iter: 599 loss: 2.90882838e-07
Iter: 600 loss: 2.98507189e-07
Iter: 601 loss: 2.90760255e-07
Iter: 602 loss: 2.90006199e-07
Iter: 603 loss: 2.9600119e-07
Iter: 604 loss: 2.89948616e-07
Iter: 605 loss: 2.89094089e-07
Iter: 606 loss: 2.90324778e-07
Iter: 607 loss: 2.88654718e-07
Iter: 608 loss: 2.87959779e-07
Iter: 609 loss: 2.87359086e-07
Iter: 610 loss: 2.87155615e-07
Iter: 611 loss: 2.86699361e-07
Iter: 612 loss: 2.86633423e-07
Iter: 613 loss: 2.85973329e-07
Iter: 614 loss: 2.85404298e-07
Iter: 615 loss: 2.85204749e-07
Iter: 616 loss: 2.84378416e-07
Iter: 617 loss: 2.84204049e-07
Iter: 618 loss: 2.83647353e-07
Iter: 619 loss: 2.82903443e-07
Iter: 620 loss: 2.82827386e-07
Iter: 621 loss: 2.82473479e-07
Iter: 622 loss: 2.81503759e-07
Iter: 623 loss: 2.87714613e-07
Iter: 624 loss: 2.8125018e-07
Iter: 625 loss: 2.80476399e-07
Iter: 626 loss: 2.80475291e-07
Iter: 627 loss: 2.79733058e-07
Iter: 628 loss: 2.83053453e-07
Iter: 629 loss: 2.79629631e-07
Iter: 630 loss: 2.79265691e-07
Iter: 631 loss: 2.78490631e-07
Iter: 632 loss: 2.91608018e-07
Iter: 633 loss: 2.7848435e-07
Iter: 634 loss: 2.77545837e-07
Iter: 635 loss: 2.78415428e-07
Iter: 636 loss: 2.7700446e-07
Iter: 637 loss: 2.76128532e-07
Iter: 638 loss: 2.76913227e-07
Iter: 639 loss: 2.75614127e-07
Iter: 640 loss: 2.75079458e-07
Iter: 641 loss: 2.74974752e-07
Iter: 642 loss: 2.74525917e-07
Iter: 643 loss: 2.73827254e-07
Iter: 644 loss: 2.73810599e-07
Iter: 645 loss: 2.73495033e-07
Iter: 646 loss: 2.73458056e-07
Iter: 647 loss: 2.73011665e-07
Iter: 648 loss: 2.72648805e-07
Iter: 649 loss: 2.72547766e-07
Iter: 650 loss: 2.72087732e-07
Iter: 651 loss: 2.71657058e-07
Iter: 652 loss: 2.71577932e-07
Iter: 653 loss: 2.7102729e-07
Iter: 654 loss: 2.70993581e-07
Iter: 655 loss: 2.70533377e-07
Iter: 656 loss: 2.69673251e-07
Iter: 657 loss: 2.89509842e-07
Iter: 658 loss: 2.69678935e-07
Iter: 659 loss: 2.6874585e-07
Iter: 660 loss: 2.69247067e-07
Iter: 661 loss: 2.68155645e-07
Iter: 662 loss: 2.67753819e-07
Iter: 663 loss: 2.67606509e-07
Iter: 664 loss: 2.67052428e-07
Iter: 665 loss: 2.66225015e-07
Iter: 666 loss: 2.66211742e-07
Iter: 667 loss: 2.65423807e-07
Iter: 668 loss: 2.65688925e-07
Iter: 669 loss: 2.64899938e-07
Iter: 670 loss: 2.64106774e-07
Iter: 671 loss: 2.71043263e-07
Iter: 672 loss: 2.64072128e-07
Iter: 673 loss: 2.63474533e-07
Iter: 674 loss: 2.63297352e-07
Iter: 675 loss: 2.62981899e-07
Iter: 676 loss: 2.61997741e-07
Iter: 677 loss: 2.62288779e-07
Iter: 678 loss: 2.61310163e-07
Iter: 679 loss: 2.60614883e-07
Iter: 680 loss: 2.68779644e-07
Iter: 681 loss: 2.6059675e-07
Iter: 682 loss: 2.59834337e-07
Iter: 683 loss: 2.62468149e-07
Iter: 684 loss: 2.59633282e-07
Iter: 685 loss: 2.59236771e-07
Iter: 686 loss: 2.58333614e-07
Iter: 687 loss: 2.70960072e-07
Iter: 688 loss: 2.58290299e-07
Iter: 689 loss: 2.57728885e-07
Iter: 690 loss: 2.57686338e-07
Iter: 691 loss: 2.57055831e-07
Iter: 692 loss: 2.57237701e-07
Iter: 693 loss: 2.56583121e-07
Iter: 694 loss: 2.56087e-07
Iter: 695 loss: 2.55933571e-07
Iter: 696 loss: 2.55636678e-07
Iter: 697 loss: 2.55154504e-07
Iter: 698 loss: 2.55115197e-07
Iter: 699 loss: 2.5476271e-07
Iter: 700 loss: 2.53875868e-07
Iter: 701 loss: 2.63793652e-07
Iter: 702 loss: 2.5379677e-07
Iter: 703 loss: 2.52897593e-07
Iter: 704 loss: 2.54207578e-07
Iter: 705 loss: 2.52465725e-07
Iter: 706 loss: 2.51888508e-07
Iter: 707 loss: 2.51824957e-07
Iter: 708 loss: 2.51349178e-07
Iter: 709 loss: 2.50400973e-07
Iter: 710 loss: 2.68694578e-07
Iter: 711 loss: 2.50409812e-07
Iter: 712 loss: 2.49919424e-07
Iter: 713 loss: 2.49892395e-07
Iter: 714 loss: 2.49438e-07
Iter: 715 loss: 2.5137706e-07
Iter: 716 loss: 2.49331634e-07
Iter: 717 loss: 2.48986566e-07
Iter: 718 loss: 2.48389568e-07
Iter: 719 loss: 2.48370895e-07
Iter: 720 loss: 2.47682834e-07
Iter: 721 loss: 2.51871825e-07
Iter: 722 loss: 2.47629828e-07
Iter: 723 loss: 2.47145e-07
Iter: 724 loss: 2.50947977e-07
Iter: 725 loss: 2.47086632e-07
Iter: 726 loss: 2.46542072e-07
Iter: 727 loss: 2.46007517e-07
Iter: 728 loss: 2.45902186e-07
Iter: 729 loss: 2.45097908e-07
Iter: 730 loss: 2.44685339e-07
Iter: 731 loss: 2.44327282e-07
Iter: 732 loss: 2.43401985e-07
Iter: 733 loss: 2.43341105e-07
Iter: 734 loss: 2.42905514e-07
Iter: 735 loss: 2.41874744e-07
Iter: 736 loss: 2.52031668e-07
Iter: 737 loss: 2.41760574e-07
Iter: 738 loss: 2.41267e-07
Iter: 739 loss: 2.41189582e-07
Iter: 740 loss: 2.40606397e-07
Iter: 741 loss: 2.40274773e-07
Iter: 742 loss: 2.40064651e-07
Iter: 743 loss: 2.39433206e-07
Iter: 744 loss: 2.40588662e-07
Iter: 745 loss: 2.39169509e-07
Iter: 746 loss: 2.38676733e-07
Iter: 747 loss: 2.38682304e-07
Iter: 748 loss: 2.38254671e-07
Iter: 749 loss: 2.37759537e-07
Iter: 750 loss: 2.37545422e-07
Iter: 751 loss: 2.37276652e-07
Iter: 752 loss: 2.36536437e-07
Iter: 753 loss: 2.40558819e-07
Iter: 754 loss: 2.36433863e-07
Iter: 755 loss: 2.35888706e-07
Iter: 756 loss: 2.35842833e-07
Iter: 757 loss: 2.35441291e-07
Iter: 758 loss: 2.34594552e-07
Iter: 759 loss: 2.35736508e-07
Iter: 760 loss: 2.34159785e-07
Iter: 761 loss: 2.33265226e-07
Iter: 762 loss: 2.38155238e-07
Iter: 763 loss: 2.33118669e-07
Iter: 764 loss: 2.32493775e-07
Iter: 765 loss: 2.3246497e-07
Iter: 766 loss: 2.32194353e-07
Iter: 767 loss: 2.31433063e-07
Iter: 768 loss: 2.38020007e-07
Iter: 769 loss: 2.31340451e-07
Iter: 770 loss: 2.30574699e-07
Iter: 771 loss: 2.34676008e-07
Iter: 772 loss: 2.30483735e-07
Iter: 773 loss: 2.30060877e-07
Iter: 774 loss: 2.29990221e-07
Iter: 775 loss: 2.29729523e-07
Iter: 776 loss: 2.29015114e-07
Iter: 777 loss: 2.34664284e-07
Iter: 778 loss: 2.28878591e-07
Iter: 779 loss: 2.28090073e-07
Iter: 780 loss: 2.28082911e-07
Iter: 781 loss: 2.27627709e-07
Iter: 782 loss: 2.26635862e-07
Iter: 783 loss: 2.42820136e-07
Iter: 784 loss: 2.26608336e-07
Iter: 785 loss: 2.25809089e-07
Iter: 786 loss: 2.25788256e-07
Iter: 787 loss: 2.2526612e-07
Iter: 788 loss: 2.24826948e-07
Iter: 789 loss: 2.24664376e-07
Iter: 790 loss: 2.23770286e-07
Iter: 791 loss: 2.26862127e-07
Iter: 792 loss: 2.23527366e-07
Iter: 793 loss: 2.2296345e-07
Iter: 794 loss: 2.2445505e-07
Iter: 795 loss: 2.22768662e-07
Iter: 796 loss: 2.22332375e-07
Iter: 797 loss: 2.25268536e-07
Iter: 798 loss: 2.22309453e-07
Iter: 799 loss: 2.21816421e-07
Iter: 800 loss: 2.2132113e-07
Iter: 801 loss: 2.2122552e-07
Iter: 802 loss: 2.20617537e-07
Iter: 803 loss: 2.20235165e-07
Iter: 804 loss: 2.20003898e-07
Iter: 805 loss: 2.1934855e-07
Iter: 806 loss: 2.19345893e-07
Iter: 807 loss: 2.18751921e-07
Iter: 808 loss: 2.18341e-07
Iter: 809 loss: 2.18136321e-07
Iter: 810 loss: 2.17547921e-07
Iter: 811 loss: 2.17934428e-07
Iter: 812 loss: 2.17190589e-07
Iter: 813 loss: 2.17531721e-07
Iter: 814 loss: 2.16947797e-07
Iter: 815 loss: 2.16797758e-07
Iter: 816 loss: 2.16441322e-07
Iter: 817 loss: 2.20229509e-07
Iter: 818 loss: 2.16413895e-07
Iter: 819 loss: 2.16015792e-07
Iter: 820 loss: 2.21084946e-07
Iter: 821 loss: 2.16024745e-07
Iter: 822 loss: 2.15665324e-07
Iter: 823 loss: 2.15347796e-07
Iter: 824 loss: 2.15253749e-07
Iter: 825 loss: 2.1466947e-07
Iter: 826 loss: 2.14760931e-07
Iter: 827 loss: 2.14244821e-07
Iter: 828 loss: 2.13628539e-07
Iter: 829 loss: 2.14283986e-07
Iter: 830 loss: 2.13324839e-07
Iter: 831 loss: 2.12640884e-07
Iter: 832 loss: 2.19849682e-07
Iter: 833 loss: 2.12618204e-07
Iter: 834 loss: 2.12152543e-07
Iter: 835 loss: 2.12623519e-07
Iter: 836 loss: 2.11927059e-07
Iter: 837 loss: 2.11583455e-07
Iter: 838 loss: 2.13103903e-07
Iter: 839 loss: 2.11514887e-07
Iter: 840 loss: 2.11073399e-07
Iter: 841 loss: 2.12362252e-07
Iter: 842 loss: 2.10934388e-07
Iter: 843 loss: 2.10556124e-07
Iter: 844 loss: 2.0959078e-07
Iter: 845 loss: 2.19972449e-07
Iter: 846 loss: 2.09484256e-07
Iter: 847 loss: 2.09037495e-07
Iter: 848 loss: 2.08943504e-07
Iter: 849 loss: 2.08315669e-07
Iter: 850 loss: 2.09125403e-07
Iter: 851 loss: 2.07975646e-07
Iter: 852 loss: 2.07628162e-07
Iter: 853 loss: 2.08332636e-07
Iter: 854 loss: 2.07487929e-07
Iter: 855 loss: 2.06995367e-07
Iter: 856 loss: 2.08781273e-07
Iter: 857 loss: 2.0689501e-07
Iter: 858 loss: 2.06588297e-07
Iter: 859 loss: 2.06802156e-07
Iter: 860 loss: 2.06366536e-07
Iter: 861 loss: 2.05933986e-07
Iter: 862 loss: 2.06196432e-07
Iter: 863 loss: 2.05646188e-07
Iter: 864 loss: 2.05139969e-07
Iter: 865 loss: 2.077727e-07
Iter: 866 loss: 2.05061184e-07
Iter: 867 loss: 2.04477871e-07
Iter: 868 loss: 2.04564586e-07
Iter: 869 loss: 2.04055397e-07
Iter: 870 loss: 2.03308019e-07
Iter: 871 loss: 2.05892817e-07
Iter: 872 loss: 2.0315855e-07
Iter: 873 loss: 2.02680326e-07
Iter: 874 loss: 2.02669895e-07
Iter: 875 loss: 2.02398923e-07
Iter: 876 loss: 2.01831185e-07
Iter: 877 loss: 2.13017771e-07
Iter: 878 loss: 2.01814714e-07
Iter: 879 loss: 2.01294128e-07
Iter: 880 loss: 2.02091314e-07
Iter: 881 loss: 2.01059834e-07
Iter: 882 loss: 2.01007737e-07
Iter: 883 loss: 2.00732217e-07
Iter: 884 loss: 2.00557935e-07
Iter: 885 loss: 2.00033213e-07
Iter: 886 loss: 2.01131186e-07
Iter: 887 loss: 1.99700523e-07
Iter: 888 loss: 1.99373687e-07
Iter: 889 loss: 1.99218263e-07
Iter: 890 loss: 1.98797878e-07
Iter: 891 loss: 1.97855414e-07
Iter: 892 loss: 2.10928476e-07
Iter: 893 loss: 1.97815226e-07
Iter: 894 loss: 1.9710771e-07
Iter: 895 loss: 2.06973652e-07
Iter: 896 loss: 1.97098302e-07
Iter: 897 loss: 1.96645061e-07
Iter: 898 loss: 1.97702562e-07
Iter: 899 loss: 1.96467568e-07
Iter: 900 loss: 1.96102263e-07
Iter: 901 loss: 1.97507589e-07
Iter: 902 loss: 1.96017268e-07
Iter: 903 loss: 1.95648411e-07
Iter: 904 loss: 1.96309259e-07
Iter: 905 loss: 1.95502537e-07
Iter: 906 loss: 1.95186061e-07
Iter: 907 loss: 1.95513209e-07
Iter: 908 loss: 1.950079e-07
Iter: 909 loss: 1.945386e-07
Iter: 910 loss: 1.96451353e-07
Iter: 911 loss: 1.94430356e-07
Iter: 912 loss: 1.94083157e-07
Iter: 913 loss: 1.93440712e-07
Iter: 914 loss: 1.9343922e-07
Iter: 915 loss: 1.92789884e-07
Iter: 916 loss: 1.99973812e-07
Iter: 917 loss: 1.92774522e-07
Iter: 918 loss: 1.9227079e-07
Iter: 919 loss: 1.91355667e-07
Iter: 920 loss: 2.13448942e-07
Iter: 921 loss: 1.91361394e-07
Iter: 922 loss: 1.90880826e-07
Iter: 923 loss: 1.98463354e-07
Iter: 924 loss: 1.9087895e-07
Iter: 925 loss: 1.90386601e-07
Iter: 926 loss: 1.91831958e-07
Iter: 927 loss: 1.90245402e-07
Iter: 928 loss: 1.89947215e-07
Iter: 929 loss: 1.89613218e-07
Iter: 930 loss: 1.89552622e-07
Iter: 931 loss: 1.89172724e-07
Iter: 932 loss: 1.89144558e-07
Iter: 933 loss: 1.88834392e-07
Iter: 934 loss: 1.88802545e-07
Iter: 935 loss: 1.88569715e-07
Iter: 936 loss: 1.88077934e-07
Iter: 937 loss: 1.881034e-07
Iter: 938 loss: 1.87659168e-07
Iter: 939 loss: 1.86995536e-07
Iter: 940 loss: 1.8968089e-07
Iter: 941 loss: 1.86811732e-07
Iter: 942 loss: 1.86346341e-07
Iter: 943 loss: 1.92670342e-07
Iter: 944 loss: 1.86339292e-07
Iter: 945 loss: 1.85965433e-07
Iter: 946 loss: 1.86046705e-07
Iter: 947 loss: 1.85676953e-07
Iter: 948 loss: 1.85379392e-07
Iter: 949 loss: 1.89705958e-07
Iter: 950 loss: 1.85386142e-07
Iter: 951 loss: 1.85148963e-07
Iter: 952 loss: 1.84781101e-07
Iter: 953 loss: 1.84770599e-07
Iter: 954 loss: 1.8436053e-07
Iter: 955 loss: 1.840952e-07
Iter: 956 loss: 1.83937175e-07
Iter: 957 loss: 1.8394087e-07
Iter: 958 loss: 1.83633546e-07
Iter: 959 loss: 1.83418763e-07
Iter: 960 loss: 1.8289127e-07
Iter: 961 loss: 1.86413146e-07
Iter: 962 loss: 1.82751108e-07
Iter: 963 loss: 1.82012201e-07
Iter: 964 loss: 1.8237526e-07
Iter: 965 loss: 1.81507431e-07
Iter: 966 loss: 1.81635386e-07
Iter: 967 loss: 1.81159251e-07
Iter: 968 loss: 1.80959404e-07
Iter: 969 loss: 1.80604161e-07
Iter: 970 loss: 1.80615132e-07
Iter: 971 loss: 1.8015119e-07
Iter: 972 loss: 1.82016265e-07
Iter: 973 loss: 1.80041084e-07
Iter: 974 loss: 1.79656638e-07
Iter: 975 loss: 1.81682964e-07
Iter: 976 loss: 1.7959681e-07
Iter: 977 loss: 1.79253163e-07
Iter: 978 loss: 1.80759145e-07
Iter: 979 loss: 1.7917128e-07
Iter: 980 loss: 1.78888584e-07
Iter: 981 loss: 1.796856e-07
Iter: 982 loss: 1.7880393e-07
Iter: 983 loss: 1.78468753e-07
Iter: 984 loss: 1.79101463e-07
Iter: 985 loss: 1.78335029e-07
Iter: 986 loss: 1.78056325e-07
Iter: 987 loss: 1.77680576e-07
Iter: 988 loss: 1.77656261e-07
Iter: 989 loss: 1.77522466e-07
Iter: 990 loss: 1.77469815e-07
Iter: 991 loss: 1.77269015e-07
Iter: 992 loss: 1.77191112e-07
Iter: 993 loss: 1.77082185e-07
Iter: 994 loss: 1.76874408e-07
Iter: 995 loss: 1.76382159e-07
Iter: 996 loss: 1.83707982e-07
Iter: 997 loss: 1.76363216e-07
Iter: 998 loss: 1.75956743e-07
Iter: 999 loss: 1.75945161e-07
Iter: 1000 loss: 1.75550014e-07
Iter: 1001 loss: 1.76286832e-07
Iter: 1002 loss: 1.75384727e-07
Iter: 1003 loss: 1.75126459e-07
Iter: 1004 loss: 1.75106891e-07
Iter: 1005 loss: 1.7490936e-07
Iter: 1006 loss: 1.7465257e-07
Iter: 1007 loss: 1.77297295e-07
Iter: 1008 loss: 1.74628411e-07
Iter: 1009 loss: 1.74401364e-07
Iter: 1010 loss: 1.75461849e-07
Iter: 1011 loss: 1.74367628e-07
Iter: 1012 loss: 1.7411864e-07
Iter: 1013 loss: 1.74184422e-07
Iter: 1014 loss: 1.73943249e-07
Iter: 1015 loss: 1.73716899e-07
Iter: 1016 loss: 1.7372723e-07
Iter: 1017 loss: 1.73543157e-07
Iter: 1018 loss: 1.73100091e-07
Iter: 1019 loss: 1.77384948e-07
Iter: 1020 loss: 1.73035062e-07
Iter: 1021 loss: 1.72472298e-07
Iter: 1022 loss: 1.75271765e-07
Iter: 1023 loss: 1.7239762e-07
Iter: 1024 loss: 1.71909534e-07
Iter: 1025 loss: 1.76671136e-07
Iter: 1026 loss: 1.71880444e-07
Iter: 1027 loss: 1.71655586e-07
Iter: 1028 loss: 1.71311484e-07
Iter: 1029 loss: 1.7132227e-07
Iter: 1030 loss: 1.70999385e-07
Iter: 1031 loss: 1.72418808e-07
Iter: 1032 loss: 1.70945029e-07
Iter: 1033 loss: 1.70785867e-07
Iter: 1034 loss: 1.70752713e-07
Iter: 1035 loss: 1.70620027e-07
Iter: 1036 loss: 1.70279094e-07
Iter: 1037 loss: 1.7343153e-07
Iter: 1038 loss: 1.70241009e-07
Iter: 1039 loss: 1.69830386e-07
Iter: 1040 loss: 1.70929439e-07
Iter: 1041 loss: 1.69694886e-07
Iter: 1042 loss: 1.69237126e-07
Iter: 1043 loss: 1.72598959e-07
Iter: 1044 loss: 1.69196028e-07
Iter: 1045 loss: 1.68801733e-07
Iter: 1046 loss: 1.70394486e-07
Iter: 1047 loss: 1.68698477e-07
Iter: 1048 loss: 1.68414687e-07
Iter: 1049 loss: 1.69564473e-07
Iter: 1050 loss: 1.68340264e-07
Iter: 1051 loss: 1.68075388e-07
Iter: 1052 loss: 1.69657611e-07
Iter: 1053 loss: 1.68055678e-07
Iter: 1054 loss: 1.67929528e-07
Iter: 1055 loss: 1.67721595e-07
Iter: 1056 loss: 1.67719875e-07
Iter: 1057 loss: 1.67574058e-07
Iter: 1058 loss: 1.67572509e-07
Iter: 1059 loss: 1.67424702e-07
Iter: 1060 loss: 1.67155449e-07
Iter: 1061 loss: 1.73306333e-07
Iter: 1062 loss: 1.67159428e-07
Iter: 1063 loss: 1.66866812e-07
Iter: 1064 loss: 1.66530498e-07
Iter: 1065 loss: 1.66501806e-07
Iter: 1066 loss: 1.66148752e-07
Iter: 1067 loss: 1.66156354e-07
Iter: 1068 loss: 1.65788492e-07
Iter: 1069 loss: 1.6679941e-07
Iter: 1070 loss: 1.6569723e-07
Iter: 1071 loss: 1.65485503e-07
Iter: 1072 loss: 1.65286096e-07
Iter: 1073 loss: 1.65254676e-07
Iter: 1074 loss: 1.65022442e-07
Iter: 1075 loss: 1.67317779e-07
Iter: 1076 loss: 1.64998e-07
Iter: 1077 loss: 1.64759854e-07
Iter: 1078 loss: 1.65694857e-07
Iter: 1079 loss: 1.64714422e-07
Iter: 1080 loss: 1.64452473e-07
Iter: 1081 loss: 1.64631572e-07
Iter: 1082 loss: 1.64277722e-07
Iter: 1083 loss: 1.6402052e-07
Iter: 1084 loss: 1.67165837e-07
Iter: 1085 loss: 1.64022069e-07
Iter: 1086 loss: 1.63769016e-07
Iter: 1087 loss: 1.63527e-07
Iter: 1088 loss: 1.63490029e-07
Iter: 1089 loss: 1.63151867e-07
Iter: 1090 loss: 1.63220591e-07
Iter: 1091 loss: 1.6287764e-07
Iter: 1092 loss: 1.62561236e-07
Iter: 1093 loss: 1.62528707e-07
Iter: 1094 loss: 1.6235883e-07
Iter: 1095 loss: 1.62000575e-07
Iter: 1096 loss: 1.69350642e-07
Iter: 1097 loss: 1.62015795e-07
Iter: 1098 loss: 1.61760838e-07
Iter: 1099 loss: 1.63481829e-07
Iter: 1100 loss: 1.61724898e-07
Iter: 1101 loss: 1.61511593e-07
Iter: 1102 loss: 1.62943437e-07
Iter: 1103 loss: 1.61479491e-07
Iter: 1104 loss: 1.61287915e-07
Iter: 1105 loss: 1.60898992e-07
Iter: 1106 loss: 1.67715598e-07
Iter: 1107 loss: 1.60875572e-07
Iter: 1108 loss: 1.60431014e-07
Iter: 1109 loss: 1.61578782e-07
Iter: 1110 loss: 1.60264577e-07
Iter: 1111 loss: 1.59950133e-07
Iter: 1112 loss: 1.59940896e-07
Iter: 1113 loss: 1.5968331e-07
Iter: 1114 loss: 1.59897652e-07
Iter: 1115 loss: 1.59548e-07
Iter: 1116 loss: 1.59321971e-07
Iter: 1117 loss: 1.61368192e-07
Iter: 1118 loss: 1.59309408e-07
Iter: 1119 loss: 1.59117633e-07
Iter: 1120 loss: 1.59735322e-07
Iter: 1121 loss: 1.59073352e-07
Iter: 1122 loss: 1.589475e-07
Iter: 1123 loss: 1.58789362e-07
Iter: 1124 loss: 1.58783536e-07
Iter: 1125 loss: 1.58611527e-07
Iter: 1126 loss: 1.61229892e-07
Iter: 1127 loss: 1.58606653e-07
Iter: 1128 loss: 1.58441239e-07
Iter: 1129 loss: 1.5808925e-07
Iter: 1130 loss: 1.64699742e-07
Iter: 1131 loss: 1.58070023e-07
Iter: 1132 loss: 1.57686188e-07
Iter: 1133 loss: 1.57740899e-07
Iter: 1134 loss: 1.57382033e-07
Iter: 1135 loss: 1.57205164e-07
Iter: 1136 loss: 1.57067987e-07
Iter: 1137 loss: 1.56859073e-07
Iter: 1138 loss: 1.56532337e-07
Iter: 1139 loss: 1.5653255e-07
Iter: 1140 loss: 1.56201963e-07
Iter: 1141 loss: 1.56775798e-07
Iter: 1142 loss: 1.56076766e-07
Iter: 1143 loss: 1.5583808e-07
Iter: 1144 loss: 1.55853272e-07
Iter: 1145 loss: 1.55622118e-07
Iter: 1146 loss: 1.55654078e-07
Iter: 1147 loss: 1.5544282e-07
Iter: 1148 loss: 1.55174121e-07
Iter: 1149 loss: 1.56985948e-07
Iter: 1150 loss: 1.55138338e-07
Iter: 1151 loss: 1.54883e-07
Iter: 1152 loss: 1.56003324e-07
Iter: 1153 loss: 1.5482604e-07
Iter: 1154 loss: 1.5461373e-07
Iter: 1155 loss: 1.54246806e-07
Iter: 1156 loss: 1.54233845e-07
Iter: 1157 loss: 1.53880734e-07
Iter: 1158 loss: 1.56245903e-07
Iter: 1159 loss: 1.53846756e-07
Iter: 1160 loss: 1.53455602e-07
Iter: 1161 loss: 1.55402489e-07
Iter: 1162 loss: 1.53396059e-07
Iter: 1163 loss: 1.5321109e-07
Iter: 1164 loss: 1.52871053e-07
Iter: 1165 loss: 1.52862498e-07
Iter: 1166 loss: 1.5270038e-07
Iter: 1167 loss: 1.5267031e-07
Iter: 1168 loss: 1.52477114e-07
Iter: 1169 loss: 1.5228099e-07
Iter: 1170 loss: 1.52219116e-07
Iter: 1171 loss: 1.51933321e-07
Iter: 1172 loss: 1.51802851e-07
Iter: 1173 loss: 1.51630118e-07
Iter: 1174 loss: 1.51199657e-07
Iter: 1175 loss: 1.5323873e-07
Iter: 1176 loss: 1.51116382e-07
Iter: 1177 loss: 1.50970138e-07
Iter: 1178 loss: 1.50910665e-07
Iter: 1179 loss: 1.50785183e-07
Iter: 1180 loss: 1.50508441e-07
Iter: 1181 loss: 1.55407534e-07
Iter: 1182 loss: 1.50504292e-07
Iter: 1183 loss: 1.50251111e-07
Iter: 1184 loss: 1.53008045e-07
Iter: 1185 loss: 1.50251765e-07
Iter: 1186 loss: 1.50003743e-07
Iter: 1187 loss: 1.5099269e-07
Iter: 1188 loss: 1.4996138e-07
Iter: 1189 loss: 1.49768567e-07
Iter: 1190 loss: 1.49388612e-07
Iter: 1191 loss: 1.57953977e-07
Iter: 1192 loss: 1.49400464e-07
Iter: 1193 loss: 1.49008599e-07
Iter: 1194 loss: 1.50407359e-07
Iter: 1195 loss: 1.4892079e-07
Iter: 1196 loss: 1.48666459e-07
Iter: 1197 loss: 1.48657648e-07
Iter: 1198 loss: 1.48518e-07
Iter: 1199 loss: 1.48266651e-07
Iter: 1200 loss: 1.54501521e-07
Iter: 1201 loss: 1.48273685e-07
Iter: 1202 loss: 1.48033948e-07
Iter: 1203 loss: 1.48506729e-07
Iter: 1204 loss: 1.47948782e-07
Iter: 1205 loss: 1.47847928e-07
Iter: 1206 loss: 1.47813992e-07
Iter: 1207 loss: 1.47693697e-07
Iter: 1208 loss: 1.47381087e-07
Iter: 1209 loss: 1.50005178e-07
Iter: 1210 loss: 1.47328791e-07
Iter: 1211 loss: 1.47124595e-07
Iter: 1212 loss: 1.47119181e-07
Iter: 1213 loss: 1.46888951e-07
Iter: 1214 loss: 1.46810379e-07
Iter: 1215 loss: 1.46693068e-07
Iter: 1216 loss: 1.46407345e-07
Iter: 1217 loss: 1.47730859e-07
Iter: 1218 loss: 1.46369288e-07
Iter: 1219 loss: 1.46134283e-07
Iter: 1220 loss: 1.46782469e-07
Iter: 1221 loss: 1.46063883e-07
Iter: 1222 loss: 1.45863325e-07
Iter: 1223 loss: 1.46682993e-07
Iter: 1224 loss: 1.4581812e-07
Iter: 1225 loss: 1.45678342e-07
Iter: 1226 loss: 1.45340081e-07
Iter: 1227 loss: 1.50558265e-07
Iter: 1228 loss: 1.45344814e-07
Iter: 1229 loss: 1.45153308e-07
Iter: 1230 loss: 1.45108601e-07
Iter: 1231 loss: 1.44955763e-07
Iter: 1232 loss: 1.44627563e-07
Iter: 1233 loss: 1.49820437e-07
Iter: 1234 loss: 1.44605607e-07
Iter: 1235 loss: 1.44154541e-07
Iter: 1236 loss: 1.44728375e-07
Iter: 1237 loss: 1.43916594e-07
Iter: 1238 loss: 1.43574397e-07
Iter: 1239 loss: 1.47372958e-07
Iter: 1240 loss: 1.43579229e-07
Iter: 1241 loss: 1.43313329e-07
Iter: 1242 loss: 1.45402709e-07
Iter: 1243 loss: 1.43297683e-07
Iter: 1244 loss: 1.43136248e-07
Iter: 1245 loss: 1.42958143e-07
Iter: 1246 loss: 1.42930034e-07
Iter: 1247 loss: 1.42667943e-07
Iter: 1248 loss: 1.45879341e-07
Iter: 1249 loss: 1.42664476e-07
Iter: 1250 loss: 1.42526574e-07
Iter: 1251 loss: 1.42293814e-07
Iter: 1252 loss: 1.42292635e-07
Iter: 1253 loss: 1.4195939e-07
Iter: 1254 loss: 1.46006883e-07
Iter: 1255 loss: 1.41964151e-07
Iter: 1256 loss: 1.41758193e-07
Iter: 1257 loss: 1.41673524e-07
Iter: 1258 loss: 1.41568592e-07
Iter: 1259 loss: 1.41172166e-07
Iter: 1260 loss: 1.41190299e-07
Iter: 1261 loss: 1.40901889e-07
Iter: 1262 loss: 1.40609103e-07
Iter: 1263 loss: 1.42006328e-07
Iter: 1264 loss: 1.40535008e-07
Iter: 1265 loss: 1.40164332e-07
Iter: 1266 loss: 1.41859687e-07
Iter: 1267 loss: 1.40080687e-07
Iter: 1268 loss: 1.39923912e-07
Iter: 1269 loss: 1.39665758e-07
Iter: 1270 loss: 1.39667804e-07
Iter: 1271 loss: 1.39420095e-07
Iter: 1272 loss: 1.4114417e-07
Iter: 1273 loss: 1.393948e-07
Iter: 1274 loss: 1.39136489e-07
Iter: 1275 loss: 1.40571771e-07
Iter: 1276 loss: 1.39101516e-07
Iter: 1277 loss: 1.38867421e-07
Iter: 1278 loss: 1.38739608e-07
Iter: 1279 loss: 1.38639592e-07
Iter: 1280 loss: 1.38368264e-07
Iter: 1281 loss: 1.41682065e-07
Iter: 1282 loss: 1.38359823e-07
Iter: 1283 loss: 1.3813434e-07
Iter: 1284 loss: 1.37886659e-07
Iter: 1285 loss: 1.37855949e-07
Iter: 1286 loss: 1.37723816e-07
Iter: 1287 loss: 1.376808e-07
Iter: 1288 loss: 1.37557365e-07
Iter: 1289 loss: 1.37373647e-07
Iter: 1290 loss: 1.3737e-07
Iter: 1291 loss: 1.37119116e-07
Iter: 1292 loss: 1.38588589e-07
Iter: 1293 loss: 1.37081372e-07
Iter: 1294 loss: 1.36902472e-07
Iter: 1295 loss: 1.3667443e-07
Iter: 1296 loss: 1.3665931e-07
Iter: 1297 loss: 1.3658665e-07
Iter: 1298 loss: 1.36509129e-07
Iter: 1299 loss: 1.36360967e-07
Iter: 1300 loss: 1.36122225e-07
Iter: 1301 loss: 1.42337711e-07
Iter: 1302 loss: 1.36113812e-07
Iter: 1303 loss: 1.35752799e-07
Iter: 1304 loss: 1.38646953e-07
Iter: 1305 loss: 1.35725656e-07
Iter: 1306 loss: 1.35573913e-07
Iter: 1307 loss: 1.35537462e-07
Iter: 1308 loss: 1.3540695e-07
Iter: 1309 loss: 1.35203763e-07
Iter: 1310 loss: 1.3980943e-07
Iter: 1311 loss: 1.352e-07
Iter: 1312 loss: 1.35065122e-07
Iter: 1313 loss: 1.35070366e-07
Iter: 1314 loss: 1.34934595e-07
Iter: 1315 loss: 1.34882441e-07
Iter: 1316 loss: 1.34781857e-07
Iter: 1317 loss: 1.34682509e-07
Iter: 1318 loss: 1.36472792e-07
Iter: 1319 loss: 1.34680249e-07
Iter: 1320 loss: 1.34541224e-07
Iter: 1321 loss: 1.34385132e-07
Iter: 1322 loss: 1.34365067e-07
Iter: 1323 loss: 1.34155613e-07
Iter: 1324 loss: 1.34765486e-07
Iter: 1325 loss: 1.34103203e-07
Iter: 1326 loss: 1.3386186e-07
Iter: 1327 loss: 1.33959944e-07
Iter: 1328 loss: 1.33698407e-07
Iter: 1329 loss: 1.33534684e-07
Iter: 1330 loss: 1.35068944e-07
Iter: 1331 loss: 1.33525475e-07
Iter: 1332 loss: 1.33337835e-07
Iter: 1333 loss: 1.33450271e-07
Iter: 1334 loss: 1.33237407e-07
Iter: 1335 loss: 1.33069818e-07
Iter: 1336 loss: 1.33150095e-07
Iter: 1337 loss: 1.32959741e-07
Iter: 1338 loss: 1.32837215e-07
Iter: 1339 loss: 1.33587534e-07
Iter: 1340 loss: 1.32821143e-07
Iter: 1341 loss: 1.32663587e-07
Iter: 1342 loss: 1.32504169e-07
Iter: 1343 loss: 1.32461025e-07
Iter: 1344 loss: 1.32244836e-07
Iter: 1345 loss: 1.33566758e-07
Iter: 1346 loss: 1.32221132e-07
Iter: 1347 loss: 1.32041592e-07
Iter: 1348 loss: 1.32411046e-07
Iter: 1349 loss: 1.31960221e-07
Iter: 1350 loss: 1.31822958e-07
Iter: 1351 loss: 1.32235698e-07
Iter: 1352 loss: 1.31789193e-07
Iter: 1353 loss: 1.31609056e-07
Iter: 1354 loss: 1.32613209e-07
Iter: 1355 loss: 1.31585978e-07
Iter: 1356 loss: 1.31502361e-07
Iter: 1357 loss: 1.31320562e-07
Iter: 1358 loss: 1.31326814e-07
Iter: 1359 loss: 1.31136431e-07
Iter: 1360 loss: 1.3280588e-07
Iter: 1361 loss: 1.3113835e-07
Iter: 1362 loss: 1.30975891e-07
Iter: 1363 loss: 1.30642547e-07
Iter: 1364 loss: 1.36352156e-07
Iter: 1365 loss: 1.3063736e-07
Iter: 1366 loss: 1.30368917e-07
Iter: 1367 loss: 1.33996295e-07
Iter: 1368 loss: 1.30375838e-07
Iter: 1369 loss: 1.30173532e-07
Iter: 1370 loss: 1.32519361e-07
Iter: 1371 loss: 1.3016772e-07
Iter: 1372 loss: 1.3011396e-07
Iter: 1373 loss: 1.29979952e-07
Iter: 1374 loss: 1.31964384e-07
Iter: 1375 loss: 1.29965443e-07
Iter: 1376 loss: 1.29887297e-07
Iter: 1377 loss: 1.29869477e-07
Iter: 1378 loss: 1.29802828e-07
Iter: 1379 loss: 1.29716554e-07
Iter: 1380 loss: 1.29708724e-07
Iter: 1381 loss: 1.29577217e-07
Iter: 1382 loss: 1.30568949e-07
Iter: 1383 loss: 1.29573536e-07
Iter: 1384 loss: 1.29466827e-07
Iter: 1385 loss: 1.29391026e-07
Iter: 1386 loss: 1.29343192e-07
Iter: 1387 loss: 1.29162586e-07
Iter: 1388 loss: 1.29972321e-07
Iter: 1389 loss: 1.29146215e-07
Iter: 1390 loss: 1.28911523e-07
Iter: 1391 loss: 1.29249457e-07
Iter: 1392 loss: 1.28811536e-07
Iter: 1393 loss: 1.28703178e-07
Iter: 1394 loss: 1.28676362e-07
Iter: 1395 loss: 1.28602835e-07
Iter: 1396 loss: 1.28452342e-07
Iter: 1397 loss: 1.28507807e-07
Iter: 1398 loss: 1.28361236e-07
Iter: 1399 loss: 1.28199403e-07
Iter: 1400 loss: 1.3025921e-07
Iter: 1401 loss: 1.28195495e-07
Iter: 1402 loss: 1.28074078e-07
Iter: 1403 loss: 1.2804324e-07
Iter: 1404 loss: 1.27959453e-07
Iter: 1405 loss: 1.27857078e-07
Iter: 1406 loss: 1.27847755e-07
Iter: 1407 loss: 1.27746901e-07
Iter: 1408 loss: 1.27547239e-07
Iter: 1409 loss: 1.29138456e-07
Iter: 1410 loss: 1.27469335e-07
Iter: 1411 loss: 1.27266077e-07
Iter: 1412 loss: 1.29534783e-07
Iter: 1413 loss: 1.27283357e-07
Iter: 1414 loss: 1.27151125e-07
Iter: 1415 loss: 1.27148525e-07
Iter: 1416 loss: 1.2707784e-07
Iter: 1417 loss: 1.26968317e-07
Iter: 1418 loss: 1.26967493e-07
Iter: 1419 loss: 1.26822826e-07
Iter: 1420 loss: 1.28094555e-07
Iter: 1421 loss: 1.26813447e-07
Iter: 1422 loss: 1.26670855e-07
Iter: 1423 loss: 1.26947356e-07
Iter: 1424 loss: 1.266109e-07
Iter: 1425 loss: 1.26507047e-07
Iter: 1426 loss: 1.26487762e-07
Iter: 1427 loss: 1.26406135e-07
Iter: 1428 loss: 1.26237907e-07
Iter: 1429 loss: 1.27541099e-07
Iter: 1430 loss: 1.26222417e-07
Iter: 1431 loss: 1.26116703e-07
Iter: 1432 loss: 1.25917509e-07
Iter: 1433 loss: 1.30467754e-07
Iter: 1434 loss: 1.25915136e-07
Iter: 1435 loss: 1.25764245e-07
Iter: 1436 loss: 1.28093689e-07
Iter: 1437 loss: 1.2575579e-07
Iter: 1438 loss: 1.25625249e-07
Iter: 1439 loss: 1.25502112e-07
Iter: 1440 loss: 1.25481449e-07
Iter: 1441 loss: 1.25372054e-07
Iter: 1442 loss: 1.25344812e-07
Iter: 1443 loss: 1.25233669e-07
Iter: 1444 loss: 1.25018474e-07
Iter: 1445 loss: 1.29476746e-07
Iter: 1446 loss: 1.2501134e-07
Iter: 1447 loss: 1.24821824e-07
Iter: 1448 loss: 1.25350013e-07
Iter: 1449 loss: 1.24751921e-07
Iter: 1450 loss: 1.24638376e-07
Iter: 1451 loss: 1.24608746e-07
Iter: 1452 loss: 1.24510095e-07
Iter: 1453 loss: 1.24326448e-07
Iter: 1454 loss: 1.28358749e-07
Iter: 1455 loss: 1.24332033e-07
Iter: 1456 loss: 1.24194599e-07
Iter: 1457 loss: 1.24181099e-07
Iter: 1458 loss: 1.24036831e-07
Iter: 1459 loss: 1.23917346e-07
Iter: 1460 loss: 1.23906986e-07
Iter: 1461 loss: 1.23782087e-07
Iter: 1462 loss: 1.23754376e-07
Iter: 1463 loss: 1.2367201e-07
Iter: 1464 loss: 1.23573756e-07
Iter: 1465 loss: 1.23567744e-07
Iter: 1466 loss: 1.23490338e-07
Iter: 1467 loss: 1.23311935e-07
Iter: 1468 loss: 1.25001407e-07
Iter: 1469 loss: 1.23284536e-07
Iter: 1470 loss: 1.2305523e-07
Iter: 1471 loss: 1.23230009e-07
Iter: 1472 loss: 1.22922629e-07
Iter: 1473 loss: 1.22733667e-07
Iter: 1474 loss: 1.23540332e-07
Iter: 1475 loss: 1.2270732e-07
Iter: 1476 loss: 1.22583714e-07
Iter: 1477 loss: 1.22410597e-07
Iter: 1478 loss: 1.2239127e-07
Iter: 1479 loss: 1.22119388e-07
Iter: 1480 loss: 1.21877719e-07
Iter: 1481 loss: 1.2178856e-07
Iter: 1482 loss: 1.2155428e-07
Iter: 1483 loss: 1.21536488e-07
Iter: 1484 loss: 1.21339966e-07
Iter: 1485 loss: 1.22356582e-07
Iter: 1486 loss: 1.2130522e-07
Iter: 1487 loss: 1.21177678e-07
Iter: 1488 loss: 1.21355654e-07
Iter: 1489 loss: 1.21100697e-07
Iter: 1490 loss: 1.20960692e-07
Iter: 1491 loss: 1.21785959e-07
Iter: 1492 loss: 1.20936249e-07
Iter: 1493 loss: 1.20793288e-07
Iter: 1494 loss: 1.21002671e-07
Iter: 1495 loss: 1.20707028e-07
Iter: 1496 loss: 1.20574612e-07
Iter: 1497 loss: 1.20289613e-07
Iter: 1498 loss: 1.25126476e-07
Iter: 1499 loss: 1.20283261e-07
Iter: 1500 loss: 1.20227867e-07
Iter: 1501 loss: 1.20139973e-07
Iter: 1502 loss: 1.19984151e-07
Iter: 1503 loss: 1.19667391e-07
Iter: 1504 loss: 1.23886508e-07
Iter: 1505 loss: 1.19636709e-07
Iter: 1506 loss: 1.19411396e-07
Iter: 1507 loss: 1.22556926e-07
Iter: 1508 loss: 1.19410444e-07
Iter: 1509 loss: 1.19199868e-07
Iter: 1510 loss: 1.19996386e-07
Iter: 1511 loss: 1.19146371e-07
Iter: 1512 loss: 1.19062662e-07
Iter: 1513 loss: 1.18887705e-07
Iter: 1514 loss: 1.22537116e-07
Iter: 1515 loss: 1.18878489e-07
Iter: 1516 loss: 1.18723563e-07
Iter: 1517 loss: 1.18722781e-07
Iter: 1518 loss: 1.18592723e-07
Iter: 1519 loss: 1.18441491e-07
Iter: 1520 loss: 1.18463873e-07
Iter: 1521 loss: 1.18323356e-07
Iter: 1522 loss: 1.18095549e-07
Iter: 1523 loss: 1.20676447e-07
Iter: 1524 loss: 1.18094974e-07
Iter: 1525 loss: 1.17977528e-07
Iter: 1526 loss: 1.17888902e-07
Iter: 1527 loss: 1.17857617e-07
Iter: 1528 loss: 1.17688593e-07
Iter: 1529 loss: 1.18430776e-07
Iter: 1530 loss: 1.1765453e-07
Iter: 1531 loss: 1.17508847e-07
Iter: 1532 loss: 1.18281022e-07
Iter: 1533 loss: 1.17491794e-07
Iter: 1534 loss: 1.17368124e-07
Iter: 1535 loss: 1.17718912e-07
Iter: 1536 loss: 1.17323552e-07
Iter: 1537 loss: 1.17208522e-07
Iter: 1538 loss: 1.17460914e-07
Iter: 1539 loss: 1.17162301e-07
Iter: 1540 loss: 1.17010934e-07
Iter: 1541 loss: 1.17226023e-07
Iter: 1542 loss: 1.16926259e-07
Iter: 1543 loss: 1.16801232e-07
Iter: 1544 loss: 1.170621e-07
Iter: 1545 loss: 1.16749128e-07
Iter: 1546 loss: 1.16575819e-07
Iter: 1547 loss: 1.17262374e-07
Iter: 1548 loss: 1.16533947e-07
Iter: 1549 loss: 1.16440916e-07
Iter: 1550 loss: 1.16334419e-07
Iter: 1551 loss: 1.16311739e-07
Iter: 1552 loss: 1.16192915e-07
Iter: 1553 loss: 1.17834e-07
Iter: 1554 loss: 1.1619268e-07
Iter: 1555 loss: 1.16091584e-07
Iter: 1556 loss: 1.16231249e-07
Iter: 1557 loss: 1.16045271e-07
Iter: 1558 loss: 1.15956674e-07
Iter: 1559 loss: 1.17110908e-07
Iter: 1560 loss: 1.15955231e-07
Iter: 1561 loss: 1.15886053e-07
Iter: 1562 loss: 1.15719629e-07
Iter: 1563 loss: 1.17701305e-07
Iter: 1564 loss: 1.15709497e-07
Iter: 1565 loss: 1.15492028e-07
Iter: 1566 loss: 1.17013343e-07
Iter: 1567 loss: 1.15482599e-07
Iter: 1568 loss: 1.15341486e-07
Iter: 1569 loss: 1.16005758e-07
Iter: 1570 loss: 1.15331268e-07
Iter: 1571 loss: 1.1521314e-07
Iter: 1572 loss: 1.15478791e-07
Iter: 1573 loss: 1.15156965e-07
Iter: 1574 loss: 1.15067159e-07
Iter: 1575 loss: 1.15437189e-07
Iter: 1576 loss: 1.15041942e-07
Iter: 1577 loss: 1.14950467e-07
Iter: 1578 loss: 1.14952087e-07
Iter: 1579 loss: 1.14867042e-07
Iter: 1580 loss: 1.1476827e-07
Iter: 1581 loss: 1.16215233e-07
Iter: 1582 loss: 1.14763409e-07
Iter: 1583 loss: 1.14677931e-07
Iter: 1584 loss: 1.14512602e-07
Iter: 1585 loss: 1.18064399e-07
Iter: 1586 loss: 1.14512474e-07
Iter: 1587 loss: 1.14321821e-07
Iter: 1588 loss: 1.14367523e-07
Iter: 1589 loss: 1.14179471e-07
Iter: 1590 loss: 1.13871693e-07
Iter: 1591 loss: 1.15873476e-07
Iter: 1592 loss: 1.13850803e-07
Iter: 1593 loss: 1.13667184e-07
Iter: 1594 loss: 1.15589586e-07
Iter: 1595 loss: 1.13665273e-07
Iter: 1596 loss: 1.13529943e-07
Iter: 1597 loss: 1.13585145e-07
Iter: 1598 loss: 1.13438723e-07
Iter: 1599 loss: 1.13316126e-07
Iter: 1600 loss: 1.13652838e-07
Iter: 1601 loss: 1.13273146e-07
Iter: 1602 loss: 1.13107568e-07
Iter: 1603 loss: 1.13413542e-07
Iter: 1604 loss: 1.13056203e-07
Iter: 1605 loss: 1.12905603e-07
Iter: 1606 loss: 1.14466971e-07
Iter: 1607 loss: 1.12902441e-07
Iter: 1608 loss: 1.12783042e-07
Iter: 1609 loss: 1.12653552e-07
Iter: 1610 loss: 1.12634467e-07
Iter: 1611 loss: 1.12418263e-07
Iter: 1612 loss: 1.13754375e-07
Iter: 1613 loss: 1.12380867e-07
Iter: 1614 loss: 1.12228335e-07
Iter: 1615 loss: 1.12849996e-07
Iter: 1616 loss: 1.12187635e-07
Iter: 1617 loss: 1.1198658e-07
Iter: 1618 loss: 1.12126202e-07
Iter: 1619 loss: 1.11872524e-07
Iter: 1620 loss: 1.1174469e-07
Iter: 1621 loss: 1.11944587e-07
Iter: 1622 loss: 1.11698334e-07
Iter: 1623 loss: 1.115747e-07
Iter: 1624 loss: 1.12228946e-07
Iter: 1625 loss: 1.11562073e-07
Iter: 1626 loss: 1.11432826e-07
Iter: 1627 loss: 1.11672279e-07
Iter: 1628 loss: 1.11381283e-07
Iter: 1629 loss: 1.11222761e-07
Iter: 1630 loss: 1.11897677e-07
Iter: 1631 loss: 1.11173492e-07
Iter: 1632 loss: 1.11055442e-07
Iter: 1633 loss: 1.10982462e-07
Iter: 1634 loss: 1.10941926e-07
Iter: 1635 loss: 1.10725253e-07
Iter: 1636 loss: 1.1154907e-07
Iter: 1637 loss: 1.10693378e-07
Iter: 1638 loss: 1.10512886e-07
Iter: 1639 loss: 1.11897926e-07
Iter: 1640 loss: 1.10495051e-07
Iter: 1641 loss: 1.1034e-07
Iter: 1642 loss: 1.10366905e-07
Iter: 1643 loss: 1.10214742e-07
Iter: 1644 loss: 1.10089246e-07
Iter: 1645 loss: 1.11331175e-07
Iter: 1646 loss: 1.10094689e-07
Iter: 1647 loss: 1.09990076e-07
Iter: 1648 loss: 1.10099641e-07
Iter: 1649 loss: 1.09942278e-07
Iter: 1650 loss: 1.09817982e-07
Iter: 1651 loss: 1.10220583e-07
Iter: 1652 loss: 1.09784118e-07
Iter: 1653 loss: 1.09681004e-07
Iter: 1654 loss: 1.09512044e-07
Iter: 1655 loss: 1.09502913e-07
Iter: 1656 loss: 1.09324439e-07
Iter: 1657 loss: 1.11441494e-07
Iter: 1658 loss: 1.09327488e-07
Iter: 1659 loss: 1.091651e-07
Iter: 1660 loss: 1.09316602e-07
Iter: 1661 loss: 1.09081284e-07
Iter: 1662 loss: 1.0888531e-07
Iter: 1663 loss: 1.1035111e-07
Iter: 1664 loss: 1.08859247e-07
Iter: 1665 loss: 1.08706715e-07
Iter: 1666 loss: 1.08610308e-07
Iter: 1667 loss: 1.08555014e-07
Iter: 1668 loss: 1.08327271e-07
Iter: 1669 loss: 1.09451939e-07
Iter: 1670 loss: 1.08299673e-07
Iter: 1671 loss: 1.08162112e-07
Iter: 1672 loss: 1.0877956e-07
Iter: 1673 loss: 1.08131786e-07
Iter: 1674 loss: 1.07991866e-07
Iter: 1675 loss: 1.08232712e-07
Iter: 1676 loss: 1.07931605e-07
Iter: 1677 loss: 1.07805008e-07
Iter: 1678 loss: 1.0795241e-07
Iter: 1679 loss: 1.07731474e-07
Iter: 1680 loss: 1.07541794e-07
Iter: 1681 loss: 1.07971132e-07
Iter: 1682 loss: 1.07490926e-07
Iter: 1683 loss: 1.07312786e-07
Iter: 1684 loss: 1.08758101e-07
Iter: 1685 loss: 1.0729832e-07
Iter: 1686 loss: 1.07177712e-07
Iter: 1687 loss: 1.06945507e-07
Iter: 1688 loss: 1.11945532e-07
Iter: 1689 loss: 1.06947802e-07
Iter: 1690 loss: 1.06703872e-07
Iter: 1691 loss: 1.08223389e-07
Iter: 1692 loss: 1.0667361e-07
Iter: 1693 loss: 1.06454905e-07
Iter: 1694 loss: 1.0761201e-07
Iter: 1695 loss: 1.06423187e-07
Iter: 1696 loss: 1.06278335e-07
Iter: 1697 loss: 1.07382419e-07
Iter: 1698 loss: 1.06276815e-07
Iter: 1699 loss: 1.06148043e-07
Iter: 1700 loss: 1.06165032e-07
Iter: 1701 loss: 1.06067183e-07
Iter: 1702 loss: 1.05938007e-07
Iter: 1703 loss: 1.06384306e-07
Iter: 1704 loss: 1.05902231e-07
Iter: 1705 loss: 1.05748839e-07
Iter: 1706 loss: 1.06085125e-07
Iter: 1707 loss: 1.05721e-07
Iter: 1708 loss: 1.05553447e-07
Iter: 1709 loss: 1.06291672e-07
Iter: 1710 loss: 1.05521679e-07
Iter: 1711 loss: 1.05403217e-07
Iter: 1712 loss: 1.05315465e-07
Iter: 1713 loss: 1.05277614e-07
Iter: 1714 loss: 1.0506588e-07
Iter: 1715 loss: 1.06152399e-07
Iter: 1716 loss: 1.05019225e-07
Iter: 1717 loss: 1.04852404e-07
Iter: 1718 loss: 1.05477042e-07
Iter: 1719 loss: 1.048233e-07
Iter: 1720 loss: 1.04637671e-07
Iter: 1721 loss: 1.04737119e-07
Iter: 1722 loss: 1.04532958e-07
Iter: 1723 loss: 1.04374294e-07
Iter: 1724 loss: 1.04550907e-07
Iter: 1725 loss: 1.04304128e-07
Iter: 1726 loss: 1.04126435e-07
Iter: 1727 loss: 1.053901e-07
Iter: 1728 loss: 1.04118236e-07
Iter: 1729 loss: 1.0398935e-07
Iter: 1730 loss: 1.04503613e-07
Iter: 1731 loss: 1.03942092e-07
Iter: 1732 loss: 1.03824391e-07
Iter: 1733 loss: 1.04059282e-07
Iter: 1734 loss: 1.03761259e-07
Iter: 1735 loss: 1.03637383e-07
Iter: 1736 loss: 1.03771654e-07
Iter: 1737 loss: 1.03563281e-07
Iter: 1738 loss: 1.03416816e-07
Iter: 1739 loss: 1.03737385e-07
Iter: 1740 loss: 1.03359611e-07
Iter: 1741 loss: 1.03189493e-07
Iter: 1742 loss: 1.04544931e-07
Iter: 1743 loss: 1.03183311e-07
Iter: 1744 loss: 1.03066952e-07
Iter: 1745 loss: 1.02991422e-07
Iter: 1746 loss: 1.02963824e-07
Iter: 1747 loss: 1.02821915e-07
Iter: 1748 loss: 1.04418731e-07
Iter: 1749 loss: 1.02823421e-07
Iter: 1750 loss: 1.02727242e-07
Iter: 1751 loss: 1.02767963e-07
Iter: 1752 loss: 1.02655456e-07
Iter: 1753 loss: 1.02483938e-07
Iter: 1754 loss: 1.02744366e-07
Iter: 1755 loss: 1.02386345e-07
Iter: 1756 loss: 1.02234893e-07
Iter: 1757 loss: 1.02252798e-07
Iter: 1758 loss: 1.02128325e-07
Iter: 1759 loss: 1.01925615e-07
Iter: 1760 loss: 1.04062892e-07
Iter: 1761 loss: 1.01930382e-07
Iter: 1762 loss: 1.0177726e-07
Iter: 1763 loss: 1.01983538e-07
Iter: 1764 loss: 1.01703804e-07
Iter: 1765 loss: 1.01512626e-07
Iter: 1766 loss: 1.02540398e-07
Iter: 1767 loss: 1.01477397e-07
Iter: 1768 loss: 1.01369665e-07
Iter: 1769 loss: 1.01350928e-07
Iter: 1770 loss: 1.01278012e-07
Iter: 1771 loss: 1.01082009e-07
Iter: 1772 loss: 1.01661186e-07
Iter: 1773 loss: 1.01053772e-07
Iter: 1774 loss: 1.00897573e-07
Iter: 1775 loss: 1.02202492e-07
Iter: 1776 loss: 1.0089326e-07
Iter: 1777 loss: 1.00772212e-07
Iter: 1778 loss: 1.00530009e-07
Iter: 1779 loss: 1.05607768e-07
Iter: 1780 loss: 1.00532056e-07
Iter: 1781 loss: 1.00336727e-07
Iter: 1782 loss: 1.03526219e-07
Iter: 1783 loss: 1.00338241e-07
Iter: 1784 loss: 1.00176081e-07
Iter: 1785 loss: 1.00279124e-07
Iter: 1786 loss: 1.00068689e-07
Iter: 1787 loss: 9.98677336e-08
Iter: 1788 loss: 1.00775011e-07
Iter: 1789 loss: 9.98371661e-08
Iter: 1790 loss: 9.9695e-08
Iter: 1791 loss: 9.95553648e-08
Iter: 1792 loss: 9.95208183e-08
Iter: 1793 loss: 9.93631915e-08
Iter: 1794 loss: 1.01739197e-07
Iter: 1795 loss: 9.93694442e-08
Iter: 1796 loss: 9.92293963e-08
Iter: 1797 loss: 9.98046232e-08
Iter: 1798 loss: 9.9213e-08
Iter: 1799 loss: 9.90820439e-08
Iter: 1800 loss: 9.97139153e-08
Iter: 1801 loss: 9.90713e-08
Iter: 1802 loss: 9.90006939e-08
Iter: 1803 loss: 9.89549207e-08
Iter: 1804 loss: 9.8927643e-08
Iter: 1805 loss: 9.8779438e-08
Iter: 1806 loss: 9.91556419e-08
Iter: 1807 loss: 9.87380417e-08
Iter: 1808 loss: 9.860441e-08
Iter: 1809 loss: 9.96374609e-08
Iter: 1810 loss: 9.85948816e-08
Iter: 1811 loss: 9.84641275e-08
Iter: 1812 loss: 9.8225641e-08
Iter: 1813 loss: 9.82239143e-08
Iter: 1814 loss: 9.79918298e-08
Iter: 1815 loss: 1.00167426e-07
Iter: 1816 loss: 9.79981536e-08
Iter: 1817 loss: 9.77809407e-08
Iter: 1818 loss: 9.82740787e-08
Iter: 1819 loss: 9.77117693e-08
Iter: 1820 loss: 9.75487353e-08
Iter: 1821 loss: 9.84758373e-08
Iter: 1822 loss: 9.75328049e-08
Iter: 1823 loss: 9.74071384e-08
Iter: 1824 loss: 9.72521121e-08
Iter: 1825 loss: 9.72411272e-08
Iter: 1826 loss: 9.70699077e-08
Iter: 1827 loss: 9.80841506e-08
Iter: 1828 loss: 9.70526912e-08
Iter: 1829 loss: 9.68682e-08
Iter: 1830 loss: 9.78129435e-08
Iter: 1831 loss: 9.68362173e-08
Iter: 1832 loss: 9.66935261e-08
Iter: 1833 loss: 9.73648326e-08
Iter: 1834 loss: 9.66709806e-08
Iter: 1835 loss: 9.65381091e-08
Iter: 1836 loss: 9.64769669e-08
Iter: 1837 loss: 9.6411128e-08
Iter: 1838 loss: 9.62103357e-08
Iter: 1839 loss: 9.69387202e-08
Iter: 1840 loss: 9.61719167e-08
Iter: 1841 loss: 9.6031e-08
Iter: 1842 loss: 9.70910534e-08
Iter: 1843 loss: 9.60095718e-08
Iter: 1844 loss: 9.58511635e-08
Iter: 1845 loss: 9.58261168e-08
Iter: 1846 loss: 9.57276427e-08
Iter: 1847 loss: 9.55930659e-08
Iter: 1848 loss: 9.63426885e-08
Iter: 1849 loss: 9.55870476e-08
Iter: 1850 loss: 9.5457132e-08
Iter: 1851 loss: 9.6006346e-08
Iter: 1852 loss: 9.54411306e-08
Iter: 1853 loss: 9.53591197e-08
Iter: 1854 loss: 9.56465342e-08
Iter: 1855 loss: 9.53345705e-08
Iter: 1856 loss: 9.52379935e-08
Iter: 1857 loss: 9.51572616e-08
Iter: 1858 loss: 9.51330676e-08
Iter: 1859 loss: 9.50016101e-08
Iter: 1860 loss: 9.52831414e-08
Iter: 1861 loss: 9.49576346e-08
Iter: 1862 loss: 9.47886036e-08
Iter: 1863 loss: 9.60069428e-08
Iter: 1864 loss: 9.47774907e-08
Iter: 1865 loss: 9.46605496e-08
Iter: 1866 loss: 9.50050492e-08
Iter: 1867 loss: 9.46343874e-08
Iter: 1868 loss: 9.4479141e-08
Iter: 1869 loss: 9.46764587e-08
Iter: 1870 loss: 9.43960146e-08
Iter: 1871 loss: 9.42705327e-08
Iter: 1872 loss: 9.4572556e-08
Iter: 1873 loss: 9.42285823e-08
Iter: 1874 loss: 9.40955687e-08
Iter: 1875 loss: 9.48086409e-08
Iter: 1876 loss: 9.40842284e-08
Iter: 1877 loss: 9.39642604e-08
Iter: 1878 loss: 9.41887208e-08
Iter: 1879 loss: 9.39131297e-08
Iter: 1880 loss: 9.38298541e-08
Iter: 1881 loss: 9.3864287e-08
Iter: 1882 loss: 9.37670137e-08
Iter: 1883 loss: 9.36373752e-08
Iter: 1884 loss: 9.43513214e-08
Iter: 1885 loss: 9.36133873e-08
Iter: 1886 loss: 9.35134352e-08
Iter: 1887 loss: 9.37527176e-08
Iter: 1888 loss: 9.34816171e-08
Iter: 1889 loss: 9.33460598e-08
Iter: 1890 loss: 9.32144246e-08
Iter: 1891 loss: 9.31839921e-08
Iter: 1892 loss: 9.29700832e-08
Iter: 1893 loss: 9.31073885e-08
Iter: 1894 loss: 9.28355632e-08
Iter: 1895 loss: 9.26282695e-08
Iter: 1896 loss: 9.26247239e-08
Iter: 1897 loss: 9.24895289e-08
Iter: 1898 loss: 9.27682393e-08
Iter: 1899 loss: 9.2429886e-08
Iter: 1900 loss: 9.22779932e-08
Iter: 1901 loss: 9.29604624e-08
Iter: 1902 loss: 9.22490955e-08
Iter: 1903 loss: 9.21450791e-08
Iter: 1904 loss: 9.22335062e-08
Iter: 1905 loss: 9.20841288e-08
Iter: 1906 loss: 9.19668395e-08
Iter: 1907 loss: 9.25626864e-08
Iter: 1908 loss: 9.19506249e-08
Iter: 1909 loss: 9.18378191e-08
Iter: 1910 loss: 9.21403682e-08
Iter: 1911 loss: 9.18167586e-08
Iter: 1912 loss: 9.1731323e-08
Iter: 1913 loss: 9.16215939e-08
Iter: 1914 loss: 9.16270722e-08
Iter: 1915 loss: 9.14581477e-08
Iter: 1916 loss: 9.30129147e-08
Iter: 1917 loss: 9.14311897e-08
Iter: 1918 loss: 9.13020841e-08
Iter: 1919 loss: 9.14495928e-08
Iter: 1920 loss: 9.12243081e-08
Iter: 1921 loss: 9.10432334e-08
Iter: 1922 loss: 9.10771405e-08
Iter: 1923 loss: 9.09068163e-08
Iter: 1924 loss: 9.06969575e-08
Iter: 1925 loss: 9.08270223e-08
Iter: 1926 loss: 9.05705519e-08
Iter: 1927 loss: 9.04393644e-08
Iter: 1928 loss: 9.04324153e-08
Iter: 1929 loss: 9.03145221e-08
Iter: 1930 loss: 9.05015725e-08
Iter: 1931 loss: 9.0261878e-08
Iter: 1932 loss: 9.01456474e-08
Iter: 1933 loss: 9.09850471e-08
Iter: 1934 loss: 9.01405599e-08
Iter: 1935 loss: 9.00586201e-08
Iter: 1936 loss: 9.01023043e-08
Iter: 1937 loss: 8.99962913e-08
Iter: 1938 loss: 8.9893561e-08
Iter: 1939 loss: 9.02350621e-08
Iter: 1940 loss: 8.98695234e-08
Iter: 1941 loss: 8.97544e-08
Iter: 1942 loss: 8.99748258e-08
Iter: 1943 loss: 8.96947725e-08
Iter: 1944 loss: 8.95556198e-08
Iter: 1945 loss: 8.939314e-08
Iter: 1946 loss: 8.93703174e-08
Iter: 1947 loss: 8.92118877e-08
Iter: 1948 loss: 8.9199e-08
Iter: 1949 loss: 8.90909178e-08
Iter: 1950 loss: 8.9112838e-08
Iter: 1951 loss: 8.89913352e-08
Iter: 1952 loss: 8.87978331e-08
Iter: 1953 loss: 8.89773872e-08
Iter: 1954 loss: 8.86892195e-08
Iter: 1955 loss: 8.85325164e-08
Iter: 1956 loss: 8.84805829e-08
Iter: 1957 loss: 8.83953533e-08
Iter: 1958 loss: 8.82292852e-08
Iter: 1959 loss: 8.98517953e-08
Iter: 1960 loss: 8.82150673e-08
Iter: 1961 loss: 8.80486581e-08
Iter: 1962 loss: 8.87593359e-08
Iter: 1963 loss: 8.80078e-08
Iter: 1964 loss: 8.78566553e-08
Iter: 1965 loss: 8.83516407e-08
Iter: 1966 loss: 8.78227908e-08
Iter: 1967 loss: 8.76823236e-08
Iter: 1968 loss: 8.78261233e-08
Iter: 1969 loss: 8.75947137e-08
Iter: 1970 loss: 8.74472192e-08
Iter: 1971 loss: 8.79421833e-08
Iter: 1972 loss: 8.73920669e-08
Iter: 1973 loss: 8.72326424e-08
Iter: 1974 loss: 8.79152822e-08
Iter: 1975 loss: 8.7200462e-08
Iter: 1976 loss: 8.70520793e-08
Iter: 1977 loss: 8.6937078e-08
Iter: 1978 loss: 8.69027588e-08
Iter: 1979 loss: 8.67624266e-08
Iter: 1980 loss: 8.89884e-08
Iter: 1981 loss: 8.6762924e-08
Iter: 1982 loss: 8.66336336e-08
Iter: 1983 loss: 8.68499157e-08
Iter: 1984 loss: 8.65811245e-08
Iter: 1985 loss: 8.64499299e-08
Iter: 1986 loss: 8.69514309e-08
Iter: 1987 loss: 8.6433289e-08
Iter: 1988 loss: 8.63480949e-08
Iter: 1989 loss: 8.6172e-08
Iter: 1990 loss: 8.9266166e-08
Iter: 1991 loss: 8.61750209e-08
Iter: 1992 loss: 8.59882192e-08
Iter: 1993 loss: 8.72320172e-08
Iter: 1994 loss: 8.59669171e-08
Iter: 1995 loss: 8.58428351e-08
Iter: 1996 loss: 8.72304042e-08
Iter: 1997 loss: 8.58324043e-08
Iter: 1998 loss: 8.57229594e-08
Iter: 1999 loss: 8.58757687e-08
Iter: 2000 loss: 8.56693418e-08
Iter: 2001 loss: 8.55355538e-08
Iter: 2002 loss: 8.58699494e-08
Iter: 2003 loss: 8.54885798e-08
Iter: 2004 loss: 8.53727897e-08
Iter: 2005 loss: 8.56473e-08
Iter: 2006 loss: 8.53322248e-08
Iter: 2007 loss: 8.52443236e-08
Iter: 2008 loss: 8.58254694e-08
Iter: 2009 loss: 8.52315267e-08
Iter: 2010 loss: 8.51566568e-08
Iter: 2011 loss: 8.5108681e-08
Iter: 2012 loss: 8.50822417e-08
Iter: 2013 loss: 8.4958117e-08
Iter: 2014 loss: 8.53275139e-08
Iter: 2015 loss: 8.493042e-08
Iter: 2016 loss: 8.47888089e-08
Iter: 2017 loss: 8.52830908e-08
Iter: 2018 loss: 8.47545607e-08
Iter: 2019 loss: 8.46488746e-08
Iter: 2020 loss: 8.51535944e-08
Iter: 2021 loss: 8.46299884e-08
Iter: 2022 loss: 8.45471e-08
Iter: 2023 loss: 8.43914307e-08
Iter: 2024 loss: 8.43851353e-08
Iter: 2025 loss: 8.42350261e-08
Iter: 2026 loss: 8.45453911e-08
Iter: 2027 loss: 8.41595948e-08
Iter: 2028 loss: 8.40455172e-08
Iter: 2029 loss: 8.40338217e-08
Iter: 2030 loss: 8.39497361e-08
Iter: 2031 loss: 8.39767935e-08
Iter: 2032 loss: 8.38887217e-08
Iter: 2033 loss: 8.37677732e-08
Iter: 2034 loss: 8.44014636e-08
Iter: 2035 loss: 8.37391951e-08
Iter: 2036 loss: 8.36587333e-08
Iter: 2037 loss: 8.37459737e-08
Iter: 2038 loss: 8.36108285e-08
Iter: 2039 loss: 8.3503771e-08
Iter: 2040 loss: 8.38484553e-08
Iter: 2041 loss: 8.34831e-08
Iter: 2042 loss: 8.33822185e-08
Iter: 2043 loss: 8.33332052e-08
Iter: 2044 loss: 8.32878086e-08
Iter: 2045 loss: 8.3121229e-08
Iter: 2046 loss: 8.31784561e-08
Iter: 2047 loss: 8.30034637e-08
Iter: 2048 loss: 8.28662223e-08
Iter: 2049 loss: 8.28566e-08
Iter: 2050 loss: 8.27808222e-08
Iter: 2051 loss: 8.28648794e-08
Iter: 2052 loss: 8.27234317e-08
Iter: 2053 loss: 8.26256e-08
Iter: 2054 loss: 8.27393052e-08
Iter: 2055 loss: 8.25806481e-08
Iter: 2056 loss: 8.25038526e-08
Iter: 2057 loss: 8.24578e-08
Iter: 2058 loss: 8.2421046e-08
Iter: 2059 loss: 8.23481e-08
Iter: 2060 loss: 8.23432629e-08
Iter: 2061 loss: 8.22729547e-08
Iter: 2062 loss: 8.22369941e-08
Iter: 2063 loss: 8.22056307e-08
Iter: 2064 loss: 8.21113275e-08
Iter: 2065 loss: 8.31280502e-08
Iter: 2066 loss: 8.21053234e-08
Iter: 2067 loss: 8.20346884e-08
Iter: 2068 loss: 8.19905566e-08
Iter: 2069 loss: 8.19695387e-08
Iter: 2070 loss: 8.18622468e-08
Iter: 2071 loss: 8.24757507e-08
Iter: 2072 loss: 8.18511126e-08
Iter: 2073 loss: 8.17562125e-08
Iter: 2074 loss: 8.19786194e-08
Iter: 2075 loss: 8.17137575e-08
Iter: 2076 loss: 8.1640259e-08
Iter: 2077 loss: 8.16150276e-08
Iter: 2078 loss: 8.1575763e-08
Iter: 2079 loss: 8.14860783e-08
Iter: 2080 loss: 8.14967578e-08
Iter: 2081 loss: 8.14292349e-08
Iter: 2082 loss: 8.14902208e-08
Iter: 2083 loss: 8.13938144e-08
Iter: 2084 loss: 8.13376602e-08
Iter: 2085 loss: 8.16541572e-08
Iter: 2086 loss: 8.13216943e-08
Iter: 2087 loss: 8.12688228e-08
Iter: 2088 loss: 8.11736882e-08
Iter: 2089 loss: 8.11807e-08
Iter: 2090 loss: 8.10655578e-08
Iter: 2091 loss: 8.1658122e-08
Iter: 2092 loss: 8.10602e-08
Iter: 2093 loss: 8.09416179e-08
Iter: 2094 loss: 8.18159833e-08
Iter: 2095 loss: 8.09347398e-08
Iter: 2096 loss: 8.08683751e-08
Iter: 2097 loss: 8.12284924e-08
Iter: 2098 loss: 8.08582357e-08
Iter: 2099 loss: 8.07990759e-08
Iter: 2100 loss: 8.07871e-08
Iter: 2101 loss: 8.07518745e-08
Iter: 2102 loss: 8.06743401e-08
Iter: 2103 loss: 8.08988645e-08
Iter: 2104 loss: 8.06489e-08
Iter: 2105 loss: 8.05840585e-08
Iter: 2106 loss: 8.09479701e-08
Iter: 2107 loss: 8.05722564e-08
Iter: 2108 loss: 8.05126774e-08
Iter: 2109 loss: 8.04190776e-08
Iter: 2110 loss: 8.04212874e-08
Iter: 2111 loss: 8.02951519e-08
Iter: 2112 loss: 8.08082e-08
Iter: 2113 loss: 8.02576778e-08
Iter: 2114 loss: 8.01458739e-08
Iter: 2115 loss: 8.14166157e-08
Iter: 2116 loss: 8.01428399e-08
Iter: 2117 loss: 8.00872826e-08
Iter: 2118 loss: 8.01716382e-08
Iter: 2119 loss: 8.00585838e-08
Iter: 2120 loss: 7.99797419e-08
Iter: 2121 loss: 7.99960631e-08
Iter: 2122 loss: 7.99280073e-08
Iter: 2123 loss: 7.98583457e-08
Iter: 2124 loss: 7.99994311e-08
Iter: 2125 loss: 7.9821227e-08
Iter: 2126 loss: 7.97661528e-08
Iter: 2127 loss: 7.9766366e-08
Iter: 2128 loss: 7.97144e-08
Iter: 2129 loss: 7.96325708e-08
Iter: 2130 loss: 7.96313e-08
Iter: 2131 loss: 7.95153312e-08
Iter: 2132 loss: 8.05061831e-08
Iter: 2133 loss: 7.95048e-08
Iter: 2134 loss: 7.94352e-08
Iter: 2135 loss: 7.95023283e-08
Iter: 2136 loss: 7.9399129e-08
Iter: 2137 loss: 7.92957735e-08
Iter: 2138 loss: 7.96126329e-08
Iter: 2139 loss: 7.92639412e-08
Iter: 2140 loss: 7.91633141e-08
Iter: 2141 loss: 7.90732884e-08
Iter: 2142 loss: 7.90388484e-08
Iter: 2143 loss: 7.89015786e-08
Iter: 2144 loss: 7.93884922e-08
Iter: 2145 loss: 7.88694194e-08
Iter: 2146 loss: 7.87983794e-08
Iter: 2147 loss: 7.87930503e-08
Iter: 2148 loss: 7.87462611e-08
Iter: 2149 loss: 7.87007224e-08
Iter: 2150 loss: 7.86861278e-08
Iter: 2151 loss: 7.86145193e-08
Iter: 2152 loss: 7.921291e-08
Iter: 2153 loss: 7.86160754e-08
Iter: 2154 loss: 7.8572711e-08
Iter: 2155 loss: 7.85144536e-08
Iter: 2156 loss: 7.85145318e-08
Iter: 2157 loss: 7.84338354e-08
Iter: 2158 loss: 7.93892951e-08
Iter: 2159 loss: 7.84291458e-08
Iter: 2160 loss: 7.83568197e-08
Iter: 2161 loss: 7.83727359e-08
Iter: 2162 loss: 7.83215199e-08
Iter: 2163 loss: 7.82523131e-08
Iter: 2164 loss: 7.88128958e-08
Iter: 2165 loss: 7.8244689e-08
Iter: 2166 loss: 7.81799301e-08
Iter: 2167 loss: 7.83050496e-08
Iter: 2168 loss: 7.81521692e-08
Iter: 2169 loss: 7.81060479e-08
Iter: 2170 loss: 7.8266666e-08
Iter: 2171 loss: 7.80843905e-08
Iter: 2172 loss: 7.79953808e-08
Iter: 2173 loss: 7.79956935e-08
Iter: 2174 loss: 7.7953537e-08
Iter: 2175 loss: 7.78610172e-08
Iter: 2176 loss: 7.77614844e-08
Iter: 2177 loss: 7.77457814e-08
Iter: 2178 loss: 7.77203e-08
Iter: 2179 loss: 7.76961073e-08
Iter: 2180 loss: 7.76317108e-08
Iter: 2181 loss: 7.75917215e-08
Iter: 2182 loss: 7.75751943e-08
Iter: 2183 loss: 7.75072166e-08
Iter: 2184 loss: 7.7770153e-08
Iter: 2185 loss: 7.74862627e-08
Iter: 2186 loss: 7.74024045e-08
Iter: 2187 loss: 7.76775479e-08
Iter: 2188 loss: 7.73832127e-08
Iter: 2189 loss: 7.72989424e-08
Iter: 2190 loss: 7.73199673e-08
Iter: 2191 loss: 7.72471083e-08
Iter: 2192 loss: 7.71450885e-08
Iter: 2193 loss: 7.83384877e-08
Iter: 2194 loss: 7.71440227e-08
Iter: 2195 loss: 7.70922881e-08
Iter: 2196 loss: 7.69704585e-08
Iter: 2197 loss: 7.9128327e-08
Iter: 2198 loss: 7.69640778e-08
Iter: 2199 loss: 7.68193473e-08
Iter: 2200 loss: 7.90086361e-08
Iter: 2201 loss: 7.68220332e-08
Iter: 2202 loss: 7.67473409e-08
Iter: 2203 loss: 7.66662325e-08
Iter: 2204 loss: 7.66540822e-08
Iter: 2205 loss: 7.65338157e-08
Iter: 2206 loss: 7.79051703e-08
Iter: 2207 loss: 7.65328636e-08
Iter: 2208 loss: 7.64795089e-08
Iter: 2209 loss: 7.64598411e-08
Iter: 2210 loss: 7.64251e-08
Iter: 2211 loss: 7.63465e-08
Iter: 2212 loss: 7.65622801e-08
Iter: 2213 loss: 7.63247101e-08
Iter: 2214 loss: 7.62878685e-08
Iter: 2215 loss: 7.62242323e-08
Iter: 2216 loss: 7.62236e-08
Iter: 2217 loss: 7.61306396e-08
Iter: 2218 loss: 7.63023564e-08
Iter: 2219 loss: 7.60910197e-08
Iter: 2220 loss: 7.60028342e-08
Iter: 2221 loss: 7.65864385e-08
Iter: 2222 loss: 7.59924674e-08
Iter: 2223 loss: 7.59117853e-08
Iter: 2224 loss: 7.63699433e-08
Iter: 2225 loss: 7.59008714e-08
Iter: 2226 loss: 7.58412639e-08
Iter: 2227 loss: 7.58339596e-08
Iter: 2228 loss: 7.57910925e-08
Iter: 2229 loss: 7.56824718e-08
Iter: 2230 loss: 7.62698136e-08
Iter: 2231 loss: 7.56671e-08
Iter: 2232 loss: 7.56146648e-08
Iter: 2233 loss: 7.5724067e-08
Iter: 2234 loss: 7.55827116e-08
Iter: 2235 loss: 7.54987681e-08
Iter: 2236 loss: 7.59138317e-08
Iter: 2237 loss: 7.54918545e-08
Iter: 2238 loss: 7.54535208e-08
Iter: 2239 loss: 7.55464313e-08
Iter: 2240 loss: 7.54288e-08
Iter: 2241 loss: 7.53624789e-08
Iter: 2242 loss: 7.52791181e-08
Iter: 2243 loss: 7.52722045e-08
Iter: 2244 loss: 7.52155103e-08
Iter: 2245 loss: 7.52129594e-08
Iter: 2246 loss: 7.51428644e-08
Iter: 2247 loss: 7.50718812e-08
Iter: 2248 loss: 7.50466072e-08
Iter: 2249 loss: 7.49717728e-08
Iter: 2250 loss: 7.49445874e-08
Iter: 2251 loss: 7.48949063e-08
Iter: 2252 loss: 7.47694386e-08
Iter: 2253 loss: 7.5483733e-08
Iter: 2254 loss: 7.47523217e-08
Iter: 2255 loss: 7.46634612e-08
Iter: 2256 loss: 7.5395107e-08
Iter: 2257 loss: 7.46561071e-08
Iter: 2258 loss: 7.45836104e-08
Iter: 2259 loss: 7.4762994e-08
Iter: 2260 loss: 7.45489e-08
Iter: 2261 loss: 7.44827915e-08
Iter: 2262 loss: 7.47540554e-08
Iter: 2263 loss: 7.44675077e-08
Iter: 2264 loss: 7.43739861e-08
Iter: 2265 loss: 7.42953929e-08
Iter: 2266 loss: 7.42707513e-08
Iter: 2267 loss: 7.41694208e-08
Iter: 2268 loss: 7.50424434e-08
Iter: 2269 loss: 7.41677937e-08
Iter: 2270 loss: 7.40469872e-08
Iter: 2271 loss: 7.43561586e-08
Iter: 2272 loss: 7.40097832e-08
Iter: 2273 loss: 7.39472412e-08
Iter: 2274 loss: 7.42587929e-08
Iter: 2275 loss: 7.39322559e-08
Iter: 2276 loss: 7.38602921e-08
Iter: 2277 loss: 7.37614627e-08
Iter: 2278 loss: 7.37611501e-08
Iter: 2279 loss: 7.36884189e-08
Iter: 2280 loss: 7.36785282e-08
Iter: 2281 loss: 7.36164338e-08
Iter: 2282 loss: 7.35092769e-08
Iter: 2283 loss: 7.3512652e-08
Iter: 2284 loss: 7.34035552e-08
Iter: 2285 loss: 7.34106891e-08
Iter: 2286 loss: 7.33359329e-08
Iter: 2287 loss: 7.32125827e-08
Iter: 2288 loss: 7.4140317e-08
Iter: 2289 loss: 7.32078291e-08
Iter: 2290 loss: 7.31262162e-08
Iter: 2291 loss: 7.35529184e-08
Iter: 2292 loss: 7.31218961e-08
Iter: 2293 loss: 7.30569e-08
Iter: 2294 loss: 7.32766523e-08
Iter: 2295 loss: 7.30416119e-08
Iter: 2296 loss: 7.29853866e-08
Iter: 2297 loss: 7.31150962e-08
Iter: 2298 loss: 7.29453262e-08
Iter: 2299 loss: 7.28694616e-08
Iter: 2300 loss: 7.27498701e-08
Iter: 2301 loss: 7.27474117e-08
Iter: 2302 loss: 7.26797467e-08
Iter: 2303 loss: 7.26627079e-08
Iter: 2304 loss: 7.25981408e-08
Iter: 2305 loss: 7.25282803e-08
Iter: 2306 loss: 7.25275129e-08
Iter: 2307 loss: 7.24087315e-08
Iter: 2308 loss: 7.29730516e-08
Iter: 2309 loss: 7.23833296e-08
Iter: 2310 loss: 7.23085662e-08
Iter: 2311 loss: 7.23814466e-08
Iter: 2312 loss: 7.22637807e-08
Iter: 2313 loss: 7.21766185e-08
Iter: 2314 loss: 7.21780538e-08
Iter: 2315 loss: 7.2124223e-08
Iter: 2316 loss: 7.20849584e-08
Iter: 2317 loss: 7.20838855e-08
Iter: 2318 loss: 7.20225e-08
Iter: 2319 loss: 7.20555065e-08
Iter: 2320 loss: 7.19789668e-08
Iter: 2321 loss: 7.18891897e-08
Iter: 2322 loss: 7.19597466e-08
Iter: 2323 loss: 7.18333766e-08
Iter: 2324 loss: 7.17647808e-08
Iter: 2325 loss: 7.2492071e-08
Iter: 2326 loss: 7.17602262e-08
Iter: 2327 loss: 7.1716542e-08
Iter: 2328 loss: 7.17783237e-08
Iter: 2329 loss: 7.1691737e-08
Iter: 2330 loss: 7.1625422e-08
Iter: 2331 loss: 7.167462e-08
Iter: 2332 loss: 7.15947479e-08
Iter: 2333 loss: 7.15398727e-08
Iter: 2334 loss: 7.18092608e-08
Iter: 2335 loss: 7.15303941e-08
Iter: 2336 loss: 7.14769044e-08
Iter: 2337 loss: 7.16120638e-08
Iter: 2338 loss: 7.14355934e-08
Iter: 2339 loss: 7.13907298e-08
Iter: 2340 loss: 7.1430776e-08
Iter: 2341 loss: 7.13715e-08
Iter: 2342 loss: 7.13013e-08
Iter: 2343 loss: 7.1503365e-08
Iter: 2344 loss: 7.12855126e-08
Iter: 2345 loss: 7.12341262e-08
Iter: 2346 loss: 7.15657e-08
Iter: 2347 loss: 7.12268786e-08
Iter: 2348 loss: 7.11643793e-08
Iter: 2349 loss: 7.11113728e-08
Iter: 2350 loss: 7.1097368e-08
Iter: 2351 loss: 7.1026669e-08
Iter: 2352 loss: 7.1499862e-08
Iter: 2353 loss: 7.10185191e-08
Iter: 2354 loss: 7.09746502e-08
Iter: 2355 loss: 7.11505663e-08
Iter: 2356 loss: 7.09484951e-08
Iter: 2357 loss: 7.09030559e-08
Iter: 2358 loss: 7.08656e-08
Iter: 2359 loss: 7.08543624e-08
Iter: 2360 loss: 7.07982082e-08
Iter: 2361 loss: 7.07937744e-08
Iter: 2362 loss: 7.07616152e-08
Iter: 2363 loss: 7.07058163e-08
Iter: 2364 loss: 7.07005583e-08
Iter: 2365 loss: 7.06233223e-08
Iter: 2366 loss: 7.09399757e-08
Iter: 2367 loss: 7.05995404e-08
Iter: 2368 loss: 7.05312218e-08
Iter: 2369 loss: 7.14577268e-08
Iter: 2370 loss: 7.05323515e-08
Iter: 2371 loss: 7.04903727e-08
Iter: 2372 loss: 7.04095413e-08
Iter: 2373 loss: 7.20643882e-08
Iter: 2374 loss: 7.04119145e-08
Iter: 2375 loss: 7.03350196e-08
Iter: 2376 loss: 7.1140029e-08
Iter: 2377 loss: 7.03353038e-08
Iter: 2378 loss: 7.02847274e-08
Iter: 2379 loss: 7.03296e-08
Iter: 2380 loss: 7.02451e-08
Iter: 2381 loss: 7.02138507e-08
Iter: 2382 loss: 7.02130762e-08
Iter: 2383 loss: 7.01929466e-08
Iter: 2384 loss: 7.01515646e-08
Iter: 2385 loss: 7.12545187e-08
Iter: 2386 loss: 7.01496674e-08
Iter: 2387 loss: 7.00812564e-08
Iter: 2388 loss: 7.02065392e-08
Iter: 2389 loss: 7.00648144e-08
Iter: 2390 loss: 7.00056049e-08
Iter: 2391 loss: 7.00305378e-08
Iter: 2392 loss: 6.99718825e-08
Iter: 2393 loss: 6.98939076e-08
Iter: 2394 loss: 7.02078395e-08
Iter: 2395 loss: 6.98781619e-08
Iter: 2396 loss: 6.98099285e-08
Iter: 2397 loss: 6.96928524e-08
Iter: 2398 loss: 6.96948703e-08
Iter: 2399 loss: 6.95572e-08
Iter: 2400 loss: 7.12826775e-08
Iter: 2401 loss: 6.95535078e-08
Iter: 2402 loss: 6.94783893e-08
Iter: 2403 loss: 6.94723212e-08
Iter: 2404 loss: 6.94216808e-08
Iter: 2405 loss: 6.95783271e-08
Iter: 2406 loss: 6.94020272e-08
Iter: 2407 loss: 6.93514366e-08
Iter: 2408 loss: 6.93158242e-08
Iter: 2409 loss: 6.92940318e-08
Iter: 2410 loss: 6.92100315e-08
Iter: 2411 loss: 6.94431392e-08
Iter: 2412 loss: 6.9188296e-08
Iter: 2413 loss: 6.91037698e-08
Iter: 2414 loss: 6.924639e-08
Iter: 2415 loss: 6.90660826e-08
Iter: 2416 loss: 6.89514366e-08
Iter: 2417 loss: 6.9698288e-08
Iter: 2418 loss: 6.89479407e-08
Iter: 2419 loss: 6.88953889e-08
Iter: 2420 loss: 6.8903482e-08
Iter: 2421 loss: 6.88407127e-08
Iter: 2422 loss: 6.87384869e-08
Iter: 2423 loss: 6.90421516e-08
Iter: 2424 loss: 6.87165382e-08
Iter: 2425 loss: 6.8656e-08
Iter: 2426 loss: 6.85803e-08
Iter: 2427 loss: 6.85827217e-08
Iter: 2428 loss: 6.85914188e-08
Iter: 2429 loss: 6.85498094e-08
Iter: 2430 loss: 6.85107793e-08
Iter: 2431 loss: 6.84436188e-08
Iter: 2432 loss: 6.95201834e-08
Iter: 2433 loss: 6.84440877e-08
Iter: 2434 loss: 6.83836205e-08
Iter: 2435 loss: 6.83663899e-08
Iter: 2436 loss: 6.83229686e-08
Iter: 2437 loss: 6.82495838e-08
Iter: 2438 loss: 6.81411123e-08
Iter: 2439 loss: 6.81414178e-08
Iter: 2440 loss: 6.81078376e-08
Iter: 2441 loss: 6.80779095e-08
Iter: 2442 loss: 6.80139962e-08
Iter: 2443 loss: 6.79967371e-08
Iter: 2444 loss: 6.79622758e-08
Iter: 2445 loss: 6.78916194e-08
Iter: 2446 loss: 6.78264129e-08
Iter: 2447 loss: 6.7814419e-08
Iter: 2448 loss: 6.77436702e-08
Iter: 2449 loss: 6.77458729e-08
Iter: 2450 loss: 6.76957654e-08
Iter: 2451 loss: 6.77670471e-08
Iter: 2452 loss: 6.76638834e-08
Iter: 2453 loss: 6.7598954e-08
Iter: 2454 loss: 6.7636563e-08
Iter: 2455 loss: 6.75699141e-08
Iter: 2456 loss: 6.74951508e-08
Iter: 2457 loss: 6.74907596e-08
Iter: 2458 loss: 6.74448e-08
Iter: 2459 loss: 6.7363e-08
Iter: 2460 loss: 6.73689655e-08
Iter: 2461 loss: 6.73102676e-08
Iter: 2462 loss: 6.73599914e-08
Iter: 2463 loss: 6.72803608e-08
Iter: 2464 loss: 6.72285125e-08
Iter: 2465 loss: 6.79840255e-08
Iter: 2466 loss: 6.72311771e-08
Iter: 2467 loss: 6.72051783e-08
Iter: 2468 loss: 6.71500402e-08
Iter: 2469 loss: 6.80080703e-08
Iter: 2470 loss: 6.71436737e-08
Iter: 2471 loss: 6.71029454e-08
Iter: 2472 loss: 6.71062494e-08
Iter: 2473 loss: 6.70598155e-08
Iter: 2474 loss: 6.7066928e-08
Iter: 2475 loss: 6.70315e-08
Iter: 2476 loss: 6.69890952e-08
Iter: 2477 loss: 6.71652458e-08
Iter: 2478 loss: 6.69773712e-08
Iter: 2479 loss: 6.69432225e-08
Iter: 2480 loss: 6.70927349e-08
Iter: 2481 loss: 6.69325857e-08
Iter: 2482 loss: 6.68999576e-08
Iter: 2483 loss: 6.70493e-08
Iter: 2484 loss: 6.68920137e-08
Iter: 2485 loss: 6.68666189e-08
Iter: 2486 loss: 6.68819808e-08
Iter: 2487 loss: 6.68508e-08
Iter: 2488 loss: 6.68115376e-08
Iter: 2489 loss: 6.67648692e-08
Iter: 2490 loss: 6.67633344e-08
Iter: 2491 loss: 6.67024835e-08
Iter: 2492 loss: 6.67410518e-08
Iter: 2493 loss: 6.66617836e-08
Iter: 2494 loss: 6.65927757e-08
Iter: 2495 loss: 6.68040485e-08
Iter: 2496 loss: 6.65721132e-08
Iter: 2497 loss: 6.6509422e-08
Iter: 2498 loss: 6.71488252e-08
Iter: 2499 loss: 6.65070132e-08
Iter: 2500 loss: 6.64450184e-08
Iter: 2501 loss: 6.66128699e-08
Iter: 2502 loss: 6.6436705e-08
Iter: 2503 loss: 6.63891626e-08
Iter: 2504 loss: 6.66959394e-08
Iter: 2505 loss: 6.63856e-08
Iter: 2506 loss: 6.63599451e-08
Iter: 2507 loss: 6.63761384e-08
Iter: 2508 loss: 6.63524418e-08
Iter: 2509 loss: 6.6327118e-08
Iter: 2510 loss: 6.63283402e-08
Iter: 2511 loss: 6.6304878e-08
Iter: 2512 loss: 6.62631e-08
Iter: 2513 loss: 6.65842776e-08
Iter: 2514 loss: 6.6261066e-08
Iter: 2515 loss: 6.62140422e-08
Iter: 2516 loss: 6.63554e-08
Iter: 2517 loss: 6.61945876e-08
Iter: 2518 loss: 6.61545556e-08
Iter: 2519 loss: 6.62531932e-08
Iter: 2520 loss: 6.61429169e-08
Iter: 2521 loss: 6.60769786e-08
Iter: 2522 loss: 6.62021122e-08
Iter: 2523 loss: 6.60575381e-08
Iter: 2524 loss: 6.60007302e-08
Iter: 2525 loss: 6.59942714e-08
Iter: 2526 loss: 6.59592203e-08
Iter: 2527 loss: 6.59000747e-08
Iter: 2528 loss: 6.60303243e-08
Iter: 2529 loss: 6.58748149e-08
Iter: 2530 loss: 6.58313439e-08
Iter: 2531 loss: 6.60960353e-08
Iter: 2532 loss: 6.58255104e-08
Iter: 2533 loss: 6.58003074e-08
Iter: 2534 loss: 6.61521398e-08
Iter: 2535 loss: 6.58012e-08
Iter: 2536 loss: 6.5771971e-08
Iter: 2537 loss: 6.58664732e-08
Iter: 2538 loss: 6.57753958e-08
Iter: 2539 loss: 6.575263e-08
Iter: 2540 loss: 6.57234622e-08
Iter: 2541 loss: 6.57219559e-08
Iter: 2542 loss: 6.56842474e-08
Iter: 2543 loss: 6.60092354e-08
Iter: 2544 loss: 6.568456e-08
Iter: 2545 loss: 6.56470576e-08
Iter: 2546 loss: 6.56533317e-08
Iter: 2547 loss: 6.56219044e-08
Iter: 2548 loss: 6.5579556e-08
Iter: 2549 loss: 6.56252e-08
Iter: 2550 loss: 6.55631283e-08
Iter: 2551 loss: 6.55177175e-08
Iter: 2552 loss: 6.57536248e-08
Iter: 2553 loss: 6.55045795e-08
Iter: 2554 loss: 6.5489175e-08
Iter: 2555 loss: 6.55613377e-08
Iter: 2556 loss: 6.54784387e-08
Iter: 2557 loss: 6.54454e-08
Iter: 2558 loss: 6.5481494e-08
Iter: 2559 loss: 6.54258656e-08
Iter: 2560 loss: 6.53851e-08
Iter: 2561 loss: 6.53430234e-08
Iter: 2562 loss: 6.53421424e-08
Iter: 2563 loss: 6.5293321e-08
Iter: 2564 loss: 6.53437837e-08
Iter: 2565 loss: 6.52655672e-08
Iter: 2566 loss: 6.52089085e-08
Iter: 2567 loss: 6.58812667e-08
Iter: 2568 loss: 6.52076864e-08
Iter: 2569 loss: 6.51737082e-08
Iter: 2570 loss: 6.5461677e-08
Iter: 2571 loss: 6.51656933e-08
Iter: 2572 loss: 6.51433467e-08
Iter: 2573 loss: 6.52052634e-08
Iter: 2574 loss: 6.51304859e-08
Iter: 2575 loss: 6.51050414e-08
Iter: 2576 loss: 6.5120318e-08
Iter: 2577 loss: 6.50876473e-08
Iter: 2578 loss: 6.5056291e-08
Iter: 2579 loss: 6.53953407e-08
Iter: 2580 loss: 6.50565539e-08
Iter: 2581 loss: 6.5034655e-08
Iter: 2582 loss: 6.50002505e-08
Iter: 2583 loss: 6.58930901e-08
Iter: 2584 loss: 6.49994405e-08
Iter: 2585 loss: 6.49567937e-08
Iter: 2586 loss: 6.53743e-08
Iter: 2587 loss: 6.49581082e-08
Iter: 2588 loss: 6.49097629e-08
Iter: 2589 loss: 6.49248122e-08
Iter: 2590 loss: 6.48959784e-08
Iter: 2591 loss: 6.48684377e-08
Iter: 2592 loss: 6.51510632e-08
Iter: 2593 loss: 6.48712231e-08
Iter: 2594 loss: 6.48461125e-08
Iter: 2595 loss: 6.48984724e-08
Iter: 2596 loss: 6.48406484e-08
Iter: 2597 loss: 6.48186429e-08
Iter: 2598 loss: 6.47941363e-08
Iter: 2599 loss: 6.47963816e-08
Iter: 2600 loss: 6.47698357e-08
Iter: 2601 loss: 6.47926512e-08
Iter: 2602 loss: 6.47594476e-08
Iter: 2603 loss: 6.47326459e-08
Iter: 2604 loss: 6.47889777e-08
Iter: 2605 loss: 6.47296758e-08
Iter: 2606 loss: 6.46890328e-08
Iter: 2607 loss: 6.47794423e-08
Iter: 2608 loss: 6.46815295e-08
Iter: 2609 loss: 6.46481908e-08
Iter: 2610 loss: 6.47919194e-08
Iter: 2611 loss: 6.46373124e-08
Iter: 2612 loss: 6.46219362e-08
Iter: 2613 loss: 6.47409735e-08
Iter: 2614 loss: 6.46130616e-08
Iter: 2615 loss: 6.45877947e-08
Iter: 2616 loss: 6.46935092e-08
Iter: 2617 loss: 6.45833325e-08
Iter: 2618 loss: 6.45674589e-08
Iter: 2619 loss: 6.45547189e-08
Iter: 2620 loss: 6.51358576e-08
Iter: 2621 loss: 6.45489422e-08
Iter: 2622 loss: 6.45393499e-08
Iter: 2623 loss: 6.47551914e-08
Iter: 2624 loss: 6.45322586e-08
Iter: 2625 loss: 6.44977689e-08
Iter: 2626 loss: 6.44695461e-08
Iter: 2627 loss: 6.44731131e-08
Iter: 2628 loss: 6.44338627e-08
Iter: 2629 loss: 6.45208331e-08
Iter: 2630 loss: 6.4425457e-08
Iter: 2631 loss: 6.44041336e-08
Iter: 2632 loss: 6.43994511e-08
Iter: 2633 loss: 6.43720952e-08
Iter: 2634 loss: 6.43374847e-08
Iter: 2635 loss: 6.49386749e-08
Iter: 2636 loss: 6.4331104e-08
Iter: 2637 loss: 6.42962874e-08
Iter: 2638 loss: 6.42966853e-08
Iter: 2639 loss: 6.42902e-08
Iter: 2640 loss: 6.42948237e-08
Iter: 2641 loss: 6.42740829e-08
Iter: 2642 loss: 6.42579181e-08
Iter: 2643 loss: 6.43524345e-08
Iter: 2644 loss: 6.42523688e-08
Iter: 2645 loss: 6.42271871e-08
Iter: 2646 loss: 6.42469118e-08
Iter: 2647 loss: 6.42139142e-08
Iter: 2648 loss: 6.41906297e-08
Iter: 2649 loss: 6.44494875e-08
Iter: 2650 loss: 6.41870557e-08
Iter: 2651 loss: 6.41770583e-08
Iter: 2652 loss: 6.41690292e-08
Iter: 2653 loss: 6.41649365e-08
Iter: 2654 loss: 6.41406359e-08
Iter: 2655 loss: 6.41455387e-08
Iter: 2656 loss: 6.41277751e-08
Iter: 2657 loss: 6.41213e-08
Iter: 2658 loss: 6.42206857e-08
Iter: 2659 loss: 6.41104521e-08
Iter: 2660 loss: 6.40977191e-08
Iter: 2661 loss: 6.41096065e-08
Iter: 2662 loss: 6.40905e-08
Iter: 2663 loss: 6.4083e-08
Iter: 2664 loss: 6.40964899e-08
Iter: 2665 loss: 6.40804743e-08
Iter: 2666 loss: 6.40575877e-08
Iter: 2667 loss: 6.40370104e-08
Iter: 2668 loss: 6.40335e-08
Iter: 2669 loss: 6.40023572e-08
Iter: 2670 loss: 6.39977529e-08
Iter: 2671 loss: 6.39796696e-08
Iter: 2672 loss: 6.3973971e-08
Iter: 2673 loss: 6.39616431e-08
Iter: 2674 loss: 6.39490096e-08
Iter: 2675 loss: 6.39226698e-08
Iter: 2676 loss: 6.3918236e-08
Iter: 2677 loss: 6.39044515e-08
Iter: 2678 loss: 6.41275264e-08
Iter: 2679 loss: 6.389795e-08
Iter: 2680 loss: 6.38915765e-08
Iter: 2681 loss: 6.38939639e-08
Iter: 2682 loss: 6.38800444e-08
Iter: 2683 loss: 6.38734718e-08
Iter: 2684 loss: 6.38749356e-08
Iter: 2685 loss: 6.3855083e-08
Iter: 2686 loss: 6.38736211e-08
Iter: 2687 loss: 6.3854678e-08
Iter: 2688 loss: 6.38329709e-08
Iter: 2689 loss: 6.3915941e-08
Iter: 2690 loss: 6.38249489e-08
Iter: 2691 loss: 6.38222843e-08
Iter: 2692 loss: 6.38216946e-08
Iter: 2693 loss: 6.38091322e-08
Iter: 2694 loss: 6.37929887e-08
Iter: 2695 loss: 6.38333049e-08
Iter: 2696 loss: 6.37905799e-08
Iter: 2697 loss: 6.377e-08
Iter: 2698 loss: 6.37896491e-08
Iter: 2699 loss: 6.37640696e-08
Iter: 2700 loss: 6.37425686e-08
Iter: 2701 loss: 6.37375734e-08
Iter: 2702 loss: 6.37200941e-08
Iter: 2703 loss: 6.36882689e-08
Iter: 2704 loss: 6.38044355e-08
Iter: 2705 loss: 6.36845314e-08
Iter: 2706 loss: 6.36422257e-08
Iter: 2707 loss: 6.3819094e-08
Iter: 2708 loss: 6.36417639e-08
Iter: 2709 loss: 6.36244764e-08
Iter: 2710 loss: 6.3587585e-08
Iter: 2711 loss: 6.35924806e-08
Iter: 2712 loss: 6.35682227e-08
Iter: 2713 loss: 6.37225241e-08
Iter: 2714 loss: 6.35608046e-08
Iter: 2715 loss: 6.35431121e-08
Iter: 2716 loss: 6.35404689e-08
Iter: 2717 loss: 6.35239559e-08
Iter: 2718 loss: 6.3505496e-08
Iter: 2719 loss: 6.35036415e-08
Iter: 2720 loss: 6.34818633e-08
Iter: 2721 loss: 6.3608141e-08
Iter: 2722 loss: 6.3485075e-08
Iter: 2723 loss: 6.346432e-08
Iter: 2724 loss: 6.34587423e-08
Iter: 2725 loss: 6.34430108e-08
Iter: 2726 loss: 6.34259933e-08
Iter: 2727 loss: 6.35576285e-08
Iter: 2728 loss: 6.34299369e-08
Iter: 2729 loss: 6.34185611e-08
Iter: 2730 loss: 6.34283452e-08
Iter: 2731 loss: 6.33995541e-08
Iter: 2732 loss: 6.33927826e-08
Iter: 2733 loss: 6.34488302e-08
Iter: 2734 loss: 6.33796304e-08
Iter: 2735 loss: 6.3362144e-08
Iter: 2736 loss: 6.33523953e-08
Iter: 2737 loss: 6.33558344e-08
Iter: 2738 loss: 6.3334042e-08
Iter: 2739 loss: 6.33501571e-08
Iter: 2740 loss: 6.33248e-08
Iter: 2741 loss: 6.32877075e-08
Iter: 2742 loss: 6.34918251e-08
Iter: 2743 loss: 6.32922905e-08
Iter: 2744 loss: 6.32714858e-08
Iter: 2745 loss: 6.32268709e-08
Iter: 2746 loss: 6.38566817e-08
Iter: 2747 loss: 6.32286e-08
Iter: 2748 loss: 6.31846859e-08
Iter: 2749 loss: 6.33395416e-08
Iter: 2750 loss: 6.31732178e-08
Iter: 2751 loss: 6.31624957e-08
Iter: 2752 loss: 6.31566053e-08
Iter: 2753 loss: 6.31487183e-08
Iter: 2754 loss: 6.3138e-08
Iter: 2755 loss: 6.31319423e-08
Iter: 2756 loss: 6.31098374e-08
Iter: 2757 loss: 6.32908623e-08
Iter: 2758 loss: 6.31099653e-08
Iter: 2759 loss: 6.31053396e-08
Iter: 2760 loss: 6.30868158e-08
Iter: 2761 loss: 6.33916883e-08
Iter: 2762 loss: 6.3094248e-08
Iter: 2763 loss: 6.30698906e-08
Iter: 2764 loss: 6.30679295e-08
Iter: 2765 loss: 6.30549408e-08
Iter: 2766 loss: 6.30404386e-08
Iter: 2767 loss: 6.35107469e-08
Iter: 2768 loss: 6.30410852e-08
Iter: 2769 loss: 6.3015527e-08
Iter: 2770 loss: 6.31434887e-08
Iter: 2771 loss: 6.30142409e-08
Iter: 2772 loss: 6.29917594e-08
Iter: 2773 loss: 6.32349071e-08
Iter: 2774 loss: 6.2990182e-08
Iter: 2775 loss: 6.29747703e-08
Iter: 2776 loss: 6.29725747e-08
Iter: 2777 loss: 6.29620374e-08
Iter: 2778 loss: 6.29510097e-08
Iter: 2779 loss: 6.29961292e-08
Iter: 2780 loss: 6.29350794e-08
Iter: 2781 loss: 6.29312353e-08
Iter: 2782 loss: 6.29433217e-08
Iter: 2783 loss: 6.29236183e-08
Iter: 2784 loss: 6.29071195e-08
Iter: 2785 loss: 6.29106083e-08
Iter: 2786 loss: 6.29021883e-08
Iter: 2787 loss: 6.28926813e-08
Iter: 2788 loss: 6.29628047e-08
Iter: 2789 loss: 6.288262e-08
Iter: 2790 loss: 6.28643306e-08
Iter: 2791 loss: 6.29938555e-08
Iter: 2792 loss: 6.28613037e-08
Iter: 2793 loss: 6.28495e-08
Iter: 2794 loss: 6.28399235e-08
Iter: 2795 loss: 6.2843668e-08
Iter: 2796 loss: 6.282621e-08
Iter: 2797 loss: 6.28256061e-08
Iter: 2798 loss: 6.28213712e-08
Iter: 2799 loss: 6.27904342e-08
Iter: 2800 loss: 6.30429398e-08
Iter: 2801 loss: 6.27907895e-08
Iter: 2802 loss: 6.27601366e-08
Iter: 2803 loss: 6.27714272e-08
Iter: 2804 loss: 6.27436521e-08
Iter: 2805 loss: 6.27317e-08
Iter: 2806 loss: 6.28468442e-08
Iter: 2807 loss: 6.27311394e-08
Iter: 2808 loss: 6.27150598e-08
Iter: 2809 loss: 6.27597814e-08
Iter: 2810 loss: 6.27031582e-08
Iter: 2811 loss: 6.26921519e-08
Iter: 2812 loss: 6.26957117e-08
Iter: 2813 loss: 6.26812451e-08
Iter: 2814 loss: 6.26711198e-08
Iter: 2815 loss: 6.26933812e-08
Iter: 2816 loss: 6.26620533e-08
Iter: 2817 loss: 6.2653811e-08
Iter: 2818 loss: 6.26546921e-08
Iter: 2819 loss: 6.26437355e-08
Iter: 2820 loss: 6.2638108e-08
Iter: 2821 loss: 6.26368788e-08
Iter: 2822 loss: 6.26134522e-08
Iter: 2823 loss: 6.26147667e-08
Iter: 2824 loss: 6.2606631e-08
Iter: 2825 loss: 6.25853573e-08
Iter: 2826 loss: 6.25589962e-08
Iter: 2827 loss: 6.25511163e-08
Iter: 2828 loss: 6.2521e-08
Iter: 2829 loss: 6.26297094e-08
Iter: 2830 loss: 6.25131449e-08
Iter: 2831 loss: 6.2499133e-08
Iter: 2832 loss: 6.24948626e-08
Iter: 2833 loss: 6.24805807e-08
Iter: 2834 loss: 6.24831387e-08
Iter: 2835 loss: 6.24706047e-08
Iter: 2836 loss: 6.24484287e-08
Iter: 2837 loss: 6.24292156e-08
Iter: 2838 loss: 6.24300753e-08
Iter: 2839 loss: 6.24100664e-08
Iter: 2840 loss: 6.24143297e-08
Iter: 2841 loss: 6.23930845e-08
Iter: 2842 loss: 6.23774739e-08
Iter: 2843 loss: 6.23796836e-08
Iter: 2844 loss: 6.23365253e-08
Iter: 2845 loss: 6.24729282e-08
Iter: 2846 loss: 6.23393177e-08
Iter: 2847 loss: 6.23261442e-08
Iter: 2848 loss: 6.24244194e-08
Iter: 2849 loss: 6.23285246e-08
Iter: 2850 loss: 6.23063698e-08
Iter: 2851 loss: 6.23456486e-08
Iter: 2852 loss: 6.23011616e-08
Iter: 2853 loss: 6.2287576e-08
Iter: 2854 loss: 6.23597813e-08
Iter: 2855 loss: 6.22851388e-08
Iter: 2856 loss: 6.22770457e-08
Iter: 2857 loss: 6.22639789e-08
Iter: 2858 loss: 6.22616483e-08
Iter: 2859 loss: 6.22541521e-08
Iter: 2860 loss: 6.22423855e-08
Iter: 2861 loss: 6.22358414e-08
Iter: 2862 loss: 6.2208855e-08
Iter: 2863 loss: 6.22820195e-08
Iter: 2864 loss: 6.21902e-08
Iter: 2865 loss: 6.21713383e-08
Iter: 2866 loss: 6.21723402e-08
Iter: 2867 loss: 6.21503631e-08
Iter: 2868 loss: 6.21367349e-08
Iter: 2869 loss: 6.21305176e-08
Iter: 2870 loss: 6.21059115e-08
Iter: 2871 loss: 6.21184952e-08
Iter: 2872 loss: 6.21014919e-08
Iter: 2873 loss: 6.20768574e-08
Iter: 2874 loss: 6.22198044e-08
Iter: 2875 loss: 6.20676914e-08
Iter: 2876 loss: 6.2055e-08
Iter: 2877 loss: 6.22742e-08
Iter: 2878 loss: 6.20551361e-08
Iter: 2879 loss: 6.20381044e-08
Iter: 2880 loss: 6.20108054e-08
Iter: 2881 loss: 6.2428569e-08
Iter: 2882 loss: 6.20088e-08
Iter: 2883 loss: 6.19804794e-08
Iter: 2884 loss: 6.21629681e-08
Iter: 2885 loss: 6.19755269e-08
Iter: 2886 loss: 6.19513258e-08
Iter: 2887 loss: 6.21259915e-08
Iter: 2888 loss: 6.19344647e-08
Iter: 2889 loss: 6.19028242e-08
Iter: 2890 loss: 6.19343297e-08
Iter: 2891 loss: 6.18835188e-08
Iter: 2892 loss: 6.18502369e-08
Iter: 2893 loss: 6.21930667e-08
Iter: 2894 loss: 6.18472e-08
Iter: 2895 loss: 6.18263556e-08
Iter: 2896 loss: 6.17909208e-08
Iter: 2897 loss: 6.17932159e-08
Iter: 2898 loss: 6.1759927e-08
Iter: 2899 loss: 6.17715159e-08
Iter: 2900 loss: 6.17415878e-08
Iter: 2901 loss: 6.17209679e-08
Iter: 2902 loss: 6.20473273e-08
Iter: 2903 loss: 6.17233624e-08
Iter: 2904 loss: 6.17006819e-08
Iter: 2905 loss: 6.18954843e-08
Iter: 2906 loss: 6.16978326e-08
Iter: 2907 loss: 6.16859239e-08
Iter: 2908 loss: 6.16554772e-08
Iter: 2909 loss: 6.23200833e-08
Iter: 2910 loss: 6.16559817e-08
Iter: 2911 loss: 6.16196e-08
Iter: 2912 loss: 6.17863662e-08
Iter: 2913 loss: 6.16168521e-08
Iter: 2914 loss: 6.15760953e-08
Iter: 2915 loss: 6.18256806e-08
Iter: 2916 loss: 6.15823481e-08
Iter: 2917 loss: 6.15653164e-08
Iter: 2918 loss: 6.15408e-08
Iter: 2919 loss: 6.21974934e-08
Iter: 2920 loss: 6.15404758e-08
Iter: 2921 loss: 6.15118836e-08
Iter: 2922 loss: 6.1803739e-08
Iter: 2923 loss: 6.15111162e-08
Iter: 2924 loss: 6.14979498e-08
Iter: 2925 loss: 6.15416269e-08
Iter: 2926 loss: 6.14892315e-08
Iter: 2927 loss: 6.14592039e-08
Iter: 2928 loss: 6.14924573e-08
Iter: 2929 loss: 6.14549478e-08
Iter: 2930 loss: 6.14292048e-08
Iter: 2931 loss: 6.16312903e-08
Iter: 2932 loss: 6.14305762e-08
Iter: 2933 loss: 6.14064817e-08
Iter: 2934 loss: 6.13716509e-08
Iter: 2935 loss: 6.19966372e-08
Iter: 2936 loss: 6.13632807e-08
Iter: 2937 loss: 6.13266877e-08
Iter: 2938 loss: 6.14156761e-08
Iter: 2939 loss: 6.13173796e-08
Iter: 2940 loss: 6.12898106e-08
Iter: 2941 loss: 6.12909403e-08
Iter: 2942 loss: 6.12650766e-08
Iter: 2943 loss: 6.1273127e-08
Iter: 2944 loss: 6.12463822e-08
Iter: 2945 loss: 6.12131075e-08
Iter: 2946 loss: 6.12343101e-08
Iter: 2947 loss: 6.1202968e-08
Iter: 2948 loss: 6.11621473e-08
Iter: 2949 loss: 6.14669773e-08
Iter: 2950 loss: 6.11709297e-08
Iter: 2951 loss: 6.11467783e-08
Iter: 2952 loss: 6.1109084e-08
Iter: 2953 loss: 6.11098443e-08
Iter: 2954 loss: 6.10684e-08
Iter: 2955 loss: 6.11358431e-08
Iter: 2956 loss: 6.10542159e-08
Iter: 2957 loss: 6.10394864e-08
Iter: 2958 loss: 6.10266824e-08
Iter: 2959 loss: 6.10145179e-08
Iter: 2960 loss: 6.10139921e-08
Iter: 2961 loss: 6.09966e-08
Iter: 2962 loss: 6.09806889e-08
Iter: 2963 loss: 6.11881461e-08
Iter: 2964 loss: 6.09830124e-08
Iter: 2965 loss: 6.0960744e-08
Iter: 2966 loss: 6.09568858e-08
Iter: 2967 loss: 6.09481177e-08
Iter: 2968 loss: 6.09283575e-08
Iter: 2969 loss: 6.08959212e-08
Iter: 2970 loss: 6.08958928e-08
Iter: 2971 loss: 6.08553421e-08
Iter: 2972 loss: 6.08886808e-08
Iter: 2973 loss: 6.08399e-08
Iter: 2974 loss: 6.08191471e-08
Iter: 2975 loss: 6.08065278e-08
Iter: 2976 loss: 6.07884942e-08
Iter: 2977 loss: 6.07726847e-08
Iter: 2978 loss: 6.07590636e-08
Iter: 2979 loss: 6.07334201e-08
Iter: 2980 loss: 6.09224315e-08
Iter: 2981 loss: 6.07308266e-08
Iter: 2982 loss: 6.07101853e-08
Iter: 2983 loss: 6.07537842e-08
Iter: 2984 loss: 6.06985324e-08
Iter: 2985 loss: 6.06778414e-08
Iter: 2986 loss: 6.06643482e-08
Iter: 2987 loss: 6.06544646e-08
Iter: 2988 loss: 6.06164576e-08
Iter: 2989 loss: 6.07527e-08
Iter: 2990 loss: 6.06147594e-08
Iter: 2991 loss: 6.05806179e-08
Iter: 2992 loss: 6.08502333e-08
Iter: 2993 loss: 6.05741235e-08
Iter: 2994 loss: 6.05505548e-08
Iter: 2995 loss: 6.05408e-08
Iter: 2996 loss: 6.05291532e-08
Iter: 2997 loss: 6.04900094e-08
Iter: 2998 loss: 6.07215256e-08
Iter: 2999 loss: 6.04924963e-08
Iter: 3000 loss: 6.04544184e-08
Iter: 3001 loss: 6.03888282e-08
Iter: 3002 loss: 6.03958412e-08
Iter: 3003 loss: 6.0335914e-08
Iter: 3004 loss: 6.04003247e-08
Iter: 3005 loss: 6.03058226e-08
Iter: 3006 loss: 6.02445738e-08
Iter: 3007 loss: 6.05160508e-08
Iter: 3008 loss: 6.02306898e-08
Iter: 3009 loss: 6.01808e-08
Iter: 3010 loss: 6.01881709e-08
Iter: 3011 loss: 6.01606e-08
Iter: 3012 loss: 6.01237176e-08
Iter: 3013 loss: 6.01259771e-08
Iter: 3014 loss: 6.00811347e-08
Iter: 3015 loss: 6.05877659e-08
Iter: 3016 loss: 6.00744059e-08
Iter: 3017 loss: 6.00412804e-08
Iter: 3018 loss: 6.00507e-08
Iter: 3019 loss: 6.00213923e-08
Iter: 3020 loss: 5.99745675e-08
Iter: 3021 loss: 5.9926478e-08
Iter: 3022 loss: 5.99249148e-08
Iter: 3023 loss: 5.98682774e-08
Iter: 3024 loss: 6.01412609e-08
Iter: 3025 loss: 5.98736065e-08
Iter: 3026 loss: 5.98171e-08
Iter: 3027 loss: 6.00108478e-08
Iter: 3028 loss: 5.9810894e-08
Iter: 3029 loss: 5.97775909e-08
Iter: 3030 loss: 5.97054353e-08
Iter: 3031 loss: 6.07187474e-08
Iter: 3032 loss: 5.97153118e-08
Iter: 3033 loss: 5.96659859e-08
Iter: 3034 loss: 5.96591789e-08
Iter: 3035 loss: 5.96193104e-08
Iter: 3036 loss: 5.96226073e-08
Iter: 3037 loss: 5.95865366e-08
Iter: 3038 loss: 5.95359175e-08
Iter: 3039 loss: 5.94818843e-08
Iter: 3040 loss: 5.94838845e-08
Iter: 3041 loss: 5.94099134e-08
Iter: 3042 loss: 5.92737166e-08
Iter: 3043 loss: 6.17255509e-08
Iter: 3044 loss: 5.92669593e-08
Iter: 3045 loss: 5.91433178e-08
Iter: 3046 loss: 6.01223462e-08
Iter: 3047 loss: 5.91327023e-08
Iter: 3048 loss: 5.9071553e-08
Iter: 3049 loss: 5.90704161e-08
Iter: 3050 loss: 5.90059095e-08
Iter: 3051 loss: 5.90455222e-08
Iter: 3052 loss: 5.89588147e-08
Iter: 3053 loss: 5.8899694e-08
Iter: 3054 loss: 5.91711711e-08
Iter: 3055 loss: 5.88934519e-08
Iter: 3056 loss: 5.88383671e-08
Iter: 3057 loss: 5.88743028e-08
Iter: 3058 loss: 5.88066e-08
Iter: 3059 loss: 5.87332885e-08
Iter: 3060 loss: 5.92787757e-08
Iter: 3061 loss: 5.87305173e-08
Iter: 3062 loss: 5.8675063e-08
Iter: 3063 loss: 5.8643927e-08
Iter: 3064 loss: 5.86213353e-08
Iter: 3065 loss: 5.85784719e-08
Iter: 3066 loss: 5.85769513e-08
Iter: 3067 loss: 5.85302047e-08
Iter: 3068 loss: 5.84269522e-08
Iter: 3069 loss: 6.07371788e-08
Iter: 3070 loss: 5.84280144e-08
Iter: 3071 loss: 5.83632556e-08
Iter: 3072 loss: 5.83618913e-08
Iter: 3073 loss: 5.83129349e-08
Iter: 3074 loss: 5.82366e-08
Iter: 3075 loss: 5.82289381e-08
Iter: 3076 loss: 5.81233301e-08
Iter: 3077 loss: 5.8093967e-08
Iter: 3078 loss: 5.80173243e-08
Iter: 3079 loss: 5.79035593e-08
Iter: 3080 loss: 5.78398769e-08
Iter: 3081 loss: 5.78028292e-08
Iter: 3082 loss: 5.77475703e-08
Iter: 3083 loss: 5.77079362e-08
Iter: 3084 loss: 5.76190331e-08
Iter: 3085 loss: 5.75009551e-08
Iter: 3086 loss: 5.74929899e-08
Iter: 3087 loss: 5.73752175e-08
Iter: 3088 loss: 5.72879273e-08
Iter: 3089 loss: 5.72370027e-08
Iter: 3090 loss: 5.71156598e-08
Iter: 3091 loss: 5.71086041e-08
Iter: 3092 loss: 5.69940326e-08
Iter: 3093 loss: 5.75844084e-08
Iter: 3094 loss: 5.69773029e-08
Iter: 3095 loss: 5.69018148e-08
Iter: 3096 loss: 5.68345584e-08
Iter: 3097 loss: 5.68121763e-08
Iter: 3098 loss: 5.67229961e-08
Iter: 3099 loss: 5.67140894e-08
Iter: 3100 loss: 5.66611575e-08
Iter: 3101 loss: 5.65266802e-08
Iter: 3102 loss: 5.86133169e-08
Iter: 3103 loss: 5.65248e-08
Iter: 3104 loss: 5.64624827e-08
Iter: 3105 loss: 5.64470568e-08
Iter: 3106 loss: 5.63906681e-08
Iter: 3107 loss: 5.62619817e-08
Iter: 3108 loss: 5.82056607e-08
Iter: 3109 loss: 5.62574378e-08
Iter: 3110 loss: 5.61534108e-08
Iter: 3111 loss: 5.61030689e-08
Iter: 3112 loss: 5.60569688e-08
Iter: 3113 loss: 5.59559723e-08
Iter: 3114 loss: 5.6007913e-08
Iter: 3115 loss: 5.58909434e-08
Iter: 3116 loss: 5.58036675e-08
Iter: 3117 loss: 5.68900056e-08
Iter: 3118 loss: 5.58072699e-08
Iter: 3119 loss: 5.57288722e-08
Iter: 3120 loss: 5.5683941e-08
Iter: 3121 loss: 5.56592497e-08
Iter: 3122 loss: 5.55334765e-08
Iter: 3123 loss: 5.5320065e-08
Iter: 3124 loss: 5.53240866e-08
Iter: 3125 loss: 5.5101907e-08
Iter: 3126 loss: 5.65455522e-08
Iter: 3127 loss: 5.50874724e-08
Iter: 3128 loss: 5.49337642e-08
Iter: 3129 loss: 5.69647298e-08
Iter: 3130 loss: 5.49359882e-08
Iter: 3131 loss: 5.48514336e-08
Iter: 3132 loss: 5.47416406e-08
Iter: 3133 loss: 5.47409e-08
Iter: 3134 loss: 5.46585426e-08
Iter: 3135 loss: 5.46500338e-08
Iter: 3136 loss: 5.45886181e-08
Iter: 3137 loss: 5.44142509e-08
Iter: 3138 loss: 5.52591928e-08
Iter: 3139 loss: 5.43544445e-08
Iter: 3140 loss: 5.4258436e-08
Iter: 3141 loss: 5.4235624e-08
Iter: 3142 loss: 5.41137624e-08
Iter: 3143 loss: 5.41935634e-08
Iter: 3144 loss: 5.40290301e-08
Iter: 3145 loss: 5.39270175e-08
Iter: 3146 loss: 5.40118847e-08
Iter: 3147 loss: 5.3873098e-08
Iter: 3148 loss: 5.37647793e-08
Iter: 3149 loss: 5.43499681e-08
Iter: 3150 loss: 5.3749396e-08
Iter: 3151 loss: 5.3662994e-08
Iter: 3152 loss: 5.38314531e-08
Iter: 3153 loss: 5.36245892e-08
Iter: 3154 loss: 5.35493427e-08
Iter: 3155 loss: 5.38613385e-08
Iter: 3156 loss: 5.35364428e-08
Iter: 3157 loss: 5.34501865e-08
Iter: 3158 loss: 5.35392388e-08
Iter: 3159 loss: 5.33995035e-08
Iter: 3160 loss: 5.33242783e-08
Iter: 3161 loss: 5.34693179e-08
Iter: 3162 loss: 5.32912203e-08
Iter: 3163 loss: 5.3201024e-08
Iter: 3164 loss: 5.33292805e-08
Iter: 3165 loss: 5.31466284e-08
Iter: 3166 loss: 5.30705364e-08
Iter: 3167 loss: 5.43777432e-08
Iter: 3168 loss: 5.30718545e-08
Iter: 3169 loss: 5.29856479e-08
Iter: 3170 loss: 5.28465911e-08
Iter: 3171 loss: 5.59917197e-08
Iter: 3172 loss: 5.28481188e-08
Iter: 3173 loss: 5.26900834e-08
Iter: 3174 loss: 5.2557354e-08
Iter: 3175 loss: 5.25040349e-08
Iter: 3176 loss: 5.25312878e-08
Iter: 3177 loss: 5.24084953e-08
Iter: 3178 loss: 5.23229886e-08
Iter: 3179 loss: 5.22562971e-08
Iter: 3180 loss: 5.22228589e-08
Iter: 3181 loss: 5.21047596e-08
Iter: 3182 loss: 5.20078203e-08
Iter: 3183 loss: 5.19599546e-08
Iter: 3184 loss: 5.17942276e-08
Iter: 3185 loss: 5.35824789e-08
Iter: 3186 loss: 5.1788529e-08
Iter: 3187 loss: 5.16361744e-08
Iter: 3188 loss: 5.2208204e-08
Iter: 3189 loss: 5.15930338e-08
Iter: 3190 loss: 5.14603045e-08
Iter: 3191 loss: 5.17036938e-08
Iter: 3192 loss: 5.14096712e-08
Iter: 3193 loss: 5.12852978e-08
Iter: 3194 loss: 5.22578922e-08
Iter: 3195 loss: 5.1282484e-08
Iter: 3196 loss: 5.11815301e-08
Iter: 3197 loss: 5.12182794e-08
Iter: 3198 loss: 5.11286018e-08
Iter: 3199 loss: 5.10262872e-08
Iter: 3200 loss: 5.15812175e-08
Iter: 3201 loss: 5.10140801e-08
Iter: 3202 loss: 5.09164977e-08
Iter: 3203 loss: 5.11347871e-08
Iter: 3204 loss: 5.08798905e-08
Iter: 3205 loss: 5.07642319e-08
Iter: 3206 loss: 5.06653066e-08
Iter: 3207 loss: 5.06432798e-08
Iter: 3208 loss: 5.05053e-08
Iter: 3209 loss: 5.08690832e-08
Iter: 3210 loss: 5.04620168e-08
Iter: 3211 loss: 5.03600077e-08
Iter: 3212 loss: 5.03551121e-08
Iter: 3213 loss: 5.03001196e-08
Iter: 3214 loss: 5.0181e-08
Iter: 3215 loss: 5.23882591e-08
Iter: 3216 loss: 5.01800841e-08
Iter: 3217 loss: 5.00468857e-08
Iter: 3218 loss: 5.02942719e-08
Iter: 3219 loss: 4.99989881e-08
Iter: 3220 loss: 4.98630541e-08
Iter: 3221 loss: 5.04115611e-08
Iter: 3222 loss: 4.98279071e-08
Iter: 3223 loss: 4.96977393e-08
Iter: 3224 loss: 5.0337114e-08
Iter: 3225 loss: 4.96725967e-08
Iter: 3226 loss: 4.95669212e-08
Iter: 3227 loss: 5.054806e-08
Iter: 3228 loss: 4.95519821e-08
Iter: 3229 loss: 4.94743659e-08
Iter: 3230 loss: 4.95711916e-08
Iter: 3231 loss: 4.943346e-08
Iter: 3232 loss: 4.93651839e-08
Iter: 3233 loss: 4.96641803e-08
Iter: 3234 loss: 4.9345779e-08
Iter: 3235 loss: 4.92744654e-08
Iter: 3236 loss: 4.94996506e-08
Iter: 3237 loss: 4.92522396e-08
Iter: 3238 loss: 4.91722112e-08
Iter: 3239 loss: 4.9167344e-08
Iter: 3240 loss: 4.91058287e-08
Iter: 3241 loss: 4.90189755e-08
Iter: 3242 loss: 5.02728597e-08
Iter: 3243 loss: 4.9014055e-08
Iter: 3244 loss: 4.89640684e-08
Iter: 3245 loss: 4.89053207e-08
Iter: 3246 loss: 4.88993237e-08
Iter: 3247 loss: 4.88250755e-08
Iter: 3248 loss: 4.8777693e-08
Iter: 3249 loss: 4.87395084e-08
Iter: 3250 loss: 4.87707084e-08
Iter: 3251 loss: 4.87034555e-08
Iter: 3252 loss: 4.86757692e-08
Iter: 3253 loss: 4.86531491e-08
Iter: 3254 loss: 4.86377125e-08
Iter: 3255 loss: 4.85872569e-08
Iter: 3256 loss: 4.85222e-08
Iter: 3257 loss: 4.85192757e-08
Iter: 3258 loss: 4.84409526e-08
Iter: 3259 loss: 4.89347656e-08
Iter: 3260 loss: 4.84373679e-08
Iter: 3261 loss: 4.8372371e-08
Iter: 3262 loss: 4.83746874e-08
Iter: 3263 loss: 4.83226756e-08
Iter: 3264 loss: 4.83025104e-08
Iter: 3265 loss: 4.82786e-08
Iter: 3266 loss: 4.81964975e-08
Iter: 3267 loss: 4.84741207e-08
Iter: 3268 loss: 4.81818212e-08
Iter: 3269 loss: 4.81038214e-08
Iter: 3270 loss: 4.82548899e-08
Iter: 3271 loss: 4.80746394e-08
Iter: 3272 loss: 4.80360782e-08
Iter: 3273 loss: 4.83358e-08
Iter: 3274 loss: 4.80316089e-08
Iter: 3275 loss: 4.79885038e-08
Iter: 3276 loss: 4.80785616e-08
Iter: 3277 loss: 4.79680722e-08
Iter: 3278 loss: 4.79442548e-08
Iter: 3279 loss: 4.79094879e-08
Iter: 3280 loss: 4.79066742e-08
Iter: 3281 loss: 4.78435496e-08
Iter: 3282 loss: 4.7904031e-08
Iter: 3283 loss: 4.78010165e-08
Iter: 3284 loss: 4.77256776e-08
Iter: 3285 loss: 4.78665427e-08
Iter: 3286 loss: 4.76873048e-08
Iter: 3287 loss: 4.76171849e-08
Iter: 3288 loss: 4.76136321e-08
Iter: 3289 loss: 4.75724917e-08
Iter: 3290 loss: 4.75047628e-08
Iter: 3291 loss: 4.75043649e-08
Iter: 3292 loss: 4.7443141e-08
Iter: 3293 loss: 4.77663882e-08
Iter: 3294 loss: 4.74365471e-08
Iter: 3295 loss: 4.73985864e-08
Iter: 3296 loss: 4.76303939e-08
Iter: 3297 loss: 4.73929589e-08
Iter: 3298 loss: 4.73677026e-08
Iter: 3299 loss: 4.76326676e-08
Iter: 3300 loss: 4.73715431e-08
Iter: 3301 loss: 4.73568846e-08
Iter: 3302 loss: 4.74097703e-08
Iter: 3303 loss: 4.73396469e-08
Iter: 3304 loss: 4.73288218e-08
Iter: 3305 loss: 4.73478252e-08
Iter: 3306 loss: 4.73236739e-08
Iter: 3307 loss: 4.72907189e-08
Iter: 3308 loss: 4.73061306e-08
Iter: 3309 loss: 4.72663295e-08
Iter: 3310 loss: 4.72408779e-08
Iter: 3311 loss: 4.72023203e-08
Iter: 3312 loss: 4.72054467e-08
Iter: 3313 loss: 4.71463117e-08
Iter: 3314 loss: 4.75968847e-08
Iter: 3315 loss: 4.71464894e-08
Iter: 3316 loss: 4.7099924e-08
Iter: 3317 loss: 4.74477773e-08
Iter: 3318 loss: 4.70920192e-08
Iter: 3319 loss: 4.7071758e-08
Iter: 3320 loss: 4.70267416e-08
Iter: 3321 loss: 4.70196611e-08
Iter: 3322 loss: 4.69636703e-08
Iter: 3323 loss: 4.69057078e-08
Iter: 3324 loss: 4.68895038e-08
Iter: 3325 loss: 4.68152095e-08
Iter: 3326 loss: 4.68171351e-08
Iter: 3327 loss: 4.67651873e-08
Iter: 3328 loss: 4.73583341e-08
Iter: 3329 loss: 4.67653e-08
Iter: 3330 loss: 4.67300829e-08
Iter: 3331 loss: 4.66764263e-08
Iter: 3332 loss: 4.6676373e-08
Iter: 3333 loss: 4.66225e-08
Iter: 3334 loss: 4.72440576e-08
Iter: 3335 loss: 4.66198458e-08
Iter: 3336 loss: 4.65693653e-08
Iter: 3337 loss: 4.68312429e-08
Iter: 3338 loss: 4.6567628e-08
Iter: 3339 loss: 4.65466243e-08
Iter: 3340 loss: 4.66323e-08
Iter: 3341 loss: 4.65422296e-08
Iter: 3342 loss: 4.65149483e-08
Iter: 3343 loss: 4.64924916e-08
Iter: 3344 loss: 4.64830201e-08
Iter: 3345 loss: 4.64391228e-08
Iter: 3346 loss: 4.64086867e-08
Iter: 3347 loss: 4.64005403e-08
Iter: 3348 loss: 4.63288714e-08
Iter: 3349 loss: 4.67493777e-08
Iter: 3350 loss: 4.63239687e-08
Iter: 3351 loss: 4.62762486e-08
Iter: 3352 loss: 4.70271e-08
Iter: 3353 loss: 4.62735e-08
Iter: 3354 loss: 4.62404159e-08
Iter: 3355 loss: 4.61895091e-08
Iter: 3356 loss: 4.61819312e-08
Iter: 3357 loss: 4.61353125e-08
Iter: 3358 loss: 4.61434979e-08
Iter: 3359 loss: 4.60902214e-08
Iter: 3360 loss: 4.60213272e-08
Iter: 3361 loss: 4.60359928e-08
Iter: 3362 loss: 4.59725555e-08
Iter: 3363 loss: 4.59126284e-08
Iter: 3364 loss: 4.59123e-08
Iter: 3365 loss: 4.5837794e-08
Iter: 3366 loss: 4.58926195e-08
Iter: 3367 loss: 4.58019223e-08
Iter: 3368 loss: 4.57539322e-08
Iter: 3369 loss: 4.57853204e-08
Iter: 3370 loss: 4.57119711e-08
Iter: 3371 loss: 4.56607658e-08
Iter: 3372 loss: 4.61984442e-08
Iter: 3373 loss: 4.5656293e-08
Iter: 3374 loss: 4.56039189e-08
Iter: 3375 loss: 4.57609239e-08
Iter: 3376 loss: 4.5593314e-08
Iter: 3377 loss: 4.55614249e-08
Iter: 3378 loss: 4.55396219e-08
Iter: 3379 loss: 4.5521503e-08
Iter: 3380 loss: 4.54963e-08
Iter: 3381 loss: 4.54848674e-08
Iter: 3382 loss: 4.54679565e-08
Iter: 3383 loss: 4.54125555e-08
Iter: 3384 loss: 4.65940531e-08
Iter: 3385 loss: 4.54120155e-08
Iter: 3386 loss: 4.53734117e-08
Iter: 3387 loss: 4.54466331e-08
Iter: 3388 loss: 4.53582842e-08
Iter: 3389 loss: 4.53045956e-08
Iter: 3390 loss: 4.5697508e-08
Iter: 3391 loss: 4.53044819e-08
Iter: 3392 loss: 4.52682229e-08
Iter: 3393 loss: 4.52529214e-08
Iter: 3394 loss: 4.5238771e-08
Iter: 3395 loss: 4.51917259e-08
Iter: 3396 loss: 4.52556392e-08
Iter: 3397 loss: 4.51764066e-08
Iter: 3398 loss: 4.51210447e-08
Iter: 3399 loss: 4.51600712e-08
Iter: 3400 loss: 4.50852333e-08
Iter: 3401 loss: 4.5086793e-08
Iter: 3402 loss: 4.50517845e-08
Iter: 3403 loss: 4.5028937e-08
Iter: 3404 loss: 4.49863187e-08
Iter: 3405 loss: 4.49911113e-08
Iter: 3406 loss: 4.49333442e-08
Iter: 3407 loss: 4.52173623e-08
Iter: 3408 loss: 4.49313688e-08
Iter: 3409 loss: 4.4884775e-08
Iter: 3410 loss: 4.5162075e-08
Iter: 3411 loss: 4.48732536e-08
Iter: 3412 loss: 4.48373711e-08
Iter: 3413 loss: 4.48634054e-08
Iter: 3414 loss: 4.48183819e-08
Iter: 3415 loss: 4.48071589e-08
Iter: 3416 loss: 4.48008564e-08
Iter: 3417 loss: 4.47868693e-08
Iter: 3418 loss: 4.47671091e-08
Iter: 3419 loss: 4.50873188e-08
Iter: 3420 loss: 4.4766626e-08
Iter: 3421 loss: 4.47399167e-08
Iter: 3422 loss: 4.47840662e-08
Iter: 3423 loss: 4.47272583e-08
Iter: 3424 loss: 4.46869919e-08
Iter: 3425 loss: 4.48415101e-08
Iter: 3426 loss: 4.46840431e-08
Iter: 3427 loss: 4.46675976e-08
Iter: 3428 loss: 4.46397372e-08
Iter: 3429 loss: 4.46395632e-08
Iter: 3430 loss: 4.46007604e-08
Iter: 3431 loss: 4.45654358e-08
Iter: 3432 loss: 4.45581421e-08
Iter: 3433 loss: 4.45163622e-08
Iter: 3434 loss: 4.45536799e-08
Iter: 3435 loss: 4.44981936e-08
Iter: 3436 loss: 4.44696937e-08
Iter: 3437 loss: 4.44696653e-08
Iter: 3438 loss: 4.44563639e-08
Iter: 3439 loss: 4.4448079e-08
Iter: 3440 loss: 4.44483597e-08
Iter: 3441 loss: 4.4420382e-08
Iter: 3442 loss: 4.44339747e-08
Iter: 3443 loss: 4.44098234e-08
Iter: 3444 loss: 4.43785879e-08
Iter: 3445 loss: 4.44928574e-08
Iter: 3446 loss: 4.43673613e-08
Iter: 3447 loss: 4.43503865e-08
Iter: 3448 loss: 4.44279316e-08
Iter: 3449 loss: 4.43379946e-08
Iter: 3450 loss: 4.43027304e-08
Iter: 3451 loss: 4.43266863e-08
Iter: 3452 loss: 4.42822348e-08
Iter: 3453 loss: 4.42559127e-08
Iter: 3454 loss: 4.43915589e-08
Iter: 3455 loss: 4.42532624e-08
Iter: 3456 loss: 4.42332286e-08
Iter: 3457 loss: 4.4227118e-08
Iter: 3458 loss: 4.42156036e-08
Iter: 3459 loss: 4.41905641e-08
Iter: 3460 loss: 4.4233424e-08
Iter: 3461 loss: 4.4180716e-08
Iter: 3462 loss: 4.41566e-08
Iter: 3463 loss: 4.41584334e-08
Iter: 3464 loss: 4.41409718e-08
Iter: 3465 loss: 4.41155734e-08
Iter: 3466 loss: 4.41182131e-08
Iter: 3467 loss: 4.40863275e-08
Iter: 3468 loss: 4.41528059e-08
Iter: 3469 loss: 4.40679955e-08
Iter: 3470 loss: 4.40380816e-08
Iter: 3471 loss: 4.41899957e-08
Iter: 3472 loss: 4.40240235e-08
Iter: 3473 loss: 4.39946533e-08
Iter: 3474 loss: 4.40620553e-08
Iter: 3475 loss: 4.39786163e-08
Iter: 3476 loss: 4.39561916e-08
Iter: 3477 loss: 4.40279315e-08
Iter: 3478 loss: 4.39464145e-08
Iter: 3479 loss: 4.39203e-08
Iter: 3480 loss: 4.41000694e-08
Iter: 3481 loss: 4.39196839e-08
Iter: 3482 loss: 4.39087771e-08
Iter: 3483 loss: 4.39456187e-08
Iter: 3484 loss: 4.39048797e-08
Iter: 3485 loss: 4.38883347e-08
Iter: 3486 loss: 4.39172503e-08
Iter: 3487 loss: 4.38785079e-08
Iter: 3488 loss: 4.38731718e-08
Iter: 3489 loss: 4.39335395e-08
Iter: 3490 loss: 4.38675798e-08
Iter: 3491 loss: 4.38556782e-08
Iter: 3492 loss: 4.38337544e-08
Iter: 3493 loss: 4.38378507e-08
Iter: 3494 loss: 4.38042562e-08
Iter: 3495 loss: 4.40941754e-08
Iter: 3496 loss: 4.3804377e-08
Iter: 3497 loss: 4.37853416e-08
Iter: 3498 loss: 4.37893917e-08
Iter: 3499 loss: 4.37694325e-08
Iter: 3500 loss: 4.37410854e-08
Iter: 3501 loss: 4.37323955e-08
Iter: 3502 loss: 4.37171437e-08
Iter: 3503 loss: 4.36885728e-08
Iter: 3504 loss: 4.36902141e-08
Iter: 3505 loss: 4.36752075e-08
Iter: 3506 loss: 4.37089902e-08
Iter: 3507 loss: 4.36649046e-08
Iter: 3508 loss: 4.36528822e-08
Iter: 3509 loss: 4.3652193e-08
Iter: 3510 loss: 4.36437304e-08
Iter: 3511 loss: 4.36278143e-08
Iter: 3512 loss: 4.39045849e-08
Iter: 3513 loss: 4.36254055e-08
Iter: 3514 loss: 4.36011334e-08
Iter: 3515 loss: 4.36127152e-08
Iter: 3516 loss: 4.35930829e-08
Iter: 3517 loss: 4.35703136e-08
Iter: 3518 loss: 4.35843077e-08
Iter: 3519 loss: 4.35620358e-08
Iter: 3520 loss: 4.35407443e-08
Iter: 3521 loss: 4.37283596e-08
Iter: 3522 loss: 4.35364562e-08
Iter: 3523 loss: 4.35191794e-08
Iter: 3524 loss: 4.34977814e-08
Iter: 3525 loss: 4.34967937e-08
Iter: 3526 loss: 4.34643432e-08
Iter: 3527 loss: 4.36698642e-08
Iter: 3528 loss: 4.34653415e-08
Iter: 3529 loss: 4.34464269e-08
Iter: 3530 loss: 4.34991776e-08
Iter: 3531 loss: 4.34364e-08
Iter: 3532 loss: 4.34173728e-08
Iter: 3533 loss: 4.34186944e-08
Iter: 3534 loss: 4.34120508e-08
Iter: 3535 loss: 4.33949481e-08
Iter: 3536 loss: 4.33967955e-08
Iter: 3537 loss: 4.33781153e-08
Iter: 3538 loss: 4.34101537e-08
Iter: 3539 loss: 4.33639187e-08
Iter: 3540 loss: 4.33442509e-08
Iter: 3541 loss: 4.33330207e-08
Iter: 3542 loss: 4.33272334e-08
Iter: 3543 loss: 4.3301366e-08
Iter: 3544 loss: 4.33009788e-08
Iter: 3545 loss: 4.32798863e-08
Iter: 3546 loss: 4.3323702e-08
Iter: 3547 loss: 4.32713243e-08
Iter: 3548 loss: 4.32499476e-08
Iter: 3549 loss: 4.32525198e-08
Iter: 3550 loss: 4.32320348e-08
Iter: 3551 loss: 4.32133618e-08
Iter: 3552 loss: 4.33747545e-08
Iter: 3553 loss: 4.32133653e-08
Iter: 3554 loss: 4.31923901e-08
Iter: 3555 loss: 4.31581668e-08
Iter: 3556 loss: 4.31581633e-08
Iter: 3557 loss: 4.31333085e-08
Iter: 3558 loss: 4.33002967e-08
Iter: 3559 loss: 4.3125489e-08
Iter: 3560 loss: 4.30999094e-08
Iter: 3561 loss: 4.32970744e-08
Iter: 3562 loss: 4.3091358e-08
Iter: 3563 loss: 4.30640803e-08
Iter: 3564 loss: 4.30241407e-08
Iter: 3565 loss: 4.39199326e-08
Iter: 3566 loss: 4.30182716e-08
Iter: 3567 loss: 4.29650697e-08
Iter: 3568 loss: 4.33635954e-08
Iter: 3569 loss: 4.29571614e-08
Iter: 3570 loss: 4.29221814e-08
Iter: 3571 loss: 4.34834249e-08
Iter: 3572 loss: 4.29211653e-08
Iter: 3573 loss: 4.29042792e-08
Iter: 3574 loss: 4.28802203e-08
Iter: 3575 loss: 4.28747597e-08
Iter: 3576 loss: 4.28491767e-08
Iter: 3577 loss: 4.29608846e-08
Iter: 3578 loss: 4.28391971e-08
Iter: 3579 loss: 4.28055813e-08
Iter: 3580 loss: 4.29493596e-08
Iter: 3581 loss: 4.27974e-08
Iter: 3582 loss: 4.2771191e-08
Iter: 3583 loss: 4.277409e-08
Iter: 3584 loss: 4.27510969e-08
Iter: 3585 loss: 4.27103046e-08
Iter: 3586 loss: 4.28781419e-08
Iter: 3587 loss: 4.27069402e-08
Iter: 3588 loss: 4.26697966e-08
Iter: 3589 loss: 4.27178541e-08
Iter: 3590 loss: 4.26507114e-08
Iter: 3591 loss: 4.26123705e-08
Iter: 3592 loss: 4.2668475e-08
Iter: 3593 loss: 4.26011759e-08
Iter: 3594 loss: 4.25818598e-08
Iter: 3595 loss: 4.25792e-08
Iter: 3596 loss: 4.25639435e-08
Iter: 3597 loss: 4.25648352e-08
Iter: 3598 loss: 4.25571685e-08
Iter: 3599 loss: 4.2538538e-08
Iter: 3600 loss: 4.25400195e-08
Iter: 3601 loss: 4.25282778e-08
Iter: 3602 loss: 4.25065245e-08
Iter: 3603 loss: 4.25068549e-08
Iter: 3604 loss: 4.24892832e-08
Iter: 3605 loss: 4.24801527e-08
Iter: 3606 loss: 4.24749445e-08
Iter: 3607 loss: 4.24506972e-08
Iter: 3608 loss: 4.24800959e-08
Iter: 3609 loss: 4.24303472e-08
Iter: 3610 loss: 4.24092121e-08
Iter: 3611 loss: 4.24109032e-08
Iter: 3612 loss: 4.23938289e-08
Iter: 3613 loss: 4.23695319e-08
Iter: 3614 loss: 4.23658939e-08
Iter: 3615 loss: 4.23307434e-08
Iter: 3616 loss: 4.24127364e-08
Iter: 3617 loss: 4.23234496e-08
Iter: 3618 loss: 4.2283375e-08
Iter: 3619 loss: 4.26262439e-08
Iter: 3620 loss: 4.22869491e-08
Iter: 3621 loss: 4.22605098e-08
Iter: 3622 loss: 4.22522461e-08
Iter: 3623 loss: 4.2247791e-08
Iter: 3624 loss: 4.22192521e-08
Iter: 3625 loss: 4.23943334e-08
Iter: 3626 loss: 4.22168895e-08
Iter: 3627 loss: 4.21897255e-08
Iter: 3628 loss: 4.21455795e-08
Iter: 3629 loss: 4.21428723e-08
Iter: 3630 loss: 4.20862278e-08
Iter: 3631 loss: 4.2309324e-08
Iter: 3632 loss: 4.20786215e-08
Iter: 3633 loss: 4.20401278e-08
Iter: 3634 loss: 4.21163264e-08
Iter: 3635 loss: 4.20320134e-08
Iter: 3636 loss: 4.19844426e-08
Iter: 3637 loss: 4.24986055e-08
Iter: 3638 loss: 4.19882e-08
Iter: 3639 loss: 4.1962636e-08
Iter: 3640 loss: 4.19527595e-08
Iter: 3641 loss: 4.19415542e-08
Iter: 3642 loss: 4.1922064e-08
Iter: 3643 loss: 4.20490345e-08
Iter: 3644 loss: 4.1917481e-08
Iter: 3645 loss: 4.1899348e-08
Iter: 3646 loss: 4.19537649e-08
Iter: 3647 loss: 4.18843982e-08
Iter: 3648 loss: 4.18618811e-08
Iter: 3649 loss: 4.18349728e-08
Iter: 3650 loss: 4.18289332e-08
Iter: 3651 loss: 4.18095425e-08
Iter: 3652 loss: 4.18044124e-08
Iter: 3653 loss: 4.17922834e-08
Iter: 3654 loss: 4.17812345e-08
Iter: 3655 loss: 4.17744062e-08
Iter: 3656 loss: 4.17549657e-08
Iter: 3657 loss: 4.19511323e-08
Iter: 3658 loss: 4.17564934e-08
Iter: 3659 loss: 4.17354435e-08
Iter: 3660 loss: 4.17855404e-08
Iter: 3661 loss: 4.17250661e-08
Iter: 3662 loss: 4.17180885e-08
Iter: 3663 loss: 4.17061869e-08
Iter: 3664 loss: 4.17015329e-08
Iter: 3665 loss: 4.16781916e-08
Iter: 3666 loss: 4.17873e-08
Iter: 3667 loss: 4.16742942e-08
Iter: 3668 loss: 4.16663894e-08
Iter: 3669 loss: 4.1865448e-08
Iter: 3670 loss: 4.16650607e-08
Iter: 3671 loss: 4.16384545e-08
Iter: 3672 loss: 4.16171133e-08
Iter: 3673 loss: 4.16192343e-08
Iter: 3674 loss: 4.15841548e-08
Iter: 3675 loss: 4.1665043e-08
Iter: 3676 loss: 4.15736103e-08
Iter: 3677 loss: 4.15660359e-08
Iter: 3678 loss: 4.15667678e-08
Iter: 3679 loss: 4.15459169e-08
Iter: 3680 loss: 4.15164045e-08
Iter: 3681 loss: 4.20709334e-08
Iter: 3682 loss: 4.15104715e-08
Iter: 3683 loss: 4.14977741e-08
Iter: 3684 loss: 4.14958592e-08
Iter: 3685 loss: 4.14832e-08
Iter: 3686 loss: 4.1477886e-08
Iter: 3687 loss: 4.14699457e-08
Iter: 3688 loss: 4.14465937e-08
Iter: 3689 loss: 4.15182839e-08
Iter: 3690 loss: 4.1444931e-08
Iter: 3691 loss: 4.14251957e-08
Iter: 3692 loss: 4.16875778e-08
Iter: 3693 loss: 4.1424606e-08
Iter: 3694 loss: 4.14087182e-08
Iter: 3695 loss: 4.13920027e-08
Iter: 3696 loss: 4.19779553e-08
Iter: 3697 loss: 4.13934345e-08
Iter: 3698 loss: 4.13698622e-08
Iter: 3699 loss: 4.14750936e-08
Iter: 3700 loss: 4.13626644e-08
Iter: 3701 loss: 4.13509191e-08
Iter: 3702 loss: 4.13838563e-08
Iter: 3703 loss: 4.13474837e-08
Iter: 3704 loss: 4.13326795e-08
Iter: 3705 loss: 4.1335646e-08
Iter: 3706 loss: 4.1327624e-08
Iter: 3707 loss: 4.13048227e-08
Iter: 3708 loss: 4.15877963e-08
Iter: 3709 loss: 4.13041192e-08
Iter: 3710 loss: 4.12766852e-08
Iter: 3711 loss: 4.12865653e-08
Iter: 3712 loss: 4.12607584e-08
Iter: 3713 loss: 4.12369126e-08
Iter: 3714 loss: 4.12342374e-08
Iter: 3715 loss: 4.12226342e-08
Iter: 3716 loss: 4.11875511e-08
Iter: 3717 loss: 4.18804333e-08
Iter: 3718 loss: 4.11873557e-08
Iter: 3719 loss: 4.11710097e-08
Iter: 3720 loss: 4.12531485e-08
Iter: 3721 loss: 4.11625152e-08
Iter: 3722 loss: 4.11400443e-08
Iter: 3723 loss: 4.12589678e-08
Iter: 3724 loss: 4.11362251e-08
Iter: 3725 loss: 4.11168237e-08
Iter: 3726 loss: 4.11317167e-08
Iter: 3727 loss: 4.11093914e-08
Iter: 3728 loss: 4.10851442e-08
Iter: 3729 loss: 4.12124628e-08
Iter: 3730 loss: 4.10777474e-08
Iter: 3731 loss: 4.10514751e-08
Iter: 3732 loss: 4.10377545e-08
Iter: 3733 loss: 4.10288052e-08
Iter: 3734 loss: 4.09873628e-08
Iter: 3735 loss: 4.10723118e-08
Iter: 3736 loss: 4.09609129e-08
Iter: 3737 loss: 4.09301357e-08
Iter: 3738 loss: 4.1075932e-08
Iter: 3739 loss: 4.09211474e-08
Iter: 3740 loss: 4.09123e-08
Iter: 3741 loss: 4.08995646e-08
Iter: 3742 loss: 4.08909173e-08
Iter: 3743 loss: 4.08756264e-08
Iter: 3744 loss: 4.08789909e-08
Iter: 3745 loss: 4.08687377e-08
Iter: 3746 loss: 4.10263787e-08
Iter: 3747 loss: 4.08641654e-08
Iter: 3748 loss: 4.08524841e-08
Iter: 3749 loss: 4.08623109e-08
Iter: 3750 loss: 4.08433962e-08
Iter: 3751 loss: 4.08291143e-08
Iter: 3752 loss: 4.08174792e-08
Iter: 3753 loss: 4.08126404e-08
Iter: 3754 loss: 4.07814227e-08
Iter: 3755 loss: 4.10474712e-08
Iter: 3756 loss: 4.07809e-08
Iter: 3757 loss: 4.0752866e-08
Iter: 3758 loss: 4.07298693e-08
Iter: 3759 loss: 4.07173602e-08
Iter: 3760 loss: 4.06952445e-08
Iter: 3761 loss: 4.06926e-08
Iter: 3762 loss: 4.06633553e-08
Iter: 3763 loss: 4.06696259e-08
Iter: 3764 loss: 4.06474499e-08
Iter: 3765 loss: 4.06307805e-08
Iter: 3766 loss: 4.06212273e-08
Iter: 3767 loss: 4.06089598e-08
Iter: 3768 loss: 4.05886453e-08
Iter: 3769 loss: 4.05759764e-08
Iter: 3770 loss: 4.05700327e-08
Iter: 3771 loss: 4.05446912e-08
Iter: 3772 loss: 4.05860661e-08
Iter: 3773 loss: 4.05324556e-08
Iter: 3774 loss: 4.05109795e-08
Iter: 3775 loss: 4.07771381e-08
Iter: 3776 loss: 4.05104572e-08
Iter: 3777 loss: 4.04942213e-08
Iter: 3778 loss: 4.04691747e-08
Iter: 3779 loss: 4.0466265e-08
Iter: 3780 loss: 4.04421279e-08
Iter: 3781 loss: 4.04389624e-08
Iter: 3782 loss: 4.04153617e-08
Iter: 3783 loss: 4.03985965e-08
Iter: 3784 loss: 4.04023233e-08
Iter: 3785 loss: 4.03847054e-08
Iter: 3786 loss: 4.04440748e-08
Iter: 3787 loss: 4.03784277e-08
Iter: 3788 loss: 4.03665865e-08
Iter: 3789 loss: 4.03391702e-08
Iter: 3790 loss: 4.08667091e-08
Iter: 3791 loss: 4.03388896e-08
Iter: 3792 loss: 4.03127416e-08
Iter: 3793 loss: 4.06456095e-08
Iter: 3794 loss: 4.03076399e-08
Iter: 3795 loss: 4.02753138e-08
Iter: 3796 loss: 4.03000406e-08
Iter: 3797 loss: 4.02434921e-08
Iter: 3798 loss: 4.02110594e-08
Iter: 3799 loss: 4.02607228e-08
Iter: 3800 loss: 4.01914164e-08
Iter: 3801 loss: 4.01710523e-08
Iter: 3802 loss: 4.04830729e-08
Iter: 3803 loss: 4.01686719e-08
Iter: 3804 loss: 4.01536724e-08
Iter: 3805 loss: 4.02399891e-08
Iter: 3806 loss: 4.01480378e-08
Iter: 3807 loss: 4.01343918e-08
Iter: 3808 loss: 4.01511144e-08
Iter: 3809 loss: 4.0118028e-08
Iter: 3810 loss: 4.01017601e-08
Iter: 3811 loss: 4.01555695e-08
Iter: 3812 loss: 4.01033482e-08
Iter: 3813 loss: 4.00772393e-08
Iter: 3814 loss: 4.00804e-08
Iter: 3815 loss: 4.00598346e-08
Iter: 3816 loss: 4.00247586e-08
Iter: 3817 loss: 3.99815221e-08
Iter: 3818 loss: 3.9978481e-08
Iter: 3819 loss: 3.99237514e-08
Iter: 3820 loss: 4.0553612e-08
Iter: 3821 loss: 3.99158289e-08
Iter: 3822 loss: 3.9885574e-08
Iter: 3823 loss: 4.02720026e-08
Iter: 3824 loss: 3.98874676e-08
Iter: 3825 loss: 3.98593549e-08
Iter: 3826 loss: 3.98349549e-08
Iter: 3827 loss: 3.98315372e-08
Iter: 3828 loss: 3.9817742e-08
Iter: 3829 loss: 3.98164417e-08
Iter: 3830 loss: 3.97938678e-08
Iter: 3831 loss: 3.97920665e-08
Iter: 3832 loss: 3.978138e-08
Iter: 3833 loss: 3.97603586e-08
Iter: 3834 loss: 3.9758433e-08
Iter: 3835 loss: 3.97443571e-08
Iter: 3836 loss: 3.97269595e-08
Iter: 3837 loss: 3.98095104e-08
Iter: 3838 loss: 3.97102866e-08
Iter: 3839 loss: 3.96937025e-08
Iter: 3840 loss: 3.98213587e-08
Iter: 3841 loss: 3.96958555e-08
Iter: 3842 loss: 3.96674977e-08
Iter: 3843 loss: 3.96399074e-08
Iter: 3844 loss: 3.9645041e-08
Iter: 3845 loss: 3.96113933e-08
Iter: 3846 loss: 3.96664461e-08
Iter: 3847 loss: 3.95970829e-08
Iter: 3848 loss: 3.95733153e-08
Iter: 3849 loss: 3.99540738e-08
Iter: 3850 loss: 3.95741893e-08
Iter: 3851 loss: 3.95607529e-08
Iter: 3852 loss: 3.95305371e-08
Iter: 3853 loss: 3.9529759e-08
Iter: 3854 loss: 3.95143971e-08
Iter: 3855 loss: 3.96945765e-08
Iter: 3856 loss: 3.95077855e-08
Iter: 3857 loss: 3.94861068e-08
Iter: 3858 loss: 3.95909758e-08
Iter: 3859 loss: 3.94860535e-08
Iter: 3860 loss: 3.94690858e-08
Iter: 3861 loss: 3.94312e-08
Iter: 3862 loss: 3.94338215e-08
Iter: 3863 loss: 3.93821082e-08
Iter: 3864 loss: 3.96144593e-08
Iter: 3865 loss: 3.93718835e-08
Iter: 3866 loss: 3.93216091e-08
Iter: 3867 loss: 3.94442e-08
Iter: 3868 loss: 3.93038064e-08
Iter: 3869 loss: 3.92752355e-08
Iter: 3870 loss: 3.93761894e-08
Iter: 3871 loss: 3.9257813e-08
Iter: 3872 loss: 3.92369053e-08
Iter: 3873 loss: 3.93477784e-08
Iter: 3874 loss: 3.92244388e-08
Iter: 3875 loss: 3.92064621e-08
Iter: 3876 loss: 3.94189e-08
Iter: 3877 loss: 3.92071691e-08
Iter: 3878 loss: 3.91883752e-08
Iter: 3879 loss: 3.91645933e-08
Iter: 3880 loss: 3.916373e-08
Iter: 3881 loss: 3.91271726e-08
Iter: 3882 loss: 3.91781327e-08
Iter: 3883 loss: 3.91212041e-08
Iter: 3884 loss: 3.90686665e-08
Iter: 3885 loss: 3.91177153e-08
Iter: 3886 loss: 3.90477375e-08
Iter: 3887 loss: 3.89930435e-08
Iter: 3888 loss: 3.89715886e-08
Iter: 3889 loss: 3.89439236e-08
Iter: 3890 loss: 3.89158217e-08
Iter: 3891 loss: 3.89122796e-08
Iter: 3892 loss: 3.88776904e-08
Iter: 3893 loss: 3.88457231e-08
Iter: 3894 loss: 3.88372712e-08
Iter: 3895 loss: 3.88032859e-08
Iter: 3896 loss: 3.88292314e-08
Iter: 3897 loss: 3.87848829e-08
Iter: 3898 loss: 3.87593886e-08
Iter: 3899 loss: 3.87584365e-08
Iter: 3900 loss: 3.87449823e-08
Iter: 3901 loss: 3.87389427e-08
Iter: 3902 loss: 3.8729624e-08
Iter: 3903 loss: 3.87006978e-08
Iter: 3904 loss: 3.8656367e-08
Iter: 3905 loss: 3.8655827e-08
Iter: 3906 loss: 3.86301267e-08
Iter: 3907 loss: 3.86223604e-08
Iter: 3908 loss: 3.85992891e-08
Iter: 3909 loss: 3.86332708e-08
Iter: 3910 loss: 3.85817849e-08
Iter: 3911 loss: 3.85657515e-08
Iter: 3912 loss: 3.86461778e-08
Iter: 3913 loss: 3.85579391e-08
Iter: 3914 loss: 3.85342318e-08
Iter: 3915 loss: 3.86371219e-08
Iter: 3916 loss: 3.85333152e-08
Iter: 3917 loss: 3.85158963e-08
Iter: 3918 loss: 3.85896897e-08
Iter: 3919 loss: 3.85169692e-08
Iter: 3920 loss: 3.8503714e-08
Iter: 3921 loss: 3.84801879e-08
Iter: 3922 loss: 3.84828596e-08
Iter: 3923 loss: 3.84610068e-08
Iter: 3924 loss: 3.86345675e-08
Iter: 3925 loss: 3.84508567e-08
Iter: 3926 loss: 3.84367809e-08
Iter: 3927 loss: 3.84014811e-08
Iter: 3928 loss: 3.90459576e-08
Iter: 3929 loss: 3.83952283e-08
Iter: 3930 loss: 3.83317484e-08
Iter: 3931 loss: 3.8456232e-08
Iter: 3932 loss: 3.83079843e-08
Iter: 3933 loss: 3.82573475e-08
Iter: 3934 loss: 3.82581824e-08
Iter: 3935 loss: 3.82068137e-08
Iter: 3936 loss: 3.82152088e-08
Iter: 3937 loss: 3.81824066e-08
Iter: 3938 loss: 3.81389711e-08
Iter: 3939 loss: 3.81227352e-08
Iter: 3940 loss: 3.80993299e-08
Iter: 3941 loss: 3.80590919e-08
Iter: 3942 loss: 3.81867196e-08
Iter: 3943 loss: 3.80439644e-08
Iter: 3944 loss: 3.7993253e-08
Iter: 3945 loss: 3.81362781e-08
Iter: 3946 loss: 3.79857532e-08
Iter: 3947 loss: 3.79366973e-08
Iter: 3948 loss: 3.79436607e-08
Iter: 3949 loss: 3.79141731e-08
Iter: 3950 loss: 3.79055543e-08
Iter: 3951 loss: 3.78877871e-08
Iter: 3952 loss: 3.78540683e-08
Iter: 3953 loss: 3.82316259e-08
Iter: 3954 loss: 3.78574931e-08
Iter: 3955 loss: 3.78293166e-08
Iter: 3956 loss: 3.79765908e-08
Iter: 3957 loss: 3.78223319e-08
Iter: 3958 loss: 3.78026854e-08
Iter: 3959 loss: 3.77986744e-08
Iter: 3960 loss: 3.77892171e-08
Iter: 3961 loss: 3.77644795e-08
Iter: 3962 loss: 3.80566156e-08
Iter: 3963 loss: 3.77645257e-08
Iter: 3964 loss: 3.77461831e-08
Iter: 3965 loss: 3.77215059e-08
Iter: 3966 loss: 3.77197864e-08
Iter: 3967 loss: 3.77056324e-08
Iter: 3968 loss: 3.80028844e-08
Iter: 3969 loss: 3.77045914e-08
Iter: 3970 loss: 3.76785252e-08
Iter: 3971 loss: 3.76570526e-08
Iter: 3972 loss: 3.76547682e-08
Iter: 3973 loss: 3.76168963e-08
Iter: 3974 loss: 3.75833231e-08
Iter: 3975 loss: 3.75738622e-08
Iter: 3976 loss: 3.75210725e-08
Iter: 3977 loss: 3.76679594e-08
Iter: 3978 loss: 3.749971e-08
Iter: 3979 loss: 3.74485651e-08
Iter: 3980 loss: 3.76746776e-08
Iter: 3981 loss: 3.74493503e-08
Iter: 3982 loss: 3.74078333e-08
Iter: 3983 loss: 3.75194631e-08
Iter: 3984 loss: 3.73979567e-08
Iter: 3985 loss: 3.7357907e-08
Iter: 3986 loss: 3.76392961e-08
Iter: 3987 loss: 3.73559068e-08
Iter: 3988 loss: 3.73333364e-08
Iter: 3989 loss: 3.73164966e-08
Iter: 3990 loss: 3.73125957e-08
Iter: 3991 loss: 3.72684958e-08
Iter: 3992 loss: 3.74282116e-08
Iter: 3993 loss: 3.72578413e-08
Iter: 3994 loss: 3.72274087e-08
Iter: 3995 loss: 3.73901337e-08
Iter: 3996 loss: 3.72256501e-08
Iter: 3997 loss: 3.72092e-08
Iter: 3998 loss: 3.72464299e-08
Iter: 3999 loss: 3.72030762e-08
Iter: 4000 loss: 3.71847584e-08
Iter: 4001 loss: 3.72465436e-08
Iter: 4002 loss: 3.71749884e-08
Iter: 4003 loss: 3.71664548e-08
Iter: 4004 loss: 3.71852558e-08
Iter: 4005 loss: 3.71546811e-08
Iter: 4006 loss: 3.71364095e-08
Iter: 4007 loss: 3.70921143e-08
Iter: 4008 loss: 3.7824698e-08
Iter: 4009 loss: 3.70936135e-08
Iter: 4010 loss: 3.70301336e-08
Iter: 4011 loss: 3.7059408e-08
Iter: 4012 loss: 3.69944289e-08
Iter: 4013 loss: 3.69152851e-08
Iter: 4014 loss: 3.71351163e-08
Iter: 4015 loss: 3.6888725e-08
Iter: 4016 loss: 3.68311817e-08
Iter: 4017 loss: 3.71109472e-08
Iter: 4018 loss: 3.68299204e-08
Iter: 4019 loss: 3.67980277e-08
Iter: 4020 loss: 3.72849e-08
Iter: 4021 loss: 3.67977542e-08
Iter: 4022 loss: 3.67601842e-08
Iter: 4023 loss: 3.68432325e-08
Iter: 4024 loss: 3.67471031e-08
Iter: 4025 loss: 3.67201025e-08
Iter: 4026 loss: 3.67323558e-08
Iter: 4027 loss: 3.67137112e-08
Iter: 4028 loss: 3.66537947e-08
Iter: 4029 loss: 3.68060817e-08
Iter: 4030 loss: 3.66306523e-08
Iter: 4031 loss: 3.65989692e-08
Iter: 4032 loss: 3.67056714e-08
Iter: 4033 loss: 3.65854049e-08
Iter: 4034 loss: 3.65411559e-08
Iter: 4035 loss: 3.66928639e-08
Iter: 4036 loss: 3.65289594e-08
Iter: 4037 loss: 3.65028399e-08
Iter: 4038 loss: 3.6654523e-08
Iter: 4039 loss: 3.65020263e-08
Iter: 4040 loss: 3.64707908e-08
Iter: 4041 loss: 3.64856518e-08
Iter: 4042 loss: 3.6459781e-08
Iter: 4043 loss: 3.64165302e-08
Iter: 4044 loss: 3.65078279e-08
Iter: 4045 loss: 3.64039821e-08
Iter: 4046 loss: 3.63767718e-08
Iter: 4047 loss: 3.63324233e-08
Iter: 4048 loss: 3.63269379e-08
Iter: 4049 loss: 3.62735904e-08
Iter: 4050 loss: 3.63684372e-08
Iter: 4051 loss: 3.62505617e-08
Iter: 4052 loss: 3.61873482e-08
Iter: 4053 loss: 3.64701123e-08
Iter: 4054 loss: 3.61770844e-08
Iter: 4055 loss: 3.61688599e-08
Iter: 4056 loss: 3.61641703e-08
Iter: 4057 loss: 3.61394079e-08
Iter: 4058 loss: 3.6103863e-08
Iter: 4059 loss: 3.61074228e-08
Iter: 4060 loss: 3.6079328e-08
Iter: 4061 loss: 3.60731818e-08
Iter: 4062 loss: 3.60591e-08
Iter: 4063 loss: 3.60132404e-08
Iter: 4064 loss: 3.65197934e-08
Iter: 4065 loss: 3.60159085e-08
Iter: 4066 loss: 3.59960026e-08
Iter: 4067 loss: 3.59682275e-08
Iter: 4068 loss: 3.59629482e-08
Iter: 4069 loss: 3.59268526e-08
Iter: 4070 loss: 3.59991e-08
Iter: 4071 loss: 3.59060728e-08
Iter: 4072 loss: 3.58717394e-08
Iter: 4073 loss: 3.61418842e-08
Iter: 4074 loss: 3.58738603e-08
Iter: 4075 loss: 3.58382231e-08
Iter: 4076 loss: 3.58709435e-08
Iter: 4077 loss: 3.58233585e-08
Iter: 4078 loss: 3.58072e-08
Iter: 4079 loss: 3.59634953e-08
Iter: 4080 loss: 3.5805698e-08
Iter: 4081 loss: 3.57907055e-08
Iter: 4082 loss: 3.57575374e-08
Iter: 4083 loss: 3.57605927e-08
Iter: 4084 loss: 3.57344945e-08
Iter: 4085 loss: 3.57975374e-08
Iter: 4086 loss: 3.57147378e-08
Iter: 4087 loss: 3.56793848e-08
Iter: 4088 loss: 3.57380188e-08
Iter: 4089 loss: 3.56707908e-08
Iter: 4090 loss: 3.56262e-08
Iter: 4091 loss: 3.59122225e-08
Iter: 4092 loss: 3.56156917e-08
Iter: 4093 loss: 3.55896432e-08
Iter: 4094 loss: 3.55469929e-08
Iter: 4095 loss: 3.55478136e-08
Iter: 4096 loss: 3.55355212e-08
Iter: 4097 loss: 3.55294354e-08
Iter: 4098 loss: 3.55097711e-08
Iter: 4099 loss: 3.54852041e-08
Iter: 4100 loss: 3.54818042e-08
Iter: 4101 loss: 3.54508458e-08
Iter: 4102 loss: 3.56124303e-08
Iter: 4103 loss: 3.54454031e-08
Iter: 4104 loss: 3.54334091e-08
Iter: 4105 loss: 3.54154643e-08
Iter: 4106 loss: 3.54142635e-08
Iter: 4107 loss: 3.53825484e-08
Iter: 4108 loss: 3.55348533e-08
Iter: 4109 loss: 3.53817846e-08
Iter: 4110 loss: 3.53473872e-08
Iter: 4111 loss: 3.56107961e-08
Iter: 4112 loss: 3.53470284e-08
Iter: 4113 loss: 3.5326007e-08
Iter: 4114 loss: 3.52806779e-08
Iter: 4115 loss: 3.52855594e-08
Iter: 4116 loss: 3.52432608e-08
Iter: 4117 loss: 3.5253553e-08
Iter: 4118 loss: 3.52130911e-08
Iter: 4119 loss: 3.51699185e-08
Iter: 4120 loss: 3.56720555e-08
Iter: 4121 loss: 3.51710163e-08
Iter: 4122 loss: 3.5146126e-08
Iter: 4123 loss: 3.51695206e-08
Iter: 4124 loss: 3.51388323e-08
Iter: 4125 loss: 3.5100534e-08
Iter: 4126 loss: 3.5066023e-08
Iter: 4127 loss: 3.50590525e-08
Iter: 4128 loss: 3.50118228e-08
Iter: 4129 loss: 3.51700429e-08
Iter: 4130 loss: 3.49960949e-08
Iter: 4131 loss: 3.4932075e-08
Iter: 4132 loss: 3.49815394e-08
Iter: 4133 loss: 3.48956277e-08
Iter: 4134 loss: 3.48533433e-08
Iter: 4135 loss: 3.53215555e-08
Iter: 4136 loss: 3.48551588e-08
Iter: 4137 loss: 3.48292382e-08
Iter: 4138 loss: 3.48667584e-08
Iter: 4139 loss: 3.48099078e-08
Iter: 4140 loss: 3.47857245e-08
Iter: 4141 loss: 3.47844775e-08
Iter: 4142 loss: 3.47656943e-08
Iter: 4143 loss: 3.4726348e-08
Iter: 4144 loss: 3.51406158e-08
Iter: 4145 loss: 3.47245397e-08
Iter: 4146 loss: 3.47001965e-08
Iter: 4147 loss: 3.48236711e-08
Iter: 4148 loss: 3.46950202e-08
Iter: 4149 loss: 3.46688331e-08
Iter: 4150 loss: 3.46368232e-08
Iter: 4151 loss: 3.46357325e-08
Iter: 4152 loss: 3.45846232e-08
Iter: 4153 loss: 3.46773632e-08
Iter: 4154 loss: 3.4564529e-08
Iter: 4155 loss: 3.45075541e-08
Iter: 4156 loss: 3.51670799e-08
Iter: 4157 loss: 3.45065416e-08
Iter: 4158 loss: 3.44643958e-08
Iter: 4159 loss: 3.46278668e-08
Iter: 4160 loss: 3.44572904e-08
Iter: 4161 loss: 3.44197275e-08
Iter: 4162 loss: 3.45042821e-08
Iter: 4163 loss: 3.44118902e-08
Iter: 4164 loss: 3.43809674e-08
Iter: 4165 loss: 3.44056801e-08
Iter: 4166 loss: 3.43549544e-08
Iter: 4167 loss: 3.43244082e-08
Iter: 4168 loss: 3.43497426e-08
Iter: 4169 loss: 3.42996e-08
Iter: 4170 loss: 3.42507533e-08
Iter: 4171 loss: 3.44941142e-08
Iter: 4172 loss: 3.42451294e-08
Iter: 4173 loss: 3.42081385e-08
Iter: 4174 loss: 3.41467974e-08
Iter: 4175 loss: 3.4143536e-08
Iter: 4176 loss: 3.40621114e-08
Iter: 4177 loss: 3.42383153e-08
Iter: 4178 loss: 3.40357182e-08
Iter: 4179 loss: 3.39504922e-08
Iter: 4180 loss: 3.39536648e-08
Iter: 4181 loss: 3.39019479e-08
Iter: 4182 loss: 3.38840387e-08
Iter: 4183 loss: 3.3858214e-08
Iter: 4184 loss: 3.38078081e-08
Iter: 4185 loss: 3.38669501e-08
Iter: 4186 loss: 3.37814541e-08
Iter: 4187 loss: 3.37399833e-08
Iter: 4188 loss: 3.3738953e-08
Iter: 4189 loss: 3.3710041e-08
Iter: 4190 loss: 3.37467334e-08
Iter: 4191 loss: 3.36954891e-08
Iter: 4192 loss: 3.36601857e-08
Iter: 4193 loss: 3.38430333e-08
Iter: 4194 loss: 3.36545796e-08
Iter: 4195 loss: 3.36276e-08
Iter: 4196 loss: 3.363742e-08
Iter: 4197 loss: 3.36097585e-08
Iter: 4198 loss: 3.35588837e-08
Iter: 4199 loss: 3.34904904e-08
Iter: 4200 loss: 3.34903874e-08
Iter: 4201 loss: 3.34285488e-08
Iter: 4202 loss: 3.3427547e-08
Iter: 4203 loss: 3.33790418e-08
Iter: 4204 loss: 3.33169083e-08
Iter: 4205 loss: 3.33161125e-08
Iter: 4206 loss: 3.32502097e-08
Iter: 4207 loss: 3.33413972e-08
Iter: 4208 loss: 3.32105969e-08
Iter: 4209 loss: 3.31727072e-08
Iter: 4210 loss: 3.38349118e-08
Iter: 4211 loss: 3.31724088e-08
Iter: 4212 loss: 3.31275629e-08
Iter: 4213 loss: 3.32087104e-08
Iter: 4214 loss: 3.31040049e-08
Iter: 4215 loss: 3.30652092e-08
Iter: 4216 loss: 3.30571019e-08
Iter: 4217 loss: 3.30265024e-08
Iter: 4218 loss: 3.2965815e-08
Iter: 4219 loss: 3.32045e-08
Iter: 4220 loss: 3.29501937e-08
Iter: 4221 loss: 3.28939187e-08
Iter: 4222 loss: 3.34104584e-08
Iter: 4223 loss: 3.28915526e-08
Iter: 4224 loss: 3.28317888e-08
Iter: 4225 loss: 3.28797825e-08
Iter: 4226 loss: 3.27967911e-08
Iter: 4227 loss: 3.27430172e-08
Iter: 4228 loss: 3.32414913e-08
Iter: 4229 loss: 3.27365726e-08
Iter: 4230 loss: 3.2702296e-08
Iter: 4231 loss: 3.2680326e-08
Iter: 4232 loss: 3.26637455e-08
Iter: 4233 loss: 3.26268612e-08
Iter: 4234 loss: 3.2904083e-08
Iter: 4235 loss: 3.26249108e-08
Iter: 4236 loss: 3.25862644e-08
Iter: 4237 loss: 3.25683303e-08
Iter: 4238 loss: 3.25542757e-08
Iter: 4239 loss: 3.24962244e-08
Iter: 4240 loss: 3.25249658e-08
Iter: 4241 loss: 3.24689182e-08
Iter: 4242 loss: 3.24055627e-08
Iter: 4243 loss: 3.24712559e-08
Iter: 4244 loss: 3.23798943e-08
Iter: 4245 loss: 3.23601022e-08
Iter: 4246 loss: 3.23539631e-08
Iter: 4247 loss: 3.23246354e-08
Iter: 4248 loss: 3.22979545e-08
Iter: 4249 loss: 3.22956311e-08
Iter: 4250 loss: 3.22559117e-08
Iter: 4251 loss: 3.23371232e-08
Iter: 4252 loss: 3.22385532e-08
Iter: 4253 loss: 3.22082485e-08
Iter: 4254 loss: 3.2375155e-08
Iter: 4255 loss: 3.22026033e-08
Iter: 4256 loss: 3.21618785e-08
Iter: 4257 loss: 3.23575087e-08
Iter: 4258 loss: 3.21538423e-08
Iter: 4259 loss: 3.21181943e-08
Iter: 4260 loss: 3.21385869e-08
Iter: 4261 loss: 3.21022817e-08
Iter: 4262 loss: 3.20589386e-08
Iter: 4263 loss: 3.24367129e-08
Iter: 4264 loss: 3.20565405e-08
Iter: 4265 loss: 3.20353202e-08
Iter: 4266 loss: 3.19879447e-08
Iter: 4267 loss: 3.1986481e-08
Iter: 4268 loss: 3.19386793e-08
Iter: 4269 loss: 3.24513145e-08
Iter: 4270 loss: 3.19387148e-08
Iter: 4271 loss: 3.18921778e-08
Iter: 4272 loss: 3.18848521e-08
Iter: 4273 loss: 3.18546682e-08
Iter: 4274 loss: 3.17969615e-08
Iter: 4275 loss: 3.17985958e-08
Iter: 4276 loss: 3.17532134e-08
Iter: 4277 loss: 3.16732525e-08
Iter: 4278 loss: 3.19777627e-08
Iter: 4279 loss: 3.16497264e-08
Iter: 4280 loss: 3.15995408e-08
Iter: 4281 loss: 3.24219904e-08
Iter: 4282 loss: 3.1599555e-08
Iter: 4283 loss: 3.15484492e-08
Iter: 4284 loss: 3.1550023e-08
Iter: 4285 loss: 3.15093729e-08
Iter: 4286 loss: 3.1459237e-08
Iter: 4287 loss: 3.14759596e-08
Iter: 4288 loss: 3.14343538e-08
Iter: 4289 loss: 3.1382644e-08
Iter: 4290 loss: 3.14805249e-08
Iter: 4291 loss: 3.13669446e-08
Iter: 4292 loss: 3.13243582e-08
Iter: 4293 loss: 3.14994111e-08
Iter: 4294 loss: 3.13123536e-08
Iter: 4295 loss: 3.12668682e-08
Iter: 4296 loss: 3.14889732e-08
Iter: 4297 loss: 3.12557091e-08
Iter: 4298 loss: 3.12278416e-08
Iter: 4299 loss: 3.11692325e-08
Iter: 4300 loss: 3.11690478e-08
Iter: 4301 loss: 3.11136716e-08
Iter: 4302 loss: 3.1762319e-08
Iter: 4303 loss: 3.11108366e-08
Iter: 4304 loss: 3.1072485e-08
Iter: 4305 loss: 3.11198924e-08
Iter: 4306 loss: 3.10568176e-08
Iter: 4307 loss: 3.10164197e-08
Iter: 4308 loss: 3.10859711e-08
Iter: 4309 loss: 3.09936219e-08
Iter: 4310 loss: 3.09722736e-08
Iter: 4311 loss: 3.13408783e-08
Iter: 4312 loss: 3.09728918e-08
Iter: 4313 loss: 3.09480939e-08
Iter: 4314 loss: 3.09413046e-08
Iter: 4315 loss: 3.0930174e-08
Iter: 4316 loss: 3.09069037e-08
Iter: 4317 loss: 3.09130392e-08
Iter: 4318 loss: 3.08918331e-08
Iter: 4319 loss: 3.08530161e-08
Iter: 4320 loss: 3.09197681e-08
Iter: 4321 loss: 3.08364108e-08
Iter: 4322 loss: 3.08005887e-08
Iter: 4323 loss: 3.0989078e-08
Iter: 4324 loss: 3.07985744e-08
Iter: 4325 loss: 3.07710657e-08
Iter: 4326 loss: 3.08089838e-08
Iter: 4327 loss: 3.07599777e-08
Iter: 4328 loss: 3.07230223e-08
Iter: 4329 loss: 3.11234807e-08
Iter: 4330 loss: 3.07221129e-08
Iter: 4331 loss: 3.07054222e-08
Iter: 4332 loss: 3.06930588e-08
Iter: 4333 loss: 3.06856229e-08
Iter: 4334 loss: 3.06665058e-08
Iter: 4335 loss: 3.06686516e-08
Iter: 4336 loss: 3.0658132e-08
Iter: 4337 loss: 3.06332097e-08
Iter: 4338 loss: 3.06305594e-08
Iter: 4339 loss: 3.06059675e-08
Iter: 4340 loss: 3.07779402e-08
Iter: 4341 loss: 3.06024184e-08
Iter: 4342 loss: 3.0577997e-08
Iter: 4343 loss: 3.06099182e-08
Iter: 4344 loss: 3.05635091e-08
Iter: 4345 loss: 3.05371586e-08
Iter: 4346 loss: 3.06873496e-08
Iter: 4347 loss: 3.05341743e-08
Iter: 4348 loss: 3.05162295e-08
Iter: 4349 loss: 3.05051309e-08
Iter: 4350 loss: 3.0499276e-08
Iter: 4351 loss: 3.04690104e-08
Iter: 4352 loss: 3.0549046e-08
Iter: 4353 loss: 3.04622958e-08
Iter: 4354 loss: 3.04356718e-08
Iter: 4355 loss: 3.04613863e-08
Iter: 4356 loss: 3.0421397e-08
Iter: 4357 loss: 3.03808392e-08
Iter: 4358 loss: 3.0459347e-08
Iter: 4359 loss: 3.03634167e-08
Iter: 4360 loss: 3.03285432e-08
Iter: 4361 loss: 3.05231538e-08
Iter: 4362 loss: 3.03250829e-08
Iter: 4363 loss: 3.03015142e-08
Iter: 4364 loss: 3.05396597e-08
Iter: 4365 loss: 3.03035712e-08
Iter: 4366 loss: 3.02778e-08
Iter: 4367 loss: 3.03049603e-08
Iter: 4368 loss: 3.0273295e-08
Iter: 4369 loss: 3.02507672e-08
Iter: 4370 loss: 3.0341436e-08
Iter: 4371 loss: 3.0247e-08
Iter: 4372 loss: 3.02325098e-08
Iter: 4373 loss: 3.02392209e-08
Iter: 4374 loss: 3.02260723e-08
Iter: 4375 loss: 3.02112326e-08
Iter: 4376 loss: 3.02976275e-08
Iter: 4377 loss: 3.0206639e-08
Iter: 4378 loss: 3.01938954e-08
Iter: 4379 loss: 3.0171357e-08
Iter: 4380 loss: 3.01715843e-08
Iter: 4381 loss: 3.0149625e-08
Iter: 4382 loss: 3.04928527e-08
Iter: 4383 loss: 3.01487475e-08
Iter: 4384 loss: 3.01329877e-08
Iter: 4385 loss: 3.01068077e-08
Iter: 4386 loss: 3.01086018e-08
Iter: 4387 loss: 3.00779703e-08
Iter: 4388 loss: 3.01368388e-08
Iter: 4389 loss: 3.00626724e-08
Iter: 4390 loss: 3.00302894e-08
Iter: 4391 loss: 3.02055945e-08
Iter: 4392 loss: 3.00272021e-08
Iter: 4393 loss: 3.00037613e-08
Iter: 4394 loss: 3.00194749e-08
Iter: 4395 loss: 2.99908578e-08
Iter: 4396 loss: 2.99601091e-08
Iter: 4397 loss: 3.0111071e-08
Iter: 4398 loss: 2.99526768e-08
Iter: 4399 loss: 2.99320142e-08
Iter: 4400 loss: 3.00077403e-08
Iter: 4401 loss: 2.99288629e-08
Iter: 4402 loss: 2.99118028e-08
Iter: 4403 loss: 3.00194216e-08
Iter: 4404 loss: 2.99127692e-08
Iter: 4405 loss: 2.98985299e-08
Iter: 4406 loss: 2.98812921e-08
Iter: 4407 loss: 2.98678771e-08
Iter: 4408 loss: 2.98490583e-08
Iter: 4409 loss: 3.00371106e-08
Iter: 4410 loss: 2.98468947e-08
Iter: 4411 loss: 2.98312024e-08
Iter: 4412 loss: 2.98196916e-08
Iter: 4413 loss: 2.98166327e-08
Iter: 4414 loss: 2.97926679e-08
Iter: 4415 loss: 2.9980832e-08
Iter: 4416 loss: 2.97881542e-08
Iter: 4417 loss: 2.977e-08
Iter: 4418 loss: 2.97678131e-08
Iter: 4419 loss: 2.97625871e-08
Iter: 4420 loss: 2.97352809e-08
Iter: 4421 loss: 2.97169276e-08
Iter: 4422 loss: 2.97078131e-08
Iter: 4423 loss: 2.96720462e-08
Iter: 4424 loss: 2.96705309e-08
Iter: 4425 loss: 2.96394163e-08
Iter: 4426 loss: 2.95883318e-08
Iter: 4427 loss: 3.01495966e-08
Iter: 4428 loss: 2.95904066e-08
Iter: 4429 loss: 2.95568263e-08
Iter: 4430 loss: 2.97215514e-08
Iter: 4431 loss: 2.95605869e-08
Iter: 4432 loss: 2.95271398e-08
Iter: 4433 loss: 2.98133429e-08
Iter: 4434 loss: 2.9529069e-08
Iter: 4435 loss: 2.95112947e-08
Iter: 4436 loss: 2.95261167e-08
Iter: 4437 loss: 2.94985192e-08
Iter: 4438 loss: 2.94795122e-08
Iter: 4439 loss: 2.95418392e-08
Iter: 4440 loss: 2.94746894e-08
Iter: 4441 loss: 2.94505096e-08
Iter: 4442 loss: 2.94730604e-08
Iter: 4443 loss: 2.94385512e-08
Iter: 4444 loss: 2.94024556e-08
Iter: 4445 loss: 2.94589686e-08
Iter: 4446 loss: 2.93903248e-08
Iter: 4447 loss: 2.93479889e-08
Iter: 4448 loss: 2.93615088e-08
Iter: 4449 loss: 2.9329323e-08
Iter: 4450 loss: 2.92712699e-08
Iter: 4451 loss: 2.95763734e-08
Iter: 4452 loss: 2.92679641e-08
Iter: 4453 loss: 2.92326554e-08
Iter: 4454 loss: 2.91669195e-08
Iter: 4455 loss: 3.06113321e-08
Iter: 4456 loss: 2.91684721e-08
Iter: 4457 loss: 2.91076301e-08
Iter: 4458 loss: 2.93511313e-08
Iter: 4459 loss: 2.91007591e-08
Iter: 4460 loss: 2.90571158e-08
Iter: 4461 loss: 2.92473885e-08
Iter: 4462 loss: 2.90378566e-08
Iter: 4463 loss: 2.89899962e-08
Iter: 4464 loss: 2.90714208e-08
Iter: 4465 loss: 2.89753039e-08
Iter: 4466 loss: 2.89518809e-08
Iter: 4467 loss: 2.89446547e-08
Iter: 4468 loss: 2.89213347e-08
Iter: 4469 loss: 2.88984499e-08
Iter: 4470 loss: 2.88885929e-08
Iter: 4471 loss: 2.88622459e-08
Iter: 4472 loss: 2.91585316e-08
Iter: 4473 loss: 2.88636954e-08
Iter: 4474 loss: 2.88373379e-08
Iter: 4475 loss: 2.88165509e-08
Iter: 4476 loss: 2.88065607e-08
Iter: 4477 loss: 2.8769982e-08
Iter: 4478 loss: 2.90811428e-08
Iter: 4479 loss: 2.87692146e-08
Iter: 4480 loss: 2.87416224e-08
Iter: 4481 loss: 2.87381123e-08
Iter: 4482 loss: 2.87224911e-08
Iter: 4483 loss: 2.86874382e-08
Iter: 4484 loss: 2.89251609e-08
Iter: 4485 loss: 2.86902377e-08
Iter: 4486 loss: 2.86498e-08
Iter: 4487 loss: 2.86116304e-08
Iter: 4488 loss: 2.86152613e-08
Iter: 4489 loss: 2.85581194e-08
Iter: 4490 loss: 2.86981958e-08
Iter: 4491 loss: 2.85437505e-08
Iter: 4492 loss: 2.85011126e-08
Iter: 4493 loss: 2.84966362e-08
Iter: 4494 loss: 2.84801782e-08
Iter: 4495 loss: 2.84378885e-08
Iter: 4496 loss: 2.86448163e-08
Iter: 4497 loss: 2.84231874e-08
Iter: 4498 loss: 2.83929076e-08
Iter: 4499 loss: 2.85776416e-08
Iter: 4500 loss: 2.83924955e-08
Iter: 4501 loss: 2.83568546e-08
Iter: 4502 loss: 2.86423312e-08
Iter: 4503 loss: 2.83600805e-08
Iter: 4504 loss: 2.83409776e-08
Iter: 4505 loss: 2.83156e-08
Iter: 4506 loss: 2.83111667e-08
Iter: 4507 loss: 2.82727921e-08
Iter: 4508 loss: 2.86159452e-08
Iter: 4509 loss: 2.82668928e-08
Iter: 4510 loss: 2.82510406e-08
Iter: 4511 loss: 2.82393167e-08
Iter: 4512 loss: 2.8216105e-08
Iter: 4513 loss: 2.82019172e-08
Iter: 4514 loss: 2.82024502e-08
Iter: 4515 loss: 2.81817805e-08
Iter: 4516 loss: 2.81816845e-08
Iter: 4517 loss: 2.81662089e-08
Iter: 4518 loss: 2.81479604e-08
Iter: 4519 loss: 2.8281999e-08
Iter: 4520 loss: 2.81449637e-08
Iter: 4521 loss: 2.81311348e-08
Iter: 4522 loss: 2.81098469e-08
Iter: 4523 loss: 2.81005157e-08
Iter: 4524 loss: 2.80754193e-08
Iter: 4525 loss: 2.80534405e-08
Iter: 4526 loss: 2.8049973e-08
Iter: 4527 loss: 2.79910601e-08
Iter: 4528 loss: 2.80305414e-08
Iter: 4529 loss: 2.7954103e-08
Iter: 4530 loss: 2.7882809e-08
Iter: 4531 loss: 2.88781408e-08
Iter: 4532 loss: 2.78823471e-08
Iter: 4533 loss: 2.78592189e-08
Iter: 4534 loss: 2.78548313e-08
Iter: 4535 loss: 2.78288681e-08
Iter: 4536 loss: 2.7801585e-08
Iter: 4537 loss: 2.77965739e-08
Iter: 4538 loss: 2.77627592e-08
Iter: 4539 loss: 2.80903691e-08
Iter: 4540 loss: 2.77606933e-08
Iter: 4541 loss: 2.77371388e-08
Iter: 4542 loss: 2.77313248e-08
Iter: 4543 loss: 2.770701e-08
Iter: 4544 loss: 2.76765366e-08
Iter: 4545 loss: 2.78922876e-08
Iter: 4546 loss: 2.76749788e-08
Iter: 4547 loss: 2.76445355e-08
Iter: 4548 loss: 2.76552363e-08
Iter: 4549 loss: 2.7625525e-08
Iter: 4550 loss: 2.75826011e-08
Iter: 4551 loss: 2.76316463e-08
Iter: 4552 loss: 2.75618426e-08
Iter: 4553 loss: 2.75066281e-08
Iter: 4554 loss: 2.78989312e-08
Iter: 4555 loss: 2.75052123e-08
Iter: 4556 loss: 2.7471021e-08
Iter: 4557 loss: 2.74204872e-08
Iter: 4558 loss: 2.74151173e-08
Iter: 4559 loss: 2.73502838e-08
Iter: 4560 loss: 2.74734031e-08
Iter: 4561 loss: 2.73249974e-08
Iter: 4562 loss: 2.72639049e-08
Iter: 4563 loss: 2.73509961e-08
Iter: 4564 loss: 2.72394836e-08
Iter: 4565 loss: 2.72124474e-08
Iter: 4566 loss: 2.71978813e-08
Iter: 4567 loss: 2.71661218e-08
Iter: 4568 loss: 2.71810876e-08
Iter: 4569 loss: 2.71455427e-08
Iter: 4570 loss: 2.70984604e-08
Iter: 4571 loss: 2.70730034e-08
Iter: 4572 loss: 2.70523799e-08
Iter: 4573 loss: 2.69767053e-08
Iter: 4574 loss: 2.7722983e-08
Iter: 4575 loss: 2.6972927e-08
Iter: 4576 loss: 2.69444644e-08
Iter: 4577 loss: 2.6904468e-08
Iter: 4578 loss: 2.69004392e-08
Iter: 4579 loss: 2.68764051e-08
Iter: 4580 loss: 2.68675642e-08
Iter: 4581 loss: 2.68435443e-08
Iter: 4582 loss: 2.67960587e-08
Iter: 4583 loss: 2.78216241e-08
Iter: 4584 loss: 2.67968439e-08
Iter: 4585 loss: 2.67496958e-08
Iter: 4586 loss: 2.67467488e-08
Iter: 4587 loss: 2.67223399e-08
Iter: 4588 loss: 2.6692474e-08
Iter: 4589 loss: 2.66852975e-08
Iter: 4590 loss: 2.66472284e-08
Iter: 4591 loss: 2.66664095e-08
Iter: 4592 loss: 2.66255427e-08
Iter: 4593 loss: 2.65818851e-08
Iter: 4594 loss: 2.65595332e-08
Iter: 4595 loss: 2.65384958e-08
Iter: 4596 loss: 2.64837396e-08
Iter: 4597 loss: 2.69434643e-08
Iter: 4598 loss: 2.64780144e-08
Iter: 4599 loss: 2.64460045e-08
Iter: 4600 loss: 2.64438604e-08
Iter: 4601 loss: 2.64178741e-08
Iter: 4602 loss: 2.63948881e-08
Iter: 4603 loss: 2.63890101e-08
Iter: 4604 loss: 2.63440203e-08
Iter: 4605 loss: 2.62876814e-08
Iter: 4606 loss: 2.62861466e-08
Iter: 4607 loss: 2.62302748e-08
Iter: 4608 loss: 2.6312815e-08
Iter: 4609 loss: 2.62084363e-08
Iter: 4610 loss: 2.6170099e-08
Iter: 4611 loss: 2.61710333e-08
Iter: 4612 loss: 2.6133506e-08
Iter: 4613 loss: 2.61975703e-08
Iter: 4614 loss: 2.61217714e-08
Iter: 4615 loss: 2.60950639e-08
Iter: 4616 loss: 2.62087383e-08
Iter: 4617 loss: 2.60884185e-08
Iter: 4618 loss: 2.60447717e-08
Iter: 4619 loss: 2.61043596e-08
Iter: 4620 loss: 2.60333763e-08
Iter: 4621 loss: 2.60031801e-08
Iter: 4622 loss: 2.59892747e-08
Iter: 4623 loss: 2.5971703e-08
Iter: 4624 loss: 2.5912307e-08
Iter: 4625 loss: 2.59407145e-08
Iter: 4626 loss: 2.5870067e-08
Iter: 4627 loss: 2.57833417e-08
Iter: 4628 loss: 2.59003521e-08
Iter: 4629 loss: 2.5739066e-08
Iter: 4630 loss: 2.56977017e-08
Iter: 4631 loss: 2.56974051e-08
Iter: 4632 loss: 2.56453472e-08
Iter: 4633 loss: 2.58226542e-08
Iter: 4634 loss: 2.56263277e-08
Iter: 4635 loss: 2.56088679e-08
Iter: 4636 loss: 2.5717398e-08
Iter: 4637 loss: 2.56007411e-08
Iter: 4638 loss: 2.55723016e-08
Iter: 4639 loss: 2.55509534e-08
Iter: 4640 loss: 2.55416985e-08
Iter: 4641 loss: 2.55057202e-08
Iter: 4642 loss: 2.5501782e-08
Iter: 4643 loss: 2.54692978e-08
Iter: 4644 loss: 2.54204249e-08
Iter: 4645 loss: 2.59986841e-08
Iter: 4646 loss: 2.54195331e-08
Iter: 4647 loss: 2.53818015e-08
Iter: 4648 loss: 2.53847681e-08
Iter: 4649 loss: 2.53599239e-08
Iter: 4650 loss: 2.53218e-08
Iter: 4651 loss: 2.57185047e-08
Iter: 4652 loss: 2.53183075e-08
Iter: 4653 loss: 2.52947565e-08
Iter: 4654 loss: 2.52773482e-08
Iter: 4655 loss: 2.52616665e-08
Iter: 4656 loss: 2.52263739e-08
Iter: 4657 loss: 2.52559111e-08
Iter: 4658 loss: 2.52013184e-08
Iter: 4659 loss: 2.51563428e-08
Iter: 4660 loss: 2.51178367e-08
Iter: 4661 loss: 2.5105992e-08
Iter: 4662 loss: 2.50204799e-08
Iter: 4663 loss: 2.52403982e-08
Iter: 4664 loss: 2.50005172e-08
Iter: 4665 loss: 2.4984498e-08
Iter: 4666 loss: 2.49557637e-08
Iter: 4667 loss: 2.49261092e-08
Iter: 4668 loss: 2.48635157e-08
Iter: 4669 loss: 2.61226418e-08
Iter: 4670 loss: 2.48584371e-08
Iter: 4671 loss: 2.48271412e-08
Iter: 4672 loss: 2.48229117e-08
Iter: 4673 loss: 2.47963516e-08
Iter: 4674 loss: 2.47443701e-08
Iter: 4675 loss: 2.4744601e-08
Iter: 4676 loss: 2.47006575e-08
Iter: 4677 loss: 2.50798955e-08
Iter: 4678 loss: 2.47000536e-08
Iter: 4679 loss: 2.46471288e-08
Iter: 4680 loss: 2.48181529e-08
Iter: 4681 loss: 2.46401619e-08
Iter: 4682 loss: 2.46067557e-08
Iter: 4683 loss: 2.46205651e-08
Iter: 4684 loss: 2.45936729e-08
Iter: 4685 loss: 2.45593625e-08
Iter: 4686 loss: 2.4979407e-08
Iter: 4687 loss: 2.4559391e-08
Iter: 4688 loss: 2.45340779e-08
Iter: 4689 loss: 2.45055745e-08
Iter: 4690 loss: 2.45013432e-08
Iter: 4691 loss: 2.44693368e-08
Iter: 4692 loss: 2.45196787e-08
Iter: 4693 loss: 2.4456174e-08
Iter: 4694 loss: 2.44236595e-08
Iter: 4695 loss: 2.44985063e-08
Iter: 4696 loss: 2.44106602e-08
Iter: 4697 loss: 2.4380773e-08
Iter: 4698 loss: 2.47889069e-08
Iter: 4699 loss: 2.43804852e-08
Iter: 4700 loss: 2.43476528e-08
Iter: 4701 loss: 2.43415208e-08
Iter: 4702 loss: 2.4322226e-08
Iter: 4703 loss: 2.42879601e-08
Iter: 4704 loss: 2.42509461e-08
Iter: 4705 loss: 2.42471e-08
Iter: 4706 loss: 2.42011851e-08
Iter: 4707 loss: 2.41986839e-08
Iter: 4708 loss: 2.41727331e-08
Iter: 4709 loss: 2.41482621e-08
Iter: 4710 loss: 2.41404621e-08
Iter: 4711 loss: 2.41172877e-08
Iter: 4712 loss: 2.41144e-08
Iter: 4713 loss: 2.40956091e-08
Iter: 4714 loss: 2.41063987e-08
Iter: 4715 loss: 2.40809257e-08
Iter: 4716 loss: 2.40551685e-08
Iter: 4717 loss: 2.41650042e-08
Iter: 4718 loss: 2.40516282e-08
Iter: 4719 loss: 2.40216096e-08
Iter: 4720 loss: 2.40478482e-08
Iter: 4721 loss: 2.40094202e-08
Iter: 4722 loss: 2.39735964e-08
Iter: 4723 loss: 2.39992399e-08
Iter: 4724 loss: 2.39576963e-08
Iter: 4725 loss: 2.39207871e-08
Iter: 4726 loss: 2.39515394e-08
Iter: 4727 loss: 2.39026665e-08
Iter: 4728 loss: 2.38793483e-08
Iter: 4729 loss: 2.38748665e-08
Iter: 4730 loss: 2.3856348e-08
Iter: 4731 loss: 2.3891749e-08
Iter: 4732 loss: 2.38438567e-08
Iter: 4733 loss: 2.3824775e-08
Iter: 4734 loss: 2.38114417e-08
Iter: 4735 loss: 2.3803219e-08
Iter: 4736 loss: 2.37825475e-08
Iter: 4737 loss: 2.37808138e-08
Iter: 4738 loss: 2.37551454e-08
Iter: 4739 loss: 2.3713234e-08
Iter: 4740 loss: 2.37124098e-08
Iter: 4741 loss: 2.36783322e-08
Iter: 4742 loss: 2.39478357e-08
Iter: 4743 loss: 2.36765878e-08
Iter: 4744 loss: 2.36477469e-08
Iter: 4745 loss: 2.38750228e-08
Iter: 4746 loss: 2.36418334e-08
Iter: 4747 loss: 2.36275977e-08
Iter: 4748 loss: 2.36585507e-08
Iter: 4749 loss: 2.36203093e-08
Iter: 4750 loss: 2.35963036e-08
Iter: 4751 loss: 2.36335786e-08
Iter: 4752 loss: 2.35873063e-08
Iter: 4753 loss: 2.35615047e-08
Iter: 4754 loss: 2.35823752e-08
Iter: 4755 loss: 2.3556062e-08
Iter: 4756 loss: 2.35187549e-08
Iter: 4757 loss: 2.3502432e-08
Iter: 4758 loss: 2.34923085e-08
Iter: 4759 loss: 2.34582203e-08
Iter: 4760 loss: 2.34591813e-08
Iter: 4761 loss: 2.34332536e-08
Iter: 4762 loss: 2.36589628e-08
Iter: 4763 loss: 2.34307223e-08
Iter: 4764 loss: 2.34125164e-08
Iter: 4765 loss: 2.34011956e-08
Iter: 4766 loss: 2.3389422e-08
Iter: 4767 loss: 2.336626e-08
Iter: 4768 loss: 2.34534845e-08
Iter: 4769 loss: 2.33641941e-08
Iter: 4770 loss: 2.33351471e-08
Iter: 4771 loss: 2.34608386e-08
Iter: 4772 loss: 2.33217925e-08
Iter: 4773 loss: 2.3304997e-08
Iter: 4774 loss: 2.32779023e-08
Iter: 4775 loss: 2.32746764e-08
Iter: 4776 loss: 2.32546391e-08
Iter: 4777 loss: 2.32584902e-08
Iter: 4778 loss: 2.32389858e-08
Iter: 4779 loss: 2.32218653e-08
Iter: 4780 loss: 2.32193571e-08
Iter: 4781 loss: 2.31934703e-08
Iter: 4782 loss: 2.34389841e-08
Iter: 4783 loss: 2.31912054e-08
Iter: 4784 loss: 2.31575825e-08
Iter: 4785 loss: 2.3155053e-08
Iter: 4786 loss: 2.31351933e-08
Iter: 4787 loss: 2.31028157e-08
Iter: 4788 loss: 2.31500898e-08
Iter: 4789 loss: 2.30864394e-08
Iter: 4790 loss: 2.30544437e-08
Iter: 4791 loss: 2.30301982e-08
Iter: 4792 loss: 2.30134489e-08
Iter: 4793 loss: 2.29680293e-08
Iter: 4794 loss: 2.33691129e-08
Iter: 4795 loss: 2.29704273e-08
Iter: 4796 loss: 2.29251356e-08
Iter: 4797 loss: 2.32108235e-08
Iter: 4798 loss: 2.29200161e-08
Iter: 4799 loss: 2.29007107e-08
Iter: 4800 loss: 2.2906228e-08
Iter: 4801 loss: 2.28898411e-08
Iter: 4802 loss: 2.2855378e-08
Iter: 4803 loss: 2.28941701e-08
Iter: 4804 loss: 2.28417267e-08
Iter: 4805 loss: 2.28122232e-08
Iter: 4806 loss: 2.28734827e-08
Iter: 4807 loss: 2.28061463e-08
Iter: 4808 loss: 2.27876527e-08
Iter: 4809 loss: 2.28667076e-08
Iter: 4810 loss: 2.2783e-08
Iter: 4811 loss: 2.27585026e-08
Iter: 4812 loss: 2.28371935e-08
Iter: 4813 loss: 2.27491199e-08
Iter: 4814 loss: 2.27326922e-08
Iter: 4815 loss: 2.27497914e-08
Iter: 4816 loss: 2.27233983e-08
Iter: 4817 loss: 2.27042865e-08
Iter: 4818 loss: 2.28462405e-08
Iter: 4819 loss: 2.27016645e-08
Iter: 4820 loss: 2.26878019e-08
Iter: 4821 loss: 2.26644197e-08
Iter: 4822 loss: 2.26636185e-08
Iter: 4823 loss: 2.26314363e-08
Iter: 4824 loss: 2.27115e-08
Iter: 4825 loss: 2.26235812e-08
Iter: 4826 loss: 2.25920758e-08
Iter: 4827 loss: 2.26428849e-08
Iter: 4828 loss: 2.25793553e-08
Iter: 4829 loss: 2.25539125e-08
Iter: 4830 loss: 2.2604624e-08
Iter: 4831 loss: 2.25428032e-08
Iter: 4832 loss: 2.25327348e-08
Iter: 4833 loss: 2.25242722e-08
Iter: 4834 loss: 2.25189645e-08
Iter: 4835 loss: 2.24980106e-08
Iter: 4836 loss: 2.27694912e-08
Iter: 4837 loss: 2.2498174e-08
Iter: 4838 loss: 2.247738e-08
Iter: 4839 loss: 2.25760317e-08
Iter: 4840 loss: 2.24774688e-08
Iter: 4841 loss: 2.24603465e-08
Iter: 4842 loss: 2.24807621e-08
Iter: 4843 loss: 2.24554721e-08
Iter: 4844 loss: 2.24341097e-08
Iter: 4845 loss: 2.25299566e-08
Iter: 4846 loss: 2.24286332e-08
Iter: 4847 loss: 2.24115624e-08
Iter: 4848 loss: 2.24206342e-08
Iter: 4849 loss: 2.23959447e-08
Iter: 4850 loss: 2.238124e-08
Iter: 4851 loss: 2.25800019e-08
Iter: 4852 loss: 2.23822809e-08
Iter: 4853 loss: 2.23598526e-08
Iter: 4854 loss: 2.23645831e-08
Iter: 4855 loss: 2.23429915e-08
Iter: 4856 loss: 2.23261427e-08
Iter: 4857 loss: 2.23172449e-08
Iter: 4858 loss: 2.23122925e-08
Iter: 4859 loss: 2.22846896e-08
Iter: 4860 loss: 2.24416308e-08
Iter: 4861 loss: 2.22847873e-08
Iter: 4862 loss: 2.22625864e-08
Iter: 4863 loss: 2.23097967e-08
Iter: 4864 loss: 2.22481678e-08
Iter: 4865 loss: 2.22338929e-08
Iter: 4866 loss: 2.23703e-08
Iter: 4867 loss: 2.22334045e-08
Iter: 4868 loss: 2.22121717e-08
Iter: 4869 loss: 2.233784e-08
Iter: 4870 loss: 2.22080772e-08
Iter: 4871 loss: 2.22009291e-08
Iter: 4872 loss: 2.21951773e-08
Iter: 4873 loss: 2.21930723e-08
Iter: 4874 loss: 2.21686864e-08
Iter: 4875 loss: 2.21895e-08
Iter: 4876 loss: 2.2156879e-08
Iter: 4877 loss: 2.21453114e-08
Iter: 4878 loss: 2.22069971e-08
Iter: 4879 loss: 2.21396022e-08
Iter: 4880 loss: 2.21223875e-08
Iter: 4881 loss: 2.22026877e-08
Iter: 4882 loss: 2.21145839e-08
Iter: 4883 loss: 2.21041301e-08
Iter: 4884 loss: 2.20964012e-08
Iter: 4885 loss: 2.20996199e-08
Iter: 4886 loss: 2.20805454e-08
Iter: 4887 loss: 2.21583161e-08
Iter: 4888 loss: 2.20796625e-08
Iter: 4889 loss: 2.20619363e-08
Iter: 4890 loss: 2.20991971e-08
Iter: 4891 loss: 2.2053861e-08
Iter: 4892 loss: 2.20349037e-08
Iter: 4893 loss: 2.20150511e-08
Iter: 4894 loss: 2.20106493e-08
Iter: 4895 loss: 2.19846861e-08
Iter: 4896 loss: 2.20212968e-08
Iter: 4897 loss: 2.19662155e-08
Iter: 4898 loss: 2.19345822e-08
Iter: 4899 loss: 2.21957563e-08
Iter: 4900 loss: 2.19364882e-08
Iter: 4901 loss: 2.19172165e-08
Iter: 4902 loss: 2.20556942e-08
Iter: 4903 loss: 2.19116956e-08
Iter: 4904 loss: 2.18966782e-08
Iter: 4905 loss: 2.20463949e-08
Iter: 4906 loss: 2.18999432e-08
Iter: 4907 loss: 2.1886672e-08
Iter: 4908 loss: 2.18568292e-08
Iter: 4909 loss: 2.2039071e-08
Iter: 4910 loss: 2.18492673e-08
Iter: 4911 loss: 2.18170175e-08
Iter: 4912 loss: 2.1946164e-08
Iter: 4913 loss: 2.18087663e-08
Iter: 4914 loss: 2.17929053e-08
Iter: 4915 loss: 2.17918199e-08
Iter: 4916 loss: 2.17731504e-08
Iter: 4917 loss: 2.17352749e-08
Iter: 4918 loss: 2.23119851e-08
Iter: 4919 loss: 2.17344471e-08
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_4000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_4000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_4000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 400013 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi1_phi0/300_300_300_1 --optimizer lbfgs --function f1 --psi 1 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_4000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf11f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf1e6c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf1e6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf178f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf178268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf105f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf105e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf105730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf0a3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf05f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf03a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf053bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf05f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebefabbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebefab1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebefd6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebefabd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebf05f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebef506a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebef508c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebef14268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebeecd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebee74598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebee8ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebee8f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebee45ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebee45950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebee45598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebee162f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebee456a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebee16ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebed70a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebed70950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebecf96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebecf9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5ebeca4158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.4774788e-06
Iter: 2 loss: 3.73378907e-06
Iter: 3 loss: 3.7159266e-06
Iter: 4 loss: 3.41461578e-06
Iter: 5 loss: 4.53727034e-06
Iter: 6 loss: 3.34132437e-06
Iter: 7 loss: 3.16286287e-06
Iter: 8 loss: 3.21895664e-06
Iter: 9 loss: 3.03556317e-06
Iter: 10 loss: 2.96265443e-06
Iter: 11 loss: 2.93409516e-06
Iter: 12 loss: 2.88282558e-06
Iter: 13 loss: 2.80476979e-06
Iter: 14 loss: 2.80336576e-06
Iter: 15 loss: 2.76551145e-06
Iter: 16 loss: 3.1603613e-06
Iter: 17 loss: 2.764491e-06
Iter: 18 loss: 2.71121257e-06
Iter: 19 loss: 2.58513728e-06
Iter: 20 loss: 4.04260754e-06
Iter: 21 loss: 2.57357237e-06
Iter: 22 loss: 2.47583262e-06
Iter: 23 loss: 2.91023071e-06
Iter: 24 loss: 2.45658293e-06
Iter: 25 loss: 2.44012472e-06
Iter: 26 loss: 2.41526345e-06
Iter: 27 loss: 2.39963083e-06
Iter: 28 loss: 2.36658798e-06
Iter: 29 loss: 2.90471098e-06
Iter: 30 loss: 2.36559345e-06
Iter: 31 loss: 2.34149934e-06
Iter: 32 loss: 2.33107312e-06
Iter: 33 loss: 2.31874355e-06
Iter: 34 loss: 2.29808165e-06
Iter: 35 loss: 2.46226273e-06
Iter: 36 loss: 2.2966974e-06
Iter: 37 loss: 2.27042665e-06
Iter: 38 loss: 2.23712823e-06
Iter: 39 loss: 2.2346012e-06
Iter: 40 loss: 2.17906631e-06
Iter: 41 loss: 2.37750828e-06
Iter: 42 loss: 2.16484773e-06
Iter: 43 loss: 2.11748693e-06
Iter: 44 loss: 2.46373838e-06
Iter: 45 loss: 2.11357428e-06
Iter: 46 loss: 2.07181233e-06
Iter: 47 loss: 2.26907605e-06
Iter: 48 loss: 2.0641794e-06
Iter: 49 loss: 2.04604407e-06
Iter: 50 loss: 2.01504145e-06
Iter: 51 loss: 2.01500052e-06
Iter: 52 loss: 2.01006287e-06
Iter: 53 loss: 1.9991362e-06
Iter: 54 loss: 1.9886902e-06
Iter: 55 loss: 1.96083442e-06
Iter: 56 loss: 2.1580322e-06
Iter: 57 loss: 1.95469329e-06
Iter: 58 loss: 1.93183541e-06
Iter: 59 loss: 2.13363091e-06
Iter: 60 loss: 1.93068968e-06
Iter: 61 loss: 1.89923207e-06
Iter: 62 loss: 1.91728486e-06
Iter: 63 loss: 1.87873729e-06
Iter: 64 loss: 1.85048452e-06
Iter: 65 loss: 1.81616042e-06
Iter: 66 loss: 1.81289852e-06
Iter: 67 loss: 1.78354935e-06
Iter: 68 loss: 2.16127773e-06
Iter: 69 loss: 1.78329947e-06
Iter: 70 loss: 1.76651508e-06
Iter: 71 loss: 1.76620779e-06
Iter: 72 loss: 1.75686694e-06
Iter: 73 loss: 1.74092554e-06
Iter: 74 loss: 1.74090292e-06
Iter: 75 loss: 1.72246064e-06
Iter: 76 loss: 1.89309412e-06
Iter: 77 loss: 1.72168598e-06
Iter: 78 loss: 1.70854048e-06
Iter: 79 loss: 1.83410134e-06
Iter: 80 loss: 1.70803617e-06
Iter: 81 loss: 1.69814246e-06
Iter: 82 loss: 1.67402959e-06
Iter: 83 loss: 1.93040182e-06
Iter: 84 loss: 1.67140888e-06
Iter: 85 loss: 1.6526609e-06
Iter: 86 loss: 1.9465142e-06
Iter: 87 loss: 1.65265953e-06
Iter: 88 loss: 1.63374909e-06
Iter: 89 loss: 1.67390306e-06
Iter: 90 loss: 1.6262187e-06
Iter: 91 loss: 1.61861624e-06
Iter: 92 loss: 1.60222089e-06
Iter: 93 loss: 1.8587582e-06
Iter: 94 loss: 1.60166087e-06
Iter: 95 loss: 1.59529213e-06
Iter: 96 loss: 1.59013575e-06
Iter: 97 loss: 1.58272576e-06
Iter: 98 loss: 1.56369413e-06
Iter: 99 loss: 1.72574664e-06
Iter: 100 loss: 1.56051112e-06
Iter: 101 loss: 1.53895621e-06
Iter: 102 loss: 1.55683392e-06
Iter: 103 loss: 1.52604241e-06
Iter: 104 loss: 1.5350812e-06
Iter: 105 loss: 1.51756547e-06
Iter: 106 loss: 1.51095844e-06
Iter: 107 loss: 1.50551114e-06
Iter: 108 loss: 1.5035605e-06
Iter: 109 loss: 1.49689959e-06
Iter: 110 loss: 1.54191696e-06
Iter: 111 loss: 1.49621837e-06
Iter: 112 loss: 1.49115704e-06
Iter: 113 loss: 1.54934219e-06
Iter: 114 loss: 1.491072e-06
Iter: 115 loss: 1.48667141e-06
Iter: 116 loss: 1.48082813e-06
Iter: 117 loss: 1.48050412e-06
Iter: 118 loss: 1.47245873e-06
Iter: 119 loss: 1.46371417e-06
Iter: 120 loss: 1.46244815e-06
Iter: 121 loss: 1.45214869e-06
Iter: 122 loss: 1.45132708e-06
Iter: 123 loss: 1.4470271e-06
Iter: 124 loss: 1.43584771e-06
Iter: 125 loss: 1.52533505e-06
Iter: 126 loss: 1.43382715e-06
Iter: 127 loss: 1.42990075e-06
Iter: 128 loss: 1.42800081e-06
Iter: 129 loss: 1.42195734e-06
Iter: 130 loss: 1.4227146e-06
Iter: 131 loss: 1.4173371e-06
Iter: 132 loss: 1.41300609e-06
Iter: 133 loss: 1.40401062e-06
Iter: 134 loss: 1.56110389e-06
Iter: 135 loss: 1.40384259e-06
Iter: 136 loss: 1.39299664e-06
Iter: 137 loss: 1.4664962e-06
Iter: 138 loss: 1.39195527e-06
Iter: 139 loss: 1.38069743e-06
Iter: 140 loss: 1.4997197e-06
Iter: 141 loss: 1.38042333e-06
Iter: 142 loss: 1.37599238e-06
Iter: 143 loss: 1.37081872e-06
Iter: 144 loss: 1.37023574e-06
Iter: 145 loss: 1.36532287e-06
Iter: 146 loss: 1.36514927e-06
Iter: 147 loss: 1.36109577e-06
Iter: 148 loss: 1.36662834e-06
Iter: 149 loss: 1.35907135e-06
Iter: 150 loss: 1.35540984e-06
Iter: 151 loss: 1.35170353e-06
Iter: 152 loss: 1.35100686e-06
Iter: 153 loss: 1.34799893e-06
Iter: 154 loss: 1.34780043e-06
Iter: 155 loss: 1.34428296e-06
Iter: 156 loss: 1.33551885e-06
Iter: 157 loss: 1.41350961e-06
Iter: 158 loss: 1.33415733e-06
Iter: 159 loss: 1.32567777e-06
Iter: 160 loss: 1.35436301e-06
Iter: 161 loss: 1.3234071e-06
Iter: 162 loss: 1.31786669e-06
Iter: 163 loss: 1.31737352e-06
Iter: 164 loss: 1.3150277e-06
Iter: 165 loss: 1.30973604e-06
Iter: 166 loss: 1.37593315e-06
Iter: 167 loss: 1.30931926e-06
Iter: 168 loss: 1.30402259e-06
Iter: 169 loss: 1.30863782e-06
Iter: 170 loss: 1.30087733e-06
Iter: 171 loss: 1.30165677e-06
Iter: 172 loss: 1.29826469e-06
Iter: 173 loss: 1.29608634e-06
Iter: 174 loss: 1.29005923e-06
Iter: 175 loss: 1.32039168e-06
Iter: 176 loss: 1.28806755e-06
Iter: 177 loss: 1.2810417e-06
Iter: 178 loss: 1.39092185e-06
Iter: 179 loss: 1.28107308e-06
Iter: 180 loss: 1.27442604e-06
Iter: 181 loss: 1.29476916e-06
Iter: 182 loss: 1.27247813e-06
Iter: 183 loss: 1.26779992e-06
Iter: 184 loss: 1.27165413e-06
Iter: 185 loss: 1.26495706e-06
Iter: 186 loss: 1.2618392e-06
Iter: 187 loss: 1.27855867e-06
Iter: 188 loss: 1.26137729e-06
Iter: 189 loss: 1.25733754e-06
Iter: 190 loss: 1.26194141e-06
Iter: 191 loss: 1.25520603e-06
Iter: 192 loss: 1.25274187e-06
Iter: 193 loss: 1.24965072e-06
Iter: 194 loss: 1.24945132e-06
Iter: 195 loss: 1.24752739e-06
Iter: 196 loss: 1.24687767e-06
Iter: 197 loss: 1.24439748e-06
Iter: 198 loss: 1.23705559e-06
Iter: 199 loss: 1.25995416e-06
Iter: 200 loss: 1.23340681e-06
Iter: 201 loss: 1.2239957e-06
Iter: 202 loss: 1.26281407e-06
Iter: 203 loss: 1.22193023e-06
Iter: 204 loss: 1.22183405e-06
Iter: 205 loss: 1.21956259e-06
Iter: 206 loss: 1.21709218e-06
Iter: 207 loss: 1.21464916e-06
Iter: 208 loss: 1.21412427e-06
Iter: 209 loss: 1.21172445e-06
Iter: 210 loss: 1.22845893e-06
Iter: 211 loss: 1.21149822e-06
Iter: 212 loss: 1.20915672e-06
Iter: 213 loss: 1.22137158e-06
Iter: 214 loss: 1.20878622e-06
Iter: 215 loss: 1.20701134e-06
Iter: 216 loss: 1.2058714e-06
Iter: 217 loss: 1.20517916e-06
Iter: 218 loss: 1.20219761e-06
Iter: 219 loss: 1.20170353e-06
Iter: 220 loss: 1.19966035e-06
Iter: 221 loss: 1.19537629e-06
Iter: 222 loss: 1.25637143e-06
Iter: 223 loss: 1.19534457e-06
Iter: 224 loss: 1.19349193e-06
Iter: 225 loss: 1.189454e-06
Iter: 226 loss: 1.25096926e-06
Iter: 227 loss: 1.18930257e-06
Iter: 228 loss: 1.18854803e-06
Iter: 229 loss: 1.18780076e-06
Iter: 230 loss: 1.18610137e-06
Iter: 231 loss: 1.18340233e-06
Iter: 232 loss: 1.18337744e-06
Iter: 233 loss: 1.18074377e-06
Iter: 234 loss: 1.17916341e-06
Iter: 235 loss: 1.17804097e-06
Iter: 236 loss: 1.17464788e-06
Iter: 237 loss: 1.19807191e-06
Iter: 238 loss: 1.17430773e-06
Iter: 239 loss: 1.16991589e-06
Iter: 240 loss: 1.18713319e-06
Iter: 241 loss: 1.16885872e-06
Iter: 242 loss: 1.16682713e-06
Iter: 243 loss: 1.16869387e-06
Iter: 244 loss: 1.16566093e-06
Iter: 245 loss: 1.16344768e-06
Iter: 246 loss: 1.19266292e-06
Iter: 247 loss: 1.16343313e-06
Iter: 248 loss: 1.16202852e-06
Iter: 249 loss: 1.16092542e-06
Iter: 250 loss: 1.16048113e-06
Iter: 251 loss: 1.15827675e-06
Iter: 252 loss: 1.16044123e-06
Iter: 253 loss: 1.15702073e-06
Iter: 254 loss: 1.15535829e-06
Iter: 255 loss: 1.15528928e-06
Iter: 256 loss: 1.15397825e-06
Iter: 257 loss: 1.15023249e-06
Iter: 258 loss: 1.16836009e-06
Iter: 259 loss: 1.14898853e-06
Iter: 260 loss: 1.14540853e-06
Iter: 261 loss: 1.18456353e-06
Iter: 262 loss: 1.14532145e-06
Iter: 263 loss: 1.14128579e-06
Iter: 264 loss: 1.15749242e-06
Iter: 265 loss: 1.14039324e-06
Iter: 266 loss: 1.13865951e-06
Iter: 267 loss: 1.13656483e-06
Iter: 268 loss: 1.13636e-06
Iter: 269 loss: 1.13420447e-06
Iter: 270 loss: 1.14165789e-06
Iter: 271 loss: 1.13358647e-06
Iter: 272 loss: 1.13159319e-06
Iter: 273 loss: 1.13159e-06
Iter: 274 loss: 1.13052567e-06
Iter: 275 loss: 1.12884493e-06
Iter: 276 loss: 1.12882913e-06
Iter: 277 loss: 1.12709279e-06
Iter: 278 loss: 1.1270497e-06
Iter: 279 loss: 1.12571911e-06
Iter: 280 loss: 1.12374528e-06
Iter: 281 loss: 1.12370549e-06
Iter: 282 loss: 1.1209529e-06
Iter: 283 loss: 1.1261227e-06
Iter: 284 loss: 1.11973281e-06
Iter: 285 loss: 1.1185133e-06
Iter: 286 loss: 1.1183223e-06
Iter: 287 loss: 1.1172e-06
Iter: 288 loss: 1.11511019e-06
Iter: 289 loss: 1.16334274e-06
Iter: 290 loss: 1.11508643e-06
Iter: 291 loss: 1.11337249e-06
Iter: 292 loss: 1.11443478e-06
Iter: 293 loss: 1.11227985e-06
Iter: 294 loss: 1.11024883e-06
Iter: 295 loss: 1.11022246e-06
Iter: 296 loss: 1.1093083e-06
Iter: 297 loss: 1.10679491e-06
Iter: 298 loss: 1.12289365e-06
Iter: 299 loss: 1.10616747e-06
Iter: 300 loss: 1.10292513e-06
Iter: 301 loss: 1.11151621e-06
Iter: 302 loss: 1.10183555e-06
Iter: 303 loss: 1.10158101e-06
Iter: 304 loss: 1.10035137e-06
Iter: 305 loss: 1.09946018e-06
Iter: 306 loss: 1.09769871e-06
Iter: 307 loss: 1.133301e-06
Iter: 308 loss: 1.0976695e-06
Iter: 309 loss: 1.09689063e-06
Iter: 310 loss: 1.09666144e-06
Iter: 311 loss: 1.0958247e-06
Iter: 312 loss: 1.09466339e-06
Iter: 313 loss: 1.0946444e-06
Iter: 314 loss: 1.09298264e-06
Iter: 315 loss: 1.0945173e-06
Iter: 316 loss: 1.09199368e-06
Iter: 317 loss: 1.09050927e-06
Iter: 318 loss: 1.1087343e-06
Iter: 319 loss: 1.09048221e-06
Iter: 320 loss: 1.08891629e-06
Iter: 321 loss: 1.08793324e-06
Iter: 322 loss: 1.08732183e-06
Iter: 323 loss: 1.08564768e-06
Iter: 324 loss: 1.08345898e-06
Iter: 325 loss: 1.0833138e-06
Iter: 326 loss: 1.08422273e-06
Iter: 327 loss: 1.08207837e-06
Iter: 328 loss: 1.08150675e-06
Iter: 329 loss: 1.07989456e-06
Iter: 330 loss: 1.09109601e-06
Iter: 331 loss: 1.07954077e-06
Iter: 332 loss: 1.07765572e-06
Iter: 333 loss: 1.07937967e-06
Iter: 334 loss: 1.07655069e-06
Iter: 335 loss: 1.07600818e-06
Iter: 336 loss: 1.07543565e-06
Iter: 337 loss: 1.074495e-06
Iter: 338 loss: 1.0723511e-06
Iter: 339 loss: 1.10298799e-06
Iter: 340 loss: 1.07223786e-06
Iter: 341 loss: 1.07132405e-06
Iter: 342 loss: 1.07098515e-06
Iter: 343 loss: 1.06999573e-06
Iter: 344 loss: 1.06923358e-06
Iter: 345 loss: 1.068958e-06
Iter: 346 loss: 1.0675036e-06
Iter: 347 loss: 1.06994821e-06
Iter: 348 loss: 1.06685115e-06
Iter: 349 loss: 1.06588959e-06
Iter: 350 loss: 1.07834103e-06
Iter: 351 loss: 1.06588573e-06
Iter: 352 loss: 1.06492e-06
Iter: 353 loss: 1.06534026e-06
Iter: 354 loss: 1.06420043e-06
Iter: 355 loss: 1.06315588e-06
Iter: 356 loss: 1.06073765e-06
Iter: 357 loss: 1.09371013e-06
Iter: 358 loss: 1.06060747e-06
Iter: 359 loss: 1.06087305e-06
Iter: 360 loss: 1.05947834e-06
Iter: 361 loss: 1.05841821e-06
Iter: 362 loss: 1.05566824e-06
Iter: 363 loss: 1.07827043e-06
Iter: 364 loss: 1.05516563e-06
Iter: 365 loss: 1.05273443e-06
Iter: 366 loss: 1.0625738e-06
Iter: 367 loss: 1.05218305e-06
Iter: 368 loss: 1.05163713e-06
Iter: 369 loss: 1.05136417e-06
Iter: 370 loss: 1.05060224e-06
Iter: 371 loss: 1.04964215e-06
Iter: 372 loss: 1.04952358e-06
Iter: 373 loss: 1.04890637e-06
Iter: 374 loss: 1.04888943e-06
Iter: 375 loss: 1.04824255e-06
Iter: 376 loss: 1.04693868e-06
Iter: 377 loss: 1.07211338e-06
Iter: 378 loss: 1.04697824e-06
Iter: 379 loss: 1.04507785e-06
Iter: 380 loss: 1.04679236e-06
Iter: 381 loss: 1.04399226e-06
Iter: 382 loss: 1.04232652e-06
Iter: 383 loss: 1.05189554e-06
Iter: 384 loss: 1.04208948e-06
Iter: 385 loss: 1.04008041e-06
Iter: 386 loss: 1.0452552e-06
Iter: 387 loss: 1.03940772e-06
Iter: 388 loss: 1.03791876e-06
Iter: 389 loss: 1.03566344e-06
Iter: 390 loss: 1.03561479e-06
Iter: 391 loss: 1.03571278e-06
Iter: 392 loss: 1.03482398e-06
Iter: 393 loss: 1.03400237e-06
Iter: 394 loss: 1.03231491e-06
Iter: 395 loss: 1.05960612e-06
Iter: 396 loss: 1.03226762e-06
Iter: 397 loss: 1.03069226e-06
Iter: 398 loss: 1.03242655e-06
Iter: 399 loss: 1.02985086e-06
Iter: 400 loss: 1.02878801e-06
Iter: 401 loss: 1.0287406e-06
Iter: 402 loss: 1.02756462e-06
Iter: 403 loss: 1.0268235e-06
Iter: 404 loss: 1.02637136e-06
Iter: 405 loss: 1.0254123e-06
Iter: 406 loss: 1.03837351e-06
Iter: 407 loss: 1.02541173e-06
Iter: 408 loss: 1.02438344e-06
Iter: 409 loss: 1.02434296e-06
Iter: 410 loss: 1.02351305e-06
Iter: 411 loss: 1.02248748e-06
Iter: 412 loss: 1.0245933e-06
Iter: 413 loss: 1.02206729e-06
Iter: 414 loss: 1.02115928e-06
Iter: 415 loss: 1.02367142e-06
Iter: 416 loss: 1.02086756e-06
Iter: 417 loss: 1.01979742e-06
Iter: 418 loss: 1.02660226e-06
Iter: 419 loss: 1.01968044e-06
Iter: 420 loss: 1.01896717e-06
Iter: 421 loss: 1.01738704e-06
Iter: 422 loss: 1.04004096e-06
Iter: 423 loss: 1.01729779e-06
Iter: 424 loss: 1.01668911e-06
Iter: 425 loss: 1.01645503e-06
Iter: 426 loss: 1.01557202e-06
Iter: 427 loss: 1.01440696e-06
Iter: 428 loss: 1.01431544e-06
Iter: 429 loss: 1.01315788e-06
Iter: 430 loss: 1.01365595e-06
Iter: 431 loss: 1.01237231e-06
Iter: 432 loss: 1.0116928e-06
Iter: 433 loss: 1.0116039e-06
Iter: 434 loss: 1.01084686e-06
Iter: 435 loss: 1.01105138e-06
Iter: 436 loss: 1.01028957e-06
Iter: 437 loss: 1.00956015e-06
Iter: 438 loss: 1.00993509e-06
Iter: 439 loss: 1.0090431e-06
Iter: 440 loss: 1.00754687e-06
Iter: 441 loss: 1.01033152e-06
Iter: 442 loss: 1.0069034e-06
Iter: 443 loss: 1.00592047e-06
Iter: 444 loss: 1.00603052e-06
Iter: 445 loss: 1.00518832e-06
Iter: 446 loss: 1.00367777e-06
Iter: 447 loss: 1.00568502e-06
Iter: 448 loss: 1.00294e-06
Iter: 449 loss: 1.00139425e-06
Iter: 450 loss: 1.00140824e-06
Iter: 451 loss: 1.00055149e-06
Iter: 452 loss: 9.99052872e-07
Iter: 453 loss: 1.03371724e-06
Iter: 454 loss: 9.99021267e-07
Iter: 455 loss: 9.98005362e-07
Iter: 456 loss: 1.00980299e-06
Iter: 457 loss: 9.97969892e-07
Iter: 458 loss: 9.96769472e-07
Iter: 459 loss: 9.98878591e-07
Iter: 460 loss: 9.96224799e-07
Iter: 461 loss: 9.95431833e-07
Iter: 462 loss: 9.93882168e-07
Iter: 463 loss: 1.02634954e-06
Iter: 464 loss: 9.93895469e-07
Iter: 465 loss: 9.92723471e-07
Iter: 466 loss: 9.92686182e-07
Iter: 467 loss: 9.91509637e-07
Iter: 468 loss: 9.94448556e-07
Iter: 469 loss: 9.91052275e-07
Iter: 470 loss: 9.90236686e-07
Iter: 471 loss: 9.89979e-07
Iter: 472 loss: 9.89520345e-07
Iter: 473 loss: 9.88151896e-07
Iter: 474 loss: 1.00544787e-06
Iter: 475 loss: 9.8815508e-07
Iter: 476 loss: 9.87665771e-07
Iter: 477 loss: 9.86964892e-07
Iter: 478 loss: 9.86939654e-07
Iter: 479 loss: 9.85974907e-07
Iter: 480 loss: 9.88094598e-07
Iter: 481 loss: 9.85609e-07
Iter: 482 loss: 9.84902726e-07
Iter: 483 loss: 9.8489727e-07
Iter: 484 loss: 9.8436476e-07
Iter: 485 loss: 9.83268933e-07
Iter: 486 loss: 1.00160287e-06
Iter: 487 loss: 9.83246878e-07
Iter: 488 loss: 9.82248821e-07
Iter: 489 loss: 9.85645329e-07
Iter: 490 loss: 9.82008146e-07
Iter: 491 loss: 9.80751793e-07
Iter: 492 loss: 9.90058e-07
Iter: 493 loss: 9.80658797e-07
Iter: 494 loss: 9.80054551e-07
Iter: 495 loss: 9.78791149e-07
Iter: 496 loss: 9.99818212e-07
Iter: 497 loss: 9.78746357e-07
Iter: 498 loss: 9.77847776e-07
Iter: 499 loss: 9.77858349e-07
Iter: 500 loss: 9.77052e-07
Iter: 501 loss: 9.81450626e-07
Iter: 502 loss: 9.76925094e-07
Iter: 503 loss: 9.76391334e-07
Iter: 504 loss: 9.75475587e-07
Iter: 505 loss: 9.754865e-07
Iter: 506 loss: 9.74834393e-07
Iter: 507 loss: 9.74672275e-07
Iter: 508 loss: 9.7431041e-07
Iter: 509 loss: 9.7343e-07
Iter: 510 loss: 9.8214332e-07
Iter: 511 loss: 9.73307579e-07
Iter: 512 loss: 9.72147291e-07
Iter: 513 loss: 9.76785941e-07
Iter: 514 loss: 9.71891e-07
Iter: 515 loss: 9.71130135e-07
Iter: 516 loss: 9.71113e-07
Iter: 517 loss: 9.7049724e-07
Iter: 518 loss: 9.69736902e-07
Iter: 519 loss: 9.69632083e-07
Iter: 520 loss: 9.68842642e-07
Iter: 521 loss: 9.69493385e-07
Iter: 522 loss: 9.68396648e-07
Iter: 523 loss: 9.67708615e-07
Iter: 524 loss: 9.67633e-07
Iter: 525 loss: 9.67275128e-07
Iter: 526 loss: 9.66235575e-07
Iter: 527 loss: 9.72796443e-07
Iter: 528 loss: 9.65988761e-07
Iter: 529 loss: 9.64877927e-07
Iter: 530 loss: 9.77670879e-07
Iter: 531 loss: 9.64850528e-07
Iter: 532 loss: 9.63932507e-07
Iter: 533 loss: 9.76657702e-07
Iter: 534 loss: 9.63933758e-07
Iter: 535 loss: 9.63406819e-07
Iter: 536 loss: 9.61976298e-07
Iter: 537 loss: 9.7190275e-07
Iter: 538 loss: 9.61675596e-07
Iter: 539 loss: 9.62345212e-07
Iter: 540 loss: 9.6097142e-07
Iter: 541 loss: 9.60578177e-07
Iter: 542 loss: 9.59700287e-07
Iter: 543 loss: 9.6911424e-07
Iter: 544 loss: 9.59615136e-07
Iter: 545 loss: 9.58595365e-07
Iter: 546 loss: 9.63314e-07
Iter: 547 loss: 9.58402893e-07
Iter: 548 loss: 9.57753173e-07
Iter: 549 loss: 9.65802201e-07
Iter: 550 loss: 9.57776251e-07
Iter: 551 loss: 9.57137445e-07
Iter: 552 loss: 9.57078441e-07
Iter: 553 loss: 9.56605845e-07
Iter: 554 loss: 9.55911e-07
Iter: 555 loss: 9.55069709e-07
Iter: 556 loss: 9.54996722e-07
Iter: 557 loss: 9.54543339e-07
Iter: 558 loss: 9.54310735e-07
Iter: 559 loss: 9.53868835e-07
Iter: 560 loss: 9.52778237e-07
Iter: 561 loss: 9.61744e-07
Iter: 562 loss: 9.52586447e-07
Iter: 563 loss: 9.51571e-07
Iter: 564 loss: 9.60977786e-07
Iter: 565 loss: 9.51556615e-07
Iter: 566 loss: 9.5106509e-07
Iter: 567 loss: 9.51076117e-07
Iter: 568 loss: 9.50738809e-07
Iter: 569 loss: 9.49879563e-07
Iter: 570 loss: 9.57731572e-07
Iter: 571 loss: 9.49776791e-07
Iter: 572 loss: 9.50106e-07
Iter: 573 loss: 9.49447497e-07
Iter: 574 loss: 9.4918e-07
Iter: 575 loss: 9.48495881e-07
Iter: 576 loss: 9.53781e-07
Iter: 577 loss: 9.48346e-07
Iter: 578 loss: 9.47523404e-07
Iter: 579 loss: 9.50212552e-07
Iter: 580 loss: 9.47262777e-07
Iter: 581 loss: 9.4653393e-07
Iter: 582 loss: 9.53750487e-07
Iter: 583 loss: 9.46510227e-07
Iter: 584 loss: 9.45722832e-07
Iter: 585 loss: 9.46393754e-07
Iter: 586 loss: 9.45253532e-07
Iter: 587 loss: 9.44611429e-07
Iter: 588 loss: 9.44221142e-07
Iter: 589 loss: 9.44000931e-07
Iter: 590 loss: 9.43918849e-07
Iter: 591 loss: 9.43621728e-07
Iter: 592 loss: 9.43312443e-07
Iter: 593 loss: 9.42643737e-07
Iter: 594 loss: 9.51715492e-07
Iter: 595 loss: 9.42585132e-07
Iter: 596 loss: 9.41972644e-07
Iter: 597 loss: 9.45430827e-07
Iter: 598 loss: 9.41878454e-07
Iter: 599 loss: 9.41475548e-07
Iter: 600 loss: 9.41488906e-07
Iter: 601 loss: 9.41126132e-07
Iter: 602 loss: 9.40145469e-07
Iter: 603 loss: 9.46564512e-07
Iter: 604 loss: 9.39899905e-07
Iter: 605 loss: 9.39775703e-07
Iter: 606 loss: 9.39426e-07
Iter: 607 loss: 9.38896619e-07
Iter: 608 loss: 9.38079097e-07
Iter: 609 loss: 9.38052494e-07
Iter: 610 loss: 9.3727482e-07
Iter: 611 loss: 9.37727918e-07
Iter: 612 loss: 9.36793185e-07
Iter: 613 loss: 9.35965772e-07
Iter: 614 loss: 9.47597641e-07
Iter: 615 loss: 9.35963953e-07
Iter: 616 loss: 9.35320827e-07
Iter: 617 loss: 9.38198241e-07
Iter: 618 loss: 9.35182698e-07
Iter: 619 loss: 9.34783088e-07
Iter: 620 loss: 9.33832098e-07
Iter: 621 loss: 9.48810566e-07
Iter: 622 loss: 9.33765705e-07
Iter: 623 loss: 9.33402589e-07
Iter: 624 loss: 9.33277647e-07
Iter: 625 loss: 9.32700289e-07
Iter: 626 loss: 9.31755949e-07
Iter: 627 loss: 9.31745205e-07
Iter: 628 loss: 9.30880049e-07
Iter: 629 loss: 9.33284809e-07
Iter: 630 loss: 9.3059316e-07
Iter: 631 loss: 9.30137446e-07
Iter: 632 loss: 9.30120905e-07
Iter: 633 loss: 9.29657062e-07
Iter: 634 loss: 9.28902864e-07
Iter: 635 loss: 9.28907411e-07
Iter: 636 loss: 9.2843004e-07
Iter: 637 loss: 9.34372679e-07
Iter: 638 loss: 9.28402812e-07
Iter: 639 loss: 9.27845804e-07
Iter: 640 loss: 9.28676798e-07
Iter: 641 loss: 9.27571e-07
Iter: 642 loss: 9.27177041e-07
Iter: 643 loss: 9.26423638e-07
Iter: 644 loss: 9.40463224e-07
Iter: 645 loss: 9.26435405e-07
Iter: 646 loss: 9.25677227e-07
Iter: 647 loss: 9.37395612e-07
Iter: 648 loss: 9.25686436e-07
Iter: 649 loss: 9.25091229e-07
Iter: 650 loss: 9.28891041e-07
Iter: 651 loss: 9.25063e-07
Iter: 652 loss: 9.24622327e-07
Iter: 653 loss: 9.23775474e-07
Iter: 654 loss: 9.41913299e-07
Iter: 655 loss: 9.23773143e-07
Iter: 656 loss: 9.23240464e-07
Iter: 657 loss: 9.30111128e-07
Iter: 658 loss: 9.23229777e-07
Iter: 659 loss: 9.22624167e-07
Iter: 660 loss: 9.24219535e-07
Iter: 661 loss: 9.22405e-07
Iter: 662 loss: 9.22079e-07
Iter: 663 loss: 9.21572337e-07
Iter: 664 loss: 9.21528e-07
Iter: 665 loss: 9.21068249e-07
Iter: 666 loss: 9.21064839e-07
Iter: 667 loss: 9.2048549e-07
Iter: 668 loss: 9.19766762e-07
Iter: 669 loss: 9.19754e-07
Iter: 670 loss: 9.19016543e-07
Iter: 671 loss: 9.21605761e-07
Iter: 672 loss: 9.18831176e-07
Iter: 673 loss: 9.18047306e-07
Iter: 674 loss: 9.25402048e-07
Iter: 675 loss: 9.18025819e-07
Iter: 676 loss: 9.17650709e-07
Iter: 677 loss: 9.16723309e-07
Iter: 678 loss: 9.2449261e-07
Iter: 679 loss: 9.16578415e-07
Iter: 680 loss: 9.15892542e-07
Iter: 681 loss: 9.24109713e-07
Iter: 682 loss: 9.15859061e-07
Iter: 683 loss: 9.15301428e-07
Iter: 684 loss: 9.15305861e-07
Iter: 685 loss: 9.14949908e-07
Iter: 686 loss: 9.14306725e-07
Iter: 687 loss: 9.1431383e-07
Iter: 688 loss: 9.13764779e-07
Iter: 689 loss: 9.16572787e-07
Iter: 690 loss: 9.13691679e-07
Iter: 691 loss: 9.13117788e-07
Iter: 692 loss: 9.16972169e-07
Iter: 693 loss: 9.13073052e-07
Iter: 694 loss: 9.12691519e-07
Iter: 695 loss: 9.11844381e-07
Iter: 696 loss: 9.23549408e-07
Iter: 697 loss: 9.11769575e-07
Iter: 698 loss: 9.11243e-07
Iter: 699 loss: 9.11216944e-07
Iter: 700 loss: 9.10624067e-07
Iter: 701 loss: 9.11614734e-07
Iter: 702 loss: 9.10334677e-07
Iter: 703 loss: 9.09934442e-07
Iter: 704 loss: 9.09911364e-07
Iter: 705 loss: 9.09608332e-07
Iter: 706 loss: 9.09196388e-07
Iter: 707 loss: 9.09216396e-07
Iter: 708 loss: 9.08985e-07
Iter: 709 loss: 9.08396828e-07
Iter: 710 loss: 9.10756285e-07
Iter: 711 loss: 9.08150753e-07
Iter: 712 loss: 9.07308845e-07
Iter: 713 loss: 9.10897711e-07
Iter: 714 loss: 9.0715514e-07
Iter: 715 loss: 9.06604782e-07
Iter: 716 loss: 9.06572097e-07
Iter: 717 loss: 9.06104901e-07
Iter: 718 loss: 9.05640604e-07
Iter: 719 loss: 9.05523223e-07
Iter: 720 loss: 9.049445e-07
Iter: 721 loss: 9.05488037e-07
Iter: 722 loss: 9.04616911e-07
Iter: 723 loss: 9.04272667e-07
Iter: 724 loss: 9.04185356e-07
Iter: 725 loss: 9.03898695e-07
Iter: 726 loss: 9.03191676e-07
Iter: 727 loss: 9.11583072e-07
Iter: 728 loss: 9.03142222e-07
Iter: 729 loss: 9.02408e-07
Iter: 730 loss: 9.02326406e-07
Iter: 731 loss: 9.01785143e-07
Iter: 732 loss: 9.01403041e-07
Iter: 733 loss: 9.0114861e-07
Iter: 734 loss: 9.00882185e-07
Iter: 735 loss: 9.00388045e-07
Iter: 736 loss: 9.00386908e-07
Iter: 737 loss: 9.0006472e-07
Iter: 738 loss: 9.00027203e-07
Iter: 739 loss: 8.99849454e-07
Iter: 740 loss: 8.99439215e-07
Iter: 741 loss: 9.04999354e-07
Iter: 742 loss: 8.9940977e-07
Iter: 743 loss: 8.9897776e-07
Iter: 744 loss: 8.98759254e-07
Iter: 745 loss: 8.98557687e-07
Iter: 746 loss: 8.98282792e-07
Iter: 747 loss: 8.98206395e-07
Iter: 748 loss: 8.97911548e-07
Iter: 749 loss: 8.9884162e-07
Iter: 750 loss: 8.97780694e-07
Iter: 751 loss: 8.97485847e-07
Iter: 752 loss: 8.97005066e-07
Iter: 753 loss: 8.9699671e-07
Iter: 754 loss: 8.96475626e-07
Iter: 755 loss: 8.99058534e-07
Iter: 756 loss: 8.96371716e-07
Iter: 757 loss: 8.958948e-07
Iter: 758 loss: 9.01209432e-07
Iter: 759 loss: 8.95891503e-07
Iter: 760 loss: 8.95620246e-07
Iter: 761 loss: 8.95039818e-07
Iter: 762 loss: 9.01827093e-07
Iter: 763 loss: 8.9499872e-07
Iter: 764 loss: 8.94790332e-07
Iter: 765 loss: 8.94710126e-07
Iter: 766 loss: 8.94391292e-07
Iter: 767 loss: 8.94088544e-07
Iter: 768 loss: 8.9402738e-07
Iter: 769 loss: 8.93676599e-07
Iter: 770 loss: 8.97758753e-07
Iter: 771 loss: 8.93680294e-07
Iter: 772 loss: 8.93271135e-07
Iter: 773 loss: 8.92911714e-07
Iter: 774 loss: 8.92801268e-07
Iter: 775 loss: 8.92421667e-07
Iter: 776 loss: 8.91913373e-07
Iter: 777 loss: 8.91845957e-07
Iter: 778 loss: 8.91224886e-07
Iter: 779 loss: 8.96845108e-07
Iter: 780 loss: 8.91203058e-07
Iter: 781 loss: 8.90721878e-07
Iter: 782 loss: 8.90717729e-07
Iter: 783 loss: 8.90380875e-07
Iter: 784 loss: 8.90220576e-07
Iter: 785 loss: 8.9006403e-07
Iter: 786 loss: 8.89548062e-07
Iter: 787 loss: 8.89874116e-07
Iter: 788 loss: 8.8921206e-07
Iter: 789 loss: 8.88913519e-07
Iter: 790 loss: 8.88858949e-07
Iter: 791 loss: 8.8861168e-07
Iter: 792 loss: 8.88016302e-07
Iter: 793 loss: 8.95752464e-07
Iter: 794 loss: 8.87960539e-07
Iter: 795 loss: 8.87444457e-07
Iter: 796 loss: 8.89466207e-07
Iter: 797 loss: 8.87333726e-07
Iter: 798 loss: 8.86792407e-07
Iter: 799 loss: 8.94160166e-07
Iter: 800 loss: 8.8681054e-07
Iter: 801 loss: 8.86583678e-07
Iter: 802 loss: 8.86202542e-07
Iter: 803 loss: 8.86189525e-07
Iter: 804 loss: 8.85557313e-07
Iter: 805 loss: 8.90189199e-07
Iter: 806 loss: 8.85520194e-07
Iter: 807 loss: 8.85216423e-07
Iter: 808 loss: 8.84521569e-07
Iter: 809 loss: 8.9241604e-07
Iter: 810 loss: 8.84457e-07
Iter: 811 loss: 8.83750658e-07
Iter: 812 loss: 8.84095584e-07
Iter: 813 loss: 8.83296138e-07
Iter: 814 loss: 8.83285793e-07
Iter: 815 loss: 8.82979e-07
Iter: 816 loss: 8.82695133e-07
Iter: 817 loss: 8.83043072e-07
Iter: 818 loss: 8.82533243e-07
Iter: 819 loss: 8.82203835e-07
Iter: 820 loss: 8.82212248e-07
Iter: 821 loss: 8.82017957e-07
Iter: 822 loss: 8.81484368e-07
Iter: 823 loss: 8.82016195e-07
Iter: 824 loss: 8.81199469e-07
Iter: 825 loss: 8.80499954e-07
Iter: 826 loss: 8.8484e-07
Iter: 827 loss: 8.8035938e-07
Iter: 828 loss: 8.79953518e-07
Iter: 829 loss: 8.79121103e-07
Iter: 830 loss: 8.95224787e-07
Iter: 831 loss: 8.79113e-07
Iter: 832 loss: 8.79288223e-07
Iter: 833 loss: 8.7878152e-07
Iter: 834 loss: 8.78539879e-07
Iter: 835 loss: 8.78011292e-07
Iter: 836 loss: 8.86741361e-07
Iter: 837 loss: 8.77988271e-07
Iter: 838 loss: 8.77835248e-07
Iter: 839 loss: 8.77751518e-07
Iter: 840 loss: 8.77505045e-07
Iter: 841 loss: 8.77010564e-07
Iter: 842 loss: 8.85133431e-07
Iter: 843 loss: 8.76985609e-07
Iter: 844 loss: 8.76553031e-07
Iter: 845 loss: 8.75519731e-07
Iter: 846 loss: 8.88954787e-07
Iter: 847 loss: 8.75438332e-07
Iter: 848 loss: 8.74559134e-07
Iter: 849 loss: 8.82283757e-07
Iter: 850 loss: 8.7450951e-07
Iter: 851 loss: 8.73841202e-07
Iter: 852 loss: 8.75153e-07
Iter: 853 loss: 8.73567046e-07
Iter: 854 loss: 8.72988267e-07
Iter: 855 loss: 8.74807654e-07
Iter: 856 loss: 8.72812e-07
Iter: 857 loss: 8.72404826e-07
Iter: 858 loss: 8.75717603e-07
Iter: 859 loss: 8.72362e-07
Iter: 860 loss: 8.72075361e-07
Iter: 861 loss: 8.73783904e-07
Iter: 862 loss: 8.72042165e-07
Iter: 863 loss: 8.71792736e-07
Iter: 864 loss: 8.71260568e-07
Iter: 865 loss: 8.79125082e-07
Iter: 866 loss: 8.71219527e-07
Iter: 867 loss: 8.70748806e-07
Iter: 868 loss: 8.70720669e-07
Iter: 869 loss: 8.70209476e-07
Iter: 870 loss: 8.70578e-07
Iter: 871 loss: 8.69908149e-07
Iter: 872 loss: 8.69422934e-07
Iter: 873 loss: 8.69884047e-07
Iter: 874 loss: 8.69124506e-07
Iter: 875 loss: 8.68293682e-07
Iter: 876 loss: 8.71917e-07
Iter: 877 loss: 8.68125881e-07
Iter: 878 loss: 8.67758445e-07
Iter: 879 loss: 8.67094855e-07
Iter: 880 loss: 8.82589234e-07
Iter: 881 loss: 8.67113499e-07
Iter: 882 loss: 8.66621576e-07
Iter: 883 loss: 8.66618279e-07
Iter: 884 loss: 8.6617257e-07
Iter: 885 loss: 8.69019516e-07
Iter: 886 loss: 8.6613386e-07
Iter: 887 loss: 8.65837e-07
Iter: 888 loss: 8.65522111e-07
Iter: 889 loss: 8.65485447e-07
Iter: 890 loss: 8.64993581e-07
Iter: 891 loss: 8.68685106e-07
Iter: 892 loss: 8.64929348e-07
Iter: 893 loss: 8.64613583e-07
Iter: 894 loss: 8.67949097e-07
Iter: 895 loss: 8.64582319e-07
Iter: 896 loss: 8.6433306e-07
Iter: 897 loss: 8.64135075e-07
Iter: 898 loss: 8.64044068e-07
Iter: 899 loss: 8.63757748e-07
Iter: 900 loss: 8.65545644e-07
Iter: 901 loss: 8.63737739e-07
Iter: 902 loss: 8.6340259e-07
Iter: 903 loss: 8.64627452e-07
Iter: 904 loss: 8.63323351e-07
Iter: 905 loss: 8.6303487e-07
Iter: 906 loss: 8.62746617e-07
Iter: 907 loss: 8.62706429e-07
Iter: 908 loss: 8.62266745e-07
Iter: 909 loss: 8.69377459e-07
Iter: 910 loss: 8.62270952e-07
Iter: 911 loss: 8.61975082e-07
Iter: 912 loss: 8.6114585e-07
Iter: 913 loss: 8.63148e-07
Iter: 914 loss: 8.60624425e-07
Iter: 915 loss: 8.59862325e-07
Iter: 916 loss: 8.59829e-07
Iter: 917 loss: 8.5943168e-07
Iter: 918 loss: 8.59426677e-07
Iter: 919 loss: 8.59230909e-07
Iter: 920 loss: 8.58733529e-07
Iter: 921 loss: 8.65879144e-07
Iter: 922 loss: 8.58714657e-07
Iter: 923 loss: 8.58181352e-07
Iter: 924 loss: 8.6333273e-07
Iter: 925 loss: 8.58149917e-07
Iter: 926 loss: 8.57777763e-07
Iter: 927 loss: 8.60196735e-07
Iter: 928 loss: 8.57744681e-07
Iter: 929 loss: 8.57343593e-07
Iter: 930 loss: 8.56919e-07
Iter: 931 loss: 8.56877648e-07
Iter: 932 loss: 8.5624248e-07
Iter: 933 loss: 8.57663736e-07
Iter: 934 loss: 8.56021074e-07
Iter: 935 loss: 8.5537431e-07
Iter: 936 loss: 8.62751e-07
Iter: 937 loss: 8.55366238e-07
Iter: 938 loss: 8.54959e-07
Iter: 939 loss: 8.5449841e-07
Iter: 940 loss: 8.54447421e-07
Iter: 941 loss: 8.54213795e-07
Iter: 942 loss: 8.54093514e-07
Iter: 943 loss: 8.53897859e-07
Iter: 944 loss: 8.53317545e-07
Iter: 945 loss: 8.57038629e-07
Iter: 946 loss: 8.5323876e-07
Iter: 947 loss: 8.5266413e-07
Iter: 948 loss: 8.56049439e-07
Iter: 949 loss: 8.52621554e-07
Iter: 950 loss: 8.52221888e-07
Iter: 951 loss: 8.57638781e-07
Iter: 952 loss: 8.52229562e-07
Iter: 953 loss: 8.51887648e-07
Iter: 954 loss: 8.51213827e-07
Iter: 955 loss: 8.6408545e-07
Iter: 956 loss: 8.51225536e-07
Iter: 957 loss: 8.50622314e-07
Iter: 958 loss: 8.55951271e-07
Iter: 959 loss: 8.505869e-07
Iter: 960 loss: 8.5014085e-07
Iter: 961 loss: 8.53716813e-07
Iter: 962 loss: 8.50120387e-07
Iter: 963 loss: 8.49717e-07
Iter: 964 loss: 8.49868798e-07
Iter: 965 loss: 8.49462879e-07
Iter: 966 loss: 8.49123467e-07
Iter: 967 loss: 8.4940433e-07
Iter: 968 loss: 8.48898708e-07
Iter: 969 loss: 8.48578509e-07
Iter: 970 loss: 8.48558898e-07
Iter: 971 loss: 8.48317882e-07
Iter: 972 loss: 8.4774581e-07
Iter: 973 loss: 8.56854911e-07
Iter: 974 loss: 8.47743308e-07
Iter: 975 loss: 8.47383774e-07
Iter: 976 loss: 8.47313686e-07
Iter: 977 loss: 8.46989792e-07
Iter: 978 loss: 8.46071657e-07
Iter: 979 loss: 8.53340794e-07
Iter: 980 loss: 8.45937791e-07
Iter: 981 loss: 8.45016643e-07
Iter: 982 loss: 8.48088916e-07
Iter: 983 loss: 8.44789383e-07
Iter: 984 loss: 8.44717192e-07
Iter: 985 loss: 8.44363626e-07
Iter: 986 loss: 8.4404121e-07
Iter: 987 loss: 8.43730732e-07
Iter: 988 loss: 8.43674798e-07
Iter: 989 loss: 8.43321061e-07
Iter: 990 loss: 8.43961857e-07
Iter: 991 loss: 8.43131488e-07
Iter: 992 loss: 8.42675149e-07
Iter: 993 loss: 8.46576086e-07
Iter: 994 loss: 8.42654799e-07
Iter: 995 loss: 8.42233135e-07
Iter: 996 loss: 8.42563509e-07
Iter: 997 loss: 8.41954716e-07
Iter: 998 loss: 8.41509348e-07
Iter: 999 loss: 8.41034534e-07
Iter: 1000 loss: 8.40970529e-07
Iter: 1001 loss: 8.40540054e-07
Iter: 1002 loss: 8.40477355e-07
Iter: 1003 loss: 8.40098323e-07
Iter: 1004 loss: 8.39609243e-07
Iter: 1005 loss: 8.39567633e-07
Iter: 1006 loss: 8.39288361e-07
Iter: 1007 loss: 8.3925147e-07
Iter: 1008 loss: 8.3896316e-07
Iter: 1009 loss: 8.3855582e-07
Iter: 1010 loss: 8.38576568e-07
Iter: 1011 loss: 8.3817838e-07
Iter: 1012 loss: 8.37664743e-07
Iter: 1013 loss: 8.37632683e-07
Iter: 1014 loss: 8.37158154e-07
Iter: 1015 loss: 8.37146672e-07
Iter: 1016 loss: 8.36547031e-07
Iter: 1017 loss: 8.36626441e-07
Iter: 1018 loss: 8.36086485e-07
Iter: 1019 loss: 8.355413e-07
Iter: 1020 loss: 8.3467603e-07
Iter: 1021 loss: 8.34664093e-07
Iter: 1022 loss: 8.33974e-07
Iter: 1023 loss: 8.43706175e-07
Iter: 1024 loss: 8.33968784e-07
Iter: 1025 loss: 8.33528873e-07
Iter: 1026 loss: 8.39990548e-07
Iter: 1027 loss: 8.33525178e-07
Iter: 1028 loss: 8.33323043e-07
Iter: 1029 loss: 8.33136824e-07
Iter: 1030 loss: 8.33036609e-07
Iter: 1031 loss: 8.32725959e-07
Iter: 1032 loss: 8.33460774e-07
Iter: 1033 loss: 8.32635635e-07
Iter: 1034 loss: 8.3216537e-07
Iter: 1035 loss: 8.33405807e-07
Iter: 1036 loss: 8.32018145e-07
Iter: 1037 loss: 8.31574198e-07
Iter: 1038 loss: 8.31709883e-07
Iter: 1039 loss: 8.31279749e-07
Iter: 1040 loss: 8.3065305e-07
Iter: 1041 loss: 8.35080812e-07
Iter: 1042 loss: 8.3057671e-07
Iter: 1043 loss: 8.30286467e-07
Iter: 1044 loss: 8.29722183e-07
Iter: 1045 loss: 8.42125303e-07
Iter: 1046 loss: 8.29704391e-07
Iter: 1047 loss: 8.29154772e-07
Iter: 1048 loss: 8.29754583e-07
Iter: 1049 loss: 8.28861516e-07
Iter: 1050 loss: 8.28749819e-07
Iter: 1051 loss: 8.2858071e-07
Iter: 1052 loss: 8.28294901e-07
Iter: 1053 loss: 8.28054453e-07
Iter: 1054 loss: 8.27971348e-07
Iter: 1055 loss: 8.27535303e-07
Iter: 1056 loss: 8.27176677e-07
Iter: 1057 loss: 8.2704122e-07
Iter: 1058 loss: 8.26902408e-07
Iter: 1059 loss: 8.26796111e-07
Iter: 1060 loss: 8.26535711e-07
Iter: 1061 loss: 8.26475116e-07
Iter: 1062 loss: 8.26339146e-07
Iter: 1063 loss: 8.26072721e-07
Iter: 1064 loss: 8.25702386e-07
Iter: 1065 loss: 8.25678285e-07
Iter: 1066 loss: 8.25240591e-07
Iter: 1067 loss: 8.25250254e-07
Iter: 1068 loss: 8.24854624e-07
Iter: 1069 loss: 8.24934546e-07
Iter: 1070 loss: 8.2457592e-07
Iter: 1071 loss: 8.24183644e-07
Iter: 1072 loss: 8.26178564e-07
Iter: 1073 loss: 8.24115091e-07
Iter: 1074 loss: 8.23668586e-07
Iter: 1075 loss: 8.25429652e-07
Iter: 1076 loss: 8.23607422e-07
Iter: 1077 loss: 8.23363848e-07
Iter: 1078 loss: 8.22900631e-07
Iter: 1079 loss: 8.33622266e-07
Iter: 1080 loss: 8.22905292e-07
Iter: 1081 loss: 8.22581285e-07
Iter: 1082 loss: 8.24768222e-07
Iter: 1083 loss: 8.22536435e-07
Iter: 1084 loss: 8.22405696e-07
Iter: 1085 loss: 8.22383413e-07
Iter: 1086 loss: 8.22247557e-07
Iter: 1087 loss: 8.2176723e-07
Iter: 1088 loss: 8.21957258e-07
Iter: 1089 loss: 8.21346e-07
Iter: 1090 loss: 8.20583637e-07
Iter: 1091 loss: 8.23416485e-07
Iter: 1092 loss: 8.20395371e-07
Iter: 1093 loss: 8.1955443e-07
Iter: 1094 loss: 8.22918423e-07
Iter: 1095 loss: 8.19382251e-07
Iter: 1096 loss: 8.19188131e-07
Iter: 1097 loss: 8.19127138e-07
Iter: 1098 loss: 8.1882456e-07
Iter: 1099 loss: 8.19083539e-07
Iter: 1100 loss: 8.18643343e-07
Iter: 1101 loss: 8.18403464e-07
Iter: 1102 loss: 8.18199453e-07
Iter: 1103 loss: 8.18137153e-07
Iter: 1104 loss: 8.17739419e-07
Iter: 1105 loss: 8.20849209e-07
Iter: 1106 loss: 8.17716682e-07
Iter: 1107 loss: 8.17353566e-07
Iter: 1108 loss: 8.20137871e-07
Iter: 1109 loss: 8.17349814e-07
Iter: 1110 loss: 8.17139721e-07
Iter: 1111 loss: 8.16840213e-07
Iter: 1112 loss: 8.16833847e-07
Iter: 1113 loss: 8.16654392e-07
Iter: 1114 loss: 8.1662381e-07
Iter: 1115 loss: 8.16433158e-07
Iter: 1116 loss: 8.16306851e-07
Iter: 1117 loss: 8.16232387e-07
Iter: 1118 loss: 8.15957321e-07
Iter: 1119 loss: 8.16138595e-07
Iter: 1120 loss: 8.15764167e-07
Iter: 1121 loss: 8.15473811e-07
Iter: 1122 loss: 8.15482281e-07
Iter: 1123 loss: 8.15333181e-07
Iter: 1124 loss: 8.14852967e-07
Iter: 1125 loss: 8.15113e-07
Iter: 1126 loss: 8.1446143e-07
Iter: 1127 loss: 8.1397252e-07
Iter: 1128 loss: 8.13968086e-07
Iter: 1129 loss: 8.13802217e-07
Iter: 1130 loss: 8.13771578e-07
Iter: 1131 loss: 8.13564156e-07
Iter: 1132 loss: 8.13233328e-07
Iter: 1133 loss: 8.13242764e-07
Iter: 1134 loss: 8.12873509e-07
Iter: 1135 loss: 8.13810857e-07
Iter: 1136 loss: 8.12756298e-07
Iter: 1137 loss: 8.12410121e-07
Iter: 1138 loss: 8.17683144e-07
Iter: 1139 loss: 8.12408e-07
Iter: 1140 loss: 8.12111409e-07
Iter: 1141 loss: 8.1163131e-07
Iter: 1142 loss: 8.11624091e-07
Iter: 1143 loss: 8.1117804e-07
Iter: 1144 loss: 8.12325538e-07
Iter: 1145 loss: 8.11002792e-07
Iter: 1146 loss: 8.10661e-07
Iter: 1147 loss: 8.10657525e-07
Iter: 1148 loss: 8.10456413e-07
Iter: 1149 loss: 8.10226311e-07
Iter: 1150 loss: 8.1021949e-07
Iter: 1151 loss: 8.10080849e-07
Iter: 1152 loss: 8.10056122e-07
Iter: 1153 loss: 8.09929077e-07
Iter: 1154 loss: 8.09665266e-07
Iter: 1155 loss: 8.13800455e-07
Iter: 1156 loss: 8.09631217e-07
Iter: 1157 loss: 8.0936934e-07
Iter: 1158 loss: 8.09014864e-07
Iter: 1159 loss: 8.09015319e-07
Iter: 1160 loss: 8.08631285e-07
Iter: 1161 loss: 8.1397377e-07
Iter: 1162 loss: 8.08643279e-07
Iter: 1163 loss: 8.08473942e-07
Iter: 1164 loss: 8.08453592e-07
Iter: 1165 loss: 8.08360539e-07
Iter: 1166 loss: 8.08135042e-07
Iter: 1167 loss: 8.10811912e-07
Iter: 1168 loss: 8.08128e-07
Iter: 1169 loss: 8.07833089e-07
Iter: 1170 loss: 8.10683e-07
Iter: 1171 loss: 8.07830475e-07
Iter: 1172 loss: 8.07602248e-07
Iter: 1173 loss: 8.09264861e-07
Iter: 1174 loss: 8.07573201e-07
Iter: 1175 loss: 8.07441097e-07
Iter: 1176 loss: 8.07065248e-07
Iter: 1177 loss: 8.10315782e-07
Iter: 1178 loss: 8.07005165e-07
Iter: 1179 loss: 8.06622268e-07
Iter: 1180 loss: 8.06635171e-07
Iter: 1181 loss: 8.06242042e-07
Iter: 1182 loss: 8.06537514e-07
Iter: 1183 loss: 8.06046103e-07
Iter: 1184 loss: 8.05838e-07
Iter: 1185 loss: 8.06660694e-07
Iter: 1186 loss: 8.05806508e-07
Iter: 1187 loss: 8.05588343e-07
Iter: 1188 loss: 8.07058427e-07
Iter: 1189 loss: 8.05577201e-07
Iter: 1190 loss: 8.05451464e-07
Iter: 1191 loss: 8.05122568e-07
Iter: 1192 loss: 8.07639708e-07
Iter: 1193 loss: 8.05055663e-07
Iter: 1194 loss: 8.04554361e-07
Iter: 1195 loss: 8.04699312e-07
Iter: 1196 loss: 8.04221941e-07
Iter: 1197 loss: 8.03587739e-07
Iter: 1198 loss: 8.04527588e-07
Iter: 1199 loss: 8.03279136e-07
Iter: 1200 loss: 8.03865305e-07
Iter: 1201 loss: 8.03162607e-07
Iter: 1202 loss: 8.03017144e-07
Iter: 1203 loss: 8.02998443e-07
Iter: 1204 loss: 8.029e-07
Iter: 1205 loss: 8.02790339e-07
Iter: 1206 loss: 8.03557441e-07
Iter: 1207 loss: 8.02772604e-07
Iter: 1208 loss: 8.02624243e-07
Iter: 1209 loss: 8.02451837e-07
Iter: 1210 loss: 8.02432282e-07
Iter: 1211 loss: 8.02198713e-07
Iter: 1212 loss: 8.02279828e-07
Iter: 1213 loss: 8.02023806e-07
Iter: 1214 loss: 8.0175073e-07
Iter: 1215 loss: 8.02992076e-07
Iter: 1216 loss: 8.01690703e-07
Iter: 1217 loss: 8.0139057e-07
Iter: 1218 loss: 8.03639068e-07
Iter: 1219 loss: 8.0136823e-07
Iter: 1220 loss: 8.01152225e-07
Iter: 1221 loss: 8.00847602e-07
Iter: 1222 loss: 8.00857606e-07
Iter: 1223 loss: 8.00695375e-07
Iter: 1224 loss: 8.00662e-07
Iter: 1225 loss: 8.00503699e-07
Iter: 1226 loss: 8.00334249e-07
Iter: 1227 loss: 8.00318446e-07
Iter: 1228 loss: 8.00140526e-07
Iter: 1229 loss: 7.99866029e-07
Iter: 1230 loss: 7.99826864e-07
Iter: 1231 loss: 7.99469603e-07
Iter: 1232 loss: 8.00860789e-07
Iter: 1233 loss: 7.99381e-07
Iter: 1234 loss: 7.99351938e-07
Iter: 1235 loss: 7.99223756e-07
Iter: 1236 loss: 7.99094153e-07
Iter: 1237 loss: 7.98791234e-07
Iter: 1238 loss: 8.03086095e-07
Iter: 1239 loss: 7.98761562e-07
Iter: 1240 loss: 7.98536917e-07
Iter: 1241 loss: 7.99632858e-07
Iter: 1242 loss: 7.98486667e-07
Iter: 1243 loss: 7.98341375e-07
Iter: 1244 loss: 7.98317387e-07
Iter: 1245 loss: 7.98236385e-07
Iter: 1246 loss: 7.98009296e-07
Iter: 1247 loss: 7.99719317e-07
Iter: 1248 loss: 7.97985308e-07
Iter: 1249 loss: 7.97576661e-07
Iter: 1250 loss: 7.97918e-07
Iter: 1251 loss: 7.97329051e-07
Iter: 1252 loss: 7.97249584e-07
Iter: 1253 loss: 7.97132088e-07
Iter: 1254 loss: 7.96972813e-07
Iter: 1255 loss: 7.96725772e-07
Iter: 1256 loss: 7.9671463e-07
Iter: 1257 loss: 7.96575932e-07
Iter: 1258 loss: 7.96561721e-07
Iter: 1259 loss: 7.96406255e-07
Iter: 1260 loss: 7.96282848e-07
Iter: 1261 loss: 7.96249651e-07
Iter: 1262 loss: 7.96063375e-07
Iter: 1263 loss: 7.95902e-07
Iter: 1264 loss: 7.95845494e-07
Iter: 1265 loss: 7.95534731e-07
Iter: 1266 loss: 7.96101403e-07
Iter: 1267 loss: 7.95388e-07
Iter: 1268 loss: 7.95201572e-07
Iter: 1269 loss: 7.95156097e-07
Iter: 1270 loss: 7.949767e-07
Iter: 1271 loss: 7.94549919e-07
Iter: 1272 loss: 7.98597512e-07
Iter: 1273 loss: 7.94505411e-07
Iter: 1274 loss: 7.94376206e-07
Iter: 1275 loss: 7.94342213e-07
Iter: 1276 loss: 7.94179641e-07
Iter: 1277 loss: 7.95110054e-07
Iter: 1278 loss: 7.94150253e-07
Iter: 1279 loss: 7.94056632e-07
Iter: 1280 loss: 7.93808e-07
Iter: 1281 loss: 7.95432186e-07
Iter: 1282 loss: 7.93759568e-07
Iter: 1283 loss: 7.93453182e-07
Iter: 1284 loss: 7.96953827e-07
Iter: 1285 loss: 7.9344909e-07
Iter: 1286 loss: 7.93212735e-07
Iter: 1287 loss: 7.948139e-07
Iter: 1288 loss: 7.93191191e-07
Iter: 1289 loss: 7.93029471e-07
Iter: 1290 loss: 7.92798971e-07
Iter: 1291 loss: 7.92807327e-07
Iter: 1292 loss: 7.92473884e-07
Iter: 1293 loss: 7.96480094e-07
Iter: 1294 loss: 7.92483775e-07
Iter: 1295 loss: 7.92299e-07
Iter: 1296 loss: 7.91971331e-07
Iter: 1297 loss: 7.91965249e-07
Iter: 1298 loss: 7.9162578e-07
Iter: 1299 loss: 7.91996342e-07
Iter: 1300 loss: 7.91458319e-07
Iter: 1301 loss: 7.91097534e-07
Iter: 1302 loss: 7.93387244e-07
Iter: 1303 loss: 7.91029152e-07
Iter: 1304 loss: 7.90537115e-07
Iter: 1305 loss: 7.91996285e-07
Iter: 1306 loss: 7.90393756e-07
Iter: 1307 loss: 7.9006935e-07
Iter: 1308 loss: 7.89629041e-07
Iter: 1309 loss: 7.89627961e-07
Iter: 1310 loss: 7.89638705e-07
Iter: 1311 loss: 7.8945726e-07
Iter: 1312 loss: 7.89236253e-07
Iter: 1313 loss: 7.88905822e-07
Iter: 1314 loss: 7.88893431e-07
Iter: 1315 loss: 7.88623765e-07
Iter: 1316 loss: 7.90089587e-07
Iter: 1317 loss: 7.88563966e-07
Iter: 1318 loss: 7.88319483e-07
Iter: 1319 loss: 7.89637738e-07
Iter: 1320 loss: 7.88298507e-07
Iter: 1321 loss: 7.88092393e-07
Iter: 1322 loss: 7.88248371e-07
Iter: 1323 loss: 7.87947386e-07
Iter: 1324 loss: 7.87687e-07
Iter: 1325 loss: 7.88378316e-07
Iter: 1326 loss: 7.87602403e-07
Iter: 1327 loss: 7.87141573e-07
Iter: 1328 loss: 7.86676651e-07
Iter: 1329 loss: 7.86600935e-07
Iter: 1330 loss: 7.86149712e-07
Iter: 1331 loss: 7.87658337e-07
Iter: 1332 loss: 7.85995212e-07
Iter: 1333 loss: 7.85706106e-07
Iter: 1334 loss: 7.86569672e-07
Iter: 1335 loss: 7.85621523e-07
Iter: 1336 loss: 7.85504426e-07
Iter: 1337 loss: 7.85438715e-07
Iter: 1338 loss: 7.85334862e-07
Iter: 1339 loss: 7.85060649e-07
Iter: 1340 loss: 7.88735406e-07
Iter: 1341 loss: 7.85043312e-07
Iter: 1342 loss: 7.8476171e-07
Iter: 1343 loss: 7.85465204e-07
Iter: 1344 loss: 7.84668146e-07
Iter: 1345 loss: 7.84264444e-07
Iter: 1346 loss: 7.86577971e-07
Iter: 1347 loss: 7.84196232e-07
Iter: 1348 loss: 7.83984774e-07
Iter: 1349 loss: 7.83724431e-07
Iter: 1350 loss: 7.83668327e-07
Iter: 1351 loss: 7.83362736e-07
Iter: 1352 loss: 7.8787383e-07
Iter: 1353 loss: 7.83356427e-07
Iter: 1354 loss: 7.83190444e-07
Iter: 1355 loss: 7.8373364e-07
Iter: 1356 loss: 7.83119503e-07
Iter: 1357 loss: 7.83006271e-07
Iter: 1358 loss: 7.83448286e-07
Iter: 1359 loss: 7.82948348e-07
Iter: 1360 loss: 7.82785037e-07
Iter: 1361 loss: 7.83005248e-07
Iter: 1362 loss: 7.82701079e-07
Iter: 1363 loss: 7.82504344e-07
Iter: 1364 loss: 7.82080065e-07
Iter: 1365 loss: 7.87791123e-07
Iter: 1366 loss: 7.82027655e-07
Iter: 1367 loss: 7.81538802e-07
Iter: 1368 loss: 7.83476253e-07
Iter: 1369 loss: 7.81436256e-07
Iter: 1370 loss: 7.81174663e-07
Iter: 1371 loss: 7.81157212e-07
Iter: 1372 loss: 7.80829907e-07
Iter: 1373 loss: 7.80625101e-07
Iter: 1374 loss: 7.80510845e-07
Iter: 1375 loss: 7.80265395e-07
Iter: 1376 loss: 7.8057019e-07
Iter: 1377 loss: 7.80146763e-07
Iter: 1378 loss: 7.80086793e-07
Iter: 1379 loss: 7.80008236e-07
Iter: 1380 loss: 7.799e-07
Iter: 1381 loss: 7.79602715e-07
Iter: 1382 loss: 7.80816094e-07
Iter: 1383 loss: 7.79486527e-07
Iter: 1384 loss: 7.79206175e-07
Iter: 1385 loss: 7.79203617e-07
Iter: 1386 loss: 7.78931906e-07
Iter: 1387 loss: 7.78963624e-07
Iter: 1388 loss: 7.78734943e-07
Iter: 1389 loss: 7.78387289e-07
Iter: 1390 loss: 7.79721347e-07
Iter: 1391 loss: 7.7834909e-07
Iter: 1392 loss: 7.78064077e-07
Iter: 1393 loss: 7.80912842e-07
Iter: 1394 loss: 7.78080221e-07
Iter: 1395 loss: 7.77936066e-07
Iter: 1396 loss: 7.77728701e-07
Iter: 1397 loss: 7.77694595e-07
Iter: 1398 loss: 7.77477339e-07
Iter: 1399 loss: 7.77678451e-07
Iter: 1400 loss: 7.77328296e-07
Iter: 1401 loss: 7.77077958e-07
Iter: 1402 loss: 7.77403e-07
Iter: 1403 loss: 7.76973707e-07
Iter: 1404 loss: 7.76601382e-07
Iter: 1405 loss: 7.8007e-07
Iter: 1406 loss: 7.76600302e-07
Iter: 1407 loss: 7.76370712e-07
Iter: 1408 loss: 7.7577721e-07
Iter: 1409 loss: 7.83244e-07
Iter: 1410 loss: 7.7571724e-07
Iter: 1411 loss: 7.75770332e-07
Iter: 1412 loss: 7.75550461e-07
Iter: 1413 loss: 7.75333831e-07
Iter: 1414 loss: 7.74997261e-07
Iter: 1415 loss: 7.83051632e-07
Iter: 1416 loss: 7.74975888e-07
Iter: 1417 loss: 7.7473635e-07
Iter: 1418 loss: 7.77205116e-07
Iter: 1419 loss: 7.7473635e-07
Iter: 1420 loss: 7.74559112e-07
Iter: 1421 loss: 7.75045123e-07
Iter: 1422 loss: 7.74486921e-07
Iter: 1423 loss: 7.74315765e-07
Iter: 1424 loss: 7.7432469e-07
Iter: 1425 loss: 7.74180876e-07
Iter: 1426 loss: 7.73919453e-07
Iter: 1427 loss: 7.75155968e-07
Iter: 1428 loss: 7.73894897e-07
Iter: 1429 loss: 7.7357538e-07
Iter: 1430 loss: 7.73541615e-07
Iter: 1431 loss: 7.73307818e-07
Iter: 1432 loss: 7.72888257e-07
Iter: 1433 loss: 7.72430838e-07
Iter: 1434 loss: 7.72368651e-07
Iter: 1435 loss: 7.7185706e-07
Iter: 1436 loss: 7.7531314e-07
Iter: 1437 loss: 7.71809937e-07
Iter: 1438 loss: 7.7157091e-07
Iter: 1439 loss: 7.71565965e-07
Iter: 1440 loss: 7.7130926e-07
Iter: 1441 loss: 7.71240877e-07
Iter: 1442 loss: 7.71035616e-07
Iter: 1443 loss: 7.70845816e-07
Iter: 1444 loss: 7.71054943e-07
Iter: 1445 loss: 7.70730367e-07
Iter: 1446 loss: 7.70470933e-07
Iter: 1447 loss: 7.74040359e-07
Iter: 1448 loss: 7.70471047e-07
Iter: 1449 loss: 7.70287556e-07
Iter: 1450 loss: 7.69775852e-07
Iter: 1451 loss: 7.70706833e-07
Iter: 1452 loss: 7.69421092e-07
Iter: 1453 loss: 7.70047393e-07
Iter: 1454 loss: 7.69245048e-07
Iter: 1455 loss: 7.69070937e-07
Iter: 1456 loss: 7.68797292e-07
Iter: 1457 loss: 7.68791892e-07
Iter: 1458 loss: 7.68516884e-07
Iter: 1459 loss: 7.70564668e-07
Iter: 1460 loss: 7.68486871e-07
Iter: 1461 loss: 7.6822414e-07
Iter: 1462 loss: 7.69328437e-07
Iter: 1463 loss: 7.68171844e-07
Iter: 1464 loss: 7.67898541e-07
Iter: 1465 loss: 7.67677534e-07
Iter: 1466 loss: 7.67631377e-07
Iter: 1467 loss: 7.67251152e-07
Iter: 1468 loss: 7.66743483e-07
Iter: 1469 loss: 7.66719722e-07
Iter: 1470 loss: 7.66713413e-07
Iter: 1471 loss: 7.66435221e-07
Iter: 1472 loss: 7.66265316e-07
Iter: 1473 loss: 7.66886558e-07
Iter: 1474 loss: 7.66211201e-07
Iter: 1475 loss: 7.6605761e-07
Iter: 1476 loss: 7.65877701e-07
Iter: 1477 loss: 7.65854e-07
Iter: 1478 loss: 7.65707114e-07
Iter: 1479 loss: 7.65694608e-07
Iter: 1480 loss: 7.65547611e-07
Iter: 1481 loss: 7.65094114e-07
Iter: 1482 loss: 7.67059419e-07
Iter: 1483 loss: 7.64928927e-07
Iter: 1484 loss: 7.64457809e-07
Iter: 1485 loss: 7.68072596e-07
Iter: 1486 loss: 7.64429899e-07
Iter: 1487 loss: 7.64017955e-07
Iter: 1488 loss: 7.68121197e-07
Iter: 1489 loss: 7.63991579e-07
Iter: 1490 loss: 7.63795754e-07
Iter: 1491 loss: 7.63554453e-07
Iter: 1492 loss: 7.63509036e-07
Iter: 1493 loss: 7.63190428e-07
Iter: 1494 loss: 7.63185881e-07
Iter: 1495 loss: 7.63041839e-07
Iter: 1496 loss: 7.63236642e-07
Iter: 1497 loss: 7.62934292e-07
Iter: 1498 loss: 7.62785362e-07
Iter: 1499 loss: 7.62480624e-07
Iter: 1500 loss: 7.6830122e-07
Iter: 1501 loss: 7.62478408e-07
Iter: 1502 loss: 7.62076411e-07
Iter: 1503 loss: 7.63621301e-07
Iter: 1504 loss: 7.61959484e-07
Iter: 1505 loss: 7.61611034e-07
Iter: 1506 loss: 7.61606486e-07
Iter: 1507 loss: 7.61380875e-07
Iter: 1508 loss: 7.61064086e-07
Iter: 1509 loss: 7.61059255e-07
Iter: 1510 loss: 7.60728142e-07
Iter: 1511 loss: 7.64522099e-07
Iter: 1512 loss: 7.60724674e-07
Iter: 1513 loss: 7.60346097e-07
Iter: 1514 loss: 7.60642934e-07
Iter: 1515 loss: 7.60147714e-07
Iter: 1516 loss: 7.59967691e-07
Iter: 1517 loss: 7.59853378e-07
Iter: 1518 loss: 7.59770558e-07
Iter: 1519 loss: 7.59729573e-07
Iter: 1520 loss: 7.59653062e-07
Iter: 1521 loss: 7.59559498e-07
Iter: 1522 loss: 7.59278123e-07
Iter: 1523 loss: 7.61497745e-07
Iter: 1524 loss: 7.59226566e-07
Iter: 1525 loss: 7.58983e-07
Iter: 1526 loss: 7.62501543e-07
Iter: 1527 loss: 7.58974465e-07
Iter: 1528 loss: 7.58690476e-07
Iter: 1529 loss: 7.59232762e-07
Iter: 1530 loss: 7.58564795e-07
Iter: 1531 loss: 7.58297688e-07
Iter: 1532 loss: 7.58062356e-07
Iter: 1533 loss: 7.5800483e-07
Iter: 1534 loss: 7.57554517e-07
Iter: 1535 loss: 7.58149326e-07
Iter: 1536 loss: 7.5735403e-07
Iter: 1537 loss: 7.57291787e-07
Iter: 1538 loss: 7.57158944e-07
Iter: 1539 loss: 7.57012e-07
Iter: 1540 loss: 7.56925772e-07
Iter: 1541 loss: 7.56886834e-07
Iter: 1542 loss: 7.56728923e-07
Iter: 1543 loss: 7.56365864e-07
Iter: 1544 loss: 7.6221022e-07
Iter: 1545 loss: 7.56348868e-07
Iter: 1546 loss: 7.56346139e-07
Iter: 1547 loss: 7.56198119e-07
Iter: 1548 loss: 7.56041e-07
Iter: 1549 loss: 7.55677775e-07
Iter: 1550 loss: 7.57651833e-07
Iter: 1551 loss: 7.55529868e-07
Iter: 1552 loss: 7.55184772e-07
Iter: 1553 loss: 7.56795714e-07
Iter: 1554 loss: 7.55111614e-07
Iter: 1555 loss: 7.54834957e-07
Iter: 1556 loss: 7.54838766e-07
Iter: 1557 loss: 7.54716837e-07
Iter: 1558 loss: 7.54448308e-07
Iter: 1559 loss: 7.56557256e-07
Iter: 1560 loss: 7.54386292e-07
Iter: 1561 loss: 7.5406507e-07
Iter: 1562 loss: 7.55047097e-07
Iter: 1563 loss: 7.53962752e-07
Iter: 1564 loss: 7.53693314e-07
Iter: 1565 loss: 7.53683e-07
Iter: 1566 loss: 7.53496124e-07
Iter: 1567 loss: 7.53105951e-07
Iter: 1568 loss: 7.58888575e-07
Iter: 1569 loss: 7.53102256e-07
Iter: 1570 loss: 7.52590608e-07
Iter: 1571 loss: 7.55149e-07
Iter: 1572 loss: 7.52513358e-07
Iter: 1573 loss: 7.52190942e-07
Iter: 1574 loss: 7.52674453e-07
Iter: 1575 loss: 7.52066398e-07
Iter: 1576 loss: 7.5185153e-07
Iter: 1577 loss: 7.54746054e-07
Iter: 1578 loss: 7.51855964e-07
Iter: 1579 loss: 7.5165633e-07
Iter: 1580 loss: 7.52601125e-07
Iter: 1581 loss: 7.51623872e-07
Iter: 1582 loss: 7.5146238e-07
Iter: 1583 loss: 7.51170546e-07
Iter: 1584 loss: 7.56290319e-07
Iter: 1585 loss: 7.51178618e-07
Iter: 1586 loss: 7.50907702e-07
Iter: 1587 loss: 7.50911511e-07
Iter: 1588 loss: 7.50706818e-07
Iter: 1589 loss: 7.5028106e-07
Iter: 1590 loss: 7.57294856e-07
Iter: 1591 loss: 7.50278389e-07
Iter: 1592 loss: 7.49978881e-07
Iter: 1593 loss: 7.50286631e-07
Iter: 1594 loss: 7.49818923e-07
Iter: 1595 loss: 7.49591663e-07
Iter: 1596 loss: 7.49547e-07
Iter: 1597 loss: 7.49425965e-07
Iter: 1598 loss: 7.49223318e-07
Iter: 1599 loss: 7.53225208e-07
Iter: 1600 loss: 7.49222863e-07
Iter: 1601 loss: 7.49081664e-07
Iter: 1602 loss: 7.49066e-07
Iter: 1603 loss: 7.48895673e-07
Iter: 1604 loss: 7.48578884e-07
Iter: 1605 loss: 7.54764869e-07
Iter: 1606 loss: 7.48569e-07
Iter: 1607 loss: 7.48165917e-07
Iter: 1608 loss: 7.49693072e-07
Iter: 1609 loss: 7.48087075e-07
Iter: 1610 loss: 7.4777347e-07
Iter: 1611 loss: 7.4802665e-07
Iter: 1612 loss: 7.47556555e-07
Iter: 1613 loss: 7.47243689e-07
Iter: 1614 loss: 7.48351624e-07
Iter: 1615 loss: 7.47162971e-07
Iter: 1616 loss: 7.47059801e-07
Iter: 1617 loss: 7.47004606e-07
Iter: 1618 loss: 7.46898763e-07
Iter: 1619 loss: 7.46555827e-07
Iter: 1620 loss: 7.49875198e-07
Iter: 1621 loss: 7.46545368e-07
Iter: 1622 loss: 7.46551109e-07
Iter: 1623 loss: 7.4643458e-07
Iter: 1624 loss: 7.46318335e-07
Iter: 1625 loss: 7.46048272e-07
Iter: 1626 loss: 7.48659659e-07
Iter: 1627 loss: 7.45981424e-07
Iter: 1628 loss: 7.45685497e-07
Iter: 1629 loss: 7.45804641e-07
Iter: 1630 loss: 7.45469379e-07
Iter: 1631 loss: 7.45321e-07
Iter: 1632 loss: 7.45294756e-07
Iter: 1633 loss: 7.45124112e-07
Iter: 1634 loss: 7.45650368e-07
Iter: 1635 loss: 7.4507517e-07
Iter: 1636 loss: 7.44949887e-07
Iter: 1637 loss: 7.44756505e-07
Iter: 1638 loss: 7.44743943e-07
Iter: 1639 loss: 7.44443923e-07
Iter: 1640 loss: 7.47051274e-07
Iter: 1641 loss: 7.44421925e-07
Iter: 1642 loss: 7.44241333e-07
Iter: 1643 loss: 7.43796477e-07
Iter: 1644 loss: 7.48304501e-07
Iter: 1645 loss: 7.43772716e-07
Iter: 1646 loss: 7.43326723e-07
Iter: 1647 loss: 7.44892134e-07
Iter: 1648 loss: 7.43208147e-07
Iter: 1649 loss: 7.42951215e-07
Iter: 1650 loss: 7.42935299e-07
Iter: 1651 loss: 7.42825137e-07
Iter: 1652 loss: 7.4281968e-07
Iter: 1653 loss: 7.42711677e-07
Iter: 1654 loss: 7.42569455e-07
Iter: 1655 loss: 7.46391038e-07
Iter: 1656 loss: 7.42541e-07
Iter: 1657 loss: 7.42418933e-07
Iter: 1658 loss: 7.43543751e-07
Iter: 1659 loss: 7.42402847e-07
Iter: 1660 loss: 7.42194345e-07
Iter: 1661 loss: 7.42159273e-07
Iter: 1662 loss: 7.42030124e-07
Iter: 1663 loss: 7.41822305e-07
Iter: 1664 loss: 7.41481188e-07
Iter: 1665 loss: 7.41471467e-07
Iter: 1666 loss: 7.41070153e-07
Iter: 1667 loss: 7.42980092e-07
Iter: 1668 loss: 7.41033432e-07
Iter: 1669 loss: 7.40953055e-07
Iter: 1670 loss: 7.40882228e-07
Iter: 1671 loss: 7.40732048e-07
Iter: 1672 loss: 7.40575274e-07
Iter: 1673 loss: 7.40554e-07
Iter: 1674 loss: 7.40414e-07
Iter: 1675 loss: 7.40425321e-07
Iter: 1676 loss: 7.40330165e-07
Iter: 1677 loss: 7.40186e-07
Iter: 1678 loss: 7.40161227e-07
Iter: 1679 loss: 7.40077212e-07
Iter: 1680 loss: 7.39814823e-07
Iter: 1681 loss: 7.4152797e-07
Iter: 1682 loss: 7.39755421e-07
Iter: 1683 loss: 7.39501559e-07
Iter: 1684 loss: 7.40667474e-07
Iter: 1685 loss: 7.39459779e-07
Iter: 1686 loss: 7.3940123e-07
Iter: 1687 loss: 7.39368033e-07
Iter: 1688 loss: 7.39291295e-07
Iter: 1689 loss: 7.39199038e-07
Iter: 1690 loss: 7.40865e-07
Iter: 1691 loss: 7.39185111e-07
Iter: 1692 loss: 7.39050392e-07
Iter: 1693 loss: 7.40093697e-07
Iter: 1694 loss: 7.39023051e-07
Iter: 1695 loss: 7.38922949e-07
Iter: 1696 loss: 7.39679763e-07
Iter: 1697 loss: 7.3890044e-07
Iter: 1698 loss: 7.38828e-07
Iter: 1699 loss: 7.38579729e-07
Iter: 1700 loss: 7.39964321e-07
Iter: 1701 loss: 7.38514643e-07
Iter: 1702 loss: 7.38131121e-07
Iter: 1703 loss: 7.38691824e-07
Iter: 1704 loss: 7.37963489e-07
Iter: 1705 loss: 7.37826497e-07
Iter: 1706 loss: 7.37769e-07
Iter: 1707 loss: 7.37582695e-07
Iter: 1708 loss: 7.3789522e-07
Iter: 1709 loss: 7.37517155e-07
Iter: 1710 loss: 7.37395226e-07
Iter: 1711 loss: 7.37255732e-07
Iter: 1712 loss: 7.37244136e-07
Iter: 1713 loss: 7.37205255e-07
Iter: 1714 loss: 7.37155176e-07
Iter: 1715 loss: 7.37053e-07
Iter: 1716 loss: 7.36876643e-07
Iter: 1717 loss: 7.39884115e-07
Iter: 1718 loss: 7.3684788e-07
Iter: 1719 loss: 7.36700486e-07
Iter: 1720 loss: 7.3678342e-07
Iter: 1721 loss: 7.36555535e-07
Iter: 1722 loss: 7.36335835e-07
Iter: 1723 loss: 7.3634294e-07
Iter: 1724 loss: 7.3624e-07
Iter: 1725 loss: 7.36076913e-07
Iter: 1726 loss: 7.40070618e-07
Iter: 1727 loss: 7.3607805e-07
Iter: 1728 loss: 7.35941512e-07
Iter: 1729 loss: 7.35927529e-07
Iter: 1730 loss: 7.35870685e-07
Iter: 1731 loss: 7.35715e-07
Iter: 1732 loss: 7.37793584e-07
Iter: 1733 loss: 7.35708795e-07
Iter: 1734 loss: 7.3554213e-07
Iter: 1735 loss: 7.3619151e-07
Iter: 1736 loss: 7.35506376e-07
Iter: 1737 loss: 7.35362846e-07
Iter: 1738 loss: 7.35454307e-07
Iter: 1739 loss: 7.35288722e-07
Iter: 1740 loss: 7.35142862e-07
Iter: 1741 loss: 7.37103562e-07
Iter: 1742 loss: 7.35140873e-07
Iter: 1743 loss: 7.34972446e-07
Iter: 1744 loss: 7.3480561e-07
Iter: 1745 loss: 7.34796402e-07
Iter: 1746 loss: 7.34675268e-07
Iter: 1747 loss: 7.34643265e-07
Iter: 1748 loss: 7.34569483e-07
Iter: 1749 loss: 7.3441123e-07
Iter: 1750 loss: 7.35875687e-07
Iter: 1751 loss: 7.34375647e-07
Iter: 1752 loss: 7.3414526e-07
Iter: 1753 loss: 7.34472451e-07
Iter: 1754 loss: 7.3404135e-07
Iter: 1755 loss: 7.33900492e-07
Iter: 1756 loss: 7.35623871e-07
Iter: 1757 loss: 7.33890829e-07
Iter: 1758 loss: 7.3381e-07
Iter: 1759 loss: 7.33703473e-07
Iter: 1760 loss: 7.33698585e-07
Iter: 1761 loss: 7.33587058e-07
Iter: 1762 loss: 7.34969e-07
Iter: 1763 loss: 7.33573415e-07
Iter: 1764 loss: 7.33455295e-07
Iter: 1765 loss: 7.33443585e-07
Iter: 1766 loss: 7.33390038e-07
Iter: 1767 loss: 7.33296133e-07
Iter: 1768 loss: 7.3325549e-07
Iter: 1769 loss: 7.3319444e-07
Iter: 1770 loss: 7.33027605e-07
Iter: 1771 loss: 7.33479908e-07
Iter: 1772 loss: 7.32984176e-07
Iter: 1773 loss: 7.32854915e-07
Iter: 1774 loss: 7.32932278e-07
Iter: 1775 loss: 7.32746059e-07
Iter: 1776 loss: 7.3260469e-07
Iter: 1777 loss: 7.3258343e-07
Iter: 1778 loss: 7.3250385e-07
Iter: 1779 loss: 7.32453145e-07
Iter: 1780 loss: 7.32437684e-07
Iter: 1781 loss: 7.32267608e-07
Iter: 1782 loss: 7.33391289e-07
Iter: 1783 loss: 7.32272383e-07
Iter: 1784 loss: 7.32195588e-07
Iter: 1785 loss: 7.32225374e-07
Iter: 1786 loss: 7.32114188e-07
Iter: 1787 loss: 7.32043418e-07
Iter: 1788 loss: 7.33158799e-07
Iter: 1789 loss: 7.32041315e-07
Iter: 1790 loss: 7.319627e-07
Iter: 1791 loss: 7.32000728e-07
Iter: 1792 loss: 7.31902219e-07
Iter: 1793 loss: 7.31842249e-07
Iter: 1794 loss: 7.3198953e-07
Iter: 1795 loss: 7.31822411e-07
Iter: 1796 loss: 7.31694058e-07
Iter: 1797 loss: 7.31707928e-07
Iter: 1798 loss: 7.3162488e-07
Iter: 1799 loss: 7.31472255e-07
Iter: 1800 loss: 7.31189289e-07
Iter: 1801 loss: 7.31182581e-07
Iter: 1802 loss: 7.30957197e-07
Iter: 1803 loss: 7.33451827e-07
Iter: 1804 loss: 7.30968e-07
Iter: 1805 loss: 7.30769102e-07
Iter: 1806 loss: 7.3072232e-07
Iter: 1807 loss: 7.30609258e-07
Iter: 1808 loss: 7.30663373e-07
Iter: 1809 loss: 7.30534055e-07
Iter: 1810 loss: 7.30489489e-07
Iter: 1811 loss: 7.30377167e-07
Iter: 1812 loss: 7.32108163e-07
Iter: 1813 loss: 7.30364775e-07
Iter: 1814 loss: 7.3031913e-07
Iter: 1815 loss: 7.30323336e-07
Iter: 1816 loss: 7.302516e-07
Iter: 1817 loss: 7.30189811e-07
Iter: 1818 loss: 7.30157524e-07
Iter: 1819 loss: 7.30012289e-07
Iter: 1820 loss: 7.2998256e-07
Iter: 1821 loss: 7.29883197e-07
Iter: 1822 loss: 7.29739668e-07
Iter: 1823 loss: 7.30917463e-07
Iter: 1824 loss: 7.29741146e-07
Iter: 1825 loss: 7.29633541e-07
Iter: 1826 loss: 7.29642124e-07
Iter: 1827 loss: 7.2951218e-07
Iter: 1828 loss: 7.29382e-07
Iter: 1829 loss: 7.30959528e-07
Iter: 1830 loss: 7.29392355e-07
Iter: 1831 loss: 7.2932346e-07
Iter: 1832 loss: 7.2922046e-07
Iter: 1833 loss: 7.29227509e-07
Iter: 1834 loss: 7.29124395e-07
Iter: 1835 loss: 7.28985356e-07
Iter: 1836 loss: 7.28957275e-07
Iter: 1837 loss: 7.28716373e-07
Iter: 1838 loss: 7.29713577e-07
Iter: 1839 loss: 7.28657142e-07
Iter: 1840 loss: 7.28442e-07
Iter: 1841 loss: 7.30855277e-07
Iter: 1842 loss: 7.28446253e-07
Iter: 1843 loss: 7.28359737e-07
Iter: 1844 loss: 7.28361897e-07
Iter: 1845 loss: 7.28265377e-07
Iter: 1846 loss: 7.28104339e-07
Iter: 1847 loss: 7.31434397e-07
Iter: 1848 loss: 7.28089731e-07
Iter: 1849 loss: 7.27950692e-07
Iter: 1850 loss: 7.30221927e-07
Iter: 1851 loss: 7.27953193e-07
Iter: 1852 loss: 7.27797556e-07
Iter: 1853 loss: 7.27627821e-07
Iter: 1854 loss: 7.27613724e-07
Iter: 1855 loss: 7.2747639e-07
Iter: 1856 loss: 7.27473548e-07
Iter: 1857 loss: 7.27362e-07
Iter: 1858 loss: 7.27172619e-07
Iter: 1859 loss: 7.27165798e-07
Iter: 1860 loss: 7.26987423e-07
Iter: 1861 loss: 7.29328178e-07
Iter: 1862 loss: 7.26991061e-07
Iter: 1863 loss: 7.26817689e-07
Iter: 1864 loss: 7.26762664e-07
Iter: 1865 loss: 7.26681264e-07
Iter: 1866 loss: 7.26549274e-07
Iter: 1867 loss: 7.26587245e-07
Iter: 1868 loss: 7.2644491e-07
Iter: 1869 loss: 7.26307803e-07
Iter: 1870 loss: 7.26462133e-07
Iter: 1871 loss: 7.26234703e-07
Iter: 1872 loss: 7.26082817e-07
Iter: 1873 loss: 7.26878056e-07
Iter: 1874 loss: 7.26050132e-07
Iter: 1875 loss: 7.25859763e-07
Iter: 1876 loss: 7.26160124e-07
Iter: 1877 loss: 7.2579968e-07
Iter: 1878 loss: 7.25614143e-07
Iter: 1879 loss: 7.28261e-07
Iter: 1880 loss: 7.2563455e-07
Iter: 1881 loss: 7.25450946e-07
Iter: 1882 loss: 7.252778e-07
Iter: 1883 loss: 7.25257792e-07
Iter: 1884 loss: 7.25181735e-07
Iter: 1885 loss: 7.25142172e-07
Iter: 1886 loss: 7.25087546e-07
Iter: 1887 loss: 7.24967322e-07
Iter: 1888 loss: 7.27576094e-07
Iter: 1889 loss: 7.24941e-07
Iter: 1890 loss: 7.24860399e-07
Iter: 1891 loss: 7.24868e-07
Iter: 1892 loss: 7.24759843e-07
Iter: 1893 loss: 7.24589484e-07
Iter: 1894 loss: 7.24604e-07
Iter: 1895 loss: 7.24531105e-07
Iter: 1896 loss: 7.24501e-07
Iter: 1897 loss: 7.2445215e-07
Iter: 1898 loss: 7.24270535e-07
Iter: 1899 loss: 7.27512941e-07
Iter: 1900 loss: 7.24269796e-07
Iter: 1901 loss: 7.24128e-07
Iter: 1902 loss: 7.24282472e-07
Iter: 1903 loss: 7.24044753e-07
Iter: 1904 loss: 7.2389048e-07
Iter: 1905 loss: 7.24341703e-07
Iter: 1906 loss: 7.23839719e-07
Iter: 1907 loss: 7.23642472e-07
Iter: 1908 loss: 7.24227903e-07
Iter: 1909 loss: 7.23603307e-07
Iter: 1910 loss: 7.23436528e-07
Iter: 1911 loss: 7.23592166e-07
Iter: 1912 loss: 7.23375251e-07
Iter: 1913 loss: 7.23126675e-07
Iter: 1914 loss: 7.25679683e-07
Iter: 1915 loss: 7.23121161e-07
Iter: 1916 loss: 7.22977802e-07
Iter: 1917 loss: 7.22874859e-07
Iter: 1918 loss: 7.22820289e-07
Iter: 1919 loss: 7.22651691e-07
Iter: 1920 loss: 7.23439939e-07
Iter: 1921 loss: 7.22627874e-07
Iter: 1922 loss: 7.22460186e-07
Iter: 1923 loss: 7.23469554e-07
Iter: 1924 loss: 7.22433185e-07
Iter: 1925 loss: 7.22355935e-07
Iter: 1926 loss: 7.22220875e-07
Iter: 1927 loss: 7.2220314e-07
Iter: 1928 loss: 7.22199786e-07
Iter: 1929 loss: 7.22137e-07
Iter: 1930 loss: 7.2209167e-07
Iter: 1931 loss: 7.21888568e-07
Iter: 1932 loss: 7.2266846e-07
Iter: 1933 loss: 7.21828599e-07
Iter: 1934 loss: 7.21758681e-07
Iter: 1935 loss: 7.21692686e-07
Iter: 1936 loss: 7.21587867e-07
Iter: 1937 loss: 7.21394088e-07
Iter: 1938 loss: 7.2501075e-07
Iter: 1939 loss: 7.21382776e-07
Iter: 1940 loss: 7.21170636e-07
Iter: 1941 loss: 7.21901472e-07
Iter: 1942 loss: 7.21105948e-07
Iter: 1943 loss: 7.20908076e-07
Iter: 1944 loss: 7.21271533e-07
Iter: 1945 loss: 7.2084822e-07
Iter: 1946 loss: 7.20745e-07
Iter: 1947 loss: 7.21731e-07
Iter: 1948 loss: 7.20722653e-07
Iter: 1949 loss: 7.20573382e-07
Iter: 1950 loss: 7.20996752e-07
Iter: 1951 loss: 7.20544335e-07
Iter: 1952 loss: 7.20406e-07
Iter: 1953 loss: 7.2039245e-07
Iter: 1954 loss: 7.20302751e-07
Iter: 1955 loss: 7.2013512e-07
Iter: 1956 loss: 7.20325147e-07
Iter: 1957 loss: 7.20015294e-07
Iter: 1958 loss: 7.19767968e-07
Iter: 1959 loss: 7.20157e-07
Iter: 1960 loss: 7.196669e-07
Iter: 1961 loss: 7.19522859e-07
Iter: 1962 loss: 7.20298317e-07
Iter: 1963 loss: 7.19500179e-07
Iter: 1964 loss: 7.19347895e-07
Iter: 1965 loss: 7.19494039e-07
Iter: 1966 loss: 7.19252625e-07
Iter: 1967 loss: 7.1913837e-07
Iter: 1968 loss: 7.19603577e-07
Iter: 1969 loss: 7.19063337e-07
Iter: 1970 loss: 7.18900253e-07
Iter: 1971 loss: 7.19290711e-07
Iter: 1972 loss: 7.18814647e-07
Iter: 1973 loss: 7.18696867e-07
Iter: 1974 loss: 7.18444312e-07
Iter: 1975 loss: 7.22068705e-07
Iter: 1976 loss: 7.18441697e-07
Iter: 1977 loss: 7.18089382e-07
Iter: 1978 loss: 7.19390584e-07
Iter: 1979 loss: 7.1800514e-07
Iter: 1980 loss: 7.17734849e-07
Iter: 1981 loss: 7.18181468e-07
Iter: 1982 loss: 7.17612e-07
Iter: 1983 loss: 7.17451542e-07
Iter: 1984 loss: 7.17448302e-07
Iter: 1985 loss: 7.17279647e-07
Iter: 1986 loss: 7.1717534e-07
Iter: 1987 loss: 7.17101e-07
Iter: 1988 loss: 7.16979571e-07
Iter: 1989 loss: 7.18129627e-07
Iter: 1990 loss: 7.16988723e-07
Iter: 1991 loss: 7.16849229e-07
Iter: 1992 loss: 7.16917839e-07
Iter: 1993 loss: 7.16778118e-07
Iter: 1994 loss: 7.1666e-07
Iter: 1995 loss: 7.1730318e-07
Iter: 1996 loss: 7.16622253e-07
Iter: 1997 loss: 7.16531417e-07
Iter: 1998 loss: 7.16933926e-07
Iter: 1999 loss: 7.16499926e-07
Iter: 2000 loss: 7.1640028e-07
Iter: 2001 loss: 7.16236e-07
Iter: 2002 loss: 7.16224406e-07
Iter: 2003 loss: 7.16161196e-07
Iter: 2004 loss: 7.16123225e-07
Iter: 2005 loss: 7.16043473e-07
Iter: 2006 loss: 7.15870272e-07
Iter: 2007 loss: 7.16505554e-07
Iter: 2008 loss: 7.15815588e-07
Iter: 2009 loss: 7.15530859e-07
Iter: 2010 loss: 7.15424903e-07
Iter: 2011 loss: 7.15274382e-07
Iter: 2012 loss: 7.1495117e-07
Iter: 2013 loss: 7.14945941e-07
Iter: 2014 loss: 7.14757107e-07
Iter: 2015 loss: 7.15369367e-07
Iter: 2016 loss: 7.14719363e-07
Iter: 2017 loss: 7.1454167e-07
Iter: 2018 loss: 7.16475711e-07
Iter: 2019 loss: 7.14532462e-07
Iter: 2020 loss: 7.14431678e-07
Iter: 2021 loss: 7.14131488e-07
Iter: 2022 loss: 7.17252078e-07
Iter: 2023 loss: 7.14102953e-07
Iter: 2024 loss: 7.14016664e-07
Iter: 2025 loss: 7.13940608e-07
Iter: 2026 loss: 7.13814529e-07
Iter: 2027 loss: 7.13725967e-07
Iter: 2028 loss: 7.13664406e-07
Iter: 2029 loss: 7.13502459e-07
Iter: 2030 loss: 7.14668829e-07
Iter: 2031 loss: 7.13479835e-07
Iter: 2032 loss: 7.13311749e-07
Iter: 2033 loss: 7.13341819e-07
Iter: 2034 loss: 7.13172199e-07
Iter: 2035 loss: 7.12988594e-07
Iter: 2036 loss: 7.1274826e-07
Iter: 2037 loss: 7.12752922e-07
Iter: 2038 loss: 7.12680276e-07
Iter: 2039 loss: 7.12614792e-07
Iter: 2040 loss: 7.1243926e-07
Iter: 2041 loss: 7.12095925e-07
Iter: 2042 loss: 7.17850639e-07
Iter: 2043 loss: 7.1208683e-07
Iter: 2044 loss: 7.11812277e-07
Iter: 2045 loss: 7.1146269e-07
Iter: 2046 loss: 7.11427333e-07
Iter: 2047 loss: 7.11146868e-07
Iter: 2048 loss: 7.11132088e-07
Iter: 2049 loss: 7.10885729e-07
Iter: 2050 loss: 7.12009864e-07
Iter: 2051 loss: 7.10837583e-07
Iter: 2052 loss: 7.10582128e-07
Iter: 2053 loss: 7.12060682e-07
Iter: 2054 loss: 7.10558083e-07
Iter: 2055 loss: 7.10421432e-07
Iter: 2056 loss: 7.10249594e-07
Iter: 2057 loss: 7.10237828e-07
Iter: 2058 loss: 7.10006077e-07
Iter: 2059 loss: 7.09980441e-07
Iter: 2060 loss: 7.098173e-07
Iter: 2061 loss: 7.09504775e-07
Iter: 2062 loss: 7.09505173e-07
Iter: 2063 loss: 7.09383528e-07
Iter: 2064 loss: 7.09377332e-07
Iter: 2065 loss: 7.09278311e-07
Iter: 2066 loss: 7.09028143e-07
Iter: 2067 loss: 7.09558492e-07
Iter: 2068 loss: 7.08932419e-07
Iter: 2069 loss: 7.08776952e-07
Iter: 2070 loss: 7.08731477e-07
Iter: 2071 loss: 7.0866173e-07
Iter: 2072 loss: 7.08482446e-07
Iter: 2073 loss: 7.08459e-07
Iter: 2074 loss: 7.08378764e-07
Iter: 2075 loss: 7.08234211e-07
Iter: 2076 loss: 7.08225741e-07
Iter: 2077 loss: 7.08041568e-07
Iter: 2078 loss: 7.07864615e-07
Iter: 2079 loss: 7.0785859e-07
Iter: 2080 loss: 7.07586423e-07
Iter: 2081 loss: 7.09259098e-07
Iter: 2082 loss: 7.07537424e-07
Iter: 2083 loss: 7.07323409e-07
Iter: 2084 loss: 7.08872449e-07
Iter: 2085 loss: 7.07292e-07
Iter: 2086 loss: 7.07082961e-07
Iter: 2087 loss: 7.07077447e-07
Iter: 2088 loss: 7.06916467e-07
Iter: 2089 loss: 7.06681476e-07
Iter: 2090 loss: 7.06587741e-07
Iter: 2091 loss: 7.06494632e-07
Iter: 2092 loss: 7.06298238e-07
Iter: 2093 loss: 7.06276808e-07
Iter: 2094 loss: 7.06080471e-07
Iter: 2095 loss: 7.05758112e-07
Iter: 2096 loss: 7.13641498e-07
Iter: 2097 loss: 7.05760669e-07
Iter: 2098 loss: 7.05617e-07
Iter: 2099 loss: 7.05572575e-07
Iter: 2100 loss: 7.0546173e-07
Iter: 2101 loss: 7.05167452e-07
Iter: 2102 loss: 7.07098e-07
Iter: 2103 loss: 7.05079515e-07
Iter: 2104 loss: 7.05033926e-07
Iter: 2105 loss: 7.04932177e-07
Iter: 2106 loss: 7.04829176e-07
Iter: 2107 loss: 7.04627382e-07
Iter: 2108 loss: 7.08e-07
Iter: 2109 loss: 7.046159e-07
Iter: 2110 loss: 7.04464128e-07
Iter: 2111 loss: 7.04182526e-07
Iter: 2112 loss: 7.04169736e-07
Iter: 2113 loss: 7.03842829e-07
Iter: 2114 loss: 7.06027549e-07
Iter: 2115 loss: 7.03840556e-07
Iter: 2116 loss: 7.03564069e-07
Iter: 2117 loss: 7.0403479e-07
Iter: 2118 loss: 7.03423552e-07
Iter: 2119 loss: 7.0313888e-07
Iter: 2120 loss: 7.05082414e-07
Iter: 2121 loss: 7.03098181e-07
Iter: 2122 loss: 7.02962268e-07
Iter: 2123 loss: 7.02751777e-07
Iter: 2124 loss: 7.02755585e-07
Iter: 2125 loss: 7.02561351e-07
Iter: 2126 loss: 7.03512569e-07
Iter: 2127 loss: 7.02538273e-07
Iter: 2128 loss: 7.02350349e-07
Iter: 2129 loss: 7.03269166e-07
Iter: 2130 loss: 7.02323291e-07
Iter: 2131 loss: 7.02171633e-07
Iter: 2132 loss: 7.02605689e-07
Iter: 2133 loss: 7.02158559e-07
Iter: 2134 loss: 7.02047373e-07
Iter: 2135 loss: 7.01734052e-07
Iter: 2136 loss: 7.04045e-07
Iter: 2137 loss: 7.01688e-07
Iter: 2138 loss: 7.01227691e-07
Iter: 2139 loss: 7.01910437e-07
Iter: 2140 loss: 7.0101953e-07
Iter: 2141 loss: 7.01502586e-07
Iter: 2142 loss: 7.00865542e-07
Iter: 2143 loss: 7.00801e-07
Iter: 2144 loss: 7.00577971e-07
Iter: 2145 loss: 7.01413683e-07
Iter: 2146 loss: 7.0048344e-07
Iter: 2147 loss: 7.00255441e-07
Iter: 2148 loss: 7.01202453e-07
Iter: 2149 loss: 7.00184046e-07
Iter: 2150 loss: 6.99990949e-07
Iter: 2151 loss: 7.02801287e-07
Iter: 2152 loss: 6.99997713e-07
Iter: 2153 loss: 6.99874249e-07
Iter: 2154 loss: 7.00050691e-07
Iter: 2155 loss: 6.99811608e-07
Iter: 2156 loss: 6.99610723e-07
Iter: 2157 loss: 6.99607369e-07
Iter: 2158 loss: 6.99448378e-07
Iter: 2159 loss: 6.99217708e-07
Iter: 2160 loss: 6.98923145e-07
Iter: 2161 loss: 6.98900863e-07
Iter: 2162 loss: 6.98928204e-07
Iter: 2163 loss: 6.9877558e-07
Iter: 2164 loss: 6.98631425e-07
Iter: 2165 loss: 6.98403539e-07
Iter: 2166 loss: 7.03965156e-07
Iter: 2167 loss: 6.98401664e-07
Iter: 2168 loss: 6.98331178e-07
Iter: 2169 loss: 6.98307417e-07
Iter: 2170 loss: 6.98190888e-07
Iter: 2171 loss: 6.97949531e-07
Iter: 2172 loss: 6.97953965e-07
Iter: 2173 loss: 6.97779683e-07
Iter: 2174 loss: 7.00197859e-07
Iter: 2175 loss: 6.97764563e-07
Iter: 2176 loss: 6.9763189e-07
Iter: 2177 loss: 6.97306348e-07
Iter: 2178 loss: 7.0149423e-07
Iter: 2179 loss: 6.97270593e-07
Iter: 2180 loss: 6.96858251e-07
Iter: 2181 loss: 6.97795144e-07
Iter: 2182 loss: 6.96710913e-07
Iter: 2183 loss: 6.96460177e-07
Iter: 2184 loss: 7.00154942e-07
Iter: 2185 loss: 6.96484904e-07
Iter: 2186 loss: 6.96261509e-07
Iter: 2187 loss: 6.98696681e-07
Iter: 2188 loss: 6.96284e-07
Iter: 2189 loss: 6.96141228e-07
Iter: 2190 loss: 6.96388611e-07
Iter: 2191 loss: 6.96078075e-07
Iter: 2192 loss: 6.95916e-07
Iter: 2193 loss: 6.95899587e-07
Iter: 2194 loss: 6.95754466e-07
Iter: 2195 loss: 6.95622305e-07
Iter: 2196 loss: 6.96388497e-07
Iter: 2197 loss: 6.95609458e-07
Iter: 2198 loss: 6.95442509e-07
Iter: 2199 loss: 6.958835e-07
Iter: 2200 loss: 6.95383505e-07
Iter: 2201 loss: 6.95253675e-07
Iter: 2202 loss: 6.95113101e-07
Iter: 2203 loss: 6.9509008e-07
Iter: 2204 loss: 6.94912956e-07
Iter: 2205 loss: 6.94904202e-07
Iter: 2206 loss: 6.94779089e-07
Iter: 2207 loss: 6.94725827e-07
Iter: 2208 loss: 6.94670121e-07
Iter: 2209 loss: 6.94423e-07
Iter: 2210 loss: 6.94635673e-07
Iter: 2211 loss: 6.94256869e-07
Iter: 2212 loss: 6.9408668e-07
Iter: 2213 loss: 6.9362693e-07
Iter: 2214 loss: 6.98493636e-07
Iter: 2215 loss: 6.93582592e-07
Iter: 2216 loss: 6.93325774e-07
Iter: 2217 loss: 6.93303946e-07
Iter: 2218 loss: 6.93195489e-07
Iter: 2219 loss: 6.93072e-07
Iter: 2220 loss: 6.93005063e-07
Iter: 2221 loss: 6.92847152e-07
Iter: 2222 loss: 6.92855167e-07
Iter: 2223 loss: 6.92670483e-07
Iter: 2224 loss: 6.92763933e-07
Iter: 2225 loss: 6.9257311e-07
Iter: 2226 loss: 6.92312256e-07
Iter: 2227 loss: 6.92474657e-07
Iter: 2228 loss: 6.92170318e-07
Iter: 2229 loss: 6.91922196e-07
Iter: 2230 loss: 6.94616176e-07
Iter: 2231 loss: 6.91903551e-07
Iter: 2232 loss: 6.91663786e-07
Iter: 2233 loss: 6.91324203e-07
Iter: 2234 loss: 6.91289358e-07
Iter: 2235 loss: 6.91248488e-07
Iter: 2236 loss: 6.91158448e-07
Iter: 2237 loss: 6.91074092e-07
Iter: 2238 loss: 6.90828358e-07
Iter: 2239 loss: 6.94626e-07
Iter: 2240 loss: 6.90846832e-07
Iter: 2241 loss: 6.9070461e-07
Iter: 2242 loss: 6.90694321e-07
Iter: 2243 loss: 6.90569436e-07
Iter: 2244 loss: 6.90221555e-07
Iter: 2245 loss: 6.92724086e-07
Iter: 2246 loss: 6.90140951e-07
Iter: 2247 loss: 6.89796479e-07
Iter: 2248 loss: 6.90067338e-07
Iter: 2249 loss: 6.8958667e-07
Iter: 2250 loss: 6.89220656e-07
Iter: 2251 loss: 6.90323134e-07
Iter: 2252 loss: 6.8910316e-07
Iter: 2253 loss: 6.8888005e-07
Iter: 2254 loss: 6.88880391e-07
Iter: 2255 loss: 6.88748742e-07
Iter: 2256 loss: 6.88725436e-07
Iter: 2257 loss: 6.88624e-07
Iter: 2258 loss: 6.88391083e-07
Iter: 2259 loss: 6.91260936e-07
Iter: 2260 loss: 6.88342482e-07
Iter: 2261 loss: 6.88010175e-07
Iter: 2262 loss: 6.89743672e-07
Iter: 2263 loss: 6.87972829e-07
Iter: 2264 loss: 6.87717375e-07
Iter: 2265 loss: 6.90518505e-07
Iter: 2266 loss: 6.8771817e-07
Iter: 2267 loss: 6.87595275e-07
Iter: 2268 loss: 6.87320949e-07
Iter: 2269 loss: 6.92351705e-07
Iter: 2270 loss: 6.87307306e-07
Iter: 2271 loss: 6.87222723e-07
Iter: 2272 loss: 6.87142801e-07
Iter: 2273 loss: 6.87078796e-07
Iter: 2274 loss: 6.86915882e-07
Iter: 2275 loss: 6.900367e-07
Iter: 2276 loss: 6.86919293e-07
Iter: 2277 loss: 6.86822034e-07
Iter: 2278 loss: 6.86824137e-07
Iter: 2279 loss: 6.86742851e-07
Iter: 2280 loss: 6.86593182e-07
Iter: 2281 loss: 6.87865509e-07
Iter: 2282 loss: 6.86551743e-07
Iter: 2283 loss: 6.86258829e-07
Iter: 2284 loss: 6.86015483e-07
Iter: 2285 loss: 6.85923283e-07
Iter: 2286 loss: 6.85437044e-07
Iter: 2287 loss: 6.85853706e-07
Iter: 2288 loss: 6.85120369e-07
Iter: 2289 loss: 6.850604e-07
Iter: 2290 loss: 6.84909537e-07
Iter: 2291 loss: 6.84670624e-07
Iter: 2292 loss: 6.85804707e-07
Iter: 2293 loss: 6.8465e-07
Iter: 2294 loss: 6.84513566e-07
Iter: 2295 loss: 6.84517431e-07
Iter: 2296 loss: 6.84408064e-07
Iter: 2297 loss: 6.84263114e-07
Iter: 2298 loss: 6.85101384e-07
Iter: 2299 loss: 6.84222186e-07
Iter: 2300 loss: 6.84059671e-07
Iter: 2301 loss: 6.83984e-07
Iter: 2302 loss: 6.8388772e-07
Iter: 2303 loss: 6.83677285e-07
Iter: 2304 loss: 6.84714848e-07
Iter: 2305 loss: 6.83628741e-07
Iter: 2306 loss: 6.83376925e-07
Iter: 2307 loss: 6.84064503e-07
Iter: 2308 loss: 6.83258691e-07
Iter: 2309 loss: 6.83113399e-07
Iter: 2310 loss: 6.83461167e-07
Iter: 2311 loss: 6.83071335e-07
Iter: 2312 loss: 6.8285e-07
Iter: 2313 loss: 6.82659334e-07
Iter: 2314 loss: 6.82591804e-07
Iter: 2315 loss: 6.82368068e-07
Iter: 2316 loss: 6.82076802e-07
Iter: 2317 loss: 6.82054292e-07
Iter: 2318 loss: 6.81535312e-07
Iter: 2319 loss: 6.82055088e-07
Iter: 2320 loss: 6.81238646e-07
Iter: 2321 loss: 6.80718585e-07
Iter: 2322 loss: 6.85610758e-07
Iter: 2323 loss: 6.8066862e-07
Iter: 2324 loss: 6.80328867e-07
Iter: 2325 loss: 6.80328583e-07
Iter: 2326 loss: 6.80145718e-07
Iter: 2327 loss: 6.80149753e-07
Iter: 2328 loss: 6.79979621e-07
Iter: 2329 loss: 6.79777827e-07
Iter: 2330 loss: 6.81492281e-07
Iter: 2331 loss: 6.79774075e-07
Iter: 2332 loss: 6.79604568e-07
Iter: 2333 loss: 6.8011127e-07
Iter: 2334 loss: 6.79559548e-07
Iter: 2335 loss: 6.79438642e-07
Iter: 2336 loss: 6.79601499e-07
Iter: 2337 loss: 6.7939277e-07
Iter: 2338 loss: 6.79297443e-07
Iter: 2339 loss: 6.80339326e-07
Iter: 2340 loss: 6.79308528e-07
Iter: 2341 loss: 6.79244e-07
Iter: 2342 loss: 6.79058644e-07
Iter: 2343 loss: 6.80824e-07
Iter: 2344 loss: 6.7900794e-07
Iter: 2345 loss: 6.78778633e-07
Iter: 2346 loss: 6.82166956e-07
Iter: 2347 loss: 6.78788e-07
Iter: 2348 loss: 6.78626293e-07
Iter: 2349 loss: 6.78248057e-07
Iter: 2350 loss: 6.82074415e-07
Iter: 2351 loss: 6.78204458e-07
Iter: 2352 loss: 6.77895287e-07
Iter: 2353 loss: 6.79512254e-07
Iter: 2354 loss: 6.77833214e-07
Iter: 2355 loss: 6.77623575e-07
Iter: 2356 loss: 6.79612867e-07
Iter: 2357 loss: 6.77613855e-07
Iter: 2358 loss: 6.77496246e-07
Iter: 2359 loss: 6.77492665e-07
Iter: 2360 loss: 6.7741189e-07
Iter: 2361 loss: 6.77214928e-07
Iter: 2362 loss: 6.79902655e-07
Iter: 2363 loss: 6.7721129e-07
Iter: 2364 loss: 6.76996706e-07
Iter: 2365 loss: 6.79388847e-07
Iter: 2366 loss: 6.769788e-07
Iter: 2367 loss: 6.76761829e-07
Iter: 2368 loss: 6.76848117e-07
Iter: 2369 loss: 6.76606078e-07
Iter: 2370 loss: 6.76251773e-07
Iter: 2371 loss: 6.76444301e-07
Iter: 2372 loss: 6.76038496e-07
Iter: 2373 loss: 6.75865465e-07
Iter: 2374 loss: 6.75825277e-07
Iter: 2375 loss: 6.75696128e-07
Iter: 2376 loss: 6.75509568e-07
Iter: 2377 loss: 6.75515594e-07
Iter: 2378 loss: 6.7537303e-07
Iter: 2379 loss: 6.7538349e-07
Iter: 2380 loss: 6.75264062e-07
Iter: 2381 loss: 6.74987234e-07
Iter: 2382 loss: 6.78419553e-07
Iter: 2383 loss: 6.74948581e-07
Iter: 2384 loss: 6.74687954e-07
Iter: 2385 loss: 6.74614625e-07
Iter: 2386 loss: 6.74449e-07
Iter: 2387 loss: 6.74042838e-07
Iter: 2388 loss: 6.75290607e-07
Iter: 2389 loss: 6.739387e-07
Iter: 2390 loss: 6.73883051e-07
Iter: 2391 loss: 6.73746172e-07
Iter: 2392 loss: 6.73617535e-07
Iter: 2393 loss: 6.7354955e-07
Iter: 2394 loss: 6.73470595e-07
Iter: 2395 loss: 6.73315753e-07
Iter: 2396 loss: 6.73899933e-07
Iter: 2397 loss: 6.73267948e-07
Iter: 2398 loss: 6.73064619e-07
Iter: 2399 loss: 6.73592922e-07
Iter: 2400 loss: 6.73007662e-07
Iter: 2401 loss: 6.72767612e-07
Iter: 2402 loss: 6.73215368e-07
Iter: 2403 loss: 6.72665408e-07
Iter: 2404 loss: 6.72496242e-07
Iter: 2405 loss: 6.73659e-07
Iter: 2406 loss: 6.72498516e-07
Iter: 2407 loss: 6.7230485e-07
Iter: 2408 loss: 6.72281317e-07
Iter: 2409 loss: 6.72153192e-07
Iter: 2410 loss: 6.72001477e-07
Iter: 2411 loss: 6.73038926e-07
Iter: 2412 loss: 6.71986868e-07
Iter: 2413 loss: 6.71765747e-07
Iter: 2414 loss: 6.71838791e-07
Iter: 2415 loss: 6.71645751e-07
Iter: 2416 loss: 6.71471355e-07
Iter: 2417 loss: 6.71234886e-07
Iter: 2418 loss: 6.7124e-07
Iter: 2419 loss: 6.7093049e-07
Iter: 2420 loss: 6.71082375e-07
Iter: 2421 loss: 6.70739041e-07
Iter: 2422 loss: 6.70452039e-07
Iter: 2423 loss: 6.70440727e-07
Iter: 2424 loss: 6.70145937e-07
Iter: 2425 loss: 6.71313728e-07
Iter: 2426 loss: 6.70100121e-07
Iter: 2427 loss: 6.69966084e-07
Iter: 2428 loss: 6.70037707e-07
Iter: 2429 loss: 6.69878432e-07
Iter: 2430 loss: 6.69731662e-07
Iter: 2431 loss: 6.71342832e-07
Iter: 2432 loss: 6.69716314e-07
Iter: 2433 loss: 6.69598137e-07
Iter: 2434 loss: 6.69613428e-07
Iter: 2435 loss: 6.69529925e-07
Iter: 2436 loss: 6.69342683e-07
Iter: 2437 loss: 6.69787e-07
Iter: 2438 loss: 6.69288625e-07
Iter: 2439 loss: 6.69053804e-07
Iter: 2440 loss: 6.69703468e-07
Iter: 2441 loss: 6.69002418e-07
Iter: 2442 loss: 6.6883797e-07
Iter: 2443 loss: 6.68835867e-07
Iter: 2444 loss: 6.68731e-07
Iter: 2445 loss: 6.68495431e-07
Iter: 2446 loss: 6.70586928e-07
Iter: 2447 loss: 6.68461098e-07
Iter: 2448 loss: 6.68340817e-07
Iter: 2449 loss: 6.68096845e-07
Iter: 2450 loss: 6.72055421e-07
Iter: 2451 loss: 6.68082066e-07
Iter: 2452 loss: 6.67892095e-07
Iter: 2453 loss: 6.68459165e-07
Iter: 2454 loss: 6.67817517e-07
Iter: 2455 loss: 6.67667734e-07
Iter: 2456 loss: 6.68782377e-07
Iter: 2457 loss: 6.67613335e-07
Iter: 2458 loss: 6.6741751e-07
Iter: 2459 loss: 6.68572852e-07
Iter: 2460 loss: 6.67410347e-07
Iter: 2461 loss: 6.67276e-07
Iter: 2462 loss: 6.67134657e-07
Iter: 2463 loss: 6.67103961e-07
Iter: 2464 loss: 6.66950598e-07
Iter: 2465 loss: 6.66943777e-07
Iter: 2466 loss: 6.66845835e-07
Iter: 2467 loss: 6.66884716e-07
Iter: 2468 loss: 6.66788878e-07
Iter: 2469 loss: 6.66664505e-07
Iter: 2470 loss: 6.66967935e-07
Iter: 2471 loss: 6.66578444e-07
Iter: 2472 loss: 6.66456799e-07
Iter: 2473 loss: 6.6705536e-07
Iter: 2474 loss: 6.66438382e-07
Iter: 2475 loss: 6.66327878e-07
Iter: 2476 loss: 6.66231e-07
Iter: 2477 loss: 6.66225731e-07
Iter: 2478 loss: 6.66057588e-07
Iter: 2479 loss: 6.66067876e-07
Iter: 2480 loss: 6.65979826e-07
Iter: 2481 loss: 6.65709308e-07
Iter: 2482 loss: 6.67279323e-07
Iter: 2483 loss: 6.65633479e-07
Iter: 2484 loss: 6.65361085e-07
Iter: 2485 loss: 6.66729818e-07
Iter: 2486 loss: 6.65260586e-07
Iter: 2487 loss: 6.65052937e-07
Iter: 2488 loss: 6.67525967e-07
Iter: 2489 loss: 6.65047708e-07
Iter: 2490 loss: 6.64877916e-07
Iter: 2491 loss: 6.66136884e-07
Iter: 2492 loss: 6.64838581e-07
Iter: 2493 loss: 6.64730351e-07
Iter: 2494 loss: 6.64532593e-07
Iter: 2495 loss: 6.69787937e-07
Iter: 2496 loss: 6.64541631e-07
Iter: 2497 loss: 6.6430141e-07
Iter: 2498 loss: 6.67395966e-07
Iter: 2499 loss: 6.64298454e-07
Iter: 2500 loss: 6.64158733e-07
Iter: 2501 loss: 6.63932042e-07
Iter: 2502 loss: 6.6393568e-07
Iter: 2503 loss: 6.63614856e-07
Iter: 2504 loss: 6.66133701e-07
Iter: 2505 loss: 6.63595074e-07
Iter: 2506 loss: 6.63387368e-07
Iter: 2507 loss: 6.63210244e-07
Iter: 2508 loss: 6.63165679e-07
Iter: 2509 loss: 6.62858838e-07
Iter: 2510 loss: 6.63965693e-07
Iter: 2511 loss: 6.62797277e-07
Iter: 2512 loss: 6.62669663e-07
Iter: 2513 loss: 6.6263442e-07
Iter: 2514 loss: 6.62553418e-07
Iter: 2515 loss: 6.62248567e-07
Iter: 2516 loss: 6.63176593e-07
Iter: 2517 loss: 6.62125899e-07
Iter: 2518 loss: 6.6165228e-07
Iter: 2519 loss: 6.62124364e-07
Iter: 2520 loss: 6.61405522e-07
Iter: 2521 loss: 6.6107e-07
Iter: 2522 loss: 6.64585059e-07
Iter: 2523 loss: 6.61062188e-07
Iter: 2524 loss: 6.60966862e-07
Iter: 2525 loss: 6.60948672e-07
Iter: 2526 loss: 6.60836e-07
Iter: 2527 loss: 6.60699698e-07
Iter: 2528 loss: 6.60695946e-07
Iter: 2529 loss: 6.60571459e-07
Iter: 2530 loss: 6.60562819e-07
Iter: 2531 loss: 6.60461069e-07
Iter: 2532 loss: 6.6022244e-07
Iter: 2533 loss: 6.64508661e-07
Iter: 2534 loss: 6.60215505e-07
Iter: 2535 loss: 6.60015644e-07
Iter: 2536 loss: 6.60006037e-07
Iter: 2537 loss: 6.59887917e-07
Iter: 2538 loss: 6.59677085e-07
Iter: 2539 loss: 6.59676516e-07
Iter: 2540 loss: 6.59399234e-07
Iter: 2541 loss: 6.60868864e-07
Iter: 2542 loss: 6.59347563e-07
Iter: 2543 loss: 6.59159468e-07
Iter: 2544 loss: 6.6032959e-07
Iter: 2545 loss: 6.59113368e-07
Iter: 2546 loss: 6.58920953e-07
Iter: 2547 loss: 6.59873649e-07
Iter: 2548 loss: 6.58874967e-07
Iter: 2549 loss: 6.5878e-07
Iter: 2550 loss: 6.58574095e-07
Iter: 2551 loss: 6.61129093e-07
Iter: 2552 loss: 6.58562726e-07
Iter: 2553 loss: 6.58326258e-07
Iter: 2554 loss: 6.58336717e-07
Iter: 2555 loss: 6.58155614e-07
Iter: 2556 loss: 6.57985368e-07
Iter: 2557 loss: 6.57797784e-07
Iter: 2558 loss: 6.57773569e-07
Iter: 2559 loss: 6.57542955e-07
Iter: 2560 loss: 6.57529881e-07
Iter: 2561 loss: 6.57372141e-07
Iter: 2562 loss: 6.57189162e-07
Iter: 2563 loss: 6.57186206e-07
Iter: 2564 loss: 6.57044382e-07
Iter: 2565 loss: 6.57365831e-07
Iter: 2566 loss: 6.57015846e-07
Iter: 2567 loss: 6.56926375e-07
Iter: 2568 loss: 6.57082182e-07
Iter: 2569 loss: 6.56880502e-07
Iter: 2570 loss: 6.56710142e-07
Iter: 2571 loss: 6.56442353e-07
Iter: 2572 loss: 6.5645429e-07
Iter: 2573 loss: 6.56264774e-07
Iter: 2574 loss: 6.5796462e-07
Iter: 2575 loss: 6.56268e-07
Iter: 2576 loss: 6.56097313e-07
Iter: 2577 loss: 6.56249654e-07
Iter: 2578 loss: 6.56022621e-07
Iter: 2579 loss: 6.55872384e-07
Iter: 2580 loss: 6.58041245e-07
Iter: 2581 loss: 6.55875169e-07
Iter: 2582 loss: 6.55738063e-07
Iter: 2583 loss: 6.55547922e-07
Iter: 2584 loss: 6.55527629e-07
Iter: 2585 loss: 6.55352892e-07
Iter: 2586 loss: 6.55705207e-07
Iter: 2587 loss: 6.55269332e-07
Iter: 2588 loss: 6.55009273e-07
Iter: 2589 loss: 6.56603902e-07
Iter: 2590 loss: 6.54982955e-07
Iter: 2591 loss: 6.54843575e-07
Iter: 2592 loss: 6.54559813e-07
Iter: 2593 loss: 6.5894892e-07
Iter: 2594 loss: 6.54561063e-07
Iter: 2595 loss: 6.54245696e-07
Iter: 2596 loss: 6.54872053e-07
Iter: 2597 loss: 6.54105861e-07
Iter: 2598 loss: 6.53834888e-07
Iter: 2599 loss: 6.54492169e-07
Iter: 2600 loss: 6.53733309e-07
Iter: 2601 loss: 6.53603706e-07
Iter: 2602 loss: 6.53552888e-07
Iter: 2603 loss: 6.53446136e-07
Iter: 2604 loss: 6.53167206e-07
Iter: 2605 loss: 6.56373686e-07
Iter: 2606 loss: 6.53143047e-07
Iter: 2607 loss: 6.52987637e-07
Iter: 2608 loss: 6.52955748e-07
Iter: 2609 loss: 6.52738549e-07
Iter: 2610 loss: 6.52469453e-07
Iter: 2611 loss: 6.52443418e-07
Iter: 2612 loss: 6.52243386e-07
Iter: 2613 loss: 6.52246058e-07
Iter: 2614 loss: 6.52141921e-07
Iter: 2615 loss: 6.52207575e-07
Iter: 2616 loss: 6.52053529e-07
Iter: 2617 loss: 6.51914434e-07
Iter: 2618 loss: 6.52485426e-07
Iter: 2619 loss: 6.51903292e-07
Iter: 2620 loss: 6.51803475e-07
Iter: 2621 loss: 6.51589289e-07
Iter: 2622 loss: 6.54063911e-07
Iter: 2623 loss: 6.51571213e-07
Iter: 2624 loss: 6.51533924e-07
Iter: 2625 loss: 6.51429332e-07
Iter: 2626 loss: 6.51337643e-07
Iter: 2627 loss: 6.51025289e-07
Iter: 2628 loss: 6.53237635e-07
Iter: 2629 loss: 6.50990955e-07
Iter: 2630 loss: 6.50644097e-07
Iter: 2631 loss: 6.50646314e-07
Iter: 2632 loss: 6.50374318e-07
Iter: 2633 loss: 6.50061452e-07
Iter: 2634 loss: 6.50061111e-07
Iter: 2635 loss: 6.49832486e-07
Iter: 2636 loss: 6.50390234e-07
Iter: 2637 loss: 6.49759727e-07
Iter: 2638 loss: 6.49647802e-07
Iter: 2639 loss: 6.49836807e-07
Iter: 2640 loss: 6.49586582e-07
Iter: 2641 loss: 6.49427932e-07
Iter: 2642 loss: 6.50177356e-07
Iter: 2643 loss: 6.49403262e-07
Iter: 2644 loss: 6.49271215e-07
Iter: 2645 loss: 6.49101423e-07
Iter: 2646 loss: 6.49093749e-07
Iter: 2647 loss: 6.48819309e-07
Iter: 2648 loss: 6.50891877e-07
Iter: 2649 loss: 6.48801233e-07
Iter: 2650 loss: 6.48580226e-07
Iter: 2651 loss: 6.49397066e-07
Iter: 2652 loss: 6.48541857e-07
Iter: 2653 loss: 6.4835956e-07
Iter: 2654 loss: 6.48014918e-07
Iter: 2655 loss: 6.53084214e-07
Iter: 2656 loss: 6.48011508e-07
Iter: 2657 loss: 6.47740308e-07
Iter: 2658 loss: 6.47715524e-07
Iter: 2659 loss: 6.47432671e-07
Iter: 2660 loss: 6.47710067e-07
Iter: 2661 loss: 6.47277204e-07
Iter: 2662 loss: 6.471e-07
Iter: 2663 loss: 6.46896751e-07
Iter: 2664 loss: 6.4688578e-07
Iter: 2665 loss: 6.46610147e-07
Iter: 2666 loss: 6.46617877e-07
Iter: 2667 loss: 6.46375781e-07
Iter: 2668 loss: 6.47273737e-07
Iter: 2669 loss: 6.46344233e-07
Iter: 2670 loss: 6.4619627e-07
Iter: 2671 loss: 6.46198941e-07
Iter: 2672 loss: 6.46091962e-07
Iter: 2673 loss: 6.45913701e-07
Iter: 2674 loss: 6.48549587e-07
Iter: 2675 loss: 6.45908699e-07
Iter: 2676 loss: 6.45787e-07
Iter: 2677 loss: 6.45599073e-07
Iter: 2678 loss: 6.49185836e-07
Iter: 2679 loss: 6.45582645e-07
Iter: 2680 loss: 6.45318892e-07
Iter: 2681 loss: 6.48857053e-07
Iter: 2682 loss: 6.45319915e-07
Iter: 2683 loss: 6.45122327e-07
Iter: 2684 loss: 6.45727255e-07
Iter: 2685 loss: 6.45071339e-07
Iter: 2686 loss: 6.4491195e-07
Iter: 2687 loss: 6.44521208e-07
Iter: 2688 loss: 6.49632625e-07
Iter: 2689 loss: 6.4449722e-07
Iter: 2690 loss: 6.44096417e-07
Iter: 2691 loss: 6.46450303e-07
Iter: 2692 loss: 6.4406845e-07
Iter: 2693 loss: 6.43671626e-07
Iter: 2694 loss: 6.47716774e-07
Iter: 2695 loss: 6.43697376e-07
Iter: 2696 loss: 6.43533951e-07
Iter: 2697 loss: 6.43234102e-07
Iter: 2698 loss: 6.48651735e-07
Iter: 2699 loss: 6.43227054e-07
Iter: 2700 loss: 6.43019916e-07
Iter: 2701 loss: 6.45355271e-07
Iter: 2702 loss: 6.42995e-07
Iter: 2703 loss: 6.42765031e-07
Iter: 2704 loss: 6.43334261e-07
Iter: 2705 loss: 6.42685e-07
Iter: 2706 loss: 6.42474e-07
Iter: 2707 loss: 6.42545501e-07
Iter: 2708 loss: 6.42306929e-07
Iter: 2709 loss: 6.42166356e-07
Iter: 2710 loss: 6.42143448e-07
Iter: 2711 loss: 6.42045222e-07
Iter: 2712 loss: 6.41815745e-07
Iter: 2713 loss: 6.4544696e-07
Iter: 2714 loss: 6.41805173e-07
Iter: 2715 loss: 6.41594283e-07
Iter: 2716 loss: 6.41594283e-07
Iter: 2717 loss: 6.41462577e-07
Iter: 2718 loss: 6.4193074e-07
Iter: 2719 loss: 6.41443876e-07
Iter: 2720 loss: 6.4129506e-07
Iter: 2721 loss: 6.4120195e-07
Iter: 2722 loss: 6.41151416e-07
Iter: 2723 loss: 6.40981966e-07
Iter: 2724 loss: 6.41044551e-07
Iter: 2725 loss: 6.40885276e-07
Iter: 2726 loss: 6.4069809e-07
Iter: 2727 loss: 6.40685698e-07
Iter: 2728 loss: 6.40577241e-07
Iter: 2729 loss: 6.40213102e-07
Iter: 2730 loss: 6.42138502e-07
Iter: 2731 loss: 6.40110557e-07
Iter: 2732 loss: 6.39931272e-07
Iter: 2733 loss: 6.3987477e-07
Iter: 2734 loss: 6.39723908e-07
Iter: 2735 loss: 6.41026759e-07
Iter: 2736 loss: 6.39692416e-07
Iter: 2737 loss: 6.39577877e-07
Iter: 2738 loss: 6.39473569e-07
Iter: 2739 loss: 6.39437076e-07
Iter: 2740 loss: 6.39348627e-07
Iter: 2741 loss: 6.39328732e-07
Iter: 2742 loss: 6.39248697e-07
Iter: 2743 loss: 6.39094367e-07
Iter: 2744 loss: 6.42247528e-07
Iter: 2745 loss: 6.39080497e-07
Iter: 2746 loss: 6.38914116e-07
Iter: 2747 loss: 6.40543078e-07
Iter: 2748 loss: 6.38903771e-07
Iter: 2749 loss: 6.38779738e-07
Iter: 2750 loss: 6.38900815e-07
Iter: 2751 loss: 6.38692086e-07
Iter: 2752 loss: 6.38454594e-07
Iter: 2753 loss: 6.38491088e-07
Iter: 2754 loss: 6.38316408e-07
Iter: 2755 loss: 6.38105803e-07
Iter: 2756 loss: 6.3804714e-07
Iter: 2757 loss: 6.37902701e-07
Iter: 2758 loss: 6.37782364e-07
Iter: 2759 loss: 6.37737514e-07
Iter: 2760 loss: 6.37593644e-07
Iter: 2761 loss: 6.37211656e-07
Iter: 2762 loss: 6.40336509e-07
Iter: 2763 loss: 6.37154756e-07
Iter: 2764 loss: 6.36799086e-07
Iter: 2765 loss: 6.37863309e-07
Iter: 2766 loss: 6.36679943e-07
Iter: 2767 loss: 6.36497134e-07
Iter: 2768 loss: 6.36462346e-07
Iter: 2769 loss: 6.36342065e-07
Iter: 2770 loss: 6.3612066e-07
Iter: 2771 loss: 6.41376971e-07
Iter: 2772 loss: 6.36123843e-07
Iter: 2773 loss: 6.35975539e-07
Iter: 2774 loss: 6.35947288e-07
Iter: 2775 loss: 6.35813308e-07
Iter: 2776 loss: 6.35634933e-07
Iter: 2777 loss: 6.35589572e-07
Iter: 2778 loss: 6.35428762e-07
Iter: 2779 loss: 6.36430798e-07
Iter: 2780 loss: 6.35399147e-07
Iter: 2781 loss: 6.35201616e-07
Iter: 2782 loss: 6.35564334e-07
Iter: 2783 loss: 6.3513545e-07
Iter: 2784 loss: 6.3492746e-07
Iter: 2785 loss: 6.35150514e-07
Iter: 2786 loss: 6.34806725e-07
Iter: 2787 loss: 6.34576395e-07
Iter: 2788 loss: 6.34497383e-07
Iter: 2789 loss: 6.34358969e-07
Iter: 2790 loss: 6.34326511e-07
Iter: 2791 loss: 6.34243918e-07
Iter: 2792 loss: 6.34134892e-07
Iter: 2793 loss: 6.3390894e-07
Iter: 2794 loss: 6.37169421e-07
Iter: 2795 loss: 6.339028e-07
Iter: 2796 loss: 6.33729769e-07
Iter: 2797 loss: 6.33769389e-07
Iter: 2798 loss: 6.33565e-07
Iter: 2799 loss: 6.33567765e-07
Iter: 2800 loss: 6.33457546e-07
Iter: 2801 loss: 6.33368e-07
Iter: 2802 loss: 6.33171908e-07
Iter: 2803 loss: 6.35562e-07
Iter: 2804 loss: 6.33152922e-07
Iter: 2805 loss: 6.32956301e-07
Iter: 2806 loss: 6.33515e-07
Iter: 2807 loss: 6.32925889e-07
Iter: 2808 loss: 6.32667138e-07
Iter: 2809 loss: 6.3271159e-07
Iter: 2810 loss: 6.32493823e-07
Iter: 2811 loss: 6.32394062e-07
Iter: 2812 loss: 6.32625358e-07
Iter: 2813 loss: 6.32346143e-07
Iter: 2814 loss: 6.32191245e-07
Iter: 2815 loss: 6.32553565e-07
Iter: 2816 loss: 6.32144861e-07
Iter: 2817 loss: 6.32032709e-07
Iter: 2818 loss: 6.32327783e-07
Iter: 2819 loss: 6.31987746e-07
Iter: 2820 loss: 6.31845751e-07
Iter: 2821 loss: 6.3175321e-07
Iter: 2822 loss: 6.31693865e-07
Iter: 2823 loss: 6.31543116e-07
Iter: 2824 loss: 6.31541752e-07
Iter: 2825 loss: 6.31404305e-07
Iter: 2826 loss: 6.31569378e-07
Iter: 2827 loss: 6.31334387e-07
Iter: 2828 loss: 6.31195746e-07
Iter: 2829 loss: 6.31031298e-07
Iter: 2830 loss: 6.31032208e-07
Iter: 2831 loss: 6.30865657e-07
Iter: 2832 loss: 6.33203626e-07
Iter: 2833 loss: 6.30868328e-07
Iter: 2834 loss: 6.30688078e-07
Iter: 2835 loss: 6.31195689e-07
Iter: 2836 loss: 6.30617592e-07
Iter: 2837 loss: 6.30528632e-07
Iter: 2838 loss: 6.30691773e-07
Iter: 2839 loss: 6.30468435e-07
Iter: 2840 loss: 6.30341276e-07
Iter: 2841 loss: 6.30804834e-07
Iter: 2842 loss: 6.3029313e-07
Iter: 2843 loss: 6.30191323e-07
Iter: 2844 loss: 6.30040233e-07
Iter: 2845 loss: 6.30052568e-07
Iter: 2846 loss: 6.29836677e-07
Iter: 2847 loss: 6.30577517e-07
Iter: 2848 loss: 6.29772e-07
Iter: 2849 loss: 6.29477427e-07
Iter: 2850 loss: 6.29875615e-07
Iter: 2851 loss: 6.29310421e-07
Iter: 2852 loss: 6.2908191e-07
Iter: 2853 loss: 6.29901194e-07
Iter: 2854 loss: 6.28994769e-07
Iter: 2855 loss: 6.28847147e-07
Iter: 2856 loss: 6.29504e-07
Iter: 2857 loss: 6.28813495e-07
Iter: 2858 loss: 6.28724706e-07
Iter: 2859 loss: 6.28722546e-07
Iter: 2860 loss: 6.28673547e-07
Iter: 2861 loss: 6.28561224e-07
Iter: 2862 loss: 6.29320652e-07
Iter: 2863 loss: 6.28527062e-07
Iter: 2864 loss: 6.28388307e-07
Iter: 2865 loss: 6.29243459e-07
Iter: 2866 loss: 6.28368639e-07
Iter: 2867 loss: 6.28244379e-07
Iter: 2868 loss: 6.29799217e-07
Iter: 2869 loss: 6.28235057e-07
Iter: 2870 loss: 6.28126486e-07
Iter: 2871 loss: 6.28053158e-07
Iter: 2872 loss: 6.28040311e-07
Iter: 2873 loss: 6.27883765e-07
Iter: 2874 loss: 6.295449e-07
Iter: 2875 loss: 6.27880468e-07
Iter: 2876 loss: 6.27798499e-07
Iter: 2877 loss: 6.27604948e-07
Iter: 2878 loss: 6.29631359e-07
Iter: 2879 loss: 6.27582153e-07
Iter: 2880 loss: 6.27416171e-07
Iter: 2881 loss: 6.28093687e-07
Iter: 2882 loss: 6.27351312e-07
Iter: 2883 loss: 6.27290035e-07
Iter: 2884 loss: 6.27231771e-07
Iter: 2885 loss: 6.27190445e-07
Iter: 2886 loss: 6.27079601e-07
Iter: 2887 loss: 6.2885897e-07
Iter: 2888 loss: 6.27078521e-07
Iter: 2889 loss: 6.2691106e-07
Iter: 2890 loss: 6.27640077e-07
Iter: 2891 loss: 6.26886219e-07
Iter: 2892 loss: 6.26810788e-07
Iter: 2893 loss: 6.26816359e-07
Iter: 2894 loss: 6.26746e-07
Iter: 2895 loss: 6.26572501e-07
Iter: 2896 loss: 6.287936e-07
Iter: 2897 loss: 6.26557494e-07
Iter: 2898 loss: 6.2637389e-07
Iter: 2899 loss: 6.2676429e-07
Iter: 2900 loss: 6.2630113e-07
Iter: 2901 loss: 6.26233088e-07
Iter: 2902 loss: 6.26209669e-07
Iter: 2903 loss: 6.26124177e-07
Iter: 2904 loss: 6.25948246e-07
Iter: 2905 loss: 6.28734142e-07
Iter: 2906 loss: 6.25936764e-07
Iter: 2907 loss: 6.25800908e-07
Iter: 2908 loss: 6.25814607e-07
Iter: 2909 loss: 6.25708424e-07
Iter: 2910 loss: 6.25490429e-07
Iter: 2911 loss: 6.28114663e-07
Iter: 2912 loss: 6.25481675e-07
Iter: 2913 loss: 6.25296707e-07
Iter: 2914 loss: 6.25154144e-07
Iter: 2915 loss: 6.2508883e-07
Iter: 2916 loss: 6.24946551e-07
Iter: 2917 loss: 6.24949621e-07
Iter: 2918 loss: 6.24737538e-07
Iter: 2919 loss: 6.24583e-07
Iter: 2920 loss: 6.24510335e-07
Iter: 2921 loss: 6.2434367e-07
Iter: 2922 loss: 6.24884763e-07
Iter: 2923 loss: 6.24291658e-07
Iter: 2924 loss: 6.24141478e-07
Iter: 2925 loss: 6.2414108e-07
Iter: 2926 loss: 6.24059169e-07
Iter: 2927 loss: 6.24265283e-07
Iter: 2928 loss: 6.2405536e-07
Iter: 2929 loss: 6.23951223e-07
Iter: 2930 loss: 6.23843562e-07
Iter: 2931 loss: 6.27040038e-07
Iter: 2932 loss: 6.23845835e-07
Iter: 2933 loss: 6.23729761e-07
Iter: 2934 loss: 6.24469351e-07
Iter: 2935 loss: 6.23719302e-07
Iter: 2936 loss: 6.23606411e-07
Iter: 2937 loss: 6.24542508e-07
Iter: 2938 loss: 6.23614483e-07
Iter: 2939 loss: 6.23529218e-07
Iter: 2940 loss: 6.2338205e-07
Iter: 2941 loss: 6.25509e-07
Iter: 2942 loss: 6.23372955e-07
Iter: 2943 loss: 6.23134042e-07
Iter: 2944 loss: 6.25101165e-07
Iter: 2945 loss: 6.23108349e-07
Iter: 2946 loss: 6.23005405e-07
Iter: 2947 loss: 6.2281589e-07
Iter: 2948 loss: 6.27058341e-07
Iter: 2949 loss: 6.22828566e-07
Iter: 2950 loss: 6.22695e-07
Iter: 2951 loss: 6.23764663e-07
Iter: 2952 loss: 6.22685661e-07
Iter: 2953 loss: 6.2258249e-07
Iter: 2954 loss: 6.2334442e-07
Iter: 2955 loss: 6.22552932e-07
Iter: 2956 loss: 6.22481366e-07
Iter: 2957 loss: 6.22312029e-07
Iter: 2958 loss: 6.25110602e-07
Iter: 2959 loss: 6.22323796e-07
Iter: 2960 loss: 6.22178334e-07
Iter: 2961 loss: 6.22475454e-07
Iter: 2962 loss: 6.22112111e-07
Iter: 2963 loss: 6.21961135e-07
Iter: 2964 loss: 6.23006429e-07
Iter: 2965 loss: 6.21967615e-07
Iter: 2966 loss: 6.21768834e-07
Iter: 2967 loss: 6.21747461e-07
Iter: 2968 loss: 6.21627237e-07
Iter: 2969 loss: 6.21466597e-07
Iter: 2970 loss: 6.21434594e-07
Iter: 2971 loss: 6.2132716e-07
Iter: 2972 loss: 6.21078584e-07
Iter: 2973 loss: 6.2184165e-07
Iter: 2974 loss: 6.20987521e-07
Iter: 2975 loss: 6.20715809e-07
Iter: 2976 loss: 6.22563789e-07
Iter: 2977 loss: 6.20679543e-07
Iter: 2978 loss: 6.2042966e-07
Iter: 2979 loss: 6.22007349e-07
Iter: 2980 loss: 6.20392825e-07
Iter: 2981 loss: 6.20261972e-07
Iter: 2982 loss: 6.20118612e-07
Iter: 2983 loss: 6.20088827e-07
Iter: 2984 loss: 6.19942739e-07
Iter: 2985 loss: 6.19932507e-07
Iter: 2986 loss: 6.19870377e-07
Iter: 2987 loss: 6.19708e-07
Iter: 2988 loss: 6.20560172e-07
Iter: 2989 loss: 6.19640218e-07
Iter: 2990 loss: 6.19569619e-07
Iter: 2991 loss: 6.19555408e-07
Iter: 2992 loss: 6.19447178e-07
Iter: 2993 loss: 6.19771072e-07
Iter: 2994 loss: 6.19416e-07
Iter: 2995 loss: 6.19347475e-07
Iter: 2996 loss: 6.19176035e-07
Iter: 2997 loss: 6.21077334e-07
Iter: 2998 loss: 6.19138689e-07
Iter: 2999 loss: 6.18954346e-07
Iter: 3000 loss: 6.20206833e-07
Iter: 3001 loss: 6.18948e-07
Iter: 3002 loss: 6.18837703e-07
Iter: 3003 loss: 6.18808144e-07
Iter: 3004 loss: 6.18760282e-07
Iter: 3005 loss: 6.18617037e-07
Iter: 3006 loss: 6.19922048e-07
Iter: 3007 loss: 6.18589e-07
Iter: 3008 loss: 6.18436843e-07
Iter: 3009 loss: 6.19003799e-07
Iter: 3010 loss: 6.18414e-07
Iter: 3011 loss: 6.18322133e-07
Iter: 3012 loss: 6.18318495e-07
Iter: 3013 loss: 6.18206627e-07
Iter: 3014 loss: 6.18094191e-07
Iter: 3015 loss: 6.18081572e-07
Iter: 3016 loss: 6.17865226e-07
Iter: 3017 loss: 6.17962712e-07
Iter: 3018 loss: 6.17734599e-07
Iter: 3019 loss: 6.17632395e-07
Iter: 3020 loss: 6.17592377e-07
Iter: 3021 loss: 6.17537694e-07
Iter: 3022 loss: 6.17382341e-07
Iter: 3023 loss: 6.18681156e-07
Iter: 3024 loss: 6.17359262e-07
Iter: 3025 loss: 6.17246258e-07
Iter: 3026 loss: 6.17356e-07
Iter: 3027 loss: 6.17195838e-07
Iter: 3028 loss: 6.17100795e-07
Iter: 3029 loss: 6.1708738e-07
Iter: 3030 loss: 6.16964485e-07
Iter: 3031 loss: 6.16735747e-07
Iter: 3032 loss: 6.21270374e-07
Iter: 3033 loss: 6.16719603e-07
Iter: 3034 loss: 6.16519571e-07
Iter: 3035 loss: 6.16589773e-07
Iter: 3036 loss: 6.16354555e-07
Iter: 3037 loss: 6.16243938e-07
Iter: 3038 loss: 6.16209491e-07
Iter: 3039 loss: 6.16080456e-07
Iter: 3040 loss: 6.16335058e-07
Iter: 3041 loss: 6.16016678e-07
Iter: 3042 loss: 6.15922886e-07
Iter: 3043 loss: 6.15969043e-07
Iter: 3044 loss: 6.15850126e-07
Iter: 3045 loss: 6.15763042e-07
Iter: 3046 loss: 6.17296109e-07
Iter: 3047 loss: 6.15763042e-07
Iter: 3048 loss: 6.15691079e-07
Iter: 3049 loss: 6.15542149e-07
Iter: 3050 loss: 6.17699072e-07
Iter: 3051 loss: 6.15529189e-07
Iter: 3052 loss: 6.15431361e-07
Iter: 3053 loss: 6.15429201e-07
Iter: 3054 loss: 6.15320232e-07
Iter: 3055 loss: 6.15216436e-07
Iter: 3056 loss: 6.15173462e-07
Iter: 3057 loss: 6.15017598e-07
Iter: 3058 loss: 6.14723831e-07
Iter: 3059 loss: 6.1472258e-07
Iter: 3060 loss: 6.14477528e-07
Iter: 3061 loss: 6.16845114e-07
Iter: 3062 loss: 6.14484634e-07
Iter: 3063 loss: 6.14445355e-07
Iter: 3064 loss: 6.14381065e-07
Iter: 3065 loss: 6.14343833e-07
Iter: 3066 loss: 6.14219289e-07
Iter: 3067 loss: 6.15241788e-07
Iter: 3068 loss: 6.14201156e-07
Iter: 3069 loss: 6.14030284e-07
Iter: 3070 loss: 6.13990721e-07
Iter: 3071 loss: 6.13889597e-07
Iter: 3072 loss: 6.1399021e-07
Iter: 3073 loss: 6.13808254e-07
Iter: 3074 loss: 6.13764655e-07
Iter: 3075 loss: 6.13675354e-07
Iter: 3076 loss: 6.15829777e-07
Iter: 3077 loss: 6.13662564e-07
Iter: 3078 loss: 6.13604243e-07
Iter: 3079 loss: 6.13598161e-07
Iter: 3080 loss: 6.135391e-07
Iter: 3081 loss: 6.13465545e-07
Iter: 3082 loss: 6.13444399e-07
Iter: 3083 loss: 6.13348561e-07
Iter: 3084 loss: 6.13437237e-07
Iter: 3085 loss: 6.13267389e-07
Iter: 3086 loss: 6.13207703e-07
Iter: 3087 loss: 6.13215093e-07
Iter: 3088 loss: 6.13097541e-07
Iter: 3089 loss: 6.12865e-07
Iter: 3090 loss: 6.14161195e-07
Iter: 3091 loss: 6.12755855e-07
Iter: 3092 loss: 6.12519102e-07
Iter: 3093 loss: 6.14119585e-07
Iter: 3094 loss: 6.12503527e-07
Iter: 3095 loss: 6.12296787e-07
Iter: 3096 loss: 6.12767337e-07
Iter: 3097 loss: 6.12228405e-07
Iter: 3098 loss: 6.12181225e-07
Iter: 3099 loss: 6.12162353e-07
Iter: 3100 loss: 6.12084705e-07
Iter: 3101 loss: 6.12018312e-07
Iter: 3102 loss: 6.11987559e-07
Iter: 3103 loss: 6.11878477e-07
Iter: 3104 loss: 6.11762232e-07
Iter: 3105 loss: 6.11753194e-07
Iter: 3106 loss: 6.11688279e-07
Iter: 3107 loss: 6.11673727e-07
Iter: 3108 loss: 6.1156004e-07
Iter: 3109 loss: 6.11463065e-07
Iter: 3110 loss: 6.11431801e-07
Iter: 3111 loss: 6.11252062e-07
Iter: 3112 loss: 6.13062866e-07
Iter: 3113 loss: 6.11249448e-07
Iter: 3114 loss: 6.11185442e-07
Iter: 3115 loss: 6.11168502e-07
Iter: 3116 loss: 6.11144458e-07
Iter: 3117 loss: 6.11058965e-07
Iter: 3118 loss: 6.11594e-07
Iter: 3119 loss: 6.11065957e-07
Iter: 3120 loss: 6.10981601e-07
Iter: 3121 loss: 6.10917709e-07
Iter: 3122 loss: 6.10883717e-07
Iter: 3123 loss: 6.10780603e-07
Iter: 3124 loss: 6.10721827e-07
Iter: 3125 loss: 6.10694372e-07
Iter: 3126 loss: 6.10559e-07
Iter: 3127 loss: 6.1041078e-07
Iter: 3128 loss: 6.10400036e-07
Iter: 3129 loss: 6.1027913e-07
Iter: 3130 loss: 6.10293569e-07
Iter: 3131 loss: 6.10197958e-07
Iter: 3132 loss: 6.10353e-07
Iter: 3133 loss: 6.10157258e-07
Iter: 3134 loss: 6.10064e-07
Iter: 3135 loss: 6.09962058e-07
Iter: 3136 loss: 6.09924541e-07
Iter: 3137 loss: 6.09808069e-07
Iter: 3138 loss: 6.11038331e-07
Iter: 3139 loss: 6.09815288e-07
Iter: 3140 loss: 6.09656354e-07
Iter: 3141 loss: 6.1016226e-07
Iter: 3142 loss: 6.09628103e-07
Iter: 3143 loss: 6.09539143e-07
Iter: 3144 loss: 6.09955237e-07
Iter: 3145 loss: 6.09504e-07
Iter: 3146 loss: 6.09404651e-07
Iter: 3147 loss: 6.09492872e-07
Iter: 3148 loss: 6.09353208e-07
Iter: 3149 loss: 6.09266749e-07
Iter: 3150 loss: 6.09210474e-07
Iter: 3151 loss: 6.09181427e-07
Iter: 3152 loss: 6.09114295e-07
Iter: 3153 loss: 6.09082349e-07
Iter: 3154 loss: 6.09050289e-07
Iter: 3155 loss: 6.08978326e-07
Iter: 3156 loss: 6.08963092e-07
Iter: 3157 loss: 6.08911705e-07
Iter: 3158 loss: 6.08888627e-07
Iter: 3159 loss: 6.08840423e-07
Iter: 3160 loss: 6.08745495e-07
Iter: 3161 loss: 6.09155e-07
Iter: 3162 loss: 6.08708319e-07
Iter: 3163 loss: 6.08624418e-07
Iter: 3164 loss: 6.09633048e-07
Iter: 3165 loss: 6.08625214e-07
Iter: 3166 loss: 6.08533583e-07
Iter: 3167 loss: 6.0877386e-07
Iter: 3168 loss: 6.08512266e-07
Iter: 3169 loss: 6.08424898e-07
Iter: 3170 loss: 6.08357823e-07
Iter: 3171 loss: 6.08350945e-07
Iter: 3172 loss: 6.08254481e-07
Iter: 3173 loss: 6.08647156e-07
Iter: 3174 loss: 6.08216e-07
Iter: 3175 loss: 6.08031542e-07
Iter: 3176 loss: 6.08309563e-07
Iter: 3177 loss: 6.07978677e-07
Iter: 3178 loss: 6.07911e-07
Iter: 3179 loss: 6.07975835e-07
Iter: 3180 loss: 6.07850779e-07
Iter: 3181 loss: 6.07755624e-07
Iter: 3182 loss: 6.08615437e-07
Iter: 3183 loss: 6.07742777e-07
Iter: 3184 loss: 6.07690595e-07
Iter: 3185 loss: 6.0763233e-07
Iter: 3186 loss: 6.07616244e-07
Iter: 3187 loss: 6.07497782e-07
Iter: 3188 loss: 6.08279834e-07
Iter: 3189 loss: 6.07493746e-07
Iter: 3190 loss: 6.07454695e-07
Iter: 3191 loss: 6.07359539e-07
Iter: 3192 loss: 6.09620258e-07
Iter: 3193 loss: 6.07355e-07
Iter: 3194 loss: 6.07200661e-07
Iter: 3195 loss: 6.07488687e-07
Iter: 3196 loss: 6.07162292e-07
Iter: 3197 loss: 6.06997105e-07
Iter: 3198 loss: 6.06874096e-07
Iter: 3199 loss: 6.06836124e-07
Iter: 3200 loss: 6.06758135e-07
Iter: 3201 loss: 6.06714e-07
Iter: 3202 loss: 6.06592664e-07
Iter: 3203 loss: 6.06710955e-07
Iter: 3204 loss: 6.06530421e-07
Iter: 3205 loss: 6.06474487e-07
Iter: 3206 loss: 6.06535252e-07
Iter: 3207 loss: 6.06439244e-07
Iter: 3208 loss: 6.06372623e-07
Iter: 3209 loss: 6.07016432e-07
Iter: 3210 loss: 6.06381263e-07
Iter: 3211 loss: 6.06339427e-07
Iter: 3212 loss: 6.06233243e-07
Iter: 3213 loss: 6.07400352e-07
Iter: 3214 loss: 6.06204594e-07
Iter: 3215 loss: 6.06142862e-07
Iter: 3216 loss: 6.06132346e-07
Iter: 3217 loss: 6.06055e-07
Iter: 3218 loss: 6.06047877e-07
Iter: 3219 loss: 6.05978812e-07
Iter: 3220 loss: 6.05923731e-07
Iter: 3221 loss: 6.05923447e-07
Iter: 3222 loss: 6.05880416e-07
Iter: 3223 loss: 6.05774517e-07
Iter: 3224 loss: 6.07403e-07
Iter: 3225 loss: 6.0576383e-07
Iter: 3226 loss: 6.05681748e-07
Iter: 3227 loss: 6.05712557e-07
Iter: 3228 loss: 6.05620357e-07
Iter: 3229 loss: 6.05563457e-07
Iter: 3230 loss: 6.05597734e-07
Iter: 3231 loss: 6.05520654e-07
Iter: 3232 loss: 6.05463e-07
Iter: 3233 loss: 6.05544756e-07
Iter: 3234 loss: 6.05439141e-07
Iter: 3235 loss: 6.05364733e-07
Iter: 3236 loss: 6.05371383e-07
Iter: 3237 loss: 6.05333639e-07
Iter: 3238 loss: 6.05235e-07
Iter: 3239 loss: 6.06674462e-07
Iter: 3240 loss: 6.05224045e-07
Iter: 3241 loss: 6.05141963e-07
Iter: 3242 loss: 6.05295838e-07
Iter: 3243 loss: 6.05107118e-07
Iter: 3244 loss: 6.05082448e-07
Iter: 3245 loss: 6.05070738e-07
Iter: 3246 loss: 6.05021341e-07
Iter: 3247 loss: 6.04920274e-07
Iter: 3248 loss: 6.06243134e-07
Iter: 3249 loss: 6.0489549e-07
Iter: 3250 loss: 6.04772254e-07
Iter: 3251 loss: 6.05010655e-07
Iter: 3252 loss: 6.04723368e-07
Iter: 3253 loss: 6.04727859e-07
Iter: 3254 loss: 6.04662603e-07
Iter: 3255 loss: 6.04628724e-07
Iter: 3256 loss: 6.04561421e-07
Iter: 3257 loss: 6.05306923e-07
Iter: 3258 loss: 6.04552099e-07
Iter: 3259 loss: 6.04486786e-07
Iter: 3260 loss: 6.04489571e-07
Iter: 3261 loss: 6.04464503e-07
Iter: 3262 loss: 6.04383786e-07
Iter: 3263 loss: 6.04753325e-07
Iter: 3264 loss: 6.04370143e-07
Iter: 3265 loss: 6.04277e-07
Iter: 3266 loss: 6.04806473e-07
Iter: 3267 loss: 6.04278966e-07
Iter: 3268 loss: 6.04191e-07
Iter: 3269 loss: 6.04907086e-07
Iter: 3270 loss: 6.0418904e-07
Iter: 3271 loss: 6.04129923e-07
Iter: 3272 loss: 6.04146692e-07
Iter: 3273 loss: 6.04082516e-07
Iter: 3274 loss: 6.03998785e-07
Iter: 3275 loss: 6.04048523e-07
Iter: 3276 loss: 6.03949104e-07
Iter: 3277 loss: 6.03855938e-07
Iter: 3278 loss: 6.04204843e-07
Iter: 3279 loss: 6.03850253e-07
Iter: 3280 loss: 6.03770218e-07
Iter: 3281 loss: 6.04811873e-07
Iter: 3282 loss: 6.03766864e-07
Iter: 3283 loss: 6.03699789e-07
Iter: 3284 loss: 6.03640899e-07
Iter: 3285 loss: 6.03642945e-07
Iter: 3286 loss: 6.03593037e-07
Iter: 3287 loss: 6.04000434e-07
Iter: 3288 loss: 6.03580133e-07
Iter: 3289 loss: 6.03516582e-07
Iter: 3290 loss: 6.0384e-07
Iter: 3291 loss: 6.03517037e-07
Iter: 3292 loss: 6.03472699e-07
Iter: 3293 loss: 6.03478725e-07
Iter: 3294 loss: 6.03430067e-07
Iter: 3295 loss: 6.03385274e-07
Iter: 3296 loss: 6.03707292e-07
Iter: 3297 loss: 6.0337436e-07
Iter: 3298 loss: 6.03351e-07
Iter: 3299 loss: 6.03296144e-07
Iter: 3300 loss: 6.03724743e-07
Iter: 3301 loss: 6.0327568e-07
Iter: 3302 loss: 6.03255e-07
Iter: 3303 loss: 6.03216904e-07
Iter: 3304 loss: 6.03209173e-07
Iter: 3305 loss: 6.03188937e-07
Iter: 3306 loss: 6.03171543e-07
Iter: 3307 loss: 6.03118337e-07
Iter: 3308 loss: 6.03116746e-07
Iter: 3309 loss: 6.0307184e-07
Iter: 3310 loss: 6.03004764e-07
Iter: 3311 loss: 6.035213e-07
Iter: 3312 loss: 6.02997147e-07
Iter: 3313 loss: 6.02962814e-07
Iter: 3314 loss: 6.03035232e-07
Iter: 3315 loss: 6.02940418e-07
Iter: 3316 loss: 6.02914724e-07
Iter: 3317 loss: 6.02892896e-07
Iter: 3318 loss: 6.02868454e-07
Iter: 3319 loss: 6.02813e-07
Iter: 3320 loss: 6.03272042e-07
Iter: 3321 loss: 6.02811383e-07
Iter: 3322 loss: 6.02724185e-07
Iter: 3323 loss: 6.03146873e-07
Iter: 3324 loss: 6.02700879e-07
Iter: 3325 loss: 6.02618911e-07
Iter: 3326 loss: 6.03759077e-07
Iter: 3327 loss: 6.02634657e-07
Iter: 3328 loss: 6.02605269e-07
Iter: 3329 loss: 6.02576335e-07
Iter: 3330 loss: 6.02573209e-07
Iter: 3331 loss: 6.02502098e-07
Iter: 3332 loss: 6.02768921e-07
Iter: 3333 loss: 6.02499881e-07
Iter: 3334 loss: 6.02479076e-07
Iter: 3335 loss: 6.0242337e-07
Iter: 3336 loss: 6.02977764e-07
Iter: 3337 loss: 6.02411546e-07
Iter: 3338 loss: 6.02392902e-07
Iter: 3339 loss: 6.02397e-07
Iter: 3340 loss: 6.0235368e-07
Iter: 3341 loss: 6.02345267e-07
Iter: 3342 loss: 6.02328271e-07
Iter: 3343 loss: 6.02291607e-07
Iter: 3344 loss: 6.0224e-07
Iter: 3345 loss: 6.02227374e-07
Iter: 3346 loss: 6.02145235e-07
Iter: 3347 loss: 6.02713442e-07
Iter: 3348 loss: 6.02143e-07
Iter: 3349 loss: 6.02122043e-07
Iter: 3350 loss: 6.02597311e-07
Iter: 3351 loss: 6.02118348e-07
Iter: 3352 loss: 6.02083105e-07
Iter: 3353 loss: 6.02021146e-07
Iter: 3354 loss: 6.02021203e-07
Iter: 3355 loss: 6.01966349e-07
Iter: 3356 loss: 6.02139039e-07
Iter: 3357 loss: 6.01956231e-07
Iter: 3358 loss: 6.01911665e-07
Iter: 3359 loss: 6.02326452e-07
Iter: 3360 loss: 6.01904219e-07
Iter: 3361 loss: 6.01855845e-07
Iter: 3362 loss: 6.0183595e-07
Iter: 3363 loss: 6.01841066e-07
Iter: 3364 loss: 6.01817419e-07
Iter: 3365 loss: 6.01806164e-07
Iter: 3366 loss: 6.01776605e-07
Iter: 3367 loss: 6.01724764e-07
Iter: 3368 loss: 6.02617604e-07
Iter: 3369 loss: 6.01722491e-07
Iter: 3370 loss: 6.0166974e-07
Iter: 3371 loss: 6.01667693e-07
Iter: 3372 loss: 6.01646889e-07
Iter: 3373 loss: 6.01586066e-07
Iter: 3374 loss: 6.01574584e-07
Iter: 3375 loss: 6.0149182e-07
Iter: 3376 loss: 6.02268642e-07
Iter: 3377 loss: 6.01491877e-07
Iter: 3378 loss: 6.01433726e-07
Iter: 3379 loss: 6.01436909e-07
Iter: 3380 loss: 6.01415309e-07
Iter: 3381 loss: 6.01365343e-07
Iter: 3382 loss: 6.01361762e-07
Iter: 3383 loss: 6.01347892e-07
Iter: 3384 loss: 6.01460101e-07
Iter: 3385 loss: 6.01329e-07
Iter: 3386 loss: 6.0132038e-07
Iter: 3387 loss: 6.01250633e-07
Iter: 3388 loss: 6.01979934e-07
Iter: 3389 loss: 6.01254442e-07
Iter: 3390 loss: 6.01257568e-07
Iter: 3391 loss: 6.01232045e-07
Iter: 3392 loss: 6.01200327e-07
Iter: 3393 loss: 6.01170029e-07
Iter: 3394 loss: 6.01165e-07
Iter: 3395 loss: 6.01122451e-07
Iter: 3396 loss: 6.0127752e-07
Iter: 3397 loss: 6.01098066e-07
Iter: 3398 loss: 6.01025818e-07
Iter: 3399 loss: 6.010373e-07
Iter: 3400 loss: 6.00971e-07
Iter: 3401 loss: 6.00920202e-07
Iter: 3402 loss: 6.01058559e-07
Iter: 3403 loss: 6.00889678e-07
Iter: 3404 loss: 6.00817202e-07
Iter: 3405 loss: 6.00902069e-07
Iter: 3406 loss: 6.0077457e-07
Iter: 3407 loss: 6.00720909e-07
Iter: 3408 loss: 6.00806175e-07
Iter: 3409 loss: 6.00683961e-07
Iter: 3410 loss: 6.00592784e-07
Iter: 3411 loss: 6.00568683e-07
Iter: 3412 loss: 6.00498879e-07
Iter: 3413 loss: 6.0044033e-07
Iter: 3414 loss: 6.01219369e-07
Iter: 3415 loss: 6.00445333e-07
Iter: 3416 loss: 6.0038434e-07
Iter: 3417 loss: 6.00785427e-07
Iter: 3418 loss: 6.00381895e-07
Iter: 3419 loss: 6.00353417e-07
Iter: 3420 loss: 6.00300154e-07
Iter: 3421 loss: 6.00310955e-07
Iter: 3422 loss: 6.00230464e-07
Iter: 3423 loss: 6.00150429e-07
Iter: 3424 loss: 6.00146734e-07
Iter: 3425 loss: 6.00067324e-07
Iter: 3426 loss: 6.00068347e-07
Iter: 3427 loss: 5.99979387e-07
Iter: 3428 loss: 6.00147814e-07
Iter: 3429 loss: 5.99907821e-07
Iter: 3430 loss: 5.99871555e-07
Iter: 3431 loss: 5.99972736e-07
Iter: 3432 loss: 5.99852683e-07
Iter: 3433 loss: 5.99751957e-07
Iter: 3434 loss: 5.99917428e-07
Iter: 3435 loss: 5.99723762e-07
Iter: 3436 loss: 5.99666237e-07
Iter: 3437 loss: 5.99600412e-07
Iter: 3438 loss: 6.00598298e-07
Iter: 3439 loss: 5.99599161e-07
Iter: 3440 loss: 5.99546354e-07
Iter: 3441 loss: 5.99515488e-07
Iter: 3442 loss: 5.99474447e-07
Iter: 3443 loss: 5.99421583e-07
Iter: 3444 loss: 5.9940669e-07
Iter: 3445 loss: 5.99353029e-07
Iter: 3446 loss: 5.99540726e-07
Iter: 3447 loss: 5.9934257e-07
Iter: 3448 loss: 5.9929539e-07
Iter: 3449 loss: 5.99308805e-07
Iter: 3450 loss: 5.9924372e-07
Iter: 3451 loss: 5.99167322e-07
Iter: 3452 loss: 6.00155317e-07
Iter: 3453 loss: 5.99165e-07
Iter: 3454 loss: 5.99131e-07
Iter: 3455 loss: 5.99076202e-07
Iter: 3456 loss: 6.00446128e-07
Iter: 3457 loss: 5.99071427e-07
Iter: 3458 loss: 5.99062901e-07
Iter: 3459 loss: 5.99037207e-07
Iter: 3460 loss: 5.98990823e-07
Iter: 3461 loss: 5.9901646e-07
Iter: 3462 loss: 5.98982638e-07
Iter: 3463 loss: 5.98930853e-07
Iter: 3464 loss: 5.98842e-07
Iter: 3465 loss: 5.98843542e-07
Iter: 3466 loss: 5.98748e-07
Iter: 3467 loss: 5.99893895e-07
Iter: 3468 loss: 5.9875731e-07
Iter: 3469 loss: 5.98683073e-07
Iter: 3470 loss: 5.98788063e-07
Iter: 3471 loss: 5.98629299e-07
Iter: 3472 loss: 5.98576321e-07
Iter: 3473 loss: 5.98506745e-07
Iter: 3474 loss: 5.9848162e-07
Iter: 3475 loss: 5.98394934e-07
Iter: 3476 loss: 5.98375721e-07
Iter: 3477 loss: 5.98342069e-07
Iter: 3478 loss: 5.9831109e-07
Iter: 3479 loss: 5.98273175e-07
Iter: 3480 loss: 5.98217184e-07
Iter: 3481 loss: 5.98595761e-07
Iter: 3482 loss: 5.98208089e-07
Iter: 3483 loss: 5.98132829e-07
Iter: 3484 loss: 5.98208317e-07
Iter: 3485 loss: 5.98118049e-07
Iter: 3486 loss: 5.98008342e-07
Iter: 3487 loss: 5.97861458e-07
Iter: 3488 loss: 5.97870837e-07
Iter: 3489 loss: 5.97763801e-07
Iter: 3490 loss: 5.98635e-07
Iter: 3491 loss: 5.9775823e-07
Iter: 3492 loss: 5.97651933e-07
Iter: 3493 loss: 5.98591953e-07
Iter: 3494 loss: 5.97637381e-07
Iter: 3495 loss: 5.97583266e-07
Iter: 3496 loss: 5.97485382e-07
Iter: 3497 loss: 5.9964708e-07
Iter: 3498 loss: 5.97487e-07
Iter: 3499 loss: 5.9739989e-07
Iter: 3500 loss: 5.98335646e-07
Iter: 3501 loss: 5.97375561e-07
Iter: 3502 loss: 5.97282678e-07
Iter: 3503 loss: 5.97726171e-07
Iter: 3504 loss: 5.97270059e-07
Iter: 3505 loss: 5.97200767e-07
Iter: 3506 loss: 5.97139206e-07
Iter: 3507 loss: 5.97120049e-07
Iter: 3508 loss: 5.97049336e-07
Iter: 3509 loss: 5.9703757e-07
Iter: 3510 loss: 5.96984819e-07
Iter: 3511 loss: 5.96952077e-07
Iter: 3512 loss: 5.96932068e-07
Iter: 3513 loss: 5.96846121e-07
Iter: 3514 loss: 5.97318035e-07
Iter: 3515 loss: 5.96839527e-07
Iter: 3516 loss: 5.96756649e-07
Iter: 3517 loss: 5.96908819e-07
Iter: 3518 loss: 5.96747896e-07
Iter: 3519 loss: 5.96648135e-07
Iter: 3520 loss: 5.9666587e-07
Iter: 3521 loss: 5.96582254e-07
Iter: 3522 loss: 5.96491873e-07
Iter: 3523 loss: 5.96598909e-07
Iter: 3524 loss: 5.96441453e-07
Iter: 3525 loss: 5.9637307e-07
Iter: 3526 loss: 5.96353e-07
Iter: 3527 loss: 5.96302925e-07
Iter: 3528 loss: 5.96210839e-07
Iter: 3529 loss: 5.96962138e-07
Iter: 3530 loss: 5.96184918e-07
Iter: 3531 loss: 5.96063273e-07
Iter: 3532 loss: 5.9702819e-07
Iter: 3533 loss: 5.96072937e-07
Iter: 3534 loss: 5.95979031e-07
Iter: 3535 loss: 5.95973461e-07
Iter: 3536 loss: 5.95926508e-07
Iter: 3537 loss: 5.95847951e-07
Iter: 3538 loss: 5.95846359e-07
Iter: 3539 loss: 5.95780705e-07
Iter: 3540 loss: 5.95771212e-07
Iter: 3541 loss: 5.95710958e-07
Iter: 3542 loss: 5.95686743e-07
Iter: 3543 loss: 5.95652068e-07
Iter: 3544 loss: 5.95587892e-07
Iter: 3545 loss: 5.95991423e-07
Iter: 3546 loss: 5.95568281e-07
Iter: 3547 loss: 5.95514166e-07
Iter: 3548 loss: 5.95695269e-07
Iter: 3549 loss: 5.95483698e-07
Iter: 3550 loss: 5.95433676e-07
Iter: 3551 loss: 5.95381e-07
Iter: 3552 loss: 5.95353129e-07
Iter: 3553 loss: 5.95268034e-07
Iter: 3554 loss: 5.95364554e-07
Iter: 3555 loss: 5.95211873e-07
Iter: 3556 loss: 5.952121e-07
Iter: 3557 loss: 5.95172764e-07
Iter: 3558 loss: 5.95145309e-07
Iter: 3559 loss: 5.95052143e-07
Iter: 3560 loss: 5.95448398e-07
Iter: 3561 loss: 5.95034351e-07
Iter: 3562 loss: 5.94946073e-07
Iter: 3563 loss: 5.95071242e-07
Iter: 3564 loss: 5.9489571e-07
Iter: 3565 loss: 5.94839548e-07
Iter: 3566 loss: 5.94814935e-07
Iter: 3567 loss: 5.94779465e-07
Iter: 3568 loss: 5.94722394e-07
Iter: 3569 loss: 5.96576115e-07
Iter: 3570 loss: 5.94705796e-07
Iter: 3571 loss: 5.9461081e-07
Iter: 3572 loss: 5.95515644e-07
Iter: 3573 loss: 5.94602056e-07
Iter: 3574 loss: 5.94541632e-07
Iter: 3575 loss: 5.94578353e-07
Iter: 3576 loss: 5.94501e-07
Iter: 3577 loss: 5.94414303e-07
Iter: 3578 loss: 5.94541291e-07
Iter: 3579 loss: 5.94386051e-07
Iter: 3580 loss: 5.94307323e-07
Iter: 3581 loss: 5.94912933e-07
Iter: 3582 loss: 5.94301525e-07
Iter: 3583 loss: 5.94215692e-07
Iter: 3584 loss: 5.94187497e-07
Iter: 3585 loss: 5.94179085e-07
Iter: 3586 loss: 5.94066705e-07
Iter: 3587 loss: 5.94079324e-07
Iter: 3588 loss: 5.93999403e-07
Iter: 3589 loss: 5.93978939e-07
Iter: 3590 loss: 5.93958816e-07
Iter: 3591 loss: 5.9390004e-07
Iter: 3592 loss: 5.93839331e-07
Iter: 3593 loss: 5.93834329e-07
Iter: 3594 loss: 5.93786638e-07
Iter: 3595 loss: 5.937693e-07
Iter: 3596 loss: 5.937232e-07
Iter: 3597 loss: 5.93663231e-07
Iter: 3598 loss: 5.93657433e-07
Iter: 3599 loss: 5.93601499e-07
Iter: 3600 loss: 5.93554887e-07
Iter: 3601 loss: 5.93557843e-07
Iter: 3602 loss: 5.93475136e-07
Iter: 3603 loss: 5.93863319e-07
Iter: 3604 loss: 5.93484458e-07
Iter: 3605 loss: 5.93388336e-07
Iter: 3606 loss: 5.93521122e-07
Iter: 3607 loss: 5.93340701e-07
Iter: 3608 loss: 5.93270386e-07
Iter: 3609 loss: 5.93186314e-07
Iter: 3610 loss: 5.93176196e-07
Iter: 3611 loss: 5.93095365e-07
Iter: 3612 loss: 5.93084565e-07
Iter: 3613 loss: 5.93037782e-07
Iter: 3614 loss: 5.93037953e-07
Iter: 3615 loss: 5.92991228e-07
Iter: 3616 loss: 5.92941205e-07
Iter: 3617 loss: 5.92856054e-07
Iter: 3618 loss: 5.92865149e-07
Iter: 3619 loss: 5.92784659e-07
Iter: 3620 loss: 5.93754578e-07
Iter: 3621 loss: 5.92803531e-07
Iter: 3622 loss: 5.92722e-07
Iter: 3623 loss: 5.92661252e-07
Iter: 3624 loss: 5.92628794e-07
Iter: 3625 loss: 5.92533752e-07
Iter: 3626 loss: 5.92480262e-07
Iter: 3627 loss: 5.92414892e-07
Iter: 3628 loss: 5.92370384e-07
Iter: 3629 loss: 5.92360038e-07
Iter: 3630 loss: 5.92302854e-07
Iter: 3631 loss: 5.92249876e-07
Iter: 3632 loss: 5.92226115e-07
Iter: 3633 loss: 5.92108222e-07
Iter: 3634 loss: 5.92270567e-07
Iter: 3635 loss: 5.92078777e-07
Iter: 3636 loss: 5.91965204e-07
Iter: 3637 loss: 5.92673587e-07
Iter: 3638 loss: 5.91946844e-07
Iter: 3639 loss: 5.9190495e-07
Iter: 3640 loss: 5.91794048e-07
Iter: 3641 loss: 5.91795128e-07
Iter: 3642 loss: 5.91688149e-07
Iter: 3643 loss: 5.93113441e-07
Iter: 3644 loss: 5.91684397e-07
Iter: 3645 loss: 5.91619e-07
Iter: 3646 loss: 5.91679e-07
Iter: 3647 loss: 5.9157486e-07
Iter: 3648 loss: 5.91477942e-07
Iter: 3649 loss: 5.91624371e-07
Iter: 3650 loss: 5.91439516e-07
Iter: 3651 loss: 5.91357491e-07
Iter: 3652 loss: 5.9203137e-07
Iter: 3653 loss: 5.9135e-07
Iter: 3654 loss: 5.91274102e-07
Iter: 3655 loss: 5.91233288e-07
Iter: 3656 loss: 5.91196283e-07
Iter: 3657 loss: 5.91087257e-07
Iter: 3658 loss: 5.91087769e-07
Iter: 3659 loss: 5.91010917e-07
Iter: 3660 loss: 5.90901607e-07
Iter: 3661 loss: 5.92033757e-07
Iter: 3662 loss: 5.90891659e-07
Iter: 3663 loss: 5.90802131e-07
Iter: 3664 loss: 5.90916045e-07
Iter: 3665 loss: 5.90746083e-07
Iter: 3666 loss: 5.90654906e-07
Iter: 3667 loss: 5.90874947e-07
Iter: 3668 loss: 5.90618811e-07
Iter: 3669 loss: 5.90543209e-07
Iter: 3670 loss: 5.91009893e-07
Iter: 3671 loss: 5.9051581e-07
Iter: 3672 loss: 5.904555e-07
Iter: 3673 loss: 5.90390471e-07
Iter: 3674 loss: 5.90369098e-07
Iter: 3675 loss: 5.90313618e-07
Iter: 3676 loss: 5.91648131e-07
Iter: 3677 loss: 5.9031106e-07
Iter: 3678 loss: 5.902358e-07
Iter: 3679 loss: 5.90190211e-07
Iter: 3680 loss: 5.90160425e-07
Iter: 3681 loss: 5.90011211e-07
Iter: 3682 loss: 5.90018885e-07
Iter: 3683 loss: 5.89888145e-07
Iter: 3684 loss: 5.89762408e-07
Iter: 3685 loss: 5.89756326e-07
Iter: 3686 loss: 5.89663e-07
Iter: 3687 loss: 5.89724777e-07
Iter: 3688 loss: 5.89577724e-07
Iter: 3689 loss: 5.89484216e-07
Iter: 3690 loss: 5.89393608e-07
Iter: 3691 loss: 5.89356432e-07
Iter: 3692 loss: 5.89222225e-07
Iter: 3693 loss: 5.90501941e-07
Iter: 3694 loss: 5.89217052e-07
Iter: 3695 loss: 5.89075285e-07
Iter: 3696 loss: 5.8990554e-07
Iter: 3697 loss: 5.89061415e-07
Iter: 3698 loss: 5.89006106e-07
Iter: 3699 loss: 5.89000933e-07
Iter: 3700 loss: 5.88950627e-07
Iter: 3701 loss: 5.88828868e-07
Iter: 3702 loss: 5.89233764e-07
Iter: 3703 loss: 5.88803e-07
Iter: 3704 loss: 5.88716148e-07
Iter: 3705 loss: 5.88677324e-07
Iter: 3706 loss: 5.88616047e-07
Iter: 3707 loss: 5.88525722e-07
Iter: 3708 loss: 5.89986e-07
Iter: 3709 loss: 5.88520038e-07
Iter: 3710 loss: 5.88416e-07
Iter: 3711 loss: 5.88333e-07
Iter: 3712 loss: 5.88315459e-07
Iter: 3713 loss: 5.88132764e-07
Iter: 3714 loss: 5.88511796e-07
Iter: 3715 loss: 5.88068531e-07
Iter: 3716 loss: 5.87959e-07
Iter: 3717 loss: 5.88988769e-07
Iter: 3718 loss: 5.87955697e-07
Iter: 3719 loss: 5.87857812e-07
Iter: 3720 loss: 5.8803306e-07
Iter: 3721 loss: 5.87825298e-07
Iter: 3722 loss: 5.87721274e-07
Iter: 3723 loss: 5.87639306e-07
Iter: 3724 loss: 5.87611112e-07
Iter: 3725 loss: 5.87506065e-07
Iter: 3726 loss: 5.88338708e-07
Iter: 3727 loss: 5.87514478e-07
Iter: 3728 loss: 5.87365207e-07
Iter: 3729 loss: 5.88325122e-07
Iter: 3730 loss: 5.87372313e-07
Iter: 3731 loss: 5.87309273e-07
Iter: 3732 loss: 5.87298359e-07
Iter: 3733 loss: 5.87248792e-07
Iter: 3734 loss: 5.87181148e-07
Iter: 3735 loss: 5.87685122e-07
Iter: 3736 loss: 5.87171371e-07
Iter: 3737 loss: 5.87104182e-07
Iter: 3738 loss: 5.87077068e-07
Iter: 3739 loss: 5.870358e-07
Iter: 3740 loss: 5.86943202e-07
Iter: 3741 loss: 5.87721388e-07
Iter: 3742 loss: 5.86934902e-07
Iter: 3743 loss: 5.8686112e-07
Iter: 3744 loss: 5.86837302e-07
Iter: 3745 loss: 5.8678927e-07
Iter: 3746 loss: 5.86680471e-07
Iter: 3747 loss: 5.87557e-07
Iter: 3748 loss: 5.86662509e-07
Iter: 3749 loss: 5.86609417e-07
Iter: 3750 loss: 5.86708609e-07
Iter: 3751 loss: 5.86598048e-07
Iter: 3752 loss: 5.86520287e-07
Iter: 3753 loss: 5.86751185e-07
Iter: 3754 loss: 5.86487317e-07
Iter: 3755 loss: 5.8640245e-07
Iter: 3756 loss: 5.86334522e-07
Iter: 3757 loss: 5.86314457e-07
Iter: 3758 loss: 5.86215378e-07
Iter: 3759 loss: 5.86629426e-07
Iter: 3760 loss: 5.86181272e-07
Iter: 3761 loss: 5.86084241e-07
Iter: 3762 loss: 5.86072929e-07
Iter: 3763 loss: 5.86026033e-07
Iter: 3764 loss: 5.86019439e-07
Iter: 3765 loss: 5.85968564e-07
Iter: 3766 loss: 5.85905411e-07
Iter: 3767 loss: 5.862683e-07
Iter: 3768 loss: 5.85884322e-07
Iter: 3769 loss: 5.85819407e-07
Iter: 3770 loss: 5.85829582e-07
Iter: 3771 loss: 5.85767566e-07
Iter: 3772 loss: 5.85708221e-07
Iter: 3773 loss: 5.86428882e-07
Iter: 3774 loss: 5.85703219e-07
Iter: 3775 loss: 5.85641487e-07
Iter: 3776 loss: 5.85639896e-07
Iter: 3777 loss: 5.85614885e-07
Iter: 3778 loss: 5.8552007e-07
Iter: 3779 loss: 5.85875455e-07
Iter: 3780 loss: 5.85500288e-07
Iter: 3781 loss: 5.85445719e-07
Iter: 3782 loss: 5.85602379e-07
Iter: 3783 loss: 5.85422e-07
Iter: 3784 loss: 5.85360283e-07
Iter: 3785 loss: 5.85629891e-07
Iter: 3786 loss: 5.85327257e-07
Iter: 3787 loss: 5.85276041e-07
Iter: 3788 loss: 5.85201064e-07
Iter: 3789 loss: 5.85189866e-07
Iter: 3790 loss: 5.85095e-07
Iter: 3791 loss: 5.85348175e-07
Iter: 3792 loss: 5.8507203e-07
Iter: 3793 loss: 5.8503116e-07
Iter: 3794 loss: 5.85017915e-07
Iter: 3795 loss: 5.84991653e-07
Iter: 3796 loss: 5.84926397e-07
Iter: 3797 loss: 5.8491446e-07
Iter: 3798 loss: 5.84864836e-07
Iter: 3799 loss: 5.85255805e-07
Iter: 3800 loss: 5.84860231e-07
Iter: 3801 loss: 5.84816632e-07
Iter: 3802 loss: 5.84816519e-07
Iter: 3803 loss: 5.84770532e-07
Iter: 3804 loss: 5.8473131e-07
Iter: 3805 loss: 5.85097951e-07
Iter: 3806 loss: 5.84718e-07
Iter: 3807 loss: 5.84658096e-07
Iter: 3808 loss: 5.84713575e-07
Iter: 3809 loss: 5.84634449e-07
Iter: 3810 loss: 5.84574082e-07
Iter: 3811 loss: 5.84704253e-07
Iter: 3812 loss: 5.84557711e-07
Iter: 3813 loss: 5.84504846e-07
Iter: 3814 loss: 5.84599775e-07
Iter: 3815 loss: 5.84473753e-07
Iter: 3816 loss: 5.84407758e-07
Iter: 3817 loss: 5.84844031e-07
Iter: 3818 loss: 5.8439673e-07
Iter: 3819 loss: 5.84353302e-07
Iter: 3820 loss: 5.84295549e-07
Iter: 3821 loss: 5.8428634e-07
Iter: 3822 loss: 5.84199256e-07
Iter: 3823 loss: 5.84264399e-07
Iter: 3824 loss: 5.84147642e-07
Iter: 3825 loss: 5.84135819e-07
Iter: 3826 loss: 5.84107909e-07
Iter: 3827 loss: 5.84069653e-07
Iter: 3828 loss: 5.84001157e-07
Iter: 3829 loss: 5.84000531e-07
Iter: 3830 loss: 5.8393681e-07
Iter: 3831 loss: 5.84472446e-07
Iter: 3832 loss: 5.83926919e-07
Iter: 3833 loss: 5.83877181e-07
Iter: 3834 loss: 5.83841654e-07
Iter: 3835 loss: 5.83820565e-07
Iter: 3836 loss: 5.83726887e-07
Iter: 3837 loss: 5.84109102e-07
Iter: 3838 loss: 5.83706253e-07
Iter: 3839 loss: 5.83606891e-07
Iter: 3840 loss: 5.83952215e-07
Iter: 3841 loss: 5.83566077e-07
Iter: 3842 loss: 5.83493886e-07
Iter: 3843 loss: 5.83648671e-07
Iter: 3844 loss: 5.8346609e-07
Iter: 3845 loss: 5.83391909e-07
Iter: 3846 loss: 5.83555902e-07
Iter: 3847 loss: 5.83372412e-07
Iter: 3848 loss: 5.83256963e-07
Iter: 3849 loss: 5.84101826e-07
Iter: 3850 loss: 5.83258611e-07
Iter: 3851 loss: 5.83193525e-07
Iter: 3852 loss: 5.83087683e-07
Iter: 3853 loss: 5.85476698e-07
Iter: 3854 loss: 5.8308342e-07
Iter: 3855 loss: 5.82933808e-07
Iter: 3856 loss: 5.83218764e-07
Iter: 3857 loss: 5.82877533e-07
Iter: 3858 loss: 5.82846781e-07
Iter: 3859 loss: 5.82814209e-07
Iter: 3860 loss: 5.82766916e-07
Iter: 3861 loss: 5.8267824e-07
Iter: 3862 loss: 5.84753707e-07
Iter: 3863 loss: 5.82683242e-07
Iter: 3864 loss: 5.8257973e-07
Iter: 3865 loss: 5.83745305e-07
Iter: 3866 loss: 5.82589678e-07
Iter: 3867 loss: 5.82515156e-07
Iter: 3868 loss: 5.82519e-07
Iter: 3869 loss: 5.82479402e-07
Iter: 3870 loss: 5.82363498e-07
Iter: 3871 loss: 5.82600592e-07
Iter: 3872 loss: 5.82349458e-07
Iter: 3873 loss: 5.82262828e-07
Iter: 3874 loss: 5.82912321e-07
Iter: 3875 loss: 5.82247935e-07
Iter: 3876 loss: 5.82211783e-07
Iter: 3877 loss: 5.82251062e-07
Iter: 3878 loss: 5.82156076e-07
Iter: 3879 loss: 5.82113e-07
Iter: 3880 loss: 5.82210532e-07
Iter: 3881 loss: 5.82098778e-07
Iter: 3882 loss: 5.82061602e-07
Iter: 3883 loss: 5.82709504e-07
Iter: 3884 loss: 5.82054327e-07
Iter: 3885 loss: 5.81992708e-07
Iter: 3886 loss: 5.81952804e-07
Iter: 3887 loss: 5.81953145e-07
Iter: 3888 loss: 5.81873735e-07
Iter: 3889 loss: 5.81997483e-07
Iter: 3890 loss: 5.81867255e-07
Iter: 3891 loss: 5.81823e-07
Iter: 3892 loss: 5.81825e-07
Iter: 3893 loss: 5.81784e-07
Iter: 3894 loss: 5.81727136e-07
Iter: 3895 loss: 5.81716449e-07
Iter: 3896 loss: 5.81657559e-07
Iter: 3897 loss: 5.82263795e-07
Iter: 3898 loss: 5.81675806e-07
Iter: 3899 loss: 5.81617769e-07
Iter: 3900 loss: 5.81614472e-07
Iter: 3901 loss: 5.815686e-07
Iter: 3902 loss: 5.8149908e-07
Iter: 3903 loss: 5.81686322e-07
Iter: 3904 loss: 5.81485949e-07
Iter: 3905 loss: 5.81392612e-07
Iter: 3906 loss: 5.8165466e-07
Iter: 3907 loss: 5.8138437e-07
Iter: 3908 loss: 5.81315874e-07
Iter: 3909 loss: 5.81423308e-07
Iter: 3910 loss: 5.81300185e-07
Iter: 3911 loss: 5.81238965e-07
Iter: 3912 loss: 5.81418817e-07
Iter: 3913 loss: 5.81208894e-07
Iter: 3914 loss: 5.81156428e-07
Iter: 3915 loss: 5.81640165e-07
Iter: 3916 loss: 5.81156e-07
Iter: 3917 loss: 5.81124539e-07
Iter: 3918 loss: 5.81047971e-07
Iter: 3919 loss: 5.82716382e-07
Iter: 3920 loss: 5.81045697e-07
Iter: 3921 loss: 5.80954861e-07
Iter: 3922 loss: 5.810831e-07
Iter: 3923 loss: 5.80929566e-07
Iter: 3924 loss: 5.80854589e-07
Iter: 3925 loss: 5.81775907e-07
Iter: 3926 loss: 5.80848337e-07
Iter: 3927 loss: 5.8077768e-07
Iter: 3928 loss: 5.80742551e-07
Iter: 3929 loss: 5.80712424e-07
Iter: 3930 loss: 5.80638584e-07
Iter: 3931 loss: 5.81369818e-07
Iter: 3932 loss: 5.80642279e-07
Iter: 3933 loss: 5.80590779e-07
Iter: 3934 loss: 5.80510516e-07
Iter: 3935 loss: 5.80509e-07
Iter: 3936 loss: 5.80409e-07
Iter: 3937 loss: 5.81109362e-07
Iter: 3938 loss: 5.80402173e-07
Iter: 3939 loss: 5.80341521e-07
Iter: 3940 loss: 5.80549852e-07
Iter: 3941 loss: 5.80316623e-07
Iter: 3942 loss: 5.80269159e-07
Iter: 3943 loss: 5.80312872e-07
Iter: 3944 loss: 5.80230278e-07
Iter: 3945 loss: 5.80165249e-07
Iter: 3946 loss: 5.80412348e-07
Iter: 3947 loss: 5.80156495e-07
Iter: 3948 loss: 5.80108519e-07
Iter: 3949 loss: 5.80632786e-07
Iter: 3950 loss: 5.80100846e-07
Iter: 3951 loss: 5.80074357e-07
Iter: 3952 loss: 5.80005747e-07
Iter: 3953 loss: 5.81196446e-07
Iter: 3954 loss: 5.79996652e-07
Iter: 3955 loss: 5.79899961e-07
Iter: 3956 loss: 5.80287178e-07
Iter: 3957 loss: 5.79882055e-07
Iter: 3958 loss: 5.7982993e-07
Iter: 3959 loss: 5.80437245e-07
Iter: 3960 loss: 5.79820153e-07
Iter: 3961 loss: 5.79770415e-07
Iter: 3962 loss: 5.79779055e-07
Iter: 3963 loss: 5.79736707e-07
Iter: 3964 loss: 5.79674463e-07
Iter: 3965 loss: 5.80088965e-07
Iter: 3966 loss: 5.79659911e-07
Iter: 3967 loss: 5.79608866e-07
Iter: 3968 loss: 5.79592893e-07
Iter: 3969 loss: 5.79559298e-07
Iter: 3970 loss: 5.79495577e-07
Iter: 3971 loss: 5.80047754e-07
Iter: 3972 loss: 5.79496714e-07
Iter: 3973 loss: 5.79455275e-07
Iter: 3974 loss: 5.79541563e-07
Iter: 3975 loss: 5.79427137e-07
Iter: 3976 loss: 5.79365917e-07
Iter: 3977 loss: 5.79389848e-07
Iter: 3978 loss: 5.79344658e-07
Iter: 3979 loss: 5.79278435e-07
Iter: 3980 loss: 5.79618e-07
Iter: 3981 loss: 5.7925979e-07
Iter: 3982 loss: 5.79203856e-07
Iter: 3983 loss: 5.79676168e-07
Iter: 3984 loss: 5.79209541e-07
Iter: 3985 loss: 5.79182483e-07
Iter: 3986 loss: 5.79104949e-07
Iter: 3987 loss: 5.79103698e-07
Iter: 3988 loss: 5.79011157e-07
Iter: 3989 loss: 5.79451182e-07
Iter: 3990 loss: 5.7898626e-07
Iter: 3991 loss: 5.78943514e-07
Iter: 3992 loss: 5.79287587e-07
Iter: 3993 loss: 5.7893044e-07
Iter: 3994 loss: 5.78873312e-07
Iter: 3995 loss: 5.78940501e-07
Iter: 3996 loss: 5.78846425e-07
Iter: 3997 loss: 5.78792708e-07
Iter: 3998 loss: 5.79152527e-07
Iter: 3999 loss: 5.78793106e-07
Iter: 4000 loss: 5.78746096e-07
Iter: 4001 loss: 5.78720631e-07
Iter: 4002 loss: 5.78706249e-07
Iter: 4003 loss: 5.78654067e-07
Iter: 4004 loss: 5.79085054e-07
Iter: 4005 loss: 5.78644688e-07
Iter: 4006 loss: 5.7860052e-07
Iter: 4007 loss: 5.78678907e-07
Iter: 4008 loss: 5.78579829e-07
Iter: 4009 loss: 5.78535662e-07
Iter: 4010 loss: 5.78593472e-07
Iter: 4011 loss: 5.78507922e-07
Iter: 4012 loss: 5.78446645e-07
Iter: 4013 loss: 5.7868607e-07
Iter: 4014 loss: 5.78440961e-07
Iter: 4015 loss: 5.78405889e-07
Iter: 4016 loss: 5.78756044e-07
Iter: 4017 loss: 5.78406855e-07
Iter: 4018 loss: 5.78371214e-07
Iter: 4019 loss: 5.78344611e-07
Iter: 4020 loss: 5.78332333e-07
Iter: 4021 loss: 5.78286176e-07
Iter: 4022 loss: 5.78474953e-07
Iter: 4023 loss: 5.78273728e-07
Iter: 4024 loss: 5.78232857e-07
Iter: 4025 loss: 5.7850275e-07
Iter: 4026 loss: 5.7823695e-07
Iter: 4027 loss: 5.78192044e-07
Iter: 4028 loss: 5.78264e-07
Iter: 4029 loss: 5.78179424e-07
Iter: 4030 loss: 5.7814168e-07
Iter: 4031 loss: 5.78258152e-07
Iter: 4032 loss: 5.78157767e-07
Iter: 4033 loss: 5.78128038e-07
Iter: 4034 loss: 5.78076879e-07
Iter: 4035 loss: 5.78075969e-07
Iter: 4036 loss: 5.78031631e-07
Iter: 4037 loss: 5.78444e-07
Iter: 4038 loss: 5.78011111e-07
Iter: 4039 loss: 5.78001561e-07
Iter: 4040 loss: 5.78045331e-07
Iter: 4041 loss: 5.77993433e-07
Iter: 4042 loss: 5.77955859e-07
Iter: 4043 loss: 5.77982348e-07
Iter: 4044 loss: 5.77944093e-07
Iter: 4045 loss: 5.77900778e-07
Iter: 4046 loss: 5.78085e-07
Iter: 4047 loss: 5.77894298e-07
Iter: 4048 loss: 5.77854678e-07
Iter: 4049 loss: 5.78118318e-07
Iter: 4050 loss: 5.77860249e-07
Iter: 4051 loss: 5.77826256e-07
Iter: 4052 loss: 5.77790047e-07
Iter: 4053 loss: 5.77782146e-07
Iter: 4054 loss: 5.7773741e-07
Iter: 4055 loss: 5.77817787e-07
Iter: 4056 loss: 5.77714161e-07
Iter: 4057 loss: 5.77671528e-07
Iter: 4058 loss: 5.77904416e-07
Iter: 4059 loss: 5.7766772e-07
Iter: 4060 loss: 5.77622757e-07
Iter: 4061 loss: 5.77790956e-07
Iter: 4062 loss: 5.77615424e-07
Iter: 4063 loss: 5.77589617e-07
Iter: 4064 loss: 5.77671e-07
Iter: 4065 loss: 5.77591095e-07
Iter: 4066 loss: 5.77562787e-07
Iter: 4067 loss: 5.77554829e-07
Iter: 4068 loss: 5.77533967e-07
Iter: 4069 loss: 5.77486958e-07
Iter: 4070 loss: 5.77829383e-07
Iter: 4071 loss: 5.77484741e-07
Iter: 4072 loss: 5.77449214e-07
Iter: 4073 loss: 5.77508445e-07
Iter: 4074 loss: 5.77441426e-07
Iter: 4075 loss: 5.77397088e-07
Iter: 4076 loss: 5.77403171e-07
Iter: 4077 loss: 5.77376341e-07
Iter: 4078 loss: 5.77334163e-07
Iter: 4079 loss: 5.77519359e-07
Iter: 4080 loss: 5.77317678e-07
Iter: 4081 loss: 5.77290393e-07
Iter: 4082 loss: 5.77538174e-07
Iter: 4083 loss: 5.77284936e-07
Iter: 4084 loss: 5.77252706e-07
Iter: 4085 loss: 5.77220135e-07
Iter: 4086 loss: 5.77204446e-07
Iter: 4087 loss: 5.77174887e-07
Iter: 4088 loss: 5.7726993e-07
Iter: 4089 loss: 5.77160336e-07
Iter: 4090 loss: 5.77116793e-07
Iter: 4091 loss: 5.77380831e-07
Iter: 4092 loss: 5.77130095e-07
Iter: 4093 loss: 5.7708553e-07
Iter: 4094 loss: 5.77244919e-07
Iter: 4095 loss: 5.77089736e-07
Iter: 4096 loss: 5.77066487e-07
Iter: 4097 loss: 5.77082574e-07
Iter: 4098 loss: 5.77051537e-07
Iter: 4099 loss: 5.76989294e-07
Iter: 4100 loss: 5.77018e-07
Iter: 4101 loss: 5.76972525e-07
Iter: 4102 loss: 5.76920911e-07
Iter: 4103 loss: 5.77169658e-07
Iter: 4104 loss: 5.76911475e-07
Iter: 4105 loss: 5.76877596e-07
Iter: 4106 loss: 5.76895104e-07
Iter: 4107 loss: 5.76877483e-07
Iter: 4108 loss: 5.76830416e-07
Iter: 4109 loss: 5.76891694e-07
Iter: 4110 loss: 5.7681433e-07
Iter: 4111 loss: 5.76774e-07
Iter: 4112 loss: 5.76946832e-07
Iter: 4113 loss: 5.76762602e-07
Iter: 4114 loss: 5.76726393e-07
Iter: 4115 loss: 5.76922275e-07
Iter: 4116 loss: 5.76719799e-07
Iter: 4117 loss: 5.76688876e-07
Iter: 4118 loss: 5.7668359e-07
Iter: 4119 loss: 5.76676314e-07
Iter: 4120 loss: 5.76645334e-07
Iter: 4121 loss: 5.76733669e-07
Iter: 4122 loss: 5.76635955e-07
Iter: 4123 loss: 5.76588207e-07
Iter: 4124 loss: 5.76723664e-07
Iter: 4125 loss: 5.7658167e-07
Iter: 4126 loss: 5.76550349e-07
Iter: 4127 loss: 5.76749e-07
Iter: 4128 loss: 5.7655e-07
Iter: 4129 loss: 5.76518687e-07
Iter: 4130 loss: 5.7652818e-07
Iter: 4131 loss: 5.76507944e-07
Iter: 4132 loss: 5.76456443e-07
Iter: 4133 loss: 5.76546e-07
Iter: 4134 loss: 5.76449793e-07
Iter: 4135 loss: 5.76395678e-07
Iter: 4136 loss: 5.76556431e-07
Iter: 4137 loss: 5.76399486e-07
Iter: 4138 loss: 5.76364e-07
Iter: 4139 loss: 5.76418415e-07
Iter: 4140 loss: 5.76347588e-07
Iter: 4141 loss: 5.76310185e-07
Iter: 4142 loss: 5.7641455e-07
Iter: 4143 loss: 5.76282503e-07
Iter: 4144 loss: 5.76262835e-07
Iter: 4145 loss: 5.76362822e-07
Iter: 4146 loss: 5.76256866e-07
Iter: 4147 loss: 5.76226967e-07
Iter: 4148 loss: 5.76428874e-07
Iter: 4149 loss: 5.76214234e-07
Iter: 4150 loss: 5.7617865e-07
Iter: 4151 loss: 5.76166599e-07
Iter: 4152 loss: 5.76163245e-07
Iter: 4153 loss: 5.76125103e-07
Iter: 4154 loss: 5.7621935e-07
Iter: 4155 loss: 5.76100319e-07
Iter: 4156 loss: 5.76066213e-07
Iter: 4157 loss: 5.76232878e-07
Iter: 4158 loss: 5.76074569e-07
Iter: 4159 loss: 5.76050525e-07
Iter: 4160 loss: 5.76220145e-07
Iter: 4161 loss: 5.76050468e-07
Iter: 4162 loss: 5.76023808e-07
Iter: 4163 loss: 5.76034495e-07
Iter: 4164 loss: 5.76001185e-07
Iter: 4165 loss: 5.75968386e-07
Iter: 4166 loss: 5.76033131e-07
Iter: 4167 loss: 5.75959064e-07
Iter: 4168 loss: 5.75920865e-07
Iter: 4169 loss: 5.76066384e-07
Iter: 4170 loss: 5.75894546e-07
Iter: 4171 loss: 5.75880961e-07
Iter: 4172 loss: 5.7593985e-07
Iter: 4173 loss: 5.75868796e-07
Iter: 4174 loss: 5.75833269e-07
Iter: 4175 loss: 5.75905119e-07
Iter: 4176 loss: 5.75832701e-07
Iter: 4177 loss: 5.75784895e-07
Iter: 4178 loss: 5.75856916e-07
Iter: 4179 loss: 5.75782224e-07
Iter: 4180 loss: 5.75745503e-07
Iter: 4181 loss: 5.75987201e-07
Iter: 4182 loss: 5.75752779e-07
Iter: 4183 loss: 5.75712761e-07
Iter: 4184 loss: 5.75675131e-07
Iter: 4185 loss: 5.75691445e-07
Iter: 4186 loss: 5.75635e-07
Iter: 4187 loss: 5.75691047e-07
Iter: 4188 loss: 5.75628235e-07
Iter: 4189 loss: 5.75590377e-07
Iter: 4190 loss: 5.75822298e-07
Iter: 4191 loss: 5.75592878e-07
Iter: 4192 loss: 5.75573608e-07
Iter: 4193 loss: 5.75701165e-07
Iter: 4194 loss: 5.75568038e-07
Iter: 4195 loss: 5.75557806e-07
Iter: 4196 loss: 5.75529043e-07
Iter: 4197 loss: 5.7552171e-07
Iter: 4198 loss: 5.75468221e-07
Iter: 4199 loss: 5.7566848e-07
Iter: 4200 loss: 5.75455147e-07
Iter: 4201 loss: 5.75417403e-07
Iter: 4202 loss: 5.75605611e-07
Iter: 4203 loss: 5.75421438e-07
Iter: 4204 loss: 5.75394267e-07
Iter: 4205 loss: 5.75451168e-07
Iter: 4206 loss: 5.75386593e-07
Iter: 4207 loss: 5.75340721e-07
Iter: 4208 loss: 5.75422519e-07
Iter: 4209 loss: 5.75327306e-07
Iter: 4210 loss: 5.75301954e-07
Iter: 4211 loss: 5.75364197e-07
Iter: 4212 loss: 5.75283536e-07
Iter: 4213 loss: 5.75252e-07
Iter: 4214 loss: 5.75662057e-07
Iter: 4215 loss: 5.75250283e-07
Iter: 4216 loss: 5.75225783e-07
Iter: 4217 loss: 5.75184856e-07
Iter: 4218 loss: 5.75177125e-07
Iter: 4219 loss: 5.75140064e-07
Iter: 4220 loss: 5.75247952e-07
Iter: 4221 loss: 5.75101126e-07
Iter: 4222 loss: 5.7505622e-07
Iter: 4223 loss: 5.75509432e-07
Iter: 4224 loss: 5.75057868e-07
Iter: 4225 loss: 5.75033255e-07
Iter: 4226 loss: 5.75166553e-07
Iter: 4227 loss: 5.75042918e-07
Iter: 4228 loss: 5.74992555e-07
Iter: 4229 loss: 5.74945886e-07
Iter: 4230 loss: 5.74938e-07
Iter: 4231 loss: 5.74866e-07
Iter: 4232 loss: 5.75423599e-07
Iter: 4233 loss: 5.74854255e-07
Iter: 4234 loss: 5.74833052e-07
Iter: 4235 loss: 5.7496419e-07
Iter: 4236 loss: 5.74813214e-07
Iter: 4237 loss: 5.74787521e-07
Iter: 4238 loss: 5.74833052e-07
Iter: 4239 loss: 5.74756768e-07
Iter: 4240 loss: 5.74718797e-07
Iter: 4241 loss: 5.74812134e-07
Iter: 4242 loss: 5.74680598e-07
Iter: 4243 loss: 5.74650869e-07
Iter: 4244 loss: 5.74673891e-07
Iter: 4245 loss: 5.74606361e-07
Iter: 4246 loss: 5.74558157e-07
Iter: 4247 loss: 5.75178547e-07
Iter: 4248 loss: 5.7456117e-07
Iter: 4249 loss: 5.74509954e-07
Iter: 4250 loss: 5.7447744e-07
Iter: 4251 loss: 5.74466185e-07
Iter: 4252 loss: 5.74420369e-07
Iter: 4253 loss: 5.74522119e-07
Iter: 4254 loss: 5.74369e-07
Iter: 4255 loss: 5.74308899e-07
Iter: 4256 loss: 5.74665364e-07
Iter: 4257 loss: 5.74301055e-07
Iter: 4258 loss: 5.74261151e-07
Iter: 4259 loss: 5.74574187e-07
Iter: 4260 loss: 5.74259275e-07
Iter: 4261 loss: 5.74200328e-07
Iter: 4262 loss: 5.74177534e-07
Iter: 4263 loss: 5.74174749e-07
Iter: 4264 loss: 5.74098635e-07
Iter: 4265 loss: 5.74663432e-07
Iter: 4266 loss: 5.74093747e-07
Iter: 4267 loss: 5.740593e-07
Iter: 4268 loss: 5.7412376e-07
Iter: 4269 loss: 5.7404128e-07
Iter: 4270 loss: 5.74002911e-07
Iter: 4271 loss: 5.74103467e-07
Iter: 4272 loss: 5.73984e-07
Iter: 4273 loss: 5.73934187e-07
Iter: 4274 loss: 5.740402e-07
Iter: 4275 loss: 5.73922762e-07
Iter: 4276 loss: 5.73883312e-07
Iter: 4277 loss: 5.73884222e-07
Iter: 4278 loss: 5.73850798e-07
Iter: 4279 loss: 5.73794864e-07
Iter: 4280 loss: 5.74593e-07
Iter: 4281 loss: 5.73795319e-07
Iter: 4282 loss: 5.7375496e-07
Iter: 4283 loss: 5.73715056e-07
Iter: 4284 loss: 5.7371517e-07
Iter: 4285 loss: 5.73654802e-07
Iter: 4286 loss: 5.73758882e-07
Iter: 4287 loss: 5.73640591e-07
Iter: 4288 loss: 5.7356948e-07
Iter: 4289 loss: 5.73981197e-07
Iter: 4290 loss: 5.73574937e-07
Iter: 4291 loss: 5.73529633e-07
Iter: 4292 loss: 5.73815385e-07
Iter: 4293 loss: 5.73515081e-07
Iter: 4294 loss: 5.73489331e-07
Iter: 4295 loss: 5.73472335e-07
Iter: 4296 loss: 5.73462103e-07
Iter: 4297 loss: 5.73400143e-07
Iter: 4298 loss: 5.73839543e-07
Iter: 4299 loss: 5.7339696e-07
Iter: 4300 loss: 5.73366151e-07
Iter: 4301 loss: 5.73421971e-07
Iter: 4302 loss: 5.73345119e-07
Iter: 4303 loss: 5.73320449e-07
Iter: 4304 loss: 5.73452155e-07
Iter: 4305 loss: 5.7329828e-07
Iter: 4306 loss: 5.73256671e-07
Iter: 4307 loss: 5.73325167e-07
Iter: 4308 loss: 5.7323507e-07
Iter: 4309 loss: 5.73184138e-07
Iter: 4310 loss: 5.73179e-07
Iter: 4311 loss: 5.73155432e-07
Iter: 4312 loss: 5.73105297e-07
Iter: 4313 loss: 5.73122804e-07
Iter: 4314 loss: 5.73073237e-07
Iter: 4315 loss: 5.73006105e-07
Iter: 4316 loss: 5.73015882e-07
Iter: 4317 loss: 5.72950967e-07
Iter: 4318 loss: 5.73079888e-07
Iter: 4319 loss: 5.72927092e-07
Iter: 4320 loss: 5.72898557e-07
Iter: 4321 loss: 5.73311354e-07
Iter: 4322 loss: 5.72893725e-07
Iter: 4323 loss: 5.72869908e-07
Iter: 4324 loss: 5.73048851e-07
Iter: 4325 loss: 5.72855924e-07
Iter: 4326 loss: 5.7283944e-07
Iter: 4327 loss: 5.72789e-07
Iter: 4328 loss: 5.72789304e-07
Iter: 4329 loss: 5.72728482e-07
Iter: 4330 loss: 5.73235468e-07
Iter: 4331 loss: 5.72717681e-07
Iter: 4332 loss: 5.72689089e-07
Iter: 4333 loss: 5.72732858e-07
Iter: 4334 loss: 5.7265936e-07
Iter: 4335 loss: 5.72608826e-07
Iter: 4336 loss: 5.72786462e-07
Iter: 4337 loss: 5.72595e-07
Iter: 4338 loss: 5.72564431e-07
Iter: 4339 loss: 5.72646e-07
Iter: 4340 loss: 5.72537203e-07
Iter: 4341 loss: 5.72481326e-07
Iter: 4342 loss: 5.72494628e-07
Iter: 4343 loss: 5.72446083e-07
Iter: 4344 loss: 5.72407714e-07
Iter: 4345 loss: 5.72415672e-07
Iter: 4346 loss: 5.72368663e-07
Iter: 4347 loss: 5.72318186e-07
Iter: 4348 loss: 5.72307556e-07
Iter: 4349 loss: 5.72256e-07
Iter: 4350 loss: 5.72385375e-07
Iter: 4351 loss: 5.72247245e-07
Iter: 4352 loss: 5.72185456e-07
Iter: 4353 loss: 5.7262713e-07
Iter: 4354 loss: 5.72189379e-07
Iter: 4355 loss: 5.72143335e-07
Iter: 4356 loss: 5.7231216e-07
Iter: 4357 loss: 5.72136059e-07
Iter: 4358 loss: 5.72089562e-07
Iter: 4359 loss: 5.72091494e-07
Iter: 4360 loss: 5.72069098e-07
Iter: 4361 loss: 5.7201828e-07
Iter: 4362 loss: 5.72508554e-07
Iter: 4363 loss: 5.72016063e-07
Iter: 4364 loss: 5.71984344e-07
Iter: 4365 loss: 5.71993837e-07
Iter: 4366 loss: 5.71951205e-07
Iter: 4367 loss: 5.71916132e-07
Iter: 4368 loss: 5.72087629e-07
Iter: 4369 loss: 5.71890382e-07
Iter: 4370 loss: 5.71859459e-07
Iter: 4371 loss: 5.71920737e-07
Iter: 4372 loss: 5.71835812e-07
Iter: 4373 loss: 5.71801422e-07
Iter: 4374 loss: 5.71816258e-07
Iter: 4375 loss: 5.71782834e-07
Iter: 4376 loss: 5.71724968e-07
Iter: 4377 loss: 5.72271e-07
Iter: 4378 loss: 5.71734745e-07
Iter: 4379 loss: 5.71706551e-07
Iter: 4380 loss: 5.71681596e-07
Iter: 4381 loss: 5.71683699e-07
Iter: 4382 loss: 5.71640726e-07
Iter: 4383 loss: 5.71696205e-07
Iter: 4384 loss: 5.71621115e-07
Iter: 4385 loss: 5.71602413e-07
Iter: 4386 loss: 5.71794203e-07
Iter: 4387 loss: 5.71591613e-07
Iter: 4388 loss: 5.7156e-07
Iter: 4389 loss: 5.71758164e-07
Iter: 4390 loss: 5.71558417e-07
Iter: 4391 loss: 5.7152215e-07
Iter: 4392 loss: 5.71541364e-07
Iter: 4393 loss: 5.71530848e-07
Iter: 4394 loss: 5.71486396e-07
Iter: 4395 loss: 5.71707687e-07
Iter: 4396 loss: 5.71480598e-07
Iter: 4397 loss: 5.71457178e-07
Iter: 4398 loss: 5.71432849e-07
Iter: 4399 loss: 5.71432565e-07
Iter: 4400 loss: 5.71383e-07
Iter: 4401 loss: 5.71611736e-07
Iter: 4402 loss: 5.71362875e-07
Iter: 4403 loss: 5.71357646e-07
Iter: 4404 loss: 5.71409089e-07
Iter: 4405 loss: 5.71343946e-07
Iter: 4406 loss: 5.7131092e-07
Iter: 4407 loss: 5.7131183e-07
Iter: 4408 loss: 5.71274654e-07
Iter: 4409 loss: 5.71248506e-07
Iter: 4410 loss: 5.71254191e-07
Iter: 4411 loss: 5.71207465e-07
Iter: 4412 loss: 5.71173473e-07
Iter: 4413 loss: 5.71171938e-07
Iter: 4414 loss: 5.71122769e-07
Iter: 4415 loss: 5.7114039e-07
Iter: 4416 loss: 5.71084e-07
Iter: 4417 loss: 5.71037276e-07
Iter: 4418 loss: 5.71317912e-07
Iter: 4419 loss: 5.71018745e-07
Iter: 4420 loss: 5.70988163e-07
Iter: 4421 loss: 5.71237592e-07
Iter: 4422 loss: 5.70979751e-07
Iter: 4423 loss: 5.70941552e-07
Iter: 4424 loss: 5.70915745e-07
Iter: 4425 loss: 5.70888744e-07
Iter: 4426 loss: 5.70817178e-07
Iter: 4427 loss: 5.71227588e-07
Iter: 4428 loss: 5.70793702e-07
Iter: 4429 loss: 5.70748171e-07
Iter: 4430 loss: 5.70764428e-07
Iter: 4431 loss: 5.70705936e-07
Iter: 4432 loss: 5.70622092e-07
Iter: 4433 loss: 5.71224177e-07
Iter: 4434 loss: 5.70606971e-07
Iter: 4435 loss: 5.70554107e-07
Iter: 4436 loss: 5.70575935e-07
Iter: 4437 loss: 5.70516306e-07
Iter: 4438 loss: 5.70448435e-07
Iter: 4439 loss: 5.70472821e-07
Iter: 4440 loss: 5.70390455e-07
Iter: 4441 loss: 5.7032554e-07
Iter: 4442 loss: 5.71312739e-07
Iter: 4443 loss: 5.70311613e-07
Iter: 4444 loss: 5.70248574e-07
Iter: 4445 loss: 5.70234818e-07
Iter: 4446 loss: 5.70186216e-07
Iter: 4447 loss: 5.70131476e-07
Iter: 4448 loss: 5.7015626e-07
Iter: 4449 loss: 5.70069517e-07
Iter: 4450 loss: 5.69998917e-07
Iter: 4451 loss: 5.70313887e-07
Iter: 4452 loss: 5.69950771e-07
Iter: 4453 loss: 5.6989046e-07
Iter: 4454 loss: 5.70301893e-07
Iter: 4455 loss: 5.69870281e-07
Iter: 4456 loss: 5.69799681e-07
Iter: 4457 loss: 5.6988091e-07
Iter: 4458 loss: 5.69741246e-07
Iter: 4459 loss: 5.69657232e-07
Iter: 4460 loss: 5.70195425e-07
Iter: 4461 loss: 5.69666554e-07
Iter: 4462 loss: 5.69590838e-07
Iter: 4463 loss: 5.69606073e-07
Iter: 4464 loss: 5.69555596e-07
Iter: 4465 loss: 5.69482097e-07
Iter: 4466 loss: 5.69954295e-07
Iter: 4467 loss: 5.69452141e-07
Iter: 4468 loss: 5.69409053e-07
Iter: 4469 loss: 5.69489657e-07
Iter: 4470 loss: 5.69393649e-07
Iter: 4471 loss: 5.69321912e-07
Iter: 4472 loss: 5.69417409e-07
Iter: 4473 loss: 5.69292752e-07
Iter: 4474 loss: 5.69244548e-07
Iter: 4475 loss: 5.69843223e-07
Iter: 4476 loss: 5.69251824e-07
Iter: 4477 loss: 5.69204417e-07
Iter: 4478 loss: 5.69186227e-07
Iter: 4479 loss: 5.69161784e-07
Iter: 4480 loss: 5.69097097e-07
Iter: 4481 loss: 5.691669e-07
Iter: 4482 loss: 5.69065264e-07
Iter: 4483 loss: 5.6901041e-07
Iter: 4484 loss: 5.69239774e-07
Iter: 4485 loss: 5.68998e-07
Iter: 4486 loss: 5.68940436e-07
Iter: 4487 loss: 5.69175256e-07
Iter: 4488 loss: 5.68926055e-07
Iter: 4489 loss: 5.68838459e-07
Iter: 4490 loss: 5.68972382e-07
Iter: 4491 loss: 5.68846588e-07
Iter: 4492 loss: 5.68795713e-07
Iter: 4493 loss: 5.69025133e-07
Iter: 4494 loss: 5.68785197e-07
Iter: 4495 loss: 5.68746486e-07
Iter: 4496 loss: 5.68739665e-07
Iter: 4497 loss: 5.68699932e-07
Iter: 4498 loss: 5.68639393e-07
Iter: 4499 loss: 5.6910369e-07
Iter: 4500 loss: 5.68626888e-07
Iter: 4501 loss: 5.68568964e-07
Iter: 4502 loss: 5.68643486e-07
Iter: 4503 loss: 5.68538098e-07
Iter: 4504 loss: 5.68501832e-07
Iter: 4505 loss: 5.68562257e-07
Iter: 4506 loss: 5.68475343e-07
Iter: 4507 loss: 5.6842083e-07
Iter: 4508 loss: 5.68743303e-07
Iter: 4509 loss: 5.68417704e-07
Iter: 4510 loss: 5.68372911e-07
Iter: 4511 loss: 5.68382859e-07
Iter: 4512 loss: 5.68330393e-07
Iter: 4513 loss: 5.68267353e-07
Iter: 4514 loss: 5.68356938e-07
Iter: 4515 loss: 5.68257519e-07
Iter: 4516 loss: 5.68193741e-07
Iter: 4517 loss: 5.6840355e-07
Iter: 4518 loss: 5.68174812e-07
Iter: 4519 loss: 5.68096141e-07
Iter: 4520 loss: 5.68336247e-07
Iter: 4521 loss: 5.68107112e-07
Iter: 4522 loss: 5.68034807e-07
Iter: 4523 loss: 5.68174471e-07
Iter: 4524 loss: 5.68008e-07
Iter: 4525 loss: 5.67942777e-07
Iter: 4526 loss: 5.6815e-07
Iter: 4527 loss: 5.67920722e-07
Iter: 4528 loss: 5.67852396e-07
Iter: 4529 loss: 5.67921347e-07
Iter: 4530 loss: 5.67808115e-07
Iter: 4531 loss: 5.67773441e-07
Iter: 4532 loss: 5.6822e-07
Iter: 4533 loss: 5.67747747e-07
Iter: 4534 loss: 5.67700397e-07
Iter: 4535 loss: 5.67740813e-07
Iter: 4536 loss: 5.6765515e-07
Iter: 4537 loss: 5.67600637e-07
Iter: 4538 loss: 5.67721258e-07
Iter: 4539 loss: 5.67594384e-07
Iter: 4540 loss: 5.67519123e-07
Iter: 4541 loss: 5.67882239e-07
Iter: 4542 loss: 5.67537484e-07
Iter: 4543 loss: 5.67482914e-07
Iter: 4544 loss: 5.67502923e-07
Iter: 4545 loss: 5.67424081e-07
Iter: 4546 loss: 5.67383836e-07
Iter: 4547 loss: 5.6737656e-07
Iter: 4548 loss: 5.67320114e-07
Iter: 4549 loss: 5.67266625e-07
Iter: 4550 loss: 5.67537768e-07
Iter: 4551 loss: 5.67247639e-07
Iter: 4552 loss: 5.67164648e-07
Iter: 4553 loss: 5.67484e-07
Iter: 4554 loss: 5.67159873e-07
Iter: 4555 loss: 5.67096095e-07
Iter: 4556 loss: 5.67242864e-07
Iter: 4557 loss: 5.670625e-07
Iter: 4558 loss: 5.66993208e-07
Iter: 4559 loss: 5.67200743e-07
Iter: 4560 loss: 5.66993776e-07
Iter: 4561 loss: 5.66939207e-07
Iter: 4562 loss: 5.67038e-07
Iter: 4563 loss: 5.66914366e-07
Iter: 4564 loss: 5.66844051e-07
Iter: 4565 loss: 5.67175789e-07
Iter: 4566 loss: 5.66835297e-07
Iter: 4567 loss: 5.66803294e-07
Iter: 4568 loss: 5.66837343e-07
Iter: 4569 loss: 5.6677635e-07
Iter: 4570 loss: 5.66718e-07
Iter: 4571 loss: 5.66838253e-07
Iter: 4572 loss: 5.66690801e-07
Iter: 4573 loss: 5.6663896e-07
Iter: 4574 loss: 5.66954498e-07
Iter: 4575 loss: 5.66622703e-07
Iter: 4576 loss: 5.66572055e-07
Iter: 4577 loss: 5.66670508e-07
Iter: 4578 loss: 5.66539256e-07
Iter: 4579 loss: 5.66501058e-07
Iter: 4580 loss: 5.66496055e-07
Iter: 4581 loss: 5.66457572e-07
Iter: 4582 loss: 5.6637748e-07
Iter: 4583 loss: 5.66723372e-07
Iter: 4584 loss: 5.66370147e-07
Iter: 4585 loss: 5.66308302e-07
Iter: 4586 loss: 5.66550852e-07
Iter: 4587 loss: 5.6630563e-07
Iter: 4588 loss: 5.66224571e-07
Iter: 4589 loss: 5.66332119e-07
Iter: 4590 loss: 5.66206438e-07
Iter: 4591 loss: 5.66153176e-07
Iter: 4592 loss: 5.66363838e-07
Iter: 4593 loss: 5.66142262e-07
Iter: 4594 loss: 5.66091785e-07
Iter: 4595 loss: 5.66160793e-07
Iter: 4596 loss: 5.66057679e-07
Iter: 4597 loss: 5.65988785e-07
Iter: 4598 loss: 5.66265044e-07
Iter: 4599 loss: 5.65983328e-07
Iter: 4600 loss: 5.65929383e-07
Iter: 4601 loss: 5.65984749e-07
Iter: 4602 loss: 5.6588533e-07
Iter: 4603 loss: 5.65819732e-07
Iter: 4604 loss: 5.66017604e-07
Iter: 4605 loss: 5.65789833e-07
Iter: 4606 loss: 5.65735604e-07
Iter: 4607 loss: 5.65951609e-07
Iter: 4608 loss: 5.65704795e-07
Iter: 4609 loss: 5.65652385e-07
Iter: 4610 loss: 5.65841333e-07
Iter: 4611 loss: 5.65628454e-07
Iter: 4612 loss: 5.65569849e-07
Iter: 4613 loss: 5.65578034e-07
Iter: 4614 loss: 5.65524658e-07
Iter: 4615 loss: 5.65464234e-07
Iter: 4616 loss: 5.65783694e-07
Iter: 4617 loss: 5.65452297e-07
Iter: 4618 loss: 5.65393407e-07
Iter: 4619 loss: 5.65537675e-07
Iter: 4620 loss: 5.65359414e-07
Iter: 4621 loss: 5.65281312e-07
Iter: 4622 loss: 5.65490723e-07
Iter: 4623 loss: 5.65262212e-07
Iter: 4624 loss: 5.651832e-07
Iter: 4625 loss: 5.65377718e-07
Iter: 4626 loss: 5.65170581e-07
Iter: 4627 loss: 5.65095831e-07
Iter: 4628 loss: 5.65182745e-07
Iter: 4629 loss: 5.65071e-07
Iter: 4630 loss: 5.64985953e-07
Iter: 4631 loss: 5.65306266e-07
Iter: 4632 loss: 5.64974698e-07
Iter: 4633 loss: 5.64870561e-07
Iter: 4634 loss: 5.65049675e-07
Iter: 4635 loss: 5.64836682e-07
Iter: 4636 loss: 5.64791151e-07
Iter: 4637 loss: 5.64925529e-07
Iter: 4638 loss: 5.64759034e-07
Iter: 4639 loss: 5.64701111e-07
Iter: 4640 loss: 5.64930247e-07
Iter: 4641 loss: 5.64678203e-07
Iter: 4642 loss: 5.6461e-07
Iter: 4643 loss: 5.64879883e-07
Iter: 4644 loss: 5.64589186e-07
Iter: 4645 loss: 5.64507104e-07
Iter: 4646 loss: 5.64474e-07
Iter: 4647 loss: 5.64465836e-07
Iter: 4648 loss: 5.64368406e-07
Iter: 4649 loss: 5.64714071e-07
Iter: 4650 loss: 5.6435772e-07
Iter: 4651 loss: 5.6428263e-07
Iter: 4652 loss: 5.64469701e-07
Iter: 4653 loss: 5.64248353e-07
Iter: 4654 loss: 5.64154618e-07
Iter: 4655 loss: 5.64586458e-07
Iter: 4656 loss: 5.64141487e-07
Iter: 4657 loss: 5.64068614e-07
Iter: 4658 loss: 5.64274387e-07
Iter: 4659 loss: 5.64036668e-07
Iter: 4660 loss: 5.63953051e-07
Iter: 4661 loss: 5.64054517e-07
Iter: 4662 loss: 5.63909339e-07
Iter: 4663 loss: 5.63801279e-07
Iter: 4664 loss: 5.64186e-07
Iter: 4665 loss: 5.63780645e-07
Iter: 4666 loss: 5.63699189e-07
Iter: 4667 loss: 5.63963113e-07
Iter: 4668 loss: 5.63681112e-07
Iter: 4669 loss: 5.63613412e-07
Iter: 4670 loss: 5.6370061e-07
Iter: 4671 loss: 5.63568733e-07
Iter: 4672 loss: 5.63504273e-07
Iter: 4673 loss: 5.63769163e-07
Iter: 4674 loss: 5.63480057e-07
Iter: 4675 loss: 5.63382741e-07
Iter: 4676 loss: 5.63786671e-07
Iter: 4677 loss: 5.63375636e-07
Iter: 4678 loss: 5.63320896e-07
Iter: 4679 loss: 5.63274057e-07
Iter: 4680 loss: 5.63263939e-07
Iter: 4681 loss: 5.63169465e-07
Iter: 4682 loss: 5.63633421e-07
Iter: 4683 loss: 5.63167362e-07
Iter: 4684 loss: 5.63054e-07
Iter: 4685 loss: 5.6325905e-07
Iter: 4686 loss: 5.63022127e-07
Iter: 4687 loss: 5.629214e-07
Iter: 4688 loss: 5.63350113e-07
Iter: 4689 loss: 5.62890818e-07
Iter: 4690 loss: 5.62807486e-07
Iter: 4691 loss: 5.63005642e-07
Iter: 4692 loss: 5.6279157e-07
Iter: 4693 loss: 5.62715456e-07
Iter: 4694 loss: 5.62943683e-07
Iter: 4695 loss: 5.6270153e-07
Iter: 4696 loss: 5.6261274e-07
Iter: 4697 loss: 5.62862112e-07
Iter: 4698 loss: 5.62590969e-07
Iter: 4699 loss: 5.62507125e-07
Iter: 4700 loss: 5.62780485e-07
Iter: 4701 loss: 5.62486662e-07
Iter: 4702 loss: 5.62412879e-07
Iter: 4703 loss: 5.62489788e-07
Iter: 4704 loss: 5.62385139e-07
Iter: 4705 loss: 5.62298339e-07
Iter: 4706 loss: 5.625771e-07
Iter: 4707 loss: 5.62268667e-07
Iter: 4708 loss: 5.62195794e-07
Iter: 4709 loss: 5.62728872e-07
Iter: 4710 loss: 5.62209379e-07
Iter: 4711 loss: 5.62159755e-07
Iter: 4712 loss: 5.62072103e-07
Iter: 4713 loss: 5.63690833e-07
Iter: 4714 loss: 5.6205181e-07
Iter: 4715 loss: 5.61963702e-07
Iter: 4716 loss: 5.62652133e-07
Iter: 4717 loss: 5.61951879e-07
Iter: 4718 loss: 5.61854677e-07
Iter: 4719 loss: 5.6220307e-07
Iter: 4720 loss: 5.61826e-07
Iter: 4721 loss: 5.61740649e-07
Iter: 4722 loss: 5.62113541e-07
Iter: 4723 loss: 5.61724335e-07
Iter: 4724 loss: 5.61652485e-07
Iter: 4725 loss: 5.61773732e-07
Iter: 4726 loss: 5.61607806e-07
Iter: 4727 loss: 5.61535842e-07
Iter: 4728 loss: 5.61799652e-07
Iter: 4729 loss: 5.6151066e-07
Iter: 4730 loss: 5.61434092e-07
Iter: 4731 loss: 5.616929e-07
Iter: 4732 loss: 5.61419938e-07
Iter: 4733 loss: 5.61363208e-07
Iter: 4734 loss: 5.61485535e-07
Iter: 4735 loss: 5.61331035e-07
Iter: 4736 loss: 5.61233207e-07
Iter: 4737 loss: 5.61369e-07
Iter: 4738 loss: 5.61217348e-07
Iter: 4739 loss: 5.61145157e-07
Iter: 4740 loss: 5.613349e-07
Iter: 4741 loss: 5.61121169e-07
Iter: 4742 loss: 5.61070465e-07
Iter: 4743 loss: 5.61648335e-07
Iter: 4744 loss: 5.61045397e-07
Iter: 4745 loss: 5.61000604e-07
Iter: 4746 loss: 5.60888e-07
Iter: 4747 loss: 5.62244395e-07
Iter: 4748 loss: 5.60880267e-07
Iter: 4749 loss: 5.60744184e-07
Iter: 4750 loss: 5.62423111e-07
Iter: 4751 loss: 5.60734918e-07
Iter: 4752 loss: 5.60628166e-07
Iter: 4753 loss: 5.61082686e-07
Iter: 4754 loss: 5.6062936e-07
Iter: 4755 loss: 5.60533522e-07
Iter: 4756 loss: 5.60816602e-07
Iter: 4757 loss: 5.60509591e-07
Iter: 4758 loss: 5.6041921e-07
Iter: 4759 loss: 5.60664091e-07
Iter: 4760 loss: 5.60400792e-07
Iter: 4761 loss: 5.60320757e-07
Iter: 4762 loss: 5.60519084e-07
Iter: 4763 loss: 5.60295348e-07
Iter: 4764 loss: 5.6021986e-07
Iter: 4765 loss: 5.60439844e-07
Iter: 4766 loss: 5.60211e-07
Iter: 4767 loss: 5.60113961e-07
Iter: 4768 loss: 5.60266699e-07
Iter: 4769 loss: 5.60084914e-07
Iter: 4770 loss: 5.60008857e-07
Iter: 4771 loss: 5.60176034e-07
Iter: 4772 loss: 5.59960711e-07
Iter: 4773 loss: 5.59880732e-07
Iter: 4774 loss: 5.60062404e-07
Iter: 4775 loss: 5.598489e-07
Iter: 4776 loss: 5.59763521e-07
Iter: 4777 loss: 5.60735202e-07
Iter: 4778 loss: 5.5977489e-07
Iter: 4779 loss: 5.59732e-07
Iter: 4780 loss: 5.59604416e-07
Iter: 4781 loss: 5.60647379e-07
Iter: 4782 loss: 5.59588443e-07
Iter: 4783 loss: 5.59485898e-07
Iter: 4784 loss: 5.60890669e-07
Iter: 4785 loss: 5.5945668e-07
Iter: 4786 loss: 5.59375e-07
Iter: 4787 loss: 5.59520913e-07
Iter: 4788 loss: 5.59335433e-07
Iter: 4789 loss: 5.592251e-07
Iter: 4790 loss: 5.59781768e-07
Iter: 4791 loss: 5.59205489e-07
Iter: 4792 loss: 5.5913506e-07
Iter: 4793 loss: 5.59427406e-07
Iter: 4794 loss: 5.59110049e-07
Iter: 4795 loss: 5.59036266e-07
Iter: 4796 loss: 5.59230216e-07
Iter: 4797 loss: 5.59010687e-07
Iter: 4798 loss: 5.58955605e-07
Iter: 4799 loss: 5.59066166e-07
Iter: 4800 loss: 5.58914792e-07
Iter: 4801 loss: 5.58802697e-07
Iter: 4802 loss: 5.5901711e-07
Iter: 4803 loss: 5.58776605e-07
Iter: 4804 loss: 5.58694353e-07
Iter: 4805 loss: 5.589946e-07
Iter: 4806 loss: 5.58657689e-07
Iter: 4807 loss: 5.58594706e-07
Iter: 4808 loss: 5.58621196e-07
Iter: 4809 loss: 5.58533088e-07
Iter: 4810 loss: 5.58458339e-07
Iter: 4811 loss: 5.58456122e-07
Iter: 4812 loss: 5.58407919e-07
Iter: 4813 loss: 5.58291958e-07
Iter: 4814 loss: 5.58967599e-07
Iter: 4815 loss: 5.58257057e-07
Iter: 4816 loss: 5.58115971e-07
Iter: 4817 loss: 5.60264198e-07
Iter: 4818 loss: 5.58109207e-07
Iter: 4819 loss: 5.57999783e-07
Iter: 4820 loss: 5.58285592e-07
Iter: 4821 loss: 5.57968121e-07
Iter: 4822 loss: 5.57878479e-07
Iter: 4823 loss: 5.58385e-07
Iter: 4824 loss: 5.57852388e-07
Iter: 4825 loss: 5.5777673e-07
Iter: 4826 loss: 5.58121769e-07
Iter: 4827 loss: 5.57761439e-07
Iter: 4828 loss: 5.57689759e-07
Iter: 4829 loss: 5.57777e-07
Iter: 4830 loss: 5.57653607e-07
Iter: 4831 loss: 5.57579597e-07
Iter: 4832 loss: 5.57760302e-07
Iter: 4833 loss: 5.57557939e-07
Iter: 4834 loss: 5.57475687e-07
Iter: 4835 loss: 5.57733642e-07
Iter: 4836 loss: 5.57454314e-07
Iter: 4837 loss: 5.57364388e-07
Iter: 4838 loss: 5.57478245e-07
Iter: 4839 loss: 5.57332328e-07
Iter: 4840 loss: 5.57231942e-07
Iter: 4841 loss: 5.57284807e-07
Iter: 4842 loss: 5.57167368e-07
Iter: 4843 loss: 5.57109558e-07
Iter: 4844 loss: 5.57108137e-07
Iter: 4845 loss: 5.57054079e-07
Iter: 4846 loss: 5.56927148e-07
Iter: 4847 loss: 5.57659291e-07
Iter: 4848 loss: 5.56903728e-07
Iter: 4849 loss: 5.56782254e-07
Iter: 4850 loss: 5.58182933e-07
Iter: 4851 loss: 5.56766736e-07
Iter: 4852 loss: 5.56662371e-07
Iter: 4853 loss: 5.57247176e-07
Iter: 4854 loss: 5.56665668e-07
Iter: 4855 loss: 5.56599161e-07
Iter: 4856 loss: 5.56817326e-07
Iter: 4857 loss: 5.56565055e-07
Iter: 4858 loss: 5.56497753e-07
Iter: 4859 loss: 5.56699774e-07
Iter: 4860 loss: 5.56493433e-07
Iter: 4861 loss: 5.56401403e-07
Iter: 4862 loss: 5.56510031e-07
Iter: 4863 loss: 5.56355758e-07
Iter: 4864 loss: 5.56271971e-07
Iter: 4865 loss: 5.5663628e-07
Iter: 4866 loss: 5.56269129e-07
Iter: 4867 loss: 5.56179145e-07
Iter: 4868 loss: 5.56324494e-07
Iter: 4869 loss: 5.56139412e-07
Iter: 4870 loss: 5.56026464e-07
Iter: 4871 loss: 5.56122245e-07
Iter: 4872 loss: 5.55982183e-07
Iter: 4873 loss: 5.55859629e-07
Iter: 4874 loss: 5.55986389e-07
Iter: 4875 loss: 5.558e-07
Iter: 4876 loss: 5.5572832e-07
Iter: 4877 loss: 5.55725933e-07
Iter: 4878 loss: 5.55678639e-07
Iter: 4879 loss: 5.55542556e-07
Iter: 4880 loss: 5.56374e-07
Iter: 4881 loss: 5.55529596e-07
Iter: 4882 loss: 5.55402721e-07
Iter: 4883 loss: 5.57070564e-07
Iter: 4884 loss: 5.55399879e-07
Iter: 4885 loss: 5.55306883e-07
Iter: 4886 loss: 5.55675228e-07
Iter: 4887 loss: 5.55285624e-07
Iter: 4888 loss: 5.55206725e-07
Iter: 4889 loss: 5.55330075e-07
Iter: 4890 loss: 5.55200586e-07
Iter: 4891 loss: 5.5505933e-07
Iter: 4892 loss: 5.55514589e-07
Iter: 4893 loss: 5.55041595e-07
Iter: 4894 loss: 5.54939106e-07
Iter: 4895 loss: 5.55052736e-07
Iter: 4896 loss: 5.54895792e-07
Iter: 4897 loss: 5.54802568e-07
Iter: 4898 loss: 5.55209454e-07
Iter: 4899 loss: 5.54789494e-07
Iter: 4900 loss: 5.54705821e-07
Iter: 4901 loss: 5.5491887e-07
Iter: 4902 loss: 5.54677911e-07
Iter: 4903 loss: 5.54618964e-07
Iter: 4904 loss: 5.54700478e-07
Iter: 4905 loss: 5.54551889e-07
Iter: 4906 loss: 5.54444341e-07
Iter: 4907 loss: 5.54617145e-07
Iter: 4908 loss: 5.54438316e-07
Iter: 4909 loss: 5.54382154e-07
Iter: 4910 loss: 5.5439267e-07
Iter: 4911 loss: 5.54332473e-07
Iter: 4912 loss: 5.54214694e-07
Iter: 4913 loss: 5.55241854e-07
Iter: 4914 loss: 5.54217763e-07
Iter: 4915 loss: 5.54123517e-07
Iter: 4916 loss: 5.54805752e-07
Iter: 4917 loss: 5.54115957e-07
Iter: 4918 loss: 5.54053429e-07
Iter: 4919 loss: 5.54396593e-07
Iter: 4920 loss: 5.54056044e-07
Iter: 4921 loss: 5.53962423e-07
Iter: 4922 loss: 5.54012104e-07
Iter: 4923 loss: 5.53928942e-07
Iter: 4924 loss: 5.53819518e-07
Iter: 4925 loss: 5.54278358e-07
Iter: 4926 loss: 5.53784787e-07
Iter: 4927 loss: 5.53685368e-07
Iter: 4928 loss: 5.53804057e-07
Iter: 4929 loss: 5.53630684e-07
Iter: 4930 loss: 5.53520579e-07
Iter: 4931 loss: 5.54003e-07
Iter: 4932 loss: 5.53501536e-07
Iter: 4933 loss: 5.53424115e-07
Iter: 4934 loss: 5.53757957e-07
Iter: 4935 loss: 5.53395409e-07
Iter: 4936 loss: 5.53358461e-07
Iter: 4937 loss: 5.53402629e-07
Iter: 4938 loss: 5.53301561e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
+ for npairs in 1000 4000 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_8000/300_300_300_1 ']'
+ python biholoNN_train.py --seed 800013 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f1_psi1_phi0/300_300_300_1 --optimizer lbfgs --function f1 --psi 1 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output75/f1_psi1_phi0_8000/ --save_name 300_300_300_1 --max_epochs 5000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c4033ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c403728c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c4033ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c403a9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c403a91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c403a9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c402b3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c40282f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c4037cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c402152f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c4037cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c401e77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c401e7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c4018f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c4018f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c401e7ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c4012a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c400fdbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c400a4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c4006d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c400591e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c40050598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c4003ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c3966b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c3966b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c3960eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c3960e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c3962e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c395cc620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c395b5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c395cc7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c3957ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c3957a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c39531c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c394fd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c3948a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.43598e-06
Iter: 2 loss: 3.77850711e-06
Iter: 3 loss: 3.7413231e-06
Iter: 4 loss: 3.45825038e-06
Iter: 5 loss: 4.13544421e-06
Iter: 6 loss: 3.35598497e-06
Iter: 7 loss: 3.16220689e-06
Iter: 8 loss: 3.3715628e-06
Iter: 9 loss: 3.05608819e-06
Iter: 10 loss: 2.95765085e-06
Iter: 11 loss: 2.94340271e-06
Iter: 12 loss: 2.89364903e-06
Iter: 13 loss: 2.83655982e-06
Iter: 14 loss: 2.82951032e-06
Iter: 15 loss: 2.80909262e-06
Iter: 16 loss: 2.80326526e-06
Iter: 17 loss: 2.77933464e-06
Iter: 18 loss: 2.69894917e-06
Iter: 19 loss: 2.66548909e-06
Iter: 20 loss: 2.60447678e-06
Iter: 21 loss: 2.5700333e-06
Iter: 22 loss: 2.54182714e-06
Iter: 23 loss: 2.47938169e-06
Iter: 24 loss: 2.70375858e-06
Iter: 25 loss: 2.46354421e-06
Iter: 26 loss: 2.4438034e-06
Iter: 27 loss: 2.42340479e-06
Iter: 28 loss: 2.41964722e-06
Iter: 29 loss: 2.40147801e-06
Iter: 30 loss: 2.40639793e-06
Iter: 31 loss: 2.38832081e-06
Iter: 32 loss: 2.37484846e-06
Iter: 33 loss: 2.37579661e-06
Iter: 34 loss: 2.36429742e-06
Iter: 35 loss: 2.34763229e-06
Iter: 36 loss: 2.30727483e-06
Iter: 37 loss: 2.74085801e-06
Iter: 38 loss: 2.30293335e-06
Iter: 39 loss: 2.23840152e-06
Iter: 40 loss: 2.59898616e-06
Iter: 41 loss: 2.22926178e-06
Iter: 42 loss: 2.19112439e-06
Iter: 43 loss: 2.75515595e-06
Iter: 44 loss: 2.19109916e-06
Iter: 45 loss: 2.15565137e-06
Iter: 46 loss: 2.15810087e-06
Iter: 47 loss: 2.12806935e-06
Iter: 48 loss: 2.10397548e-06
Iter: 49 loss: 2.19017647e-06
Iter: 50 loss: 2.0978282e-06
Iter: 51 loss: 2.06947925e-06
Iter: 52 loss: 2.20818606e-06
Iter: 53 loss: 2.06457e-06
Iter: 54 loss: 2.05404376e-06
Iter: 55 loss: 2.02789124e-06
Iter: 56 loss: 2.28251224e-06
Iter: 57 loss: 2.02448336e-06
Iter: 58 loss: 2.02457591e-06
Iter: 59 loss: 2.00997965e-06
Iter: 60 loss: 1.99751094e-06
Iter: 61 loss: 1.96123051e-06
Iter: 62 loss: 2.11247288e-06
Iter: 63 loss: 1.94688823e-06
Iter: 64 loss: 1.92149855e-06
Iter: 65 loss: 1.91791401e-06
Iter: 66 loss: 1.89883826e-06
Iter: 67 loss: 1.92590846e-06
Iter: 68 loss: 1.88953118e-06
Iter: 69 loss: 1.87297974e-06
Iter: 70 loss: 1.85658496e-06
Iter: 71 loss: 1.8531523e-06
Iter: 72 loss: 1.83277484e-06
Iter: 73 loss: 2.06904224e-06
Iter: 74 loss: 1.83242969e-06
Iter: 75 loss: 1.81879523e-06
Iter: 76 loss: 1.91759977e-06
Iter: 77 loss: 1.81760265e-06
Iter: 78 loss: 1.80506277e-06
Iter: 79 loss: 1.86567308e-06
Iter: 80 loss: 1.80283519e-06
Iter: 81 loss: 1.79389951e-06
Iter: 82 loss: 1.77480297e-06
Iter: 83 loss: 2.07614403e-06
Iter: 84 loss: 1.77414313e-06
Iter: 85 loss: 1.75517107e-06
Iter: 86 loss: 1.75491073e-06
Iter: 87 loss: 1.74392665e-06
Iter: 88 loss: 1.71897534e-06
Iter: 89 loss: 2.04855269e-06
Iter: 90 loss: 1.71740305e-06
Iter: 91 loss: 1.72087812e-06
Iter: 92 loss: 1.71216e-06
Iter: 93 loss: 1.70661747e-06
Iter: 94 loss: 1.69467103e-06
Iter: 95 loss: 1.87991668e-06
Iter: 96 loss: 1.69423981e-06
Iter: 97 loss: 1.68418865e-06
Iter: 98 loss: 1.78292612e-06
Iter: 99 loss: 1.68385782e-06
Iter: 100 loss: 1.67282769e-06
Iter: 101 loss: 1.69143436e-06
Iter: 102 loss: 1.66781172e-06
Iter: 103 loss: 1.6570109e-06
Iter: 104 loss: 1.64235121e-06
Iter: 105 loss: 1.64162543e-06
Iter: 106 loss: 1.62561446e-06
Iter: 107 loss: 1.74163e-06
Iter: 108 loss: 1.62425374e-06
Iter: 109 loss: 1.61582102e-06
Iter: 110 loss: 1.61555613e-06
Iter: 111 loss: 1.61053663e-06
Iter: 112 loss: 1.64406856e-06
Iter: 113 loss: 1.61003254e-06
Iter: 114 loss: 1.60628542e-06
Iter: 115 loss: 1.59949718e-06
Iter: 116 loss: 1.75872378e-06
Iter: 117 loss: 1.5994774e-06
Iter: 118 loss: 1.59528122e-06
Iter: 119 loss: 1.59485307e-06
Iter: 120 loss: 1.59079468e-06
Iter: 121 loss: 1.57945715e-06
Iter: 122 loss: 1.64144456e-06
Iter: 123 loss: 1.57603517e-06
Iter: 124 loss: 1.56661804e-06
Iter: 125 loss: 1.69412215e-06
Iter: 126 loss: 1.56657939e-06
Iter: 127 loss: 1.55631074e-06
Iter: 128 loss: 1.59479873e-06
Iter: 129 loss: 1.55381463e-06
Iter: 130 loss: 1.54885174e-06
Iter: 131 loss: 1.54258623e-06
Iter: 132 loss: 1.54210989e-06
Iter: 133 loss: 1.53639e-06
Iter: 134 loss: 1.53576866e-06
Iter: 135 loss: 1.5329706e-06
Iter: 136 loss: 1.52702523e-06
Iter: 137 loss: 1.62499714e-06
Iter: 138 loss: 1.52686823e-06
Iter: 139 loss: 1.52016923e-06
Iter: 140 loss: 1.52005066e-06
Iter: 141 loss: 1.51477468e-06
Iter: 142 loss: 1.50610015e-06
Iter: 143 loss: 1.50608469e-06
Iter: 144 loss: 1.49988227e-06
Iter: 145 loss: 1.54192639e-06
Iter: 146 loss: 1.4992504e-06
Iter: 147 loss: 1.49473487e-06
Iter: 148 loss: 1.49437528e-06
Iter: 149 loss: 1.49102254e-06
Iter: 150 loss: 1.48803508e-06
Iter: 151 loss: 1.53367921e-06
Iter: 152 loss: 1.48805475e-06
Iter: 153 loss: 1.48497475e-06
Iter: 154 loss: 1.47927153e-06
Iter: 155 loss: 1.60667366e-06
Iter: 156 loss: 1.47924879e-06
Iter: 157 loss: 1.47396224e-06
Iter: 158 loss: 1.47752905e-06
Iter: 159 loss: 1.47064293e-06
Iter: 160 loss: 1.46458729e-06
Iter: 161 loss: 1.4645409e-06
Iter: 162 loss: 1.46143987e-06
Iter: 163 loss: 1.45356967e-06
Iter: 164 loss: 1.52021414e-06
Iter: 165 loss: 1.45221088e-06
Iter: 166 loss: 1.45090655e-06
Iter: 167 loss: 1.44767819e-06
Iter: 168 loss: 1.44518924e-06
Iter: 169 loss: 1.44060562e-06
Iter: 170 loss: 1.54623967e-06
Iter: 171 loss: 1.44060232e-06
Iter: 172 loss: 1.4366974e-06
Iter: 173 loss: 1.43534839e-06
Iter: 174 loss: 1.43311968e-06
Iter: 175 loss: 1.42803901e-06
Iter: 176 loss: 1.50288133e-06
Iter: 177 loss: 1.42803958e-06
Iter: 178 loss: 1.42328281e-06
Iter: 179 loss: 1.44984506e-06
Iter: 180 loss: 1.42262695e-06
Iter: 181 loss: 1.41813678e-06
Iter: 182 loss: 1.41652345e-06
Iter: 183 loss: 1.41402506e-06
Iter: 184 loss: 1.40905e-06
Iter: 185 loss: 1.4270795e-06
Iter: 186 loss: 1.40784e-06
Iter: 187 loss: 1.40183226e-06
Iter: 188 loss: 1.42520571e-06
Iter: 189 loss: 1.40041016e-06
Iter: 190 loss: 1.39754138e-06
Iter: 191 loss: 1.39329836e-06
Iter: 192 loss: 1.39319013e-06
Iter: 193 loss: 1.39557164e-06
Iter: 194 loss: 1.39171948e-06
Iter: 195 loss: 1.39074086e-06
Iter: 196 loss: 1.38803728e-06
Iter: 197 loss: 1.40110353e-06
Iter: 198 loss: 1.38710209e-06
Iter: 199 loss: 1.38480732e-06
Iter: 200 loss: 1.38473524e-06
Iter: 201 loss: 1.38192172e-06
Iter: 202 loss: 1.37556628e-06
Iter: 203 loss: 1.46266984e-06
Iter: 204 loss: 1.37518691e-06
Iter: 205 loss: 1.36925905e-06
Iter: 206 loss: 1.38185055e-06
Iter: 207 loss: 1.36693529e-06
Iter: 208 loss: 1.36316066e-06
Iter: 209 loss: 1.38678593e-06
Iter: 210 loss: 1.36271433e-06
Iter: 211 loss: 1.3603501e-06
Iter: 212 loss: 1.36029234e-06
Iter: 213 loss: 1.35849882e-06
Iter: 214 loss: 1.36112158e-06
Iter: 215 loss: 1.35765208e-06
Iter: 216 loss: 1.35599976e-06
Iter: 217 loss: 1.35408823e-06
Iter: 218 loss: 1.35385631e-06
Iter: 219 loss: 1.35096275e-06
Iter: 220 loss: 1.38859912e-06
Iter: 221 loss: 1.3509341e-06
Iter: 222 loss: 1.34872471e-06
Iter: 223 loss: 1.34339666e-06
Iter: 224 loss: 1.4023758e-06
Iter: 225 loss: 1.34288018e-06
Iter: 226 loss: 1.34201321e-06
Iter: 227 loss: 1.34120341e-06
Iter: 228 loss: 1.33950334e-06
Iter: 229 loss: 1.34023583e-06
Iter: 230 loss: 1.33832225e-06
Iter: 231 loss: 1.3371008e-06
Iter: 232 loss: 1.33686e-06
Iter: 233 loss: 1.33602362e-06
Iter: 234 loss: 1.3332932e-06
Iter: 235 loss: 1.34289189e-06
Iter: 236 loss: 1.33265894e-06
Iter: 237 loss: 1.33081471e-06
Iter: 238 loss: 1.32672517e-06
Iter: 239 loss: 1.38564474e-06
Iter: 240 loss: 1.32654714e-06
Iter: 241 loss: 1.32178445e-06
Iter: 242 loss: 1.34542711e-06
Iter: 243 loss: 1.32097784e-06
Iter: 244 loss: 1.32025093e-06
Iter: 245 loss: 1.31885508e-06
Iter: 246 loss: 1.31729109e-06
Iter: 247 loss: 1.31860202e-06
Iter: 248 loss: 1.31636807e-06
Iter: 249 loss: 1.31475451e-06
Iter: 250 loss: 1.31545767e-06
Iter: 251 loss: 1.31366903e-06
Iter: 252 loss: 1.31259321e-06
Iter: 253 loss: 1.31256945e-06
Iter: 254 loss: 1.31146612e-06
Iter: 255 loss: 1.30897661e-06
Iter: 256 loss: 1.34065158e-06
Iter: 257 loss: 1.3087913e-06
Iter: 258 loss: 1.30559954e-06
Iter: 259 loss: 1.30522312e-06
Iter: 260 loss: 1.30291323e-06
Iter: 261 loss: 1.3003779e-06
Iter: 262 loss: 1.2997732e-06
Iter: 263 loss: 1.29839884e-06
Iter: 264 loss: 1.29479918e-06
Iter: 265 loss: 1.32360151e-06
Iter: 266 loss: 1.29411342e-06
Iter: 267 loss: 1.292977e-06
Iter: 268 loss: 1.29176874e-06
Iter: 269 loss: 1.29066109e-06
Iter: 270 loss: 1.28835563e-06
Iter: 271 loss: 1.327071e-06
Iter: 272 loss: 1.28830186e-06
Iter: 273 loss: 1.28624697e-06
Iter: 274 loss: 1.28543479e-06
Iter: 275 loss: 1.28437932e-06
Iter: 276 loss: 1.28139629e-06
Iter: 277 loss: 1.31935394e-06
Iter: 278 loss: 1.28136776e-06
Iter: 279 loss: 1.2786727e-06
Iter: 280 loss: 1.2947495e-06
Iter: 281 loss: 1.27830504e-06
Iter: 282 loss: 1.27663463e-06
Iter: 283 loss: 1.27740191e-06
Iter: 284 loss: 1.27546309e-06
Iter: 285 loss: 1.27397709e-06
Iter: 286 loss: 1.28122588e-06
Iter: 287 loss: 1.27373823e-06
Iter: 288 loss: 1.27207863e-06
Iter: 289 loss: 1.27707199e-06
Iter: 290 loss: 1.27155226e-06
Iter: 291 loss: 1.27056558e-06
Iter: 292 loss: 1.26893929e-06
Iter: 293 loss: 1.26894031e-06
Iter: 294 loss: 1.26854411e-06
Iter: 295 loss: 1.26809277e-06
Iter: 296 loss: 1.26721773e-06
Iter: 297 loss: 1.26493239e-06
Iter: 298 loss: 1.28166073e-06
Iter: 299 loss: 1.26440477e-06
Iter: 300 loss: 1.26329189e-06
Iter: 301 loss: 1.26299392e-06
Iter: 302 loss: 1.26158693e-06
Iter: 303 loss: 1.25887914e-06
Iter: 304 loss: 1.31747288e-06
Iter: 305 loss: 1.25888823e-06
Iter: 306 loss: 1.25697147e-06
Iter: 307 loss: 1.2596671e-06
Iter: 308 loss: 1.25607596e-06
Iter: 309 loss: 1.25431575e-06
Iter: 310 loss: 1.25732333e-06
Iter: 311 loss: 1.25352744e-06
Iter: 312 loss: 1.2523675e-06
Iter: 313 loss: 1.2520793e-06
Iter: 314 loss: 1.25121915e-06
Iter: 315 loss: 1.2502237e-06
Iter: 316 loss: 1.25007489e-06
Iter: 317 loss: 1.24845815e-06
Iter: 318 loss: 1.24841608e-06
Iter: 319 loss: 1.24715643e-06
Iter: 320 loss: 1.24541793e-06
Iter: 321 loss: 1.24538121e-06
Iter: 322 loss: 1.24422104e-06
Iter: 323 loss: 1.2421865e-06
Iter: 324 loss: 1.24218695e-06
Iter: 325 loss: 1.24100427e-06
Iter: 326 loss: 1.2511556e-06
Iter: 327 loss: 1.24092719e-06
Iter: 328 loss: 1.23962661e-06
Iter: 329 loss: 1.2448379e-06
Iter: 330 loss: 1.23935888e-06
Iter: 331 loss: 1.23842392e-06
Iter: 332 loss: 1.23702728e-06
Iter: 333 loss: 1.23699624e-06
Iter: 334 loss: 1.23441703e-06
Iter: 335 loss: 1.24664029e-06
Iter: 336 loss: 1.23396217e-06
Iter: 337 loss: 1.23272787e-06
Iter: 338 loss: 1.23056179e-06
Iter: 339 loss: 1.23058555e-06
Iter: 340 loss: 1.22844392e-06
Iter: 341 loss: 1.23116979e-06
Iter: 342 loss: 1.22734309e-06
Iter: 343 loss: 1.22621714e-06
Iter: 344 loss: 1.23220366e-06
Iter: 345 loss: 1.22604126e-06
Iter: 346 loss: 1.22518986e-06
Iter: 347 loss: 1.22515166e-06
Iter: 348 loss: 1.22468578e-06
Iter: 349 loss: 1.22325707e-06
Iter: 350 loss: 1.22437586e-06
Iter: 351 loss: 1.2220022e-06
Iter: 352 loss: 1.22161714e-06
Iter: 353 loss: 1.22070264e-06
Iter: 354 loss: 1.21983646e-06
Iter: 355 loss: 1.21967344e-06
Iter: 356 loss: 1.21913865e-06
Iter: 357 loss: 1.21816367e-06
Iter: 358 loss: 1.22024494e-06
Iter: 359 loss: 1.21779908e-06
Iter: 360 loss: 1.21713333e-06
Iter: 361 loss: 1.2244036e-06
Iter: 362 loss: 1.21710752e-06
Iter: 363 loss: 1.21636833e-06
Iter: 364 loss: 1.21624748e-06
Iter: 365 loss: 1.21575852e-06
Iter: 366 loss: 1.21501603e-06
Iter: 367 loss: 1.21446237e-06
Iter: 368 loss: 1.21424e-06
Iter: 369 loss: 1.21270375e-06
Iter: 370 loss: 1.22602432e-06
Iter: 371 loss: 1.21263827e-06
Iter: 372 loss: 1.21181847e-06
Iter: 373 loss: 1.20955428e-06
Iter: 374 loss: 1.22593451e-06
Iter: 375 loss: 1.20908533e-06
Iter: 376 loss: 1.20738184e-06
Iter: 377 loss: 1.22364509e-06
Iter: 378 loss: 1.20733e-06
Iter: 379 loss: 1.20671723e-06
Iter: 380 loss: 1.20661753e-06
Iter: 381 loss: 1.20579398e-06
Iter: 382 loss: 1.20450773e-06
Iter: 383 loss: 1.20449783e-06
Iter: 384 loss: 1.20349364e-06
Iter: 385 loss: 1.2032915e-06
Iter: 386 loss: 1.20260745e-06
Iter: 387 loss: 1.20079949e-06
Iter: 388 loss: 1.21926064e-06
Iter: 389 loss: 1.20073867e-06
Iter: 390 loss: 1.19962954e-06
Iter: 391 loss: 1.19851882e-06
Iter: 392 loss: 1.19828314e-06
Iter: 393 loss: 1.19671597e-06
Iter: 394 loss: 1.20626055e-06
Iter: 395 loss: 1.19654749e-06
Iter: 396 loss: 1.19585127e-06
Iter: 397 loss: 1.20500295e-06
Iter: 398 loss: 1.19586298e-06
Iter: 399 loss: 1.19519189e-06
Iter: 400 loss: 1.19494825e-06
Iter: 401 loss: 1.19457673e-06
Iter: 402 loss: 1.19388517e-06
Iter: 403 loss: 1.19288416e-06
Iter: 404 loss: 1.19286346e-06
Iter: 405 loss: 1.19134484e-06
Iter: 406 loss: 1.2129143e-06
Iter: 407 loss: 1.19132392e-06
Iter: 408 loss: 1.1906028e-06
Iter: 409 loss: 1.18896719e-06
Iter: 410 loss: 1.21045798e-06
Iter: 411 loss: 1.18885896e-06
Iter: 412 loss: 1.18824642e-06
Iter: 413 loss: 1.1879481e-06
Iter: 414 loss: 1.18710034e-06
Iter: 415 loss: 1.18656794e-06
Iter: 416 loss: 1.18624837e-06
Iter: 417 loss: 1.18555567e-06
Iter: 418 loss: 1.18579032e-06
Iter: 419 loss: 1.1850907e-06
Iter: 420 loss: 1.18432604e-06
Iter: 421 loss: 1.19494416e-06
Iter: 422 loss: 1.18433798e-06
Iter: 423 loss: 1.18346736e-06
Iter: 424 loss: 1.18316916e-06
Iter: 425 loss: 1.18267167e-06
Iter: 426 loss: 1.18179719e-06
Iter: 427 loss: 1.18115622e-06
Iter: 428 loss: 1.18085325e-06
Iter: 429 loss: 1.17885099e-06
Iter: 430 loss: 1.18338812e-06
Iter: 431 loss: 1.17807656e-06
Iter: 432 loss: 1.17713148e-06
Iter: 433 loss: 1.17697289e-06
Iter: 434 loss: 1.17644413e-06
Iter: 435 loss: 1.1750675e-06
Iter: 436 loss: 1.18489993e-06
Iter: 437 loss: 1.17476475e-06
Iter: 438 loss: 1.17511843e-06
Iter: 439 loss: 1.17417358e-06
Iter: 440 loss: 1.17378772e-06
Iter: 441 loss: 1.17280308e-06
Iter: 442 loss: 1.17957325e-06
Iter: 443 loss: 1.17252171e-06
Iter: 444 loss: 1.17121033e-06
Iter: 445 loss: 1.17023296e-06
Iter: 446 loss: 1.16979072e-06
Iter: 447 loss: 1.17119441e-06
Iter: 448 loss: 1.16919864e-06
Iter: 449 loss: 1.16872616e-06
Iter: 450 loss: 1.16741649e-06
Iter: 451 loss: 1.17595846e-06
Iter: 452 loss: 1.1671018e-06
Iter: 453 loss: 1.16621118e-06
Iter: 454 loss: 1.17785396e-06
Iter: 455 loss: 1.16621948e-06
Iter: 456 loss: 1.16557976e-06
Iter: 457 loss: 1.16820411e-06
Iter: 458 loss: 1.1654497e-06
Iter: 459 loss: 1.16499177e-06
Iter: 460 loss: 1.16413958e-06
Iter: 461 loss: 1.18400101e-06
Iter: 462 loss: 1.16411957e-06
Iter: 463 loss: 1.16302181e-06
Iter: 464 loss: 1.16907131e-06
Iter: 465 loss: 1.16285378e-06
Iter: 466 loss: 1.16198385e-06
Iter: 467 loss: 1.17389504e-06
Iter: 468 loss: 1.16197657e-06
Iter: 469 loss: 1.16124352e-06
Iter: 470 loss: 1.16190654e-06
Iter: 471 loss: 1.16081287e-06
Iter: 472 loss: 1.16009164e-06
Iter: 473 loss: 1.16132469e-06
Iter: 474 loss: 1.15981493e-06
Iter: 475 loss: 1.15925081e-06
Iter: 476 loss: 1.15925138e-06
Iter: 477 loss: 1.1589417e-06
Iter: 478 loss: 1.15807302e-06
Iter: 479 loss: 1.16289425e-06
Iter: 480 loss: 1.15776947e-06
Iter: 481 loss: 1.15664989e-06
Iter: 482 loss: 1.15779085e-06
Iter: 483 loss: 1.1560212e-06
Iter: 484 loss: 1.15504031e-06
Iter: 485 loss: 1.15490479e-06
Iter: 486 loss: 1.15424245e-06
Iter: 487 loss: 1.15261514e-06
Iter: 488 loss: 1.16779643e-06
Iter: 489 loss: 1.15234184e-06
Iter: 490 loss: 1.15243961e-06
Iter: 491 loss: 1.15170951e-06
Iter: 492 loss: 1.1512368e-06
Iter: 493 loss: 1.15002263e-06
Iter: 494 loss: 1.16262481e-06
Iter: 495 loss: 1.14988381e-06
Iter: 496 loss: 1.14897125e-06
Iter: 497 loss: 1.15644593e-06
Iter: 498 loss: 1.14895136e-06
Iter: 499 loss: 1.14838599e-06
Iter: 500 loss: 1.1527369e-06
Iter: 501 loss: 1.14836621e-06
Iter: 502 loss: 1.14773457e-06
Iter: 503 loss: 1.14917646e-06
Iter: 504 loss: 1.14751106e-06
Iter: 505 loss: 1.14687987e-06
Iter: 506 loss: 1.146268e-06
Iter: 507 loss: 1.14611566e-06
Iter: 508 loss: 1.14513625e-06
Iter: 509 loss: 1.15572107e-06
Iter: 510 loss: 1.14510658e-06
Iter: 511 loss: 1.14435329e-06
Iter: 512 loss: 1.14361205e-06
Iter: 513 loss: 1.14344027e-06
Iter: 514 loss: 1.14272711e-06
Iter: 515 loss: 1.1438691e-06
Iter: 516 loss: 1.14238662e-06
Iter: 517 loss: 1.14229465e-06
Iter: 518 loss: 1.14213753e-06
Iter: 519 loss: 1.14187912e-06
Iter: 520 loss: 1.14131319e-06
Iter: 521 loss: 1.15096111e-06
Iter: 522 loss: 1.14129989e-06
Iter: 523 loss: 1.14076408e-06
Iter: 524 loss: 1.14185718e-06
Iter: 525 loss: 1.14055013e-06
Iter: 526 loss: 1.13958959e-06
Iter: 527 loss: 1.13993769e-06
Iter: 528 loss: 1.13891303e-06
Iter: 529 loss: 1.13802116e-06
Iter: 530 loss: 1.13679152e-06
Iter: 531 loss: 1.13674412e-06
Iter: 532 loss: 1.13566762e-06
Iter: 533 loss: 1.14977047e-06
Iter: 534 loss: 1.13566409e-06
Iter: 535 loss: 1.13514682e-06
Iter: 536 loss: 1.13512294e-06
Iter: 537 loss: 1.13476972e-06
Iter: 538 loss: 1.13471219e-06
Iter: 539 loss: 1.13446686e-06
Iter: 540 loss: 1.13408396e-06
Iter: 541 loss: 1.13670603e-06
Iter: 542 loss: 1.13404872e-06
Iter: 543 loss: 1.13363399e-06
Iter: 544 loss: 1.13378337e-06
Iter: 545 loss: 1.13332896e-06
Iter: 546 loss: 1.1328799e-06
Iter: 547 loss: 1.13211081e-06
Iter: 548 loss: 1.13211195e-06
Iter: 549 loss: 1.13137048e-06
Iter: 550 loss: 1.1313814e-06
Iter: 551 loss: 1.13062492e-06
Iter: 552 loss: 1.13256237e-06
Iter: 553 loss: 1.130393e-06
Iter: 554 loss: 1.12998714e-06
Iter: 555 loss: 1.1295374e-06
Iter: 556 loss: 1.12950079e-06
Iter: 557 loss: 1.1291778e-06
Iter: 558 loss: 1.12905195e-06
Iter: 559 loss: 1.12889268e-06
Iter: 560 loss: 1.12829298e-06
Iter: 561 loss: 1.12990256e-06
Iter: 562 loss: 1.12799421e-06
Iter: 563 loss: 1.12700741e-06
Iter: 564 loss: 1.12912448e-06
Iter: 565 loss: 1.12659291e-06
Iter: 566 loss: 1.12650832e-06
Iter: 567 loss: 1.12617772e-06
Iter: 568 loss: 1.12572775e-06
Iter: 569 loss: 1.12546718e-06
Iter: 570 loss: 1.12531609e-06
Iter: 571 loss: 1.12473e-06
Iter: 572 loss: 1.12720579e-06
Iter: 573 loss: 1.12463908e-06
Iter: 574 loss: 1.12427301e-06
Iter: 575 loss: 1.12428165e-06
Iter: 576 loss: 1.12413454e-06
Iter: 577 loss: 1.12369344e-06
Iter: 578 loss: 1.1282109e-06
Iter: 579 loss: 1.12366706e-06
Iter: 580 loss: 1.12314865e-06
Iter: 581 loss: 1.12563794e-06
Iter: 582 loss: 1.12303928e-06
Iter: 583 loss: 1.12241901e-06
Iter: 584 loss: 1.12680107e-06
Iter: 585 loss: 1.12235853e-06
Iter: 586 loss: 1.12194812e-06
Iter: 587 loss: 1.12102316e-06
Iter: 588 loss: 1.13309579e-06
Iter: 589 loss: 1.120967e-06
Iter: 590 loss: 1.12095245e-06
Iter: 591 loss: 1.12056932e-06
Iter: 592 loss: 1.12028977e-06
Iter: 593 loss: 1.11967836e-06
Iter: 594 loss: 1.13063879e-06
Iter: 595 loss: 1.11964255e-06
Iter: 596 loss: 1.11919098e-06
Iter: 597 loss: 1.11967404e-06
Iter: 598 loss: 1.11893451e-06
Iter: 599 loss: 1.11838858e-06
Iter: 600 loss: 1.12035582e-06
Iter: 601 loss: 1.1182708e-06
Iter: 602 loss: 1.11758368e-06
Iter: 603 loss: 1.12248711e-06
Iter: 604 loss: 1.1175116e-06
Iter: 605 loss: 1.11701661e-06
Iter: 606 loss: 1.11689474e-06
Iter: 607 loss: 1.11657869e-06
Iter: 608 loss: 1.11588395e-06
Iter: 609 loss: 1.12163934e-06
Iter: 610 loss: 1.11582858e-06
Iter: 611 loss: 1.1152847e-06
Iter: 612 loss: 1.11533552e-06
Iter: 613 loss: 1.11483871e-06
Iter: 614 loss: 1.11445058e-06
Iter: 615 loss: 1.11547024e-06
Iter: 616 loss: 1.11430779e-06
Iter: 617 loss: 1.11407292e-06
Iter: 618 loss: 1.11404051e-06
Iter: 619 loss: 1.11385054e-06
Iter: 620 loss: 1.11339716e-06
Iter: 621 loss: 1.11802331e-06
Iter: 622 loss: 1.11333543e-06
Iter: 623 loss: 1.11297845e-06
Iter: 624 loss: 1.11825693e-06
Iter: 625 loss: 1.11298641e-06
Iter: 626 loss: 1.11255031e-06
Iter: 627 loss: 1.11223767e-06
Iter: 628 loss: 1.11212455e-06
Iter: 629 loss: 1.11153963e-06
Iter: 630 loss: 1.11057693e-06
Iter: 631 loss: 1.11057693e-06
Iter: 632 loss: 1.10953351e-06
Iter: 633 loss: 1.11644204e-06
Iter: 634 loss: 1.10942688e-06
Iter: 635 loss: 1.10957387e-06
Iter: 636 loss: 1.10917472e-06
Iter: 637 loss: 1.10893825e-06
Iter: 638 loss: 1.1083265e-06
Iter: 639 loss: 1.11328882e-06
Iter: 640 loss: 1.10823157e-06
Iter: 641 loss: 1.10756093e-06
Iter: 642 loss: 1.10756105e-06
Iter: 643 loss: 1.10701467e-06
Iter: 644 loss: 1.10746146e-06
Iter: 645 loss: 1.10668634e-06
Iter: 646 loss: 1.10609062e-06
Iter: 647 loss: 1.10511542e-06
Iter: 648 loss: 1.10512e-06
Iter: 649 loss: 1.1045513e-06
Iter: 650 loss: 1.10449832e-06
Iter: 651 loss: 1.10387589e-06
Iter: 652 loss: 1.10567521e-06
Iter: 653 loss: 1.10370411e-06
Iter: 654 loss: 1.10344195e-06
Iter: 655 loss: 1.1032123e-06
Iter: 656 loss: 1.10313863e-06
Iter: 657 loss: 1.10276028e-06
Iter: 658 loss: 1.10274891e-06
Iter: 659 loss: 1.10251108e-06
Iter: 660 loss: 1.10192605e-06
Iter: 661 loss: 1.1058255e-06
Iter: 662 loss: 1.10175176e-06
Iter: 663 loss: 1.10091969e-06
Iter: 664 loss: 1.10113854e-06
Iter: 665 loss: 1.10026076e-06
Iter: 666 loss: 1.09971961e-06
Iter: 667 loss: 1.09969574e-06
Iter: 668 loss: 1.09919131e-06
Iter: 669 loss: 1.10386304e-06
Iter: 670 loss: 1.09917369e-06
Iter: 671 loss: 1.09895984e-06
Iter: 672 loss: 1.09888674e-06
Iter: 673 loss: 1.09877726e-06
Iter: 674 loss: 1.09848349e-06
Iter: 675 loss: 1.10144163e-06
Iter: 676 loss: 1.09847656e-06
Iter: 677 loss: 1.09826362e-06
Iter: 678 loss: 1.09795258e-06
Iter: 679 loss: 1.09794246e-06
Iter: 680 loss: 1.09736754e-06
Iter: 681 loss: 1.09666985e-06
Iter: 682 loss: 1.09660448e-06
Iter: 683 loss: 1.09569328e-06
Iter: 684 loss: 1.09890698e-06
Iter: 685 loss: 1.09545203e-06
Iter: 686 loss: 1.09620612e-06
Iter: 687 loss: 1.09527889e-06
Iter: 688 loss: 1.09512484e-06
Iter: 689 loss: 1.09476355e-06
Iter: 690 loss: 1.09673556e-06
Iter: 691 loss: 1.09465759e-06
Iter: 692 loss: 1.09458188e-06
Iter: 693 loss: 1.09446228e-06
Iter: 694 loss: 1.09431062e-06
Iter: 695 loss: 1.09390487e-06
Iter: 696 loss: 1.09772509e-06
Iter: 697 loss: 1.09384246e-06
Iter: 698 loss: 1.09332802e-06
Iter: 699 loss: 1.09263453e-06
Iter: 700 loss: 1.09261873e-06
Iter: 701 loss: 1.09192206e-06
Iter: 702 loss: 1.09345842e-06
Iter: 703 loss: 1.09170151e-06
Iter: 704 loss: 1.09175039e-06
Iter: 705 loss: 1.09141536e-06
Iter: 706 loss: 1.091287e-06
Iter: 707 loss: 1.09098369e-06
Iter: 708 loss: 1.09223822e-06
Iter: 709 loss: 1.09084317e-06
Iter: 710 loss: 1.0906524e-06
Iter: 711 loss: 1.09055327e-06
Iter: 712 loss: 1.09040548e-06
Iter: 713 loss: 1.08997301e-06
Iter: 714 loss: 1.09216251e-06
Iter: 715 loss: 1.08983306e-06
Iter: 716 loss: 1.08916697e-06
Iter: 717 loss: 1.08943766e-06
Iter: 718 loss: 1.08870438e-06
Iter: 719 loss: 1.08779989e-06
Iter: 720 loss: 1.09349685e-06
Iter: 721 loss: 1.087692e-06
Iter: 722 loss: 1.08694803e-06
Iter: 723 loss: 1.08779932e-06
Iter: 724 loss: 1.08657503e-06
Iter: 725 loss: 1.08661425e-06
Iter: 726 loss: 1.08637846e-06
Iter: 727 loss: 1.08613415e-06
Iter: 728 loss: 1.0856063e-06
Iter: 729 loss: 1.092969e-06
Iter: 730 loss: 1.08558015e-06
Iter: 731 loss: 1.08519839e-06
Iter: 732 loss: 1.08828124e-06
Iter: 733 loss: 1.08515576e-06
Iter: 734 loss: 1.08457516e-06
Iter: 735 loss: 1.08430368e-06
Iter: 736 loss: 1.08401537e-06
Iter: 737 loss: 1.08344898e-06
Iter: 738 loss: 1.08294648e-06
Iter: 739 loss: 1.08281017e-06
Iter: 740 loss: 1.0827182e-06
Iter: 741 loss: 1.08233257e-06
Iter: 742 loss: 1.08202721e-06
Iter: 743 loss: 1.08132133e-06
Iter: 744 loss: 1.09002224e-06
Iter: 745 loss: 1.0812937e-06
Iter: 746 loss: 1.08093741e-06
Iter: 747 loss: 1.08095026e-06
Iter: 748 loss: 1.08051097e-06
Iter: 749 loss: 1.0802338e-06
Iter: 750 loss: 1.08008851e-06
Iter: 751 loss: 1.07950586e-06
Iter: 752 loss: 1.078943e-06
Iter: 753 loss: 1.07883386e-06
Iter: 754 loss: 1.07795131e-06
Iter: 755 loss: 1.07913104e-06
Iter: 756 loss: 1.07755102e-06
Iter: 757 loss: 1.07663868e-06
Iter: 758 loss: 1.08477195e-06
Iter: 759 loss: 1.07660537e-06
Iter: 760 loss: 1.07581138e-06
Iter: 761 loss: 1.08237873e-06
Iter: 762 loss: 1.07575056e-06
Iter: 763 loss: 1.07551739e-06
Iter: 764 loss: 1.07512108e-06
Iter: 765 loss: 1.07510687e-06
Iter: 766 loss: 1.07464848e-06
Iter: 767 loss: 1.08125937e-06
Iter: 768 loss: 1.07463461e-06
Iter: 769 loss: 1.0743712e-06
Iter: 770 loss: 1.07362177e-06
Iter: 771 loss: 1.07802555e-06
Iter: 772 loss: 1.07341612e-06
Iter: 773 loss: 1.07254846e-06
Iter: 774 loss: 1.08074573e-06
Iter: 775 loss: 1.0725206e-06
Iter: 776 loss: 1.07154676e-06
Iter: 777 loss: 1.07568326e-06
Iter: 778 loss: 1.0713286e-06
Iter: 779 loss: 1.07090727e-06
Iter: 780 loss: 1.07033372e-06
Iter: 781 loss: 1.07032338e-06
Iter: 782 loss: 1.06975e-06
Iter: 783 loss: 1.06969651e-06
Iter: 784 loss: 1.0694024e-06
Iter: 785 loss: 1.06903462e-06
Iter: 786 loss: 1.06902326e-06
Iter: 787 loss: 1.0684812e-06
Iter: 788 loss: 1.0711758e-06
Iter: 789 loss: 1.0683832e-06
Iter: 790 loss: 1.06789844e-06
Iter: 791 loss: 1.06714356e-06
Iter: 792 loss: 1.06711468e-06
Iter: 793 loss: 1.06678124e-06
Iter: 794 loss: 1.06667608e-06
Iter: 795 loss: 1.0662086e-06
Iter: 796 loss: 1.06651078e-06
Iter: 797 loss: 1.06592029e-06
Iter: 798 loss: 1.06561367e-06
Iter: 799 loss: 1.0655923e-06
Iter: 800 loss: 1.0653149e-06
Iter: 801 loss: 1.06482503e-06
Iter: 802 loss: 1.06854407e-06
Iter: 803 loss: 1.0647542e-06
Iter: 804 loss: 1.06452444e-06
Iter: 805 loss: 1.0640731e-06
Iter: 806 loss: 1.06407811e-06
Iter: 807 loss: 1.06367304e-06
Iter: 808 loss: 1.06978405e-06
Iter: 809 loss: 1.06364587e-06
Iter: 810 loss: 1.06333971e-06
Iter: 811 loss: 1.06261814e-06
Iter: 812 loss: 1.07260632e-06
Iter: 813 loss: 1.06259199e-06
Iter: 814 loss: 1.06200218e-06
Iter: 815 loss: 1.07052972e-06
Iter: 816 loss: 1.06201401e-06
Iter: 817 loss: 1.06141783e-06
Iter: 818 loss: 1.06339917e-06
Iter: 819 loss: 1.06126504e-06
Iter: 820 loss: 1.06095717e-06
Iter: 821 loss: 1.06104824e-06
Iter: 822 loss: 1.06072798e-06
Iter: 823 loss: 1.06038169e-06
Iter: 824 loss: 1.06117784e-06
Iter: 825 loss: 1.06021707e-06
Iter: 826 loss: 1.05983543e-06
Iter: 827 loss: 1.060562e-06
Iter: 828 loss: 1.05966876e-06
Iter: 829 loss: 1.05920583e-06
Iter: 830 loss: 1.06622224e-06
Iter: 831 loss: 1.05920651e-06
Iter: 832 loss: 1.05897197e-06
Iter: 833 loss: 1.05824711e-06
Iter: 834 loss: 1.06151708e-06
Iter: 835 loss: 1.05800382e-06
Iter: 836 loss: 1.05749746e-06
Iter: 837 loss: 1.05736558e-06
Iter: 838 loss: 1.05692823e-06
Iter: 839 loss: 1.05650406e-06
Iter: 840 loss: 1.05642891e-06
Iter: 841 loss: 1.05603795e-06
Iter: 842 loss: 1.06187463e-06
Iter: 843 loss: 1.05604931e-06
Iter: 844 loss: 1.05567779e-06
Iter: 845 loss: 1.0557244e-06
Iter: 846 loss: 1.05538288e-06
Iter: 847 loss: 1.05508434e-06
Iter: 848 loss: 1.05555728e-06
Iter: 849 loss: 1.05497145e-06
Iter: 850 loss: 1.0546255e-06
Iter: 851 loss: 1.05910794e-06
Iter: 852 loss: 1.05461504e-06
Iter: 853 loss: 1.05436015e-06
Iter: 854 loss: 1.05392417e-06
Iter: 855 loss: 1.05393292e-06
Iter: 856 loss: 1.0534668e-06
Iter: 857 loss: 1.05447441e-06
Iter: 858 loss: 1.05330128e-06
Iter: 859 loss: 1.05278014e-06
Iter: 860 loss: 1.05248978e-06
Iter: 861 loss: 1.05225797e-06
Iter: 862 loss: 1.0522898e-06
Iter: 863 loss: 1.05195306e-06
Iter: 864 loss: 1.05167931e-06
Iter: 865 loss: 1.05113793e-06
Iter: 866 loss: 1.06101459e-06
Iter: 867 loss: 1.05113e-06
Iter: 868 loss: 1.0508146e-06
Iter: 869 loss: 1.05479216e-06
Iter: 870 loss: 1.05079619e-06
Iter: 871 loss: 1.05039953e-06
Iter: 872 loss: 1.05007166e-06
Iter: 873 loss: 1.04995127e-06
Iter: 874 loss: 1.04956382e-06
Iter: 875 loss: 1.04934588e-06
Iter: 876 loss: 1.04918547e-06
Iter: 877 loss: 1.04883532e-06
Iter: 878 loss: 1.04882236e-06
Iter: 879 loss: 1.04835101e-06
Iter: 880 loss: 1.04863034e-06
Iter: 881 loss: 1.04810943e-06
Iter: 882 loss: 1.04778451e-06
Iter: 883 loss: 1.04810601e-06
Iter: 884 loss: 1.04762489e-06
Iter: 885 loss: 1.04714059e-06
Iter: 886 loss: 1.04926721e-06
Iter: 887 loss: 1.04702463e-06
Iter: 888 loss: 1.04672529e-06
Iter: 889 loss: 1.04633671e-06
Iter: 890 loss: 1.04631181e-06
Iter: 891 loss: 1.04572655e-06
Iter: 892 loss: 1.05045592e-06
Iter: 893 loss: 1.04573064e-06
Iter: 894 loss: 1.04538526e-06
Iter: 895 loss: 1.04804974e-06
Iter: 896 loss: 1.04537503e-06
Iter: 897 loss: 1.04511525e-06
Iter: 898 loss: 1.04656772e-06
Iter: 899 loss: 1.04507035e-06
Iter: 900 loss: 1.04493586e-06
Iter: 901 loss: 1.04455921e-06
Iter: 902 loss: 1.04828837e-06
Iter: 903 loss: 1.04453522e-06
Iter: 904 loss: 1.0442285e-06
Iter: 905 loss: 1.04419428e-06
Iter: 906 loss: 1.0439453e-06
Iter: 907 loss: 1.04318724e-06
Iter: 908 loss: 1.04653759e-06
Iter: 909 loss: 1.04289825e-06
Iter: 910 loss: 1.0422574e-06
Iter: 911 loss: 1.04712115e-06
Iter: 912 loss: 1.04219794e-06
Iter: 913 loss: 1.04176e-06
Iter: 914 loss: 1.04175024e-06
Iter: 915 loss: 1.04152809e-06
Iter: 916 loss: 1.04126332e-06
Iter: 917 loss: 1.04122887e-06
Iter: 918 loss: 1.04091021e-06
Iter: 919 loss: 1.04545313e-06
Iter: 920 loss: 1.04092283e-06
Iter: 921 loss: 1.04073501e-06
Iter: 922 loss: 1.04028686e-06
Iter: 923 loss: 1.04588742e-06
Iter: 924 loss: 1.04025162e-06
Iter: 925 loss: 1.03978618e-06
Iter: 926 loss: 1.04122012e-06
Iter: 927 loss: 1.03964294e-06
Iter: 928 loss: 1.03927175e-06
Iter: 929 loss: 1.03994512e-06
Iter: 930 loss: 1.03912214e-06
Iter: 931 loss: 1.03879188e-06
Iter: 932 loss: 1.04273556e-06
Iter: 933 loss: 1.03879847e-06
Iter: 934 loss: 1.0384806e-06
Iter: 935 loss: 1.03858099e-06
Iter: 936 loss: 1.03826619e-06
Iter: 937 loss: 1.03808839e-06
Iter: 938 loss: 1.03885782e-06
Iter: 939 loss: 1.03806656e-06
Iter: 940 loss: 1.03777029e-06
Iter: 941 loss: 1.0378958e-06
Iter: 942 loss: 1.03760522e-06
Iter: 943 loss: 1.03736113e-06
Iter: 944 loss: 1.036968e-06
Iter: 945 loss: 1.03695265e-06
Iter: 946 loss: 1.03686716e-06
Iter: 947 loss: 1.03676666e-06
Iter: 948 loss: 1.03651655e-06
Iter: 949 loss: 1.03608477e-06
Iter: 950 loss: 1.04604874e-06
Iter: 951 loss: 1.03609955e-06
Iter: 952 loss: 1.03591526e-06
Iter: 953 loss: 1.0358973e-06
Iter: 954 loss: 1.03570437e-06
Iter: 955 loss: 1.03549473e-06
Iter: 956 loss: 1.03546449e-06
Iter: 957 loss: 1.03517118e-06
Iter: 958 loss: 1.03504476e-06
Iter: 959 loss: 1.034913e-06
Iter: 960 loss: 1.03453135e-06
Iter: 961 loss: 1.03451953e-06
Iter: 962 loss: 1.03420666e-06
Iter: 963 loss: 1.03474474e-06
Iter: 964 loss: 1.03407706e-06
Iter: 965 loss: 1.0337003e-06
Iter: 966 loss: 1.03418233e-06
Iter: 967 loss: 1.03349566e-06
Iter: 968 loss: 1.03313869e-06
Iter: 969 loss: 1.03249567e-06
Iter: 970 loss: 1.03249317e-06
Iter: 971 loss: 1.03192315e-06
Iter: 972 loss: 1.03370007e-06
Iter: 973 loss: 1.03172408e-06
Iter: 974 loss: 1.03187858e-06
Iter: 975 loss: 1.0314775e-06
Iter: 976 loss: 1.03131231e-06
Iter: 977 loss: 1.03086916e-06
Iter: 978 loss: 1.03272271e-06
Iter: 979 loss: 1.03069056e-06
Iter: 980 loss: 1.03023149e-06
Iter: 981 loss: 1.03277591e-06
Iter: 982 loss: 1.03015668e-06
Iter: 983 loss: 1.02982585e-06
Iter: 984 loss: 1.02980471e-06
Iter: 985 loss: 1.02968215e-06
Iter: 986 loss: 1.0293611e-06
Iter: 987 loss: 1.03204525e-06
Iter: 988 loss: 1.02931563e-06
Iter: 989 loss: 1.02925912e-06
Iter: 990 loss: 1.02919057e-06
Iter: 991 loss: 1.02904505e-06
Iter: 992 loss: 1.02861031e-06
Iter: 993 loss: 1.03287505e-06
Iter: 994 loss: 1.0285512e-06
Iter: 995 loss: 1.02837475e-06
Iter: 996 loss: 1.02833792e-06
Iter: 997 loss: 1.02812601e-06
Iter: 998 loss: 1.02763306e-06
Iter: 999 loss: 1.03352704e-06
Iter: 1000 loss: 1.02757872e-06
Iter: 1001 loss: 1.02720196e-06
Iter: 1002 loss: 1.0272056e-06
Iter: 1003 loss: 1.02696e-06
Iter: 1004 loss: 1.02677859e-06
Iter: 1005 loss: 1.02671152e-06
Iter: 1006 loss: 1.02639763e-06
Iter: 1007 loss: 1.02735294e-06
Iter: 1008 loss: 1.02631907e-06
Iter: 1009 loss: 1.02606987e-06
Iter: 1010 loss: 1.02606214e-06
Iter: 1011 loss: 1.02595141e-06
Iter: 1012 loss: 1.02558715e-06
Iter: 1013 loss: 1.02625563e-06
Iter: 1014 loss: 1.02532226e-06
Iter: 1015 loss: 1.02512172e-06
Iter: 1016 loss: 1.02496779e-06
Iter: 1017 loss: 1.0246888e-06
Iter: 1018 loss: 1.02416584e-06
Iter: 1019 loss: 1.03582033e-06
Iter: 1020 loss: 1.02416834e-06
Iter: 1021 loss: 1.02380716e-06
Iter: 1022 loss: 1.02473621e-06
Iter: 1023 loss: 1.02367767e-06
Iter: 1024 loss: 1.02357501e-06
Iter: 1025 loss: 1.0235234e-06
Iter: 1026 loss: 1.02337981e-06
Iter: 1027 loss: 1.02298054e-06
Iter: 1028 loss: 1.02640479e-06
Iter: 1029 loss: 1.02293529e-06
Iter: 1030 loss: 1.02264482e-06
Iter: 1031 loss: 1.02262868e-06
Iter: 1032 loss: 1.02246804e-06
Iter: 1033 loss: 1.02208605e-06
Iter: 1034 loss: 1.02730542e-06
Iter: 1035 loss: 1.02209447e-06
Iter: 1036 loss: 1.02174465e-06
Iter: 1037 loss: 1.02230615e-06
Iter: 1038 loss: 1.02159299e-06
Iter: 1039 loss: 1.02129889e-06
Iter: 1040 loss: 1.0211777e-06
Iter: 1041 loss: 1.02104752e-06
Iter: 1042 loss: 1.02080276e-06
Iter: 1043 loss: 1.02075194e-06
Iter: 1044 loss: 1.02057356e-06
Iter: 1045 loss: 1.02013041e-06
Iter: 1046 loss: 1.02737749e-06
Iter: 1047 loss: 1.02013053e-06
Iter: 1048 loss: 1.01978299e-06
Iter: 1049 loss: 1.0233432e-06
Iter: 1050 loss: 1.01974956e-06
Iter: 1051 loss: 1.01929777e-06
Iter: 1052 loss: 1.02025194e-06
Iter: 1053 loss: 1.01911246e-06
Iter: 1054 loss: 1.0188387e-06
Iter: 1055 loss: 1.01828607e-06
Iter: 1056 loss: 1.02862691e-06
Iter: 1057 loss: 1.0182855e-06
Iter: 1058 loss: 1.01783132e-06
Iter: 1059 loss: 1.02274339e-06
Iter: 1060 loss: 1.01783905e-06
Iter: 1061 loss: 1.01758269e-06
Iter: 1062 loss: 1.01757314e-06
Iter: 1063 loss: 1.01746787e-06
Iter: 1064 loss: 1.01718456e-06
Iter: 1065 loss: 1.02074591e-06
Iter: 1066 loss: 1.0171774e-06
Iter: 1067 loss: 1.01685441e-06
Iter: 1068 loss: 1.02102319e-06
Iter: 1069 loss: 1.01683418e-06
Iter: 1070 loss: 1.01664841e-06
Iter: 1071 loss: 1.01611147e-06
Iter: 1072 loss: 1.01672072e-06
Iter: 1073 loss: 1.01568048e-06
Iter: 1074 loss: 1.01511932e-06
Iter: 1075 loss: 1.01509761e-06
Iter: 1076 loss: 1.01462274e-06
Iter: 1077 loss: 1.01778039e-06
Iter: 1078 loss: 1.01457977e-06
Iter: 1079 loss: 1.01431669e-06
Iter: 1080 loss: 1.01626642e-06
Iter: 1081 loss: 1.01428373e-06
Iter: 1082 loss: 1.01406329e-06
Iter: 1083 loss: 1.01368335e-06
Iter: 1084 loss: 1.02314789e-06
Iter: 1085 loss: 1.01368369e-06
Iter: 1086 loss: 1.01353885e-06
Iter: 1087 loss: 1.01347223e-06
Iter: 1088 loss: 1.01326975e-06
Iter: 1089 loss: 1.01279693e-06
Iter: 1090 loss: 1.01976661e-06
Iter: 1091 loss: 1.01277669e-06
Iter: 1092 loss: 1.01238766e-06
Iter: 1093 loss: 1.01243836e-06
Iter: 1094 loss: 1.01205126e-06
Iter: 1095 loss: 1.01200658e-06
Iter: 1096 loss: 1.01192177e-06
Iter: 1097 loss: 1.01177375e-06
Iter: 1098 loss: 1.01149669e-06
Iter: 1099 loss: 1.01666637e-06
Iter: 1100 loss: 1.01148362e-06
Iter: 1101 loss: 1.01132707e-06
Iter: 1102 loss: 1.01344881e-06
Iter: 1103 loss: 1.01131855e-06
Iter: 1104 loss: 1.01108992e-06
Iter: 1105 loss: 1.01105479e-06
Iter: 1106 loss: 1.01087028e-06
Iter: 1107 loss: 1.01061198e-06
Iter: 1108 loss: 1.01020078e-06
Iter: 1109 loss: 1.01019464e-06
Iter: 1110 loss: 1.00971533e-06
Iter: 1111 loss: 1.01742103e-06
Iter: 1112 loss: 1.00972204e-06
Iter: 1113 loss: 1.00933664e-06
Iter: 1114 loss: 1.01148203e-06
Iter: 1115 loss: 1.0092707e-06
Iter: 1116 loss: 1.00892055e-06
Iter: 1117 loss: 1.0086801e-06
Iter: 1118 loss: 1.00856573e-06
Iter: 1119 loss: 1.00836974e-06
Iter: 1120 loss: 1.00836905e-06
Iter: 1121 loss: 1.00820068e-06
Iter: 1122 loss: 1.0085123e-06
Iter: 1123 loss: 1.00810701e-06
Iter: 1124 loss: 1.00799605e-06
Iter: 1125 loss: 1.00775651e-06
Iter: 1126 loss: 1.01304977e-06
Iter: 1127 loss: 1.00777515e-06
Iter: 1128 loss: 1.00758734e-06
Iter: 1129 loss: 1.00759416e-06
Iter: 1130 loss: 1.0073984e-06
Iter: 1131 loss: 1.0070479e-06
Iter: 1132 loss: 1.00704347e-06
Iter: 1133 loss: 1.00663726e-06
Iter: 1134 loss: 1.00687225e-06
Iter: 1135 loss: 1.00637976e-06
Iter: 1136 loss: 1.00637362e-06
Iter: 1137 loss: 1.00613624e-06
Iter: 1138 loss: 1.00604575e-06
Iter: 1139 loss: 1.0057629e-06
Iter: 1140 loss: 1.00656189e-06
Iter: 1141 loss: 1.00564216e-06
Iter: 1142 loss: 1.00531929e-06
Iter: 1143 loss: 1.00915281e-06
Iter: 1144 loss: 1.00531042e-06
Iter: 1145 loss: 1.00504735e-06
Iter: 1146 loss: 1.00663942e-06
Iter: 1147 loss: 1.00500392e-06
Iter: 1148 loss: 1.004762e-06
Iter: 1149 loss: 1.00493708e-06
Iter: 1150 loss: 1.00460454e-06
Iter: 1151 loss: 1.00430771e-06
Iter: 1152 loss: 1.00421471e-06
Iter: 1153 loss: 1.00404168e-06
Iter: 1154 loss: 1.00373131e-06
Iter: 1155 loss: 1.00372267e-06
Iter: 1156 loss: 1.00349882e-06
Iter: 1157 loss: 1.00307341e-06
Iter: 1158 loss: 1.01180513e-06
Iter: 1159 loss: 1.00307091e-06
Iter: 1160 loss: 1.00276634e-06
Iter: 1161 loss: 1.00712214e-06
Iter: 1162 loss: 1.00278601e-06
Iter: 1163 loss: 1.00247416e-06
Iter: 1164 loss: 1.00309217e-06
Iter: 1165 loss: 1.00235957e-06
Iter: 1166 loss: 1.00212446e-06
Iter: 1167 loss: 1.00197371e-06
Iter: 1168 loss: 1.00190209e-06
Iter: 1169 loss: 1.00175521e-06
Iter: 1170 loss: 1.00171349e-06
Iter: 1171 loss: 1.00154818e-06
Iter: 1172 loss: 1.00110071e-06
Iter: 1173 loss: 1.00600084e-06
Iter: 1174 loss: 1.00105422e-06
Iter: 1175 loss: 1.00065358e-06
Iter: 1176 loss: 1.00199827e-06
Iter: 1177 loss: 1.00054046e-06
Iter: 1178 loss: 1.00029013e-06
Iter: 1179 loss: 1.00397961e-06
Iter: 1180 loss: 1.00028774e-06
Iter: 1181 loss: 1.00008083e-06
Iter: 1182 loss: 1.00046418e-06
Iter: 1183 loss: 1.00002262e-06
Iter: 1184 loss: 9.99778194e-07
Iter: 1185 loss: 9.99571398e-07
Iter: 1186 loss: 9.99528311e-07
Iter: 1187 loss: 9.99337544e-07
Iter: 1188 loss: 9.99325607e-07
Iter: 1189 loss: 9.99116651e-07
Iter: 1190 loss: 9.98948167e-07
Iter: 1191 loss: 9.98886776e-07
Iter: 1192 loss: 9.98649e-07
Iter: 1193 loss: 9.98439191e-07
Iter: 1194 loss: 9.98367113e-07
Iter: 1195 loss: 9.98235e-07
Iter: 1196 loss: 9.9815361e-07
Iter: 1197 loss: 9.97998313e-07
Iter: 1198 loss: 9.97659299e-07
Iter: 1199 loss: 1.00311854e-06
Iter: 1200 loss: 9.97628831e-07
Iter: 1201 loss: 9.97539928e-07
Iter: 1202 loss: 9.97512757e-07
Iter: 1203 loss: 9.97331313e-07
Iter: 1204 loss: 9.97204211e-07
Iter: 1205 loss: 9.97165444e-07
Iter: 1206 loss: 9.96997414e-07
Iter: 1207 loss: 9.96783e-07
Iter: 1208 loss: 9.96759809e-07
Iter: 1209 loss: 9.9660565e-07
Iter: 1210 loss: 9.96577e-07
Iter: 1211 loss: 9.96434e-07
Iter: 1212 loss: 9.96351446e-07
Iter: 1213 loss: 9.96294e-07
Iter: 1214 loss: 9.96042e-07
Iter: 1215 loss: 9.96576773e-07
Iter: 1216 loss: 9.95963205e-07
Iter: 1217 loss: 9.95778237e-07
Iter: 1218 loss: 9.97014e-07
Iter: 1219 loss: 9.95746518e-07
Iter: 1220 loss: 9.95512664e-07
Iter: 1221 loss: 9.95577921e-07
Iter: 1222 loss: 9.9533338e-07
Iter: 1223 loss: 9.95148e-07
Iter: 1224 loss: 9.95037226e-07
Iter: 1225 loss: 9.94925813e-07
Iter: 1226 loss: 9.94789275e-07
Iter: 1227 loss: 9.94768698e-07
Iter: 1228 loss: 9.94550192e-07
Iter: 1229 loss: 9.94391371e-07
Iter: 1230 loss: 9.94344532e-07
Iter: 1231 loss: 9.94109882e-07
Iter: 1232 loss: 9.9514e-07
Iter: 1233 loss: 9.94078277e-07
Iter: 1234 loss: 9.93797357e-07
Iter: 1235 loss: 9.95130108e-07
Iter: 1236 loss: 9.93755066e-07
Iter: 1237 loss: 9.93619437e-07
Iter: 1238 loss: 9.93331696e-07
Iter: 1239 loss: 9.959615e-07
Iter: 1240 loss: 9.93308504e-07
Iter: 1241 loss: 9.93015192e-07
Iter: 1242 loss: 9.97111783e-07
Iter: 1243 loss: 9.93017e-07
Iter: 1244 loss: 9.92720402e-07
Iter: 1245 loss: 9.94181505e-07
Iter: 1246 loss: 9.92671858e-07
Iter: 1247 loss: 9.92481546e-07
Iter: 1248 loss: 9.92598643e-07
Iter: 1249 loss: 9.92328296e-07
Iter: 1250 loss: 9.92070227e-07
Iter: 1251 loss: 9.91967454e-07
Iter: 1252 loss: 9.918042e-07
Iter: 1253 loss: 9.91335241e-07
Iter: 1254 loss: 9.96263338e-07
Iter: 1255 loss: 9.91336719e-07
Iter: 1256 loss: 9.91181423e-07
Iter: 1257 loss: 9.90986791e-07
Iter: 1258 loss: 9.90953822e-07
Iter: 1259 loss: 9.90784201e-07
Iter: 1260 loss: 9.92252126e-07
Iter: 1261 loss: 9.90774197e-07
Iter: 1262 loss: 9.90549552e-07
Iter: 1263 loss: 9.90763169e-07
Iter: 1264 loss: 9.90414151e-07
Iter: 1265 loss: 9.90228841e-07
Iter: 1266 loss: 9.90676654e-07
Iter: 1267 loss: 9.90199851e-07
Iter: 1268 loss: 9.90017497e-07
Iter: 1269 loss: 9.91401748e-07
Iter: 1270 loss: 9.90022727e-07
Iter: 1271 loss: 9.8995e-07
Iter: 1272 loss: 9.89665068e-07
Iter: 1273 loss: 9.89811838e-07
Iter: 1274 loss: 9.89415071e-07
Iter: 1275 loss: 9.89016712e-07
Iter: 1276 loss: 9.95283e-07
Iter: 1277 loss: 9.89033197e-07
Iter: 1278 loss: 9.88792181e-07
Iter: 1279 loss: 9.88794e-07
Iter: 1280 loss: 9.8865e-07
Iter: 1281 loss: 9.88669626e-07
Iter: 1282 loss: 9.88557758e-07
Iter: 1283 loss: 9.88316742e-07
Iter: 1284 loss: 9.88137117e-07
Iter: 1285 loss: 9.88071633e-07
Iter: 1286 loss: 9.87989893e-07
Iter: 1287 loss: 9.87931799e-07
Iter: 1288 loss: 9.87792305e-07
Iter: 1289 loss: 9.8751093e-07
Iter: 1290 loss: 9.90687795e-07
Iter: 1291 loss: 9.87508201e-07
Iter: 1292 loss: 9.87248086e-07
Iter: 1293 loss: 9.87509679e-07
Iter: 1294 loss: 9.87101e-07
Iter: 1295 loss: 9.86943405e-07
Iter: 1296 loss: 9.8690623e-07
Iter: 1297 loss: 9.86767191e-07
Iter: 1298 loss: 9.86507075e-07
Iter: 1299 loss: 9.91838874e-07
Iter: 1300 loss: 9.8649889e-07
Iter: 1301 loss: 9.86355303e-07
Iter: 1302 loss: 9.86328587e-07
Iter: 1303 loss: 9.86221494e-07
Iter: 1304 loss: 9.85971838e-07
Iter: 1305 loss: 9.88432248e-07
Iter: 1306 loss: 9.85922725e-07
Iter: 1307 loss: 9.85604402e-07
Iter: 1308 loss: 9.85728093e-07
Iter: 1309 loss: 9.85357815e-07
Iter: 1310 loss: 9.85340762e-07
Iter: 1311 loss: 9.85222e-07
Iter: 1312 loss: 9.8511191e-07
Iter: 1313 loss: 9.85015276e-07
Iter: 1314 loss: 9.84975145e-07
Iter: 1315 loss: 9.84751068e-07
Iter: 1316 loss: 9.84682174e-07
Iter: 1317 loss: 9.84523922e-07
Iter: 1318 loss: 9.84276085e-07
Iter: 1319 loss: 9.85851102e-07
Iter: 1320 loss: 9.8426392e-07
Iter: 1321 loss: 9.84021085e-07
Iter: 1322 loss: 9.85360202e-07
Iter: 1323 loss: 9.83974473e-07
Iter: 1324 loss: 9.83834525e-07
Iter: 1325 loss: 9.83494829e-07
Iter: 1326 loss: 9.88558213e-07
Iter: 1327 loss: 9.83465e-07
Iter: 1328 loss: 9.83267228e-07
Iter: 1329 loss: 9.83256086e-07
Iter: 1330 loss: 9.82998472e-07
Iter: 1331 loss: 9.83065434e-07
Iter: 1332 loss: 9.82815436e-07
Iter: 1333 loss: 9.82665483e-07
Iter: 1334 loss: 9.84642156e-07
Iter: 1335 loss: 9.82657525e-07
Iter: 1336 loss: 9.82496e-07
Iter: 1337 loss: 9.82275424e-07
Iter: 1338 loss: 9.82253368e-07
Iter: 1339 loss: 9.8202e-07
Iter: 1340 loss: 9.8180476e-07
Iter: 1341 loss: 9.81758376e-07
Iter: 1342 loss: 9.81634457e-07
Iter: 1343 loss: 9.81587164e-07
Iter: 1344 loss: 9.81346e-07
Iter: 1345 loss: 9.81681524e-07
Iter: 1346 loss: 9.81259745e-07
Iter: 1347 loss: 9.810135e-07
Iter: 1348 loss: 9.81003836e-07
Iter: 1349 loss: 9.8083342e-07
Iter: 1350 loss: 9.80449727e-07
Iter: 1351 loss: 9.80051254e-07
Iter: 1352 loss: 9.79988272e-07
Iter: 1353 loss: 9.80124e-07
Iter: 1354 loss: 9.79793e-07
Iter: 1355 loss: 9.79631523e-07
Iter: 1356 loss: 9.79200877e-07
Iter: 1357 loss: 9.83895688e-07
Iter: 1358 loss: 9.7917291e-07
Iter: 1359 loss: 9.78887215e-07
Iter: 1360 loss: 9.81596e-07
Iter: 1361 loss: 9.78878e-07
Iter: 1362 loss: 9.78623575e-07
Iter: 1363 loss: 9.79765332e-07
Iter: 1364 loss: 9.78580374e-07
Iter: 1365 loss: 9.7837642e-07
Iter: 1366 loss: 9.78927119e-07
Iter: 1367 loss: 9.78318099e-07
Iter: 1368 loss: 9.78059688e-07
Iter: 1369 loss: 9.78304342e-07
Iter: 1370 loss: 9.77940431e-07
Iter: 1371 loss: 9.77692707e-07
Iter: 1372 loss: 9.77357786e-07
Iter: 1373 loss: 9.77328682e-07
Iter: 1374 loss: 9.76911e-07
Iter: 1375 loss: 9.77402124e-07
Iter: 1376 loss: 9.76666115e-07
Iter: 1377 loss: 9.76972387e-07
Iter: 1378 loss: 9.76528554e-07
Iter: 1379 loss: 9.76427145e-07
Iter: 1380 loss: 9.76177262e-07
Iter: 1381 loss: 9.77928266e-07
Iter: 1382 loss: 9.76118827e-07
Iter: 1383 loss: 9.7576833e-07
Iter: 1384 loss: 9.77019454e-07
Iter: 1385 loss: 9.75656803e-07
Iter: 1386 loss: 9.75413514e-07
Iter: 1387 loss: 9.76383e-07
Iter: 1388 loss: 9.7536622e-07
Iter: 1389 loss: 9.75113153e-07
Iter: 1390 loss: 9.78108801e-07
Iter: 1391 loss: 9.75129751e-07
Iter: 1392 loss: 9.74978e-07
Iter: 1393 loss: 9.74577e-07
Iter: 1394 loss: 9.76119622e-07
Iter: 1395 loss: 9.74365435e-07
Iter: 1396 loss: 9.74386353e-07
Iter: 1397 loss: 9.74086333e-07
Iter: 1398 loss: 9.73869646e-07
Iter: 1399 loss: 9.73486749e-07
Iter: 1400 loss: 9.7347629e-07
Iter: 1401 loss: 9.73305305e-07
Iter: 1402 loss: 9.73268698e-07
Iter: 1403 loss: 9.73075203e-07
Iter: 1404 loss: 9.72819862e-07
Iter: 1405 loss: 9.72809516e-07
Iter: 1406 loss: 9.72317821e-07
Iter: 1407 loss: 9.72644102e-07
Iter: 1408 loss: 9.72010184e-07
Iter: 1409 loss: 9.7156169e-07
Iter: 1410 loss: 9.72894327e-07
Iter: 1411 loss: 9.71415602e-07
Iter: 1412 loss: 9.70992346e-07
Iter: 1413 loss: 9.76760589e-07
Iter: 1414 loss: 9.70975861e-07
Iter: 1415 loss: 9.70626388e-07
Iter: 1416 loss: 9.73755618e-07
Iter: 1417 loss: 9.70612518e-07
Iter: 1418 loss: 9.70439e-07
Iter: 1419 loss: 9.70157316e-07
Iter: 1420 loss: 9.76791171e-07
Iter: 1421 loss: 9.701522e-07
Iter: 1422 loss: 9.69744519e-07
Iter: 1423 loss: 9.71299414e-07
Iter: 1424 loss: 9.69656e-07
Iter: 1425 loss: 9.69328653e-07
Iter: 1426 loss: 9.71296458e-07
Iter: 1427 loss: 9.69298071e-07
Iter: 1428 loss: 9.68994e-07
Iter: 1429 loss: 9.70937094e-07
Iter: 1430 loss: 9.68961672e-07
Iter: 1431 loss: 9.68789209e-07
Iter: 1432 loss: 9.68484073e-07
Iter: 1433 loss: 9.68482823e-07
Iter: 1434 loss: 9.68094128e-07
Iter: 1435 loss: 9.73085889e-07
Iter: 1436 loss: 9.68095264e-07
Iter: 1437 loss: 9.67938831e-07
Iter: 1438 loss: 9.67948267e-07
Iter: 1439 loss: 9.67839128e-07
Iter: 1440 loss: 9.67530468e-07
Iter: 1441 loss: 9.68321274e-07
Iter: 1442 loss: 9.67411893e-07
Iter: 1443 loss: 9.67244887e-07
Iter: 1444 loss: 9.6687e-07
Iter: 1445 loss: 9.72205726e-07
Iter: 1446 loss: 9.66838911e-07
Iter: 1447 loss: 9.66438165e-07
Iter: 1448 loss: 9.67825e-07
Iter: 1449 loss: 9.66297307e-07
Iter: 1450 loss: 9.66211928e-07
Iter: 1451 loss: 9.66126663e-07
Iter: 1452 loss: 9.65952e-07
Iter: 1453 loss: 9.6606891e-07
Iter: 1454 loss: 9.65805611e-07
Iter: 1455 loss: 9.65629624e-07
Iter: 1456 loss: 9.65530717e-07
Iter: 1457 loss: 9.65464778e-07
Iter: 1458 loss: 9.65128379e-07
Iter: 1459 loss: 9.66224889e-07
Iter: 1460 loss: 9.65014578e-07
Iter: 1461 loss: 9.64810852e-07
Iter: 1462 loss: 9.64822334e-07
Iter: 1463 loss: 9.64631e-07
Iter: 1464 loss: 9.64341098e-07
Iter: 1465 loss: 9.64341439e-07
Iter: 1466 loss: 9.64039373e-07
Iter: 1467 loss: 9.67753294e-07
Iter: 1468 loss: 9.64022774e-07
Iter: 1469 loss: 9.63685466e-07
Iter: 1470 loss: 9.63390903e-07
Iter: 1471 loss: 9.63321213e-07
Iter: 1472 loss: 9.63188313e-07
Iter: 1473 loss: 9.63145794e-07
Iter: 1474 loss: 9.629955e-07
Iter: 1475 loss: 9.6253666e-07
Iter: 1476 loss: 9.64064611e-07
Iter: 1477 loss: 9.6236613e-07
Iter: 1478 loss: 9.61840215e-07
Iter: 1479 loss: 9.63237653e-07
Iter: 1480 loss: 9.61694354e-07
Iter: 1481 loss: 9.61337264e-07
Iter: 1482 loss: 9.61051796e-07
Iter: 1483 loss: 9.60954367e-07
Iter: 1484 loss: 9.60914349e-07
Iter: 1485 loss: 9.60701e-07
Iter: 1486 loss: 9.60465059e-07
Iter: 1487 loss: 9.60141e-07
Iter: 1488 loss: 9.60100351e-07
Iter: 1489 loss: 9.5984e-07
Iter: 1490 loss: 9.60741772e-07
Iter: 1491 loss: 9.59750651e-07
Iter: 1492 loss: 9.59506337e-07
Iter: 1493 loss: 9.59715294e-07
Iter: 1494 loss: 9.59325e-07
Iter: 1495 loss: 9.5903431e-07
Iter: 1496 loss: 9.61007e-07
Iter: 1497 loss: 9.5900532e-07
Iter: 1498 loss: 9.58767373e-07
Iter: 1499 loss: 9.5903863e-07
Iter: 1500 loss: 9.58635383e-07
Iter: 1501 loss: 9.5841051e-07
Iter: 1502 loss: 9.60694251e-07
Iter: 1503 loss: 9.58392e-07
Iter: 1504 loss: 9.58244186e-07
Iter: 1505 loss: 9.58239525e-07
Iter: 1506 loss: 9.58111e-07
Iter: 1507 loss: 9.57784323e-07
Iter: 1508 loss: 9.57449856e-07
Iter: 1509 loss: 9.57386e-07
Iter: 1510 loss: 9.56975327e-07
Iter: 1511 loss: 9.57091515e-07
Iter: 1512 loss: 9.56695885e-07
Iter: 1513 loss: 9.56307758e-07
Iter: 1514 loss: 9.57044904e-07
Iter: 1515 loss: 9.56150643e-07
Iter: 1516 loss: 9.55931455e-07
Iter: 1517 loss: 9.55909059e-07
Iter: 1518 loss: 9.5572716e-07
Iter: 1519 loss: 9.56266376e-07
Iter: 1520 loss: 9.55659061e-07
Iter: 1521 loss: 9.55530595e-07
Iter: 1522 loss: 9.55279e-07
Iter: 1523 loss: 9.60133093e-07
Iter: 1524 loss: 9.55277073e-07
Iter: 1525 loss: 9.54951361e-07
Iter: 1526 loss: 9.58772716e-07
Iter: 1527 loss: 9.54957386e-07
Iter: 1528 loss: 9.54738e-07
Iter: 1529 loss: 9.55681116e-07
Iter: 1530 loss: 9.54689085e-07
Iter: 1531 loss: 9.54490361e-07
Iter: 1532 loss: 9.54538109e-07
Iter: 1533 loss: 9.54339384e-07
Iter: 1534 loss: 9.54235816e-07
Iter: 1535 loss: 9.54204e-07
Iter: 1536 loss: 9.54128836e-07
Iter: 1537 loss: 9.54074267e-07
Iter: 1538 loss: 9.54056759e-07
Iter: 1539 loss: 9.53923291e-07
Iter: 1540 loss: 9.55100631e-07
Iter: 1541 loss: 9.53931476e-07
Iter: 1542 loss: 9.53853487e-07
Iter: 1543 loss: 9.53670792e-07
Iter: 1544 loss: 9.55618134e-07
Iter: 1545 loss: 9.53661811e-07
Iter: 1546 loss: 9.53460756e-07
Iter: 1547 loss: 9.53705467e-07
Iter: 1548 loss: 9.53366623e-07
Iter: 1549 loss: 9.53199219e-07
Iter: 1550 loss: 9.55292762e-07
Iter: 1551 loss: 9.53184554e-07
Iter: 1552 loss: 9.53014705e-07
Iter: 1553 loss: 9.54390316e-07
Iter: 1554 loss: 9.52985374e-07
Iter: 1555 loss: 9.52899882e-07
Iter: 1556 loss: 9.52754e-07
Iter: 1557 loss: 9.52744927e-07
Iter: 1558 loss: 9.52591506e-07
Iter: 1559 loss: 9.53406243e-07
Iter: 1560 loss: 9.52567348e-07
Iter: 1561 loss: 9.52434903e-07
Iter: 1562 loss: 9.52896698e-07
Iter: 1563 loss: 9.52393805e-07
Iter: 1564 loss: 9.52271705e-07
Iter: 1565 loss: 9.52607081e-07
Iter: 1566 loss: 9.52200821e-07
Iter: 1567 loss: 9.52072867e-07
Iter: 1568 loss: 9.52136133e-07
Iter: 1569 loss: 9.51987204e-07
Iter: 1570 loss: 9.51814798e-07
Iter: 1571 loss: 9.53832341e-07
Iter: 1572 loss: 9.51824632e-07
Iter: 1573 loss: 9.51732147e-07
Iter: 1574 loss: 9.5183e-07
Iter: 1575 loss: 9.5168258e-07
Iter: 1576 loss: 9.51532172e-07
Iter: 1577 loss: 9.51805703e-07
Iter: 1578 loss: 9.51480843e-07
Iter: 1579 loss: 9.51386596e-07
Iter: 1580 loss: 9.51246648e-07
Iter: 1581 loss: 9.51246534e-07
Iter: 1582 loss: 9.51062191e-07
Iter: 1583 loss: 9.5111352e-07
Iter: 1584 loss: 9.50942535e-07
Iter: 1585 loss: 9.50730964e-07
Iter: 1586 loss: 9.52759592e-07
Iter: 1587 loss: 9.50723177e-07
Iter: 1588 loss: 9.50537071e-07
Iter: 1589 loss: 9.51497668e-07
Iter: 1590 loss: 9.50494893e-07
Iter: 1591 loss: 9.50400135e-07
Iter: 1592 loss: 9.50179469e-07
Iter: 1593 loss: 9.5340539e-07
Iter: 1594 loss: 9.50171909e-07
Iter: 1595 loss: 9.49985804e-07
Iter: 1596 loss: 9.52677681e-07
Iter: 1597 loss: 9.49983871e-07
Iter: 1598 loss: 9.49847504e-07
Iter: 1599 loss: 9.50809351e-07
Iter: 1600 loss: 9.49833463e-07
Iter: 1601 loss: 9.49712273e-07
Iter: 1602 loss: 9.49732453e-07
Iter: 1603 loss: 9.49636956e-07
Iter: 1604 loss: 9.49487912e-07
Iter: 1605 loss: 9.49337846e-07
Iter: 1606 loss: 9.49327386e-07
Iter: 1607 loss: 9.49209721e-07
Iter: 1608 loss: 9.49177263e-07
Iter: 1609 loss: 9.49091543e-07
Iter: 1610 loss: 9.48998718e-07
Iter: 1611 loss: 9.48976776e-07
Iter: 1612 loss: 9.48848765e-07
Iter: 1613 loss: 9.50629556e-07
Iter: 1614 loss: 9.48852744e-07
Iter: 1615 loss: 9.48781e-07
Iter: 1616 loss: 9.48629747e-07
Iter: 1617 loss: 9.51513243e-07
Iter: 1618 loss: 9.48630088e-07
Iter: 1619 loss: 9.48511456e-07
Iter: 1620 loss: 9.48549371e-07
Iter: 1621 loss: 9.48434206e-07
Iter: 1622 loss: 9.48363493e-07
Iter: 1623 loss: 9.48332854e-07
Iter: 1624 loss: 9.48236675e-07
Iter: 1625 loss: 9.48104059e-07
Iter: 1626 loss: 9.48096726e-07
Iter: 1627 loss: 9.47898457e-07
Iter: 1628 loss: 9.47677449e-07
Iter: 1629 loss: 9.4766159e-07
Iter: 1630 loss: 9.47625495e-07
Iter: 1631 loss: 9.47509136e-07
Iter: 1632 loss: 9.47413241e-07
Iter: 1633 loss: 9.47361855e-07
Iter: 1634 loss: 9.47310468e-07
Iter: 1635 loss: 9.47172339e-07
Iter: 1636 loss: 9.47025e-07
Iter: 1637 loss: 9.47001183e-07
Iter: 1638 loss: 9.46772843e-07
Iter: 1639 loss: 9.48654815e-07
Iter: 1640 loss: 9.46763578e-07
Iter: 1641 loss: 9.46546379e-07
Iter: 1642 loss: 9.48135153e-07
Iter: 1643 loss: 9.46550927e-07
Iter: 1644 loss: 9.46450768e-07
Iter: 1645 loss: 9.46734076e-07
Iter: 1646 loss: 9.46417572e-07
Iter: 1647 loss: 9.46282512e-07
Iter: 1648 loss: 9.46119314e-07
Iter: 1649 loss: 9.46119485e-07
Iter: 1650 loss: 9.45948614e-07
Iter: 1651 loss: 9.45823786e-07
Iter: 1652 loss: 9.45776435e-07
Iter: 1653 loss: 9.45522061e-07
Iter: 1654 loss: 9.4636016e-07
Iter: 1655 loss: 9.45463853e-07
Iter: 1656 loss: 9.45340844e-07
Iter: 1657 loss: 9.45330271e-07
Iter: 1658 loss: 9.45181512e-07
Iter: 1659 loss: 9.44915371e-07
Iter: 1660 loss: 9.449152e-07
Iter: 1661 loss: 9.44722615e-07
Iter: 1662 loss: 9.44831e-07
Iter: 1663 loss: 9.44600799e-07
Iter: 1664 loss: 9.44566864e-07
Iter: 1665 loss: 9.44506496e-07
Iter: 1666 loss: 9.44419639e-07
Iter: 1667 loss: 9.44243084e-07
Iter: 1668 loss: 9.47842068e-07
Iter: 1669 loss: 9.44238536e-07
Iter: 1670 loss: 9.44129397e-07
Iter: 1671 loss: 9.44858357e-07
Iter: 1672 loss: 9.44098815e-07
Iter: 1673 loss: 9.43984276e-07
Iter: 1674 loss: 9.43952443e-07
Iter: 1675 loss: 9.43876273e-07
Iter: 1676 loss: 9.43757186e-07
Iter: 1677 loss: 9.4507277e-07
Iter: 1678 loss: 9.43760938e-07
Iter: 1679 loss: 9.436406e-07
Iter: 1680 loss: 9.44310273e-07
Iter: 1681 loss: 9.43615703e-07
Iter: 1682 loss: 9.43553e-07
Iter: 1683 loss: 9.43529187e-07
Iter: 1684 loss: 9.43500936e-07
Iter: 1685 loss: 9.43386e-07
Iter: 1686 loss: 9.44113367e-07
Iter: 1687 loss: 9.43383156e-07
Iter: 1688 loss: 9.43323e-07
Iter: 1689 loss: 9.43186819e-07
Iter: 1690 loss: 9.45500233e-07
Iter: 1691 loss: 9.43207283e-07
Iter: 1692 loss: 9.43105078e-07
Iter: 1693 loss: 9.43105192e-07
Iter: 1694 loss: 9.42989232e-07
Iter: 1695 loss: 9.42877136e-07
Iter: 1696 loss: 9.42853433e-07
Iter: 1697 loss: 9.42760948e-07
Iter: 1698 loss: 9.44065334e-07
Iter: 1699 loss: 9.4276794e-07
Iter: 1700 loss: 9.42665e-07
Iter: 1701 loss: 9.42521694e-07
Iter: 1702 loss: 9.42509928e-07
Iter: 1703 loss: 9.42310294e-07
Iter: 1704 loss: 9.42426254e-07
Iter: 1705 loss: 9.42170061e-07
Iter: 1706 loss: 9.41960764e-07
Iter: 1707 loss: 9.44229e-07
Iter: 1708 loss: 9.41970939e-07
Iter: 1709 loss: 9.41848782e-07
Iter: 1710 loss: 9.41757776e-07
Iter: 1711 loss: 9.41745384e-07
Iter: 1712 loss: 9.41629708e-07
Iter: 1713 loss: 9.41602366e-07
Iter: 1714 loss: 9.41496523e-07
Iter: 1715 loss: 9.41309679e-07
Iter: 1716 loss: 9.4493231e-07
Iter: 1717 loss: 9.41309168e-07
Iter: 1718 loss: 9.41226176e-07
Iter: 1719 loss: 9.41204121e-07
Iter: 1720 loss: 9.41122039e-07
Iter: 1721 loss: 9.40956738e-07
Iter: 1722 loss: 9.43011287e-07
Iter: 1723 loss: 9.40942471e-07
Iter: 1724 loss: 9.40784616e-07
Iter: 1725 loss: 9.42668521e-07
Iter: 1726 loss: 9.40768132e-07
Iter: 1727 loss: 9.40636255e-07
Iter: 1728 loss: 9.40802124e-07
Iter: 1729 loss: 9.40552923e-07
Iter: 1730 loss: 9.40479651e-07
Iter: 1731 loss: 9.40725101e-07
Iter: 1732 loss: 9.40418317e-07
Iter: 1733 loss: 9.40321229e-07
Iter: 1734 loss: 9.40528935e-07
Iter: 1735 loss: 9.40245286e-07
Iter: 1736 loss: 9.40115228e-07
Iter: 1737 loss: 9.40223231e-07
Iter: 1738 loss: 9.40044629e-07
Iter: 1739 loss: 9.39888594e-07
Iter: 1740 loss: 9.39687311e-07
Iter: 1741 loss: 9.39672532e-07
Iter: 1742 loss: 9.39521271e-07
Iter: 1743 loss: 9.39517e-07
Iter: 1744 loss: 9.39407585e-07
Iter: 1745 loss: 9.40344421e-07
Iter: 1746 loss: 9.39401275e-07
Iter: 1747 loss: 9.39269171e-07
Iter: 1748 loss: 9.39495578e-07
Iter: 1749 loss: 9.39215909e-07
Iter: 1750 loss: 9.39106485e-07
Iter: 1751 loss: 9.39330619e-07
Iter: 1752 loss: 9.39077836e-07
Iter: 1753 loss: 9.38933e-07
Iter: 1754 loss: 9.39497568e-07
Iter: 1755 loss: 9.38891958e-07
Iter: 1756 loss: 9.38831818e-07
Iter: 1757 loss: 9.3870068e-07
Iter: 1758 loss: 9.41099813e-07
Iter: 1759 loss: 9.38668109e-07
Iter: 1760 loss: 9.38491439e-07
Iter: 1761 loss: 9.38502183e-07
Iter: 1762 loss: 9.38391054e-07
Iter: 1763 loss: 9.38353878e-07
Iter: 1764 loss: 9.38324092e-07
Iter: 1765 loss: 9.38196763e-07
Iter: 1766 loss: 9.39251549e-07
Iter: 1767 loss: 9.38189714e-07
Iter: 1768 loss: 9.38103369e-07
Iter: 1769 loss: 9.38052e-07
Iter: 1770 loss: 9.38033793e-07
Iter: 1771 loss: 9.37903224e-07
Iter: 1772 loss: 9.37952052e-07
Iter: 1773 loss: 9.3782478e-07
Iter: 1774 loss: 9.37720131e-07
Iter: 1775 loss: 9.37513846e-07
Iter: 1776 loss: 9.37541245e-07
Iter: 1777 loss: 9.37325467e-07
Iter: 1778 loss: 9.37339451e-07
Iter: 1779 loss: 9.37143284e-07
Iter: 1780 loss: 9.37172103e-07
Iter: 1781 loss: 9.3699424e-07
Iter: 1782 loss: 9.36779657e-07
Iter: 1783 loss: 9.38307e-07
Iter: 1784 loss: 9.36751064e-07
Iter: 1785 loss: 9.36613446e-07
Iter: 1786 loss: 9.38048345e-07
Iter: 1787 loss: 9.36590482e-07
Iter: 1788 loss: 9.36545916e-07
Iter: 1789 loss: 9.36420349e-07
Iter: 1790 loss: 9.36417678e-07
Iter: 1791 loss: 9.36352e-07
Iter: 1792 loss: 9.36350375e-07
Iter: 1793 loss: 9.3625772e-07
Iter: 1794 loss: 9.36094182e-07
Iter: 1795 loss: 9.39450047e-07
Iter: 1796 loss: 9.36081733e-07
Iter: 1797 loss: 9.35953551e-07
Iter: 1798 loss: 9.37977745e-07
Iter: 1799 loss: 9.35945422e-07
Iter: 1800 loss: 9.3581275e-07
Iter: 1801 loss: 9.35632443e-07
Iter: 1802 loss: 9.35602145e-07
Iter: 1803 loss: 9.35430762e-07
Iter: 1804 loss: 9.36900904e-07
Iter: 1805 loss: 9.35404387e-07
Iter: 1806 loss: 9.3522408e-07
Iter: 1807 loss: 9.3528763e-07
Iter: 1808 loss: 9.35077196e-07
Iter: 1809 loss: 9.34979653e-07
Iter: 1810 loss: 9.35060825e-07
Iter: 1811 loss: 9.34951629e-07
Iter: 1812 loss: 9.34831803e-07
Iter: 1813 loss: 9.35548371e-07
Iter: 1814 loss: 9.34812533e-07
Iter: 1815 loss: 9.34713171e-07
Iter: 1816 loss: 9.35134551e-07
Iter: 1817 loss: 9.34687478e-07
Iter: 1818 loss: 9.34596244e-07
Iter: 1819 loss: 9.34938839e-07
Iter: 1820 loss: 9.34563559e-07
Iter: 1821 loss: 9.34468744e-07
Iter: 1822 loss: 9.34440436e-07
Iter: 1823 loss: 9.34379727e-07
Iter: 1824 loss: 9.34257741e-07
Iter: 1825 loss: 9.34651894e-07
Iter: 1826 loss: 9.34190325e-07
Iter: 1827 loss: 9.34097045e-07
Iter: 1828 loss: 9.34109949e-07
Iter: 1829 loss: 9.34028662e-07
Iter: 1830 loss: 9.33927765e-07
Iter: 1831 loss: 9.33935553e-07
Iter: 1832 loss: 9.33849492e-07
Iter: 1833 loss: 9.3416304e-07
Iter: 1834 loss: 9.33828915e-07
Iter: 1835 loss: 9.33693173e-07
Iter: 1836 loss: 9.34129503e-07
Iter: 1837 loss: 9.33669526e-07
Iter: 1838 loss: 9.33587e-07
Iter: 1839 loss: 9.33444312e-07
Iter: 1840 loss: 9.36544666e-07
Iter: 1841 loss: 9.33451417e-07
Iter: 1842 loss: 9.33307e-07
Iter: 1843 loss: 9.34546676e-07
Iter: 1844 loss: 9.33300669e-07
Iter: 1845 loss: 9.33172544e-07
Iter: 1846 loss: 9.33292426e-07
Iter: 1847 loss: 9.33085914e-07
Iter: 1848 loss: 9.33001161e-07
Iter: 1849 loss: 9.3299775e-07
Iter: 1850 loss: 9.32958642e-07
Iter: 1851 loss: 9.3300946e-07
Iter: 1852 loss: 9.32957107e-07
Iter: 1853 loss: 9.32899866e-07
Iter: 1854 loss: 9.33221372e-07
Iter: 1855 loss: 9.32872922e-07
Iter: 1856 loss: 9.32818864e-07
Iter: 1857 loss: 9.32766852e-07
Iter: 1858 loss: 9.3275321e-07
Iter: 1859 loss: 9.32651346e-07
Iter: 1860 loss: 9.33024751e-07
Iter: 1861 loss: 9.32627131e-07
Iter: 1862 loss: 9.32533339e-07
Iter: 1863 loss: 9.32957278e-07
Iter: 1864 loss: 9.32503099e-07
Iter: 1865 loss: 9.32406863e-07
Iter: 1866 loss: 9.32219e-07
Iter: 1867 loss: 9.32207286e-07
Iter: 1868 loss: 9.32189607e-07
Iter: 1869 loss: 9.32120145e-07
Iter: 1870 loss: 9.32075523e-07
Iter: 1871 loss: 9.31972636e-07
Iter: 1872 loss: 9.34259106e-07
Iter: 1873 loss: 9.31966156e-07
Iter: 1874 loss: 9.31922386e-07
Iter: 1875 loss: 9.32121679e-07
Iter: 1876 loss: 9.31920908e-07
Iter: 1877 loss: 9.31854458e-07
Iter: 1878 loss: 9.32277771e-07
Iter: 1879 loss: 9.31829e-07
Iter: 1880 loss: 9.31777436e-07
Iter: 1881 loss: 9.31844966e-07
Iter: 1882 loss: 9.31749e-07
Iter: 1883 loss: 9.31678073e-07
Iter: 1884 loss: 9.31647264e-07
Iter: 1885 loss: 9.31573368e-07
Iter: 1886 loss: 9.31557906e-07
Iter: 1887 loss: 9.31529314e-07
Iter: 1888 loss: 9.31485147e-07
Iter: 1889 loss: 9.31355771e-07
Iter: 1890 loss: 9.3333864e-07
Iter: 1891 loss: 9.31358386e-07
Iter: 1892 loss: 9.31275508e-07
Iter: 1893 loss: 9.32359171e-07
Iter: 1894 loss: 9.31260445e-07
Iter: 1895 loss: 9.31198088e-07
Iter: 1896 loss: 9.31621628e-07
Iter: 1897 loss: 9.31193654e-07
Iter: 1898 loss: 9.31142495e-07
Iter: 1899 loss: 9.3104228e-07
Iter: 1900 loss: 9.31045406e-07
Iter: 1901 loss: 9.30975261e-07
Iter: 1902 loss: 9.31399597e-07
Iter: 1903 loss: 9.3096503e-07
Iter: 1904 loss: 9.30857084e-07
Iter: 1905 loss: 9.30874478e-07
Iter: 1906 loss: 9.30777e-07
Iter: 1907 loss: 9.30699457e-07
Iter: 1908 loss: 9.30709348e-07
Iter: 1909 loss: 9.30611463e-07
Iter: 1910 loss: 9.30548481e-07
Iter: 1911 loss: 9.30569058e-07
Iter: 1912 loss: 9.30496412e-07
Iter: 1913 loss: 9.30522219e-07
Iter: 1914 loss: 9.30467365e-07
Iter: 1915 loss: 9.3040768e-07
Iter: 1916 loss: 9.30524607e-07
Iter: 1917 loss: 9.30368969e-07
Iter: 1918 loss: 9.30279384e-07
Iter: 1919 loss: 9.30497151e-07
Iter: 1920 loss: 9.30259944e-07
Iter: 1921 loss: 9.30151714e-07
Iter: 1922 loss: 9.30368969e-07
Iter: 1923 loss: 9.30111753e-07
Iter: 1924 loss: 9.3005184e-07
Iter: 1925 loss: 9.30006422e-07
Iter: 1926 loss: 9.29974817e-07
Iter: 1927 loss: 9.29856242e-07
Iter: 1928 loss: 9.30693204e-07
Iter: 1929 loss: 9.29834357e-07
Iter: 1930 loss: 9.29741361e-07
Iter: 1931 loss: 9.301163e-07
Iter: 1932 loss: 9.2971959e-07
Iter: 1933 loss: 9.29666726e-07
Iter: 1934 loss: 9.29704584e-07
Iter: 1935 loss: 9.29638588e-07
Iter: 1936 loss: 9.29589191e-07
Iter: 1937 loss: 9.3036931e-07
Iter: 1938 loss: 9.29603743e-07
Iter: 1939 loss: 9.2955338e-07
Iter: 1940 loss: 9.29420821e-07
Iter: 1941 loss: 9.29737e-07
Iter: 1942 loss: 9.29343e-07
Iter: 1943 loss: 9.29252053e-07
Iter: 1944 loss: 9.29252906e-07
Iter: 1945 loss: 9.29165878e-07
Iter: 1946 loss: 9.29339762e-07
Iter: 1947 loss: 9.29100793e-07
Iter: 1948 loss: 9.29019279e-07
Iter: 1949 loss: 9.29271437e-07
Iter: 1950 loss: 9.29018483e-07
Iter: 1951 loss: 9.28948907e-07
Iter: 1952 loss: 9.29101361e-07
Iter: 1953 loss: 9.28908889e-07
Iter: 1954 loss: 9.28867735e-07
Iter: 1955 loss: 9.28869497e-07
Iter: 1956 loss: 9.28849829e-07
Iter: 1957 loss: 9.28756549e-07
Iter: 1958 loss: 9.29556563e-07
Iter: 1959 loss: 9.28774682e-07
Iter: 1960 loss: 9.28688735e-07
Iter: 1961 loss: 9.29296903e-07
Iter: 1962 loss: 9.28681061e-07
Iter: 1963 loss: 9.28603527e-07
Iter: 1964 loss: 9.28598e-07
Iter: 1965 loss: 9.28527527e-07
Iter: 1966 loss: 9.28394797e-07
Iter: 1967 loss: 9.28677196e-07
Iter: 1968 loss: 9.28351596e-07
Iter: 1969 loss: 9.28281111e-07
Iter: 1970 loss: 9.28280144e-07
Iter: 1971 loss: 9.28231941e-07
Iter: 1972 loss: 9.28211421e-07
Iter: 1973 loss: 9.28169868e-07
Iter: 1974 loss: 9.28123825e-07
Iter: 1975 loss: 9.28093e-07
Iter: 1976 loss: 9.28079317e-07
Iter: 1977 loss: 9.28043278e-07
Iter: 1978 loss: 9.2803441e-07
Iter: 1979 loss: 9.27986264e-07
Iter: 1980 loss: 9.27924e-07
Iter: 1981 loss: 9.27930273e-07
Iter: 1982 loss: 9.27830797e-07
Iter: 1983 loss: 9.27755877e-07
Iter: 1984 loss: 9.27717451e-07
Iter: 1985 loss: 9.27586143e-07
Iter: 1986 loss: 9.28525537e-07
Iter: 1987 loss: 9.27561246e-07
Iter: 1988 loss: 9.27450628e-07
Iter: 1989 loss: 9.28679299e-07
Iter: 1990 loss: 9.27444603e-07
Iter: 1991 loss: 9.27393387e-07
Iter: 1992 loss: 9.272851e-07
Iter: 1993 loss: 9.28683335e-07
Iter: 1994 loss: 9.27287033e-07
Iter: 1995 loss: 9.27255712e-07
Iter: 1996 loss: 9.27227745e-07
Iter: 1997 loss: 9.27196083e-07
Iter: 1998 loss: 9.27111273e-07
Iter: 1999 loss: 9.27107294e-07
Iter: 2000 loss: 9.27036922e-07
Iter: 2001 loss: 9.27078133e-07
Iter: 2002 loss: 9.26985649e-07
Iter: 2003 loss: 9.26870257e-07
Iter: 2004 loss: 9.27319093e-07
Iter: 2005 loss: 9.26859911e-07
Iter: 2006 loss: 9.26761402e-07
Iter: 2007 loss: 9.2732563e-07
Iter: 2008 loss: 9.26727353e-07
Iter: 2009 loss: 9.26666189e-07
Iter: 2010 loss: 9.26598318e-07
Iter: 2011 loss: 9.26580469e-07
Iter: 2012 loss: 9.26502935e-07
Iter: 2013 loss: 9.26625603e-07
Iter: 2014 loss: 9.2649384e-07
Iter: 2015 loss: 9.26459165e-07
Iter: 2016 loss: 9.26432563e-07
Iter: 2017 loss: 9.2642324e-07
Iter: 2018 loss: 9.26342e-07
Iter: 2019 loss: 9.27023166e-07
Iter: 2020 loss: 9.26334224e-07
Iter: 2021 loss: 9.26300572e-07
Iter: 2022 loss: 9.26295684e-07
Iter: 2023 loss: 9.26251e-07
Iter: 2024 loss: 9.26190182e-07
Iter: 2025 loss: 9.26198766e-07
Iter: 2026 loss: 9.26121e-07
Iter: 2027 loss: 9.26696e-07
Iter: 2028 loss: 9.26109806e-07
Iter: 2029 loss: 9.26053644e-07
Iter: 2030 loss: 9.26493044e-07
Iter: 2031 loss: 9.26041878e-07
Iter: 2032 loss: 9.26002485e-07
Iter: 2033 loss: 9.25909603e-07
Iter: 2034 loss: 9.2590119e-07
Iter: 2035 loss: 9.25849918e-07
Iter: 2036 loss: 9.25847701e-07
Iter: 2037 loss: 9.25807285e-07
Iter: 2038 loss: 9.25790403e-07
Iter: 2039 loss: 9.25751181e-07
Iter: 2040 loss: 9.25668928e-07
Iter: 2041 loss: 9.25789777e-07
Iter: 2042 loss: 9.25653353e-07
Iter: 2043 loss: 9.25573e-07
Iter: 2044 loss: 9.25515792e-07
