+ RUN=2
+ export CUDA_VISIBLE_DEVICES=2
+ CUDA_VISIBLE_DEVICES=2
+ LAYERS=300_300_300_1
+ case $RUN in
+ PSI=2
+ OPTIONS='			 --optimizer adam 				 --n_pairs 50000 				 --batch_size 5000 				 --max_epochs 200 				 --learning_rate 0.001 				 --decay_rate 0.98 				 --loss_func weighted_MSE 
'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output80
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output81
+ for fn in f1
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL='--load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0
+ date
Mon Nov  2 08:23:29 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 2 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f402661e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f40266378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f401e4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f4022ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f4022f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f40146400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f4022f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef46e8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f40167620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f4022f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f400a4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f40067f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f40067b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f400c1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef4751d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef4751bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef4641598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef46419d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef44a9e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef44a9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef44e2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef458de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef45cd9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef45d0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef46116a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef4611bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef46197b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef46198c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef433a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef433aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef4509048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef4467ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef4486730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef4559598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef43f7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4ef440ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 1.1762902e-05
test_loss: 1.0715558e-05
train_loss: 8.725289e-06
test_loss: 8.972613e-06
train_loss: 8.21555e-06
test_loss: 8.521943e-06
train_loss: 7.258821e-06
test_loss: 7.3365595e-06
train_loss: 6.5497934e-06
test_loss: 6.8738377e-06
train_loss: 6.0138896e-06
test_loss: 6.4284395e-06
train_loss: 6.183449e-06
test_loss: 6.130449e-06
train_loss: 5.5171413e-06
test_loss: 5.854846e-06
train_loss: 5.3453646e-06
test_loss: 5.464832e-06
train_loss: 5.033834e-06
test_loss: 5.259502e-06
train_loss: 4.8060174e-06
test_loss: 4.9420023e-06
train_loss: 4.472705e-06
test_loss: 4.7872218e-06
train_loss: 4.3582877e-06
test_loss: 4.702769e-06
train_loss: 4.065923e-06
test_loss: 4.5327624e-06
train_loss: 4.176958e-06
test_loss: 4.3365344e-06
train_loss: 3.6996732e-06
test_loss: 4.248774e-06
train_loss: 3.710264e-06
test_loss: 4.111176e-06
train_loss: 3.821283e-06
test_loss: 3.982779e-06
train_loss: 3.4439668e-06
test_loss: 3.921809e-06
train_loss: 3.4222069e-06
test_loss: 3.817846e-06
train_loss: 3.2881085e-06
test_loss: 3.864025e-06
train_loss: 3.3388887e-06
test_loss: 3.8264266e-06
train_loss: 2.9712628e-06
test_loss: 3.690266e-06
train_loss: 3.2567893e-06
test_loss: 3.6599556e-06
train_loss: 3.271646e-06
test_loss: 3.617764e-06
train_loss: 3.0405304e-06
test_loss: 3.6820609e-06
train_loss: 2.920092e-06
test_loss: 3.5291898e-06
train_loss: 3.146189e-06
test_loss: 3.5252917e-06
train_loss: 2.769925e-06
test_loss: 3.4743111e-06
train_loss: 2.811086e-06
test_loss: 3.4784757e-06
train_loss: 3.0950046e-06
test_loss: 3.433531e-06
train_loss: 2.8296004e-06
test_loss: 3.406043e-06
train_loss: 2.8135723e-06
test_loss: 3.412566e-06
train_loss: 2.818058e-06
test_loss: 3.3783638e-06
train_loss: 2.9947e-06
test_loss: 3.3701945e-06
train_loss: 2.7232013e-06
test_loss: 3.3312108e-06
train_loss: 2.7572485e-06
test_loss: 3.3240676e-06
train_loss: 2.6793714e-06
test_loss: 3.3075078e-06
train_loss: 2.826842e-06
test_loss: 3.3200638e-06
train_loss: 2.6374926e-06
test_loss: 3.3051422e-06
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c46f0c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c46fa620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c46f0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c4603f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c45fd268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c45fdd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c460cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c460c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c45b1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c452f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32c45b1ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b86be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b86b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b86ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b7e8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b78ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b80d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b7e88c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b80d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32746b3a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32746b3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b75dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f329b75d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32745f21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32745e1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32745ac840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32745ac8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32745ac400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32745ac158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32745139d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3274553ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f327460e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f327460e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f327460e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f327446f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f32743b8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.68967074e-06
Iter: 2 loss: 2.66432335e-06
Iter: 3 loss: 2.91031029e-06
Iter: 4 loss: 2.66342545e-06
Iter: 5 loss: 2.65535459e-06
Iter: 6 loss: 2.65537074e-06
Iter: 7 loss: 2.65075846e-06
Iter: 8 loss: 2.65459425e-06
Iter: 9 loss: 2.64799519e-06
Iter: 10 loss: 2.64382106e-06
Iter: 11 loss: 2.65268181e-06
Iter: 12 loss: 2.64220444e-06
Iter: 13 loss: 2.63616175e-06
Iter: 14 loss: 2.64476921e-06
Iter: 15 loss: 2.63316224e-06
Iter: 16 loss: 2.62993922e-06
Iter: 17 loss: 2.62229401e-06
Iter: 18 loss: 2.71106501e-06
Iter: 19 loss: 2.62161393e-06
Iter: 20 loss: 2.616031e-06
Iter: 21 loss: 2.61479499e-06
Iter: 22 loss: 2.61125024e-06
Iter: 23 loss: 2.60341358e-06
Iter: 24 loss: 2.71852355e-06
Iter: 25 loss: 2.60308207e-06
Iter: 26 loss: 2.59929607e-06
Iter: 27 loss: 2.6493517e-06
Iter: 28 loss: 2.5992897e-06
Iter: 29 loss: 2.59605486e-06
Iter: 30 loss: 2.62684262e-06
Iter: 31 loss: 2.59595436e-06
Iter: 32 loss: 2.59431567e-06
Iter: 33 loss: 2.58950104e-06
Iter: 34 loss: 2.6110356e-06
Iter: 35 loss: 2.58771956e-06
Iter: 36 loss: 2.58060618e-06
Iter: 37 loss: 2.58941964e-06
Iter: 38 loss: 2.57690181e-06
Iter: 39 loss: 2.56791645e-06
Iter: 40 loss: 2.59456169e-06
Iter: 41 loss: 2.56516523e-06
Iter: 42 loss: 2.56489466e-06
Iter: 43 loss: 2.56257e-06
Iter: 44 loss: 2.56049043e-06
Iter: 45 loss: 2.5777897e-06
Iter: 46 loss: 2.56037265e-06
Iter: 47 loss: 2.55939358e-06
Iter: 48 loss: 2.55889449e-06
Iter: 49 loss: 2.55843224e-06
Iter: 50 loss: 2.55622172e-06
Iter: 51 loss: 2.5566269e-06
Iter: 52 loss: 2.55456143e-06
Iter: 53 loss: 2.55135251e-06
Iter: 54 loss: 2.56027397e-06
Iter: 55 loss: 2.55030182e-06
Iter: 56 loss: 2.54816541e-06
Iter: 57 loss: 2.54614883e-06
Iter: 58 loss: 2.54561792e-06
Iter: 59 loss: 2.54318729e-06
Iter: 60 loss: 2.54292877e-06
Iter: 61 loss: 2.54173347e-06
Iter: 62 loss: 2.53895905e-06
Iter: 63 loss: 2.57120882e-06
Iter: 64 loss: 2.53870621e-06
Iter: 65 loss: 2.53747066e-06
Iter: 66 loss: 2.53738085e-06
Iter: 67 loss: 2.53597455e-06
Iter: 68 loss: 2.53906273e-06
Iter: 69 loss: 2.5354293e-06
Iter: 70 loss: 2.53431608e-06
Iter: 71 loss: 2.53102462e-06
Iter: 72 loss: 2.54322913e-06
Iter: 73 loss: 2.52962604e-06
Iter: 74 loss: 2.52671225e-06
Iter: 75 loss: 2.56139788e-06
Iter: 76 loss: 2.52668883e-06
Iter: 77 loss: 2.52440327e-06
Iter: 78 loss: 2.53302142e-06
Iter: 79 loss: 2.52385553e-06
Iter: 80 loss: 2.52235395e-06
Iter: 81 loss: 2.52273298e-06
Iter: 82 loss: 2.52127506e-06
Iter: 83 loss: 2.51988104e-06
Iter: 84 loss: 2.51967322e-06
Iter: 85 loss: 2.5184811e-06
Iter: 86 loss: 2.5177028e-06
Iter: 87 loss: 2.51727215e-06
Iter: 88 loss: 2.51548022e-06
Iter: 89 loss: 2.52246423e-06
Iter: 90 loss: 2.515083e-06
Iter: 91 loss: 2.51433721e-06
Iter: 92 loss: 2.51426718e-06
Iter: 93 loss: 2.51371853e-06
Iter: 94 loss: 2.51262213e-06
Iter: 95 loss: 2.53422468e-06
Iter: 96 loss: 2.5126069e-06
Iter: 97 loss: 2.51186134e-06
Iter: 98 loss: 2.51187703e-06
Iter: 99 loss: 2.51106303e-06
Iter: 100 loss: 2.50920357e-06
Iter: 101 loss: 2.53492067e-06
Iter: 102 loss: 2.50910125e-06
Iter: 103 loss: 2.50777157e-06
Iter: 104 loss: 2.50911194e-06
Iter: 105 loss: 2.50703715e-06
Iter: 106 loss: 2.50547419e-06
Iter: 107 loss: 2.50547964e-06
Iter: 108 loss: 2.50470725e-06
Iter: 109 loss: 2.50357311e-06
Iter: 110 loss: 2.50352878e-06
Iter: 111 loss: 2.50260473e-06
Iter: 112 loss: 2.50161247e-06
Iter: 113 loss: 2.50142e-06
Iter: 114 loss: 2.4996059e-06
Iter: 115 loss: 2.5029708e-06
Iter: 116 loss: 2.49879622e-06
Iter: 117 loss: 2.49693267e-06
Iter: 118 loss: 2.51198685e-06
Iter: 119 loss: 2.49682671e-06
Iter: 120 loss: 2.49587038e-06
Iter: 121 loss: 2.4996848e-06
Iter: 122 loss: 2.49563163e-06
Iter: 123 loss: 2.49467303e-06
Iter: 124 loss: 2.51001347e-06
Iter: 125 loss: 2.4946637e-06
Iter: 126 loss: 2.49427103e-06
Iter: 127 loss: 2.49464188e-06
Iter: 128 loss: 2.49402e-06
Iter: 129 loss: 2.49346749e-06
Iter: 130 loss: 2.49337381e-06
Iter: 131 loss: 2.4929941e-06
Iter: 132 loss: 2.49183222e-06
Iter: 133 loss: 2.49599771e-06
Iter: 134 loss: 2.49150889e-06
Iter: 135 loss: 2.49076879e-06
Iter: 136 loss: 2.48938318e-06
Iter: 137 loss: 2.52057407e-06
Iter: 138 loss: 2.48940364e-06
Iter: 139 loss: 2.48911965e-06
Iter: 140 loss: 2.48859806e-06
Iter: 141 loss: 2.48827018e-06
Iter: 142 loss: 2.48756623e-06
Iter: 143 loss: 2.4991698e-06
Iter: 144 loss: 2.48754895e-06
Iter: 145 loss: 2.48693232e-06
Iter: 146 loss: 2.48726928e-06
Iter: 147 loss: 2.48650576e-06
Iter: 148 loss: 2.48564925e-06
Iter: 149 loss: 2.49905e-06
Iter: 150 loss: 2.48564947e-06
Iter: 151 loss: 2.48531114e-06
Iter: 152 loss: 2.48427705e-06
Iter: 153 loss: 2.48850392e-06
Iter: 154 loss: 2.48390052e-06
Iter: 155 loss: 2.4823662e-06
Iter: 156 loss: 2.48761717e-06
Iter: 157 loss: 2.48195056e-06
Iter: 158 loss: 2.4823994e-06
Iter: 159 loss: 2.48160563e-06
Iter: 160 loss: 2.48125116e-06
Iter: 161 loss: 2.48107017e-06
Iter: 162 loss: 2.48093602e-06
Iter: 163 loss: 2.48057404e-06
Iter: 164 loss: 2.48252036e-06
Iter: 165 loss: 2.48049764e-06
Iter: 166 loss: 2.48005949e-06
Iter: 167 loss: 2.48049059e-06
Iter: 168 loss: 2.47982734e-06
Iter: 169 loss: 2.47922617e-06
Iter: 170 loss: 2.48009314e-06
Iter: 171 loss: 2.47892467e-06
Iter: 172 loss: 2.4785038e-06
Iter: 173 loss: 2.47885873e-06
Iter: 174 loss: 2.47821254e-06
Iter: 175 loss: 2.47747926e-06
Iter: 176 loss: 2.48094e-06
Iter: 177 loss: 2.47730463e-06
Iter: 178 loss: 2.47702337e-06
Iter: 179 loss: 2.47628873e-06
Iter: 180 loss: 2.48766537e-06
Iter: 181 loss: 2.4762785e-06
Iter: 182 loss: 2.47619596e-06
Iter: 183 loss: 2.47603384e-06
Iter: 184 loss: 2.47572825e-06
Iter: 185 loss: 2.47543903e-06
Iter: 186 loss: 2.47537105e-06
Iter: 187 loss: 2.4748656e-06
Iter: 188 loss: 2.47359e-06
Iter: 189 loss: 2.48374408e-06
Iter: 190 loss: 2.4733647e-06
Iter: 191 loss: 2.47237358e-06
Iter: 192 loss: 2.47236744e-06
Iter: 193 loss: 2.47219077e-06
Iter: 194 loss: 2.47201115e-06
Iter: 195 loss: 2.47177513e-06
Iter: 196 loss: 2.47132766e-06
Iter: 197 loss: 2.48105562e-06
Iter: 198 loss: 2.47132721e-06
Iter: 199 loss: 2.4710489e-06
Iter: 200 loss: 2.4710057e-06
Iter: 201 loss: 2.4708138e-06
Iter: 202 loss: 2.47052049e-06
Iter: 203 loss: 2.47050548e-06
Iter: 204 loss: 2.47006028e-06
Iter: 205 loss: 2.47048183e-06
Iter: 206 loss: 2.46975605e-06
Iter: 207 loss: 2.46934678e-06
Iter: 208 loss: 2.47501839e-06
Iter: 209 loss: 2.46935269e-06
Iter: 210 loss: 2.46892932e-06
Iter: 211 loss: 2.46810987e-06
Iter: 212 loss: 2.48335414e-06
Iter: 213 loss: 2.46805644e-06
Iter: 214 loss: 2.46753598e-06
Iter: 215 loss: 2.46955233e-06
Iter: 216 loss: 2.46743639e-06
Iter: 217 loss: 2.46724403e-06
Iter: 218 loss: 2.46717e-06
Iter: 219 loss: 2.46693253e-06
Iter: 220 loss: 2.46624904e-06
Iter: 221 loss: 2.46987565e-06
Iter: 222 loss: 2.46609807e-06
Iter: 223 loss: 2.4653923e-06
Iter: 224 loss: 2.46616037e-06
Iter: 225 loss: 2.46502918e-06
Iter: 226 loss: 2.46434229e-06
Iter: 227 loss: 2.47207709e-06
Iter: 228 loss: 2.46431591e-06
Iter: 229 loss: 2.4637045e-06
Iter: 230 loss: 2.4695737e-06
Iter: 231 loss: 2.46366835e-06
Iter: 232 loss: 2.46351601e-06
Iter: 233 loss: 2.46385707e-06
Iter: 234 loss: 2.46345462e-06
Iter: 235 loss: 2.46316813e-06
Iter: 236 loss: 2.46325021e-06
Iter: 237 loss: 2.46294962e-06
Iter: 238 loss: 2.46268769e-06
Iter: 239 loss: 2.46293484e-06
Iter: 240 loss: 2.46253171e-06
Iter: 241 loss: 2.46213e-06
Iter: 242 loss: 2.46261175e-06
Iter: 243 loss: 2.46187301e-06
Iter: 244 loss: 2.46135733e-06
Iter: 245 loss: 2.46492209e-06
Iter: 246 loss: 2.46130503e-06
Iter: 247 loss: 2.46104219e-06
Iter: 248 loss: 2.46056061e-06
Iter: 249 loss: 2.47166395e-06
Iter: 250 loss: 2.46055606e-06
Iter: 251 loss: 2.46013815e-06
Iter: 252 loss: 2.46377795e-06
Iter: 253 loss: 2.4601386e-06
Iter: 254 loss: 2.45972387e-06
Iter: 255 loss: 2.4624278e-06
Iter: 256 loss: 2.45968795e-06
Iter: 257 loss: 2.45953879e-06
Iter: 258 loss: 2.45910178e-06
Iter: 259 loss: 2.46035074e-06
Iter: 260 loss: 2.4588785e-06
Iter: 261 loss: 2.45812043e-06
Iter: 262 loss: 2.46067839e-06
Iter: 263 loss: 2.45787851e-06
Iter: 264 loss: 2.45796582e-06
Iter: 265 loss: 2.45759475e-06
Iter: 266 loss: 2.45737147e-06
Iter: 267 loss: 2.45699653e-06
Iter: 268 loss: 2.46563627e-06
Iter: 269 loss: 2.45697811e-06
Iter: 270 loss: 2.4568767e-06
Iter: 271 loss: 2.45676847e-06
Iter: 272 loss: 2.45666934e-06
Iter: 273 loss: 2.45635692e-06
Iter: 274 loss: 2.45800084e-06
Iter: 275 loss: 2.45622709e-06
Iter: 276 loss: 2.45587603e-06
Iter: 277 loss: 2.45588217e-06
Iter: 278 loss: 2.45569663e-06
Iter: 279 loss: 2.45546039e-06
Iter: 280 loss: 2.45542606e-06
Iter: 281 loss: 2.45496039e-06
Iter: 282 loss: 2.45645379e-06
Iter: 283 loss: 2.4548342e-06
Iter: 284 loss: 2.45444289e-06
Iter: 285 loss: 2.45486763e-06
Iter: 286 loss: 2.45422052e-06
Iter: 287 loss: 2.45428578e-06
Iter: 288 loss: 2.45408273e-06
Iter: 289 loss: 2.45394858e-06
Iter: 290 loss: 2.45367914e-06
Iter: 291 loss: 2.45735373e-06
Iter: 292 loss: 2.45364117e-06
Iter: 293 loss: 2.45340107e-06
Iter: 294 loss: 2.45329966e-06
Iter: 295 loss: 2.45316824e-06
Iter: 296 loss: 2.45298475e-06
Iter: 297 loss: 2.45267256e-06
Iter: 298 loss: 2.45265801e-06
Iter: 299 loss: 2.45220326e-06
Iter: 300 loss: 2.4518049e-06
Iter: 301 loss: 2.45168758e-06
Iter: 302 loss: 2.45178262e-06
Iter: 303 loss: 2.45135834e-06
Iter: 304 loss: 2.45123397e-06
Iter: 305 loss: 2.45083356e-06
Iter: 306 loss: 2.45343676e-06
Iter: 307 loss: 2.45070714e-06
Iter: 308 loss: 2.45059755e-06
Iter: 309 loss: 2.45052843e-06
Iter: 310 loss: 2.45036131e-06
Iter: 311 loss: 2.45023057e-06
Iter: 312 loss: 2.45019419e-06
Iter: 313 loss: 2.44994089e-06
Iter: 314 loss: 2.45076149e-06
Iter: 315 loss: 2.44986904e-06
Iter: 316 loss: 2.44954458e-06
Iter: 317 loss: 2.45001502e-06
Iter: 318 loss: 2.44935836e-06
Iter: 319 loss: 2.44909597e-06
Iter: 320 loss: 2.44947796e-06
Iter: 321 loss: 2.44898456e-06
Iter: 322 loss: 2.44853163e-06
Iter: 323 loss: 2.45038359e-06
Iter: 324 loss: 2.44842113e-06
Iter: 325 loss: 2.44824423e-06
Iter: 326 loss: 2.44986813e-06
Iter: 327 loss: 2.44822309e-06
Iter: 328 loss: 2.44805688e-06
Iter: 329 loss: 2.44817e-06
Iter: 330 loss: 2.44794978e-06
Iter: 331 loss: 2.44777266e-06
Iter: 332 loss: 2.44745343e-06
Iter: 333 loss: 2.45526962e-06
Iter: 334 loss: 2.44743978e-06
Iter: 335 loss: 2.44712373e-06
Iter: 336 loss: 2.45132833e-06
Iter: 337 loss: 2.44712419e-06
Iter: 338 loss: 2.44679745e-06
Iter: 339 loss: 2.44783519e-06
Iter: 340 loss: 2.44669309e-06
Iter: 341 loss: 2.44649164e-06
Iter: 342 loss: 2.4463202e-06
Iter: 343 loss: 2.44629086e-06
Iter: 344 loss: 2.44610897e-06
Iter: 345 loss: 2.44609646e-06
Iter: 346 loss: 2.44597913e-06
Iter: 347 loss: 2.4457504e-06
Iter: 348 loss: 2.44871626e-06
Iter: 349 loss: 2.44572152e-06
Iter: 350 loss: 2.44551893e-06
Iter: 351 loss: 2.44551165e-06
Iter: 352 loss: 2.44534385e-06
Iter: 353 loss: 2.44493572e-06
Iter: 354 loss: 2.44994226e-06
Iter: 355 loss: 2.44492367e-06
Iter: 356 loss: 2.44451348e-06
Iter: 357 loss: 2.44451985e-06
Iter: 358 loss: 2.44429293e-06
Iter: 359 loss: 2.44422608e-06
Iter: 360 loss: 2.44405533e-06
Iter: 361 loss: 2.4438948e-06
Iter: 362 loss: 2.44386865e-06
Iter: 363 loss: 2.44379225e-06
Iter: 364 loss: 2.44375224e-06
Iter: 365 loss: 2.44369153e-06
Iter: 366 loss: 2.44354601e-06
Iter: 367 loss: 2.44347439e-06
Iter: 368 loss: 2.44342618e-06
Iter: 369 loss: 2.44324519e-06
Iter: 370 loss: 2.4429969e-06
Iter: 371 loss: 2.44298622e-06
Iter: 372 loss: 2.44266903e-06
Iter: 373 loss: 2.44488228e-06
Iter: 374 loss: 2.44262083e-06
Iter: 375 loss: 2.44237481e-06
Iter: 376 loss: 2.44356488e-06
Iter: 377 loss: 2.44233752e-06
Iter: 378 loss: 2.44203261e-06
Iter: 379 loss: 2.44192415e-06
Iter: 380 loss: 2.44177954e-06
Iter: 381 loss: 2.44154626e-06
Iter: 382 loss: 2.44442526e-06
Iter: 383 loss: 2.44156467e-06
Iter: 384 loss: 2.44137141e-06
Iter: 385 loss: 2.44355738e-06
Iter: 386 loss: 2.44134526e-06
Iter: 387 loss: 2.44124385e-06
Iter: 388 loss: 2.4411047e-06
Iter: 389 loss: 2.44110061e-06
Iter: 390 loss: 2.44085e-06
Iter: 391 loss: 2.44199327e-06
Iter: 392 loss: 2.44081e-06
Iter: 393 loss: 2.440657e-06
Iter: 394 loss: 2.44241642e-06
Iter: 395 loss: 2.44064677e-06
Iter: 396 loss: 2.44052e-06
Iter: 397 loss: 2.4402143e-06
Iter: 398 loss: 2.44364787e-06
Iter: 399 loss: 2.44017428e-06
Iter: 400 loss: 2.44007038e-06
Iter: 401 loss: 2.44003195e-06
Iter: 402 loss: 2.43987415e-06
Iter: 403 loss: 2.43996192e-06
Iter: 404 loss: 2.43978866e-06
Iter: 405 loss: 2.43971908e-06
Iter: 406 loss: 2.440049e-06
Iter: 407 loss: 2.43968611e-06
Iter: 408 loss: 2.43957015e-06
Iter: 409 loss: 2.4396254e-06
Iter: 410 loss: 2.4395008e-06
Iter: 411 loss: 2.43933277e-06
Iter: 412 loss: 2.4390697e-06
Iter: 413 loss: 2.43907516e-06
Iter: 414 loss: 2.43877184e-06
Iter: 415 loss: 2.43891e-06
Iter: 416 loss: 2.43857949e-06
Iter: 417 loss: 2.43868703e-06
Iter: 418 loss: 2.43840168e-06
Iter: 419 loss: 2.43825662e-06
Iter: 420 loss: 2.43815475e-06
Iter: 421 loss: 2.43812292e-06
Iter: 422 loss: 2.43798831e-06
Iter: 423 loss: 2.4390506e-06
Iter: 424 loss: 2.43796353e-06
Iter: 425 loss: 2.43780642e-06
Iter: 426 loss: 2.43795353e-06
Iter: 427 loss: 2.43771774e-06
Iter: 428 loss: 2.43753198e-06
Iter: 429 loss: 2.43787463e-06
Iter: 430 loss: 2.43743443e-06
Iter: 431 loss: 2.43728664e-06
Iter: 432 loss: 2.43724412e-06
Iter: 433 loss: 2.43713293e-06
Iter: 434 loss: 2.4369424e-06
Iter: 435 loss: 2.43696e-06
Iter: 436 loss: 2.43685167e-06
Iter: 437 loss: 2.43662907e-06
Iter: 438 loss: 2.44003263e-06
Iter: 439 loss: 2.43663112e-06
Iter: 440 loss: 2.43659133e-06
Iter: 441 loss: 2.43651948e-06
Iter: 442 loss: 2.43645309e-06
Iter: 443 loss: 2.43631757e-06
Iter: 444 loss: 2.43810018e-06
Iter: 445 loss: 2.43630871e-06
Iter: 446 loss: 2.43609315e-06
Iter: 447 loss: 2.43599516e-06
Iter: 448 loss: 2.43592604e-06
Iter: 449 loss: 2.43570048e-06
Iter: 450 loss: 2.43568775e-06
Iter: 451 loss: 2.43540944e-06
Iter: 452 loss: 2.43562408e-06
Iter: 453 loss: 2.4352471e-06
Iter: 454 loss: 2.43508589e-06
Iter: 455 loss: 2.43541149e-06
Iter: 456 loss: 2.43498562e-06
Iter: 457 loss: 2.43474619e-06
Iter: 458 loss: 2.43609475e-06
Iter: 459 loss: 2.43471641e-06
Iter: 460 loss: 2.43455611e-06
Iter: 461 loss: 2.43531258e-06
Iter: 462 loss: 2.43452541e-06
Iter: 463 loss: 2.43444151e-06
Iter: 464 loss: 2.43430418e-06
Iter: 465 loss: 2.43429986e-06
Iter: 466 loss: 2.43414411e-06
Iter: 467 loss: 2.43415457e-06
Iter: 468 loss: 2.43398972e-06
Iter: 469 loss: 2.43359091e-06
Iter: 470 loss: 2.43717614e-06
Iter: 471 loss: 2.43355407e-06
Iter: 472 loss: 2.43353838e-06
Iter: 473 loss: 2.43340651e-06
Iter: 474 loss: 2.43328122e-06
Iter: 475 loss: 2.43300406e-06
Iter: 476 loss: 2.43747809e-06
Iter: 477 loss: 2.43297472e-06
Iter: 478 loss: 2.43270961e-06
Iter: 479 loss: 2.43322211e-06
Iter: 480 loss: 2.43259137e-06
Iter: 481 loss: 2.43242607e-06
Iter: 482 loss: 2.43289378e-06
Iter: 483 loss: 2.43237082e-06
Iter: 484 loss: 2.43224076e-06
Iter: 485 loss: 2.43225395e-06
Iter: 486 loss: 2.43213981e-06
Iter: 487 loss: 2.4318997e-06
Iter: 488 loss: 2.43448858e-06
Iter: 489 loss: 2.43188651e-06
Iter: 490 loss: 2.4316721e-06
Iter: 491 loss: 2.43167096e-06
Iter: 492 loss: 2.43149179e-06
Iter: 493 loss: 2.4315043e-06
Iter: 494 loss: 2.43138174e-06
Iter: 495 loss: 2.43113482e-06
Iter: 496 loss: 2.43209161e-06
Iter: 497 loss: 2.43108752e-06
Iter: 498 loss: 2.43094428e-06
Iter: 499 loss: 2.4311405e-06
Iter: 500 loss: 2.43088334e-06
Iter: 501 loss: 2.43069121e-06
Iter: 502 loss: 2.43180739e-06
Iter: 503 loss: 2.43067711e-06
Iter: 504 loss: 2.430623e-06
Iter: 505 loss: 2.4305441e-06
Iter: 506 loss: 2.43052909e-06
Iter: 507 loss: 2.43035e-06
Iter: 508 loss: 2.43097702e-06
Iter: 509 loss: 2.43029967e-06
Iter: 510 loss: 2.43010822e-06
Iter: 511 loss: 2.42967326e-06
Iter: 512 loss: 2.43291788e-06
Iter: 513 loss: 2.42956503e-06
Iter: 514 loss: 2.42915894e-06
Iter: 515 loss: 2.43263594e-06
Iter: 516 loss: 2.42914666e-06
Iter: 517 loss: 2.42937313e-06
Iter: 518 loss: 2.42900956e-06
Iter: 519 loss: 2.42893611e-06
Iter: 520 loss: 2.42869737e-06
Iter: 521 loss: 2.43129671e-06
Iter: 522 loss: 2.42868509e-06
Iter: 523 loss: 2.42851365e-06
Iter: 524 loss: 2.42962756e-06
Iter: 525 loss: 2.42848569e-06
Iter: 526 loss: 2.42828037e-06
Iter: 527 loss: 2.42907618e-06
Iter: 528 loss: 2.42824149e-06
Iter: 529 loss: 2.42808596e-06
Iter: 530 loss: 2.42828719e-06
Iter: 531 loss: 2.42801912e-06
Iter: 532 loss: 2.42777378e-06
Iter: 533 loss: 2.42747888e-06
Iter: 534 loss: 2.42747547e-06
Iter: 535 loss: 2.42733358e-06
Iter: 536 loss: 2.42726355e-06
Iter: 537 loss: 2.42709984e-06
Iter: 538 loss: 2.42690885e-06
Iter: 539 loss: 2.42689566e-06
Iter: 540 loss: 2.42678925e-06
Iter: 541 loss: 2.4267913e-06
Iter: 542 loss: 2.42671558e-06
Iter: 543 loss: 2.42655619e-06
Iter: 544 loss: 2.42824035e-06
Iter: 545 loss: 2.42655096e-06
Iter: 546 loss: 2.42635269e-06
Iter: 547 loss: 2.42624355e-06
Iter: 548 loss: 2.42619944e-06
Iter: 549 loss: 2.42599708e-06
Iter: 550 loss: 2.4275414e-06
Iter: 551 loss: 2.42599504e-06
Iter: 552 loss: 2.42586657e-06
Iter: 553 loss: 2.42552187e-06
Iter: 554 loss: 2.43023169e-06
Iter: 555 loss: 2.42549982e-06
Iter: 556 loss: 2.42508099e-06
Iter: 557 loss: 2.42622764e-06
Iter: 558 loss: 2.42494616e-06
Iter: 559 loss: 2.4249407e-06
Iter: 560 loss: 2.42484293e-06
Iter: 561 loss: 2.42474562e-06
Iter: 562 loss: 2.42469696e-06
Iter: 563 loss: 2.4246724e-06
Iter: 564 loss: 2.42453825e-06
Iter: 565 loss: 2.42524038e-06
Iter: 566 loss: 2.42453189e-06
Iter: 567 loss: 2.42440683e-06
Iter: 568 loss: 2.4242795e-06
Iter: 569 loss: 2.42425313e-06
Iter: 570 loss: 2.4240353e-06
Iter: 571 loss: 2.42578722e-06
Iter: 572 loss: 2.42400347e-06
Iter: 573 loss: 2.4238484e-06
Iter: 574 loss: 2.42402439e-06
Iter: 575 loss: 2.42374813e-06
Iter: 576 loss: 2.42352598e-06
Iter: 577 loss: 2.42357805e-06
Iter: 578 loss: 2.42336182e-06
Iter: 579 loss: 2.42309829e-06
Iter: 580 loss: 2.42304304e-06
Iter: 581 loss: 2.42288274e-06
Iter: 582 loss: 2.42284295e-06
Iter: 583 loss: 2.42275109e-06
Iter: 584 loss: 2.42264787e-06
Iter: 585 loss: 2.4224878e-06
Iter: 586 loss: 2.42536316e-06
Iter: 587 loss: 2.42251417e-06
Iter: 588 loss: 2.42223905e-06
Iter: 589 loss: 2.42212172e-06
Iter: 590 loss: 2.42201759e-06
Iter: 591 loss: 2.42185843e-06
Iter: 592 loss: 2.42184592e-06
Iter: 593 loss: 2.42165902e-06
Iter: 594 loss: 2.42195574e-06
Iter: 595 loss: 2.42156602e-06
Iter: 596 loss: 2.42137048e-06
Iter: 597 loss: 2.4218898e-06
Iter: 598 loss: 2.42134433e-06
Iter: 599 loss: 2.4211613e-06
Iter: 600 loss: 2.42171132e-06
Iter: 601 loss: 2.42112606e-06
Iter: 602 loss: 2.42104124e-06
Iter: 603 loss: 2.42236774e-06
Iter: 604 loss: 2.42102851e-06
Iter: 605 loss: 2.42096667e-06
Iter: 606 loss: 2.42081069e-06
Iter: 607 loss: 2.42079932e-06
Iter: 608 loss: 2.42059332e-06
Iter: 609 loss: 2.42190572e-06
Iter: 610 loss: 2.4206056e-06
Iter: 611 loss: 2.4204619e-06
Iter: 612 loss: 2.42013857e-06
Iter: 613 loss: 2.42325086e-06
Iter: 614 loss: 2.42011174e-06
Iter: 615 loss: 2.42002329e-06
Iter: 616 loss: 2.41991756e-06
Iter: 617 loss: 2.41978319e-06
Iter: 618 loss: 2.41959242e-06
Iter: 619 loss: 2.41957378e-06
Iter: 620 loss: 2.41935095e-06
Iter: 621 loss: 2.41936914e-06
Iter: 622 loss: 2.4192077e-06
Iter: 623 loss: 2.41897806e-06
Iter: 624 loss: 2.41938233e-06
Iter: 625 loss: 2.41887687e-06
Iter: 626 loss: 2.41873772e-06
Iter: 627 loss: 2.41872044e-06
Iter: 628 loss: 2.41857606e-06
Iter: 629 loss: 2.41830139e-06
Iter: 630 loss: 2.42256624e-06
Iter: 631 loss: 2.4182882e-06
Iter: 632 loss: 2.41796829e-06
Iter: 633 loss: 2.42193391e-06
Iter: 634 loss: 2.41795533e-06
Iter: 635 loss: 2.41773023e-06
Iter: 636 loss: 2.41808402e-06
Iter: 637 loss: 2.41762109e-06
Iter: 638 loss: 2.41740281e-06
Iter: 639 loss: 2.41901716e-06
Iter: 640 loss: 2.41738371e-06
Iter: 641 loss: 2.41728912e-06
Iter: 642 loss: 2.41773159e-06
Iter: 643 loss: 2.41725047e-06
Iter: 644 loss: 2.41713497e-06
Iter: 645 loss: 2.41689622e-06
Iter: 646 loss: 2.4214487e-06
Iter: 647 loss: 2.41684461e-06
Iter: 648 loss: 2.4166593e-06
Iter: 649 loss: 2.41705766e-06
Iter: 650 loss: 2.41656471e-06
Iter: 651 loss: 2.41635234e-06
Iter: 652 loss: 2.41973157e-06
Iter: 653 loss: 2.41634461e-06
Iter: 654 loss: 2.41621501e-06
Iter: 655 loss: 2.41581483e-06
Iter: 656 loss: 2.41951466e-06
Iter: 657 loss: 2.41577595e-06
Iter: 658 loss: 2.41542193e-06
Iter: 659 loss: 2.41656448e-06
Iter: 660 loss: 2.41534417e-06
Iter: 661 loss: 2.41513294e-06
Iter: 662 loss: 2.41703947e-06
Iter: 663 loss: 2.41511839e-06
Iter: 664 loss: 2.41493944e-06
Iter: 665 loss: 2.41493535e-06
Iter: 666 loss: 2.41480984e-06
Iter: 667 loss: 2.41458702e-06
Iter: 668 loss: 2.41822272e-06
Iter: 669 loss: 2.41458702e-06
Iter: 670 loss: 2.41427642e-06
Iter: 671 loss: 2.41718089e-06
Iter: 672 loss: 2.41424846e-06
Iter: 673 loss: 2.41406133e-06
Iter: 674 loss: 2.41465432e-06
Iter: 675 loss: 2.41400153e-06
Iter: 676 loss: 2.41376074e-06
Iter: 677 loss: 2.41400926e-06
Iter: 678 loss: 2.4136325e-06
Iter: 679 loss: 2.41338012e-06
Iter: 680 loss: 2.41610405e-06
Iter: 681 loss: 2.41338057e-06
Iter: 682 loss: 2.41329326e-06
Iter: 683 loss: 2.41309681e-06
Iter: 684 loss: 2.41529278e-06
Iter: 685 loss: 2.4130693e-06
Iter: 686 loss: 2.41285738e-06
Iter: 687 loss: 2.41425687e-06
Iter: 688 loss: 2.41286807e-06
Iter: 689 loss: 2.41264797e-06
Iter: 690 loss: 2.41411635e-06
Iter: 691 loss: 2.41261296e-06
Iter: 692 loss: 2.41252474e-06
Iter: 693 loss: 2.41216958e-06
Iter: 694 loss: 2.41293401e-06
Iter: 695 loss: 2.41201633e-06
Iter: 696 loss: 2.41160819e-06
Iter: 697 loss: 2.41570024e-06
Iter: 698 loss: 2.41158659e-06
Iter: 699 loss: 2.41136422e-06
Iter: 700 loss: 2.41216389e-06
Iter: 701 loss: 2.41131056e-06
Iter: 702 loss: 2.41121415e-06
Iter: 703 loss: 2.41117368e-06
Iter: 704 loss: 2.41109888e-06
Iter: 705 loss: 2.4108806e-06
Iter: 706 loss: 2.41260204e-06
Iter: 707 loss: 2.41085263e-06
Iter: 708 loss: 2.4105575e-06
Iter: 709 loss: 2.41237194e-06
Iter: 710 loss: 2.41049838e-06
Iter: 711 loss: 2.41025737e-06
Iter: 712 loss: 2.41091493e-06
Iter: 713 loss: 2.41016255e-06
Iter: 714 loss: 2.41004727e-06
Iter: 715 loss: 2.41003636e-06
Iter: 716 loss: 2.4099304e-06
Iter: 717 loss: 2.40976601e-06
Iter: 718 loss: 2.41354564e-06
Iter: 719 loss: 2.40980921e-06
Iter: 720 loss: 2.409638e-06
Iter: 721 loss: 2.41126486e-06
Iter: 722 loss: 2.40964391e-06
Iter: 723 loss: 2.40949385e-06
Iter: 724 loss: 2.4095043e-06
Iter: 725 loss: 2.40935015e-06
Iter: 726 loss: 2.40924828e-06
Iter: 727 loss: 2.40905956e-06
Iter: 728 loss: 2.40904956e-06
Iter: 729 loss: 2.4089818e-06
Iter: 730 loss: 2.40890722e-06
Iter: 731 loss: 2.40886811e-06
Iter: 732 loss: 2.40873896e-06
Iter: 733 loss: 2.41025919e-06
Iter: 734 loss: 2.40869622e-06
Iter: 735 loss: 2.40851864e-06
Iter: 736 loss: 2.40860618e-06
Iter: 737 loss: 2.40842655e-06
Iter: 738 loss: 2.40815802e-06
Iter: 739 loss: 2.40783856e-06
Iter: 740 loss: 2.4078372e-06
Iter: 741 loss: 2.40739791e-06
Iter: 742 loss: 2.41146017e-06
Iter: 743 loss: 2.40738655e-06
Iter: 744 loss: 2.40723693e-06
Iter: 745 loss: 2.40722102e-06
Iter: 746 loss: 2.40711961e-06
Iter: 747 loss: 2.40787313e-06
Iter: 748 loss: 2.40711779e-06
Iter: 749 loss: 2.40702047e-06
Iter: 750 loss: 2.40710938e-06
Iter: 751 loss: 2.40698637e-06
Iter: 752 loss: 2.4069177e-06
Iter: 753 loss: 2.40683949e-06
Iter: 754 loss: 2.40681948e-06
Iter: 755 loss: 2.40666691e-06
Iter: 756 loss: 2.4083181e-06
Iter: 757 loss: 2.40663735e-06
Iter: 758 loss: 2.4065971e-06
Iter: 759 loss: 2.40646978e-06
Iter: 760 loss: 2.40936197e-06
Iter: 761 loss: 2.40646159e-06
Iter: 762 loss: 2.4062083e-06
Iter: 763 loss: 2.40743111e-06
Iter: 764 loss: 2.40614145e-06
Iter: 765 loss: 2.40603686e-06
Iter: 766 loss: 2.4059209e-06
Iter: 767 loss: 2.40588565e-06
Iter: 768 loss: 2.40584541e-06
Iter: 769 loss: 2.40582722e-06
Iter: 770 loss: 2.40574877e-06
Iter: 771 loss: 2.40558711e-06
Iter: 772 loss: 2.40619124e-06
Iter: 773 loss: 2.40553732e-06
Iter: 774 loss: 2.40534564e-06
Iter: 775 loss: 2.40522422e-06
Iter: 776 loss: 2.40512918e-06
Iter: 777 loss: 2.40485724e-06
Iter: 778 loss: 2.40496638e-06
Iter: 779 loss: 2.40468216e-06
Iter: 780 loss: 2.40435384e-06
Iter: 781 loss: 2.4054134e-06
Iter: 782 loss: 2.4042165e-06
Iter: 783 loss: 2.40410736e-06
Iter: 784 loss: 2.40407e-06
Iter: 785 loss: 2.4039241e-06
Iter: 786 loss: 2.40429631e-06
Iter: 787 loss: 2.40385134e-06
Iter: 788 loss: 2.40369218e-06
Iter: 789 loss: 2.40383406e-06
Iter: 790 loss: 2.40359577e-06
Iter: 791 loss: 2.40338022e-06
Iter: 792 loss: 2.4038186e-06
Iter: 793 loss: 2.40332611e-06
Iter: 794 loss: 2.40304098e-06
Iter: 795 loss: 2.40425356e-06
Iter: 796 loss: 2.40297754e-06
Iter: 797 loss: 2.40288136e-06
Iter: 798 loss: 2.40326517e-06
Iter: 799 loss: 2.40281565e-06
Iter: 800 loss: 2.40268832e-06
Iter: 801 loss: 2.40254963e-06
Iter: 802 loss: 2.402478e-06
Iter: 803 loss: 2.40231498e-06
Iter: 804 loss: 2.40268355e-06
Iter: 805 loss: 2.40226723e-06
Iter: 806 loss: 2.40203258e-06
Iter: 807 loss: 2.40296026e-06
Iter: 808 loss: 2.40196141e-06
Iter: 809 loss: 2.40184181e-06
Iter: 810 loss: 2.4015028e-06
Iter: 811 loss: 2.40438794e-06
Iter: 812 loss: 2.40144163e-06
Iter: 813 loss: 2.40101144e-06
Iter: 814 loss: 2.40282202e-06
Iter: 815 loss: 2.40094414e-06
Iter: 816 loss: 2.40067652e-06
Iter: 817 loss: 2.40342706e-06
Iter: 818 loss: 2.40068e-06
Iter: 819 loss: 2.40056147e-06
Iter: 820 loss: 2.40054487e-06
Iter: 821 loss: 2.40042982e-06
Iter: 822 loss: 2.40037161e-06
Iter: 823 loss: 2.40030568e-06
Iter: 824 loss: 2.40016607e-06
Iter: 825 loss: 2.40094346e-06
Iter: 826 loss: 2.4001406e-06
Iter: 827 loss: 2.40001373e-06
Iter: 828 loss: 2.40012128e-06
Iter: 829 loss: 2.39989231e-06
Iter: 830 loss: 2.39970518e-06
Iter: 831 loss: 2.40023383e-06
Iter: 832 loss: 2.39962242e-06
Iter: 833 loss: 2.39948918e-06
Iter: 834 loss: 2.40046461e-06
Iter: 835 loss: 2.39944939e-06
Iter: 836 loss: 2.39929091e-06
Iter: 837 loss: 2.39895962e-06
Iter: 838 loss: 2.40647228e-06
Iter: 839 loss: 2.39896e-06
Iter: 840 loss: 2.39892847e-06
Iter: 841 loss: 2.39885185e-06
Iter: 842 loss: 2.39878136e-06
Iter: 843 loss: 2.39859628e-06
Iter: 844 loss: 2.40177906e-06
Iter: 845 loss: 2.39862766e-06
Iter: 846 loss: 2.39843735e-06
Iter: 847 loss: 2.39817132e-06
Iter: 848 loss: 2.39817928e-06
Iter: 849 loss: 2.39778024e-06
Iter: 850 loss: 2.39867836e-06
Iter: 851 loss: 2.39763949e-06
Iter: 852 loss: 2.39748806e-06
Iter: 853 loss: 2.39744872e-06
Iter: 854 loss: 2.39723022e-06
Iter: 855 loss: 2.39788051e-06
Iter: 856 loss: 2.39718929e-06
Iter: 857 loss: 2.39704787e-06
Iter: 858 loss: 2.39763858e-06
Iter: 859 loss: 2.39703263e-06
Iter: 860 loss: 2.39686779e-06
Iter: 861 loss: 2.39720066e-06
Iter: 862 loss: 2.39681617e-06
Iter: 863 loss: 2.39669635e-06
Iter: 864 loss: 2.39715632e-06
Iter: 865 loss: 2.3966611e-06
Iter: 866 loss: 2.39651558e-06
Iter: 867 loss: 2.39629071e-06
Iter: 868 loss: 2.39628389e-06
Iter: 869 loss: 2.39593714e-06
Iter: 870 loss: 2.39814062e-06
Iter: 871 loss: 2.39588599e-06
Iter: 872 loss: 2.39578594e-06
Iter: 873 loss: 2.39576866e-06
Iter: 874 loss: 2.39566407e-06
Iter: 875 loss: 2.39542669e-06
Iter: 876 loss: 2.39708902e-06
Iter: 877 loss: 2.39540941e-06
Iter: 878 loss: 2.39530686e-06
Iter: 879 loss: 2.39505289e-06
Iter: 880 loss: 2.39787732e-06
Iter: 881 loss: 2.39501333e-06
Iter: 882 loss: 2.39469728e-06
Iter: 883 loss: 2.3949076e-06
Iter: 884 loss: 2.39453107e-06
Iter: 885 loss: 2.3942107e-06
Iter: 886 loss: 2.39689393e-06
Iter: 887 loss: 2.39424e-06
Iter: 888 loss: 2.39403357e-06
Iter: 889 loss: 2.39401629e-06
Iter: 890 loss: 2.39392102e-06
Iter: 891 loss: 2.39387919e-06
Iter: 892 loss: 2.39379938e-06
Iter: 893 loss: 2.39364294e-06
Iter: 894 loss: 2.39535893e-06
Iter: 895 loss: 2.3936409e-06
Iter: 896 loss: 2.3935404e-06
Iter: 897 loss: 2.39363726e-06
Iter: 898 loss: 2.39347173e-06
Iter: 899 loss: 2.39331371e-06
Iter: 900 loss: 2.39330416e-06
Iter: 901 loss: 2.39319093e-06
Iter: 902 loss: 2.39301153e-06
Iter: 903 loss: 2.39496831e-06
Iter: 904 loss: 2.39300562e-06
Iter: 905 loss: 2.39286055e-06
Iter: 906 loss: 2.392635e-06
Iter: 907 loss: 2.39267047e-06
Iter: 908 loss: 2.39260839e-06
Iter: 909 loss: 2.39253927e-06
Iter: 910 loss: 2.39247402e-06
Iter: 911 loss: 2.39229553e-06
Iter: 912 loss: 2.39418227e-06
Iter: 913 loss: 2.39227393e-06
Iter: 914 loss: 2.39205701e-06
Iter: 915 loss: 2.39199335e-06
Iter: 916 loss: 2.39186693e-06
Iter: 917 loss: 2.39155293e-06
Iter: 918 loss: 2.39243809e-06
Iter: 919 loss: 2.39143969e-06
Iter: 920 loss: 2.39130623e-06
Iter: 921 loss: 2.39125666e-06
Iter: 922 loss: 2.39107317e-06
Iter: 923 loss: 2.39089422e-06
Iter: 924 loss: 2.39085148e-06
Iter: 925 loss: 2.39066412e-06
Iter: 926 loss: 2.39388191e-06
Iter: 927 loss: 2.39066139e-06
Iter: 928 loss: 2.39051633e-06
Iter: 929 loss: 2.39050678e-06
Iter: 930 loss: 2.39041742e-06
Iter: 931 loss: 2.39021756e-06
Iter: 932 loss: 2.39125848e-06
Iter: 933 loss: 2.39021665e-06
Iter: 934 loss: 2.39005476e-06
Iter: 935 loss: 2.39097949e-06
Iter: 936 loss: 2.39003521e-06
Iter: 937 loss: 2.3898765e-06
Iter: 938 loss: 2.38962707e-06
Iter: 939 loss: 2.38963207e-06
Iter: 940 loss: 2.38948337e-06
Iter: 941 loss: 2.3894886e-06
Iter: 942 loss: 2.38931466e-06
Iter: 943 loss: 2.38901202e-06
Iter: 944 loss: 2.39546148e-06
Iter: 945 loss: 2.38898861e-06
Iter: 946 loss: 2.38870734e-06
Iter: 947 loss: 2.38874281e-06
Iter: 948 loss: 2.38844177e-06
Iter: 949 loss: 2.38810526e-06
Iter: 950 loss: 2.38915209e-06
Iter: 951 loss: 2.38799885e-06
Iter: 952 loss: 2.38784446e-06
Iter: 953 loss: 2.38784878e-06
Iter: 954 loss: 2.38764164e-06
Iter: 955 loss: 2.38754751e-06
Iter: 956 loss: 2.38747407e-06
Iter: 957 loss: 2.38725306e-06
Iter: 958 loss: 2.38929306e-06
Iter: 959 loss: 2.38726034e-06
Iter: 960 loss: 2.38705752e-06
Iter: 961 loss: 2.38705e-06
Iter: 962 loss: 2.38692473e-06
Iter: 963 loss: 2.38668576e-06
Iter: 964 loss: 2.38758685e-06
Iter: 965 loss: 2.38665848e-06
Iter: 966 loss: 2.38648022e-06
Iter: 967 loss: 2.38711732e-06
Iter: 968 loss: 2.38640951e-06
Iter: 969 loss: 2.38621215e-06
Iter: 970 loss: 2.38636721e-06
Iter: 971 loss: 2.38606208e-06
Iter: 972 loss: 2.38585062e-06
Iter: 973 loss: 2.38662642e-06
Iter: 974 loss: 2.38581333e-06
Iter: 975 loss: 2.38557232e-06
Iter: 976 loss: 2.38571511e-06
Iter: 977 loss: 2.38537177e-06
Iter: 978 loss: 2.38517259e-06
Iter: 979 loss: 2.38496568e-06
Iter: 980 loss: 2.38493703e-06
Iter: 981 loss: 2.38461053e-06
Iter: 982 loss: 2.38491293e-06
Iter: 983 loss: 2.38441498e-06
Iter: 984 loss: 2.38415805e-06
Iter: 985 loss: 2.38415168e-06
Iter: 986 loss: 2.38391635e-06
Iter: 987 loss: 2.38588859e-06
Iter: 988 loss: 2.38388793e-06
Iter: 989 loss: 2.38372422e-06
Iter: 990 loss: 2.38371831e-06
Iter: 991 loss: 2.38364e-06
Iter: 992 loss: 2.38332836e-06
Iter: 993 loss: 2.3839284e-06
Iter: 994 loss: 2.38322809e-06
Iter: 995 loss: 2.38302664e-06
Iter: 996 loss: 2.3839782e-06
Iter: 997 loss: 2.38301891e-06
Iter: 998 loss: 2.38284224e-06
Iter: 999 loss: 2.38323537e-06
Iter: 1000 loss: 2.38279927e-06
Iter: 1001 loss: 2.38259145e-06
Iter: 1002 loss: 2.38320376e-06
Iter: 1003 loss: 2.38256689e-06
Iter: 1004 loss: 2.38239636e-06
Iter: 1005 loss: 2.3823427e-06
Iter: 1006 loss: 2.38223083e-06
Iter: 1007 loss: 2.38199755e-06
Iter: 1008 loss: 2.38375469e-06
Iter: 1009 loss: 2.3820005e-06
Iter: 1010 loss: 2.38185476e-06
Iter: 1011 loss: 2.38149528e-06
Iter: 1012 loss: 2.38474877e-06
Iter: 1013 loss: 2.38146731e-06
Iter: 1014 loss: 2.38101893e-06
Iter: 1015 loss: 2.38183429e-06
Iter: 1016 loss: 2.38087318e-06
Iter: 1017 loss: 2.38046e-06
Iter: 1018 loss: 2.38366852e-06
Iter: 1019 loss: 2.38043549e-06
Iter: 1020 loss: 2.38035727e-06
Iter: 1021 loss: 2.38029429e-06
Iter: 1022 loss: 2.38017287e-06
Iter: 1023 loss: 2.38002121e-06
Iter: 1024 loss: 2.38363282e-06
Iter: 1025 loss: 2.38002144e-06
Iter: 1026 loss: 2.37975883e-06
Iter: 1027 loss: 2.38166103e-06
Iter: 1028 loss: 2.3797229e-06
Iter: 1029 loss: 2.37956715e-06
Iter: 1030 loss: 2.37974928e-06
Iter: 1031 loss: 2.37945392e-06
Iter: 1032 loss: 2.37925315e-06
Iter: 1033 loss: 2.37973654e-06
Iter: 1034 loss: 2.37918584e-06
Iter: 1035 loss: 2.37900508e-06
Iter: 1036 loss: 2.38032976e-06
Iter: 1037 loss: 2.37897257e-06
Iter: 1038 loss: 2.37880772e-06
Iter: 1039 loss: 2.37860604e-06
Iter: 1040 loss: 2.37860377e-06
Iter: 1041 loss: 2.37830386e-06
Iter: 1042 loss: 2.38195207e-06
Iter: 1043 loss: 2.37833e-06
Iter: 1044 loss: 2.37812219e-06
Iter: 1045 loss: 2.37772042e-06
Iter: 1046 loss: 2.38269877e-06
Iter: 1047 loss: 2.37765539e-06
Iter: 1048 loss: 2.37726363e-06
Iter: 1049 loss: 2.37777522e-06
Iter: 1050 loss: 2.37704535e-06
Iter: 1051 loss: 2.37656332e-06
Iter: 1052 loss: 2.37849895e-06
Iter: 1053 loss: 2.37645054e-06
Iter: 1054 loss: 2.37656604e-06
Iter: 1055 loss: 2.37632776e-06
Iter: 1056 loss: 2.37621452e-06
Iter: 1057 loss: 2.37593713e-06
Iter: 1058 loss: 2.37905851e-06
Iter: 1059 loss: 2.37592394e-06
Iter: 1060 loss: 2.37570271e-06
Iter: 1061 loss: 2.37569293e-06
Iter: 1062 loss: 2.37549557e-06
Iter: 1063 loss: 2.37529684e-06
Iter: 1064 loss: 2.37525956e-06
Iter: 1065 loss: 2.37495829e-06
Iter: 1066 loss: 2.37683685e-06
Iter: 1067 loss: 2.37492554e-06
Iter: 1068 loss: 2.37474796e-06
Iter: 1069 loss: 2.37597806e-06
Iter: 1070 loss: 2.37472568e-06
Iter: 1071 loss: 2.37458471e-06
Iter: 1072 loss: 2.37440645e-06
Iter: 1073 loss: 2.37438962e-06
Iter: 1074 loss: 2.37418521e-06
Iter: 1075 loss: 2.3768871e-06
Iter: 1076 loss: 2.37419385e-06
Iter: 1077 loss: 2.3739849e-06
Iter: 1078 loss: 2.37361064e-06
Iter: 1079 loss: 2.38016401e-06
Iter: 1080 loss: 2.37356744e-06
Iter: 1081 loss: 2.37318227e-06
Iter: 1082 loss: 2.37335144e-06
Iter: 1083 loss: 2.37290942e-06
Iter: 1084 loss: 2.37247309e-06
Iter: 1085 loss: 2.37355812e-06
Iter: 1086 loss: 2.37230279e-06
Iter: 1087 loss: 2.37222253e-06
Iter: 1088 loss: 2.37211043e-06
Iter: 1089 loss: 2.37195172e-06
Iter: 1090 loss: 2.37216091e-06
Iter: 1091 loss: 2.3718494e-06
Iter: 1092 loss: 2.37174118e-06
Iter: 1093 loss: 2.37245649e-06
Iter: 1094 loss: 2.37173367e-06
Iter: 1095 loss: 2.37159247e-06
Iter: 1096 loss: 2.37134e-06
Iter: 1097 loss: 2.37133781e-06
Iter: 1098 loss: 2.37104e-06
Iter: 1099 loss: 2.3730986e-06
Iter: 1100 loss: 2.3710229e-06
Iter: 1101 loss: 2.37081304e-06
Iter: 1102 loss: 2.3712837e-06
Iter: 1103 loss: 2.37076324e-06
Iter: 1104 loss: 2.37051e-06
Iter: 1105 loss: 2.37096356e-06
Iter: 1106 loss: 2.37040922e-06
Iter: 1107 loss: 2.37024847e-06
Iter: 1108 loss: 2.37122413e-06
Iter: 1109 loss: 2.37023232e-06
Iter: 1110 loss: 2.37000495e-06
Iter: 1111 loss: 2.36983851e-06
Iter: 1112 loss: 2.36977257e-06
Iter: 1113 loss: 2.36950609e-06
Iter: 1114 loss: 2.36929304e-06
Iter: 1115 loss: 2.36920096e-06
Iter: 1116 loss: 2.36880169e-06
Iter: 1117 loss: 2.36924507e-06
Iter: 1118 loss: 2.36859069e-06
Iter: 1119 loss: 2.36825917e-06
Iter: 1120 loss: 2.36823394e-06
Iter: 1121 loss: 2.36794676e-06
Iter: 1122 loss: 2.37082554e-06
Iter: 1123 loss: 2.36794858e-06
Iter: 1124 loss: 2.36781261e-06
Iter: 1125 loss: 2.36779351e-06
Iter: 1126 loss: 2.36772485e-06
Iter: 1127 loss: 2.36745927e-06
Iter: 1128 loss: 2.36792266e-06
Iter: 1129 loss: 2.36735673e-06
Iter: 1130 loss: 2.36715573e-06
Iter: 1131 loss: 2.36809615e-06
Iter: 1132 loss: 2.36708274e-06
Iter: 1133 loss: 2.36689857e-06
Iter: 1134 loss: 2.36700453e-06
Iter: 1135 loss: 2.36676124e-06
Iter: 1136 loss: 2.36649589e-06
Iter: 1137 loss: 2.36827668e-06
Iter: 1138 loss: 2.36649066e-06
Iter: 1139 loss: 2.36631695e-06
Iter: 1140 loss: 2.36659253e-06
Iter: 1141 loss: 2.36626556e-06
Iter: 1142 loss: 2.36605e-06
Iter: 1143 loss: 2.36641699e-06
Iter: 1144 loss: 2.36595838e-06
Iter: 1145 loss: 2.36574579e-06
Iter: 1146 loss: 2.36541609e-06
Iter: 1147 loss: 2.37170843e-06
Iter: 1148 loss: 2.36544042e-06
Iter: 1149 loss: 2.36495907e-06
Iter: 1150 loss: 2.36584947e-06
Iter: 1151 loss: 2.36481083e-06
Iter: 1152 loss: 2.36436154e-06
Iter: 1153 loss: 2.36610276e-06
Iter: 1154 loss: 2.36424194e-06
Iter: 1155 loss: 2.3639368e-06
Iter: 1156 loss: 2.36393885e-06
Iter: 1157 loss: 2.36376718e-06
Iter: 1158 loss: 2.36359028e-06
Iter: 1159 loss: 2.36359642e-06
Iter: 1160 loss: 2.36334949e-06
Iter: 1161 loss: 2.36335427e-06
Iter: 1162 loss: 2.36325081e-06
Iter: 1163 loss: 2.3630555e-06
Iter: 1164 loss: 2.36303799e-06
Iter: 1165 loss: 2.36271717e-06
Iter: 1166 loss: 2.36337678e-06
Iter: 1167 loss: 2.36258734e-06
Iter: 1168 loss: 2.36230085e-06
Iter: 1169 loss: 2.36476717e-06
Iter: 1170 loss: 2.36227197e-06
Iter: 1171 loss: 2.36209507e-06
Iter: 1172 loss: 2.36208234e-06
Iter: 1173 loss: 2.36195888e-06
Iter: 1174 loss: 2.36168898e-06
Iter: 1175 loss: 2.36452775e-06
Iter: 1176 loss: 2.36168898e-06
Iter: 1177 loss: 2.36154756e-06
Iter: 1178 loss: 2.36119718e-06
Iter: 1179 loss: 2.36387541e-06
Iter: 1180 loss: 2.36113328e-06
Iter: 1181 loss: 2.36075039e-06
Iter: 1182 loss: 2.36226083e-06
Iter: 1183 loss: 2.36066398e-06
Iter: 1184 loss: 2.36033748e-06
Iter: 1185 loss: 2.36013807e-06
Iter: 1186 loss: 2.35997413e-06
Iter: 1187 loss: 2.35997891e-06
Iter: 1188 loss: 2.35968878e-06
Iter: 1189 loss: 2.35949915e-06
Iter: 1190 loss: 2.35927428e-06
Iter: 1191 loss: 2.35925881e-06
Iter: 1192 loss: 2.35911193e-06
Iter: 1193 loss: 2.35908738e-06
Iter: 1194 loss: 2.35892094e-06
Iter: 1195 loss: 2.35859488e-06
Iter: 1196 loss: 2.36332698e-06
Iter: 1197 loss: 2.3585585e-06
Iter: 1198 loss: 2.3582129e-06
Iter: 1199 loss: 2.36342521e-06
Iter: 1200 loss: 2.35818675e-06
Iter: 1201 loss: 2.35801599e-06
Iter: 1202 loss: 2.35811285e-06
Iter: 1203 loss: 2.35785092e-06
Iter: 1204 loss: 2.3575758e-06
Iter: 1205 loss: 2.35781795e-06
Iter: 1206 loss: 2.35736979e-06
Iter: 1207 loss: 2.35718812e-06
Iter: 1208 loss: 2.3571572e-06
Iter: 1209 loss: 2.3570019e-06
Iter: 1210 loss: 2.35662537e-06
Iter: 1211 loss: 2.36017672e-06
Iter: 1212 loss: 2.35657626e-06
Iter: 1213 loss: 2.35616244e-06
Iter: 1214 loss: 2.35674861e-06
Iter: 1215 loss: 2.35596508e-06
Iter: 1216 loss: 2.35558e-06
Iter: 1217 loss: 2.35682228e-06
Iter: 1218 loss: 2.35548805e-06
Iter: 1219 loss: 2.35514653e-06
Iter: 1220 loss: 2.35927655e-06
Iter: 1221 loss: 2.355172e-06
Iter: 1222 loss: 2.35481457e-06
Iter: 1223 loss: 2.35584184e-06
Iter: 1224 loss: 2.35472953e-06
Iter: 1225 loss: 2.35461061e-06
Iter: 1226 loss: 2.35527273e-06
Iter: 1227 loss: 2.35461266e-06
Iter: 1228 loss: 2.35444486e-06
Iter: 1229 loss: 2.35458674e-06
Iter: 1230 loss: 2.35438438e-06
Iter: 1231 loss: 2.35423659e-06
Iter: 1232 loss: 2.35483617e-06
Iter: 1233 loss: 2.3542143e-06
Iter: 1234 loss: 2.35407151e-06
Iter: 1235 loss: 2.3539385e-06
Iter: 1236 loss: 2.35391144e-06
Iter: 1237 loss: 2.35364769e-06
Iter: 1238 loss: 2.35505331e-06
Iter: 1239 loss: 2.3535938e-06
Iter: 1240 loss: 2.3534235e-06
Iter: 1241 loss: 2.35433413e-06
Iter: 1242 loss: 2.35339053e-06
Iter: 1243 loss: 2.35319226e-06
Iter: 1244 loss: 2.3529135e-06
Iter: 1245 loss: 2.35288348e-06
Iter: 1246 loss: 2.35258176e-06
Iter: 1247 loss: 2.35257676e-06
Iter: 1248 loss: 2.35234666e-06
Iter: 1249 loss: 2.35208358e-06
Iter: 1250 loss: 2.3534194e-06
Iter: 1251 loss: 2.35204675e-06
Iter: 1252 loss: 2.35183779e-06
Iter: 1253 loss: 2.35198786e-06
Iter: 1254 loss: 2.35167386e-06
Iter: 1255 loss: 2.35132688e-06
Iter: 1256 loss: 2.35134075e-06
Iter: 1257 loss: 2.35115203e-06
Iter: 1258 loss: 2.35079892e-06
Iter: 1259 loss: 2.35080779e-06
Iter: 1260 loss: 2.35041807e-06
Iter: 1261 loss: 2.35041512e-06
Iter: 1262 loss: 2.35028187e-06
Iter: 1263 loss: 2.35009657e-06
Iter: 1264 loss: 2.35009566e-06
Iter: 1265 loss: 2.34981599e-06
Iter: 1266 loss: 2.35214588e-06
Iter: 1267 loss: 2.3497696e-06
Iter: 1268 loss: 2.34967365e-06
Iter: 1269 loss: 2.34978916e-06
Iter: 1270 loss: 2.3495918e-06
Iter: 1271 loss: 2.34938625e-06
Iter: 1272 loss: 2.34957474e-06
Iter: 1273 loss: 2.34928e-06
Iter: 1274 loss: 2.34914182e-06
Iter: 1275 loss: 2.34913159e-06
Iter: 1276 loss: 2.34898926e-06
Iter: 1277 loss: 2.34861318e-06
Iter: 1278 loss: 2.34906815e-06
Iter: 1279 loss: 2.34833988e-06
Iter: 1280 loss: 2.3478151e-06
Iter: 1281 loss: 2.35347989e-06
Iter: 1282 loss: 2.34780327e-06
Iter: 1283 loss: 2.34753475e-06
Iter: 1284 loss: 2.3484331e-06
Iter: 1285 loss: 2.34741901e-06
Iter: 1286 loss: 2.34735717e-06
Iter: 1287 loss: 2.34734262e-06
Iter: 1288 loss: 2.34721301e-06
Iter: 1289 loss: 2.34696063e-06
Iter: 1290 loss: 2.35211792e-06
Iter: 1291 loss: 2.34694789e-06
Iter: 1292 loss: 2.34679669e-06
Iter: 1293 loss: 2.34677168e-06
Iter: 1294 loss: 2.34667e-06
Iter: 1295 loss: 2.34645427e-06
Iter: 1296 loss: 2.35171819e-06
Iter: 1297 loss: 2.34643562e-06
Iter: 1298 loss: 2.34617846e-06
Iter: 1299 loss: 2.34888603e-06
Iter: 1300 loss: 2.346168e-06
Iter: 1301 loss: 2.34597519e-06
Iter: 1302 loss: 2.34588015e-06
Iter: 1303 loss: 2.34578238e-06
Iter: 1304 loss: 2.34550907e-06
Iter: 1305 loss: 2.34635036e-06
Iter: 1306 loss: 2.34541267e-06
Iter: 1307 loss: 2.3453108e-06
Iter: 1308 loss: 2.34528579e-06
Iter: 1309 loss: 2.34517938e-06
Iter: 1310 loss: 2.34489039e-06
Iter: 1311 loss: 2.34619165e-06
Iter: 1312 loss: 2.34474101e-06
Iter: 1313 loss: 2.3443813e-06
Iter: 1314 loss: 2.34474032e-06
Iter: 1315 loss: 2.34417439e-06
Iter: 1316 loss: 2.34373988e-06
Iter: 1317 loss: 2.34634535e-06
Iter: 1318 loss: 2.34371646e-06
Iter: 1319 loss: 2.34354889e-06
Iter: 1320 loss: 2.34353229e-06
Iter: 1321 loss: 2.34332083e-06
Iter: 1322 loss: 2.34336858e-06
Iter: 1323 loss: 2.34316917e-06
Iter: 1324 loss: 2.34298068e-06
Iter: 1325 loss: 2.34428899e-06
Iter: 1326 loss: 2.34298614e-06
Iter: 1327 loss: 2.34278059e-06
Iter: 1328 loss: 2.34271511e-06
Iter: 1329 loss: 2.34258277e-06
Iter: 1330 loss: 2.34236268e-06
Iter: 1331 loss: 2.34326944e-06
Iter: 1332 loss: 2.34230356e-06
Iter: 1333 loss: 2.34196318e-06
Iter: 1334 loss: 2.34173876e-06
Iter: 1335 loss: 2.34164099e-06
Iter: 1336 loss: 2.34120807e-06
Iter: 1337 loss: 2.3442135e-06
Iter: 1338 loss: 2.34116601e-06
Iter: 1339 loss: 2.34096842e-06
Iter: 1340 loss: 2.34185177e-06
Iter: 1341 loss: 2.34092477e-06
Iter: 1342 loss: 2.34070467e-06
Iter: 1343 loss: 2.34113668e-06
Iter: 1344 loss: 2.34059439e-06
Iter: 1345 loss: 2.34039567e-06
Iter: 1346 loss: 2.33996047e-06
Iter: 1347 loss: 2.34368736e-06
Iter: 1348 loss: 2.33988749e-06
Iter: 1349 loss: 2.33924789e-06
Iter: 1350 loss: 2.34082017e-06
Iter: 1351 loss: 2.33903802e-06
Iter: 1352 loss: 2.33845321e-06
Iter: 1353 loss: 2.34237496e-06
Iter: 1354 loss: 2.33841274e-06
Iter: 1355 loss: 2.33827586e-06
Iter: 1356 loss: 2.33814444e-06
Iter: 1357 loss: 2.33802166e-06
Iter: 1358 loss: 2.33794708e-06
Iter: 1359 loss: 2.33790161e-06
Iter: 1360 loss: 2.33774836e-06
Iter: 1361 loss: 2.34002982e-06
Iter: 1362 loss: 2.3377404e-06
Iter: 1363 loss: 2.33764831e-06
Iter: 1364 loss: 2.33753e-06
Iter: 1365 loss: 2.3375153e-06
Iter: 1366 loss: 2.33725245e-06
Iter: 1367 loss: 2.33744709e-06
Iter: 1368 loss: 2.33707465e-06
Iter: 1369 loss: 2.33676974e-06
Iter: 1370 loss: 2.33675337e-06
Iter: 1371 loss: 2.33652918e-06
Iter: 1372 loss: 2.33609398e-06
Iter: 1373 loss: 2.33768833e-06
Iter: 1374 loss: 2.33597166e-06
Iter: 1375 loss: 2.33584069e-06
Iter: 1376 loss: 2.33581977e-06
Iter: 1377 loss: 2.33568494e-06
Iter: 1378 loss: 2.33538299e-06
Iter: 1379 loss: 2.34051072e-06
Iter: 1380 loss: 2.33536502e-06
Iter: 1381 loss: 2.33508376e-06
Iter: 1382 loss: 2.33500464e-06
Iter: 1383 loss: 2.33481319e-06
Iter: 1384 loss: 2.33441665e-06
Iter: 1385 loss: 2.33441392e-06
Iter: 1386 loss: 2.33407718e-06
Iter: 1387 loss: 2.33335527e-06
Iter: 1388 loss: 2.3367902e-06
Iter: 1389 loss: 2.33322544e-06
Iter: 1390 loss: 2.33316132e-06
Iter: 1391 loss: 2.33305173e-06
Iter: 1392 loss: 2.33286528e-06
Iter: 1393 loss: 2.3327766e-06
Iter: 1394 loss: 2.33269566e-06
Iter: 1395 loss: 2.33248693e-06
Iter: 1396 loss: 2.33239712e-06
Iter: 1397 loss: 2.33226e-06
Iter: 1398 loss: 2.33188166e-06
Iter: 1399 loss: 2.3355251e-06
Iter: 1400 loss: 2.3318787e-06
Iter: 1401 loss: 2.33162405e-06
Iter: 1402 loss: 2.33129731e-06
Iter: 1403 loss: 2.33128685e-06
Iter: 1404 loss: 2.33089895e-06
Iter: 1405 loss: 2.33605351e-06
Iter: 1406 loss: 2.33090782e-06
Iter: 1407 loss: 2.33065111e-06
Iter: 1408 loss: 2.33115838e-06
Iter: 1409 loss: 2.33053083e-06
Iter: 1410 loss: 2.33020501e-06
Iter: 1411 loss: 2.33022683e-06
Iter: 1412 loss: 2.32992807e-06
Iter: 1413 loss: 2.32967386e-06
Iter: 1414 loss: 2.3296725e-06
Iter: 1415 loss: 2.32952198e-06
Iter: 1416 loss: 2.32913317e-06
Iter: 1417 loss: 2.33296942e-06
Iter: 1418 loss: 2.32909315e-06
Iter: 1419 loss: 2.32859179e-06
Iter: 1420 loss: 2.32863249e-06
Iter: 1421 loss: 2.32819525e-06
Iter: 1422 loss: 2.32760681e-06
Iter: 1423 loss: 2.33040737e-06
Iter: 1424 loss: 2.32745037e-06
Iter: 1425 loss: 2.32737216e-06
Iter: 1426 loss: 2.32720095e-06
Iter: 1427 loss: 2.32695584e-06
Iter: 1428 loss: 2.32656635e-06
Iter: 1429 loss: 2.32657885e-06
Iter: 1430 loss: 2.32625166e-06
Iter: 1431 loss: 2.32724074e-06
Iter: 1432 loss: 2.32616048e-06
Iter: 1433 loss: 2.32576258e-06
Iter: 1434 loss: 2.32820139e-06
Iter: 1435 loss: 2.32569505e-06
Iter: 1436 loss: 2.32550519e-06
Iter: 1437 loss: 2.32540515e-06
Iter: 1438 loss: 2.32531784e-06
Iter: 1439 loss: 2.32496836e-06
Iter: 1440 loss: 2.32686716e-06
Iter: 1441 loss: 2.32492107e-06
Iter: 1442 loss: 2.32464527e-06
Iter: 1443 loss: 2.3251996e-06
Iter: 1444 loss: 2.32454363e-06
Iter: 1445 loss: 2.32422872e-06
Iter: 1446 loss: 2.32493858e-06
Iter: 1447 loss: 2.32408161e-06
Iter: 1448 loss: 2.32380535e-06
Iter: 1449 loss: 2.32618231e-06
Iter: 1450 loss: 2.32379512e-06
Iter: 1451 loss: 2.32362163e-06
Iter: 1452 loss: 2.32318257e-06
Iter: 1453 loss: 2.32535081e-06
Iter: 1454 loss: 2.32299794e-06
Iter: 1455 loss: 2.32242382e-06
Iter: 1456 loss: 2.32592e-06
Iter: 1457 loss: 2.3223397e-06
Iter: 1458 loss: 2.32185539e-06
Iter: 1459 loss: 2.32224897e-06
Iter: 1460 loss: 2.32157981e-06
Iter: 1461 loss: 2.32163416e-06
Iter: 1462 loss: 2.32126376e-06
Iter: 1463 loss: 2.32112734e-06
Iter: 1464 loss: 2.32067487e-06
Iter: 1465 loss: 2.32483762e-06
Iter: 1466 loss: 2.32062712e-06
Iter: 1467 loss: 2.32034563e-06
Iter: 1468 loss: 2.32336515e-06
Iter: 1469 loss: 2.32033813e-06
Iter: 1470 loss: 2.32000639e-06
Iter: 1471 loss: 2.32106231e-06
Iter: 1472 loss: 2.31991157e-06
Iter: 1473 loss: 2.31971194e-06
Iter: 1474 loss: 2.319651e-06
Iter: 1475 loss: 2.31956437e-06
Iter: 1476 loss: 2.31916e-06
Iter: 1477 loss: 2.32069942e-06
Iter: 1478 loss: 2.31906961e-06
Iter: 1479 loss: 2.31882814e-06
Iter: 1480 loss: 2.31988793e-06
Iter: 1481 loss: 2.31877902e-06
Iter: 1482 loss: 2.31854096e-06
Iter: 1483 loss: 2.31895092e-06
Iter: 1484 loss: 2.31841454e-06
Iter: 1485 loss: 2.31808326e-06
Iter: 1486 loss: 2.31859235e-06
Iter: 1487 loss: 2.31792092e-06
Iter: 1488 loss: 2.31762397e-06
Iter: 1489 loss: 2.31746799e-06
Iter: 1490 loss: 2.31733316e-06
Iter: 1491 loss: 2.31702757e-06
Iter: 1492 loss: 2.31691388e-06
Iter: 1493 loss: 2.3167172e-06
Iter: 1494 loss: 2.31617241e-06
Iter: 1495 loss: 2.31911508e-06
Iter: 1496 loss: 2.31607851e-06
Iter: 1497 loss: 2.31597824e-06
Iter: 1498 loss: 2.3158434e-06
Iter: 1499 loss: 2.31571494e-06
Iter: 1500 loss: 2.31532613e-06
Iter: 1501 loss: 2.31672539e-06
Iter: 1502 loss: 2.31519221e-06
Iter: 1503 loss: 2.31494505e-06
Iter: 1504 loss: 2.31493232e-06
Iter: 1505 loss: 2.31462673e-06
Iter: 1506 loss: 2.31491686e-06
Iter: 1507 loss: 2.31447325e-06
Iter: 1508 loss: 2.31425838e-06
Iter: 1509 loss: 2.31431386e-06
Iter: 1510 loss: 2.314109e-06
Iter: 1511 loss: 2.31379977e-06
Iter: 1512 loss: 2.3156374e-06
Iter: 1513 loss: 2.31374588e-06
Iter: 1514 loss: 2.3135226e-06
Iter: 1515 loss: 2.31337572e-06
Iter: 1516 loss: 2.31330796e-06
Iter: 1517 loss: 2.3128996e-06
Iter: 1518 loss: 2.31557169e-06
Iter: 1519 loss: 2.31283548e-06
Iter: 1520 loss: 2.31256945e-06
Iter: 1521 loss: 2.31371268e-06
Iter: 1522 loss: 2.31254262e-06
Iter: 1523 loss: 2.31233957e-06
Iter: 1524 loss: 2.31220884e-06
Iter: 1525 loss: 2.31212948e-06
Iter: 1526 loss: 2.31187187e-06
Iter: 1527 loss: 2.31150261e-06
Iter: 1528 loss: 2.31145327e-06
Iter: 1529 loss: 2.31096806e-06
Iter: 1530 loss: 2.31296099e-06
Iter: 1531 loss: 2.31084891e-06
Iter: 1532 loss: 2.31082231e-06
Iter: 1533 loss: 2.3106245e-06
Iter: 1534 loss: 2.310421e-06
Iter: 1535 loss: 2.30997557e-06
Iter: 1536 loss: 2.31685317e-06
Iter: 1537 loss: 2.30997375e-06
Iter: 1538 loss: 2.30971455e-06
Iter: 1539 loss: 2.31332751e-06
Iter: 1540 loss: 2.30972e-06
Iter: 1541 loss: 2.30942533e-06
Iter: 1542 loss: 2.30958221e-06
Iter: 1543 loss: 2.30921933e-06
Iter: 1544 loss: 2.3090397e-06
Iter: 1545 loss: 2.30896785e-06
Iter: 1546 loss: 2.30885826e-06
Iter: 1547 loss: 2.30852584e-06
Iter: 1548 loss: 2.31109948e-06
Iter: 1549 loss: 2.30849218e-06
Iter: 1550 loss: 2.30827118e-06
Iter: 1551 loss: 2.30777096e-06
Iter: 1552 loss: 2.31615286e-06
Iter: 1553 loss: 2.30776868e-06
Iter: 1554 loss: 2.30765272e-06
Iter: 1555 loss: 2.30750311e-06
Iter: 1556 loss: 2.30731234e-06
Iter: 1557 loss: 2.30702062e-06
Iter: 1558 loss: 2.30699584e-06
Iter: 1559 loss: 2.30651176e-06
Iter: 1560 loss: 2.30740216e-06
Iter: 1561 loss: 2.30630485e-06
Iter: 1562 loss: 2.30600108e-06
Iter: 1563 loss: 2.30642627e-06
Iter: 1564 loss: 2.30586647e-06
Iter: 1565 loss: 2.30564342e-06
Iter: 1566 loss: 2.30866794e-06
Iter: 1567 loss: 2.30564456e-06
Iter: 1568 loss: 2.30539808e-06
Iter: 1569 loss: 2.30519299e-06
Iter: 1570 loss: 2.3051075e-06
Iter: 1571 loss: 2.30474188e-06
Iter: 1572 loss: 2.30449041e-06
Iter: 1573 loss: 2.30437922e-06
Iter: 1574 loss: 2.30443152e-06
Iter: 1575 loss: 2.30415958e-06
Iter: 1576 loss: 2.30393516e-06
Iter: 1577 loss: 2.30339447e-06
Iter: 1578 loss: 2.31018248e-06
Iter: 1579 loss: 2.30333876e-06
Iter: 1580 loss: 2.3032826e-06
Iter: 1581 loss: 2.30317801e-06
Iter: 1582 loss: 2.30303021e-06
Iter: 1583 loss: 2.30269734e-06
Iter: 1584 loss: 2.30669457e-06
Iter: 1585 loss: 2.30266619e-06
Iter: 1586 loss: 2.30251771e-06
Iter: 1587 loss: 2.30249566e-06
Iter: 1588 loss: 2.3023274e-06
Iter: 1589 loss: 2.30213345e-06
Iter: 1590 loss: 2.30209639e-06
Iter: 1591 loss: 2.30176283e-06
Iter: 1592 loss: 2.30321825e-06
Iter: 1593 loss: 2.30172554e-06
Iter: 1594 loss: 2.30143405e-06
Iter: 1595 loss: 2.3011446e-06
Iter: 1596 loss: 2.30110754e-06
Iter: 1597 loss: 2.30088972e-06
Iter: 1598 loss: 2.30091086e-06
Iter: 1599 loss: 2.30069213e-06
Iter: 1600 loss: 2.30098522e-06
Iter: 1601 loss: 2.30064279e-06
Iter: 1602 loss: 2.30047704e-06
Iter: 1603 loss: 2.30029787e-06
Iter: 1604 loss: 2.30024443e-06
Iter: 1605 loss: 2.30008095e-06
Iter: 1606 loss: 2.30113619e-06
Iter: 1607 loss: 2.30006231e-06
Iter: 1608 loss: 2.29983834e-06
Iter: 1609 loss: 2.29990496e-06
Iter: 1610 loss: 2.29971079e-06
Iter: 1611 loss: 2.29944681e-06
Iter: 1612 loss: 2.29904072e-06
Iter: 1613 loss: 2.29902616e-06
Iter: 1614 loss: 2.29936904e-06
Iter: 1615 loss: 2.29884927e-06
Iter: 1616 loss: 2.29877242e-06
Iter: 1617 loss: 2.29852594e-06
Iter: 1618 loss: 2.30072646e-06
Iter: 1619 loss: 2.29849047e-06
Iter: 1620 loss: 2.29817988e-06
Iter: 1621 loss: 2.29805096e-06
Iter: 1622 loss: 2.29787156e-06
Iter: 1623 loss: 2.29759189e-06
Iter: 1624 loss: 2.30207797e-06
Iter: 1625 loss: 2.29757916e-06
Iter: 1626 loss: 2.29721854e-06
Iter: 1627 loss: 2.29810416e-06
Iter: 1628 loss: 2.29710622e-06
Iter: 1629 loss: 2.29685338e-06
Iter: 1630 loss: 2.29782063e-06
Iter: 1631 loss: 2.29678835e-06
Iter: 1632 loss: 2.29656484e-06
Iter: 1633 loss: 2.29635361e-06
Iter: 1634 loss: 2.29631928e-06
Iter: 1635 loss: 2.29627858e-06
Iter: 1636 loss: 2.29617672e-06
Iter: 1637 loss: 2.29609077e-06
Iter: 1638 loss: 2.29580587e-06
Iter: 1639 loss: 2.29919988e-06
Iter: 1640 loss: 2.29578268e-06
Iter: 1641 loss: 2.29542502e-06
Iter: 1642 loss: 2.29663237e-06
Iter: 1643 loss: 2.29535044e-06
Iter: 1644 loss: 2.29499597e-06
Iter: 1645 loss: 2.29779653e-06
Iter: 1646 loss: 2.29497027e-06
Iter: 1647 loss: 2.29474517e-06
Iter: 1648 loss: 2.29438024e-06
Iter: 1649 loss: 2.30263299e-06
Iter: 1650 loss: 2.29435545e-06
Iter: 1651 loss: 2.29405805e-06
Iter: 1652 loss: 2.29456873e-06
Iter: 1653 loss: 2.29388479e-06
Iter: 1654 loss: 2.29399757e-06
Iter: 1655 loss: 2.29379e-06
Iter: 1656 loss: 2.29367038e-06
Iter: 1657 loss: 2.2934255e-06
Iter: 1658 loss: 2.29629745e-06
Iter: 1659 loss: 2.29341958e-06
Iter: 1660 loss: 2.29318721e-06
Iter: 1661 loss: 2.29443776e-06
Iter: 1662 loss: 2.29312332e-06
Iter: 1663 loss: 2.29284933e-06
Iter: 1664 loss: 2.29412763e-06
Iter: 1665 loss: 2.29279112e-06
Iter: 1666 loss: 2.29258603e-06
Iter: 1667 loss: 2.29251123e-06
Iter: 1668 loss: 2.29239595e-06
Iter: 1669 loss: 2.29206876e-06
Iter: 1670 loss: 2.29319835e-06
Iter: 1671 loss: 2.2919553e-06
Iter: 1672 loss: 2.29181524e-06
Iter: 1673 loss: 2.2918307e-06
Iter: 1674 loss: 2.29169609e-06
Iter: 1675 loss: 2.2914794e-06
Iter: 1676 loss: 2.29148282e-06
Iter: 1677 loss: 2.29124271e-06
Iter: 1678 loss: 2.29177886e-06
Iter: 1679 loss: 2.29115858e-06
Iter: 1680 loss: 2.29091415e-06
Iter: 1681 loss: 2.29371653e-06
Iter: 1682 loss: 2.29093212e-06
Iter: 1683 loss: 2.29081979e-06
Iter: 1684 loss: 2.29051943e-06
Iter: 1685 loss: 2.29134503e-06
Iter: 1686 loss: 2.29038187e-06
Iter: 1687 loss: 2.29008447e-06
Iter: 1688 loss: 2.2900665e-06
Iter: 1689 loss: 2.28988529e-06
Iter: 1690 loss: 2.29259331e-06
Iter: 1691 loss: 2.28988483e-06
Iter: 1692 loss: 2.28978865e-06
Iter: 1693 loss: 2.2895797e-06
Iter: 1694 loss: 2.29258399e-06
Iter: 1695 loss: 2.28957742e-06
Iter: 1696 loss: 2.28944532e-06
Iter: 1697 loss: 2.2894219e-06
Iter: 1698 loss: 2.28928866e-06
Iter: 1699 loss: 2.28901104e-06
Iter: 1700 loss: 2.29404395e-06
Iter: 1701 loss: 2.28898875e-06
Iter: 1702 loss: 2.28872182e-06
Iter: 1703 loss: 2.29099078e-06
Iter: 1704 loss: 2.28871659e-06
Iter: 1705 loss: 2.28855106e-06
Iter: 1706 loss: 2.28903946e-06
Iter: 1707 loss: 2.28848717e-06
Iter: 1708 loss: 2.28834097e-06
Iter: 1709 loss: 2.28982094e-06
Iter: 1710 loss: 2.28830845e-06
Iter: 1711 loss: 2.28817635e-06
Iter: 1712 loss: 2.28787803e-06
Iter: 1713 loss: 2.29058401e-06
Iter: 1714 loss: 2.28780436e-06
Iter: 1715 loss: 2.2878985e-06
Iter: 1716 loss: 2.28771091e-06
Iter: 1717 loss: 2.28758449e-06
Iter: 1718 loss: 2.28731187e-06
Iter: 1719 loss: 2.28890531e-06
Iter: 1720 loss: 2.28722047e-06
Iter: 1721 loss: 2.28672343e-06
Iter: 1722 loss: 2.28997897e-06
Iter: 1723 loss: 2.28665635e-06
Iter: 1724 loss: 2.28633371e-06
Iter: 1725 loss: 2.28632098e-06
Iter: 1726 loss: 2.2861168e-06
Iter: 1727 loss: 2.2862464e-06
Iter: 1728 loss: 2.28597128e-06
Iter: 1729 loss: 2.28579233e-06
Iter: 1730 loss: 2.28600379e-06
Iter: 1731 loss: 2.28572162e-06
Iter: 1732 loss: 2.28546105e-06
Iter: 1733 loss: 2.28643148e-06
Iter: 1734 loss: 2.28539147e-06
Iter: 1735 loss: 2.28521549e-06
Iter: 1736 loss: 2.28497947e-06
Iter: 1737 loss: 2.28495423e-06
Iter: 1738 loss: 2.28459635e-06
Iter: 1739 loss: 2.28612248e-06
Iter: 1740 loss: 2.28452e-06
Iter: 1741 loss: 2.28418276e-06
Iter: 1742 loss: 2.28495355e-06
Iter: 1743 loss: 2.28408271e-06
Iter: 1744 loss: 2.28367048e-06
Iter: 1745 loss: 2.284321e-06
Iter: 1746 loss: 2.28347881e-06
Iter: 1747 loss: 2.28324961e-06
Iter: 1748 loss: 2.28429144e-06
Iter: 1749 loss: 2.28322438e-06
Iter: 1750 loss: 2.28300951e-06
Iter: 1751 loss: 2.28405361e-06
Iter: 1752 loss: 2.28295767e-06
Iter: 1753 loss: 2.28283e-06
Iter: 1754 loss: 2.28249746e-06
Iter: 1755 loss: 2.28455519e-06
Iter: 1756 loss: 2.28242084e-06
Iter: 1757 loss: 2.28202089e-06
Iter: 1758 loss: 2.28565523e-06
Iter: 1759 loss: 2.28202953e-06
Iter: 1760 loss: 2.28153203e-06
Iter: 1761 loss: 2.28303793e-06
Iter: 1762 loss: 2.28138151e-06
Iter: 1763 loss: 2.28112026e-06
Iter: 1764 loss: 2.2813947e-06
Iter: 1765 loss: 2.28095359e-06
Iter: 1766 loss: 2.28076829e-06
Iter: 1767 loss: 2.28077124e-06
Iter: 1768 loss: 2.28060935e-06
Iter: 1769 loss: 2.28027079e-06
Iter: 1770 loss: 2.28548788e-06
Iter: 1771 loss: 2.28025397e-06
Iter: 1772 loss: 2.2800491e-06
Iter: 1773 loss: 2.28330896e-06
Iter: 1774 loss: 2.28003341e-06
Iter: 1775 loss: 2.27982719e-06
Iter: 1776 loss: 2.27987653e-06
Iter: 1777 loss: 2.27965802e-06
Iter: 1778 loss: 2.27940836e-06
Iter: 1779 loss: 2.28164572e-06
Iter: 1780 loss: 2.27938745e-06
Iter: 1781 loss: 2.27916144e-06
Iter: 1782 loss: 2.27864484e-06
Iter: 1783 loss: 2.28593262e-06
Iter: 1784 loss: 2.27861233e-06
Iter: 1785 loss: 2.27869532e-06
Iter: 1786 loss: 2.27842474e-06
Iter: 1787 loss: 2.27824967e-06
Iter: 1788 loss: 2.27787859e-06
Iter: 1789 loss: 2.28259182e-06
Iter: 1790 loss: 2.27784017e-06
Iter: 1791 loss: 2.27757982e-06
Iter: 1792 loss: 2.27768896e-06
Iter: 1793 loss: 2.2774002e-06
Iter: 1794 loss: 2.27718783e-06
Iter: 1795 loss: 2.27719102e-06
Iter: 1796 loss: 2.27688133e-06
Iter: 1797 loss: 2.27716e-06
Iter: 1798 loss: 2.27671126e-06
Iter: 1799 loss: 2.27658165e-06
Iter: 1800 loss: 2.27728674e-06
Iter: 1801 loss: 2.27651481e-06
Iter: 1802 loss: 2.27624264e-06
Iter: 1803 loss: 2.27611372e-06
Iter: 1804 loss: 2.27597502e-06
Iter: 1805 loss: 2.27564851e-06
Iter: 1806 loss: 2.27642249e-06
Iter: 1807 loss: 2.27556666e-06
Iter: 1808 loss: 2.27535293e-06
Iter: 1809 loss: 2.27533519e-06
Iter: 1810 loss: 2.27522173e-06
Iter: 1811 loss: 2.27528199e-06
Iter: 1812 loss: 2.27513328e-06
Iter: 1813 loss: 2.27491137e-06
Iter: 1814 loss: 2.27491137e-06
Iter: 1815 loss: 2.27471537e-06
Iter: 1816 loss: 2.27446458e-06
Iter: 1817 loss: 2.27469354e-06
Iter: 1818 loss: 2.27433884e-06
Iter: 1819 loss: 2.27408509e-06
Iter: 1820 loss: 2.27407236e-06
Iter: 1821 loss: 2.27396595e-06
Iter: 1822 loss: 2.27365513e-06
Iter: 1823 loss: 2.2756617e-06
Iter: 1824 loss: 2.27358851e-06
Iter: 1825 loss: 2.27322062e-06
Iter: 1826 loss: 2.27373221e-06
Iter: 1827 loss: 2.27307078e-06
Iter: 1828 loss: 2.27309374e-06
Iter: 1829 loss: 2.27290434e-06
Iter: 1830 loss: 2.27272221e-06
Iter: 1831 loss: 2.27242253e-06
Iter: 1832 loss: 2.27892701e-06
Iter: 1833 loss: 2.27241344e-06
Iter: 1834 loss: 2.27212922e-06
Iter: 1835 loss: 2.27637292e-06
Iter: 1836 loss: 2.27211194e-06
Iter: 1837 loss: 2.27182818e-06
Iter: 1838 loss: 2.27134615e-06
Iter: 1839 loss: 2.27134615e-06
Iter: 1840 loss: 2.27112787e-06
Iter: 1841 loss: 2.27330111e-06
Iter: 1842 loss: 2.2711024e-06
Iter: 1843 loss: 2.27092642e-06
Iter: 1844 loss: 2.27210603e-06
Iter: 1845 loss: 2.27092505e-06
Iter: 1846 loss: 2.27073633e-06
Iter: 1847 loss: 2.27082705e-06
Iter: 1848 loss: 2.27063197e-06
Iter: 1849 loss: 2.27038527e-06
Iter: 1850 loss: 2.2702809e-06
Iter: 1851 loss: 2.2701754e-06
Iter: 1852 loss: 2.26988368e-06
Iter: 1853 loss: 2.27134933e-06
Iter: 1854 loss: 2.26984594e-06
Iter: 1855 loss: 2.2694071e-06
Iter: 1856 loss: 2.26963766e-06
Iter: 1857 loss: 2.26918246e-06
Iter: 1858 loss: 2.26891234e-06
Iter: 1859 loss: 2.26862176e-06
Iter: 1860 loss: 2.26862562e-06
Iter: 1861 loss: 2.26823067e-06
Iter: 1862 loss: 2.26946077e-06
Iter: 1863 loss: 2.26815746e-06
Iter: 1864 loss: 2.26805741e-06
Iter: 1865 loss: 2.26800512e-06
Iter: 1866 loss: 2.26781322e-06
Iter: 1867 loss: 2.26730663e-06
Iter: 1868 loss: 2.26987822e-06
Iter: 1869 loss: 2.2671486e-06
Iter: 1870 loss: 2.26710745e-06
Iter: 1871 loss: 2.26687553e-06
Iter: 1872 loss: 2.26666225e-06
Iter: 1873 loss: 2.2662889e-06
Iter: 1874 loss: 2.27523651e-06
Iter: 1875 loss: 2.2662864e-06
Iter: 1876 loss: 2.26602742e-06
Iter: 1877 loss: 2.26859265e-06
Iter: 1878 loss: 2.2660131e-06
Iter: 1879 loss: 2.26576731e-06
Iter: 1880 loss: 2.2669833e-06
Iter: 1881 loss: 2.26569978e-06
Iter: 1882 loss: 2.26557881e-06
Iter: 1883 loss: 2.26578913e-06
Iter: 1884 loss: 2.26551765e-06
Iter: 1885 loss: 2.2653719e-06
Iter: 1886 loss: 2.26501743e-06
Iter: 1887 loss: 2.27103374e-06
Iter: 1888 loss: 2.26500379e-06
Iter: 1889 loss: 2.26457e-06
Iter: 1890 loss: 2.26624934e-06
Iter: 1891 loss: 2.26447446e-06
Iter: 1892 loss: 2.263939e-06
Iter: 1893 loss: 2.26736302e-06
Iter: 1894 loss: 2.26386919e-06
Iter: 1895 loss: 2.26369525e-06
Iter: 1896 loss: 2.26348561e-06
Iter: 1897 loss: 2.26347106e-06
Iter: 1898 loss: 2.26317229e-06
Iter: 1899 loss: 2.26352017e-06
Iter: 1900 loss: 2.26303359e-06
Iter: 1901 loss: 2.26264638e-06
Iter: 1902 loss: 2.26753946e-06
Iter: 1903 loss: 2.26262796e-06
Iter: 1904 loss: 2.26248676e-06
Iter: 1905 loss: 2.26204907e-06
Iter: 1906 loss: 2.26563202e-06
Iter: 1907 loss: 2.2619663e-06
Iter: 1908 loss: 2.26172892e-06
Iter: 1909 loss: 2.26162183e-06
Iter: 1910 loss: 2.2614613e-06
Iter: 1911 loss: 2.26101747e-06
Iter: 1912 loss: 2.26394923e-06
Iter: 1913 loss: 2.26089833e-06
Iter: 1914 loss: 2.26112047e-06
Iter: 1915 loss: 2.26073553e-06
Iter: 1916 loss: 2.26060979e-06
Iter: 1917 loss: 2.26045768e-06
Iter: 1918 loss: 2.2604695e-06
Iter: 1919 loss: 2.26023462e-06
Iter: 1920 loss: 2.2606323e-06
Iter: 1921 loss: 2.26012594e-06
Iter: 1922 loss: 2.25980193e-06
Iter: 1923 loss: 2.25952726e-06
Iter: 1924 loss: 2.25944e-06
Iter: 1925 loss: 2.25914755e-06
Iter: 1926 loss: 2.25915e-06
Iter: 1927 loss: 2.25883832e-06
Iter: 1928 loss: 2.25958911e-06
Iter: 1929 loss: 2.25869917e-06
Iter: 1930 loss: 2.25851682e-06
Iter: 1931 loss: 2.25825966e-06
Iter: 1932 loss: 2.26502698e-06
Iter: 1933 loss: 2.25826852e-06
Iter: 1934 loss: 2.25828376e-06
Iter: 1935 loss: 2.25812823e-06
Iter: 1936 loss: 2.25804274e-06
Iter: 1937 loss: 2.25775057e-06
Iter: 1938 loss: 2.25962231e-06
Iter: 1939 loss: 2.257706e-06
Iter: 1940 loss: 2.25744043e-06
Iter: 1941 loss: 2.26087695e-06
Iter: 1942 loss: 2.25742815e-06
Iter: 1943 loss: 2.25706049e-06
Iter: 1944 loss: 2.25652093e-06
Iter: 1945 loss: 2.25652389e-06
Iter: 1946 loss: 2.25614986e-06
Iter: 1947 loss: 2.25603367e-06
Iter: 1948 loss: 2.25580334e-06
Iter: 1949 loss: 2.25550457e-06
Iter: 1950 loss: 2.25550866e-06
Iter: 1951 loss: 2.25515737e-06
Iter: 1952 loss: 2.25639769e-06
Iter: 1953 loss: 2.25509302e-06
Iter: 1954 loss: 2.25494523e-06
Iter: 1955 loss: 2.25478561e-06
Iter: 1956 loss: 2.25473377e-06
Iter: 1957 loss: 2.25447639e-06
Iter: 1958 loss: 2.25559143e-06
Iter: 1959 loss: 2.25439817e-06
Iter: 1960 loss: 2.25417e-06
Iter: 1961 loss: 2.25458734e-06
Iter: 1962 loss: 2.2541044e-06
Iter: 1963 loss: 2.25369013e-06
Iter: 1964 loss: 2.25371627e-06
Iter: 1965 loss: 2.25336e-06
Iter: 1966 loss: 2.25315443e-06
Iter: 1967 loss: 2.25471808e-06
Iter: 1968 loss: 2.25312669e-06
Iter: 1969 loss: 2.25289068e-06
Iter: 1970 loss: 2.25371946e-06
Iter: 1971 loss: 2.25285703e-06
Iter: 1972 loss: 2.25271469e-06
Iter: 1973 loss: 2.25237955e-06
Iter: 1974 loss: 2.25704298e-06
Iter: 1975 loss: 2.25236317e-06
Iter: 1976 loss: 2.25237227e-06
Iter: 1977 loss: 2.25222357e-06
Iter: 1978 loss: 2.25210761e-06
Iter: 1979 loss: 2.25174404e-06
Iter: 1980 loss: 2.25472081e-06
Iter: 1981 loss: 2.2517022e-06
Iter: 1982 loss: 2.25129816e-06
Iter: 1983 loss: 2.25108897e-06
Iter: 1984 loss: 2.25088615e-06
Iter: 1985 loss: 2.25136569e-06
Iter: 1986 loss: 2.25069607e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.4 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0.4
+ date
Mon Nov  2 09:29:34 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.4/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 2 --phi 0.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.4/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324491268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324585ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f632448fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63245a9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324502d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324502c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63243778c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f632437f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63242e07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63242e0268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63241cb730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63241a9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324433730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63243ecd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324437ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63240e2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63240e2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63240e2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324324f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63243d7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63243bd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63243bdbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324218ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63241690d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324169c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f632407d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c747f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63240d7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63240d7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63240a7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63240378c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c6af158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c6af0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6324120598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f632414e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c6ffc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 4.2659347e-05
test_loss: 4.424275e-05
train_loss: 2.5049098e-05
test_loss: 2.246561e-05
train_loss: 1.6058693e-05
test_loss: 1.6970647e-05
train_loss: 1.5232225e-05
test_loss: 1.4477239e-05
train_loss: 1.3229892e-05
test_loss: 1.3285728e-05
train_loss: 1.1652672e-05
test_loss: 1.2974888e-05
train_loss: 1.1081109e-05
test_loss: 1.2312743e-05
train_loss: 1.0789639e-05
test_loss: 1.1310331e-05
train_loss: 1.014243e-05
test_loss: 1.0678182e-05
train_loss: 9.443966e-06
test_loss: 1.0372764e-05
train_loss: 9.212807e-06
test_loss: 9.751399e-06
train_loss: 9.185166e-06
test_loss: 9.4199195e-06
train_loss: 8.478795e-06
test_loss: 9.170936e-06
train_loss: 8.398453e-06
test_loss: 8.925523e-06
train_loss: 7.825762e-06
test_loss: 8.600521e-06
train_loss: 7.675277e-06
test_loss: 8.794804e-06
train_loss: 7.4333484e-06
test_loss: 8.254997e-06
train_loss: 7.517065e-06
test_loss: 7.943405e-06
train_loss: 6.9926045e-06
test_loss: 7.807391e-06
train_loss: 7.321303e-06
test_loss: 7.720325e-06
train_loss: 6.9880675e-06
test_loss: 7.681369e-06
train_loss: 6.3854504e-06
test_loss: 7.43674e-06
train_loss: 6.783599e-06
test_loss: 7.418516e-06
train_loss: 6.4026644e-06
test_loss: 7.2545895e-06
train_loss: 6.296009e-06
test_loss: 7.1936333e-06
train_loss: 6.337319e-06
test_loss: 7.0849937e-06
train_loss: 6.7448673e-06
test_loss: 7.053194e-06
train_loss: 6.725708e-06
test_loss: 6.9253288e-06
train_loss: 6.0728566e-06
test_loss: 6.914947e-06
train_loss: 6.1754035e-06
test_loss: 6.821174e-06
train_loss: 5.847923e-06
test_loss: 6.8020086e-06
train_loss: 5.416814e-06
test_loss: 6.7097712e-06
train_loss: 6.101156e-06
test_loss: 6.6753805e-06
train_loss: 5.576188e-06
test_loss: 6.58435e-06
train_loss: 5.6309514e-06
test_loss: 6.5539084e-06
train_loss: 5.809044e-06
test_loss: 6.5182344e-06
train_loss: 5.231953e-06
test_loss: 6.5219742e-06
train_loss: 5.597123e-06
test_loss: 6.5064696e-06
train_loss: 5.546082e-06
test_loss: 6.4692103e-06
train_loss: 5.7996463e-06
test_loss: 6.4619744e-06
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0.4/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 0.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0.4/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ec88c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ec7dfea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ec7df6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ec7dfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ec81c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ec7ebae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76ec7ebc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c1a12950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c1a127b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c1a2e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c19cf158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c19e7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c19e78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c1962d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c1a64400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c1a69c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c1a6f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76c1a6fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f769c0498c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76800a3158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76800a32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76800cd158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f769c097400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76800286a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76800288c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7680028c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f768006f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7680062840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76800621e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f761877d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f761870f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76186be510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76186dcb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76186db6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76186649d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7618759158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.38501808e-06
Iter: 2 loss: 5.36048174e-06
Iter: 3 loss: 5.35505296e-06
Iter: 4 loss: 5.33937282e-06
Iter: 5 loss: 5.33673847e-06
Iter: 6 loss: 5.32597096e-06
Iter: 7 loss: 5.31686055e-06
Iter: 8 loss: 5.45429293e-06
Iter: 9 loss: 5.31685555e-06
Iter: 10 loss: 5.30802663e-06
Iter: 11 loss: 5.28760484e-06
Iter: 12 loss: 5.54180633e-06
Iter: 13 loss: 5.28610917e-06
Iter: 14 loss: 5.2737e-06
Iter: 15 loss: 5.40742803e-06
Iter: 16 loss: 5.27342854e-06
Iter: 17 loss: 5.26226086e-06
Iter: 18 loss: 5.30992293e-06
Iter: 19 loss: 5.2599944e-06
Iter: 20 loss: 5.24846109e-06
Iter: 21 loss: 5.26517124e-06
Iter: 22 loss: 5.24283723e-06
Iter: 23 loss: 5.23279323e-06
Iter: 24 loss: 5.24101097e-06
Iter: 25 loss: 5.22685968e-06
Iter: 26 loss: 5.22568689e-06
Iter: 27 loss: 5.22289929e-06
Iter: 28 loss: 5.22019945e-06
Iter: 29 loss: 5.21226684e-06
Iter: 30 loss: 5.24018378e-06
Iter: 31 loss: 5.20866706e-06
Iter: 32 loss: 5.19708237e-06
Iter: 33 loss: 5.20336062e-06
Iter: 34 loss: 5.18949219e-06
Iter: 35 loss: 5.17158242e-06
Iter: 36 loss: 5.19710511e-06
Iter: 37 loss: 5.16289356e-06
Iter: 38 loss: 5.14566909e-06
Iter: 39 loss: 5.26630083e-06
Iter: 40 loss: 5.14399653e-06
Iter: 41 loss: 5.14582416e-06
Iter: 42 loss: 5.13995201e-06
Iter: 43 loss: 5.13618124e-06
Iter: 44 loss: 5.13482428e-06
Iter: 45 loss: 5.1326806e-06
Iter: 46 loss: 5.12975112e-06
Iter: 47 loss: 5.15204556e-06
Iter: 48 loss: 5.12953466e-06
Iter: 49 loss: 5.12569068e-06
Iter: 50 loss: 5.11682538e-06
Iter: 51 loss: 5.22977371e-06
Iter: 52 loss: 5.11625876e-06
Iter: 53 loss: 5.10975906e-06
Iter: 54 loss: 5.13551458e-06
Iter: 55 loss: 5.10821792e-06
Iter: 56 loss: 5.10397513e-06
Iter: 57 loss: 5.10369773e-06
Iter: 58 loss: 5.10122391e-06
Iter: 59 loss: 5.0960607e-06
Iter: 60 loss: 5.18825527e-06
Iter: 61 loss: 5.09599249e-06
Iter: 62 loss: 5.09290476e-06
Iter: 63 loss: 5.09273923e-06
Iter: 64 loss: 5.0907629e-06
Iter: 65 loss: 5.10111386e-06
Iter: 66 loss: 5.09044776e-06
Iter: 67 loss: 5.08858329e-06
Iter: 68 loss: 5.08499852e-06
Iter: 69 loss: 5.1648085e-06
Iter: 70 loss: 5.08496487e-06
Iter: 71 loss: 5.08049e-06
Iter: 72 loss: 5.08076755e-06
Iter: 73 loss: 5.07698815e-06
Iter: 74 loss: 5.07133973e-06
Iter: 75 loss: 5.07903587e-06
Iter: 76 loss: 5.06855577e-06
Iter: 77 loss: 5.06298238e-06
Iter: 78 loss: 5.10054269e-06
Iter: 79 loss: 5.06238302e-06
Iter: 80 loss: 5.05922e-06
Iter: 81 loss: 5.09282108e-06
Iter: 82 loss: 5.05911657e-06
Iter: 83 loss: 5.05593471e-06
Iter: 84 loss: 5.08016e-06
Iter: 85 loss: 5.05571e-06
Iter: 86 loss: 5.05419939e-06
Iter: 87 loss: 5.05100934e-06
Iter: 88 loss: 5.10244e-06
Iter: 89 loss: 5.05093703e-06
Iter: 90 loss: 5.04590616e-06
Iter: 91 loss: 5.08146286e-06
Iter: 92 loss: 5.04548734e-06
Iter: 93 loss: 5.04354648e-06
Iter: 94 loss: 5.04100535e-06
Iter: 95 loss: 5.04082618e-06
Iter: 96 loss: 5.03916726e-06
Iter: 97 loss: 5.0390845e-06
Iter: 98 loss: 5.03712954e-06
Iter: 99 loss: 5.03547062e-06
Iter: 100 loss: 5.03486353e-06
Iter: 101 loss: 5.0331e-06
Iter: 102 loss: 5.03266e-06
Iter: 103 loss: 5.03159026e-06
Iter: 104 loss: 5.02946205e-06
Iter: 105 loss: 5.02938929e-06
Iter: 106 loss: 5.02786497e-06
Iter: 107 loss: 5.02347757e-06
Iter: 108 loss: 5.05114531e-06
Iter: 109 loss: 5.0223648e-06
Iter: 110 loss: 5.01922204e-06
Iter: 111 loss: 5.01920476e-06
Iter: 112 loss: 5.01693785e-06
Iter: 113 loss: 5.02484454e-06
Iter: 114 loss: 5.01630257e-06
Iter: 115 loss: 5.0148e-06
Iter: 116 loss: 5.01673e-06
Iter: 117 loss: 5.0140161e-06
Iter: 118 loss: 5.0119379e-06
Iter: 119 loss: 5.03606179e-06
Iter: 120 loss: 5.01189697e-06
Iter: 121 loss: 5.01082195e-06
Iter: 122 loss: 5.00882652e-06
Iter: 123 loss: 5.05202661e-06
Iter: 124 loss: 5.00880515e-06
Iter: 125 loss: 5.00739225e-06
Iter: 126 loss: 5.00726128e-06
Iter: 127 loss: 5.00616625e-06
Iter: 128 loss: 5.00289434e-06
Iter: 129 loss: 5.01212435e-06
Iter: 130 loss: 5.00114947e-06
Iter: 131 loss: 5.00088845e-06
Iter: 132 loss: 4.99983344e-06
Iter: 133 loss: 4.99850648e-06
Iter: 134 loss: 5.00194255e-06
Iter: 135 loss: 4.99805719e-06
Iter: 136 loss: 4.99727594e-06
Iter: 137 loss: 4.99552971e-06
Iter: 138 loss: 5.01873501e-06
Iter: 139 loss: 4.99538965e-06
Iter: 140 loss: 4.99284943e-06
Iter: 141 loss: 4.99439557e-06
Iter: 142 loss: 4.99116049e-06
Iter: 143 loss: 4.99283578e-06
Iter: 144 loss: 4.9899686e-06
Iter: 145 loss: 4.98907639e-06
Iter: 146 loss: 4.98673171e-06
Iter: 147 loss: 5.00337455e-06
Iter: 148 loss: 4.9862e-06
Iter: 149 loss: 4.98402551e-06
Iter: 150 loss: 4.99910948e-06
Iter: 151 loss: 4.98384179e-06
Iter: 152 loss: 4.9839141e-06
Iter: 153 loss: 4.98336249e-06
Iter: 154 loss: 4.98286454e-06
Iter: 155 loss: 4.98168265e-06
Iter: 156 loss: 4.99623866e-06
Iter: 157 loss: 4.98160716e-06
Iter: 158 loss: 4.98029112e-06
Iter: 159 loss: 4.98977079e-06
Iter: 160 loss: 4.98018289e-06
Iter: 161 loss: 4.97898918e-06
Iter: 162 loss: 4.98329337e-06
Iter: 163 loss: 4.97876817e-06
Iter: 164 loss: 4.97768542e-06
Iter: 165 loss: 4.977549e-06
Iter: 166 loss: 4.97684687e-06
Iter: 167 loss: 4.97548717e-06
Iter: 168 loss: 4.97549672e-06
Iter: 169 loss: 4.97444853e-06
Iter: 170 loss: 4.9736509e-06
Iter: 171 loss: 4.97332576e-06
Iter: 172 loss: 4.97281872e-06
Iter: 173 loss: 4.97154679e-06
Iter: 174 loss: 4.98263307e-06
Iter: 175 loss: 4.97129577e-06
Iter: 176 loss: 4.96966504e-06
Iter: 177 loss: 4.9705759e-06
Iter: 178 loss: 4.96865414e-06
Iter: 179 loss: 4.96772554e-06
Iter: 180 loss: 4.9674818e-06
Iter: 181 loss: 4.96620942e-06
Iter: 182 loss: 4.96555185e-06
Iter: 183 loss: 4.96496796e-06
Iter: 184 loss: 4.96407756e-06
Iter: 185 loss: 4.96356824e-06
Iter: 186 loss: 4.96319262e-06
Iter: 187 loss: 4.96185203e-06
Iter: 188 loss: 4.96643588e-06
Iter: 189 loss: 4.96145367e-06
Iter: 190 loss: 4.96089478e-06
Iter: 191 loss: 4.96065331e-06
Iter: 192 loss: 4.96019675e-06
Iter: 193 loss: 4.95899076e-06
Iter: 194 loss: 4.96782195e-06
Iter: 195 loss: 4.95874974e-06
Iter: 196 loss: 4.95750373e-06
Iter: 197 loss: 4.95750101e-06
Iter: 198 loss: 4.95655604e-06
Iter: 199 loss: 4.95801669e-06
Iter: 200 loss: 4.95613313e-06
Iter: 201 loss: 4.95523045e-06
Iter: 202 loss: 4.95570976e-06
Iter: 203 loss: 4.95468885e-06
Iter: 204 loss: 4.9539326e-06
Iter: 205 loss: 4.95925906e-06
Iter: 206 loss: 4.95384847e-06
Iter: 207 loss: 4.95296081e-06
Iter: 208 loss: 4.95395716e-06
Iter: 209 loss: 4.95249424e-06
Iter: 210 loss: 4.95173481e-06
Iter: 211 loss: 4.950316e-06
Iter: 212 loss: 4.98352256e-06
Iter: 213 loss: 4.95027962e-06
Iter: 214 loss: 4.94913684e-06
Iter: 215 loss: 4.96380426e-06
Iter: 216 loss: 4.94915093e-06
Iter: 217 loss: 4.94801134e-06
Iter: 218 loss: 4.95534641e-06
Iter: 219 loss: 4.94786855e-06
Iter: 220 loss: 4.94723599e-06
Iter: 221 loss: 4.94581764e-06
Iter: 222 loss: 4.96985285e-06
Iter: 223 loss: 4.94578217e-06
Iter: 224 loss: 4.94471715e-06
Iter: 225 loss: 4.94785399e-06
Iter: 226 loss: 4.94437e-06
Iter: 227 loss: 4.94393498e-06
Iter: 228 loss: 4.94366304e-06
Iter: 229 loss: 4.94323331e-06
Iter: 230 loss: 4.94199185e-06
Iter: 231 loss: 4.95227368e-06
Iter: 232 loss: 4.94177402e-06
Iter: 233 loss: 4.94122514e-06
Iter: 234 loss: 4.94107053e-06
Iter: 235 loss: 4.94047345e-06
Iter: 236 loss: 4.9399423e-06
Iter: 237 loss: 4.93978177e-06
Iter: 238 loss: 4.93887228e-06
Iter: 239 loss: 4.94208916e-06
Iter: 240 loss: 4.93868811e-06
Iter: 241 loss: 4.93800781e-06
Iter: 242 loss: 4.94065443e-06
Iter: 243 loss: 4.93784682e-06
Iter: 244 loss: 4.93696734e-06
Iter: 245 loss: 4.93884454e-06
Iter: 246 loss: 4.93662674e-06
Iter: 247 loss: 4.93603147e-06
Iter: 248 loss: 4.93508787e-06
Iter: 249 loss: 4.93509879e-06
Iter: 250 loss: 4.93385642e-06
Iter: 251 loss: 4.93694733e-06
Iter: 252 loss: 4.9334194e-06
Iter: 253 loss: 4.93241532e-06
Iter: 254 loss: 4.93233756e-06
Iter: 255 loss: 4.9319242e-06
Iter: 256 loss: 4.93098378e-06
Iter: 257 loss: 4.94417054e-06
Iter: 258 loss: 4.93093557e-06
Iter: 259 loss: 4.92987e-06
Iter: 260 loss: 4.93016705e-06
Iter: 261 loss: 4.92911386e-06
Iter: 262 loss: 4.92791241e-06
Iter: 263 loss: 4.93387597e-06
Iter: 264 loss: 4.92771369e-06
Iter: 265 loss: 4.92787376e-06
Iter: 266 loss: 4.92722e-06
Iter: 267 loss: 4.92694653e-06
Iter: 268 loss: 4.92612435e-06
Iter: 269 loss: 4.92849085e-06
Iter: 270 loss: 4.92568233e-06
Iter: 271 loss: 4.92471372e-06
Iter: 272 loss: 4.93349307e-06
Iter: 273 loss: 4.92467e-06
Iter: 274 loss: 4.92394156e-06
Iter: 275 loss: 4.93268226e-06
Iter: 276 loss: 4.92390609e-06
Iter: 277 loss: 4.92338586e-06
Iter: 278 loss: 4.92320896e-06
Iter: 279 loss: 4.92291929e-06
Iter: 280 loss: 4.92201298e-06
Iter: 281 loss: 4.9211385e-06
Iter: 282 loss: 4.92093204e-06
Iter: 283 loss: 4.92026811e-06
Iter: 284 loss: 4.93068637e-06
Iter: 285 loss: 4.92027266e-06
Iter: 286 loss: 4.91974606e-06
Iter: 287 loss: 4.92430354e-06
Iter: 288 loss: 4.91970059e-06
Iter: 289 loss: 4.91938681e-06
Iter: 290 loss: 4.91851e-06
Iter: 291 loss: 4.92492109e-06
Iter: 292 loss: 4.91835272e-06
Iter: 293 loss: 4.91827768e-06
Iter: 294 loss: 4.91791661e-06
Iter: 295 loss: 4.9174464e-06
Iter: 296 loss: 4.9165842e-06
Iter: 297 loss: 4.93066909e-06
Iter: 298 loss: 4.91655373e-06
Iter: 299 loss: 4.91558967e-06
Iter: 300 loss: 4.91548235e-06
Iter: 301 loss: 4.91474839e-06
Iter: 302 loss: 4.91548735e-06
Iter: 303 loss: 4.91428364e-06
Iter: 304 loss: 4.91398441e-06
Iter: 305 loss: 4.91334504e-06
Iter: 306 loss: 4.92161735e-06
Iter: 307 loss: 4.91327137e-06
Iter: 308 loss: 4.91270794e-06
Iter: 309 loss: 4.91333913e-06
Iter: 310 loss: 4.91237e-06
Iter: 311 loss: 4.91181027e-06
Iter: 312 loss: 4.92115623e-06
Iter: 313 loss: 4.91178935e-06
Iter: 314 loss: 4.91135734e-06
Iter: 315 loss: 4.91053652e-06
Iter: 316 loss: 4.92513618e-06
Iter: 317 loss: 4.91052288e-06
Iter: 318 loss: 4.90960383e-06
Iter: 319 loss: 4.91625087e-06
Iter: 320 loss: 4.90956518e-06
Iter: 321 loss: 4.90888215e-06
Iter: 322 loss: 4.90823913e-06
Iter: 323 loss: 4.90812863e-06
Iter: 324 loss: 4.90756702e-06
Iter: 325 loss: 4.9075511e-06
Iter: 326 loss: 4.90703e-06
Iter: 327 loss: 4.90891762e-06
Iter: 328 loss: 4.90685534e-06
Iter: 329 loss: 4.90652747e-06
Iter: 330 loss: 4.90569391e-06
Iter: 331 loss: 4.91548144e-06
Iter: 332 loss: 4.90563116e-06
Iter: 333 loss: 4.90511593e-06
Iter: 334 loss: 4.90501088e-06
Iter: 335 loss: 4.90442062e-06
Iter: 336 loss: 4.90359844e-06
Iter: 337 loss: 4.90356615e-06
Iter: 338 loss: 4.90320053e-06
Iter: 339 loss: 4.90315597e-06
Iter: 340 loss: 4.90265711e-06
Iter: 341 loss: 4.9021528e-06
Iter: 342 loss: 4.9021105e-06
Iter: 343 loss: 4.90164166e-06
Iter: 344 loss: 4.90271213e-06
Iter: 345 loss: 4.9014443e-06
Iter: 346 loss: 4.90087768e-06
Iter: 347 loss: 4.90488128e-06
Iter: 348 loss: 4.90080174e-06
Iter: 349 loss: 4.90046568e-06
Iter: 350 loss: 4.89983358e-06
Iter: 351 loss: 4.91039236e-06
Iter: 352 loss: 4.8998e-06
Iter: 353 loss: 4.898935e-06
Iter: 354 loss: 4.90484763e-06
Iter: 355 loss: 4.89884496e-06
Iter: 356 loss: 4.89808463e-06
Iter: 357 loss: 4.8992647e-06
Iter: 358 loss: 4.89775084e-06
Iter: 359 loss: 4.89723789e-06
Iter: 360 loss: 4.89997865e-06
Iter: 361 loss: 4.89717786e-06
Iter: 362 loss: 4.89664399e-06
Iter: 363 loss: 4.89993681e-06
Iter: 364 loss: 4.89655395e-06
Iter: 365 loss: 4.89623244e-06
Iter: 366 loss: 4.89544618e-06
Iter: 367 loss: 4.90566026e-06
Iter: 368 loss: 4.89541162e-06
Iter: 369 loss: 4.89454305e-06
Iter: 370 loss: 4.89564e-06
Iter: 371 loss: 4.89410968e-06
Iter: 372 loss: 4.89419381e-06
Iter: 373 loss: 4.89365129e-06
Iter: 374 loss: 4.89333706e-06
Iter: 375 loss: 4.8925549e-06
Iter: 376 loss: 4.90201865e-06
Iter: 377 loss: 4.89247759e-06
Iter: 378 loss: 4.89243121e-06
Iter: 379 loss: 4.89215927e-06
Iter: 380 loss: 4.89191098e-06
Iter: 381 loss: 4.89138847e-06
Iter: 382 loss: 4.90068442e-06
Iter: 383 loss: 4.89139529e-06
Iter: 384 loss: 4.89088325e-06
Iter: 385 loss: 4.89007743e-06
Iter: 386 loss: 4.89008107e-06
Iter: 387 loss: 4.88977548e-06
Iter: 388 loss: 4.88943397e-06
Iter: 389 loss: 4.88911064e-06
Iter: 390 loss: 4.88859496e-06
Iter: 391 loss: 4.88862e-06
Iter: 392 loss: 4.88804517e-06
Iter: 393 loss: 4.88990963e-06
Iter: 394 loss: 4.88787146e-06
Iter: 395 loss: 4.88735077e-06
Iter: 396 loss: 4.88869364e-06
Iter: 397 loss: 4.88712158e-06
Iter: 398 loss: 4.88670275e-06
Iter: 399 loss: 4.89297872e-06
Iter: 400 loss: 4.88667683e-06
Iter: 401 loss: 4.88648902e-06
Iter: 402 loss: 4.88597243e-06
Iter: 403 loss: 4.88986e-06
Iter: 404 loss: 4.88587739e-06
Iter: 405 loss: 4.88525711e-06
Iter: 406 loss: 4.88985143e-06
Iter: 407 loss: 4.88522255e-06
Iter: 408 loss: 4.88456044e-06
Iter: 409 loss: 4.88565729e-06
Iter: 410 loss: 4.8842312e-06
Iter: 411 loss: 4.88375372e-06
Iter: 412 loss: 4.88315891e-06
Iter: 413 loss: 4.88312435e-06
Iter: 414 loss: 4.88326486e-06
Iter: 415 loss: 4.88278056e-06
Iter: 416 loss: 4.88256819e-06
Iter: 417 loss: 4.88205706e-06
Iter: 418 loss: 4.88413662e-06
Iter: 419 loss: 4.88183514e-06
Iter: 420 loss: 4.88151818e-06
Iter: 421 loss: 4.88142814e-06
Iter: 422 loss: 4.88114256e-06
Iter: 423 loss: 4.88082787e-06
Iter: 424 loss: 4.88074147e-06
Iter: 425 loss: 4.8803181e-06
Iter: 426 loss: 4.87979378e-06
Iter: 427 loss: 4.87973e-06
Iter: 428 loss: 4.87901525e-06
Iter: 429 loss: 4.88979731e-06
Iter: 430 loss: 4.87900888e-06
Iter: 431 loss: 4.8785223e-06
Iter: 432 loss: 4.87973466e-06
Iter: 433 loss: 4.87834541e-06
Iter: 434 loss: 4.87788384e-06
Iter: 435 loss: 4.88034038e-06
Iter: 436 loss: 4.87779607e-06
Iter: 437 loss: 4.87747775e-06
Iter: 438 loss: 4.87685065e-06
Iter: 439 loss: 4.88734531e-06
Iter: 440 loss: 4.87682655e-06
Iter: 441 loss: 4.87687066e-06
Iter: 442 loss: 4.87648822e-06
Iter: 443 loss: 4.87621855e-06
Iter: 444 loss: 4.87567104e-06
Iter: 445 loss: 4.88797468e-06
Iter: 446 loss: 4.8757e-06
Iter: 447 loss: 4.87518e-06
Iter: 448 loss: 4.87465832e-06
Iter: 449 loss: 4.87462648e-06
Iter: 450 loss: 4.87435318e-06
Iter: 451 loss: 4.87418311e-06
Iter: 452 loss: 4.87371926e-06
Iter: 453 loss: 4.87391662e-06
Iter: 454 loss: 4.87342413e-06
Iter: 455 loss: 4.87306534e-06
Iter: 456 loss: 4.87341322e-06
Iter: 457 loss: 4.87289253e-06
Iter: 458 loss: 4.87229863e-06
Iter: 459 loss: 4.87333955e-06
Iter: 460 loss: 4.87200577e-06
Iter: 461 loss: 4.87162652e-06
Iter: 462 loss: 4.87111447e-06
Iter: 463 loss: 4.87106354e-06
Iter: 464 loss: 4.87078159e-06
Iter: 465 loss: 4.87072293e-06
Iter: 466 loss: 4.87041325e-06
Iter: 467 loss: 4.87036868e-06
Iter: 468 loss: 4.87013131e-06
Iter: 469 loss: 4.86966383e-06
Iter: 470 loss: 4.87051329e-06
Iter: 471 loss: 4.86949102e-06
Iter: 472 loss: 4.86904219e-06
Iter: 473 loss: 4.86887711e-06
Iter: 474 loss: 4.86860608e-06
Iter: 475 loss: 4.86797944e-06
Iter: 476 loss: 4.86800855e-06
Iter: 477 loss: 4.86751469e-06
Iter: 478 loss: 4.86773843e-06
Iter: 479 loss: 4.86714362e-06
Iter: 480 loss: 4.86695353e-06
Iter: 481 loss: 4.86650742e-06
Iter: 482 loss: 4.87047237e-06
Iter: 483 loss: 4.86641193e-06
Iter: 484 loss: 4.86597219e-06
Iter: 485 loss: 4.86812405e-06
Iter: 486 loss: 4.86592126e-06
Iter: 487 loss: 4.8653983e-06
Iter: 488 loss: 4.86973886e-06
Iter: 489 loss: 4.86536737e-06
Iter: 490 loss: 4.86512727e-06
Iter: 491 loss: 4.86454974e-06
Iter: 492 loss: 4.8699585e-06
Iter: 493 loss: 4.86436511e-06
Iter: 494 loss: 4.86423414e-06
Iter: 495 loss: 4.86402041e-06
Iter: 496 loss: 4.86374392e-06
Iter: 497 loss: 4.86315093e-06
Iter: 498 loss: 4.87054604e-06
Iter: 499 loss: 4.8631523e-06
Iter: 500 loss: 4.86265935e-06
Iter: 501 loss: 4.86699e-06
Iter: 502 loss: 4.86264344e-06
Iter: 503 loss: 4.86220597e-06
Iter: 504 loss: 4.86481804e-06
Iter: 505 loss: 4.86214049e-06
Iter: 506 loss: 4.86192221e-06
Iter: 507 loss: 4.8615093e-06
Iter: 508 loss: 4.86792032e-06
Iter: 509 loss: 4.86147474e-06
Iter: 510 loss: 4.860849e-06
Iter: 511 loss: 4.86497e-06
Iter: 512 loss: 4.86079125e-06
Iter: 513 loss: 4.86021099e-06
Iter: 514 loss: 4.86080717e-06
Iter: 515 loss: 4.85989631e-06
Iter: 516 loss: 4.8594693e-06
Iter: 517 loss: 4.86166346e-06
Iter: 518 loss: 4.8594311e-06
Iter: 519 loss: 4.85877626e-06
Iter: 520 loss: 4.86043155e-06
Iter: 521 loss: 4.85856344e-06
Iter: 522 loss: 4.8583e-06
Iter: 523 loss: 4.85957298e-06
Iter: 524 loss: 4.85826786e-06
Iter: 525 loss: 4.85795044e-06
Iter: 526 loss: 4.85846385e-06
Iter: 527 loss: 4.85780402e-06
Iter: 528 loss: 4.85753753e-06
Iter: 529 loss: 4.85699729e-06
Iter: 530 loss: 4.86144472e-06
Iter: 531 loss: 4.85684723e-06
Iter: 532 loss: 4.85636883e-06
Iter: 533 loss: 4.85631335e-06
Iter: 534 loss: 4.85581586e-06
Iter: 535 loss: 4.85890268e-06
Iter: 536 loss: 4.85576402e-06
Iter: 537 loss: 4.85553483e-06
Iter: 538 loss: 4.85492637e-06
Iter: 539 loss: 4.86088e-06
Iter: 540 loss: 4.8548618e-06
Iter: 541 loss: 4.85439887e-06
Iter: 542 loss: 4.85440478e-06
Iter: 543 loss: 4.85390228e-06
Iter: 544 loss: 4.85535475e-06
Iter: 545 loss: 4.85374494e-06
Iter: 546 loss: 4.85345163e-06
Iter: 547 loss: 4.85286637e-06
Iter: 548 loss: 4.86608587e-06
Iter: 549 loss: 4.85287273e-06
Iter: 550 loss: 4.85220653e-06
Iter: 551 loss: 4.85675e-06
Iter: 552 loss: 4.85207647e-06
Iter: 553 loss: 4.85151941e-06
Iter: 554 loss: 4.85359578e-06
Iter: 555 loss: 4.85134751e-06
Iter: 556 loss: 4.85113105e-06
Iter: 557 loss: 4.85108194e-06
Iter: 558 loss: 4.85084865e-06
Iter: 559 loss: 4.85054306e-06
Iter: 560 loss: 4.8505e-06
Iter: 561 loss: 4.85020337e-06
Iter: 562 loss: 4.8518832e-06
Iter: 563 loss: 4.85013788e-06
Iter: 564 loss: 4.84969769e-06
Iter: 565 loss: 4.85021428e-06
Iter: 566 loss: 4.84941575e-06
Iter: 567 loss: 4.84912653e-06
Iter: 568 loss: 4.84865632e-06
Iter: 569 loss: 4.84866814e-06
Iter: 570 loss: 4.84818474e-06
Iter: 571 loss: 4.85189503e-06
Iter: 572 loss: 4.84815473e-06
Iter: 573 loss: 4.84762541e-06
Iter: 574 loss: 4.85095188e-06
Iter: 575 loss: 4.84758948e-06
Iter: 576 loss: 4.8472989e-06
Iter: 577 loss: 4.84680822e-06
Iter: 578 loss: 4.85744249e-06
Iter: 579 loss: 4.8468255e-06
Iter: 580 loss: 4.84632437e-06
Iter: 581 loss: 4.84659131e-06
Iter: 582 loss: 4.84599559e-06
Iter: 583 loss: 4.84566044e-06
Iter: 584 loss: 4.84552038e-06
Iter: 585 loss: 4.84532302e-06
Iter: 586 loss: 4.84487873e-06
Iter: 587 loss: 4.85142482e-06
Iter: 588 loss: 4.84480552e-06
Iter: 589 loss: 4.84439261e-06
Iter: 590 loss: 4.84490283e-06
Iter: 591 loss: 4.84414386e-06
Iter: 592 loss: 4.84387101e-06
Iter: 593 loss: 4.84382736e-06
Iter: 594 loss: 4.84354496e-06
Iter: 595 loss: 4.84320844e-06
Iter: 596 loss: 4.84319708e-06
Iter: 597 loss: 4.84288103e-06
Iter: 598 loss: 4.84809198e-06
Iter: 599 loss: 4.84289376e-06
Iter: 600 loss: 4.84262955e-06
Iter: 601 loss: 4.84249904e-06
Iter: 602 loss: 4.84234579e-06
Iter: 603 loss: 4.84191787e-06
Iter: 604 loss: 4.8418915e-06
Iter: 605 loss: 4.84157681e-06
Iter: 606 loss: 4.84115662e-06
Iter: 607 loss: 4.84342945e-06
Iter: 608 loss: 4.84107295e-06
Iter: 609 loss: 4.84063185e-06
Iter: 610 loss: 4.84343036e-06
Iter: 611 loss: 4.84059728e-06
Iter: 612 loss: 4.84033444e-06
Iter: 613 loss: 4.8396505e-06
Iter: 614 loss: 4.84409156e-06
Iter: 615 loss: 4.83948224e-06
Iter: 616 loss: 4.83858776e-06
Iter: 617 loss: 4.84538896e-06
Iter: 618 loss: 4.83853546e-06
Iter: 619 loss: 4.83824169e-06
Iter: 620 loss: 4.83816348e-06
Iter: 621 loss: 4.83794429e-06
Iter: 622 loss: 4.83732947e-06
Iter: 623 loss: 4.8406223e-06
Iter: 624 loss: 4.83716667e-06
Iter: 625 loss: 4.83656368e-06
Iter: 626 loss: 4.84010616e-06
Iter: 627 loss: 4.8365182e-06
Iter: 628 loss: 4.83636086e-06
Iter: 629 loss: 4.83627218e-06
Iter: 630 loss: 4.8360107e-06
Iter: 631 loss: 4.83530039e-06
Iter: 632 loss: 4.83955091e-06
Iter: 633 loss: 4.83511485e-06
Iter: 634 loss: 4.83489248e-06
Iter: 635 loss: 4.83467375e-06
Iter: 636 loss: 4.83429676e-06
Iter: 637 loss: 4.83369331e-06
Iter: 638 loss: 4.83370513e-06
Iter: 639 loss: 4.83325312e-06
Iter: 640 loss: 4.83369877e-06
Iter: 641 loss: 4.83294298e-06
Iter: 642 loss: 4.83258827e-06
Iter: 643 loss: 4.83256144e-06
Iter: 644 loss: 4.83228769e-06
Iter: 645 loss: 4.83209897e-06
Iter: 646 loss: 4.83199e-06
Iter: 647 loss: 4.8315469e-06
Iter: 648 loss: 4.83208942e-06
Iter: 649 loss: 4.83131407e-06
Iter: 650 loss: 4.83083477e-06
Iter: 651 loss: 4.83015583e-06
Iter: 652 loss: 4.83009899e-06
Iter: 653 loss: 4.82958512e-06
Iter: 654 loss: 4.82957284e-06
Iter: 655 loss: 4.82901851e-06
Iter: 656 loss: 4.83045324e-06
Iter: 657 loss: 4.8288266e-06
Iter: 658 loss: 4.82847327e-06
Iter: 659 loss: 4.82781707e-06
Iter: 660 loss: 4.84131579e-06
Iter: 661 loss: 4.82782934e-06
Iter: 662 loss: 4.82723772e-06
Iter: 663 loss: 4.83358599e-06
Iter: 664 loss: 4.8272268e-06
Iter: 665 loss: 4.82666383e-06
Iter: 666 loss: 4.830531e-06
Iter: 667 loss: 4.82658697e-06
Iter: 668 loss: 4.82635551e-06
Iter: 669 loss: 4.82589076e-06
Iter: 670 loss: 4.83655e-06
Iter: 671 loss: 4.82585438e-06
Iter: 672 loss: 4.82570067e-06
Iter: 673 loss: 4.8255547e-06
Iter: 674 loss: 4.82530868e-06
Iter: 675 loss: 4.82462701e-06
Iter: 676 loss: 4.82800669e-06
Iter: 677 loss: 4.82439918e-06
Iter: 678 loss: 4.82379801e-06
Iter: 679 loss: 4.82587438e-06
Iter: 680 loss: 4.82362475e-06
Iter: 681 loss: 4.82300857e-06
Iter: 682 loss: 4.82644282e-06
Iter: 683 loss: 4.82291352e-06
Iter: 684 loss: 4.82232554e-06
Iter: 685 loss: 4.82636e-06
Iter: 686 loss: 4.82233372e-06
Iter: 687 loss: 4.82178439e-06
Iter: 688 loss: 4.82272117e-06
Iter: 689 loss: 4.82155247e-06
Iter: 690 loss: 4.82111591e-06
Iter: 691 loss: 4.82078576e-06
Iter: 692 loss: 4.82061296e-06
Iter: 693 loss: 4.82018277e-06
Iter: 694 loss: 4.82463656e-06
Iter: 695 loss: 4.8201282e-06
Iter: 696 loss: 4.81961251e-06
Iter: 697 loss: 4.82043379e-06
Iter: 698 loss: 4.8192278e-06
Iter: 699 loss: 4.81892539e-06
Iter: 700 loss: 4.81843199e-06
Iter: 701 loss: 4.81842926e-06
Iter: 702 loss: 4.817648e-06
Iter: 703 loss: 4.81810048e-06
Iter: 704 loss: 4.81718416e-06
Iter: 705 loss: 4.81740153e-06
Iter: 706 loss: 4.81677125e-06
Iter: 707 loss: 4.81654024e-06
Iter: 708 loss: 4.81602228e-06
Iter: 709 loss: 4.82368432e-06
Iter: 710 loss: 4.81599091e-06
Iter: 711 loss: 4.81576535e-06
Iter: 712 loss: 4.81566485e-06
Iter: 713 loss: 4.81543611e-06
Iter: 714 loss: 4.81472216e-06
Iter: 715 loss: 4.81891948e-06
Iter: 716 loss: 4.81457846e-06
Iter: 717 loss: 4.81383358e-06
Iter: 718 loss: 4.81377674e-06
Iter: 719 loss: 4.81333245e-06
Iter: 720 loss: 4.81235566e-06
Iter: 721 loss: 4.82086671e-06
Iter: 722 loss: 4.81227471e-06
Iter: 723 loss: 4.81149755e-06
Iter: 724 loss: 4.81639e-06
Iter: 725 loss: 4.81140523e-06
Iter: 726 loss: 4.81081406e-06
Iter: 727 loss: 4.8111192e-06
Iter: 728 loss: 4.8103966e-06
Iter: 729 loss: 4.81015695e-06
Iter: 730 loss: 4.8099937e-06
Iter: 731 loss: 4.80970903e-06
Iter: 732 loss: 4.80892459e-06
Iter: 733 loss: 4.8165175e-06
Iter: 734 loss: 4.80883864e-06
Iter: 735 loss: 4.80823928e-06
Iter: 736 loss: 4.81576808e-06
Iter: 737 loss: 4.808222e-06
Iter: 738 loss: 4.80766221e-06
Iter: 739 loss: 4.81215693e-06
Iter: 740 loss: 4.80764629e-06
Iter: 741 loss: 4.80730387e-06
Iter: 742 loss: 4.80671224e-06
Iter: 743 loss: 4.80670633e-06
Iter: 744 loss: 4.8061338e-06
Iter: 745 loss: 4.80610379e-06
Iter: 746 loss: 4.80589551e-06
Iter: 747 loss: 4.80552626e-06
Iter: 748 loss: 4.80553763e-06
Iter: 749 loss: 4.80490053e-06
Iter: 750 loss: 4.8085958e-06
Iter: 751 loss: 4.80483141e-06
Iter: 752 loss: 4.80447125e-06
Iter: 753 loss: 4.80348444e-06
Iter: 754 loss: 4.8104489e-06
Iter: 755 loss: 4.80327071e-06
Iter: 756 loss: 4.80226163e-06
Iter: 757 loss: 4.80818e-06
Iter: 758 loss: 4.8021393e-06
Iter: 759 loss: 4.80147855e-06
Iter: 760 loss: 4.80475819e-06
Iter: 761 loss: 4.80141443e-06
Iter: 762 loss: 4.80070048e-06
Iter: 763 loss: 4.80464314e-06
Iter: 764 loss: 4.80064136e-06
Iter: 765 loss: 4.80022481e-06
Iter: 766 loss: 4.80466679e-06
Iter: 767 loss: 4.80018116e-06
Iter: 768 loss: 4.79983555e-06
Iter: 769 loss: 4.79923938e-06
Iter: 770 loss: 4.79924347e-06
Iter: 771 loss: 4.79865685e-06
Iter: 772 loss: 4.80203835e-06
Iter: 773 loss: 4.79858136e-06
Iter: 774 loss: 4.79777646e-06
Iter: 775 loss: 4.79760456e-06
Iter: 776 loss: 4.79707251e-06
Iter: 777 loss: 4.7966796e-06
Iter: 778 loss: 4.79664868e-06
Iter: 779 loss: 4.7962626e-06
Iter: 780 loss: 4.79598566e-06
Iter: 781 loss: 4.79588243e-06
Iter: 782 loss: 4.79556093e-06
Iter: 783 loss: 4.79813116e-06
Iter: 784 loss: 4.79549726e-06
Iter: 785 loss: 4.79502842e-06
Iter: 786 loss: 4.79433675e-06
Iter: 787 loss: 4.79432947e-06
Iter: 788 loss: 4.79376104e-06
Iter: 789 loss: 4.79341543e-06
Iter: 790 loss: 4.79314167e-06
Iter: 791 loss: 4.7921726e-06
Iter: 792 loss: 4.79388e-06
Iter: 793 loss: 4.79176924e-06
Iter: 794 loss: 4.79115897e-06
Iter: 795 loss: 4.79116807e-06
Iter: 796 loss: 4.79067603e-06
Iter: 797 loss: 4.79442224e-06
Iter: 798 loss: 4.7906683e-06
Iter: 799 loss: 4.79026312e-06
Iter: 800 loss: 4.79104938e-06
Iter: 801 loss: 4.79013e-06
Iter: 802 loss: 4.78966467e-06
Iter: 803 loss: 4.78895799e-06
Iter: 804 loss: 4.78897164e-06
Iter: 805 loss: 4.78841548e-06
Iter: 806 loss: 4.78836546e-06
Iter: 807 loss: 4.7879189e-06
Iter: 808 loss: 4.78705897e-06
Iter: 809 loss: 4.80301969e-06
Iter: 810 loss: 4.78699076e-06
Iter: 811 loss: 4.78662605e-06
Iter: 812 loss: 4.78648599e-06
Iter: 813 loss: 4.7861522e-06
Iter: 814 loss: 4.78531365e-06
Iter: 815 loss: 4.79079335e-06
Iter: 816 loss: 4.78510901e-06
Iter: 817 loss: 4.78488619e-06
Iter: 818 loss: 4.78462425e-06
Iter: 819 loss: 4.78426045e-06
Iter: 820 loss: 4.78362517e-06
Iter: 821 loss: 4.79407117e-06
Iter: 822 loss: 4.78357e-06
Iter: 823 loss: 4.78284301e-06
Iter: 824 loss: 4.78211587e-06
Iter: 825 loss: 4.78195579e-06
Iter: 826 loss: 4.78094171e-06
Iter: 827 loss: 4.78270886e-06
Iter: 828 loss: 4.7805e-06
Iter: 829 loss: 4.78016682e-06
Iter: 830 loss: 4.78002539e-06
Iter: 831 loss: 4.77956564e-06
Iter: 832 loss: 4.77944468e-06
Iter: 833 loss: 4.77916183e-06
Iter: 834 loss: 4.7785561e-06
Iter: 835 loss: 4.7802514e-06
Iter: 836 loss: 4.77840513e-06
Iter: 837 loss: 4.77784306e-06
Iter: 838 loss: 4.77895583e-06
Iter: 839 loss: 4.7775543e-06
Iter: 840 loss: 4.77697085e-06
Iter: 841 loss: 4.78198353e-06
Iter: 842 loss: 4.77692811e-06
Iter: 843 loss: 4.77655703e-06
Iter: 844 loss: 4.77622689e-06
Iter: 845 loss: 4.77616823e-06
Iter: 846 loss: 4.77533922e-06
Iter: 847 loss: 4.7796666e-06
Iter: 848 loss: 4.77519052e-06
Iter: 849 loss: 4.77490494e-06
Iter: 850 loss: 4.77488038e-06
Iter: 851 loss: 4.77463027e-06
Iter: 852 loss: 4.77407593e-06
Iter: 853 loss: 4.77744561e-06
Iter: 854 loss: 4.77397e-06
Iter: 855 loss: 4.77361891e-06
Iter: 856 loss: 4.77268713e-06
Iter: 857 loss: 4.7784979e-06
Iter: 858 loss: 4.77240155e-06
Iter: 859 loss: 4.77128469e-06
Iter: 860 loss: 4.77996764e-06
Iter: 861 loss: 4.77118556e-06
Iter: 862 loss: 4.77026424e-06
Iter: 863 loss: 4.77154117e-06
Iter: 864 loss: 4.76979494e-06
Iter: 865 loss: 4.76955029e-06
Iter: 866 loss: 4.76931928e-06
Iter: 867 loss: 4.76888772e-06
Iter: 868 loss: 4.76808145e-06
Iter: 869 loss: 4.78739048e-06
Iter: 870 loss: 4.76806281e-06
Iter: 871 loss: 4.76737705e-06
Iter: 872 loss: 4.76867717e-06
Iter: 873 loss: 4.76705645e-06
Iter: 874 loss: 4.7666249e-06
Iter: 875 loss: 4.76653895e-06
Iter: 876 loss: 4.76610103e-06
Iter: 877 loss: 4.76542118e-06
Iter: 878 loss: 4.76540936e-06
Iter: 879 loss: 4.76471e-06
Iter: 880 loss: 4.77326466e-06
Iter: 881 loss: 4.76472815e-06
Iter: 882 loss: 4.76428932e-06
Iter: 883 loss: 4.76707373e-06
Iter: 884 loss: 4.7642452e-06
Iter: 885 loss: 4.76395326e-06
Iter: 886 loss: 4.76354217e-06
Iter: 887 loss: 4.76355899e-06
Iter: 888 loss: 4.76305831e-06
Iter: 889 loss: 4.76980904e-06
Iter: 890 loss: 4.76307559e-06
Iter: 891 loss: 4.76281639e-06
Iter: 892 loss: 4.76212881e-06
Iter: 893 loss: 4.76751666e-06
Iter: 894 loss: 4.76196283e-06
Iter: 895 loss: 4.7610838e-06
Iter: 896 loss: 4.76112473e-06
Iter: 897 loss: 4.7604135e-06
Iter: 898 loss: 4.75924116e-06
Iter: 899 loss: 4.76853165e-06
Iter: 900 loss: 4.75915e-06
Iter: 901 loss: 4.75917795e-06
Iter: 902 loss: 4.7588519e-06
Iter: 903 loss: 4.75857814e-06
Iter: 904 loss: 4.75795423e-06
Iter: 905 loss: 4.76683408e-06
Iter: 906 loss: 4.75796151e-06
Iter: 907 loss: 4.75737625e-06
Iter: 908 loss: 4.75946e-06
Iter: 909 loss: 4.75719207e-06
Iter: 910 loss: 4.75653087e-06
Iter: 911 loss: 4.76263176e-06
Iter: 912 loss: 4.75649904e-06
Iter: 913 loss: 4.75613479e-06
Iter: 914 loss: 4.75587649e-06
Iter: 915 loss: 4.75568777e-06
Iter: 916 loss: 4.75515117e-06
Iter: 917 loss: 4.76223249e-06
Iter: 918 loss: 4.7551448e-06
Iter: 919 loss: 4.7546564e-06
Iter: 920 loss: 4.75452271e-06
Iter: 921 loss: 4.75424e-06
Iter: 922 loss: 4.75374145e-06
Iter: 923 loss: 4.75622437e-06
Iter: 924 loss: 4.75362413e-06
Iter: 925 loss: 4.75306661e-06
Iter: 926 loss: 4.75482e-06
Iter: 927 loss: 4.75287e-06
Iter: 928 loss: 4.75260777e-06
Iter: 929 loss: 4.75191246e-06
Iter: 930 loss: 4.76114e-06
Iter: 931 loss: 4.75187699e-06
Iter: 932 loss: 4.75082288e-06
Iter: 933 loss: 4.75103843e-06
Iter: 934 loss: 4.75005345e-06
Iter: 935 loss: 4.74909393e-06
Iter: 936 loss: 4.75750494e-06
Iter: 937 loss: 4.74901663e-06
Iter: 938 loss: 4.74877834e-06
Iter: 939 loss: 4.74862236e-06
Iter: 940 loss: 4.74831e-06
Iter: 941 loss: 4.74759554e-06
Iter: 942 loss: 4.75481784e-06
Iter: 943 loss: 4.74751141e-06
Iter: 944 loss: 4.74705621e-06
Iter: 945 loss: 4.74706e-06
Iter: 946 loss: 4.74651961e-06
Iter: 947 loss: 4.74681838e-06
Iter: 948 loss: 4.74621265e-06
Iter: 949 loss: 4.7456806e-06
Iter: 950 loss: 4.7458575e-06
Iter: 951 loss: 4.74529133e-06
Iter: 952 loss: 4.74442459e-06
Iter: 953 loss: 4.75014e-06
Iter: 954 loss: 4.74438866e-06
Iter: 955 loss: 4.74378794e-06
Iter: 956 loss: 4.74448279e-06
Iter: 957 loss: 4.74353601e-06
Iter: 958 loss: 4.74312128e-06
Iter: 959 loss: 4.74709122e-06
Iter: 960 loss: 4.74310309e-06
Iter: 961 loss: 4.74274384e-06
Iter: 962 loss: 4.74249464e-06
Iter: 963 loss: 4.74234457e-06
Iter: 964 loss: 4.74183844e-06
Iter: 965 loss: 4.7412741e-06
Iter: 966 loss: 4.74116177e-06
Iter: 967 loss: 4.74035232e-06
Iter: 968 loss: 4.74118315e-06
Iter: 969 loss: 4.7399335e-06
Iter: 970 loss: 4.73872115e-06
Iter: 971 loss: 4.74061744e-06
Iter: 972 loss: 4.73811269e-06
Iter: 973 loss: 4.73738783e-06
Iter: 974 loss: 4.74897024e-06
Iter: 975 loss: 4.73740329e-06
Iter: 976 loss: 4.73684577e-06
Iter: 977 loss: 4.7368394e-06
Iter: 978 loss: 4.73657747e-06
Iter: 979 loss: 4.73588261e-06
Iter: 980 loss: 4.74111857e-06
Iter: 981 loss: 4.73566433e-06
Iter: 982 loss: 4.73533237e-06
Iter: 983 loss: 4.73521504e-06
Iter: 984 loss: 4.73470845e-06
Iter: 985 loss: 4.7341523e-06
Iter: 986 loss: 4.73405089e-06
Iter: 987 loss: 4.73359796e-06
Iter: 988 loss: 4.73693217e-06
Iter: 989 loss: 4.73353612e-06
Iter: 990 loss: 4.73290129e-06
Iter: 991 loss: 4.73248883e-06
Iter: 992 loss: 4.73220689e-06
Iter: 993 loss: 4.73186947e-06
Iter: 994 loss: 4.73186674e-06
Iter: 995 loss: 4.73153341e-06
Iter: 996 loss: 4.73118962e-06
Iter: 997 loss: 4.73109867e-06
Iter: 998 loss: 4.73059299e-06
Iter: 999 loss: 4.72983629e-06
Iter: 1000 loss: 4.72980309e-06
Iter: 1001 loss: 4.72904503e-06
Iter: 1002 loss: 4.72904367e-06
Iter: 1003 loss: 4.72845932e-06
Iter: 1004 loss: 4.72832835e-06
Iter: 1005 loss: 4.72796364e-06
Iter: 1006 loss: 4.72721376e-06
Iter: 1007 loss: 4.72874854e-06
Iter: 1008 loss: 4.72692818e-06
Iter: 1009 loss: 4.72669944e-06
Iter: 1010 loss: 4.72658894e-06
Iter: 1011 loss: 4.72618785e-06
Iter: 1012 loss: 4.72550937e-06
Iter: 1013 loss: 4.73637556e-06
Iter: 1014 loss: 4.72548709e-06
Iter: 1015 loss: 4.72478769e-06
Iter: 1016 loss: 4.72547254e-06
Iter: 1017 loss: 4.72445936e-06
Iter: 1018 loss: 4.72368129e-06
Iter: 1019 loss: 4.723659e-06
Iter: 1020 loss: 4.72335068e-06
Iter: 1021 loss: 4.72274951e-06
Iter: 1022 loss: 4.72274405e-06
Iter: 1023 loss: 4.72255579e-06
Iter: 1024 loss: 4.72242073e-06
Iter: 1025 loss: 4.72222337e-06
Iter: 1026 loss: 4.7217145e-06
Iter: 1027 loss: 4.72470356e-06
Iter: 1028 loss: 4.72153442e-06
Iter: 1029 loss: 4.7209669e-06
Iter: 1030 loss: 4.72097099e-06
Iter: 1031 loss: 4.72059673e-06
Iter: 1032 loss: 4.72004467e-06
Iter: 1033 loss: 4.72001875e-06
Iter: 1034 loss: 4.71936664e-06
Iter: 1035 loss: 4.72217653e-06
Iter: 1036 loss: 4.71920657e-06
Iter: 1037 loss: 4.71849489e-06
Iter: 1038 loss: 4.71795192e-06
Iter: 1039 loss: 4.71768271e-06
Iter: 1040 loss: 4.71688054e-06
Iter: 1041 loss: 4.72268266e-06
Iter: 1042 loss: 4.71677231e-06
Iter: 1043 loss: 4.71639169e-06
Iter: 1044 loss: 4.71630392e-06
Iter: 1045 loss: 4.71597468e-06
Iter: 1046 loss: 4.71509202e-06
Iter: 1047 loss: 4.72047395e-06
Iter: 1048 loss: 4.71487692e-06
Iter: 1049 loss: 4.71413932e-06
Iter: 1050 loss: 4.72299098e-06
Iter: 1051 loss: 4.71412932e-06
Iter: 1052 loss: 4.713419e-06
Iter: 1053 loss: 4.71818748e-06
Iter: 1054 loss: 4.71334806e-06
Iter: 1055 loss: 4.71296516e-06
Iter: 1056 loss: 4.71253e-06
Iter: 1057 loss: 4.71249405e-06
Iter: 1058 loss: 4.71182284e-06
Iter: 1059 loss: 4.72138208e-06
Iter: 1060 loss: 4.71180647e-06
Iter: 1061 loss: 4.71149815e-06
Iter: 1062 loss: 4.71083149e-06
Iter: 1063 loss: 4.72147e-06
Iter: 1064 loss: 4.71083831e-06
Iter: 1065 loss: 4.71023577e-06
Iter: 1066 loss: 4.71021758e-06
Iter: 1067 loss: 4.70988e-06
Iter: 1068 loss: 4.70905661e-06
Iter: 1069 loss: 4.71706335e-06
Iter: 1070 loss: 4.70894338e-06
Iter: 1071 loss: 4.70799932e-06
Iter: 1072 loss: 4.71392423e-06
Iter: 1073 loss: 4.70783152e-06
Iter: 1074 loss: 4.70706e-06
Iter: 1075 loss: 4.70892519e-06
Iter: 1076 loss: 4.70673149e-06
Iter: 1077 loss: 4.70604664e-06
Iter: 1078 loss: 4.70505165e-06
Iter: 1079 loss: 4.70500345e-06
Iter: 1080 loss: 4.70514806e-06
Iter: 1081 loss: 4.70453142e-06
Iter: 1082 loss: 4.7040221e-06
Iter: 1083 loss: 4.70396662e-06
Iter: 1084 loss: 4.70359601e-06
Iter: 1085 loss: 4.70299074e-06
Iter: 1086 loss: 4.70195619e-06
Iter: 1087 loss: 4.70195846e-06
Iter: 1088 loss: 4.70237637e-06
Iter: 1089 loss: 4.70146506e-06
Iter: 1090 loss: 4.70117402e-06
Iter: 1091 loss: 4.70054829e-06
Iter: 1092 loss: 4.71208705e-06
Iter: 1093 loss: 4.70053874e-06
Iter: 1094 loss: 4.69997576e-06
Iter: 1095 loss: 4.69994029e-06
Iter: 1096 loss: 4.69962288e-06
Iter: 1097 loss: 4.69886027e-06
Iter: 1098 loss: 4.70754276e-06
Iter: 1099 loss: 4.69880479e-06
Iter: 1100 loss: 4.69816632e-06
Iter: 1101 loss: 4.69815313e-06
Iter: 1102 loss: 4.69774159e-06
Iter: 1103 loss: 4.69691349e-06
Iter: 1104 loss: 4.71127714e-06
Iter: 1105 loss: 4.69687893e-06
Iter: 1106 loss: 4.69602037e-06
Iter: 1107 loss: 4.69655515e-06
Iter: 1108 loss: 4.69540919e-06
Iter: 1109 loss: 4.69479664e-06
Iter: 1110 loss: 4.69912129e-06
Iter: 1111 loss: 4.69472116e-06
Iter: 1112 loss: 4.69411225e-06
Iter: 1113 loss: 4.6946011e-06
Iter: 1114 loss: 4.69374709e-06
Iter: 1115 loss: 4.69325187e-06
Iter: 1116 loss: 4.69953648e-06
Iter: 1117 loss: 4.69322413e-06
Iter: 1118 loss: 4.69274528e-06
Iter: 1119 loss: 4.69222141e-06
Iter: 1120 loss: 4.69212819e-06
Iter: 1121 loss: 4.69150473e-06
Iter: 1122 loss: 4.69826728e-06
Iter: 1123 loss: 4.691512e-06
Iter: 1124 loss: 4.69082261e-06
Iter: 1125 loss: 4.6901414e-06
Iter: 1126 loss: 4.68998496e-06
Iter: 1127 loss: 4.68945473e-06
Iter: 1128 loss: 4.69501083e-06
Iter: 1129 loss: 4.68947655e-06
Iter: 1130 loss: 4.68888902e-06
Iter: 1131 loss: 4.68971712e-06
Iter: 1132 loss: 4.68858434e-06
Iter: 1133 loss: 4.68823691e-06
Iter: 1134 loss: 4.68854523e-06
Iter: 1135 loss: 4.68808594e-06
Iter: 1136 loss: 4.68746111e-06
Iter: 1137 loss: 4.68942835e-06
Iter: 1138 loss: 4.68731423e-06
Iter: 1139 loss: 4.68687267e-06
Iter: 1140 loss: 4.68606277e-06
Iter: 1141 loss: 4.70228588e-06
Iter: 1142 loss: 4.6860473e-06
Iter: 1143 loss: 4.68494363e-06
Iter: 1144 loss: 4.69072165e-06
Iter: 1145 loss: 4.68476856e-06
Iter: 1146 loss: 4.68378357e-06
Iter: 1147 loss: 4.68614144e-06
Iter: 1148 loss: 4.68344524e-06
Iter: 1149 loss: 4.6827181e-06
Iter: 1150 loss: 4.68672533e-06
Iter: 1151 loss: 4.68261806e-06
Iter: 1152 loss: 4.68189046e-06
Iter: 1153 loss: 4.68517328e-06
Iter: 1154 loss: 4.68172948e-06
Iter: 1155 loss: 4.68121198e-06
Iter: 1156 loss: 4.68186272e-06
Iter: 1157 loss: 4.68091685e-06
Iter: 1158 loss: 4.68034523e-06
Iter: 1159 loss: 4.68684e-06
Iter: 1160 loss: 4.68033704e-06
Iter: 1161 loss: 4.67990594e-06
Iter: 1162 loss: 4.67893369e-06
Iter: 1163 loss: 4.68658482e-06
Iter: 1164 loss: 4.67872724e-06
Iter: 1165 loss: 4.67882819e-06
Iter: 1166 loss: 4.67822201e-06
Iter: 1167 loss: 4.67781956e-06
Iter: 1168 loss: 4.67686323e-06
Iter: 1169 loss: 4.69007318e-06
Iter: 1170 loss: 4.67690097e-06
Iter: 1171 loss: 4.67626433e-06
Iter: 1172 loss: 4.68153212e-06
Iter: 1173 loss: 4.67617247e-06
Iter: 1174 loss: 4.67541395e-06
Iter: 1175 loss: 4.67772907e-06
Iter: 1176 loss: 4.67522932e-06
Iter: 1177 loss: 4.67480777e-06
Iter: 1178 loss: 4.67419977e-06
Iter: 1179 loss: 4.67415794e-06
Iter: 1180 loss: 4.67328346e-06
Iter: 1181 loss: 4.68031431e-06
Iter: 1182 loss: 4.67322e-06
Iter: 1183 loss: 4.67242899e-06
Iter: 1184 loss: 4.67186419e-06
Iter: 1185 loss: 4.67158316e-06
Iter: 1186 loss: 4.67107293e-06
Iter: 1187 loss: 4.67101427e-06
Iter: 1188 loss: 4.67044629e-06
Iter: 1189 loss: 4.66978872e-06
Iter: 1190 loss: 4.66975e-06
Iter: 1191 loss: 4.66909387e-06
Iter: 1192 loss: 4.66948768e-06
Iter: 1193 loss: 4.66868823e-06
Iter: 1194 loss: 4.66830807e-06
Iter: 1195 loss: 4.66824258e-06
Iter: 1196 loss: 4.6679188e-06
Iter: 1197 loss: 4.66713891e-06
Iter: 1198 loss: 4.67676546e-06
Iter: 1199 loss: 4.66711208e-06
Iter: 1200 loss: 4.66666188e-06
Iter: 1201 loss: 4.66657821e-06
Iter: 1202 loss: 4.66609617e-06
Iter: 1203 loss: 4.66566053e-06
Iter: 1204 loss: 4.66557e-06
Iter: 1205 loss: 4.66493793e-06
Iter: 1206 loss: 4.66576512e-06
Iter: 1207 loss: 4.66462552e-06
Iter: 1208 loss: 4.66370921e-06
Iter: 1209 loss: 4.66991332e-06
Iter: 1210 loss: 4.66364372e-06
Iter: 1211 loss: 4.66327037e-06
Iter: 1212 loss: 4.66258325e-06
Iter: 1213 loss: 4.67838163e-06
Iter: 1214 loss: 4.66257188e-06
Iter: 1215 loss: 4.66176607e-06
Iter: 1216 loss: 4.66771689e-06
Iter: 1217 loss: 4.66173333e-06
Iter: 1218 loss: 4.66099254e-06
Iter: 1219 loss: 4.66337588e-06
Iter: 1220 loss: 4.66077518e-06
Iter: 1221 loss: 4.66003621e-06
Iter: 1222 loss: 4.66357596e-06
Iter: 1223 loss: 4.6598534e-06
Iter: 1224 loss: 4.6592495e-06
Iter: 1225 loss: 4.65815629e-06
Iter: 1226 loss: 4.65815356e-06
Iter: 1227 loss: 4.6576024e-06
Iter: 1228 loss: 4.6575642e-06
Iter: 1229 loss: 4.65689436e-06
Iter: 1230 loss: 4.65730409e-06
Iter: 1231 loss: 4.65645917e-06
Iter: 1232 loss: 4.6559353e-06
Iter: 1233 loss: 4.65572612e-06
Iter: 1234 loss: 4.65546145e-06
Iter: 1235 loss: 4.65487665e-06
Iter: 1236 loss: 4.654853e-06
Iter: 1237 loss: 4.65450921e-06
Iter: 1238 loss: 4.65363109e-06
Iter: 1239 loss: 4.66070651e-06
Iter: 1240 loss: 4.65351059e-06
Iter: 1241 loss: 4.65312e-06
Iter: 1242 loss: 4.65296671e-06
Iter: 1243 loss: 4.65247422e-06
Iter: 1244 loss: 4.65196536e-06
Iter: 1245 loss: 4.65185076e-06
Iter: 1246 loss: 4.65119228e-06
Iter: 1247 loss: 4.65103358e-06
Iter: 1248 loss: 4.65057792e-06
Iter: 1249 loss: 4.65009089e-06
Iter: 1250 loss: 4.6500495e-06
Iter: 1251 loss: 4.64956247e-06
Iter: 1252 loss: 4.64965115e-06
Iter: 1253 loss: 4.64922e-06
Iter: 1254 loss: 4.64847153e-06
Iter: 1255 loss: 4.64876484e-06
Iter: 1256 loss: 4.64789809e-06
Iter: 1257 loss: 4.64716049e-06
Iter: 1258 loss: 4.64709956e-06
Iter: 1259 loss: 4.64659024e-06
Iter: 1260 loss: 4.64640971e-06
Iter: 1261 loss: 4.64614732e-06
Iter: 1262 loss: 4.64573623e-06
Iter: 1263 loss: 4.64481036e-06
Iter: 1264 loss: 4.65477842e-06
Iter: 1265 loss: 4.64470077e-06
Iter: 1266 loss: 4.64377854e-06
Iter: 1267 loss: 4.64809818e-06
Iter: 1268 loss: 4.64366076e-06
Iter: 1269 loss: 4.6424384e-06
Iter: 1270 loss: 4.64891855e-06
Iter: 1271 loss: 4.64230061e-06
Iter: 1272 loss: 4.64178902e-06
Iter: 1273 loss: 4.64069217e-06
Iter: 1274 loss: 4.65670382e-06
Iter: 1275 loss: 4.64063942e-06
Iter: 1276 loss: 4.64030563e-06
Iter: 1277 loss: 4.63992865e-06
Iter: 1278 loss: 4.63944934e-06
Iter: 1279 loss: 4.63850256e-06
Iter: 1280 loss: 4.65629364e-06
Iter: 1281 loss: 4.63850074e-06
Iter: 1282 loss: 4.63773358e-06
Iter: 1283 loss: 4.64273398e-06
Iter: 1284 loss: 4.63769902e-06
Iter: 1285 loss: 4.63695142e-06
Iter: 1286 loss: 4.6400728e-06
Iter: 1287 loss: 4.63674496e-06
Iter: 1288 loss: 4.63601282e-06
Iter: 1289 loss: 4.63691777e-06
Iter: 1290 loss: 4.6356181e-06
Iter: 1291 loss: 4.63484412e-06
Iter: 1292 loss: 4.63425249e-06
Iter: 1293 loss: 4.63403148e-06
Iter: 1294 loss: 4.63348e-06
Iter: 1295 loss: 4.63338e-06
Iter: 1296 loss: 4.63277047e-06
Iter: 1297 loss: 4.63199467e-06
Iter: 1298 loss: 4.63196284e-06
Iter: 1299 loss: 4.6311161e-06
Iter: 1300 loss: 4.63073502e-06
Iter: 1301 loss: 4.63032939e-06
Iter: 1302 loss: 4.63053721e-06
Iter: 1303 loss: 4.6298087e-06
Iter: 1304 loss: 4.62936032e-06
Iter: 1305 loss: 4.62819071e-06
Iter: 1306 loss: 4.63903825e-06
Iter: 1307 loss: 4.62806747e-06
Iter: 1308 loss: 4.6270934e-06
Iter: 1309 loss: 4.63558627e-06
Iter: 1310 loss: 4.62708886e-06
Iter: 1311 loss: 4.62597609e-06
Iter: 1312 loss: 4.62741264e-06
Iter: 1313 loss: 4.62539811e-06
Iter: 1314 loss: 4.62480511e-06
Iter: 1315 loss: 4.62463549e-06
Iter: 1316 loss: 4.6242435e-06
Iter: 1317 loss: 4.62338176e-06
Iter: 1318 loss: 4.63287734e-06
Iter: 1319 loss: 4.62336357e-06
Iter: 1320 loss: 4.62261369e-06
Iter: 1321 loss: 4.62392154e-06
Iter: 1322 loss: 4.62230219e-06
Iter: 1323 loss: 4.62157095e-06
Iter: 1324 loss: 4.62205253e-06
Iter: 1325 loss: 4.6211826e-06
Iter: 1326 loss: 4.62038088e-06
Iter: 1327 loss: 4.62120352e-06
Iter: 1328 loss: 4.61995705e-06
Iter: 1329 loss: 4.61879472e-06
Iter: 1330 loss: 4.62719527e-06
Iter: 1331 loss: 4.61866966e-06
Iter: 1332 loss: 4.61817854e-06
Iter: 1333 loss: 4.6173127e-06
Iter: 1334 loss: 4.61727e-06
Iter: 1335 loss: 4.61642639e-06
Iter: 1336 loss: 4.62167236e-06
Iter: 1337 loss: 4.61636319e-06
Iter: 1338 loss: 4.61543596e-06
Iter: 1339 loss: 4.6221553e-06
Iter: 1340 loss: 4.61534864e-06
Iter: 1341 loss: 4.61484024e-06
Iter: 1342 loss: 4.61351556e-06
Iter: 1343 loss: 4.62559819e-06
Iter: 1344 loss: 4.61331365e-06
Iter: 1345 loss: 4.61344644e-06
Iter: 1346 loss: 4.61269974e-06
Iter: 1347 loss: 4.61229592e-06
Iter: 1348 loss: 4.61119089e-06
Iter: 1349 loss: 4.61838044e-06
Iter: 1350 loss: 4.61094214e-06
Iter: 1351 loss: 4.60999217e-06
Iter: 1352 loss: 4.62514845e-06
Iter: 1353 loss: 4.60999308e-06
Iter: 1354 loss: 4.60916954e-06
Iter: 1355 loss: 4.61246418e-06
Iter: 1356 loss: 4.60900264e-06
Iter: 1357 loss: 4.60848059e-06
Iter: 1358 loss: 4.60973388e-06
Iter: 1359 loss: 4.60831325e-06
Iter: 1360 loss: 4.60775709e-06
Iter: 1361 loss: 4.60671527e-06
Iter: 1362 loss: 4.62951e-06
Iter: 1363 loss: 4.60673073e-06
Iter: 1364 loss: 4.60617684e-06
Iter: 1365 loss: 4.60602405e-06
Iter: 1366 loss: 4.60530373e-06
Iter: 1367 loss: 4.60419642e-06
Iter: 1368 loss: 4.60421188e-06
Iter: 1369 loss: 4.60321553e-06
Iter: 1370 loss: 4.60371893e-06
Iter: 1371 loss: 4.60259616e-06
Iter: 1372 loss: 4.60211595e-06
Iter: 1373 loss: 4.60211641e-06
Iter: 1374 loss: 4.60163938e-06
Iter: 1375 loss: 4.60098272e-06
Iter: 1376 loss: 4.60091587e-06
Iter: 1377 loss: 4.60021784e-06
Iter: 1378 loss: 4.59997636e-06
Iter: 1379 loss: 4.5995107e-06
Iter: 1380 loss: 4.59934472e-06
Iter: 1381 loss: 4.59905914e-06
Iter: 1382 loss: 4.59861531e-06
Iter: 1383 loss: 4.59739204e-06
Iter: 1384 loss: 4.60506499e-06
Iter: 1385 loss: 4.59705643e-06
Iter: 1386 loss: 4.59598778e-06
Iter: 1387 loss: 4.60264027e-06
Iter: 1388 loss: 4.59582634e-06
Iter: 1389 loss: 4.59543662e-06
Iter: 1390 loss: 4.59528974e-06
Iter: 1391 loss: 4.59487092e-06
Iter: 1392 loss: 4.59382136e-06
Iter: 1393 loss: 4.60672391e-06
Iter: 1394 loss: 4.59378e-06
Iter: 1395 loss: 4.59297371e-06
Iter: 1396 loss: 4.60299543e-06
Iter: 1397 loss: 4.59299e-06
Iter: 1398 loss: 4.59231796e-06
Iter: 1399 loss: 4.59389139e-06
Iter: 1400 loss: 4.5920824e-06
Iter: 1401 loss: 4.59117655e-06
Iter: 1402 loss: 4.59363309e-06
Iter: 1403 loss: 4.59091552e-06
Iter: 1404 loss: 4.59031435e-06
Iter: 1405 loss: 4.5891411e-06
Iter: 1406 loss: 4.61225454e-06
Iter: 1407 loss: 4.58913928e-06
Iter: 1408 loss: 4.58888371e-06
Iter: 1409 loss: 4.58855357e-06
Iter: 1410 loss: 4.58794921e-06
Iter: 1411 loss: 4.58739123e-06
Iter: 1412 loss: 4.58722025e-06
Iter: 1413 loss: 4.58650402e-06
Iter: 1414 loss: 4.5861434e-06
Iter: 1415 loss: 4.58582645e-06
Iter: 1416 loss: 4.58524391e-06
Iter: 1417 loss: 4.58512795e-06
Iter: 1418 loss: 4.58478871e-06
Iter: 1419 loss: 4.5839015e-06
Iter: 1420 loss: 4.59096736e-06
Iter: 1421 loss: 4.58373233e-06
Iter: 1422 loss: 4.58278e-06
Iter: 1423 loss: 4.58778459e-06
Iter: 1424 loss: 4.58261457e-06
Iter: 1425 loss: 4.58152726e-06
Iter: 1426 loss: 4.59010653e-06
Iter: 1427 loss: 4.58145678e-06
Iter: 1428 loss: 4.58094519e-06
Iter: 1429 loss: 4.57987153e-06
Iter: 1430 loss: 4.59901185e-06
Iter: 1431 loss: 4.57981923e-06
Iter: 1432 loss: 4.57879105e-06
Iter: 1433 loss: 4.57878195e-06
Iter: 1434 loss: 4.57803753e-06
Iter: 1435 loss: 4.58202885e-06
Iter: 1436 loss: 4.57786837e-06
Iter: 1437 loss: 4.57730039e-06
Iter: 1438 loss: 4.57727629e-06
Iter: 1439 loss: 4.57679198e-06
Iter: 1440 loss: 4.5762572e-06
Iter: 1441 loss: 4.57567421e-06
Iter: 1442 loss: 4.57557189e-06
Iter: 1443 loss: 4.57565056e-06
Iter: 1444 loss: 4.57514125e-06
Iter: 1445 loss: 4.57486203e-06
Iter: 1446 loss: 4.5739539e-06
Iter: 1447 loss: 4.57670467e-06
Iter: 1448 loss: 4.57359329e-06
Iter: 1449 loss: 4.57260103e-06
Iter: 1450 loss: 4.58035538e-06
Iter: 1451 loss: 4.57252099e-06
Iter: 1452 loss: 4.57177612e-06
Iter: 1453 loss: 4.58311843e-06
Iter: 1454 loss: 4.5717461e-06
Iter: 1455 loss: 4.57131227e-06
Iter: 1456 loss: 4.57021542e-06
Iter: 1457 loss: 4.5830061e-06
Iter: 1458 loss: 4.57015e-06
Iter: 1459 loss: 4.56987937e-06
Iter: 1460 loss: 4.56977705e-06
Iter: 1461 loss: 4.56931093e-06
Iter: 1462 loss: 4.56867383e-06
Iter: 1463 loss: 4.5686711e-06
Iter: 1464 loss: 4.56797443e-06
Iter: 1465 loss: 4.56787075e-06
Iter: 1466 loss: 4.56734688e-06
Iter: 1467 loss: 4.56713e-06
Iter: 1468 loss: 4.56693033e-06
Iter: 1469 loss: 4.5665679e-06
Iter: 1470 loss: 4.56604539e-06
Iter: 1471 loss: 4.56605176e-06
Iter: 1472 loss: 4.56529415e-06
Iter: 1473 loss: 4.56749649e-06
Iter: 1474 loss: 4.56512e-06
Iter: 1475 loss: 4.56459e-06
Iter: 1476 loss: 4.56575435e-06
Iter: 1477 loss: 4.56436646e-06
Iter: 1478 loss: 4.56377347e-06
Iter: 1479 loss: 4.5716879e-06
Iter: 1480 loss: 4.56379894e-06
Iter: 1481 loss: 4.56351654e-06
Iter: 1482 loss: 4.56268208e-06
Iter: 1483 loss: 4.56670614e-06
Iter: 1484 loss: 4.56241833e-06
Iter: 1485 loss: 4.56144517e-06
Iter: 1486 loss: 4.5669085e-06
Iter: 1487 loss: 4.56133876e-06
Iter: 1488 loss: 4.56077942e-06
Iter: 1489 loss: 4.56074122e-06
Iter: 1490 loss: 4.56039e-06
Iter: 1491 loss: 4.55965619e-06
Iter: 1492 loss: 4.56722319e-06
Iter: 1493 loss: 4.55951158e-06
Iter: 1494 loss: 4.55898544e-06
Iter: 1495 loss: 4.56333919e-06
Iter: 1496 loss: 4.55892405e-06
Iter: 1497 loss: 4.55820691e-06
Iter: 1498 loss: 4.56211865e-06
Iter: 1499 loss: 4.5580764e-06
Iter: 1500 loss: 4.55779355e-06
Iter: 1501 loss: 4.5571428e-06
Iter: 1502 loss: 4.56523958e-06
Iter: 1503 loss: 4.55712234e-06
Iter: 1504 loss: 4.55687814e-06
Iter: 1505 loss: 4.55670488e-06
Iter: 1506 loss: 4.55632289e-06
Iter: 1507 loss: 4.55632653e-06
Iter: 1508 loss: 4.55593454e-06
Iter: 1509 loss: 4.55563895e-06
Iter: 1510 loss: 4.55552572e-06
Iter: 1511 loss: 4.55529789e-06
Iter: 1512 loss: 4.55480495e-06
Iter: 1513 loss: 4.55922418e-06
Iter: 1514 loss: 4.55472491e-06
Iter: 1515 loss: 4.55432746e-06
Iter: 1516 loss: 4.55692225e-06
Iter: 1517 loss: 4.55428744e-06
Iter: 1518 loss: 4.55406507e-06
Iter: 1519 loss: 4.55353802e-06
Iter: 1520 loss: 4.56131193e-06
Iter: 1521 loss: 4.55354211e-06
Iter: 1522 loss: 4.55292229e-06
Iter: 1523 loss: 4.55369081e-06
Iter: 1524 loss: 4.55261306e-06
Iter: 1525 loss: 4.55189092e-06
Iter: 1526 loss: 4.55186773e-06
Iter: 1527 loss: 4.55157033e-06
Iter: 1528 loss: 4.5508832e-06
Iter: 1529 loss: 4.55633563e-06
Iter: 1530 loss: 4.55074314e-06
Iter: 1531 loss: 4.55012287e-06
Iter: 1532 loss: 4.55935833e-06
Iter: 1533 loss: 4.55013787e-06
Iter: 1534 loss: 4.5494603e-06
Iter: 1535 loss: 4.55151167e-06
Iter: 1536 loss: 4.5492834e-06
Iter: 1537 loss: 4.54893416e-06
Iter: 1538 loss: 4.54831752e-06
Iter: 1539 loss: 4.5483248e-06
Iter: 1540 loss: 4.5477891e-06
Iter: 1541 loss: 4.55275222e-06
Iter: 1542 loss: 4.54772e-06
Iter: 1543 loss: 4.54699693e-06
Iter: 1544 loss: 4.54903966e-06
Iter: 1545 loss: 4.54682731e-06
Iter: 1546 loss: 4.54633391e-06
Iter: 1547 loss: 4.54556402e-06
Iter: 1548 loss: 4.56493399e-06
Iter: 1549 loss: 4.54554265e-06
Iter: 1550 loss: 4.54502424e-06
Iter: 1551 loss: 4.5450297e-06
Iter: 1552 loss: 4.54436577e-06
Iter: 1553 loss: 4.5449915e-06
Iter: 1554 loss: 4.54399833e-06
Iter: 1555 loss: 4.54363317e-06
Iter: 1556 loss: 4.54319343e-06
Iter: 1557 loss: 4.54322071e-06
Iter: 1558 loss: 4.54269775e-06
Iter: 1559 loss: 4.549408e-06
Iter: 1560 loss: 4.5427023e-06
Iter: 1561 loss: 4.54218753e-06
Iter: 1562 loss: 4.54273413e-06
Iter: 1563 loss: 4.54192696e-06
Iter: 1564 loss: 4.54128713e-06
Iter: 1565 loss: 4.54192741e-06
Iter: 1566 loss: 4.54094516e-06
Iter: 1567 loss: 4.54022938e-06
Iter: 1568 loss: 4.54001656e-06
Iter: 1569 loss: 4.53961457e-06
Iter: 1570 loss: 4.53911798e-06
Iter: 1571 loss: 4.53898883e-06
Iter: 1572 loss: 4.53869052e-06
Iter: 1573 loss: 4.53777511e-06
Iter: 1574 loss: 4.54529527e-06
Iter: 1575 loss: 4.53762e-06
Iter: 1576 loss: 4.53678103e-06
Iter: 1577 loss: 4.54166138e-06
Iter: 1578 loss: 4.53667781e-06
Iter: 1579 loss: 4.53603661e-06
Iter: 1580 loss: 4.53599841e-06
Iter: 1581 loss: 4.53567327e-06
Iter: 1582 loss: 4.53475968e-06
Iter: 1583 loss: 4.53905886e-06
Iter: 1584 loss: 4.53440862e-06
Iter: 1585 loss: 4.5338e-06
Iter: 1586 loss: 4.53378198e-06
Iter: 1587 loss: 4.53304619e-06
Iter: 1588 loss: 4.53547136e-06
Iter: 1589 loss: 4.53289067e-06
Iter: 1590 loss: 4.53250686e-06
Iter: 1591 loss: 4.5317579e-06
Iter: 1592 loss: 4.54365181e-06
Iter: 1593 loss: 4.53173561e-06
Iter: 1594 loss: 4.53157827e-06
Iter: 1595 loss: 4.53134817e-06
Iter: 1596 loss: 4.53101939e-06
Iter: 1597 loss: 4.53057964e-06
Iter: 1598 loss: 4.53056e-06
Iter: 1599 loss: 4.52989752e-06
Iter: 1600 loss: 4.53153916e-06
Iter: 1601 loss: 4.52969243e-06
Iter: 1602 loss: 4.52899167e-06
Iter: 1603 loss: 4.53010216e-06
Iter: 1604 loss: 4.52869926e-06
Iter: 1605 loss: 4.52814356e-06
Iter: 1606 loss: 4.52815721e-06
Iter: 1607 loss: 4.52783843e-06
Iter: 1608 loss: 4.52706809e-06
Iter: 1609 loss: 4.53181474e-06
Iter: 1610 loss: 4.52682161e-06
Iter: 1611 loss: 4.52624317e-06
Iter: 1612 loss: 4.53575376e-06
Iter: 1613 loss: 4.52621589e-06
Iter: 1614 loss: 4.52559561e-06
Iter: 1615 loss: 4.53107623e-06
Iter: 1616 loss: 4.5255988e-06
Iter: 1617 loss: 4.52527365e-06
Iter: 1618 loss: 4.5244733e-06
Iter: 1619 loss: 4.528e-06
Iter: 1620 loss: 4.52415634e-06
Iter: 1621 loss: 4.52360473e-06
Iter: 1622 loss: 4.52352833e-06
Iter: 1623 loss: 4.52285622e-06
Iter: 1624 loss: 4.52484164e-06
Iter: 1625 loss: 4.52266158e-06
Iter: 1626 loss: 4.5223378e-06
Iter: 1627 loss: 4.52164113e-06
Iter: 1628 loss: 4.53343864e-06
Iter: 1629 loss: 4.52161521e-06
Iter: 1630 loss: 4.52125641e-06
Iter: 1631 loss: 4.52115546e-06
Iter: 1632 loss: 4.52075e-06
Iter: 1633 loss: 4.52020049e-06
Iter: 1634 loss: 4.52017957e-06
Iter: 1635 loss: 4.51961023e-06
Iter: 1636 loss: 4.52321774e-06
Iter: 1637 loss: 4.51952474e-06
Iter: 1638 loss: 4.51911637e-06
Iter: 1639 loss: 4.52324639e-06
Iter: 1640 loss: 4.519105e-06
Iter: 1641 loss: 4.51867754e-06
Iter: 1642 loss: 4.51788173e-06
Iter: 1643 loss: 4.51789128e-06
Iter: 1644 loss: 4.51718552e-06
Iter: 1645 loss: 4.51877895e-06
Iter: 1646 loss: 4.51695223e-06
Iter: 1647 loss: 4.51676215e-06
Iter: 1648 loss: 4.51660435e-06
Iter: 1649 loss: 4.51632468e-06
Iter: 1650 loss: 4.5154884e-06
Iter: 1651 loss: 4.52350559e-06
Iter: 1652 loss: 4.51544e-06
Iter: 1653 loss: 4.51471669e-06
Iter: 1654 loss: 4.51582582e-06
Iter: 1655 loss: 4.5144061e-06
Iter: 1656 loss: 4.51423693e-06
Iter: 1657 loss: 4.51398137e-06
Iter: 1658 loss: 4.51376854e-06
Iter: 1659 loss: 4.51310098e-06
Iter: 1660 loss: 4.51714e-06
Iter: 1661 loss: 4.51284177e-06
Iter: 1662 loss: 4.51212782e-06
Iter: 1663 loss: 4.51601409e-06
Iter: 1664 loss: 4.51202459e-06
Iter: 1665 loss: 4.51110191e-06
Iter: 1666 loss: 4.51621054e-06
Iter: 1667 loss: 4.51093729e-06
Iter: 1668 loss: 4.51054711e-06
Iter: 1669 loss: 4.51053438e-06
Iter: 1670 loss: 4.51022152e-06
Iter: 1671 loss: 4.50953348e-06
Iter: 1672 loss: 4.51106462e-06
Iter: 1673 loss: 4.50926e-06
Iter: 1674 loss: 4.50873586e-06
Iter: 1675 loss: 4.5171646e-06
Iter: 1676 loss: 4.50870357e-06
Iter: 1677 loss: 4.5083525e-06
Iter: 1678 loss: 4.50771267e-06
Iter: 1679 loss: 4.50770858e-06
Iter: 1680 loss: 4.50704738e-06
Iter: 1681 loss: 4.50744119e-06
Iter: 1682 loss: 4.5066563e-06
Iter: 1683 loss: 4.50571861e-06
Iter: 1684 loss: 4.51904e-06
Iter: 1685 loss: 4.50571042e-06
Iter: 1686 loss: 4.50534571e-06
Iter: 1687 loss: 4.50438711e-06
Iter: 1688 loss: 4.51626511e-06
Iter: 1689 loss: 4.50431889e-06
Iter: 1690 loss: 4.5036727e-06
Iter: 1691 loss: 4.50369134e-06
Iter: 1692 loss: 4.50296193e-06
Iter: 1693 loss: 4.50411881e-06
Iter: 1694 loss: 4.5026195e-06
Iter: 1695 loss: 4.50221114e-06
Iter: 1696 loss: 4.50143762e-06
Iter: 1697 loss: 4.51935284e-06
Iter: 1698 loss: 4.50143807e-06
Iter: 1699 loss: 4.50099333e-06
Iter: 1700 loss: 4.50093694e-06
Iter: 1701 loss: 4.50040397e-06
Iter: 1702 loss: 4.49933486e-06
Iter: 1703 loss: 4.52026052e-06
Iter: 1704 loss: 4.49934259e-06
Iter: 1705 loss: 4.498409e-06
Iter: 1706 loss: 4.499846e-06
Iter: 1707 loss: 4.49796971e-06
Iter: 1708 loss: 4.49749086e-06
Iter: 1709 loss: 4.4974272e-06
Iter: 1710 loss: 4.49704976e-06
Iter: 1711 loss: 4.49765366e-06
Iter: 1712 loss: 4.49683967e-06
Iter: 1713 loss: 4.49631261e-06
Iter: 1714 loss: 4.49575418e-06
Iter: 1715 loss: 4.49566369e-06
Iter: 1716 loss: 4.49493291e-06
Iter: 1717 loss: 4.49606705e-06
Iter: 1718 loss: 4.49458275e-06
Iter: 1719 loss: 4.49426807e-06
Iter: 1720 loss: 4.49411891e-06
Iter: 1721 loss: 4.49378513e-06
Iter: 1722 loss: 4.49272693e-06
Iter: 1723 loss: 4.49632216e-06
Iter: 1724 loss: 4.49231629e-06
Iter: 1725 loss: 4.49279423e-06
Iter: 1726 loss: 4.49180061e-06
Iter: 1727 loss: 4.49147137e-06
Iter: 1728 loss: 4.49065465e-06
Iter: 1729 loss: 4.50092284e-06
Iter: 1730 loss: 4.49058189e-06
Iter: 1731 loss: 4.48987112e-06
Iter: 1732 loss: 4.49263553e-06
Iter: 1733 loss: 4.48970832e-06
Iter: 1734 loss: 4.48906121e-06
Iter: 1735 loss: 4.49495474e-06
Iter: 1736 loss: 4.48899755e-06
Iter: 1737 loss: 4.48856235e-06
Iter: 1738 loss: 4.48766968e-06
Iter: 1739 loss: 4.50381685e-06
Iter: 1740 loss: 4.48766286e-06
Iter: 1741 loss: 4.4868857e-06
Iter: 1742 loss: 4.49574873e-06
Iter: 1743 loss: 4.48687842e-06
Iter: 1744 loss: 4.48599076e-06
Iter: 1745 loss: 4.49074741e-06
Iter: 1746 loss: 4.48588253e-06
Iter: 1747 loss: 4.48530591e-06
Iter: 1748 loss: 4.48649644e-06
Iter: 1749 loss: 4.48505625e-06
Iter: 1750 loss: 4.48441824e-06
Iter: 1751 loss: 4.48373885e-06
Iter: 1752 loss: 4.48360424e-06
Iter: 1753 loss: 4.48326864e-06
Iter: 1754 loss: 4.4831595e-06
Iter: 1755 loss: 4.48264291e-06
Iter: 1756 loss: 4.48177e-06
Iter: 1757 loss: 4.48177252e-06
Iter: 1758 loss: 4.48112405e-06
Iter: 1759 loss: 4.4897979e-06
Iter: 1760 loss: 4.48113133e-06
Iter: 1761 loss: 4.48043e-06
Iter: 1762 loss: 4.48046649e-06
Iter: 1763 loss: 4.47987441e-06
Iter: 1764 loss: 4.47929415e-06
Iter: 1765 loss: 4.47873663e-06
Iter: 1766 loss: 4.47862294e-06
Iter: 1767 loss: 4.4780295e-06
Iter: 1768 loss: 4.477939e-06
Iter: 1769 loss: 4.47751245e-06
Iter: 1770 loss: 4.47657067e-06
Iter: 1771 loss: 4.49125764e-06
Iter: 1772 loss: 4.47655566e-06
Iter: 1773 loss: 4.4756307e-06
Iter: 1774 loss: 4.47861157e-06
Iter: 1775 loss: 4.47541606e-06
Iter: 1776 loss: 4.47484354e-06
Iter: 1777 loss: 4.47482489e-06
Iter: 1778 loss: 4.47439379e-06
Iter: 1779 loss: 4.47413368e-06
Iter: 1780 loss: 4.47393222e-06
Iter: 1781 loss: 4.47319371e-06
Iter: 1782 loss: 4.47363755e-06
Iter: 1783 loss: 4.47261755e-06
Iter: 1784 loss: 4.47188222e-06
Iter: 1785 loss: 4.4737335e-06
Iter: 1786 loss: 4.47155753e-06
Iter: 1787 loss: 4.47071761e-06
Iter: 1788 loss: 4.48225683e-06
Iter: 1789 loss: 4.4706776e-06
Iter: 1790 loss: 4.47029834e-06
Iter: 1791 loss: 4.46985723e-06
Iter: 1792 loss: 4.46982676e-06
Iter: 1793 loss: 4.4691069e-06
Iter: 1794 loss: 4.47730508e-06
Iter: 1795 loss: 4.46904414e-06
Iter: 1796 loss: 4.46867944e-06
Iter: 1797 loss: 4.46786498e-06
Iter: 1798 loss: 4.47874663e-06
Iter: 1799 loss: 4.46774629e-06
Iter: 1800 loss: 4.46751346e-06
Iter: 1801 loss: 4.46736431e-06
Iter: 1802 loss: 4.46694139e-06
Iter: 1803 loss: 4.46639115e-06
Iter: 1804 loss: 4.4663866e-06
Iter: 1805 loss: 4.46568311e-06
Iter: 1806 loss: 4.46501826e-06
Iter: 1807 loss: 4.46486683e-06
Iter: 1808 loss: 4.46428476e-06
Iter: 1809 loss: 4.46419108e-06
Iter: 1810 loss: 4.46371632e-06
Iter: 1811 loss: 4.4636663e-06
Iter: 1812 loss: 4.46327567e-06
Iter: 1813 loss: 4.46268814e-06
Iter: 1814 loss: 4.46521517e-06
Iter: 1815 loss: 4.46257536e-06
Iter: 1816 loss: 4.46196054e-06
Iter: 1817 loss: 4.4616163e-06
Iter: 1818 loss: 4.46139393e-06
Iter: 1819 loss: 4.46122249e-06
Iter: 1820 loss: 4.46098693e-06
Iter: 1821 loss: 4.4606868e-06
Iter: 1822 loss: 4.45994556e-06
Iter: 1823 loss: 4.46586546e-06
Iter: 1824 loss: 4.45982e-06
Iter: 1825 loss: 4.45945898e-06
Iter: 1826 loss: 4.45938076e-06
Iter: 1827 loss: 4.45886872e-06
Iter: 1828 loss: 4.45779142e-06
Iter: 1829 loss: 4.47729917e-06
Iter: 1830 loss: 4.45777232e-06
Iter: 1831 loss: 4.45711885e-06
Iter: 1832 loss: 4.46243303e-06
Iter: 1833 loss: 4.45710521e-06
Iter: 1834 loss: 4.45640671e-06
Iter: 1835 loss: 4.45915066e-06
Iter: 1836 loss: 4.45626029e-06
Iter: 1837 loss: 4.45586329e-06
Iter: 1838 loss: 4.45517162e-06
Iter: 1839 loss: 4.45515934e-06
Iter: 1840 loss: 4.4546814e-06
Iter: 1841 loss: 4.45467504e-06
Iter: 1842 loss: 4.45423575e-06
Iter: 1843 loss: 4.45374235e-06
Iter: 1844 loss: 4.45370279e-06
Iter: 1845 loss: 4.45282285e-06
Iter: 1846 loss: 4.45440219e-06
Iter: 1847 loss: 4.45245314e-06
Iter: 1848 loss: 4.4514145e-06
Iter: 1849 loss: 4.45325441e-06
Iter: 1850 loss: 4.45093474e-06
Iter: 1851 loss: 4.4502176e-06
Iter: 1852 loss: 4.45520345e-06
Iter: 1853 loss: 4.4501021e-06
Iter: 1854 loss: 4.44925945e-06
Iter: 1855 loss: 4.45182559e-06
Iter: 1856 loss: 4.44893976e-06
Iter: 1857 loss: 4.44852731e-06
Iter: 1858 loss: 4.44847183e-06
Iter: 1859 loss: 4.4481676e-06
Iter: 1860 loss: 4.4473345e-06
Iter: 1861 loss: 4.45086516e-06
Iter: 1862 loss: 4.44718216e-06
Iter: 1863 loss: 4.4466542e-06
Iter: 1864 loss: 4.44579746e-06
Iter: 1865 loss: 4.46768081e-06
Iter: 1866 loss: 4.4458252e-06
Iter: 1867 loss: 4.44520037e-06
Iter: 1868 loss: 4.44509942e-06
Iter: 1869 loss: 4.44468196e-06
Iter: 1870 loss: 4.44355874e-06
Iter: 1871 loss: 4.45531714e-06
Iter: 1872 loss: 4.44342641e-06
Iter: 1873 loss: 4.44237548e-06
Iter: 1874 loss: 4.44733359e-06
Iter: 1875 loss: 4.44221814e-06
Iter: 1876 loss: 4.4416588e-06
Iter: 1877 loss: 4.44154466e-06
Iter: 1878 loss: 4.44115267e-06
Iter: 1879 loss: 4.44047919e-06
Iter: 1880 loss: 4.44046236e-06
Iter: 1881 loss: 4.43968838e-06
Iter: 1882 loss: 4.44453235e-06
Iter: 1883 loss: 4.43958925e-06
Iter: 1884 loss: 4.43899535e-06
Iter: 1885 loss: 4.43837234e-06
Iter: 1886 loss: 4.43828549e-06
Iter: 1887 loss: 4.43772751e-06
Iter: 1888 loss: 4.43755471e-06
Iter: 1889 loss: 4.43713179e-06
Iter: 1890 loss: 4.43591853e-06
Iter: 1891 loss: 4.44700163e-06
Iter: 1892 loss: 4.43576846e-06
Iter: 1893 loss: 4.43566796e-06
Iter: 1894 loss: 4.43528143e-06
Iter: 1895 loss: 4.43478348e-06
Iter: 1896 loss: 4.43374392e-06
Iter: 1897 loss: 4.44847547e-06
Iter: 1898 loss: 4.43370709e-06
Iter: 1899 loss: 4.432889e-06
Iter: 1900 loss: 4.43501267e-06
Iter: 1901 loss: 4.43259705e-06
Iter: 1902 loss: 4.43197177e-06
Iter: 1903 loss: 4.43196768e-06
Iter: 1904 loss: 4.43165209e-06
Iter: 1905 loss: 4.4308731e-06
Iter: 1906 loss: 4.43700719e-06
Iter: 1907 loss: 4.43074396e-06
Iter: 1908 loss: 4.4300491e-06
Iter: 1909 loss: 4.43004956e-06
Iter: 1910 loss: 4.42931605e-06
Iter: 1911 loss: 4.42961391e-06
Iter: 1912 loss: 4.42878172e-06
Iter: 1913 loss: 4.4281278e-06
Iter: 1914 loss: 4.43041608e-06
Iter: 1915 loss: 4.42795499e-06
Iter: 1916 loss: 4.42732608e-06
Iter: 1917 loss: 4.42758e-06
Iter: 1918 loss: 4.42689361e-06
Iter: 1919 loss: 4.42641158e-06
Iter: 1920 loss: 4.43250474e-06
Iter: 1921 loss: 4.42638157e-06
Iter: 1922 loss: 4.42581177e-06
Iter: 1923 loss: 4.4263561e-06
Iter: 1924 loss: 4.42547298e-06
Iter: 1925 loss: 4.42509099e-06
Iter: 1926 loss: 4.42443343e-06
Iter: 1927 loss: 4.42440523e-06
Iter: 1928 loss: 4.42413557e-06
Iter: 1929 loss: 4.42390865e-06
Iter: 1930 loss: 4.42353348e-06
Iter: 1931 loss: 4.42263035e-06
Iter: 1932 loss: 4.43085e-06
Iter: 1933 loss: 4.42252531e-06
Iter: 1934 loss: 4.42163e-06
Iter: 1935 loss: 4.42446344e-06
Iter: 1936 loss: 4.42138662e-06
Iter: 1937 loss: 4.42052715e-06
Iter: 1938 loss: 4.42050896e-06
Iter: 1939 loss: 4.42021155e-06
Iter: 1940 loss: 4.41933207e-06
Iter: 1941 loss: 4.43060799e-06
Iter: 1942 loss: 4.41930342e-06
Iter: 1943 loss: 4.4186545e-06
Iter: 1944 loss: 4.42221062e-06
Iter: 1945 loss: 4.418549e-06
Iter: 1946 loss: 4.4180133e-06
Iter: 1947 loss: 4.41802877e-06
Iter: 1948 loss: 4.41770499e-06
Iter: 1949 loss: 4.41694601e-06
Iter: 1950 loss: 4.42581768e-06
Iter: 1951 loss: 4.41686507e-06
Iter: 1952 loss: 4.41632119e-06
Iter: 1953 loss: 4.41634484e-06
Iter: 1954 loss: 4.41588918e-06
Iter: 1955 loss: 4.4174194e-06
Iter: 1956 loss: 4.41578277e-06
Iter: 1957 loss: 4.41532029e-06
Iter: 1958 loss: 4.41585144e-06
Iter: 1959 loss: 4.41509746e-06
Iter: 1960 loss: 4.41466182e-06
Iter: 1961 loss: 4.41423799e-06
Iter: 1962 loss: 4.41418752e-06
Iter: 1963 loss: 4.4142439e-06
Iter: 1964 loss: 4.41388738e-06
Iter: 1965 loss: 4.41371049e-06
Iter: 1966 loss: 4.41315296e-06
Iter: 1967 loss: 4.41416068e-06
Iter: 1968 loss: 4.41280099e-06
Iter: 1969 loss: 4.4118915e-06
Iter: 1970 loss: 4.41304746e-06
Iter: 1971 loss: 4.41142492e-06
Iter: 1972 loss: 4.4107e-06
Iter: 1973 loss: 4.41888142e-06
Iter: 1974 loss: 4.41067095e-06
Iter: 1975 loss: 4.40984877e-06
Iter: 1976 loss: 4.41365546e-06
Iter: 1977 loss: 4.40965232e-06
Iter: 1978 loss: 4.40935855e-06
Iter: 1979 loss: 4.40896611e-06
Iter: 1980 loss: 4.40891154e-06
Iter: 1981 loss: 4.40845497e-06
Iter: 1982 loss: 4.41135035e-06
Iter: 1983 loss: 4.40845088e-06
Iter: 1984 loss: 4.40780377e-06
Iter: 1985 loss: 4.40895656e-06
Iter: 1986 loss: 4.40758367e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.8 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0.8
+ date
Mon Nov  2 10:28:55 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.8/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 2 --phi 0.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.8/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff07006b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff070175ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff070175e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0701758c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0700dc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0700dc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0245fb8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff07000e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff07000e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0245fb7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff024441158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0245158c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0245156a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0244087b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff024512488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0242e6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff02430b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff024585510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff02449c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff02449cd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0244b9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0244b98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff02439b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0243be730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0243be840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff024373378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0243be048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0245a7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0245a7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff02459a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff02423c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0242bd1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0242bd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff0240ab730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff02409aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff024024e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.000110840556
test_loss: 0.00011164363
train_loss: 5.018834e-05
test_loss: 5.1531686e-05
train_loss: 3.763741e-05
test_loss: 3.8829094e-05
train_loss: 3.183205e-05
test_loss: 3.257144e-05
train_loss: 2.6738124e-05
test_loss: 2.7612961e-05
train_loss: 2.6812182e-05
test_loss: 2.6245876e-05
train_loss: 2.2030512e-05
test_loss: 2.322338e-05
train_loss: 2.265193e-05
test_loss: 2.2808847e-05
train_loss: 2.058542e-05
test_loss: 2.0061896e-05
train_loss: 1.9356257e-05
test_loss: 1.9638659e-05
train_loss: 1.7076398e-05
test_loss: 1.8763621e-05
train_loss: 1.8499168e-05
test_loss: 1.7641303e-05
train_loss: 1.7449891e-05
test_loss: 1.7366712e-05
train_loss: 1.5311976e-05
test_loss: 1.6441885e-05
train_loss: 1.5614327e-05
test_loss: 1.6066899e-05
train_loss: 1.3348181e-05
test_loss: 1.5742346e-05
train_loss: 1.3901568e-05
test_loss: 1.5775235e-05
train_loss: 1.3435518e-05
test_loss: 1.4945982e-05
train_loss: 1.31414945e-05
test_loss: 1.4327831e-05
train_loss: 1.3621717e-05
test_loss: 1.4335505e-05
train_loss: 1.3750631e-05
test_loss: 1.3942823e-05
train_loss: 1.299424e-05
test_loss: 1.3984981e-05
train_loss: 1.253644e-05
test_loss: 1.345122e-05
train_loss: 1.2758319e-05
test_loss: 1.3229103e-05
train_loss: 1.1492744e-05
test_loss: 1.314862e-05
train_loss: 1.0886415e-05
test_loss: 1.2872368e-05
train_loss: 1.2192499e-05
test_loss: 1.2601171e-05
train_loss: 1.1250667e-05
test_loss: 1.2446103e-05
train_loss: 1.0766375e-05
test_loss: 1.256062e-05
train_loss: 1.0210021e-05
test_loss: 1.2273548e-05
train_loss: 1.119811e-05
test_loss: 1.2113755e-05
train_loss: 1.1778667e-05
test_loss: 1.2059328e-05
train_loss: 1.06448015e-05
test_loss: 1.2018799e-05
train_loss: 9.51434e-06
test_loss: 1.1994785e-05
train_loss: 1.0597596e-05
test_loss: 1.1876305e-05
train_loss: 1.06939315e-05
test_loss: 1.183786e-05
train_loss: 1.0979727e-05
test_loss: 1.1705721e-05
train_loss: 1.0784923e-05
test_loss: 1.1710317e-05
train_loss: 1.0194955e-05
test_loss: 1.1609615e-05
train_loss: 1.0364964e-05
test_loss: 1.1565663e-05
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0.8/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi2_phi0.8/300_300_300_1 --optimizer lbfgs --function f1 --psi 2 --phi 0.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi2_phi0.8/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb665416268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6654c7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6654208c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6654e5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6654f0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6386cd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb63869dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6386d82f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb63865c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb63865ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6653947b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6653948c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6103db8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6385f4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb63860b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb638615d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb63861d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb63861d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6103470d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb610347d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6102d9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6102d9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb610232730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6102d9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb61023d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6102246a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6101df730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6101df158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6101c2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb610180a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6101046a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6100b0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6100ae2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6100cfd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb61027ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb610277f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 9.68948734e-06
Iter: 2 loss: 9.63135335e-06
Iter: 3 loss: 1.03833327e-05
Iter: 4 loss: 9.63087223e-06
Iter: 5 loss: 9.59811678e-06
Iter: 6 loss: 9.70137262e-06
Iter: 7 loss: 9.58854616e-06
Iter: 8 loss: 9.56549866e-06
Iter: 9 loss: 9.58274177e-06
Iter: 10 loss: 9.55134601e-06
Iter: 11 loss: 9.52365917e-06
Iter: 12 loss: 9.69372377e-06
Iter: 13 loss: 9.52021583e-06
Iter: 14 loss: 9.49757e-06
Iter: 15 loss: 9.55013638e-06
Iter: 16 loss: 9.48912748e-06
Iter: 17 loss: 9.47132139e-06
Iter: 18 loss: 9.49431524e-06
Iter: 19 loss: 9.46217824e-06
Iter: 20 loss: 9.4357838e-06
Iter: 21 loss: 9.54540337e-06
Iter: 22 loss: 9.43014857e-06
Iter: 23 loss: 9.41574217e-06
Iter: 24 loss: 9.40390237e-06
Iter: 25 loss: 9.39973e-06
Iter: 26 loss: 9.38406083e-06
Iter: 27 loss: 9.38320954e-06
Iter: 28 loss: 9.37496497e-06
Iter: 29 loss: 9.35235403e-06
Iter: 30 loss: 9.48473644e-06
Iter: 31 loss: 9.34598756e-06
Iter: 32 loss: 9.31505656e-06
Iter: 33 loss: 9.37743062e-06
Iter: 34 loss: 9.30249826e-06
Iter: 35 loss: 9.27261317e-06
Iter: 36 loss: 9.40268546e-06
Iter: 37 loss: 9.26652592e-06
Iter: 38 loss: 9.24410506e-06
Iter: 39 loss: 9.3280687e-06
Iter: 40 loss: 9.23863536e-06
Iter: 41 loss: 9.22686e-06
Iter: 42 loss: 9.22670552e-06
Iter: 43 loss: 9.2140308e-06
Iter: 44 loss: 9.24694632e-06
Iter: 45 loss: 9.2097107e-06
Iter: 46 loss: 9.20161619e-06
Iter: 47 loss: 9.20791e-06
Iter: 48 loss: 9.19672402e-06
Iter: 49 loss: 9.18727892e-06
Iter: 50 loss: 9.29707676e-06
Iter: 51 loss: 9.18720798e-06
Iter: 52 loss: 9.18232e-06
Iter: 53 loss: 9.17938087e-06
Iter: 54 loss: 9.17738907e-06
Iter: 55 loss: 9.16902172e-06
Iter: 56 loss: 9.21575611e-06
Iter: 57 loss: 9.16782938e-06
Iter: 58 loss: 9.16116e-06
Iter: 59 loss: 9.18414298e-06
Iter: 60 loss: 9.15941746e-06
Iter: 61 loss: 9.15422061e-06
Iter: 62 loss: 9.14726843e-06
Iter: 63 loss: 9.14690736e-06
Iter: 64 loss: 9.13886288e-06
Iter: 65 loss: 9.13874737e-06
Iter: 66 loss: 9.13480926e-06
Iter: 67 loss: 9.1243237e-06
Iter: 68 loss: 9.19883405e-06
Iter: 69 loss: 9.12193536e-06
Iter: 70 loss: 9.10891e-06
Iter: 71 loss: 9.15955479e-06
Iter: 72 loss: 9.10590916e-06
Iter: 73 loss: 9.0970243e-06
Iter: 74 loss: 9.12870564e-06
Iter: 75 loss: 9.09462869e-06
Iter: 76 loss: 9.08524453e-06
Iter: 77 loss: 9.09368282e-06
Iter: 78 loss: 9.07971116e-06
Iter: 79 loss: 9.0773774e-06
Iter: 80 loss: 9.07531103e-06
Iter: 81 loss: 9.06991772e-06
Iter: 82 loss: 9.06442438e-06
Iter: 83 loss: 9.06340392e-06
Iter: 84 loss: 9.05892375e-06
Iter: 85 loss: 9.10829294e-06
Iter: 86 loss: 9.05884554e-06
Iter: 87 loss: 9.05436718e-06
Iter: 88 loss: 9.05989145e-06
Iter: 89 loss: 9.05204615e-06
Iter: 90 loss: 9.04828448e-06
Iter: 91 loss: 9.0538806e-06
Iter: 92 loss: 9.04641456e-06
Iter: 93 loss: 9.04095123e-06
Iter: 94 loss: 9.06441892e-06
Iter: 95 loss: 9.03983801e-06
Iter: 96 loss: 9.03632554e-06
Iter: 97 loss: 9.03574619e-06
Iter: 98 loss: 9.03327509e-06
Iter: 99 loss: 9.02801e-06
Iter: 100 loss: 9.05978595e-06
Iter: 101 loss: 9.02737156e-06
Iter: 102 loss: 9.02339616e-06
Iter: 103 loss: 9.04234912e-06
Iter: 104 loss: 9.02261672e-06
Iter: 105 loss: 9.01955536e-06
Iter: 106 loss: 9.01354e-06
Iter: 107 loss: 9.1329257e-06
Iter: 108 loss: 9.01345084e-06
Iter: 109 loss: 9.00709256e-06
Iter: 110 loss: 9.01166914e-06
Iter: 111 loss: 9.0031408e-06
Iter: 112 loss: 8.99543193e-06
Iter: 113 loss: 9.02553802e-06
Iter: 114 loss: 8.99367114e-06
Iter: 115 loss: 8.98785947e-06
Iter: 116 loss: 9.03337877e-06
Iter: 117 loss: 8.98739472e-06
Iter: 118 loss: 8.98322469e-06
Iter: 119 loss: 8.99265069e-06
Iter: 120 loss: 8.98165672e-06
Iter: 121 loss: 8.97891823e-06
Iter: 122 loss: 8.97850714e-06
Iter: 123 loss: 8.97664268e-06
Iter: 124 loss: 8.97188875e-06
Iter: 125 loss: 9.01168096e-06
Iter: 126 loss: 8.97106656e-06
Iter: 127 loss: 8.96944e-06
Iter: 128 loss: 8.96804158e-06
Iter: 129 loss: 8.96624e-06
Iter: 130 loss: 8.96229449e-06
Iter: 131 loss: 9.0171643e-06
Iter: 132 loss: 8.9621044e-06
Iter: 133 loss: 8.95921e-06
Iter: 134 loss: 8.95888752e-06
Iter: 135 loss: 8.95674293e-06
Iter: 136 loss: 8.95372796e-06
Iter: 137 loss: 8.95357789e-06
Iter: 138 loss: 8.95112e-06
Iter: 139 loss: 8.97785776e-06
Iter: 140 loss: 8.95109e-06
Iter: 141 loss: 8.94860932e-06
Iter: 142 loss: 8.95024641e-06
Iter: 143 loss: 8.94701589e-06
Iter: 144 loss: 8.94360528e-06
Iter: 145 loss: 8.94954246e-06
Iter: 146 loss: 8.94209097e-06
Iter: 147 loss: 8.93941797e-06
Iter: 148 loss: 8.93661854e-06
Iter: 149 loss: 8.93611468e-06
Iter: 150 loss: 8.93156448e-06
Iter: 151 loss: 8.93976085e-06
Iter: 152 loss: 8.92959815e-06
Iter: 153 loss: 8.92593926e-06
Iter: 154 loss: 8.96144411e-06
Iter: 155 loss: 8.92581829e-06
Iter: 156 loss: 8.92303524e-06
Iter: 157 loss: 8.96623351e-06
Iter: 158 loss: 8.92303251e-06
Iter: 159 loss: 8.92137086e-06
Iter: 160 loss: 8.91827221e-06
Iter: 161 loss: 8.97898e-06
Iter: 162 loss: 8.9182613e-06
Iter: 163 loss: 8.91655691e-06
Iter: 164 loss: 8.9160967e-06
Iter: 165 loss: 8.91475065e-06
Iter: 166 loss: 8.91161562e-06
Iter: 167 loss: 8.95139056e-06
Iter: 168 loss: 8.91144555e-06
Iter: 169 loss: 8.91005129e-06
Iter: 170 loss: 8.90945e-06
Iter: 171 loss: 8.90843694e-06
Iter: 172 loss: 8.90601e-06
Iter: 173 loss: 8.93769447e-06
Iter: 174 loss: 8.90586489e-06
Iter: 175 loss: 8.90362389e-06
Iter: 176 loss: 8.93524e-06
Iter: 177 loss: 8.90363117e-06
Iter: 178 loss: 8.90141291e-06
Iter: 179 loss: 8.90285082e-06
Iter: 180 loss: 8.90004048e-06
Iter: 181 loss: 8.89779221e-06
Iter: 182 loss: 8.90174942e-06
Iter: 183 loss: 8.89690091e-06
Iter: 184 loss: 8.8943807e-06
Iter: 185 loss: 8.89413423e-06
Iter: 186 loss: 8.89229614e-06
Iter: 187 loss: 8.88955219e-06
Iter: 188 loss: 8.89337389e-06
Iter: 189 loss: 8.88825e-06
Iter: 190 loss: 8.88516843e-06
Iter: 191 loss: 8.89192415e-06
Iter: 192 loss: 8.88400427e-06
Iter: 193 loss: 8.88023897e-06
Iter: 194 loss: 8.88845261e-06
Iter: 195 loss: 8.8787674e-06
Iter: 196 loss: 8.87567694e-06
Iter: 197 loss: 8.89129842e-06
Iter: 198 loss: 8.87509668e-06
Iter: 199 loss: 8.87438364e-06
Iter: 200 loss: 8.8738625e-06
Iter: 201 loss: 8.87261922e-06
Iter: 202 loss: 8.86998714e-06
Iter: 203 loss: 8.9144678e-06
Iter: 204 loss: 8.86990165e-06
Iter: 205 loss: 8.8693123e-06
Iter: 206 loss: 8.86877933e-06
Iter: 207 loss: 8.86779253e-06
Iter: 208 loss: 8.86527141e-06
Iter: 209 loss: 8.88071099e-06
Iter: 210 loss: 8.86456382e-06
Iter: 211 loss: 8.8628467e-06
Iter: 212 loss: 8.86267208e-06
Iter: 213 loss: 8.86092312e-06
Iter: 214 loss: 8.86076577e-06
Iter: 215 loss: 8.85949248e-06
Iter: 216 loss: 8.85794907e-06
Iter: 217 loss: 8.86074486e-06
Iter: 218 loss: 8.85735517e-06
Iter: 219 loss: 8.85534701e-06
Iter: 220 loss: 8.86635371e-06
Iter: 221 loss: 8.85505324e-06
Iter: 222 loss: 8.85340796e-06
Iter: 223 loss: 8.85594272e-06
Iter: 224 loss: 8.85258305e-06
Iter: 225 loss: 8.85093e-06
Iter: 226 loss: 8.84898509e-06
Iter: 227 loss: 8.84878136e-06
Iter: 228 loss: 8.84606197e-06
Iter: 229 loss: 8.84762449e-06
Iter: 230 loss: 8.84433666e-06
Iter: 231 loss: 8.84133e-06
Iter: 232 loss: 8.86439e-06
Iter: 233 loss: 8.84110705e-06
Iter: 234 loss: 8.83979101e-06
Iter: 235 loss: 8.83973735e-06
Iter: 236 loss: 8.83813482e-06
Iter: 237 loss: 8.83704524e-06
Iter: 238 loss: 8.83644771e-06
Iter: 239 loss: 8.83477514e-06
Iter: 240 loss: 8.84739165e-06
Iter: 241 loss: 8.83466782e-06
Iter: 242 loss: 8.8327406e-06
Iter: 243 loss: 8.83303164e-06
Iter: 244 loss: 8.83132634e-06
Iter: 245 loss: 8.8298184e-06
Iter: 246 loss: 8.83175926e-06
Iter: 247 loss: 8.8290717e-06
Iter: 248 loss: 8.82677523e-06
Iter: 249 loss: 8.83858684e-06
Iter: 250 loss: 8.82646418e-06
Iter: 251 loss: 8.8256038e-06
Iter: 252 loss: 8.8241959e-06
Iter: 253 loss: 8.8241668e-06
Iter: 254 loss: 8.82268341e-06
Iter: 255 loss: 8.8226534e-06
Iter: 256 loss: 8.82149e-06
Iter: 257 loss: 8.81998312e-06
Iter: 258 loss: 8.81994e-06
Iter: 259 loss: 8.8179313e-06
Iter: 260 loss: 8.82484801e-06
Iter: 261 loss: 8.81748201e-06
Iter: 262 loss: 8.81549931e-06
Iter: 263 loss: 8.8146935e-06
Iter: 264 loss: 8.81371216e-06
Iter: 265 loss: 8.81141932e-06
Iter: 266 loss: 8.81871074e-06
Iter: 267 loss: 8.81073538e-06
Iter: 268 loss: 8.81022243e-06
Iter: 269 loss: 8.80963125e-06
Iter: 270 loss: 8.80871085e-06
Iter: 271 loss: 8.80676e-06
Iter: 272 loss: 8.8353454e-06
Iter: 273 loss: 8.80666266e-06
Iter: 274 loss: 8.80552761e-06
Iter: 275 loss: 8.80538119e-06
Iter: 276 loss: 8.80437074e-06
Iter: 277 loss: 8.80232074e-06
Iter: 278 loss: 8.83757821e-06
Iter: 279 loss: 8.80225707e-06
Iter: 280 loss: 8.80091739e-06
Iter: 281 loss: 8.8008419e-06
Iter: 282 loss: 8.7994631e-06
Iter: 283 loss: 8.79911204e-06
Iter: 284 loss: 8.79819254e-06
Iter: 285 loss: 8.79686195e-06
Iter: 286 loss: 8.79746221e-06
Iter: 287 loss: 8.79589788e-06
Iter: 288 loss: 8.79427535e-06
Iter: 289 loss: 8.79428717e-06
Iter: 290 loss: 8.79341587e-06
Iter: 291 loss: 8.79132767e-06
Iter: 292 loss: 8.8153e-06
Iter: 293 loss: 8.79118306e-06
Iter: 294 loss: 8.78893934e-06
Iter: 295 loss: 8.80987136e-06
Iter: 296 loss: 8.78883657e-06
Iter: 297 loss: 8.78710762e-06
Iter: 298 loss: 8.78678475e-06
Iter: 299 loss: 8.78562696e-06
Iter: 300 loss: 8.78438095e-06
Iter: 301 loss: 8.78428636e-06
Iter: 302 loss: 8.78311948e-06
Iter: 303 loss: 8.7854587e-06
Iter: 304 loss: 8.78262745e-06
Iter: 305 loss: 8.78171886e-06
Iter: 306 loss: 8.781828e-06
Iter: 307 loss: 8.78098763e-06
Iter: 308 loss: 8.77914863e-06
Iter: 309 loss: 8.78394349e-06
Iter: 310 loss: 8.77855109e-06
Iter: 311 loss: 8.77751e-06
Iter: 312 loss: 8.7776807e-06
Iter: 313 loss: 8.77674e-06
Iter: 314 loss: 8.77544335e-06
Iter: 315 loss: 8.79204e-06
Iter: 316 loss: 8.77537059e-06
Iter: 317 loss: 8.77451839e-06
Iter: 318 loss: 8.77263301e-06
Iter: 319 loss: 8.80110747e-06
Iter: 320 loss: 8.77259117e-06
Iter: 321 loss: 8.77184539e-06
Iter: 322 loss: 8.77151433e-06
Iter: 323 loss: 8.77054663e-06
Iter: 324 loss: 8.76913509e-06
Iter: 325 loss: 8.76911417e-06
Iter: 326 loss: 8.7676417e-06
Iter: 327 loss: 8.76738432e-06
Iter: 328 loss: 8.76632112e-06
Iter: 329 loss: 8.76429658e-06
Iter: 330 loss: 8.78440824e-06
Iter: 331 loss: 8.76423564e-06
Iter: 332 loss: 8.7628905e-06
Iter: 333 loss: 8.76332524e-06
Iter: 334 loss: 8.76199192e-06
Iter: 335 loss: 8.76111062e-06
Iter: 336 loss: 8.76090053e-06
Iter: 337 loss: 8.76021477e-06
Iter: 338 loss: 8.75878322e-06
Iter: 339 loss: 8.78236e-06
Iter: 340 loss: 8.75873411e-06
Iter: 341 loss: 8.75754813e-06
Iter: 342 loss: 8.75753449e-06
Iter: 343 loss: 8.75662499e-06
Iter: 344 loss: 8.75478872e-06
Iter: 345 loss: 8.78857827e-06
Iter: 346 loss: 8.75474507e-06
Iter: 347 loss: 8.75386104e-06
Iter: 348 loss: 8.75373644e-06
Iter: 349 loss: 8.75272053e-06
Iter: 350 loss: 8.75100613e-06
Iter: 351 loss: 8.75099067e-06
Iter: 352 loss: 8.74958641e-06
Iter: 353 loss: 8.75190744e-06
Iter: 354 loss: 8.7489334e-06
Iter: 355 loss: 8.747842e-06
Iter: 356 loss: 8.74782836e-06
Iter: 357 loss: 8.7469889e-06
Iter: 358 loss: 8.74516e-06
Iter: 359 loss: 8.77041566e-06
Iter: 360 loss: 8.74504258e-06
Iter: 361 loss: 8.74326906e-06
Iter: 362 loss: 8.74598118e-06
Iter: 363 loss: 8.74245779e-06
Iter: 364 loss: 8.74054786e-06
Iter: 365 loss: 8.75776914e-06
Iter: 366 loss: 8.74049238e-06
Iter: 367 loss: 8.73901809e-06
Iter: 368 loss: 8.74310354e-06
Iter: 369 loss: 8.73851423e-06
Iter: 370 loss: 8.73750105e-06
Iter: 371 loss: 8.73746285e-06
Iter: 372 loss: 8.73681165e-06
Iter: 373 loss: 8.73539193e-06
Iter: 374 loss: 8.75598744e-06
Iter: 375 loss: 8.73530371e-06
Iter: 376 loss: 8.73404497e-06
Iter: 377 loss: 8.73405315e-06
Iter: 378 loss: 8.73312092e-06
Iter: 379 loss: 8.73112185e-06
Iter: 380 loss: 8.75902879e-06
Iter: 381 loss: 8.73098907e-06
Iter: 382 loss: 8.73010777e-06
Iter: 383 loss: 8.72982127e-06
Iter: 384 loss: 8.72887085e-06
Iter: 385 loss: 8.72811142e-06
Iter: 386 loss: 8.72777127e-06
Iter: 387 loss: 8.72657711e-06
Iter: 388 loss: 8.72702549e-06
Iter: 389 loss: 8.72582496e-06
Iter: 390 loss: 8.72454257e-06
Iter: 391 loss: 8.72452893e-06
Iter: 392 loss: 8.72390137e-06
Iter: 393 loss: 8.72212058e-06
Iter: 394 loss: 8.72790315e-06
Iter: 395 loss: 8.72131659e-06
Iter: 396 loss: 8.71868451e-06
Iter: 397 loss: 8.7356093e-06
Iter: 398 loss: 8.7184344e-06
Iter: 399 loss: 8.71648535e-06
Iter: 400 loss: 8.72605051e-06
Iter: 401 loss: 8.7162507e-06
Iter: 402 loss: 8.71478551e-06
Iter: 403 loss: 8.72564669e-06
Iter: 404 loss: 8.71463635e-06
Iter: 405 loss: 8.71366319e-06
Iter: 406 loss: 8.72290184e-06
Iter: 407 loss: 8.71355587e-06
Iter: 408 loss: 8.71268367e-06
Iter: 409 loss: 8.71151497e-06
Iter: 410 loss: 8.71135671e-06
Iter: 411 loss: 8.71037719e-06
Iter: 412 loss: 8.71035354e-06
Iter: 413 loss: 8.70929216e-06
Iter: 414 loss: 8.70762597e-06
Iter: 415 loss: 8.70764779e-06
Iter: 416 loss: 8.70617714e-06
Iter: 417 loss: 8.71501925e-06
Iter: 418 loss: 8.7059525e-06
Iter: 419 loss: 8.70442091e-06
Iter: 420 loss: 8.71165685e-06
Iter: 421 loss: 8.70405347e-06
Iter: 422 loss: 8.70321128e-06
Iter: 423 loss: 8.70217536e-06
Iter: 424 loss: 8.70212716e-06
Iter: 425 loss: 8.70122767e-06
Iter: 426 loss: 8.70113945e-06
Iter: 427 loss: 8.70035728e-06
Iter: 428 loss: 8.69850737e-06
Iter: 429 loss: 8.72054534e-06
Iter: 430 loss: 8.69831456e-06
Iter: 431 loss: 8.69653e-06
Iter: 432 loss: 8.69659743e-06
Iter: 433 loss: 8.69512e-06
Iter: 434 loss: 8.69287e-06
Iter: 435 loss: 8.71011071e-06
Iter: 436 loss: 8.69268297e-06
Iter: 437 loss: 8.69112409e-06
Iter: 438 loss: 8.70032818e-06
Iter: 439 loss: 8.69096129e-06
Iter: 440 loss: 8.6895634e-06
Iter: 441 loss: 8.69367523e-06
Iter: 442 loss: 8.68905772e-06
Iter: 443 loss: 8.68780717e-06
Iter: 444 loss: 8.70499389e-06
Iter: 445 loss: 8.68786174e-06
Iter: 446 loss: 8.68679854e-06
Iter: 447 loss: 8.68551524e-06
Iter: 448 loss: 8.6854343e-06
Iter: 449 loss: 8.68434199e-06
Iter: 450 loss: 8.70024633e-06
Iter: 451 loss: 8.68436473e-06
Iter: 452 loss: 8.68334791e-06
Iter: 453 loss: 8.68256484e-06
Iter: 454 loss: 8.68218831e-06
Iter: 455 loss: 8.68102688e-06
Iter: 456 loss: 8.68462485e-06
Iter: 457 loss: 8.6807031e-06
Iter: 458 loss: 8.67944163e-06
Iter: 459 loss: 8.68825e-06
Iter: 460 loss: 8.67928247e-06
Iter: 461 loss: 8.67849758e-06
Iter: 462 loss: 8.67694689e-06
Iter: 463 loss: 8.70607801e-06
Iter: 464 loss: 8.67687595e-06
Iter: 465 loss: 8.67559447e-06
Iter: 466 loss: 8.67548897e-06
Iter: 467 loss: 8.67454582e-06
Iter: 468 loss: 8.67258859e-06
Iter: 469 loss: 8.71061457e-06
Iter: 470 loss: 8.67253766e-06
Iter: 471 loss: 8.67088329e-06
Iter: 472 loss: 8.67134077e-06
Iter: 473 loss: 8.66961909e-06
Iter: 474 loss: 8.66746814e-06
Iter: 475 loss: 8.67915151e-06
Iter: 476 loss: 8.66715163e-06
Iter: 477 loss: 8.66643677e-06
Iter: 478 loss: 8.66618e-06
Iter: 479 loss: 8.66520531e-06
Iter: 480 loss: 8.664083e-06
Iter: 481 loss: 8.66395112e-06
Iter: 482 loss: 8.66263872e-06
Iter: 483 loss: 8.66887603e-06
Iter: 484 loss: 8.66239498e-06
Iter: 485 loss: 8.66112e-06
Iter: 486 loss: 8.66608116e-06
Iter: 487 loss: 8.66083337e-06
Iter: 488 loss: 8.6596574e-06
Iter: 489 loss: 8.66230766e-06
Iter: 490 loss: 8.65914444e-06
Iter: 491 loss: 8.65832862e-06
Iter: 492 loss: 8.65829952e-06
Iter: 493 loss: 8.65756374e-06
Iter: 494 loss: 8.65607e-06
Iter: 495 loss: 8.66402843e-06
Iter: 496 loss: 8.65579932e-06
Iter: 497 loss: 8.65475158e-06
Iter: 498 loss: 8.65339371e-06
Iter: 499 loss: 8.65327e-06
Iter: 500 loss: 8.65233778e-06
Iter: 501 loss: 8.65211223e-06
Iter: 502 loss: 8.65148195e-06
Iter: 503 loss: 8.64955564e-06
Iter: 504 loss: 8.66292e-06
Iter: 505 loss: 8.64912909e-06
Iter: 506 loss: 8.64690082e-06
Iter: 507 loss: 8.65198854e-06
Iter: 508 loss: 8.6460368e-06
Iter: 509 loss: 8.64384765e-06
Iter: 510 loss: 8.64745562e-06
Iter: 511 loss: 8.64284084e-06
Iter: 512 loss: 8.64283629e-06
Iter: 513 loss: 8.64166e-06
Iter: 514 loss: 8.64077083e-06
Iter: 515 loss: 8.63906735e-06
Iter: 516 loss: 8.67538438e-06
Iter: 517 loss: 8.63906462e-06
Iter: 518 loss: 8.63760397e-06
Iter: 519 loss: 8.65120273e-06
Iter: 520 loss: 8.63756941e-06
Iter: 521 loss: 8.63623e-06
Iter: 522 loss: 8.63999776e-06
Iter: 523 loss: 8.63577861e-06
Iter: 524 loss: 8.6347e-06
Iter: 525 loss: 8.63610512e-06
Iter: 526 loss: 8.63416517e-06
Iter: 527 loss: 8.63285459e-06
Iter: 528 loss: 8.63529e-06
Iter: 529 loss: 8.63234163e-06
Iter: 530 loss: 8.63070818e-06
Iter: 531 loss: 8.63996502e-06
Iter: 532 loss: 8.630509e-06
Iter: 533 loss: 8.62953493e-06
Iter: 534 loss: 8.62791512e-06
Iter: 535 loss: 8.62799243e-06
Iter: 536 loss: 8.62579691e-06
Iter: 537 loss: 8.65466154e-06
Iter: 538 loss: 8.62580691e-06
Iter: 539 loss: 8.6248383e-06
Iter: 540 loss: 8.62325305e-06
Iter: 541 loss: 8.62325214e-06
Iter: 542 loss: 8.62150591e-06
Iter: 543 loss: 8.62235356e-06
Iter: 544 loss: 8.62036177e-06
Iter: 545 loss: 8.61824083e-06
Iter: 546 loss: 8.6293494e-06
Iter: 547 loss: 8.61794e-06
Iter: 548 loss: 8.61736135e-06
Iter: 549 loss: 8.61690751e-06
Iter: 550 loss: 8.61616172e-06
Iter: 551 loss: 8.61387343e-06
Iter: 552 loss: 8.62421803e-06
Iter: 553 loss: 8.61308e-06
Iter: 554 loss: 8.61228273e-06
Iter: 555 loss: 8.61185e-06
Iter: 556 loss: 8.61065473e-06
Iter: 557 loss: 8.60981891e-06
Iter: 558 loss: 8.60936052e-06
Iter: 559 loss: 8.60805631e-06
Iter: 560 loss: 8.61188255e-06
Iter: 561 loss: 8.6076252e-06
Iter: 562 loss: 8.60612636e-06
Iter: 563 loss: 8.61284e-06
Iter: 564 loss: 8.60575256e-06
Iter: 565 loss: 8.60444834e-06
Iter: 566 loss: 8.60573891e-06
Iter: 567 loss: 8.60365162e-06
Iter: 568 loss: 8.60202454e-06
Iter: 569 loss: 8.60679393e-06
Iter: 570 loss: 8.60147429e-06
Iter: 571 loss: 8.60005639e-06
Iter: 572 loss: 8.61171793e-06
Iter: 573 loss: 8.59998909e-06
Iter: 574 loss: 8.59892862e-06
Iter: 575 loss: 8.59659121e-06
Iter: 576 loss: 8.63542118e-06
Iter: 577 loss: 8.59654392e-06
Iter: 578 loss: 8.59442662e-06
Iter: 579 loss: 8.59952161e-06
Iter: 580 loss: 8.59360534e-06
Iter: 581 loss: 8.59144166e-06
Iter: 582 loss: 8.59771e-06
Iter: 583 loss: 8.59072316e-06
Iter: 584 loss: 8.5903639e-06
Iter: 585 loss: 8.58964904e-06
Iter: 586 loss: 8.58889507e-06
Iter: 587 loss: 8.58713793e-06
Iter: 588 loss: 8.60182e-06
Iter: 589 loss: 8.58682142e-06
Iter: 590 loss: 8.5853917e-06
Iter: 591 loss: 8.60689124e-06
Iter: 592 loss: 8.58540443e-06
Iter: 593 loss: 8.5838119e-06
Iter: 594 loss: 8.5852007e-06
Iter: 595 loss: 8.58292151e-06
Iter: 596 loss: 8.58177e-06
Iter: 597 loss: 8.58280509e-06
Iter: 598 loss: 8.58116346e-06
Iter: 599 loss: 8.57944906e-06
Iter: 600 loss: 8.58745443e-06
Iter: 601 loss: 8.57916893e-06
Iter: 602 loss: 8.5780448e-06
Iter: 603 loss: 8.57669e-06
Iter: 604 loss: 8.57656e-06
Iter: 605 loss: 8.57495252e-06
Iter: 606 loss: 8.57494069e-06
Iter: 607 loss: 8.57381383e-06
Iter: 608 loss: 8.57452e-06
Iter: 609 loss: 8.5731408e-06
Iter: 610 loss: 8.57182476e-06
Iter: 611 loss: 8.57340092e-06
Iter: 612 loss: 8.57109e-06
Iter: 613 loss: 8.56964471e-06
Iter: 614 loss: 8.56685074e-06
Iter: 615 loss: 8.62759225e-06
Iter: 616 loss: 8.5668571e-06
Iter: 617 loss: 8.56435327e-06
Iter: 618 loss: 8.59463671e-06
Iter: 619 loss: 8.56433e-06
Iter: 620 loss: 8.56266706e-06
Iter: 621 loss: 8.56265706e-06
Iter: 622 loss: 8.56178667e-06
Iter: 623 loss: 8.55974395e-06
Iter: 624 loss: 8.58215481e-06
Iter: 625 loss: 8.55942744e-06
Iter: 626 loss: 8.55845883e-06
Iter: 627 loss: 8.55829239e-06
Iter: 628 loss: 8.55715462e-06
Iter: 629 loss: 8.55660255e-06
Iter: 630 loss: 8.55603685e-06
Iter: 631 loss: 8.55478e-06
Iter: 632 loss: 8.55677808e-06
Iter: 633 loss: 8.55422604e-06
Iter: 634 loss: 8.55224152e-06
Iter: 635 loss: 8.56090628e-06
Iter: 636 loss: 8.55186772e-06
Iter: 637 loss: 8.55070721e-06
Iter: 638 loss: 8.54923292e-06
Iter: 639 loss: 8.54908285e-06
Iter: 640 loss: 8.5476e-06
Iter: 641 loss: 8.54755308e-06
Iter: 642 loss: 8.5467e-06
Iter: 643 loss: 8.5450738e-06
Iter: 644 loss: 8.58084786e-06
Iter: 645 loss: 8.54508835e-06
Iter: 646 loss: 8.54314203e-06
Iter: 647 loss: 8.55319377e-06
Iter: 648 loss: 8.54288e-06
Iter: 649 loss: 8.54127302e-06
Iter: 650 loss: 8.54034533e-06
Iter: 651 loss: 8.53977e-06
Iter: 652 loss: 8.53714846e-06
Iter: 653 loss: 8.54145947e-06
Iter: 654 loss: 8.53593883e-06
Iter: 655 loss: 8.53566598e-06
Iter: 656 loss: 8.5348729e-06
Iter: 657 loss: 8.53368419e-06
Iter: 658 loss: 8.5313477e-06
Iter: 659 loss: 8.575842e-06
Iter: 660 loss: 8.53139318e-06
Iter: 661 loss: 8.52953781e-06
Iter: 662 loss: 8.53821348e-06
Iter: 663 loss: 8.52920675e-06
Iter: 664 loss: 8.52752237e-06
Iter: 665 loss: 8.54414429e-06
Iter: 666 loss: 8.52746052e-06
Iter: 667 loss: 8.52641824e-06
Iter: 668 loss: 8.52429912e-06
Iter: 669 loss: 8.55701e-06
Iter: 670 loss: 8.52417088e-06
Iter: 671 loss: 8.52262292e-06
Iter: 672 loss: 8.5224774e-06
Iter: 673 loss: 8.52131052e-06
Iter: 674 loss: 8.51917139e-06
Iter: 675 loss: 8.56845e-06
Iter: 676 loss: 8.51913865e-06
Iter: 677 loss: 8.51788718e-06
Iter: 678 loss: 8.51778e-06
Iter: 679 loss: 8.5164811e-06
Iter: 680 loss: 8.51502e-06
Iter: 681 loss: 8.51478399e-06
Iter: 682 loss: 8.51306504e-06
Iter: 683 loss: 8.5148522e-06
Iter: 684 loss: 8.51213736e-06
Iter: 685 loss: 8.50952529e-06
Iter: 686 loss: 8.51718323e-06
Iter: 687 loss: 8.50879678e-06
Iter: 688 loss: 8.50692e-06
Iter: 689 loss: 8.50875222e-06
Iter: 690 loss: 8.50584274e-06
Iter: 691 loss: 8.50496326e-06
Iter: 692 loss: 8.50461e-06
Iter: 693 loss: 8.5036e-06
Iter: 694 loss: 8.5015854e-06
Iter: 695 loss: 8.54119935e-06
Iter: 696 loss: 8.50157357e-06
Iter: 697 loss: 8.49992375e-06
Iter: 698 loss: 8.50902416e-06
Iter: 699 loss: 8.49967e-06
Iter: 700 loss: 8.49756361e-06
Iter: 701 loss: 8.50181823e-06
Iter: 702 loss: 8.49674325e-06
Iter: 703 loss: 8.49533353e-06
Iter: 704 loss: 8.49481148e-06
Iter: 705 loss: 8.4940566e-06
Iter: 706 loss: 8.49137541e-06
Iter: 707 loss: 8.50912875e-06
Iter: 708 loss: 8.49107164e-06
Iter: 709 loss: 8.4898229e-06
Iter: 710 loss: 8.48901618e-06
Iter: 711 loss: 8.48853597e-06
Iter: 712 loss: 8.48669697e-06
Iter: 713 loss: 8.51164259e-06
Iter: 714 loss: 8.48670152e-06
Iter: 715 loss: 8.48564e-06
Iter: 716 loss: 8.48321179e-06
Iter: 717 loss: 8.51579443e-06
Iter: 718 loss: 8.48304626e-06
Iter: 719 loss: 8.48064701e-06
Iter: 720 loss: 8.5016527e-06
Iter: 721 loss: 8.48059517e-06
Iter: 722 loss: 8.47839e-06
Iter: 723 loss: 8.47812225e-06
Iter: 724 loss: 8.47656884e-06
Iter: 725 loss: 8.47509091e-06
Iter: 726 loss: 8.47499e-06
Iter: 727 loss: 8.47348838e-06
Iter: 728 loss: 8.47338197e-06
Iter: 729 loss: 8.47226511e-06
Iter: 730 loss: 8.47086267e-06
Iter: 731 loss: 8.47097908e-06
Iter: 732 loss: 8.46982857e-06
Iter: 733 loss: 8.4681742e-06
Iter: 734 loss: 8.46819e-06
Iter: 735 loss: 8.46722833e-06
Iter: 736 loss: 8.46498369e-06
Iter: 737 loss: 8.4949952e-06
Iter: 738 loss: 8.46481817e-06
Iter: 739 loss: 8.46344e-06
Iter: 740 loss: 8.46328203e-06
Iter: 741 loss: 8.46185594e-06
Iter: 742 loss: 8.46016519e-06
Iter: 743 loss: 8.45990689e-06
Iter: 744 loss: 8.45840168e-06
Iter: 745 loss: 8.4818148e-06
Iter: 746 loss: 8.45837621e-06
Iter: 747 loss: 8.45690192e-06
Iter: 748 loss: 8.45452905e-06
Iter: 749 loss: 8.45462546e-06
Iter: 750 loss: 8.45240902e-06
Iter: 751 loss: 8.45758586e-06
Iter: 752 loss: 8.45166778e-06
Iter: 753 loss: 8.44922852e-06
Iter: 754 loss: 8.45751947e-06
Iter: 755 loss: 8.44858278e-06
Iter: 756 loss: 8.44614624e-06
Iter: 757 loss: 8.44816714e-06
Iter: 758 loss: 8.44464739e-06
Iter: 759 loss: 8.44312e-06
Iter: 760 loss: 8.44285387e-06
Iter: 761 loss: 8.44176429e-06
Iter: 762 loss: 8.43937778e-06
Iter: 763 loss: 8.46507191e-06
Iter: 764 loss: 8.43908492e-06
Iter: 765 loss: 8.43791804e-06
Iter: 766 loss: 8.43760608e-06
Iter: 767 loss: 8.43637e-06
Iter: 768 loss: 8.43439102e-06
Iter: 769 loss: 8.43435919e-06
Iter: 770 loss: 8.43255293e-06
Iter: 771 loss: 8.44075294e-06
Iter: 772 loss: 8.43221733e-06
Iter: 773 loss: 8.43009e-06
Iter: 774 loss: 8.43987436e-06
Iter: 775 loss: 8.4296671e-06
Iter: 776 loss: 8.42833288e-06
Iter: 777 loss: 8.42849477e-06
Iter: 778 loss: 8.42744e-06
Iter: 779 loss: 8.42504051e-06
Iter: 780 loss: 8.43343696e-06
Iter: 781 loss: 8.42446e-06
Iter: 782 loss: 8.42293048e-06
Iter: 783 loss: 8.42128429e-06
Iter: 784 loss: 8.42100781e-06
Iter: 785 loss: 8.41856763e-06
Iter: 786 loss: 8.43014641e-06
Iter: 787 loss: 8.41809378e-06
Iter: 788 loss: 8.4157582e-06
Iter: 789 loss: 8.41861947e-06
Iter: 790 loss: 8.41441215e-06
Iter: 791 loss: 8.41287874e-06
Iter: 792 loss: 8.41288511e-06
Iter: 793 loss: 8.41096789e-06
Iter: 794 loss: 8.40916618e-06
Iter: 795 loss: 8.40872599e-06
Iter: 796 loss: 8.40685425e-06
Iter: 797 loss: 8.41102e-06
Iter: 798 loss: 8.40618941e-06
Iter: 799 loss: 8.40392204e-06
Iter: 800 loss: 8.42463396e-06
Iter: 801 loss: 8.40382108e-06
Iter: 802 loss: 8.40271514e-06
Iter: 803 loss: 8.40010125e-06
Iter: 804 loss: 8.43208363e-06
Iter: 805 loss: 8.39988297e-06
Iter: 806 loss: 8.39841778e-06
Iter: 807 loss: 8.39805398e-06
Iter: 808 loss: 8.3964278e-06
Iter: 809 loss: 8.39440327e-06
Iter: 810 loss: 8.39423319e-06
Iter: 811 loss: 8.39268705e-06
Iter: 812 loss: 8.39265613e-06
Iter: 813 loss: 8.39123186e-06
Iter: 814 loss: 8.38847882e-06
Iter: 815 loss: 8.44714123e-06
Iter: 816 loss: 8.38847336e-06
Iter: 817 loss: 8.38595497e-06
Iter: 818 loss: 8.38742108e-06
Iter: 819 loss: 8.3842624e-06
Iter: 820 loss: 8.38155756e-06
Iter: 821 loss: 8.41682413e-06
Iter: 822 loss: 8.3815e-06
Iter: 823 loss: 8.37959578e-06
Iter: 824 loss: 8.38586493e-06
Iter: 825 loss: 8.37901e-06
Iter: 826 loss: 8.37665903e-06
Iter: 827 loss: 8.38898086e-06
Iter: 828 loss: 8.3763216e-06
Iter: 829 loss: 8.37481184e-06
Iter: 830 loss: 8.37265088e-06
Iter: 831 loss: 8.37260268e-06
Iter: 832 loss: 8.3717614e-06
Iter: 833 loss: 8.3713494e-06
Iter: 834 loss: 8.37026073e-06
Iter: 835 loss: 8.3677387e-06
Iter: 836 loss: 8.40426492e-06
Iter: 837 loss: 8.36757317e-06
Iter: 838 loss: 8.36527943e-06
Iter: 839 loss: 8.37214793e-06
Iter: 840 loss: 8.36464824e-06
Iter: 841 loss: 8.36184881e-06
Iter: 842 loss: 8.38510732e-06
Iter: 843 loss: 8.36165782e-06
Iter: 844 loss: 8.36015352e-06
Iter: 845 loss: 8.3590121e-06
Iter: 846 loss: 8.3585e-06
Iter: 847 loss: 8.35571882e-06
Iter: 848 loss: 8.37879816e-06
Iter: 849 loss: 8.35563515e-06
Iter: 850 loss: 8.35429e-06
Iter: 851 loss: 8.35183e-06
Iter: 852 loss: 8.40339635e-06
Iter: 853 loss: 8.35181e-06
Iter: 854 loss: 8.34892217e-06
Iter: 855 loss: 8.36117306e-06
Iter: 856 loss: 8.34833e-06
Iter: 857 loss: 8.34565617e-06
Iter: 858 loss: 8.36080471e-06
Iter: 859 loss: 8.3452378e-06
Iter: 860 loss: 8.34327784e-06
Iter: 861 loss: 8.36153777e-06
Iter: 862 loss: 8.34318416e-06
Iter: 863 loss: 8.3411e-06
Iter: 864 loss: 8.34040657e-06
Iter: 865 loss: 8.33914e-06
Iter: 866 loss: 8.33719241e-06
Iter: 867 loss: 8.33683589e-06
Iter: 868 loss: 8.33550712e-06
Iter: 869 loss: 8.33292415e-06
Iter: 870 loss: 8.33291415e-06
Iter: 871 loss: 8.33185823e-06
Iter: 872 loss: 8.32935802e-06
Iter: 873 loss: 8.35868832e-06
Iter: 874 loss: 8.32919e-06
Iter: 875 loss: 8.32734258e-06
Iter: 876 loss: 8.32727892e-06
Iter: 877 loss: 8.32524893e-06
Iter: 878 loss: 8.32379192e-06
Iter: 879 loss: 8.32306068e-06
Iter: 880 loss: 8.32120713e-06
Iter: 881 loss: 8.33741797e-06
Iter: 882 loss: 8.32111436e-06
Iter: 883 loss: 8.31910711e-06
Iter: 884 loss: 8.31905709e-06
Iter: 885 loss: 8.31745274e-06
Iter: 886 loss: 8.3156574e-06
Iter: 887 loss: 8.31479883e-06
Iter: 888 loss: 8.31389752e-06
Iter: 889 loss: 8.31144644e-06
Iter: 890 loss: 8.31785928e-06
Iter: 891 loss: 8.31065518e-06
Iter: 892 loss: 8.30830413e-06
Iter: 893 loss: 8.34463208e-06
Iter: 894 loss: 8.30830413e-06
Iter: 895 loss: 8.30686076e-06
Iter: 896 loss: 8.31830403e-06
Iter: 897 loss: 8.30673707e-06
Iter: 898 loss: 8.30544741e-06
Iter: 899 loss: 8.30241243e-06
Iter: 900 loss: 8.33910781e-06
Iter: 901 loss: 8.30209683e-06
Iter: 902 loss: 8.30015142e-06
Iter: 903 loss: 8.30008139e-06
Iter: 904 loss: 8.29806e-06
Iter: 905 loss: 8.3007e-06
Iter: 906 loss: 8.29703e-06
Iter: 907 loss: 8.2954266e-06
Iter: 908 loss: 8.29367127e-06
Iter: 909 loss: 8.29337932e-06
Iter: 910 loss: 8.29279e-06
Iter: 911 loss: 8.29221062e-06
Iter: 912 loss: 8.2911065e-06
Iter: 913 loss: 8.28840712e-06
Iter: 914 loss: 8.3219129e-06
Iter: 915 loss: 8.28823431e-06
Iter: 916 loss: 8.2869883e-06
Iter: 917 loss: 8.28675547e-06
Iter: 918 loss: 8.28540578e-06
Iter: 919 loss: 8.28260545e-06
Iter: 920 loss: 8.33199e-06
Iter: 921 loss: 8.28256634e-06
Iter: 922 loss: 8.28029079e-06
Iter: 923 loss: 8.28321663e-06
Iter: 924 loss: 8.27910117e-06
Iter: 925 loss: 8.27667191e-06
Iter: 926 loss: 8.28451266e-06
Iter: 927 loss: 8.27598797e-06
Iter: 928 loss: 8.27434633e-06
Iter: 929 loss: 8.27425174e-06
Iter: 930 loss: 8.27275653e-06
Iter: 931 loss: 8.2741135e-06
Iter: 932 loss: 8.2718816e-06
Iter: 933 loss: 8.27026815e-06
Iter: 934 loss: 8.27138774e-06
Iter: 935 loss: 8.26934411e-06
Iter: 936 loss: 8.2677825e-06
Iter: 937 loss: 8.27696567e-06
Iter: 938 loss: 8.26754331e-06
Iter: 939 loss: 8.26571886e-06
Iter: 940 loss: 8.267677e-06
Iter: 941 loss: 8.26469477e-06
Iter: 942 loss: 8.26340329e-06
Iter: 943 loss: 8.261517e-06
Iter: 944 loss: 8.26148425e-06
Iter: 945 loss: 8.26047471e-06
Iter: 946 loss: 8.2599945e-06
Iter: 947 loss: 8.25889674e-06
Iter: 948 loss: 8.2567276e-06
Iter: 949 loss: 8.29839337e-06
Iter: 950 loss: 8.25665848e-06
Iter: 951 loss: 8.25533698e-06
Iter: 952 loss: 8.25524876e-06
Iter: 953 loss: 8.2539018e-06
Iter: 954 loss: 8.25163625e-06
Iter: 955 loss: 8.25158531e-06
Iter: 956 loss: 8.24954e-06
Iter: 957 loss: 8.25050665e-06
Iter: 958 loss: 8.24810922e-06
Iter: 959 loss: 8.24545714e-06
Iter: 960 loss: 8.2493043e-06
Iter: 961 loss: 8.24416747e-06
Iter: 962 loss: 8.24442395e-06
Iter: 963 loss: 8.24281233e-06
Iter: 964 loss: 8.2418137e-06
Iter: 965 loss: 8.23997652e-06
Iter: 966 loss: 8.28505472e-06
Iter: 967 loss: 8.23992741e-06
Iter: 968 loss: 8.23788287e-06
Iter: 969 loss: 8.24805738e-06
Iter: 970 loss: 8.2375218e-06
Iter: 971 loss: 8.23606933e-06
Iter: 972 loss: 8.24438484e-06
Iter: 973 loss: 8.23585833e-06
Iter: 974 loss: 8.23438495e-06
Iter: 975 loss: 8.2367751e-06
Iter: 976 loss: 8.23371738e-06
Iter: 977 loss: 8.23248502e-06
Iter: 978 loss: 8.23106893e-06
Iter: 979 loss: 8.23088612e-06
Iter: 980 loss: 8.22994934e-06
Iter: 981 loss: 8.22967741e-06
Iter: 982 loss: 8.2286524e-06
Iter: 983 loss: 8.22608581e-06
Iter: 984 loss: 8.25823099e-06
Iter: 985 loss: 8.22595575e-06
Iter: 986 loss: 8.22482616e-06
Iter: 987 loss: 8.22464244e-06
Iter: 988 loss: 8.22335278e-06
Iter: 989 loss: 8.22089351e-06
Iter: 990 loss: 8.27239091e-06
Iter: 991 loss: 8.22086167e-06
Iter: 992 loss: 8.21876711e-06
Iter: 993 loss: 8.22298443e-06
Iter: 994 loss: 8.21786853e-06
Iter: 995 loss: 8.21559479e-06
Iter: 996 loss: 8.21583853e-06
Iter: 997 loss: 8.21387e-06
Iter: 998 loss: 8.21289e-06
Iter: 999 loss: 8.21223693e-06
Iter: 1000 loss: 8.21046706e-06
Iter: 1001 loss: 8.20977e-06
Iter: 1002 loss: 8.20887726e-06
Iter: 1003 loss: 8.20738114e-06
Iter: 1004 loss: 8.21203e-06
Iter: 1005 loss: 8.20689729e-06
Iter: 1006 loss: 8.20502464e-06
Iter: 1007 loss: 8.21084814e-06
Iter: 1008 loss: 8.20448258e-06
Iter: 1009 loss: 8.20278547e-06
Iter: 1010 loss: 8.20822424e-06
Iter: 1011 loss: 8.20228161e-06
Iter: 1012 loss: 8.20086098e-06
Iter: 1013 loss: 8.19929392e-06
Iter: 1014 loss: 8.19913475e-06
Iter: 1015 loss: 8.19767411e-06
Iter: 1016 loss: 8.19752495e-06
Iter: 1017 loss: 8.19629167e-06
Iter: 1018 loss: 8.1934686e-06
Iter: 1019 loss: 8.23559822e-06
Iter: 1020 loss: 8.1933922e-06
Iter: 1021 loss: 8.19147681e-06
Iter: 1022 loss: 8.19142679e-06
Iter: 1023 loss: 8.18960325e-06
Iter: 1024 loss: 8.18927765e-06
Iter: 1025 loss: 8.18800072e-06
Iter: 1026 loss: 8.18639637e-06
Iter: 1027 loss: 8.18357057e-06
Iter: 1028 loss: 8.18352146e-06
Iter: 1029 loss: 8.18024819e-06
Iter: 1030 loss: 8.20316291e-06
Iter: 1031 loss: 8.17994169e-06
Iter: 1032 loss: 8.1783628e-06
Iter: 1033 loss: 8.17809178e-06
Iter: 1034 loss: 8.17685213e-06
Iter: 1035 loss: 8.17374712e-06
Iter: 1036 loss: 8.20355581e-06
Iter: 1037 loss: 8.17337605e-06
Iter: 1038 loss: 8.17151249e-06
Iter: 1039 loss: 8.1714e-06
Iter: 1040 loss: 8.16955071e-06
Iter: 1041 loss: 8.17153432e-06
Iter: 1042 loss: 8.16857391e-06
Iter: 1043 loss: 8.16682e-06
Iter: 1044 loss: 8.17035652e-06
Iter: 1045 loss: 8.16607917e-06
Iter: 1046 loss: 8.16426837e-06
Iter: 1047 loss: 8.16639476e-06
Iter: 1048 loss: 8.16331703e-06
Iter: 1049 loss: 8.16126794e-06
Iter: 1050 loss: 8.18775243e-06
Iter: 1051 loss: 8.16129068e-06
Iter: 1052 loss: 8.16027386e-06
Iter: 1053 loss: 8.15786825e-06
Iter: 1054 loss: 8.18594708e-06
Iter: 1055 loss: 8.15761177e-06
Iter: 1056 loss: 8.15635576e-06
Iter: 1057 loss: 8.15589556e-06
Iter: 1058 loss: 8.15473322e-06
Iter: 1059 loss: 8.15164276e-06
Iter: 1060 loss: 8.1780363e-06
Iter: 1061 loss: 8.15109161e-06
Iter: 1062 loss: 8.14822124e-06
Iter: 1063 loss: 8.15937e-06
Iter: 1064 loss: 8.1475373e-06
Iter: 1065 loss: 8.14544546e-06
Iter: 1066 loss: 8.17274304e-06
Iter: 1067 loss: 8.14543728e-06
Iter: 1068 loss: 8.14287705e-06
Iter: 1069 loss: 8.14712257e-06
Iter: 1070 loss: 8.14181567e-06
Iter: 1071 loss: 8.14041778e-06
Iter: 1072 loss: 8.13932093e-06
Iter: 1073 loss: 8.13884526e-06
Iter: 1074 loss: 8.1369144e-06
Iter: 1075 loss: 8.13694169e-06
Iter: 1076 loss: 8.13569568e-06
Iter: 1077 loss: 8.13435145e-06
Iter: 1078 loss: 8.13418228e-06
Iter: 1079 loss: 8.13200859e-06
Iter: 1080 loss: 8.13982479e-06
Iter: 1081 loss: 8.1314538e-06
Iter: 1082 loss: 8.12992948e-06
Iter: 1083 loss: 8.14587656e-06
Iter: 1084 loss: 8.12991675e-06
Iter: 1085 loss: 8.12832059e-06
Iter: 1086 loss: 8.126377e-06
Iter: 1087 loss: 8.12618418e-06
Iter: 1088 loss: 8.12414e-06
Iter: 1089 loss: 8.13133283e-06
